{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the quality of the dataset, specifically questioning the \"pristine\" set of tweets and suggesting that it might contain misinformation and outofcontext images. The reviewer implies that more analysis is needed to assess the dataset\"s quality and potential noise. While the comment highlights an important area for improvement, it does not provide explicit guidance on how the authors should conduct this analysis or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors can infer that they need to analyze the dataset\"s quality but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the quality of the dataset, specifically questioning the \"pristine\" set of tweets and suggesting that it might contain misinformation and outofcontext images. However, it does not specify which part of the paper discusses the dataset, making it weakly grounded. The comment is specific in detailing the concern about the dataset\"s quality and suggesting additional analysis, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the quality of the dataset, specifically questioning the \"pristine\" set of tweets and suggesting that it might contain misinformation and outofcontext images. The reviewer expresses a desire to see more analysis around the dataset\"s quality and potential noise. However, the comment lacks specific examples or references to support the claim that the dataset is not pristine or that it contains misinformation. This makes the claim 3, as it provides a logical reasoning but lacks detailed evidence or examples to fully substantiate the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the quality of the dataset, specifically questioning the \"pristine\" set of tweets and suggesting that it might contain misinformation and outofcontext images. This is an important point that the authors should address to ensure the reliability and validity of their results. The comment provides a clear direction for improvement by suggesting that more analysis is needed around the dataset\"s quality and potential noise. However, it could be more helpful if it offered specific suggestions on how to conduct this analysis or what aspects to focus on. Overall, the comment is 4 as it identifies a critical area for improvement and provides a general direction for further analysis, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of exploration into the theoretical properties of the proposed algorithm, specifically regarding convergence. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion of what aspects of the theory should be investigated or how to demonstrate convergence properties. Without specific instructions or examples, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a lack of exploration into the theoretical properties of the proposed algorithm, specifically regarding convergence. However, it does not specify which part of the paper this critique pertains to, such as a particular section or analysis. Without explicit references to specific sections or examples, the authors cannot confidently determine where to address this feedback. The comment is vague and lacks specificity, making it difficult for the authors to pinpoint the exact areas needing improvement. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper lacks an exploration into the theoretical properties of the proposed algorithm, specifically regarding convergence. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific references to what aspects of the theory are missing or how the convergence properties could be demonstrated, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting that it lacks an exploration into the theoretical properties of the proposed algorithm, particularly regarding convergence. This is a critical area that could enhance the understanding and applicability of the method. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending particular theoretical analyses or experiments to conduct. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a significant weakness but does not fully support the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the rationale behind selecting only 10 answers from all correct answers and whether this affects the underestimation of performances. While it implies that the authors should provide an explanation or justification for this selection, the comment does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to address the issue but are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the rationale behind selecting only 10 answers from all correct answers and whether this affects the underestimation of performances. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the selection process and its potential impact on performance estimation. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point is a question seeking clarification about the rationale behind selecting only 10 answers from all correct answers and whether this affects the underestimation of performances. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the rationale behind selecting only 10 answers from all correct answers and whether this affects the underestimation of performances. While it identifies a potential issue, it does not provide any suggestions or guidance on how the authors might address this concern or improve their methodology. The comment lacks depth and actionable feedback, leaving the authors with only a vague understanding of what needs to be clarified or improved. Therefore, it is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point questions the purpose of the average duration reported in Table 1 and asks for an explanation regarding whether it includes time spent by the user waiting for the model to generate a response. While the comment implies that the authors should provide an explanation or clarification, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the question about the purpose and content of the reported duration. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the purpose of the average duration reported in the table and asks for an explanation regarding whether it includes time spent by the user waiting for the model to generate a response. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the purpose of the average duration reported in Table 1 and asks for an explanation regarding whether it includes time spent by the user waiting for the model to generate a response. This is a request for clarification and does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment questions the purpose of the average duration reported in Table 1 and asks for an explanation regarding whether it includes time spent by the user waiting for the model to generate a response. This is a relevant and specific inquiry that could help the authors clarify an aspect of their results that might be unclear to readers. By addressing this point, the authors can provide a more comprehensive explanation of their findings, which is beneficial for the clarity and transparency of their work. However, the comment could be more helpful if it suggested ways to improve the presentation or interpretation of this data. Overall, the comment is 3 as it identifies a potential area for improvement but lacks detailed guidance on how to address it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly requests clarification regarding the splits used for obtaining the ATIS numbers in Table 4. The comment is clear and direct, providing a specific action for the authors to take. The authors know exactly what needs to be clarified and can address this by providing the necessary information. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs clarification: the splits used for obtaining the ATIS numbers. This provides clear guidance on what the authors need to address to improve the clarity of their work. Therefore, this comment is labeled as 5.", "verifiability_rationale": "The review point is a request for clarification regarding the splits used for obtaining the ATIS numbers in Table 4. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a factual request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area for improvement by requesting clarification on the splits used for obtaining the ATIS numbers in Table 4. This feedback is clear and actionable, as it directs the authors to provide additional information that could enhance the clarity and transparency of their work. However, the comment could be more helpful if it included suggestions on how to present this information or why it is important. Despite this, the feedback is 4 as it guides the authors toward improving the clarity and completeness of their draft. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the formatting of Table 2 and Table 3, noting that some items have spaces between accuracy and standard deviation, while others do not. This comment suggests that the inconsistency affects the visual appeal of the tables. However, it does not provide explicit guidance on how to address this issue or suggest a specific action for the authors to take. The feedback is implicit, as the authors can infer that they need to ensure consistency in the formatting, but it lacks concrete details on how to implement this change. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2 and Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue of inconsistent spacing between accuracy and standard deviation, which affects the visual appeal of the tables. This provides clear guidance on what needs to be addressed to improve the presentation of the data. Therefore, the comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point highlights a formatting issue in Tables 2 and 3, noting that some items have spaces between accuracy and standard deviation, while others do not. The comment suggests that this inconsistency affects the visual appeal of the tables. However, it does not provide any reasoning or evidence to support why this inconsistency is problematic or how it affects the visual appeal. Without additional context or explanation, the claim is difficult for the authors to understand and address, making it 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific formatting issue in Tables 2 and 3, noting that some items have spaces between accuracy and standard deviation, while others do not. This inconsistency is described as affecting the visual appeal of the tables. While the comment points out a minor aesthetic issue, it lacks depth and does not provide actionable guidance on how to address this inconsistency or why it is important. The feedback is 3 as it prompts the authors to pay attention to the formatting of their tables, but it does not offer detailed suggestions for improvement. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the lack of novelty in the paper, noting that adversarial attacks by perturbing text have been done on many NLP models and imagetext models, and that the related work section nicely summarizes this. The reviewer suggests that the only new effort is to apply similar ideas to videotext models. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address the issue of novelty or improve their work. Without actionable suggestions or a clear direction for improvement, the authors are left without a path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the lack of novelty in the paper, specifically mentioning that adversarial attacks by perturbing text have been done on many NLP models and imagetext models, and that the related work section nicely summarizes this. The reviewer suggests that the only new effort is to apply similar ideas to videotext models. However, the comment does not specify which part of the paper this critique is based on, such as a particular section or experiment, making it difficult for the authors to pinpoint the exact area needing revision. Additionally, while it highlights the lack of novelty, it does not provide specific guidance on how to address this issue or improve the paper. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper lacks novelty, specifically in the context of adversarial attacks by perturbing text. It supports this claim by referencing that similar work has been done on NLP models and imagetext models, and that the related work section nicely summarizes this. However, the comment does not provide specific examples or references to substantiate the claim further, leaving the authors without detailed evidence to address the critique. This makes the claim 3, as it provides a general context but lacks specific details or references to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the paper for lacking novelty, specifically in the context of adversarial attacks by perturbing text. It points out that similar work has been done on NLP models and imagetext models, and that the related work section nicely summarizes this. The reviewer suggests that the only new effort is to apply similar ideas to videotext models. While the comment identifies a potential weakness in the paper, it does not provide actionable suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. The feedback is 3 as it highlights a concern, but it lacks depth and specific advice, leaving the authors with limited direction for improvement. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a specific issue with the organization of Section 3.2, noting that the explanations for features are intertwined and confusing. It suggests that the section would be more coherent if it had separate paragraphs dedicated to each of the lexical features and sentencelevel features. While the comment provides a clear action for the authors to take\u2014organizing the section into separate paragraphs\u2014it does not offer detailed guidance on how to implement this change or what specific content should be included in each paragraph. The action is explicit but somewhat vague, as it lacks concrete steps for execution. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the explanations for features being intertwined and confusing, and it provides a suggestion for improvement by recommending separate paragraphs for lexical features and sentencelevel features. This level of detail helps the authors understand what needs to be addressed and how to improve the organization of the section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the explanations for features in Section 3.2 are intertwined and confusing, suggesting that the section would be more coherent with separate paragraphs dedicated to lexical features and sentencelevel features. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the exact issues or how to address them. The lack of detailed justification or examples makes the claim 3, as the authors may struggle to fully grasp the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the organization of Section 3.2, noting that the explanations for features are intertwined and confusing. It suggests that the section would be more coherent if it were organized with separate paragraphs dedicated to each of the lexical features and sentencelevel features. This feedback is clear and actionable, providing the authors with a concrete suggestion for improving the clarity and structure of their paper. By following this advice, the authors can enhance the readability and comprehensibility of their work. However, the comment could be more helpful if it included specific examples or detailed guidance on how to separate the paragraphs. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses a lack of usefulness regarding the dedicated section and experimental results, suggesting that the space allocated for this information is excessive. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue of space allocation or whether the information is necessary or can be condensed. Without actionable suggestions or a clear direction for improvement, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the allocation of space for a section and experimental results, suggesting that it is excessive. However, it does not specify which section or results are being referred to, making it difficult for the authors to pinpoint the exact parts of the paper that need revision. Additionally, the comment lacks specificity regarding what aspects of the section or results are considered not useful. Without explicit references or detailed feedback, the authors cannot effectively address the issue. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses a subjective opinion about the allocation of space for a section and experimental results, suggesting that it is excessive. However, the comment lacks specific reasoning or examples to support why this allocation is not useful or how it could be improved. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment expresses a subjective opinion about the allocation of space for a section and experimental results, suggesting that it is excessive. However, it lacks specificity and does not provide any actionable feedback or suggestions for improvement. Without detailed guidance or examples, the authors are left without a clear understanding of what aspects of the section or results are considered excessive or how they might be improved. This makes the comment 2, as it identifies a potential issue but does not offer any actionable steps for the authors to take."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment provides a suggestion for improving the abstract by pointing out that \"evaluating with gold answers is inconsistent with human evaluation\" and offering an example of the inconsistency, such as models getting ranked differently. This feedback is explicit and provides a concrete action for the authors to take, which is to include an example of the inconsistency in the abstract. The comment clearly guides the authors on how to enhance their draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for improvement by pointing out the inconsistency between evaluating with gold answers and human evaluation and offering an example of how models might be ranked differently. This provides the authors with a concrete direction for enhancing their abstract. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the abstract is wellwritten and intriguing but suggests that it could be improved by providing an example of the inconsistency between evaluating with gold answers and human evaluation. The reviewer offers a specific suggestion by mentioning that models might be ranked differently, which provides a concrete example to support the claim. This level of detail and specificity makes the claim 4, as it offers a clear direction for improvement. However, the comment could be strengthened by providing more detailed reasoning or references to support the claim fully. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment acknowledges that the abstract is wellwritten and intriguing but suggests a specific improvement by pointing out the inconsistency between evaluating with gold answers and human evaluation. It provides a concrete example of how models might be ranked differently, which could enhance the clarity and relevance of the abstract. This feedback is clear and actionable, offering the authors a specific direction for improving their draft. However, it could be more helpful if it included additional suggestions or examples to further guide the authors in refining their abstract. Overall, the comment is 4 as it provides valuable insights for enhancing the abstract, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should include discussions on the convergence of the proposed joint learning process, specifically for RNN and CopyRNN, to help readers understand how stable points in the probabilistic metric space are obtained. This feedback is explicit in its request for additional discussion, but it does not provide specific guidance on what aspects of the convergence should be discussed or how to present this information. While the action is clear, the lack of detailed instructions makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that discussions are needed on the convergence of the proposed joint learning process, specifically for RNN and CopyRNN, to help readers understand how stable points in the probabilistic metric space are obtained. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its request for additional discussion on convergence, but without clear grounding, the authors may struggle to identify the exact sections that need revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that discussions are needed on the convergence of the proposed joint learning process, specifically for RNN and CopyRNN, to help readers understand how stable points in the probabilistic metric space are obtained. The comment implies that without such discussions, it may be difficult to replicate the results. However, the comment lacks specific examples or detailed reasoning to support the claim that the current explanation is insufficient. This makes the claim 3, as it provides a general direction for improvement but lacks the depth needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by suggesting that discussions on the convergence of the proposed joint learning process are needed. It highlights the importance of understanding how stable points in the probabilistic metric space are obtained, which is crucial for replicating the results. However, the comment does not provide detailed guidance on what aspects of the convergence should be discussed or how to present this information. While it points out a clear area for improvement, the lack of specific suggestions or examples limits its helpfulness. Therefore, the comment is 3, as it provides a direction for improvement but lacks depth and actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point provides explicit actions for the authors to take. It suggests discussing the results for the task of inferring knowledge on objects and includes results for model (B), while also recommending using consistent terminology for the model in Tables 1 and 2. Additionally, it questions why objects are not mentioned in relation to \"latent in verbs.\" These suggestions are clear and concrete, giving the authors specific steps to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (681 and 778) in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it provides clear suggestions for improvement, such as discussing results for the task of inferring knowledge on objects and including results for model (B), and it questions the omission of objects in relation to \"latent in verbs.\" This level of detail and explicit references to specific parts of the paper make the comment 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a series of requests for clarification and suggestions for improvement, such as discussing results for the task of inferring knowledge on objects and including results for model (B). It also questions the omission of objects in relation to \"latent in verbs.\" These are requests for clarification or suggestions, not claims that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback, suggesting that the authors should discuss the results for the task of inferring knowledge on objects and include results for model (B). It also points out the inconsistency in terminology used for the model in Tables 1 and 2, recommending consistency. Additionally, it questions the omission of objects in relation to \"latent in verbs,\" prompting the authors to clarify this aspect. This feedback is clear and detailed, offering the authors concrete steps to enhance their draft. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a specific issue with the wording in line 212, suggesting that the statement is not strictly correct and provides a correction. It also references Figure 2 to support the suggested change. This feedback is explicit and provides concrete guidance on how to improve the draft by correcting the wording and aligning it with the visual representation in Figure 2. The authors know exactly what needs to be changed and where to make the correction, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 212\" and \"Figure 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the wording in line 212 and provides a suggestion for a more accurate description. The reviewer explains that the sentence is not strictly correct and offers a correction, referencing Figure 2 for support. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the sentence in line 212 is not strictly correct and suggests a correction. The reviewer provides a specific suggestion for how the sentence could be improved, referencing Figure 2 for support. This level of detail and reference to a specific figure provides a clear basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the wording in the paper, pointing out that the sentence in line 212 is not strictly correct. It provides a clear and actionable suggestion for improvement by recommending that the authors use a bidirectional encoder to encode the source sentence into a set of vectors, as shown in Figure 2. This feedback is valuable as it directly addresses a potential misunderstanding in the paper and offers a concrete correction, allowing the authors to enhance the clarity and accuracy of their work. However, the comment could be more helpful if it explained why the current wording is incorrect or provided additional context on the importance of using a bidirectional encoder. Overall, the comment is 4 as it provides clear guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the work is a straightforward extension of existing retrofitting work and recommends adding additional baselines, such as character embeddings. While the comment implies that the authors should include these baselines, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to implement the suggested baselines or what other baselines might be relevant. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the work is a straightforward extension of existing retrofitting work and recommends adding additional baselines, such as character embeddings. However, it does not specify which part of the paper this comment pertains to, making it weakly grounded. The comment is specific in suggesting the addition of character embeddings as baselines, which provides some guidance on what could be improved. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the work is a \"fairly straightforward extension of existing retrofitting work\" and suggests adding additional baselines, such as character embeddings. However, the comment lacks specific examples or references to support the claim that the work is a straightforward extension or to justify the need for additional baselines. Without detailed evidence or reasoning, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is classified as 2.", "helpfulness_rationale": "The review comment points out that the work is a straightforward extension of existing retrofitting work and suggests adding additional baselines, such as character embeddings. While it identifies a potential area for improvement, the comment lacks depth and does not provide specific guidance on how to implement these additional baselines or why they would be beneficial. The feedback is 3 as it prompts the authors to consider expanding their work, but it could be more actionable with additional details or examples. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests a specific change to the yaxis label in Figure 5, recommending the use of \"Exact Match ratio\" instead of the current label. This is an explicit and concrete action, as it provides clear guidance on how to improve the draft. The authors know exactly what needs to be done to address this feedback, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be changed, namely the yaxis label, and suggests using \"Exact Match ratio\" instead of the current label. This provides clear guidance on how to improve the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests a change to the yaxis label in Figure 5, recommending the use of \"Exact Match ratio\" instead of the current label. This is a specific suggestion that aims to improve the clarity and accuracy of the figure. However, the comment does not provide any reasoning or justification for why this change is necessary or how it would benefit the paper. Without additional context or explanation, the authors may find it challenging to understand the rationale behind the suggestion. Therefore, the comment is considered 2, as it provides a suggestion but lacks sufficient justification or evidence to fully support the claim.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the clarity of the paper. By recommending a change to the yaxis label in Figure 5, the reviewer offers a concrete way for the authors to enhance the readability and accuracy of their presentation. This feedback is clear and direct, giving the authors a clear path to improve their draft. However, the comment could be more helpful if it explained why the current label is unclear or how the suggested change would benefit the paper. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the lack of description regarding whether the knowledge bases used are free from societal biases and whether the issue is affected by such restrictions. However, it does not provide explicit guidance or suggestions on how the authors should address this concern. The comment mentions \"Comments  I like attacking implicit offensive texts with reasoning chains, but not yet convinced with the example of Fig,\" which appears to be a separate issue unrelated to the main concern about biases. The lack of actionable advice and the disconnected nature of the comment make it difficult for the authors to know what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the lack of description regarding whether the knowledge bases used are free from societal biases and whether the issue is affected by such restrictions. However, it does not specify which part of the paper this concern pertains to, making it weakly grounded. The comment also lacks specificity as it does not provide detailed guidance on what needs to be addressed or how to improve the description. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a concern about the lack of description regarding whether the knowledge bases used are free from societal biases and whether the issue is affected by such restrictions. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the lack of description regarding whether the knowledge bases used are free from societal biases and whether the issue is affected by such restrictions. This is an important consideration for ethical and responsible AI development. However, the comment does not provide specific guidance or suggestions on how the authors might address this concern or what steps they could take to ensure their work is free from biases. Additionally, the mention of \"Comments  I like attacking implicit offensive texts with reasoning chains, but not yet convinced with the example of Fig\" appears to be a separate issue unrelated to the main concern about biases. The lack of actionable feedback and the disconnected nature of the comment make it 3, as it identifies an area for improvement but does not offer detailed guidance on how to address it. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that it is easier to show that something, such as attention in seq2seq MTL, is not working, but the real value lies in understanding why it fails and making changes to the attention mechanism to make it work. However, the comment does not provide explicit guidance on how to identify the specific issues with the attention mechanism or how to make it work. The action is implicit and somewhat vague, as the authors are left to infer the necessary changes without concrete steps or examples. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that it is easier to show that something, such as attention in seq2seq MTL, is not working, but the value lies in understanding why it fails and making changes to the attention mechanism to make it work. However, the comment does not specify which part of the paper discusses attention in seq2seq MTL, making it weakly grounded. It does provide some specificity by suggesting that the authors should focus on understanding why the attention mechanism fails and how to improve it. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it is easier to show that something, such as attention in seq2seq MTL, is not working, but the value lies in understanding why it fails and making changes to the attention mechanism to make it work. However, the comment lacks specific examples, reasoning, or references to support the claim that attention in seq2seq MTL is not working. Without detailed evidence or justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 2, as it provides a general idea but lacks the necessary details to fully substantiate the claim.", "helpfulness_rationale": "The review comment suggests that it is easier to show that something, such as attention in seq2seq MTL, is not working, but the real value lies in understanding why it fails and making changes to the attention mechanism to make it work. This feedback highlights a potential area for improvement by encouraging the authors to delve deeper into understanding the limitations of their approach and suggesting a path for enhancement. However, the comment lacks specific guidance on how to identify the issues with the attention mechanism or how to make it work effectively. While it provides a general direction, it does not offer detailed actionable steps, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks the authors to justify why MCNC does not include many strong baselines that are not compared, such as those mentioned in 1. This request is clear and direct, providing a specific action for the authors to take. The comment also specifies the baselines that should be included, which further concretely guides the authors on how to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by questioning the absence of strong baselines in MCNC and asking for a justification. The reference to 1 provides additional context for what should be included. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the absence of strong baselines in Table 3 and suggests that the authors should include them, referencing a specific source (1). This is a request for clarification or justification, not a claim. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, the label \"No\" is appropriate.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 3, questioning the absence of strong baselines that are not compared, such as those mentioned in 1. It prompts the authors to justify the reason for this omission, which is a clear and actionable suggestion for improvement. By addressing this feedback, the authors can enhance the comprehensiveness and rigor of their analysis. However, the comment could be more helpful if it provided additional context or examples of the specific baselines that should be included. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with further guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the paper relies on supplemental space to contain its content, which makes it dependent on the supplemental material. It specifically mentions Section 3.1 and references to Supplemental Figure 6, as well as the model comparison and span versus sentence investigation. However, the comment does not provide explicit guidance on how the authors should address this issue or improve the independence of the paper. The action is implicit and somewhat vague, as the authors are left to infer that they need to make the paper more selfcontained without specific instructions on how to achieve this. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper, including \"S3.1 reference to Sup. Fig. 6\" and \"model comparison and other details of the span vs. sentence investigation,\" allowing the authors to accurately identify the parts being addressed. It also specifies the issue by pointing out that the paper relies on supplemental space, which makes it dependent on the supplemental material. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper relies on supplemental space to contain its content, making it dependent on the supplemental material. It provides specific examples, such as \"S3.1 reference to Sup. Fig. 6\" and \"model comparison and other details of the span vs. sentence investigation,\" which help substantiate the claim. However, the comment could be strengthened by providing more detailed reasoning or examples of how this reliance affects the paper\"s independence. Overall, the claim is 4, as it provides some evidence but lacks comprehensive justification. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s reliance on supplemental space to contain its content, which makes it dependent on the supplemental material. It specifically mentions Section 3.1 and references to Supplemental Figure 6, as well as the model comparison and span versus sentence investigation. This feedback is valuable as it highlights a potential weakness in the paper\"s independence and suggests that the authors should address this issue to improve the overall quality and clarity of their work. However, the comment could be more helpful if it provided specific suggestions on how to make the paper more selfcontained or independent. Despite this, the feedback is 4 as it directs the authors\" attention to a critical area that needs improvement. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to provide more information about the traits of the experts and to justify why annotation must be carried out by the experts, rather than focusing solely on commercial values. It also asks specific questions about the expertise of the experts, the nature of the annotation, and potential linguistic challenges. These questions provide clear guidance on what the authors need to address, making the comment 5. The authors know exactly what information to include and what questions to answer to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first point, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is a more detailed description of the traits of the experts and a justification for why annotation must be carried out by them, rather than focusing solely on commercial values. The comment also asks specific questions about the expertise of the experts, the nature of the annotation, and potential linguistic challenges. This level of detail provides clear guidance on what the authors need to address, making the comment 5. Therefore, this comment aligns with a score of 5.", "verifiability_rationale": "The review point raises a claim about the need for more information regarding the traits of the experts and the justification for using their expertise for annotation. However, it does not provide any specific reasoning or evidence to support this claim. The comment lacks detailed justification or examples that would help the authors understand the basis of the suggestion. As a result, the claim is 1, as it does not offer sufficient support for the authors to address the feedback effectively. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by suggesting that the authors provide more information about the traits of the experts involved in the annotation process. It also questions the necessity of using experts for annotation, asking whether they were linguistic experts or domain experts, and whether the annotation differed from what nonexperts would do. These questions prompt the authors to clarify the expertise and rationale behind the annotation process, which could enhance the transparency and credibility of their work. The comment is 4 as it provides clear and actionable feedback that can guide the authors in improving their draft. However, it could be more helpful if it offered specific suggestions on how to address these questions or provided examples of what additional information would be beneficial. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should include examples of their system applied to actual texts rather than focusing solely on other components or models. While the comment implies that the authors should provide such examples, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not specify the type of examples or how they should be presented. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including examples of the system applied to actual texts, rather than focusing on other components or models. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the results or discussion sections, but this inference is not explicit. The comment is specific in suggesting the inclusion of examples, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it would be beneficial to include examples of the system applied to actual texts, rather than focusing solely on other components or models. However, the comment does not provide any specific reasoning, examples, or references to support why this would be valuable or necessary. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that the authors should include examples of their system applied to actual texts, rather than focusing solely on other components or models. This feedback is 3 as it provides a specific direction for enhancing the paper by demonstrating the system\"s practical application. However, the comment lacks depth and does not offer detailed guidance on how to present these examples or what specific aspects of the system should be highlighted. While it points out a potential area for improvement, it does not fully support the authors in making those improvements. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the claims in the paper would benefit from more indepth analysis. However, it does not provide specific guidance on what aspects of the claims need further analysis or how the authors should conduct this analysis. The action is implicit and vague, as the authors are left to infer that they need to provide more detailed analysis but without concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the claims in the paper would benefit from more indepth analysis, but it does not specify which claims or parts of the paper are being referred to. This lack of specificity and grounding makes it difficult for the authors to identify the exact areas that need improvement. The comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that \"a number of claims from this paper would benefit from more indepth analysis.\" However, it does not provide any specific examples or reasoning to support this claim. Without detailed justification or references to particular claims or areas that need further analysis, the comment lacks verifiability. Therefore, it is classified as \"1.\"", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, suggesting that several claims could benefit from more indepth analysis. However, it does not specify which claims are lacking in depth or provide guidance on how the authors might address this issue. Without specific examples or suggestions for improvement, the comment lacks actionable feedback that could help the authors enhance their draft. As a result, it is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the paper raises two hypotheses about multilinguality and country/languagespecific bias but does not test or discuss them further. The reviewer suggests that the hypotheses could be phrased more optimally for testing but acknowledges their value. The comment also expresses a desire for the paper to delve deeper into these topics. While the comment highlights an issue with the paper\"s structure and suggests a potential improvement, it does not provide explicit instructions or concrete steps for the authors to follow. The action is implicit and somewhat vague, as the authors are left to infer that they should test or discuss the hypotheses more thoroughly. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 078086, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the hypotheses about multilinguality and country/languagespecific bias are not tested or discussed further, which is misleading. The comment further suggests that the paper should delve deeper into these topics. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper raises two hypotheses about multilinguality and country/languagespecific bias but does not test or discuss them further. The reviewer suggests that the hypotheses could be phrased more optimally for testing but acknowledges their value. The comment also expresses a desire for the paper to delve deeper into these topics. While the reviewer provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion that the hypotheses are not tested or discussed. This makes the claim 3, as the authors would need to further explore the reasoning to fully understand and address the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that it raises two hypotheses about multilinguality and country/languagespecific bias but does not test or discuss them further. This is considered misleading, as the hypotheses are not explored or mentioned again in the paper. The comment also suggests that the paper should delve deeper into these topics, which is a valuable suggestion for improvement. However, the comment could be more helpful if it provided specific guidance on how to test or discuss these hypotheses, or if it offered examples of how other papers have addressed similar issues. Despite this, the feedback is 4 as it highlights a critical area for improvement and encourages the authors to explore these important topics further. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether feature engineering could improve the performance of the current work. It references a study by Uto et al. (2020) that achieved a QWK of 0.801 using a set of handcrafted features. The comment suggests that using the same feature set as Uto et al. (2020) might also improve the results of the current work. While the comment implies that the authors should consider using feature engineering, it does not explicitly instruct them to do so or provide detailed guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should explore feature engineering and consider using the same feature set as Uto et al. (2020). Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about whether feature engineering could improve the performance of the current work, referencing a study by Uto et al. (2020) that achieved a QWK of 0.801 using a set of handcrafted features. However, the comment does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where feature engineering could be applied. This lack of explicit grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. Additionally, while the comment provides a reference to Uto et al. (2020) and suggests using their feature set, it does not specify how this could be implemented or what specific features are being referred to. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about whether feature engineering could improve the performance of the current work, referencing a study by Uto et al. (2020) that achieved a QWK of 0.801 using a set of handcrafted features. The comment suggests that using the same feature set as Uto et al. (2020) might also improve the results of the current work. However, the comment does not provide detailed reasoning or examples to support why feature engineering would be beneficial or how it could be implemented in the current context. The reference to Uto et al. (2020) is a starting point, but it lacks specific guidance or evidence to fully substantiate the claim. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed justification or examples to be fully convincing.", "helpfulness_rationale": "The review comment raises a question about whether feature engineering could improve the performance of the current work, referencing a study by Uto et al. (2020) that achieved a QWK of 0.801 using a set of handcrafted features. The comment suggests that using the same feature set as Uto et al. (2020) might also improve the results of the current work. While the comment identifies a potential area for improvement and provides a reference for further exploration, it lacks specific guidance or detailed suggestions on how to implement feature engineering or which features to consider. The feedback is 3 as it prompts the authors to consider a specific approach, but it could be more actionable with additional details or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises questions about the use of the Challenge Set (CS) and its role in the evaluation and training process. It explicitly asks whether the CS is used to augment the training material and requests information about the data split. While the comment does not provide explicit instructions, it does imply that the authors should clarify these aspects. The action is implicit but concrete, as it directs the authors to provide specific information about the use of the CS. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment raises questions about the use of the Challenge Set (CS) and its role in the evaluation and training process. It explicitly mentions the CS, which allows the authors to accurately identify the part of the paper being addressed. The comment is specific in its questions about the data split and whether the CS is used for training augmentation. However, it does not specify which section of the paper should include this information, making it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the use of the Challenge Set (CS) and its role in the evaluation and training process. It seeks clarification on whether the CS is used for training augmentation and requests information about the data split. However, the comment does not provide any supporting evidence, reasoning, or references to justify these questions. Without additional context or explanation, the authors may find it challenging to address the concerns effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises important questions about the use of the Challenge Set (CS) in the evaluation and training process. It seeks clarification on whether the CS is used for training augmentation and requests information about the data split. This feedback is clear and actionable, as it prompts the authors to provide specific details about the data used in their study. By addressing these questions, the authors can enhance the transparency and comprehensiveness of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to present this information in the paper. Overall, the comment is 4, as it directs the authors to clarify important aspects of their methodology, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the paper\"s claim that the model generalizes to different knowledge, specifically questioning the use of constituent parse as knowledge. The reviewer suggests that the substructure should be represented as a sequence of words and expresses hesitation in calling it \"knowledge.\" However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their draft. The action is implicit and vague, as the authors are left to infer that they need to clarify the use of \"knowledge\" and potentially revise their claims. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific claim in the paper regarding the generalization of the model to different knowledge. It questions the use of constituent parse as knowledge and suggests that it should be represented as a sequence of words. The comment also expresses hesitation in calling it \"knowledge\" and points out that it is more accurately described as syntax or semantics. However, the comment does not explicitly mention which part of the paper this claim is made in, making it weakly grounded. The authors can infer that it relates to the sections discussing the model\"s generalization or knowledge representation, but this inference is not as direct as it could be. The comment is specific in detailing the issue with the use of \"knowledge\" and suggesting an alternative perspective. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a claim about the paper\"s use of \"knowledge\" in the context of the model\"s generalization. The reviewer questions the appropriateness of using constituent parse as knowledge, suggesting that it should be represented as a sequence of words. The comment also expresses hesitation in calling it \"knowledge,\" noting that it is more accurately described as syntax or semantics. This critique is based on a logical reasoning that the term \"knowledge\" is typically associated with external knowledge bases, while the use in the paper is more related to syntax or semantics. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to consider the reviewer\"s perspective and provide additional context or clarification to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the paper\"s claim that the model generalizes to different knowledge, specifically questioning the use of constituent parse as knowledge. The reviewer suggests that the substructure should be represented as a sequence of words and expresses hesitation in calling it \"knowledge,\" noting that it is more accurately described as syntax or semantics. This feedback is 3 as it identifies a potential misunderstanding or misrepresentation of the term \"knowledge\" in the context of the paper. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or clarify their claims. While it points out a potential area for improvement, it does not provide detailed actionable steps, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the relatively poor performance of TWSI on nouns, which is expected due to its nature. It also notes that the oracle GAP for PPDBClus is higher than most clustering approaches, which is disconcerting. The reviewer suggests understanding the gap better and points out a contradiction with the claim that the clustering approach is generalizable to all parts of speech. While the comment identifies areas of concern and suggests further exploration, it does not provide explicit instructions or concrete steps for the authors to take. The action is implicit and somewhat vague, as the authors are left to infer that they should investigate the gap and reconcile the contradictory claims. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the performance of TWSI on nouns, which is expected due to its nature, and the fact that the oracle GAP for PPDBClus is higher than most clustering approaches. It also points out a contradiction with the claim that the clustering approach is generalizable to all parts of speech. However, the comment does not specify which sections of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the concerns about performance and the contradiction with the claim, but without explicit references to sections, it is challenging for the authors to pinpoint the exact parts of the paper that need attention. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the relatively poor performance of TWSI on nouns is disconcerting, given the nature of TWSI and the fact that the oracle GAP for PPDBClus is higher than most clustering approaches. The comment also points out a contradiction with the claim that the clustering approach is generalizable to all parts of speech. While the reviewer provides some reasoning by mentioning the oracle GAP and the nature of TWSI, the comment lacks specific examples or detailed analysis to fully substantiate the claim. The reasoning is 3, as it highlights a potential issue but requires more detailed evidence or examples to be fully convincing. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific concern about the performance of TWSI on nouns, which is expected due to its nature. It also highlights the fact that the oracle GAP for PPDBClus is higher than most clustering approaches, which is disconcerting. The reviewer suggests understanding the gap better and points out a contradiction with the claim that the clustering approach is generalizable to all parts of speech. This feedback is 3 as it directs the authors to investigate the performance gap and reconcile the contradictory claims. However, the comment could be more helpful if it provided specific suggestions on how to address these issues or offered examples of how to improve the generalizability claim. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly requests the authors to provide examples of spurious structures in the discussion of section 5.2, which is a direct and concrete action. The authors are given a clear direction on what needs to be added to their draft to address the reviewer\"s concern. This makes the comment 5, as it provides a specific task with detailed guidance on how to improve the paper.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 5.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the discussion, stating that it is too abstract and lacks examples of spurious structures. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the discussion in section 5.2 is too abstract and lacks examples of spurious structures. However, it does not provide any specific reasoning or evidence to support this claim. Without detailed examples or references to what aspects of the discussion are unclear or how the examples could improve the paper, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the discussion in section 5.2, noting that it is too abstract and lacks examples of spurious structures. This feedback is clear and actionable, as it directs the authors to provide concrete examples to support their claims about the superiority of the new model over MH. By addressing this feedback, the authors can enhance the clarity and persuasiveness of their discussion, making the comment 4. However, the comment could be more helpful if it provided suggestions on how to present these examples or what specific aspects of the discussion need more detail. Therefore, the comment is rated as 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should include the maximum number of tasks done by any annotator. This is an explicit action that provides a clear direction for improvement. The comment is concrete because it specifies exactly what information should be added, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"241,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be added, which is the maximum number of tasks done by any annotator. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that it would be beneficial to include the maximum number of tasks done by any annotator. However, it does not provide any reasoning or evidence to support why this information is important or how it would enhance the paper. Without additional context or justification, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the authors should include the maximum number of tasks done by any annotator. While this is a specific and actionable piece of feedback, it does not provide any context or rationale for why this information is important or how it might impact the study. The comment lacks depth and does not offer any additional insights or suggestions for improvement. Therefore, it is 3, as it provides a clear direction for improvement but lacks comprehensive guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests including the hard prompt baseline in Table 1 to demonstrate the increase in performance of each method. This is an explicit action that provides clear guidance on what the authors should do to improve their draft. The comment specifies exactly what needs to be added to the table, making it 5. The authors know exactly how to implement this suggestion, ensuring that they can effectively address the feedback.", "grounding_specificity_rationale": "The comment suggests including the hard prompt baseline in Table 1 to demonstrate the increase in performance of each method. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table. The authors can infer that it relates to the results or discussion sections, but this inference is not explicit. The comment is specific in suggesting the inclusion of the hard prompt baseline, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests including the hard prompt baseline in Table 1 to demonstrate the increase in performance of each method. This is a request for additional information or analysis, rather than a claim or opinion that requires verification. It does not contain subjective judgments, suggestions, or deductions that need to be supported by evidence or reasoning. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment suggests including the hard prompt baseline in Table 1 to demonstrate the increase in performance of each method. This feedback is clear and actionable, providing the authors with a specific suggestion to enhance their results section. By incorporating the hard prompt baseline, the authors can better illustrate the effectiveness of their methods and provide a more comprehensive comparison. However, the comment could be more helpful if it explained why this comparison is important or how it would impact the overall understanding of the results. Despite this, the suggestion is valuable and provides a clear path for improvement, making the comment 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the lack of numerical results and expresses curiosity about how the method could be applied to popular algorithms and compared with existing DP algorithms. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should include numerical results and comparisons, but it lacks concrete details on what specific algorithms to consider or how to conduct the comparisons. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment highlights the lack of numerical results and expresses curiosity about how the method could be applied to popular algorithms and compared with existing DP algorithms. However, it does not specify which part of the paper lacks numerical results or where the authors should include these comparisons. The authors might infer that it relates to the experimental results or methodology sections, but this inference is not explicit. The comment is specific in its request for numerical results and comparisons, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses curiosity about the lack of numerical results and suggests that the authors should provide comparisons with existing DP algorithms. However, it does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for additional information or clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of numerical results and expressing curiosity about how the method could be applied to popular algorithms and compared with existing DP algorithms. This feedback is valuable as it highlights an important area for improvement that could enhance the paper\"s contribution and impact. However, the comment lacks specific guidance or suggestions on how the authors might address this issue, such as which algorithms to consider or how to conduct the comparisons. While it points out a critical area for enhancement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide empirical evidence to support their claim that the proposed algorithm works better for the Column Subset Selection problem. This is an explicit request for additional data or analysis to substantiate the claim made in the paper. The action is clear and concrete, as it specifies what the authors need to do to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the authors should provide empirical evidence to support their claim that the proposed algorithm works better for the Column Subset Selection problem. However, it does not specify which part of the paper this claim is made in, nor does it provide details on what specific evidence or analysis is needed. This makes it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its request for empirical evidence but lacks grounding, as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide empirical evidence to support their claim that the proposed algorithm works better for the Column Subset Selection problem. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the algorithm is better suited for this problem. Without such evidence or justification, the authors may find it challenging to address the suggestion effectively. Therefore, the comment is considered 2, as it lacks sufficient support to fully substantiate the claim.", "helpfulness_rationale": "The review comment suggests that the authors should provide empirical evidence to support their claim that the proposed algorithm works better for the Column Subset Selection problem. This feedback is clear and actionable, as it identifies a specific area where the paper could be strengthened by including additional data or analysis. However, the comment could be more helpful if it provided guidance on how to conduct this empirical evaluation or suggested specific metrics to consider. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the applicability of the robust training scheme to practical datasets, particularly those in highdimensional domains. It suggests that the accuracy might scale unfavorably unless the size of V scales exponentially with the dimension. However, the comment does not provide explicit guidance or suggestions on how the authors might address this concern or improve the robustness of their scheme. The action is implicit and vague, as the authors are left to infer that they need to explore ways to enhance the robustness of their scheme, but without concrete steps or examples, the action remains unclear. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the applicability of the robust training scheme to practical datasets, particularly those in highdimensional domains. However, it does not specify which part of the paper discusses this scheme or where the issue of scaling is mentioned. This makes it difficult for the authors to pinpoint the exact section that needs attention. While the comment provides some insight into the potential limitations of the scheme, it lacks specificity and grounding, as it does not direct the authors to a particular part of the paper. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the robust training scheme is unlikely to scale to practical datasets, particularly those in highdimensional domains. The reviewer suggests that the accuracy would scale unfavorably unless the size of V scales exponentially with the dimension. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. The lack of evidence or detailed explanation makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the applicability of the robust training scheme to practical datasets, particularly those in highdimensional domains. It suggests that the accuracy might scale unfavorably unless the size of V scales exponentially with the dimension. While the comment identifies a potential limitation of the scheme, it lacks specific suggestions or guidance on how the authors might address this issue or improve the robustness of their approach. The feedback is 3 as it points out a critical area for improvement, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests making a distinction between hard prompt work updates that modify the frozen model and those that do not. However, it does not provide explicit guidance on how to implement this distinction or what specific changes should be made to the draft. The action is implicit and somewhat vague, as the authors can infer that they need to differentiate between these types of updates, but they are not given concrete steps on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 148,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests making a distinction between hard prompt work updates that modify the frozen model and those that do not. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests making a distinction between hard prompt work updates that modify the frozen model and those that do not. However, it does not provide any supporting evidence, reasoning, or references to justify why this distinction is necessary or how it would improve the paper. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests making a distinction between hard prompt work updates that modify the frozen model and those that do not. This is a specific and actionable piece of feedback that could help the authors clarify their work and improve the clarity of their paper. By differentiating between these types of updates, the authors can provide a more nuanced understanding of their methodology and its implications. However, the comment could be more helpful if it provided examples or further guidance on how to make this distinction. Overall, the feedback is 4 as it directs the authors to a meaningful improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy in the amount of data used to train the text disambiguation model compared to the endtoend system. It questions the conclusion that the direct model is clearly superior, given the small difference in performance. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific actions to improve the draft. The feedback implies that the authors should reconsider their conclusions based on the data discrepancy, but it lacks concrete steps or suggestions for revision. As a result, the comment is 3, as it identifies an area for consideration but does not offer direct guidance on how to address it.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the amount of data used to train the text disambiguation model compared to the endtoend system. It questions the conclusion that the direct model is clearly superior, given the small difference in performance. However, the comment does not specify which part of the paper discusses these models or their performance, making it weakly grounded. The comment is specific in detailing the issue with the data discrepancy and its impact on the conclusion, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact parts needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the conclusion that the direct model is clearly superior, given the small difference in performance compared to the endtoend system. The comment highlights a discrepancy in the amount of data used for training, suggesting that this may impact the conclusion. However, the comment lacks specific examples or references to support the claim that the difference in data usage is significant or that it affects the conclusion. Without detailed evidence or reasoning, the claim remains 3, as it provides a logical point but lacks sufficient justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the conclusion that the direct model is clearly superior, given the small difference in performance compared to the endtoend system. It highlights a discrepancy in the amount of data used for training, which could impact the validity of the conclusion. This feedback is 3 as it points out a critical area for consideration, prompting the authors to reevaluate their conclusions and potentially revise their analysis. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending additional experiments or data analysis. Therefore, while it provides some insight, it could be more helpful with additional detail or actionable advice. Overall, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies two main issues: the lack of motivation for GaRare compared to GaLore and the need for a more detailed algorithmic presentation, particularly regarding the process of recovering updated parameters from projected gradients. The comment provides explicit actions for the authors to take, such as providing evidence or justification for GaRare\"s advantages and clarifying the algorithmic presentation. These suggestions are clear and concrete, giving the authors a direct path to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of motivation for GaRare and the need for a more detailed algorithmic presentation, particularly regarding the process of recovering updated parameters from projected gradients. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what is missing or unclear, providing a clear direction for improvement. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks motivation for GaRare and does not provide evidence or justification for its advantages over GaLore. It also notes the need for a more detailed algorithmic presentation, particularly regarding the process of recovering updated parameters from projected gradients. While the comment identifies areas for improvement, it does not provide specific examples or references to support the claim about the lack of motivation or the need for a more detailed algorithmic presentation. This makes the claim 3, as it highlights areas for improvement but lacks detailed justification or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two key areas for improvement in the paper. First, it points out the lack of motivation for GaRare, specifically noting the absence of evidence or justification for its advantages over GaLore based on theoretical analysis. This feedback is clear and actionable, as it prompts the authors to provide a more thorough explanation of the benefits and advantages of GaRare. Second, the comment highlights the need for a more detailed algorithmic presentation, particularly regarding the process of recovering updated parameters from projected gradients. This suggestion is also actionable, as it directs the authors to enhance the clarity and understanding of their algorithmic approach. By addressing these points, the authors can significantly improve the comprehensiveness and clarity of their paper. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly requests the authors to conduct an ablation study on the visDial dataset to further validate the proposed visual reference resolution model. It also suggests conducting an experiment to evaluate the performance of ATT(+H) without considering relevant attention retrieval from the attention memory. The comment provides clear and specific actions for the authors to take, including conducting additional experiments and analyzing specific aspects of the model. This level of detail and explicit guidance makes the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 4 left,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, which is the need for an ablation study on the visDial dataset and an experiment to evaluate the performance of ATT(+H) without considering relevant attention retrieval from the attention memory. This level of detail provides clear guidance on what the authors should do to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests conducting an ablation study on the visDial dataset to further validate the proposed visual reference resolution model. It also requests an experiment to evaluate the performance of ATT(+H) without considering relevant attention retrieval from the attention memory. While the comment provides a clear suggestion for additional experiments, it lacks specific reasoning or evidence to support why these experiments are necessary or how they would contribute to the paper\"s validity. The request for an ablation study is 3, as it suggests a logical next step, but the lack of detailed justification or examples makes it difficult for the authors to fully understand the importance of these experiments. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting additional experiments to further validate the proposed visual reference resolution model. It recommends conducting an ablation study on the visDial dataset to assess the model\"s performance in a realworld scenario. Additionally, it highlights an experiment of particular interest, namely the performance of ATT(+H) without considering relevant attention retrieval from the attention memory. This feedback is clear and detailed, offering the authors a concrete direction for enhancing the robustness and validity of their work. By addressing these suggestions, the authors can significantly improve the comprehensiveness and credibility of their draft. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide an explanation for why WPA works, specifically asking what the model is predicting with np.ones input and whether any input would serve as a white paper. It also questions why Gaussian noise input does not work as well as WPA and why the authors spend time showing WPA improves test performance without providing insights into how it works. The comment implies that the authors should address these questions to enhance the paper\"s contribution and potential for future research. While the actions are implicit, they are concrete in nature, as the authors know exactly what needs to be addressed to improve the draft. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2\" and \"WPA,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear questions and suggestions for improvement, such as explaining why WPA works, what the model is predicting with np.ones input, and why Gaussian noise input does not work as well as WPA. The comment also highlights the importance of providing insights into how WPA works, which can spark future research directions. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises several questions and suggestions, such as why WPA works and whether any input would serve as a white paper. It also questions the effectiveness of Gaussian noise input compared to WPA. While the comment provides some logical reasoning by suggesting that the authors should provide insights into how WPA works, it lacks specific examples, references, or detailed explanations to fully substantiate the claims. The authors are left with a general direction for improvement but without clear guidance on how to address the issues raised. Therefore, the comment is 3, as it provides a basis for further exploration but requires more detailed justification.", "helpfulness_rationale": "The review comment provides a series of questions and suggestions that could significantly enhance the paper. It challenges the authors to explain why WPA works, particularly with np.ones input and whether any input could serve as a white paper. The comment also questions the effectiveness of Gaussian noise input compared to WPA and highlights the importance of providing insights into how WPA works, which could spark future research directions. By addressing these points, the authors could improve the clarity and depth of their work. However, the comment could be more helpful if it offered specific suggestions on how to approach these questions or provided examples of similar analyses in the literature. Overall, the feedback is 4 as it identifies key areas for improvement and encourages the authors to provide more detailed explanations and insights."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the similarity between the method described in the paper and the related work cited, specifically \"Generating Adversarial Disturbances for Controller Verification.\" It explicitly asks the author to provide more clarification on this issue. This request is clear and direct, giving the authors a specific action to take to address the reviewer\"s concern. The feedback is concrete, as it specifies what the authors need to do to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment raises a concern about the similarity between the method described in the paper and the related work cited, specifically \"Generating Adversarial Disturbances for Controller Verification.\" However, it does not specify which part of the paper this similarity is observed in, such as a particular section or subsection. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its request for clarification, but without clear grounding, it remains 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point raises a concern about the similarity between the method described in the paper and the related work cited, specifically \"Generating Adversarial Disturbances for Controller Verification.\" However, it does not provide any further explanation, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the similarity or how it affects their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the similarity between the method described in the paper and the related work cited, specifically \"Generating Adversarial Disturbances for Controller Verification.\" It raises a concern that the authors should clarify this similarity to avoid confusion or potential overlap with existing work. While the comment highlights an important area for clarification, it does not provide specific guidance on how the authors might address this issue or what aspects of the method need further explanation. The feedback is 3 as it points out a potential weakness, but it lacks depth and actionable suggestions, leaving the authors with a general direction for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises questions about the fairness of comparing the proposed method with other methods and whether the proposed technique promotes existing Class incremental semantic segmentation methods. It also acknowledges that the authors have addressed the limitations and potential negative societal impact of their work. However, the comment does not provide explicit guidance or suggestions on how the authors should address these questions or improve their draft. The actions are implicit and vague, leaving the authors without clear direction on how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises questions about the fairness of comparing the proposed method with other methods and whether the proposed technique promotes existing Class incremental semantic segmentation methods. However, it does not specify which part of the paper these questions pertain to, making it difficult for the authors to identify the exact sections that need attention. The comment also acknowledges that the authors have addressed the limitations and potential negative societal impact of their work, but this does not provide specific guidance on how to improve the paper. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point raises questions about the fairness of comparing the proposed method with other methods and whether the proposed technique promotes existing Class incremental semantic segmentation methods. However, it does not provide any supporting evidence, reasoning, or references to justify these claims. The comment also acknowledges that the authors have addressed the limitations and potential negative societal impact of their work, but this is not a claim that requires verification. Therefore, the comment lacks verifiability, as it does not provide sufficient evidence or justification for the claims made. The authors would need to infer the issues and address them without clear guidance from the review. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises questions about the fairness of comparing the proposed method with other methods and whether the proposed technique promotes existing Class incremental semantic segmentation methods. It also acknowledges that the authors have addressed the limitations and potential negative societal impact of their work. However, the comment lacks specificity and does not provide actionable feedback or suggestions for improvement. It does not offer guidance on how the authors might address the questions raised or how they could enhance their work. As a result, the comment is 2, as it identifies some areas of concern but does not provide enough detail or direction for the authors to make meaningful improvements to their draft. Therefore, it aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the experimental section (Section 3) does not mention or discuss how important parameters, such as the minimum cluster size and conductance threshold, are set and how sensitive the performance is to these parameters. This feedback implies that the authors should include a discussion on these parameters in the experimental section, providing explicit guidance on what needs to be addressed. However, the comment does not specify how the authors should present this information, such as through a table, figure, or detailed explanation. While the action is explicit, the lack of concrete details on how to implement it makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"End of Sec.2\" and \"Sec. 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the absence of discussion on important parameters, such as the minimum cluster size and conductance threshold, in the experimental section. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental section (Section 3) does not mention or discuss how important parameters, such as the minimum cluster size and conductance threshold, are set and how sensitive the performance is to these parameters. This is a valid claim as it highlights a gap in the paper\"s discussion of critical experimental settings. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. While the authors are alerted to this omission, they may find it challenging to address the issue without additional guidance. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed support to be fully convincing.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out that important parameters, such as the minimum cluster size and conductance threshold, are not discussed in the experimental section. This feedback is valuable as it highlights a critical area for improvement, specifically the need to include a discussion on how these parameters are set and how they affect the performance. By addressing this issue, the authors can enhance the comprehensiveness and clarity of their experimental section. However, the comment could be more helpful if it provided suggestions on how to present this information or examples of how similar parameters are discussed in other works. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a potential concern about the need for reinforcement learning in a static VQA task, suggesting that it might be a weakness that could make the approach less data efficient and harder to train models using gradient descent. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this potential weakness or improve the approach, leaving the authors without a clear understanding of what steps to take. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises a potential concern about the need for reinforcement learning in a static VQA task, suggesting it might be a weakness that could make the approach less data efficient and harder to train models using gradient descent. However, the comment does not specify which part of the paper this issue pertains to, nor does it provide detailed guidance on how to address this concern. Without explicit references to sections or examples, the authors cannot confidently determine where to focus their efforts. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the need for reinforcement learning in a static VQA task may be a potential weakness, making the approach less data efficient and harder to train models using gradient descent. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a potential concern about the need for reinforcement learning in a static VQA task, suggesting that it might be a weakness that could make the approach less data efficient and harder to train models using gradient descent. While the comment identifies a potential issue, it lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this concern. Without detailed feedback or recommendations, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the proposed method is too similar to other attentional modules proposed in previous works, specifically mentioning 1, 2, 3 and ResNeSt 4. It notes that although these works did not evaluate their performance on object detection and instance segmentation, the overall structures are similar. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest ways to differentiate their work. The action is implicit and vague, as the authors are left to infer that they need to clarify the novelty of their method and potentially discuss the differences with existing works. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the novelty of the proposed method, specifically mentioning its similarity to other attentional modules in previous works and its relationship to ResNeSt. However, it does not explicitly mention which part of the paper discusses these comparisons or the proposed method, making it weakly grounded. The comment is specific in detailing the similarities and lack of discussion regarding ResNeSt, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the novelty of the proposed method is limited due to its similarity to other attentional modules in previous works. It provides specific references to 1, 2, 3 and mentions a potential relationship with ResNeSt 4, but does not elaborate on how these similarities affect the novelty of the current work. The comment also notes that the previous works did not evaluate their performance on object detection and instance segmentation, which could be a potential area of differentiation. However, the lack of detailed comparison or analysis makes the claim 3, as it provides a basis for the argument but requires more evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the novelty of the proposed method, noting that it is too similar to other attentional modules proposed in previous works. It specifically mentions the group attention design and its potential relationship to ResNeSt, which is not discussed in the paper. While the comment highlights a critical area for improvement, it lacks specific suggestions or guidance on how the authors might differentiate their work or address the similarity concerns. The feedback is 3 as it points out a key weakness, but it could be more actionable with additional details or recommendations. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper should include a comparison with testtime adaptation (TTA) methods, such as AB, which also aim to adapt to outofdistribution data when the input data is disturbed by noise. The reviewer questions the superiority of data processing over model parameter adjustment and suggests making a comparison based on experimental results. While the comment implies that the authors should include a comparison with TTA methods, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to conduct the comparison or what metrics to use. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"video action recognition\" and \"testtime adaptation (TTA) methods,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting a comparison with TTA methods and questioning the superiority of data processing over model parameter adjustment. The comment provides a clear direction for improvement by recommending a comparison based on experimental results. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks comparison with testtime adaptation (TTA) methods, suggesting that such comparisons could help prove the superiority of data processing over model parameter adjustment. The reviewer provides a logical reasoning by pointing out that TTA methods also aim to adapt to outofdistribution data when the input data is disturbed by noise. However, the comment lacks specific references to TTA methods or detailed examples of how these comparisons could be conducted, which would strengthen the argument. This makes the claim 3, as it provides a logical basis but requires more detailed support to be fully convincing.", "helpfulness_rationale": "The review comment identifies a gap in the paper by pointing out the lack of comparison with testtime adaptation (TTA) methods, which are relevant to the topic of robustness in video action recognition. It suggests that such comparisons could help prove the superiority of data processing over model parameter adjustment. The comment is clear and actionable, as it provides a specific direction for improvement by recommending a comparison based on experimental results. This feedback is valuable as it guides the authors to enhance the comprehensiveness and robustness of their work. However, it could be more helpful if it included suggestions on which TTA methods to consider or how to conduct the comparison. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies an error in the first expression for J(\u03b8) in Section 3.2.1, stating that it should be Q(st0, \u03c0\u03b8(st0)). This provides a clear and direct action for the authors to take, which is to correct the expression. The feedback is specific and leaves no ambiguity about what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the error in the first expression for J(\u03b8), stating that it should be Q(st0, \u03c0\u03b8(st0)). This provides clear guidance on what needs to be corrected. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the first expression for J(\u03b8) in Section 3.2.1 is incorrect and provides a correction. This is a factual statement that does not require verification or justification. It is a direct observation about the content of the paper, making it a normal statement and fitting the label \"No.\"", "helpfulness_rationale": "The review comment identifies a specific error in the first expression for J(\u03b8) in Section 3.2.1, pointing out that it should be Q(st0, \u03c0\u03b8(st0)). This feedback is clear and actionable, providing the authors with a precise correction to make in their draft. By addressing this error, the authors can ensure the accuracy and correctness of their work. However, the comment could be more helpful if it explained why the correction is necessary or how it impacts the overall analysis. Despite this, the comment is 4 as it directly guides the authors in improving their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point consists of a series of corrections to specific words and references in the paper. It explicitly states the changes that need to be made, such as correcting \"expensive approaches\" to \"expensive approaches,2) allows,\" and capitalizing words like \"ai\" and \"bayesian\" in references. These corrections are clear and direct, providing the authors with specific actions to take. The comment is 5 as it offers concrete guidance on how to improve the draft, ensuring that the authors know exactly what changes to make.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper, such as \"p.8\" and \"p.13, supplement, Fig.\" This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it details the corrections needed, such as capitalizing words in references and correcting specific phrases. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a series of corrections to specific words and references in the paper. It does not contain subjective opinions, claims, or suggestions that require verification. It is purely factual and descriptive, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment provides a list of corrections to specific words and references in the paper. It identifies errors in capitalization and punctuation, such as \"ai\" and \"bayesian,\" and corrects phrases like \"expensive approaches\" and \"estimates.\" These corrections are clear and actionable, allowing the authors to make precise changes to improve the accuracy and professionalism of their draft. However, the comment could be more helpful if it also provided context or explanation for why these corrections are important or how they impact the paper\"s readability or credibility. Overall, the feedback is 4 as it guides the authors toward improving the draft\"s quality, but it could be more comprehensive with additional context or suggestions."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly requests information about the model parameters for task 1 and the lambda value chosen for the Boltzmann policy. It also asks how the parameters were chosen, suggesting that maximum likelihood estimates might be used. These questions are clear and direct, providing the authors with specific actions to take to address the reviewer\"s concerns. The feedback is concrete and actionable, as it guides the authors on what information to include in their draft to improve its clarity and completeness. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"task 1\" and \"Boltzmann policy,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what information is missing, namely the model parameters for task 1 and the lambda value chosen for the Boltzmann policy. Additionally, it asks how the parameters were chosen, suggesting maximum likelihood estimates as a possibility. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of factual questions seeking clarification on specific parameters and their choices. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific gap in the paper by noting the absence of information about certain model parameters, such as those for task 1 and the lambda value for the Boltzmann policy. It also raises a question about how the parameters were chosen, suggesting maximum likelihood estimates as a possibility. This feedback is clear and actionable, as it directs the authors to provide missing information and clarifies the methodology used in parameter selection. By addressing these points, the authors can enhance the transparency and comprehensiveness of their draft. However, the comment could be more helpful if it provided additional context or suggestions on how to present this information effectively. Overall, the comment is 4, as it guides the authors toward improving the clarity and completeness of their work."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the authors\" claim of achieving stateoftheart results on challenging scene text recognition tasks, suggesting that the performance is primarily due to the first step. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or improve their claims. The comment implies that the authors should conduct comparisons with existing detection methods, but this is not directly stated. The action is implicit and lacks concrete details, making it barely actionable.", "grounding_specificity_rationale": "The comment addresses the authors\" claim of achieving stateoftheart results on challenging scene text recognition tasks, questioning the validity of this claim. It suggests that the performance is primarily due to the first step and implies that comparisons with existing detection methods are necessary. However, the comment does not specify which part of the paper discusses these claims or where the authors should make comparisons. This lack of explicit grounding makes it difficult for the authors to pinpoint the exact sections that need revision. While the comment is specific in its critique, it is 1, as it does not direct the authors to a particular part of the paper. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point questions the authors\" claim of achieving stateoftheart results on challenging scene text recognition tasks, suggesting that the performance is primarily due to the first step. The reviewer provides a logical reasoning by questioning the validity of the claim and suggesting that comparisons with existing detection methods are necessary. However, the comment lacks specific examples or references to support the claim that the performance is primarily due to the first step. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the authors\" claim of achieving stateoftheart results on challenging scene text recognition tasks, suggesting that the performance is primarily due to the first step. It implies that comparisons with existing detection methods are necessary to validate the claim. While the comment identifies a potential weakness in the paper\"s claims, it lacks specific guidance or suggestions on how the authors might address this issue or improve their methodology. The feedback is 3 as it points out a critical area for improvement, but it could be more actionable with additional details or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance of applying Conditional Batch Norm (CBN) to layer 2 in addition to layers 3 and 4, compared to when CBN is applied to layers 4 and 3 only. It explicitly asks the authors to provide an explanation for this observation, suggesting that they should address the potential reasons for the observed performance deterioration. While the comment does not explicitly instruct the authors to include an explanation in the paper, the question implies that this is the desired action. The action is explicit but lacks concrete guidance on how to address the issue, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the application of Conditional Batch Norm (CBN) to layer 2, compared to when CBN is applied to layers 4 and 3 only, and asks for an explanation of why this might be happening. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the performance of applying Conditional Batch Norm (CBN) to layer 2 in addition to layers 3 and 4, compared to when CBN is applied to layers 4 and 3 only. The reviewer asks for an explanation of why this might be happening. While the comment does not provide specific evidence or references to support the claim, it does present a logical question that requires the authors to provide an explanation. The authors can address this by conducting further analysis or experimentation to understand the observed performance deterioration. Therefore, the comment is 3, as it prompts the authors to provide additional information but lacks detailed evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the application of Conditional Batch Norm (CBN) in Table 2, noting that applying CBN to layer 2 in addition to layers 3 and 4 deteriorates performance for GuessWhat?! compared to when CBN is applied to layers 4 and 3 only. This observation is relevant and could help the authors understand the impact of their experimental setup. The comment is 3 as it points out a potential issue but lacks detailed guidance or suggestions on how the authors might investigate or address this observation. To be more helpful, the comment could include suggestions for further analysis or experimentation to understand the cause of the performance deterioration. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the paper lacks a comparison with a highly relevant method, specifically mentioning the use of \"intertask ensemble\" and \"intratask\" ensemble. It also notes that the authors did not include a method or performance comparison. This feedback provides a clear and explicit action for the authors to take: include a comparison with the relevant method and its performance. The comment is specific and provides concrete guidance on what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of comparison with a highly relevant method, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the absence of a method or performance comparison, particularly in relation to the use of \"intertask ensemble\" and \"intratask\" ensemble. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a comparison with a highly relevant method, specifically mentioning the use of \"intertask ensemble\" and \"intratask\" ensemble. The reviewer provides a specific reference to another work that proposes a similar approach, which supports the claim that such a comparison is necessary. This provides a clear basis for the claim, making it 4. However, the comment could be strengthened by including more detailed reasoning or examples of how the comparison would benefit the paper. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of comparison with a highly relevant method. It specifically mentions the use of \"intertask ensemble\" and \"intratask\" ensemble, which are important aspects of the proposed method. By highlighting this omission, the comment provides clear and actionable feedback for the authors to include a comparison with the relevant method, enhancing the comprehensiveness and validity of their work. This feedback is detailed and constructive, making it 5 for the authors to improve their draft. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the proposed method\"s inability to handle headpose, questioning why it cannot condition headpose parameters similar to a previous work. While the comment implies that the authors should address this issue, it does not provide explicit instructions on how to do so. The suggestion to condition headpose parameters is implicit, and the authors would need to infer that they should explore this possibility. However, the comment lacks concrete guidance on how to implement this suggestion, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed method\"s inability to handle headpose, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning why the proposed method cannot condition headpose parameters similar to a previous work, providing a specific example (Gafni et al. ICCV 2021). This level of detail and reference to a specific work helps the authors understand what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a claim about the proposed method\"s inability to handle headpose, questioning why it cannot condition headpose parameters similar to a previous work. The reviewer provides a specific reference to a previous work (Gafni et al. ICCV 2021) that can control both facial expression and headpose, which supports the claim. However, the comment could be strengthened by providing more detailed reasoning or examples of how the previous work achieves this control. Overall, the claim is 4 as it provides a reference but lacks full elaboration, aligning with a score of 4.", "helpfulness_rationale": "The review comment identifies a significant limitation in the proposed method, specifically its inability to handle headpose. It questions why the method cannot condition headpose parameters similar to a previous work, providing a specific reference (Gafni et al. ICCV 2021) as a point of comparison. This feedback is clear and actionable, as it prompts the authors to consider how their method could be extended to address this limitation. By highlighting a specific area for improvement and providing a reference for comparison, the comment offers valuable guidance for enhancing the draft. However, it could be more helpful if it included suggestions on how to address the issue or potential approaches to explore. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a similarity between the spurious features discussed in Sections 3.1 and 3.2 and backdoor triggers, noting that both are artificial patterns that appear infrequently in the training set. It references specific examples from Chen et al. (2017) and Gu et al. (2019) 1 to illustrate this point. The comment also mentions the wellknown impact of rare spurious examples on trained models. While the comment provides a clear comparison and references external work, it does not explicitly instruct the authors to make any changes or improvements to their draft. The action is implicit and somewhat vague, as the authors can infer that they should consider the implications of these similarities but are not given specific guidance on how to address them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1 and 3.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the similarity between the spurious features discussed in the paper and backdoor triggers, providing examples from external works (Chen et al., 2017, and Gu et al., 2019) to illustrate the point. This level of detail helps the authors understand what needs to be addressed in their paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the spurious features in Sections 3.1 and 3.2 are similar to backdoor triggers, citing examples from Chen et al. (2017) and Gu et al. (2019) 1. It also mentions the wellknown impact of rare spurious examples on trained models. The comment provides specific references to external works, which helps substantiate the claim. However, it could be strengthened by providing more detailed reasoning or examples from the paper itself to fully support the comparison. Overall, the comment is 4, as it provides a solid foundation for the claim but lacks comprehensive evidence within the paper. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a similarity between the spurious features discussed in Sections 3.1 and 3.2 and backdoor triggers, noting that both are artificial patterns that appear infrequently in the training set. It references specific examples from Chen et al. (2017) and Gu et al. (2019) 1 to illustrate this point. The comment also highlights the wellknown impact of rare spurious examples on trained models. While the comment provides valuable insights and references, it does not offer specific suggestions or guidance on how the authors might address this similarity or its implications for their work. The feedback is 3 as it points out an important connection, but it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the structural optimization is a key component of the paper and has been emphasized multiple times. However, it notes that the optimization algorithm appears to be directly taken from previous works, which the reviewer finds confusing and reduces the contribution of the paper. While the comment highlights a potential issue with the originality of the work, it does not provide explicit guidance on how the authors should address this concern. The action is implicit, as the authors need to infer that they should clarify the source of the optimization algorithm and its contribution to the paper. Additionally, the comment lacks concrete suggestions on how to improve the clarity or originality of the optimization section. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"structural optimization,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the optimization algorithm appears to be directly taken from previous works, which the reviewer finds confusing and reduces the contribution of the paper. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the structural optimization is a key component of the paper but is directly taken from previous works, which reduces the contribution. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed evidence or references makes it challenging for the authors to address the concern effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient support for the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the originality of the paper, specifically regarding the structural optimization component. It points out that the optimization algorithm appears to be directly taken from previous works, which the reviewer finds confusing and reduces the contribution of the paper. This feedback is 3 as it highlights a specific area that may need clarification or originality, prompting the authors to address this concern. However, the comment could be more helpful if it provided suggestions on how to enhance the originality or differentiate the work from previous studies. Overall, the comment provides some direction for improvement but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the pipeline style method, which includes two models, does not provide better average results for both XVNLI and MaRVL. Additionally, it notes that the baseline models in the experiments are not well introduced. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to improve the introduction of baseline models or how to enhance the pipeline style method to achieve better results. Without specific suggestions or instructions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the performance of the pipeline style method, which includes two models, and the introduction of baseline models in the experiments. However, it does not specify which sections of the paper these issues are discussed in, making it weakly grounded. The comment is specific in pointing out the lack of better average results for both XVNLI and MaRVL and the inadequate introduction of baseline models. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the pipeline style method, which includes two models, does not provide better average results for both XVNLI and MaRVL. Additionally, it notes that the baseline models in the experiments are not well introduced. However, the comment lacks specific examples, detailed reasoning, or references to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies two main issues with the paper: the performance of the pipeline style method, which includes two models, and the introduction of baseline models in the experiments. It points out that the method does not provide better average results for both XVNLI and MaRVL, which is a critical finding that the authors should address. Additionally, it highlights the lack of a clear introduction of baseline models, which is important for understanding the context of the experiments. However, the comment does not provide specific suggestions or guidance on how to improve the performance of the pipeline style method or how to better introduce the baseline models. While it identifies areas for improvement, it lacks actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the authors for reproducing a wellknown result in the literature regarding left political bias in ChatGPT and LLMs in general. It questions the need for the authors to use their \"coarse\" methodology to make this observation, given that it has been made at each step of the evolution of these models. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might improve their methodology or what specific changes they should consider. As a result, the authors are left without a clear understanding of how to address the feedback or improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the authors for reproducing a wellknown result in the literature regarding left political bias in ChatGPT and LLMs in general. It questions the need for the authors to use their \"coarse\" methodology to make this observation, given that it has been made at each step of the evolution of these models. However, the comment does not specify which part of the paper this critique is based on, making it difficult for the authors to identify the exact section that needs attention. Additionally, while it provides some context about the literature and the methodology, it lacks specific details on what aspects of the paper are problematic or how they could be improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point critiques the authors for reproducing a wellknown result in the literature regarding left political bias in ChatGPT and LLMs in general. It questions the need for the authors to use their \"coarse\" methodology to make this observation, given that it has been made at each step of the evolution of these models. The comment provides a logical reasoning by referencing the historical context of similar observations in the literature, suggesting that the current observation is not novel. However, it lacks specific references or detailed examples to fully substantiate the claim, making it 3. The authors would need to further explore the literature to fully understand the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the authors for reproducing a wellknown result in the literature regarding left political bias in ChatGPT and LLMs in general. It questions the need for the authors to use their \"coarse\" methodology to make this observation, given that it has been made at each step of the evolution of these models. While the comment highlights a potential issue with the novelty of the observation, it lacks specific suggestions or guidance on how the authors might improve their work or address the critique. The feedback is 3 as it points out a potential weakness, but it does not provide actionable advice or detailed insights into how the authors might enhance their draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the authors primarily focus on SSC and do not contrast their method with other subsequent methods, such as TSC and greedy subspace clustering by Park, which are computationally efficient and have similar guarantees. While the comment highlights an area for improvement, it does not provide explicit guidance on how the authors should address this issue or suggest specific methods to include in the comparison. The action is implicit and somewhat vague, as the authors are left to infer that they should include a more comprehensive comparison with these methods. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights a focus on SSC and suggests that the authors should contrast their method with other subsequent methods, such as TSC and greedy subspace clustering by Park, which are computationally efficient and have similar guarantees. However, it does not specify which part of the paper this critique pertains to, making it weakly grounded. The comment is specific in its suggestion to include a more comprehensive comparison with these methods, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors primarily focus on SSC and do not contrast their method with other subsequent methods, such as TSC and greedy subspace clustering by Park, which are computationally efficient and have similar guarantees. The comment provides a logical reasoning by suggesting that a more comprehensive comparison with these methods would be beneficial. However, it lacks specific examples or references to these subsequent methods, which would strengthen the claim. This makes the comment 3, as it provides a logical basis but requires more detailed evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, noting that the authors primarily focus on SSC and do not contrast their method with other subsequent methods, such as TSC and greedy subspace clustering by Park, which are computationally efficient and have similar guarantees. This feedback is clear and actionable, as it suggests that the authors should include a more comprehensive comparison with these methods to enhance the robustness and relevance of their work. However, the comment could be more helpful if it provided specific guidance on how to conduct this comparison or which aspects to focus on. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to remove statements about semantic segmentation being a lowlevel cue from the paper. This is a clear and direct action that the authors can take to address the comment. The feedback is specific and provides a concrete step for improvement, making it 5.", "grounding_specificity_rationale": "The comment addresses the issue of semantic segmentation being categorized as a lowlevel cue, suggesting that this categorization should be removed. However, it does not specify which part of the paper discusses this categorization, making it weakly grounded. The comment is specific in its request to remove the statements about semantic segmentation being a lowlevel cue, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that \"semantic\" segmentation is not lowlevel since the categories are specified for each pixel. This claim is based on a logical reasoning that the level of detail in semantic segmentation makes it not a lowlevel cue. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to understand the reasoning behind the categorization to fully grasp the basis of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the categorization of semantic segmentation as a lowlevel cue, suggesting that this categorization is incorrect. It provides a clear and actionable suggestion to remove statements about semantic segmentation being a lowlevel cue from the paper. This feedback is valuable as it directs the authors to correct a potential misconception in their work, which could improve the accuracy and clarity of their claims. However, the comment could be more helpful if it provided additional context or examples to support the reasoning behind the categorization. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive with further elaboration."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that the authors should expand their experiments to include more datasets from the Federated learning benchmarks, such as LEAF, and consider relevant works like FedProx and FedMAX. It provides specific examples of datasets and references to relevant literature, which gives the authors clear guidance on how to improve their experimental section. The comment also highlights the importance of a comprehensive experimental evaluation for the paper to be considered strong. This level of detail and specificity makes the action 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiments section\" and the \"results presented only on CIFAR10 dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the experiments, namely the lack of consideration for other datasets from Federated learning benchmarks and the need to include relevant works like FedProx and FedMAX. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments section is weak due to the limited dataset used (CIFAR10) and the lack of consideration for other datasets from Federated learning benchmarks. The reviewer suggests that the authors should refer to relevant works like FedProx and FedMAX for details on different datasets and model types. This claim is 4 as it provides specific references to external works that could be used to enhance the experimental evaluation. However, the comment could be strengthened by providing more detailed reasoning or examples of how these works could be applied to improve the paper. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, specifically in the experiments section, where the results are presented only on the CIFAR10 dataset and do not consider other datasets from Federated learning benchmarks. It suggests that the authors should refer to relevant works like FedProx and FedMAX for details on different datasets and model types. This feedback is clear and actionable, providing specific examples and references that the authors can use to enhance their experimental evaluation. By addressing this issue, the authors can significantly improve the comprehensiveness and robustness of their experimental results. Therefore, the comment is 5, as it offers detailed guidance that can lead to a substantial improvement in the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the validity of the claim that the proposed modules improve both accuracy and completeness, as stated in the table. It suggests using an alternative dataset, such as the training set of Tanks & Temples or ETH3D, for the ablation study. While the comment implies that the authors should consider using a different dataset, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement the suggestion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the validity of a claim made in the paper regarding the improvement in accuracy and completeness of the proposed modules. It suggests using an alternative dataset, such as the training set of Tanks & Temples or ETH3D, for the ablation study. However, the comment does not specify which part of the paper this claim is made in, making it weakly grounded. The suggestion to use an alternative dataset is specific, as it provides a concrete example of what could be done to address the issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the validity of a claim made in the paper regarding the improvement in accuracy and completeness of the proposed modules. It suggests using an alternative dataset, such as the training set of Tanks & Temples or ETH3D, for the ablation study. This is a logical suggestion to verify the claim, as it proposes a different dataset that could provide more robust evidence. However, the comment lacks specific reasoning or examples to fully support the need for an alternative dataset. While it provides a direction for further investigation, it does not fully substantiate the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the validity of a claim made in the paper regarding the improvement in accuracy and completeness of the proposed modules. It suggests using an alternative dataset, such as the training set of Tanks & Temples or ETH3D, for the ablation study, which could provide more robust evidence for the claim. This feedback is 3 as it identifies a potential weakness in the paper and offers a specific suggestion for improvement. However, it lacks detailed guidance on how to implement the suggestion or why the current dataset might not be suitable. To be more helpful, the comment could include additional context or reasoning to support the need for an alternative dataset. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the need for more explanation regarding how a small degree of bias can be obtained from a clear community structure. It references Theorem 1 and 2, which prove that GCL conforms to a clearer community structure, but notes that the relationship with degree bias is not intuitive enough. While the comment identifies a gap in the explanation, it does not provide explicit guidance on how to address this issue or suggest specific steps for improvement. The action is implicit and somewhat vague, as the authors are left to infer what additional explanations are needed and how to present them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 1 and 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the need for more explanation regarding the relationship between a small degree of bias and a clear community structure, as well as the lack of intuitive understanding of the relationship between GCL and degree bias. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the relationship between a small degree of bias and a clear community structure is not intuitive enough, despite Theorem 1 and 2 proving that GCL conforms to a clearer community structure. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed explanation or references leaves the claim 3, as it requires more information to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by suggesting that the relationship between a small degree of bias and a clear community structure needs more explanation. It references Theorem 1 and 2, which prove that GCL conforms to a clearer community structure, but notes that the relationship with degree bias is not intuitive enough. This feedback is clear and actionable, as it directs the authors to provide a more detailed explanation of the relationship between these concepts. However, the comment could be more helpful if it offered specific suggestions on how to enhance the explanation or provided examples of similar approaches in the literature. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the construction of clean exemplar manifolds for nonstochastic networks, specifically asking how the denominator of Figure 2.c is computed for ResNet50 and ATResNet50 networks. While the comment does not explicitly instruct the authors to provide an explanation or clarification, it implies that the authors should address this question by either providing an explanation or updating the manuscript to clarify this aspect. The action is implicit but concrete, as the authors know exactly what needs to be clarified or added to their draft. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (182183) and figures (2.c) in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies the issue by questioning the construction of clean exemplar manifolds for nonstochastic networks and how the denominator of Figure 2.c is computed for ResNet50 and ATResNet50 networks. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the construction of clean exemplar manifolds for nonstochastic networks, specifically asking how the denominator of Figure 2.c is computed for ResNet50 and ATResNet50 networks. The comment does not contain subjective opinions, suggestions, or judgments that require verification. It is a factual question seeking clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the construction of clean exemplar manifolds for nonstochastic networks, specifically asking how the denominator of Figure 2.c is computed for ResNet50 and ATResNet50 networks. This feedback is 3 as it identifies a potential gap in the explanation or methodology, prompting the authors to clarify this aspect of their work. However, the comment does not provide specific suggestions or guidance on how to address this issue, leaving the authors with a clear question but without detailed instructions on how to improve their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the evaluation of shape model invariance, specifically questioning whether the study on transformations of training images is sufficient to prove the point. It suggests that quantitative results on testing images might be needed to fully validate the claim. While the comment implies that the authors should provide such results, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to conduct the evaluation or what metrics to use. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the shape model invariance study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the sufficiency of the evaluation on transformations of training images and suggests that quantitative results on testing images might be needed. This provides clear guidance on what aspect of the study needs further evaluation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the sufficiency of the evaluation on transformations of training images for proving shape model invariance. It suggests that quantitative results on testing images might be necessary. However, the comment does not provide specific examples, references, or detailed reasoning to support why testing images are crucial or how they would provide additional evidence. This lack of detailed justification makes the claim 3, as the authors would need to infer the importance of testing images based on the general suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the evaluation of shape model invariance. It questions the sufficiency of the evaluation on transformations of training images and suggests that quantitative results on testing images might be necessary to fully prove the point. This feedback is clear and actionable, as it directs the authors to consider an additional aspect of their evaluation that could strengthen their argument. However, the comment could be more helpful if it provided specific suggestions on how to conduct the evaluation on testing images or what metrics to use. Overall, the comment is 4 as it guides the authors toward a potential improvement in their study, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should discuss and compare their work with the AAAI15 paper by Ghoshdastidar and Dukkipati, which deals with hypergraph data using tensors. This feedback is explicit and provides a clear action for the authors to take, which is to include a discussion and comparison with this related work. The comment also specifies the reason for this action, highlighting the relevance of the AAAI15 paper to the authors\" work. Therefore, the comment is 5, as it gives the authors a direct and concrete step to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the AAAI15 paper by Ghoshdastidar and Dukkipati, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of a discussion and comparison with this related work. This provides clear guidance on how to improve the paper by ensuring it covers relevant stateoftheart work. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the AAAI15 paper by Ghoshdastidar and Dukkipati is a related work that should be discussed and compared to provide a better understanding of the stateoftheart. The comment provides a specific reference to the AAAI15 paper, which is a clear and explicit source of evidence supporting the claim. This makes the claim 5, as it is based on a concrete reference that the authors can easily verify or address in their work. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a potential gap in the authors\" work by pointing out a related paper, \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications\" by Ghoshdastidar and Dukkipati, which deals with hypergraph data using tensors. The comment suggests that this paper should be discussed and compared to provide a better understanding of the stateoftheart. This feedback is clear and actionable, as it directs the authors to include a discussion and comparison with this related work, which can enhance the context and relevance of their own work. However, the comment could be more helpful if it provided specific suggestions on how to integrate this comparison or discussed potential insights that could be gained from it. Overall, the comment is 4, as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point raises concerns about the scalability of the method for computing optimal transport distance and questions the approach used to compute it. It explicitly asks for an evaluation of the method\"s scalability on normal machines with a few cores and inquires about the process of converting a doubly stochastic matrix into optimal transport. These questions provide clear and specific actions for the authors to take, such as conducting scalability tests and clarifying the conversion process. The feedback is explicit and concrete, giving the authors a clear understanding of what needs to be addressed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Approach,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises concerns about the scalability of the method for computing optimal transport distance and questions the approach used to compute it. The reviewer specifically asks for an evaluation of the method\"s scalability on normal machines with a few cores and inquires about the process of converting a doubly stochastic matrix into optimal transport. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises concerns about the scalability of the method for computing optimal transport distance and questions the approach used to compute it. The reviewer points out that the authors have indicated that the computation takes seconds on a 36core machine, but questions whether it scales to normal machines with fewer cores. Additionally, the reviewer asks how the doubly stochastic matrix is converted into optimal transport. These questions are logical and based on the information provided, but they lack specific references or detailed reasoning to fully substantiate the claims. Therefore, the comment is 3, as it provides a basis for the questions but requires more detailed justification or evidence to be 5.", "helpfulness_rationale": "The review comment raises important concerns about the scalability of the method for computing optimal transport distance and questions the approach used to compute it. It specifically asks for an evaluation of the method\"s scalability on normal machines with a few cores and inquires about the process of converting a doubly stochastic matrix into optimal transport. These questions are clear and actionable, providing the authors with specific areas to address and improve their draft. By seeking clarification on these points, the comment empowers the authors to enhance the comprehensiveness and robustness of their work. Therefore, the comment is rated as 5, as it offers detailed and constructive feedback that can significantly benefit the authors in improving their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment indicates that the paper is difficult to follow, specifically mentioning issues with understanding the experimental procedures and evaluations. However, it does not provide any explicit or implicit suggestions for improvement. There is no guidance on how the authors might clarify or simplify the experimental procedures or evaluations to make the paper more accessible. Without actionable advice or specific recommendations, the authors are left without a clear path to address the issues raised. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment indicates that the paper is difficult to follow, specifically mentioning issues with understanding the experimental procedures and evaluations. However, it does not specify which part of the paper is particularly challenging to follow, making it weakly grounded. The comment is specific in identifying the issue with understanding the experimental procedures and evaluations, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is difficult to follow, specifically mentioning issues with understanding the experimental procedures and evaluations. However, the comment does not provide any specific examples or detailed reasoning to support this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment indicates that the paper is difficult to follow, specifically mentioning issues with understanding the experimental procedures and evaluations. However, it does not provide any specific suggestions or guidance on how the authors might improve the clarity or organization of their work. Without actionable feedback or detailed advice, the authors are left without a clear path to address the issues raised. Therefore, the comment is 1, as it does not offer any constructive direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the applicability of the parameters, model, and experiments to areas beyond image data and ViT. It suggests that the authors should consider applying their principles to other research areas, such as NLP or simpler models in the image domain (CNNs), to demonstrate generalizability. While the comment implies that the authors should explore these areas, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement this exploration. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1\" and \"the model and the experiments,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the applicability of the parameters, model, and experiments to areas beyond image data and ViT, suggesting that the authors should explore other research areas such as NLP or simpler models in the image domain. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a claim about the applicability of the parameters, model, and experiments to areas beyond image data and ViT. It suggests that the authors should explore other research areas, such as NLP or simpler models in the image domain, to demonstrate generalizability. The comment provides a logical reasoning by questioning the focus on stateoftheart performance and suggesting that broader applicability would strengthen the paper. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to provide additional evidence or context to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the applicability of the parameters, model, and experiments to areas beyond image data and ViT. It suggests that the authors should explore other research areas, such as NLP or simpler models in the image domain, to demonstrate the generalizability of their method. This feedback is clear and actionable, as it provides a specific direction for the authors to expand their work and improve its relevance. However, the comment could be more helpful if it offered additional guidance on how to approach these other areas or what specific aspects to consider. Overall, the comment is 4, as it effectively guides the authors toward enhancing the scope and applicability of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights an interesting observation about the performance of TTA methods on nonstandard benchmarks, suggesting that evaluating TTA on more conditions of natural distribution shift, such as WILDS, could strengthen the paper. While the comment implies that the authors should consider evaluating TTA on WILDS, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement this evaluation or what specific aspects of WILDS should be considered. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Performance of TTA methods,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests evaluating TTA on more conditions of natural distribution shift, such as WILDS, which provides a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point makes an observation about the performance of TTA methods on nonstandard benchmarks, suggesting that evaluating TTA on more conditions of natural distribution shift, such as WILDS, could strengthen the paper. The comment provides a logical reasoning by suggesting that evaluating TTA on a more diverse set of conditions could enhance the paper\"s contribution. However, it lacks specific examples or references to WILDS or other relevant datasets, which would strengthen the justification. Therefore, the claim is 3, as it provides a logical basis but requires more detailed support to be fully convincing.", "helpfulness_rationale": "The review comment highlights an interesting observation about the performance of TTA methods on nonstandard benchmarks, suggesting that evaluating TTA on more conditions of natural distribution shift, such as WILDS, could strengthen the paper. This feedback is 3 as it provides a specific suggestion for enhancing the paper\"s scope and relevance. However, it lacks detailed guidance on how to implement this evaluation or what specific aspects of WILDS should be considered. While it points the authors in a promising direction, it could be more helpful with additional details or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the usefulness of the results in the context of machine learning algorithms and the analysis of the algorithm. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve the clarity of the paper. The comment lacks actionable details, such as recommending specific ways to demonstrate the significance of the paper or suggesting how to better integrate the results into machine learning applications. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the usefulness of the results in the context of machine learning algorithms and the analysis of the algorithm, suggesting that the significance of the paper is poor. However, it does not specify which part of the paper this issue pertains to, such as a particular section or methodology, making it difficult for the authors to identify the exact area needing revision. The comment is specific in its critique of the paper\"s significance but lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the significance of the paper is poor because the results are not clear in their usefulness for machine learning algorithms or the analysis of the algorithm. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, noting that the usefulness of the results in the context of machine learning algorithms or the analysis of the algorithm is unclear. This feedback highlights a critical area for improvement, as it suggests that the paper\"s significance may be undermined by the lack of clarity in its application to machine learning. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or enhance the clarity of the paper. While it points out a crucial area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight but lacks depth and specificity in its guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment expresses skepticism about the experimental results and questions the usefulness of the experiments section. It points out that the paper aims to solve POMDP problems with nonconvex value functions but does not provide experiments on the specific settings mentioned, such as surveillance in museums with thresholded rewards or privacypreserving data collection. The comment implies that the authors should include experiments on these settings to better motivate their solution. However, it does not explicitly instruct the authors to conduct these experiments or provide detailed guidance on how to implement them. The action is implicit and somewhat vague, as the authors can infer that they need to add experiments but are not given specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental results\" and the \"POMDP problem with nonconvex value function,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the lack of experiments on specific settings, such as surveillance in museums with thresholded rewards or privacypreserving data collection. This provides clear guidance on what needs to be addressed in the experiments section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point expresses skepticism about the experimental results, questioning the usefulness of the experiments section. It challenges the paper\"s motivation by pointing out that the examples used to motivate the solution are not tested in the experiments. The reviewer suggests that the experiments should include scenarios similar to those mentioned, such as surveillance in museums with thresholded rewards or privacypreserving data collection. However, the comment lacks specific examples or detailed reasoning to support the claim that these experiments are necessary or how they would improve the paper. The lack of detailed justification makes the claim 3, as it provides a general direction but requires more detailed evidence or examples to fully substantiate the critique.", "helpfulness_rationale": "The review comment raises a significant concern about the experimental results and the usefulness of the experiments section. It questions the motivation of the paper by pointing out that the examples used to motivate the solution are not tested in the experiments. The reviewer suggests that the experiments should include scenarios similar to those mentioned, such as surveillance in museums with thresholded rewards or privacypreserving data collection. This feedback is clear and actionable, as it identifies a specific area for improvement and provides a direction for the authors to enhance the relevance and applicability of their experiments. However, the comment could be more helpful if it offered specific suggestions on how to incorporate these scenarios or provided examples of similar experiments. Overall, the comment is 4, as it effectively guides the authors toward improving the experimental section of their paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that an epochwise analysis, particularly for finite sum settings, could provide insights into the behaviors of optimization algorithms. It proposes investigating the effects of batch size and different sampling strategies on the progress of algorithms after every full pass of data. Additionally, it suggests that this analysis could aid in comparative analysis of deterministic and stochastic methods. While the comment implies that the authors should consider including an epochwise analysis, it does not explicitly instruct them to do so or provide detailed guidance on how to implement this analysis. The action is implicit and somewhat vague, as the authors can infer the need for an epochwise analysis but may not be entirely sure of the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests an analysis of epochwise behavior, particularly for finite sum settings, to gain insights into optimization algorithms. It proposes investigating the effects of batch size and different sampling strategies on the progress of algorithms after every full pass of data. Additionally, it mentions the potential for comparative analysis of deterministic and stochastic methods. However, the comment does not specify which part of the paper this analysis should be included in, making it weakly grounded. The suggestion is specific in terms of the type of analysis and potential insights it could provide, but without explicit references to sections or figures, the authors may find it challenging to pinpoint where to incorporate this feedback. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that an epochwise analysis, particularly for finite sum settings, could provide insights into the behaviors of optimization algorithms. It proposes investigating the effects of batch size and different sampling strategies on the progress of algorithms after every full pass of data. The comment also mentions the potential for comparative analysis of deterministic and stochastic methods. While the suggestion is logical and provides a clear direction for further analysis, it lacks specific examples or references to support the claim. This makes the comment 3, as it provides a reasonable basis for the suggestion but requires more detailed justification or evidence to be fully convincing.", "helpfulness_rationale": "The review comment suggests a potential area for improvement by proposing an epochwise analysis, particularly for finite sum settings, to gain insights into the behaviors of optimization algorithms. It provides a specific example of investigating the effects of batch size and different sampling strategies on the progress of algorithms after every full pass of data. Additionally, it mentions the potential for comparative analysis of deterministic and stochastic methods. This feedback is clear and actionable, offering the authors a concrete direction for enhancing their analysis and understanding of their results. However, it could be more helpful if it included specific suggestions on how to implement this analysis or examples of similar studies that have used epochwise analysis. Overall, the comment is 4 as it provides a valuable insight into improving the paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights several issues with the paper, including the incremental nature of the contribution, the lack of citation for key baselines, and the absence of essential RAG algorithms like MedRetriever and KGRAG. While the comment identifies specific areas that need attention, it does not provide explicit instructions or concrete suggestions on how the authors should address these issues. The authors are left to infer that they should include these citations and algorithms, but the comment lacks detailed guidance on how to implement these changes. Therefore, the comment is 3, as it points out areas for improvement but does not provide direct steps for the authors to take.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"your code\" and \"the details in the article,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the incremental nature of the contribution, the lack of citation for key baselines, and the absence of essential RAG algorithms like MedRetriever and KGRAG. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the contribution of the article is incremental, stating that it is essentially a combination of GraphRAG and GraphCare. It also points out the lack of citation for key baselines and suggests that essential RAG algorithms like MedRetriever and KGRAG should have been introduced. While the comment provides some reasoning by referencing specific algorithms, it lacks detailed justification or examples to fully substantiate the claim about the incremental nature of the contribution. The mention of specific algorithms and baselines adds some support, but the overall justification is not robust. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed evidence or examples to be fully convincing.", "helpfulness_rationale": "The review comment provides a detailed critique of the paper, identifying several areas for improvement. It highlights the incremental nature of the contribution, noting that it is essentially a combination of existing methods like GraphRAG and GraphCare. The comment also points out the lack of citation for key baselines and suggests that essential RAG algorithms, such as MedRetriever and KGRAG, should have been introduced. This feedback is actionable as it directs the authors to include relevant citations and algorithms, which could enhance the paper\"s contribution and relevance. However, the comment could be more helpful if it offered specific suggestions on how to integrate these algorithms or provided examples of how to improve the paper\"s originality. Overall, the comment is 4 as it identifies clear areas for improvement and provides some guidance, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to include a graph showing the plot of T vs the number of images and Expectation(T) over the ImageNet test set. This provides a clear and direct action for the authors to take, as it specifies exactly what needs to be added to the draft. The comment also offers a rationale for why this information is important, which further clarifies the action. Therefore, the comment is 5, as it provides concrete guidance on how to improve the draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for a graph showing the plot of T vs the number of images and Expectation(T) over the ImageNet test set. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be added to the paper, namely, a graph to understand the performance improvement and whether it stems from the network design or the nature of ImageNet. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should include a graph showing the plot of T vs the number of images and Expectation(T) over the ImageNet test set to understand whether the performance improvement stems from the network design or the nature of ImageNet. The comment provides a logical reasoning for why this information is important, suggesting that the nature of ImageNet, with a large fraction of images that can be done with Glance, might give an unfair advantage to algorithms with lower resolution. However, the comment does not provide specific examples or references to support this claim, making it 3. The authors would need to infer the importance of this analysis based on the provided reasoning. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides clear and actionable feedback by suggesting that the authors include a graph showing the plot of T vs the number of images and Expectation(T) over the ImageNet test set. This request is specific and offers a concrete way for the authors to enhance their draft by providing additional data visualization. The comment also raises an important question about whether the performance improvement stems from the network design or the nature of ImageNet, which is relevant for understanding the fairness of the results. While the comment could be more detailed in explaining the rationale behind this request, it still offers valuable guidance for improving the paper. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors need to change the notation to make it mathematically correct, unless doing so would make other equations messy. It also points out that the notation L_l should be introduced beforehand. While the comment implies that changes are needed, it does not provide explicit instructions on how to make these changes or what specific elements need to be revised. The action is implicit and somewhat vague, as the authors can infer that they need to address the notation issue but may not be entirely sure of the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig.\" and \"L_l,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the mathematical correctness of the notation and the introduction of the notation L_l. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the notation used in the paper, specifically \"L_l\" instead of just \"L,\" should be introduced beforehand. The comment implies that this change is necessary for mathematical correctness, but it does not provide specific reasoning or examples to support why this is the case. Without detailed explanation or references, the claim remains somewhat vague, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper: the need for mathematical correctness and the introduction of notation. It suggests that the notation \"L_l\" should be introduced beforehand, which is a clear and actionable piece of feedback. However, the comment could be more helpful if it provided additional context or examples of how the notation should be introduced or why it is necessary for mathematical correctness. Despite this, the comment offers valuable guidance that can help the authors improve the clarity and accuracy of their work. Therefore, it is rated as 4, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the importance of studying the effect of noise accumulation in the context of homomorphic encryption for sequential ensembling. It also mentions a limitation that prevents the use of even single deep neural networks on homomorphically encrypted data. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their draft. The action is implicit and vague, as it lacks concrete steps or details on how to study the effect of noise accumulation or overcome the limitation. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the issue of noise accumulation in the context of homomorphic encryption for sequential ensembling. However, it does not specify which part of the paper discusses this topic, making it weakly grounded. The comment is specific in its suggestion to study the effect of noise accumulation and mentions a limitation that prevents the use of even single deep neural networks on homomorphically encrypted data. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that studying the effect of noise accumulation in the context of homomorphic encryption is important for sequential ensembling and that a limitation prevents the use of even single deep neural networks on homomorphically encrypted data. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. The absence of supporting evidence or detailed justification makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment highlights an important limitation in the context of sequential ensembling and homomorphic encryption, specifically mentioning the issue of noise accumulation. It points out that this limitation prevents the use of even single deep neural networks on homomorphically encrypted data. While the comment identifies a critical area for improvement, it lacks specific suggestions or guidance on how the authors might address this limitation or explore alternative approaches. The feedback is 3 as it provides insight into a significant challenge, but it could be more actionable with additional guidance or examples. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should use a standard regularization trick to compare the obtained complexity for the proposed method with the previous result in a stronglyconvex concave case. However, it does not provide specific details on which regularization trick should be used or how to implement it. The action is explicit but vague, as the authors are left to infer the exact steps needed to apply the suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests using a standard regularization trick to compare the obtained complexity for the proposed method with the previous result in a stronglyconvex concave case. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. Without explicit references, the authors may find it challenging to determine where to incorporate this suggestion. The comment is specific in its recommendation to use a standard regularization trick but lacks grounding, as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests using a standard regularization trick to compare the obtained complexity for the proposed method with the previous result in a stronglyconvex concave case. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this approach is necessary or beneficial. Without additional context or explanation, the authors may find it challenging to understand the rationale behind the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests using a standard regularization trick to compare the obtained complexity for the proposed method with the previous result in a stronglyconvex concave case. While it identifies a potential area for improvement, the comment lacks specificity and does not provide detailed guidance on which regularization trick to use or how to implement it. The suggestion is 3 as it points out a possible enhancement, but it does not offer actionable steps or detailed advice, leaving the authors with limited direction for improvement. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests including a learning curve for a model without any mean teacher or pi regularization in the left graph of Figure 3. This suggestion is clear and provides a concrete action for the authors to take, as it specifies exactly what needs to be added to the figure for comparison. The authors know exactly what to do to improve their draft based on this feedback, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be included in the left graph of Figure 3, namely, the learning curve for a model without any mean teacher or pi regularization. This provides clear guidance on what the authors need to address to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests including a learning curve for a model without any mean teacher or pi regularization in the left graph of Figure 3 to compare the effect of these techniques on learning. This is a logical suggestion to enhance the clarity and comprehensiveness of the figure, but it does not contain any subjective claims, opinions, or judgments that require verification. It is purely a request for additional information or clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the paper. It recommends including a learning curve for a model without any mean teacher or pi regularization in the left graph of Figure 3, which would allow for a direct comparison of the effect of these techniques on learning. This feedback is clear and offers a concrete way for the authors to enhance the comprehensiveness and clarity of their results. By addressing this suggestion, the authors can provide a more detailed analysis of the impact of the proposed methods, which is highly beneficial for improving the draft. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the handling of different types of inputs, such as biomedical signals or speech, and suggests that the authors should discuss and present their solutions in the paper. While the comment implies that the authors should address this issue, it does not provide specific guidance on how to do so or what aspects of the solutions should be discussed. The mention of \"citation\" being \"a bit disordered\" is vague and does not offer actionable advice. Therefore, the comment is 3, as it identifies an area for improvement but lacks concrete details on how to implement the suggested changes.", "grounding_specificity_rationale": "The comment raises a concern about the handling of different types of inputs, such as biomedical signals or speech, and suggests discussing and presenting solutions in the paper. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in suggesting that the authors should discuss and present their solutions regarding different types of inputs. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the handling of different types of inputs, such as biomedical signals or speech, and suggests discussing and presenting solutions in the paper. However, the comment does not provide specific examples or detailed reasoning to support why this is an issue or how it could be addressed. The mention of \"citation\" being \"a bit disordered\" is vague and lacks context. Without additional details or examples, the claim is difficult for the authors to understand and address, making it 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors should discuss and present their solutions for handling different types of inputs, such as biomedical signals or speech. This feedback is clear and actionable, as it directs the authors to address a critical aspect of their work that could enhance its applicability and relevance. However, the comment could be more helpful if it provided specific examples or suggestions on how to approach this discussion or solution. Despite this, the feedback is 4 as it guides the authors toward a meaningful enhancement of their draft. Therefore, it aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the question answering process, specifically the use of template mapping to transform questions into masked statements. It suggests that this approach might lead to poor generalization for questions that are not \"Whtypes\" or transformable. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the generalization of their model. The action is implicit and vague, as the authors are left to infer that they need to explore alternative methods or improve the template mapping process. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the question answering process, namely the use of template mapping to transform questions into masked statements. However, it does not specify which part of the paper discusses this process, making it weakly grounded. The comment is specific in detailing the potential issue with generalization for questions that are not \"Whtypes\" or transformable. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the question answering process might lead to poor generalization due to the use of template mapping to transform questions into masked statements. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks references to similar cases or studies that demonstrate the potential issue with generalization. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient support for the authors to fully understand and address the issue.", "helpfulness_rationale": "The review comment identifies a potential issue with the question answering process, specifically the use of template mapping to transform questions into masked statements. It suggests that this approach might lead to poor generalization for questions that are not \"Whtypes\" or transformable. While the comment highlights a critical area for improvement, it lacks specific suggestions or guidance on how the authors might address this issue or explore alternative methods. The feedback is 3 as it points out a potential weakness, but it could be more actionable with additional details or recommendations. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to cite the source of the rockpaperscissors example, which is clearly inspired by an example from previous work. This is a direct and concrete action, leaving no ambiguity about what the authors need to do. The comment provides a clear and specific instruction, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"rockpaperscissors example,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by pointing out that the example is inspired by previous work and requests appropriate citation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the rockpaperscissors example is inspired by an example from previous work and requests appropriate citation. This claim is verifiable as it provides a logical reasoning that the example is not original and should be properly attributed. However, the comment lacks specific references to the previous work, which would strengthen the justification. Therefore, the claim is 4, as it requires additional information to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the rockpaperscissors example is inspired by an example from previous work and requests appropriate citation. This feedback is clear and actionable, as it directs the authors to address a potential issue with originality and attribution. By providing this information, the comment helps the authors improve the integrity and transparency of their work. However, it could be more helpful if it included suggestions on how to integrate the citation or discuss the inspiration from previous work. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point critiques the limited innovations in network architecture design and constraint embedding, noting that the authors have discussed the performance being limited by the oracle expert. However, it does not provide any explicit or implicit suggestions for improvement or guidance on how the authors might address these limitations. Without actionable advice or specific recommendations, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the limited innovations in network architecture design and constraint embedding, noting that the authors have discussed the performance being limited by the oracle expert. However, it does not specify which part of the paper discusses these limitations or how they could be improved. The authors might infer that it relates to the methodology or results sections, but this inference is not explicit. The comment lacks specificity as it does not provide detailed guidance on what aspects of the network architecture or constraint embedding need improvement. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the innovations in network architecture design and constraint embedding are limited, and it references the authors\" discussion about the performance being limited by the oracle expert. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed justification or references makes the claim 3, as it requires more information to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a limitation in the innovations of network architecture design and constraint embedding, noting that the performance is limited by the oracle expert. However, it does not provide specific suggestions or guidance on how the authors might address this limitation or improve their work. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that comparing the performance of the model only pretrained on synthetic data is unfair and recommends demonstrating the importance of the proposed three projection errors. It also specifies that the performance of models pretrained on synthetic data but finetuned on realworld datasets with different losses should be provided. This feedback is clear and provides concrete guidance on what the authors need to do to improve their draft. The explicit nature of the action and the detailed suggestions make this comment 5.", "grounding_specificity_rationale": "The comment suggests that comparing the performance of the model only pretrained on synthetic data is unfair and recommends demonstrating the importance of the proposed three projection errors. It also specifies that the performance of models pretrained on synthetic data but finetuned on realworld datasets with different losses should be provided. However, the comment does not explicitly mention which part of the paper this critique pertains to, such as a specific section or experiment. While the authors might infer that it relates to the experimental results or methodology sections, the lack of explicit grounding makes it weakly grounded. The comment is specific in detailing what needs to be addressed, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that comparing the performance of the model only pretrained on synthetic data is unfair and suggests that demonstrating the importance of the proposed three projection errors is more appropriate. The comment provides a logical reasoning by suggesting that the performance should be evaluated on realworld datasets with different losses. However, it lacks specific examples or references to support the claim that the current approach is unfair or to substantiate the suggestion for alternative evaluations. This makes the claim 3, as it provides a logical basis but lacks detailed evidence or examples to fully substantiate the argument.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental setup, noting that comparing the performance of the model only pretrained on synthetic data is unfair. It suggests that demonstrating the importance of the proposed three projection errors is more appropriate, and provides a clear and actionable recommendation to include the performance of models pretrained on synthetic data but finetuned on realworld datasets with different losses. This feedback is valuable as it highlights a potential weakness in the experimental design and offers a concrete suggestion for improvement. By addressing this issue, the authors can enhance the validity and comprehensiveness of their results. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the range of ID and OOD in Figure 4 does not seem to change much with sparsification, and it highlights the importance of Lemma 2 requiring approximately identical mean as the assumption. The reviewer suggests that these conditions are crucial for DICE but are not well discussed, specifically asking how to ensure DICE meets these conditions. While the comment identifies areas that need further discussion, it does not provide explicit guidance on how the authors should address these issues or what specific aspects should be included in the discussion. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps without concrete instructions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4\" and \"Lemma 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the range of ID and OOD does not seem to change much with sparsification, and it highlights the importance of Lemma 2 requiring approximately identical mean as the assumption. The comment further suggests that these conditions are crucial for DICE but are not well discussed, specifically asking how to ensure DICE meets these conditions. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with a score of 5.", "verifiability_rationale": "The review point claims that the range of ID and OOD in Figure 4 does not seem to change much with sparsification, and it questions the relevance of Lemma 2 requiring approximately identical mean as the assumption. The comment suggests that these conditions are crucial for DICE but are not well discussed. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that these conditions are not adequately addressed. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the range of ID and OOD in Figure 4 does not seem to change much with sparsification, and it questions the relevance of Lemma 2 requiring approximately identical mean as the assumption. The comment highlights the importance of these conditions for DICE but points out that they are not well discussed. This feedback is 3 as it directs the authors to a potential area of improvement by suggesting that they should discuss how to ensure DICE meets these conditions. However, the comment could be more helpful if it provided specific suggestions or examples on how to address these issues. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the integration of the update over all possible environments, assuming the true environment is unknown at update time. It also suggests that the bolded sections on page 6 should be broken out into paragraphs due to being a \"huge wall of text.\" While the comment implies that the authors should clarify the integration process and consider restructuring the text, it does not provide explicit instructions on how to address these issues. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"page 6\" and the \"bolded sections,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the text being a \"huge wall of text\" and suggests breaking it into paragraphs. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the integration of the update over all possible environments, assuming the true environment is unknown at update time. The reviewer suggests that this integration might be necessary for the update to be meaningful. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the integration of the update over all possible environments, assuming the true environment is unknown at update time. This is a valid point that could help the authors clarify their methodology or assumptions. Additionally, the comment suggests breaking out the bolded sections on page 6 into paragraphs, which is a practical suggestion to improve the readability of the text. However, the comment could be more helpful if it provided more detailed guidance on how to address the integration issue or offered specific examples of how to structure the paragraphs. Overall, the comment is 3 as it identifies areas for improvement but lacks depth and actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests adding a citation on differential privacy, specifically mentioning a standard work like 2 as an example. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 156,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding a citation on differential privacy, providing a clear direction for improvement. The comment specifies a particular standard work, 2, which could be used as a reference. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests adding a citation on differential privacy, specifically mentioning a standard work like 2. This is a clear and specific request for additional information, providing a direct action for the authors to take. The suggestion is wellsupported by the explicit mention of a specific reference, which makes the claim 5. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the paper by recommending the addition of a citation on differential privacy, specifically mentioning a standard work like 2. This feedback is clear and direct, offering the authors a concrete step to enhance the comprehensiveness and credibility of their work. By including this reference, the authors can provide a more thorough context for their discussion on differential privacy, which is beneficial for both the reader and the authors themselves. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point consists of two parts. The first part addresses a claim in the paper that \"this methodology requires significant additional assumptions,\" suggesting that this claim is too extreme. The reviewer provides a specific counterargument, stating that the only additional assumption is that the test set is drawn from the same distribution as the query set, which is a natural assumption in many machine learning settings. This feedback is explicit and provides a clear direction for the authors to reconsider their claim. The second part of the comment points out an inequality with the wrong sign, providing a specific line number for correction. This is also explicit and actionable, as it directs the authors to make a precise change. Both parts of the comment are clear and provide concrete guidance, making the review 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2\" and \"line 310,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides a detailed critique of the claim made in the first paragraph of Section 3.2, questioning the necessity of additional assumptions and offering a counterargument. Additionally, it points out an error in the inequality on line 310, specifying the incorrect sign. This level of detail and specificity provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of two parts. The first part challenges the claim that \"this methodology requires significant additional assumptions,\" suggesting that the only additional assumption is that the test set is drawn from the same distribution as the query set, which is a natural assumption in many machine learning settings. This provides a logical reasoning to support the claim, making it 4. The second part points out an error in the inequality on line 310, suggesting a correction by comparing it to the inequality on line 227. This is a factual observation that does not require verification, as it is a straightforward correction. Therefore, the overall comment is 4, as the first part provides logical reasoning while the second part is factual.", "helpfulness_rationale": "The review comment provides two distinct pieces of feedback. First, it challenges the claim in the paper that \"this methodology requires significant additional assumptions,\" suggesting that the only additional assumption is that the test set is drawn from the same distribution as the query set, which is a natural assumption in many machine learning settings. This critique is logical and provides a clear rationale for questioning the claim, offering the authors a perspective to reconsider their argument. Second, the comment points out an error in the inequality on line 310, suggesting a correction by comparing it to the inequality on line 227. This specific feedback is actionable and helps the authors improve the accuracy of their work. Both parts of the comment are clear and provide valuable insights, making the feedback 4. However, it could be more comprehensive by offering suggestions on how to address the critique or improve the clarity of the assumptions. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide a more robust justification for using Shapely values over other methods, such as CaCE or raw gradients, by conducting experimental comparisons. It also recommends including a significant discussion on the advantages and disadvantages of different methods for transforming highdimensional data to lowdimensional latent space. While the comment implies that the authors should conduct additional experiments and provide a more comprehensive discussion, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Shapely values\" and \"other methods,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear suggestions for improvement, such as comparing Shapely values with other methods like CaCE or raw gradients, and discussing the advantages and disadvantages of different methods for transforming highdimensional data. This level of detail guides the authors on what specific aspects need attention and improvement. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide a more robust justification for using Shapely values over other methods, such as CaCE or raw gradients, by conducting experimental comparisons. It also recommends including a significant discussion on the advantages and disadvantages of different methods for transforming highdimensional data to lowdimensional latent space. While the comment provides a logical reasoning for the need to compare methods and discuss their advantages, it lacks specific examples or references to support the claim. This makes the claim 3, as the authors would need to provide additional evidence or examples to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors should provide a more robust justification for using Shapely values over other methods, such as CaCE or raw gradients. It also recommends including a significant discussion on the advantages and disadvantages of different methods for transforming highdimensional data to lowdimensional latent space. This feedback is clear and actionable, as it guides the authors on how to strengthen their argument and enhance the comprehensiveness of their paper. However, the comment could be more helpful if it provided specific examples or references to support the suggested comparisons or discussions. Overall, the comment is 4, as it offers valuable insights for improving the draft, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point acknowledges the comprehensive experiments conducted by the authors to validate the efficacy of CATER in various settings, including an architectural mismatch and crossdomain imitation. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to improve the experiments, what specific aspects need further exploration, or how to enhance the results. Without any actionable suggestions or feedback, the authors are left without a clear path for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment acknowledges the comprehensive experiments conducted by the authors to validate the efficacy of CATER in various settings, including an architectural mismatch and crossdomain imitation. However, it does not specify which part of the paper these experiments are discussed in, nor does it provide any specific feedback or suggestions for improvement. Without explicit references to sections or figures, the authors cannot confidently determine which parts of the paper are being addressed. Additionally, the comment lacks specificity regarding what aspects of the experiments need further exploration or improvement. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point acknowledges the comprehensive experiments conducted by the authors to validate the efficacy of CATER in various settings, including an architectural mismatch and crossdomain imitation. However, it does not express any subjective opinions, judgments, or suggestions for improvement. It is purely descriptive and factual, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment acknowledges the comprehensive experiments conducted by the authors to validate the efficacy of CATER in various settings, including an architectural mismatch and crossdomain imitation. However, it does not provide any feedback, suggestions, or critique that could help the authors improve their work. It lacks specificity and does not offer any actionable advice or guidance for enhancing the paper. As a result, the comment is 1, as it does not provide the authors with any direction for improvement. Therefore, it aligns with a score of 1."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a specific issue with Appendix A.2, noting that it does not clearly illustrate the state space representation of the environment. However, it does not provide any explicit or implicit guidance on how to address this issue or improve the clarity of the representation. The authors are left without any actionable steps to take, such as suggestions for additional explanations, examples, or changes to the representation. Without specific instructions or examples, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix A.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity in illustrating the state space representation of the environment. This provides clear guidance on what needs to be addressed in the appendix. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Appendix A.2 does not illustrate the state space representation of the environment clearly. However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the clarity of the state space representation of the environment in Appendix A.2. This is a clear and actionable piece of feedback that can help the authors improve the clarity and comprehensibility of their work. However, the comment could be more helpful if it provided suggestions on how to enhance the clarity of the representation or examples of what a clear illustration might look like. Despite this, the feedback is still valuable as it directs the authors to a specific area needing improvement. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point highlights a limitation of the authors\" approach, stating that it is only applicable for small or mediumscale problems and that largescale problems may overwhelm current LPsolvers. However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or improve their approach to handle largerscale problems. The comment lacks actionable guidance, leaving the authors without a clear understanding of what steps to take to enhance their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a limitation of the authors\" approach, stating that it is only applicable for small or mediumscale problems and that largescale problems may overwhelm current LPsolvers. However, it does not specify which part of the paper this limitation is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the approach need to be improved or how the authors might address this limitation. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the authors\" approach is only applicable for small or mediumscale problems, and that largescale problems may overwhelm current LPsolvers. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation of the authors\" approach, noting that it is only applicable for small or mediumscale problems and may struggle with largescale problems. However, it does not provide any suggestions or guidance on how the authors might address this limitation or improve their approach to handle largerscale problems. Without actionable feedback or constructive advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the motivation behind using characteristic function regularization is unclear. However, it does not provide any explicit or implicit suggestions on how the authors might clarify this motivation or improve the clarity of their explanation. Without guidance on what specific aspects of the motivation are unclear or how to address them, the authors are left without a clear path forward. The comment lacks actionable details, leaving the authors without a clear understanding of what changes are needed to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the overall motivation for using characteristic function regularization, but it does not specify which part of the paper this issue pertains to, such as a specific section or subsection. This makes it difficult for the authors to pinpoint the exact area that needs revision. Additionally, the comment lacks specificity regarding what aspects of the motivation are unclear or how they could be clarified. Without explicit references or detailed guidance, the authors are left without a clear understanding of what needs to be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the overall motivation for using characteristic function regularization is unclear. However, the comment does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a critical issue with the paper, noting that the overall motivation for using characteristic function regularization is unclear. This is an important observation that could impact the paper\"s clarity and impact. However, the comment lacks specificity and does not provide any suggestions or guidance on how the authors might clarify this motivation or improve the explanation. Without actionable feedback or examples, the authors are left without a clear path to address the issue. Therefore, the comment is 3, as it highlights a significant area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the paper for being limited to a combination of existing techniques, suggesting that the contribution is incremental. However, it does not provide any explicit or implicit actions for the authors to take to improve their draft. There is no guidance on how to enhance the originality or novelty of the work, nor are there suggestions for potential areas of improvement or additional contributions. As a result, the comment lacks any actionable advice, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment critiques the paper for being limited to a combination of existing techniques, specifically mentioning the adaptation to an unknown level of corruption (Lykouris et al., 2018), varying variances treated with a weighted version of OFUL (Zhou et al., 2021), and variable decision sets (standard in contextual linear bandits). However, it does not specify which part of the paper these techniques are discussed in, making it weakly grounded. The comment is specific in detailing the existing techniques used and the perceived lack of originality, but it lacks grounding as it does not direct the authors to a specific section. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is limited to a combination of existing techniques, citing specific references (Lykouris et al., 2018; Zhou et al., 2021) for context. This provides a clear basis for the claim, as it references specific works that the paper builds upon. However, the comment lacks detailed analysis or examples of how these techniques are combined, which would strengthen the justification. Overall, the claim is 4, as it provides a solid foundation but could be further supported with more detailed evidence or examples. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment critiques the paper for being limited to a combination of existing techniques, suggesting that the contribution is incremental. It references specific works (Lykouris et al., 2018; Zhou et al., 2021) and mentions the use of standard techniques in contextual linear bandits. While the comment identifies a potential limitation, it does not provide actionable feedback or suggestions for improvement. It lacks depth and does not offer guidance on how the authors might enhance the originality or novelty of their work. As a result, the comment is 3, as it highlights a concern but does not fully support the authors in addressing it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to provide more details about the aggregation operation after \"Integration\" in the main paper. It also suggests acknowledging the structure of other architectures if they are referred to. This feedback is clear and provides specific actions for the authors to take, making it 5. The authors know exactly what needs to be done to address the comment, ensuring a clear path for improvement.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Multiscale modeling,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by requesting clarification on the aggregation operation after \"Integration\" and suggesting the inclusion of more details in the main paper. Additionally, it advises acknowledging the structure of other architectures if they are referred to. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the aggregation operation after \"Integration\" needs further clarification and requests more details in the main paper. It also advises acknowledging the structure of other architectures if they are referred to. However, the comment does not provide specific examples or references to support the claim that the aggregation operation is unclear or how it should be clarified. Without detailed justification or examples, the authors may find it challenging to understand the exact nature of the issue and how to address it. Therefore, the comment is considered 2, as it provides some guidance but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the aggregation operation after \"Integration\" in the context of multiscale modeling. It suggests that the authors provide more details in the main paper and, if referring to other architectures, acknowledge their structure properly. This feedback is clear and actionable, as it directs the authors to clarify a particular aspect of their work and ensures transparency in referencing other architectures. By addressing these points, the authors can enhance the clarity and comprehensiveness of their paper. However, the comment could be more helpful if it provided specific suggestions on how to clarify the aggregation operation or examples of how other architectures are acknowledged. Overall, the comment is 4, as it guides the authors toward improving their draft but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the meaning of \"100 steps\" in the context of a search model comparison. It asks whether this refers to 100 sampled strategies. This comment is explicit in its request for clarification, as it directly asks for an explanation of the term \"100 steps.\" However, it does not provide any guidance on how the authors should address this issue or what specific information should be included in the explanation. While the action is explicit, it lacks concrete details on how to implement the clarification, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Search models comparison 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the meaning of \"100 steps\" and whether it refers to 100 sampled strategies. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the meaning of \"100 steps\" in the context of a search model comparison. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the meaning of \"100 steps\" in the context of a search model comparison. It seeks clarification on whether this refers to 100 sampled strategies. While the comment identifies a potential area of confusion, it does not provide any suggestions or guidance on how the authors might address this issue or clarify the terminology in their draft. The feedback is 3 as it points out a specific area that needs clarification, but it lacks actionable advice or depth, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should repeat the experiments and conduct statistical significance analysis on the numbers to determine whether the improvement over previous methods is statistically significant. This provides a clear and direct action for the authors to take. The comment also specifies that the results in Table 1 and Fig. 5 do not report the mean and standard deviation, which is another actionable point. The reviewer\"s suggestion to reject the paper due to limited novelty and marginal improvement adds a layer of urgency to the feedback. Overall, the comment is 5 as it provides concrete steps for the authors to follow, ensuring they know exactly what actions to take to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1\" and \"Fig. 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the results, namely the lack of reporting of mean and standard deviation, and the difficulty in determining statistical significance. The comment further suggests repeating the experiments and conducting statistical significance analysis, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the improvement over previous methods is small, about 0.2%1%, and suggests that the results in Table 1 and Fig. 5 do not report the mean and standard deviation, making it difficult to determine statistical significance. The reviewer provides a clear and logical reasoning for the claim, noting the limited novelty and marginal improvement. However, the comment could be strengthened by providing specific examples or references to support the claim about the small improvement. Despite this, the reasoning is 4, as it provides a logical basis for the suggestion to repeat the experiments and conduct statistical significance analysis. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the improvement over previous methods is small, about 0.2%1%. It also points out that the results in Table 1 and Fig. 5 do not report the mean and standard deviation, making it difficult to determine statistical significance. The reviewer suggests repeating the experiments and conducting statistical significance analysis to address these issues. This feedback is clear and actionable, providing the authors with specific steps to take to improve their draft. However, the comment could be more helpful by offering suggestions on how to enhance the novelty or significance of the work beyond the limited improvement. Overall, the comment is 4 as it guides the authors toward improving the paper but could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests running experiments on a different benchmark, such as Atari, to evaluate the method\"s generalizability. It provides a clear and concrete action for the authors to take, ensuring that the method is tested on a different domain to verify its applicability. The comment also specifies the reason for this recommendation, which is to assess the method\"s performance with discrete action spaces and highdimensional observations. This level of detail provides the authors with a direct and concrete action to improve their draft, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the evaluation being conducted on a single domain, Meta World, and suggests running experiments on a different benchmark like Atari. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the need for evaluating the method on a different domain and provides a concrete suggestion for a benchmark to use. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation is limited to a single domain, Meta World, and suggests running experiments on a different benchmark like Atari to assess generalizability. The comment provides a logical reasoning for the recommendation, noting that the results may not generalize to other domains. However, it lacks specific examples or references to support the claim that Atari is a commonly used benchmark or that it would provide a better test of the method\"s generalizability. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the suggestion.", "helpfulness_rationale": "The review comment identifies a limitation in the evaluation of the method, noting that it is only tested on a single domain, Meta World. It suggests running experiments on a different benchmark, such as Atari, to assess the method\"s generalizability and applicability to other domains. This feedback is clear and actionable, providing a specific recommendation for improving the evaluation process. By suggesting a commonly used benchmark like Atari, the comment offers a concrete step for the authors to take to enhance the robustness and validity of their results. However, the comment could be more helpful if it included additional suggestions or rationale for why Atari is a suitable benchmark. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their evaluation strategy."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges that the method is presented well and the experiments are good and complete, but it suggests that the paper lacks analysis on what the model does, which could be interesting. However, it does not provide specific guidance on how to conduct this analysis or what aspects of the model should be explored. The comment implies that the authors should consider the feedback or suggestions provided, but it does not specify what those suggestions are. As a result, the action is implicit and somewhat vague, leaving the authors with a general direction but without concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment acknowledges that the method is presented nicely and the experiments are good and complete, but it suggests that the paper lacks analysis on what the model does, which could be interesting. However, it does not specify which part of the paper lacks this analysis or provide examples of what kind of analysis would be beneficial. The comment is 1 as it does not identify a specific section or aspect of the paper being addressed, and it is also not specific in detailing what kind of analysis is missing. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point acknowledges that the method is presented well and the experiments are good and complete, but it suggests that the paper lacks analysis on what the model does, which could be interesting. However, the comment does not provide specific examples or detailed reasoning to support why this analysis is necessary or how it could enhance the paper. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the suggestion, rendering the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges that the method is presented well and the experiments are good and complete, but it points out a missing aspect: analysis on what the model does, which could be interesting. This feedback identifies a specific area for improvement, suggesting that the authors should include an analysis of the model\"s behavior or functionality. However, the comment does not provide detailed guidance on how to conduct this analysis or what specific aspects should be explored. While it highlights a potential enhancement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is 3, as it provides a clear direction for improvement but lacks depth and specificity in its guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the \"approach section\" is missing from the main paper and suggests that the supplementary material should be used more like additional information rather than an extension. The reviewer provides a specific reference to the work by Timothy Nguyen, Zhourong Chen, and Jaehoon Lee, which can guide the authors in understanding the expected format for the approach section. This feedback is clear and provides concrete guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"approach section\" in the main paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the supplementary material should be used more like additional information and not as an extension to the paper. The comment provides a specific reference to the work by Timothy Nguyen, Zhourong Chen, and Jaehoon Lee, which further clarifies the expectation for the approach section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the \"approach section\" is missing from the main paper and suggests that the supplementary material should be used more like additional information rather than an extension. The reviewer provides a specific reference to the work by Timothy Nguyen, Zhourong Chen, and Jaehoon Lee, which supports the claim that the supplementary material should be used appropriately. This provides a clear and specific reference, making the claim 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how the approach section should be structured. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant omission in the main paper, specifically the absence of an \"approach section.\" It highlights that the supplementary material should be used more like additional information and not as an extension to the paper. The reviewer provides a specific reference to the work by Timothy Nguyen, Zhourong Chen, and Jaehoon Lee, which can guide the authors in understanding the expected format for the approach section. This feedback is clear and actionable, offering a concrete suggestion for improvement that can help the authors enhance the structure and clarity of their paper. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the statement in the introduction regarding the biological plausibility of backpropagation, suggesting that it may be too weak. The reviewer provides a counterargument by stating that backpropagation is widely accepted as biologically implausible. However, the comment does not offer any explicit or implicit actions for the authors to take. It lacks guidance on how to address the issue or improve the statement in the introduction. Without specific suggestions or instructions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific statement in the introduction regarding the biological plausibility of backpropagation. It critiques the statement by suggesting that it may be too weak and provides a counterargument that backpropagation is widely accepted as biologically implausible. However, the comment does not specify which part of the introduction this statement is located in, making it weakly grounded. The comment is specific in its critique of the statement but lacks grounding, as the authors cannot confidently determine the exact section being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the statement regarding the biological plausibility of backpropagation is too weak, as it is widely accepted that backpropagation is biologically implausible. The reviewer provides a counterargument by stating that backpropagation is widely accepted as biologically implausible, which is a logical reasoning based on common knowledge. However, the comment could be strengthened by providing specific references or examples to support the claim, which would make it 5. As it stands, the comment is 4, as it provides a logical argument but lacks detailed evidence or references. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential weakness in the introduction, specifically the statement regarding the biological plausibility of backpropagation. It points out that the current phrasing may be too weak, as backpropagation is widely accepted as biologically implausible. This feedback is 3 as it highlights an area where the authors might need to strengthen their argument or provide additional context. However, the comment does not offer specific suggestions or guidance on how to address this issue, such as proposing alternative phrasing or additional evidence to support the claim. While it provides some insight, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a concern about the modulator being heuristically designed, questioning whether there might be scalability issues that require tedious hyperparameter tuning for diverse training data. However, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve the scalability of their modulator. The comment lacks actionable details, such as recommending specific methods or approaches to address the scalability issue. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the modulator being heuristically designed, questioning its scalability and potential need for tedious hyperparameter tuning for diverse training data. However, it does not specify which part of the paper discusses the modulator or its design, making it difficult for the authors to pinpoint the exact section that needs attention. The comment lacks specificity as it does not provide detailed guidance on what aspects of the modulator design or scalability need to be addressed. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a concern about the modulator being heuristically designed, questioning its scalability and potential need for tedious hyperparameter tuning for diverse training data. However, the comment lacks specific examples, references, or detailed reasoning to support the claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the modulator being heuristically designed, questioning its scalability and potential need for tedious hyperparameter tuning for diverse training data. While it identifies a potential issue, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this concern. Without detailed feedback or recommendations, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, the comment is 2, as it highlights an area for improvement but does not offer sufficient direction for the authors to make meaningful changes."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the experiments performed in the paper incorporated a significant amount of domain knowledge into the structure of f_R and f_P, implying that a less informed version of these functions might require an impractical amount of data to learn. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their experiments. It lacks concrete details on what changes could be made to reduce the reliance on domain knowledge or how to ensure that the experiments are more dataefficient. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the adaptability of f_R and f_P over time and the incorporation of domain knowledge in the experiments. However, it does not specify which part of the paper discusses these functions or experiments, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its critique of the reliance on domain knowledge and the potential data requirements for a less informed version of f_R/f_P, but it lacks grounding as it does not explicitly mention the sections being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments performed in the paper incorporated a significant amount of domain knowledge into the structure of f_R and f_P, suggesting that a less informed version of these functions might require an impractical amount of data to learn. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence makes it challenging for the authors to address the feedback effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the experiments, suggesting that the functions f_R and f_P may require a significant amount of domain knowledge to be effective. It implies that a less informed version of these functions might need impractical amounts of data to learn. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this issue or improve their experiments. Without detailed feedback or recommendations, the authors are left without a clear understanding of what changes they could make to enhance their work. Therefore, the comment is 2, as it identifies a potential weakness but does not offer sufficient guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the implications of overparameterization leading to powerful memorization and good generalization performance. It suggests that the necessary conditions for robust memorization might have stronger implications if connected to generalization bounds. However, the comment does not provide explicit guidance on how the authors should address this concern or what specific actions they should take to improve their draft. The suggestion to acknowledge this in the conclusion is implicit and lacks concrete details on how to implement it. As a result, the comment is 3, as it highlights an area for improvement but does not provide clear steps for the authors to follow.", "grounding_specificity_rationale": "The comment addresses a specific concern about the implications of overparameterization on robust memorization and generalization bounds. It mentions the need for stronger connections between necessary conditions and generalization bounds, and questions whether the constructions of ReLU networks for robust memorization would lead to robust generalization. However, the comment does not specify which part of the paper discusses these constructions or where the authors acknowledge the issue in the conclusion. While the authors might have an idea of where these topics are discussed, the comment lacks full grounding as it does not explicitly mention specific sections or elements of the paper. The comment is specific in detailing the concern about the implications of overparameterization, but it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the implications of overparameterization on robust memorization and generalization bounds. It suggests that the necessary conditions for robust memorization might have stronger implications if connected to generalization bounds. The reviewer acknowledges that the authors address this issue in the conclusion but questions whether the constructions of ReLU networks for robust memorization would lead to robust generalization. While the comment highlights a potential gap in the paper, it lacks specific examples or detailed reasoning to fully substantiate the claim. The reference to the conclusion provides some context, but the comment could be strengthened with more explicit evidence or references. Therefore, the claim is 3, as it provides a logical basis but requires further elaboration for full verification.", "helpfulness_rationale": "The review comment raises a critical question about the implications of overparameterization on robust memorization and generalization bounds. It points out that while the authors acknowledge this issue in the conclusion, it is not clear how the constructions of ReLU networks for robust memorization would lead to robust generalization. This feedback is 3 as it identifies a potential gap in the paper and prompts the authors to further explore and clarify the connection between robust memorization and generalization. However, the comment could be more helpful if it provided specific suggestions or examples on how to address this issue or improve the clarity of the connection. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper provides valuable insights for contrastive learning in code search tasks but does not thoroughly explore the implications of their proposed method for other NLP tasks. This limitation is noted as somewhat restricting the generalizability of the results. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this limitation or explore the implications for other NLP tasks. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a limitation in the paper, noting that while it provides valuable insights for contrastive learning in code search tasks, it does not thoroughly explore the implications of the proposed method for other NLP tasks. However, it does not specify which part of the paper this limitation pertains to, such as specific sections or experiments that could be expanded. Additionally, the comment lacks specificity in terms of what aspects of other NLP tasks should be explored or how the generalizability could be improved. As a result, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper provides valuable insights for contrastive learning in code search tasks but does not thoroughly explore the implications of their proposed method for other NLP tasks. This limits the generalizability of the results. However, the comment lacks specific examples or references to other NLP tasks that could be explored, making it difficult for the authors to understand the exact scope of the limitation. The claim is 3 as it highlights a potential gap in the paper, but it requires more detailed justification or examples to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the value of the paper\"s insights for contrastive learning in code search tasks but points out a limitation in the paper\"s scope. It notes that the paper does not thoroughly explore the implications of its proposed method for other NLP tasks, which limits the generalizability of the results. While the comment identifies a potential area for improvement, it lacks specific suggestions or guidance on how the authors might address this limitation or expand their exploration to other NLP tasks. The feedback is 3 as it highlights a gap in the paper\"s scope, but it could be more actionable with additional direction or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the clarity of why the proposed sample selection mechanism helps preserve the label distribution. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve the clarity of their explanation. Without guidance on what specific aspects of the mechanism need further elaboration or how the authors might demonstrate its effectiveness, the comment lacks actionability. The authors are left without a clear path forward to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the clarity of why the proposed sample selection mechanism helps preserve the label distribution. However, it does not specify which part of the paper discusses this mechanism, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in identifying the issue of clarity but lacks grounding as it does not mention a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the clarity of why the proposed sample selection mechanism helps preserve the label distribution. However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific area of concern regarding the clarity of why the proposed sample selection mechanism helps preserve the label distribution. This is a relevant observation that could help the authors improve their explanation or justification of the mechanism. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue. Without actionable advice or examples, the feedback is 3, as it points out a potential weakness but does not fully support the authors in making improvements. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the results and analysis are detailed and comprehensive, but it notes that only two relatively old and small models are evaluated. However, it does not provide any explicit or implicit suggestions for improvement. There is no guidance on whether the authors should evaluate additional models, what types of models should be considered, or how to address the issue of evaluating only a limited number of models. Without actionable advice or specific recommendations, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the evaluation of results and analysis, noting that only two relatively old and small models are evaluated. However, it does not specify which part of the paper this critique pertains to, such as the results section or the discussion of model evaluation. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper being addressed. Additionally, while the comment highlights a specific issue with the models evaluated, it does not provide detailed guidance on how to address this issue or what alternative models should be considered. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the results and analysis are detailed and comprehensive, but it notes that only two relatively old and small models are evaluated. This claim is 3 as it provides a specific critique about the scope of the evaluation, which could be addressed by expanding the model selection. However, the comment lacks detailed reasoning or examples of how this limitation affects the comprehensiveness of the analysis. To fully substantiate the claim, the reviewer could provide additional context or references to support the importance of evaluating a broader range of models. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment points out a limitation in the evaluation of results and analysis, noting that only two relatively old and small models are evaluated. While the comment identifies a specific area for improvement, it lacks depth and does not provide actionable suggestions or guidance on how the authors might address this issue. Without specific recommendations or examples of alternative models or evaluation strategies, the authors are left with a general understanding of the problem but without a clear path to improvement. Therefore, the comment is 3, as it highlights a potential weakness but does not fully support the authors in making meaningful improvements to their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges that KD and LS are not identical but suggests that KD can be viewed as a special form of LS under specific conditions. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this observation or how it might impact the paper. The comment lacks actionable details, leaving the authors without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment discusses the relationship between KD (Knowledge Distillation) and LS (Label Smoothing), suggesting that KD can be viewed as a special form of LS under specific conditions. However, it does not specify which part of the paper this discussion is based on, making it difficult for the authors to identify the exact section being addressed. The comment is specific in its claim about the equivalence of KD and LS under certain conditions, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that KD (Knowledge Distillation) can be viewed as a special form of LS (Label Smoothing) under specific conditions. The reviewer provides a logical reasoning by stating that when the teacher network is uniformly distributed and the temperature is set at 1, KD and LS are equivalent. This reasoning is based on a clear understanding of the concepts and their relationship, which provides a solid foundation for the claim. However, the comment could be strengthened by providing specific examples or references to support the claim further. Overall, the claim is 4, as it provides a logical basis but lacks detailed evidence or references. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment acknowledges that KD (Knowledge Distillation) and LS (Label Smoothing) are not identical but suggests that KD can be viewed as a special form of LS under specific conditions. The reviewer provides a logical reasoning by stating that when the teacher network is uniformly distributed and the temperature is set at 1, KD and LS are equivalent. This observation could be valuable for the authors, as it offers a deeper understanding of the relationship between these two methods. However, the comment lacks actionable suggestions or guidance on how this insight might impact the paper or its presentation. While it provides some insight, it does not fully support the authors in improving their draft. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that more recent works should be included in the paper and that results on largescale datasets, such as ImageNet, should be provided to further verify the effectiveness of the proposed method. This feedback is clear and provides concrete actions for the authors to take, such as updating the literature review and conducting additional experiments on larger datasets. The explicit nature of the suggestions and the concrete steps outlined make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"No.3. 2021,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of more recent works and results on largescale datasets, such as ImageNet, to further verify the effectiveness of the proposed method. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper should include more recent works and results on largescale datasets, such as ImageNet, to further verify the effectiveness of the proposed method. This claim is 3 as it provides a logical reasoning for including more recent works and larger datasets to enhance the paper\"s credibility. However, the comment lacks specific references or examples of recent works or datasets that should be included, which would strengthen the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper. It points out that the dynamicpruning methods mentioned are outdated and suggests including more recent works to keep the literature review current. Additionally, it notes that only results on smallscale datasets are provided and recommends including results on largescale datasets, such as ImageNet, to further verify the effectiveness of the proposed method. This feedback is clear and actionable, providing the authors with specific directions to enhance the comprehensiveness and validity of their work. However, the comment could be more helpful if it offered suggestions on which specific recent works to include or how to conduct experiments on larger datasets. Overall, the comment is 4 as it guides the authors toward improving the paper\"s content and credibility."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks the authors to provide an explanation for the observed performance degradation when using additional information about missing, wrong, or redundant data in the FBN results. This request is clear and direct, giving the authors a specific action to take. The comment provides a concrete direction for the authors to follow, ensuring they know exactly what is expected of them. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the authors are asked to provide an explanation for the performance degradation when using additional information about missing, wrong, or redundant data. This provides clear guidance on what the authors need to address in their paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification, asking the authors to explain why the performance degrades when using additional information about missing, wrong, or redundant data. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area of concern regarding the performance degradation in the FBN results when using additional information about missing, wrong, or redundant data. By asking for an explanation, the comment prompts the authors to address a potential issue in their methodology or results. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might investigate or resolve this issue. To be more helpful, the comment could include questions or suggestions for further analysis or experimentation. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the motivation behind using randomly sampled CIFAR images as backgrounds to make the task harder. It explicitly asks for an explanation of why this particular dimension of difficulty is interesting. This request is clear and direct, providing the authors with a specific action to take: explaining the rationale behind this choice. The feedback is concrete, as it specifies what the authors need to address, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of randomly sampled CIFAR images as backgrounds, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the motivation behind this choice and asks for an explanation of why this particular dimension of difficulty is interesting. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the motivation behind using randomly sampled CIFAR images as backgrounds to make the task harder, suggesting that this choice is not wellmotivated. The comment does not provide any specific reasoning or evidence to support why this particular dimension of difficulty is not wellmotivated, nor does it offer suggestions or examples to help the authors understand the issue. As a result, the claim is 1, as it lacks sufficient justification or evidence to support the critique. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment questions the motivation behind using randomly sampled CIFAR images as backgrounds to make the task harder, suggesting that this choice is not wellmotivated. It asks for an explanation of why this particular dimension of difficulty is interesting, which is a valid point that could help the authors clarify their rationale. However, the comment does not provide specific suggestions or guidance on how to address this issue or improve the paper. While it identifies a potential weakness, it lacks actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a gap in the analysis regarding the flatness of the minima found by the proposed method. It explicitly states that the authors need to provide an analysis on the losses of the noiseinjected models after training to support their claim that the minima found are flat. This feedback is clear and provides a specific action for the authors to take, ensuring they know exactly what needs to be done to address the issue. The comment is explicit and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq (3),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing in the analysis regarding the flatness of the minima and provides a detailed explanation of what is required to support the claim. The comment suggests that the authors need to analyze the losses of the noiseinjected models after training to ensure the flatness of the minima. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of flatness is missing, despite the paper arguing that the proposed method finds flat minima. The reviewer provides a logical reasoning by pointing out that minimizing the averaged loss across noiseinjected models does not ensure the flatness of the minima. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened by referencing specific examples or studies that support the claim about the relationship between averaged loss and flatness. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a critical gap in the analysis of the paper, specifically regarding the flatness of the minima found by the proposed method. It points out that while the paper argues that the method finds flat minima, the analysis on flatness is missing. The comment provides a clear and actionable suggestion by explaining that the authors need to analyze the losses of the noiseinjected models after training to support their claim. This feedback is valuable as it directs the authors to a specific area that requires further investigation and clarification, which can significantly enhance the robustness of their findings. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the text inside the figure and the labels are too small to read without zooming, and it suggests that this text should be roughly the same size as the manuscript text. This feedback provides a clear and direct action for the authors to take, ensuring that the text is legible and consistent with the rest of the manuscript. The comment is explicit and concrete, giving the authors precise guidance on how to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"figure\" and \"labels,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the text being too small and suggests that it should be the same size as the manuscript text. This provides clear guidance on what needs to be addressed to improve the readability of the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the text inside the figure and the labels are too small to read without zooming, and suggests that they should be the same size as the manuscript text. This is a factual observation about the readability of the figure, which does not require any subjective judgment or opinion. It is purely descriptive and does not contain a claim that needs verification. Therefore, the label \"No\" is appropriate.", "helpfulness_rationale": "The review comment identifies a specific issue with the readability of the figures in the paper, noting that the text and labels are too small to be legible without zooming. It provides a clear and actionable suggestion to improve the draft by recommending that the text should be roughly the same size as the manuscript text. This feedback is valuable as it directly addresses a practical issue that could impact the reader\"s experience and understanding of the figures. However, the comment could be more helpful if it included suggestions on how to achieve this adjustment or provided examples of similar figures with legible text. Overall, the comment is 4 as it guides the authors toward a specific improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the motivation of the paper is unclear and recommends revising the introduction to make it easier to follow. However, it does not provide specific guidance on what aspects of the motivation are unclear or how the introduction should be revised. The action is implicit and somewhat vague, as the authors are left to infer what needs to be addressed and how to make the necessary revisions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the motivation of the paper is unclear and recommends revising the introduction to make it easier to follow. However, it does not specify which parts of the introduction are unclear or what aspects of the motivation need clarification. This lack of specificity makes it difficult for the authors to pinpoint the exact areas that need revision. Additionally, the comment does not mention any specific sections or elements of the paper, making it weakly grounded. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the motivation of the paper is unclear, suggesting that the introduction should be revised to make it easier to follow. However, the comment does not provide any specific examples or detailed reasoning to support this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1, as it lacks sufficient evidence or justification.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the motivation is unclear. It suggests that the introduction should be carefully revised to make the paper easier to follow. However, the comment lacks specificity and does not provide detailed guidance on what aspects of the motivation are unclear or how the introduction should be revised. While it highlights an important area for improvement, the feedback is somewhat vague, leaving the authors with a general direction but without concrete steps to take. Therefore, the comment is 3, as it points out a critical issue but does not fully support the authors in addressing it."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the alignment of relabeled reward data with human annotator judgments, suggesting that it is insufficiently validated. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to validate the alignment or what specific steps should be taken to improve the validation process. As a result, the authors are left without a clear understanding of what changes are needed to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the alignment of relabeled reward data with human annotator judgments, suggesting that it is insufficiently validated. However, it does not specify which part of the paper this issue pertains to, such as a specific section or experiment, making it weakly grounded. The comment is specific in identifying the issue of insufficient validation but lacks grounding, as the authors cannot confidently determine which part of the paper this critique relates to. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the alignment of relabeled reward data with human annotator judgments is insufficiently validated. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the alignment of relabeled reward data with human annotator judgments, suggesting that it is insufficiently validated. This is a relevant observation that could impact the credibility and validity of the results. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve the validation process. Without actionable feedback or specific recommendations, the authors are left with a general understanding of the problem but without a clear path to improvement. Therefore, the comment is 3, as it highlights an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the presentation of the model in Section 4 is complicated and requires careful reading, possibly with reference to the supplement. It provides a specific action for the authors to consider, which is to improve the presentation by replacing some of the natural language description with notation and adding breakout diagrams showing the attention mechanisms. This feedback is explicit and provides concrete guidance on how to enhance the clarity of the model presentation, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear suggestions for improving the presentation, such as replacing natural language descriptions with notation and adding breakout diagrams to illustrate attention mechanisms. This level of detail guides the authors on what changes to make to enhance the clarity of the model presentation. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the model presentation in Section 4 is complicated and requires careful reading, possibly with reference to the supplement. It provides a specific suggestion to improve the presentation by replacing natural language descriptions with notation and adding breakout diagrams to illustrate attention mechanisms. While the comment offers a logical reasoning for the complexity and suggests a potential solution, it lacks specific examples or references to support the claim. This makes the claim 3, as the authors would need to infer the exact improvements needed based on the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of the model in Section 4, noting that it is somewhat complicated and requires careful reading. It suggests that the authors could improve this presentation by replacing natural language descriptions with notation and adding breakout diagrams to illustrate attention mechanisms. This feedback is clear and actionable, providing the authors with a concrete way to enhance the clarity and accessibility of their work. However, the comment could be more helpful if it included additional suggestions or examples of how to effectively use notation and diagrams. Overall, the comment is 4 as it offers valuable guidance for improving the draft, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the paper, noting that it only conducts experiments on a limited number of molecules and provides indistribution testing for these samples. The reviewer suggests that the method\"s value would be limited if it requires training for each molecule individually. However, the comment does not provide explicit guidance or suggestions on how the authors might address this limitation or improve the generalizability of their method. The action is implicit and vague, as the authors are left to infer that they should expand their experiments to a broader range of molecules or improve the generalizability of their method. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment highlights a limitation in the paper, noting that it only conducts experiments on a limited number of molecules and provides indistribution testing for these samples. However, it does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The comment is specific in identifying the issue of limited generalizability and the need for broader testing, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper\"s value is limited due to its focus on a limited number of molecules and indistribution testing. However, the comment lacks specific examples or references to support this claim. It does not provide detailed reasoning or evidence to substantiate why the method\"s value would be limited or how it could be improved. Without additional context or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, noting that it only conducts experiments on a limited number of molecules and provides indistribution testing for these samples. The reviewer suggests that the method\"s value would be limited if it requires training for each molecule individually. This feedback is 3 as it points out a potential weakness in the generalizability of the method. However, it lacks specific suggestions or guidance on how the authors might address this limitation or expand their experiments to a broader range of molecules. To be more helpful, the comment could include recommendations on how to improve the generalizability or provide examples of how other methods have addressed similar issues. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment states that the symbols are complicated and take time to understand, but it does not provide any explicit or implicit actions for the authors to take. It lacks specific suggestions or guidance on how to simplify or clarify the symbols, leaving the authors without a clear understanding of what changes are needed. Without actionable advice or concrete steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions that symbols are complicated and take time to understand, but it does not specify which symbols or parts of the paper are being referred to. This lack of explicit reference makes it difficult for the authors to identify the exact sections that need attention. Additionally, the comment does not provide specific details on what aspects of the symbols are confusing or how they could be simplified. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the symbols are complicated and take time to understand. However, it does not provide any specific examples, reasoning, or references to support this claim. Without detailed explanation or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment indicates that the symbols used in the paper are complicated and take time to understand. However, it lacks specificity and does not provide any actionable feedback or suggestions on how to simplify or clarify the symbols. Without detailed guidance or examples, the authors are left without a clear understanding of what changes are needed to improve the clarity of their symbols. This lack of actionable feedback makes the comment unhelpful, as it does not offer any meaningful direction for improvement. Therefore, it aligns with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly questions the understanding of the red line in Figure 3, asking where the test data comes from and whether there is a ground truth. This provides a clear and direct action for the authors to take: they need to clarify the source of the test data and whether a ground truth exists. The comment is explicit and provides concrete guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by questioning the understanding of the red line and asking about the source of the test data and the existence of a ground truth. This provides clear guidance on what needs to be clarified or addressed in the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the red line in Figure 3, specifically asking where the test data comes from and whether there is a ground truth. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area of confusion in the paper, namely the red line in Figure 3. It raises questions about the source of the test data and the existence of a ground truth, which could be clarified by the authors. However, the comment does not provide any suggestions or guidance on how to address these questions or improve the clarity of the figure. While it points out a potential issue, it lacks depth and actionable advice, making it 3 but incomplete."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It suggests that adding periodicity to the spectral kernel might be enough to allow it to capture all of the results at a similar level to the explicitly compositional model. While the comment implies that the authors should consider this aspect, it does not explicitly instruct them to conduct additional experiments or analyses to address the question. The action is implicit and somewhat vague, as it lacks specific guidance on how to proceed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It specifically mentions the comparison model, which cannot capture periodic relationships, and questions whether adding periodicity to the spectral kernel would allow it to capture all of the results at a similar level to the explicitly compositional model. However, the comment does not explicitly mention which part of the paper this question pertains to, such as specific sections or experiments. While the authors might infer that it relates to the results or methodology sections, the lack of explicit grounding makes it difficult to pinpoint the exact part of the paper being addressed. The comment is specific in its questioning of the results, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point raises a question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It suggests that the comparison model, which cannot capture periodic relationships, may not be able to replicate the results. The comment questions whether adding periodicity to the spectral kernel would be sufficient to capture all of the results. While the comment provides a logical reasoning for questioning the results, it lacks specific examples or references to support the claim. This makes the claim 3, as it requires further elaboration or evidence to fully substantiate the question. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises an interesting question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It points out that the comparison model cannot capture periodic relationships, and in most experiments, the relationships involve periodicity. The comment suggests that adding periodicity to the spectral kernel might be enough to allow it to capture all of these results at a similar level to the explicitly compositional model. This feedback is 3 as it prompts the authors to consider the role of periodicity in their results and potentially explore its impact on the model\"s performance. However, the comment could be more helpful if it provided specific suggestions or examples on how to address this question or conduct further analysis. Overall, the comment offers a valuable insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment indicates that the paper is not wellwritten and suggests that it was possibly written in a hurry, making it difficult to read. It also mentions that there is a lot desired in terms of presentation and formatting, particularly in figures and tables. However, the comment does not provide specific guidance on how to improve the writing, presentation, or formatting. It lacks actionable details such as suggesting ways to enhance clarity, structure, or visual appeal. As a result, the authors are left without a clear understanding of what changes to make to improve the draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment provides a general observation about the paper being \"not very wellwritten\" and suggests that it was possibly written in a hurry, making it difficult to read. It also mentions that there is a lot desired in terms of presentation and formatting, particularly in figures and tables. However, the comment does not specify which parts of the paper are particularly problematic or what specific issues need to be addressed. Without detailed guidance or examples, the authors cannot confidently determine which sections require improvement or how to address the issues mentioned. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is not wellwritten and suggests it was possibly written in a hurry, making it difficult to read. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to substantiate the assertion about the writing quality or the impact of a hurried writing process. Without such support, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that the paper is not wellwritten and possibly written in a hurry, making it difficult to read. It also mentions that there is a lot desired in terms of presentation and formatting, particularly in figures and tables. However, the comment lacks specificity and does not provide actionable feedback or suggestions on how to improve the writing, presentation, or formatting. Without detailed guidance or examples, the authors are left without a clear understanding of what changes to make to enhance the readability and presentation of their work. Therefore, the comment is 2, as it identifies a general issue but does not offer meaningful guidance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the introduction to orthogonality in Part 2 could be more detailed. However, it does not provide specific guidance on what aspects of the introduction should be expanded or how to improve the detail. The action is implicit, as the authors can infer that they need to add more detail, but it is vague because it lacks concrete instructions on what specific details to include. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the introduction to orthogonality in Part 2 could be more detailed. However, it does not specify which part of the introduction is lacking in detail or what specific aspects need to be expanded. This makes it difficult for the authors to pinpoint the exact areas that need improvement. Additionally, the comment lacks specificity regarding what kind of detail is needed or how it could be improved. As a result, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the introduction to orthogonality in Part 2 could be more detailed. However, it does not provide any specific examples or reasoning to support why this is necessary or how the introduction could be improved. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The comment identifies a specific area for improvement in the paper, suggesting that the introduction to orthogonality in Part 2 could be more detailed. This feedback is 3 as it points out a potential weakness in the paper and encourages the authors to enhance the clarity and depth of their introduction. However, the comment lacks specificity and does not provide detailed guidance on what aspects of the introduction should be expanded or how to improve the detail. To be more helpful, the comment could include suggestions or examples of what additional information could be included. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the paper\"s main contribution, suggesting that it may not be novel given prior work on samplewise multiple descent in linear regression. The reviewer recommends that the paper should better highlight its novelty in relation to prior results. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific ways to highlight the novelty. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the novelty of their results but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the novelty of the paper\"s main contribution in relation to prior work on samplewise multiple descent in linear regression. However, it does not specify which part of the paper discusses this contribution, making it weakly grounded. The comment is specific in its suggestion to better highlight the novelty of the result in relation to prior results, but it lacks explicit references to specific sections or elements of the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the main contribution of the paper is the result that optimal regularization can remove double descent in certain anisotropic settings, given that prior work has already shown samplewise multiple descent in linear regression. The reviewer acknowledges that they are not familiar with the particular techniques and tools used in the paper, but suggests that the claims seem correct. However, the comment lacks specific references or detailed reasoning to support the claim about the novelty of the paper\"s contribution. This makes the claim 3, as it provides some justification but lacks comprehensive evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s main contribution, suggesting that it may not be novel given prior work on samplewise multiple descent in linear regression. It recommends that the paper should better highlight its novelty in relation to prior results. While the comment points out a critical area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue or enhance their discussion of novelty. The feedback is 3 as it prompts the authors to consider the novelty of their results, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the proposed methods, contrastive training objective and contrastive search, are independent and lack an inner connection in terms of intuition and algorithm. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting ways to establish a connection between the methods or improve their integration. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the proposed methods, specifically mentioning \"contrastive training objective\" and \"contrastive search.\" However, it does not specify which part of the paper these methods are discussed in, making it weakly grounded. The comment is specific in pointing out the lack of inner connection between these methods in terms of intuition and algorithm. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed methods, contrastive training objective and contrastive search, are independent and lack an inner connection in terms of intuition and algorithm. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that the proposed methods, contrastive training objective and contrastive search, are independent and lack an inner connection in terms of intuition and algorithm. This observation highlights a potential weakness in the paper, suggesting that the authors may need to clarify or strengthen the connection between these methods. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as proposing ways to integrate the methods or explaining their relationship. While it identifies a relevant area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the goal of the paper and the lack of comparison or justification for the proposed method. It suggests that if the paper claims to be a foundation model, it should be clearer and should demonstrate or justify a future useful application. While the comment implies that the authors should clarify the paper\"s goal and provide comparisons or justifications, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the paper\"s goal and provide comparisons or justifications. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the goal of the paper and references a specific earthquake detector, \"PhaseNetDas,\" by Zhu et al. (2023), which the authors cited. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue with the paper\"s goal, namely the lack of comparison or justification for the proposed method, and suggests that if the paper claims to be a foundation model, it should demonstrate or justify a future useful application. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the paper\"s goal and the lack of comparison or justification for the proposed method. It suggests that if the paper claims to be a foundation model, it should demonstrate or justify a future useful application. The comment references a specific earthquake detector, \"PhaseNetDas,\" by Zhu et al. (2023), which the authors cited, providing some context. However, the comment lacks detailed reasoning or examples to fully substantiate the claim that the paper\"s goal is unclear or that comparisons are necessary. While it provides some basis for the claim, it is not 5 due to the lack of specific evidence or detailed justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s goal and the lack of comparison or justification for the proposed method. It points out that while earthquake detectors like \"PhaseNetDas\" exist, the paper does not compare or justify its method against these existing detectors. If the paper claims to be a foundation model, it should be clearer and demonstrate or justify a future useful application. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their draft by clarifying the paper\"s goal and demonstrating the benefits of their method. However, it could be more helpful if it offered suggestions on how to conduct comparisons or provide justifications. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the limitation of using triplets (or a sliding window of length 3) and asks whether this is a fundamental limitation of the approach or if extending to longer subsequences without a sliding window is straightforward. While the comment implies that the authors should consider the limitations of their approach and potentially explore extensions, it does not provide explicit guidance or suggestions on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should consider the limitations and potential extensions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the limitation of using triplets (or a sliding window of length 3) and asks whether this is a fundamental limitation of the approach or if extending to longer subsequences without a sliding window is straightforward. However, it does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The comment is specific in its inquiry about the limitation and potential extensions, but without clear grounding, the authors may struggle to identify the exact section being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the limitation of using triplets (or a sliding window of length 3) and asks whether this is a fundamental limitation of the approach or if extending to longer subsequences without a sliding window is straightforward. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this limitation is significant or how it might impact the approach. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the limitation of using triplets (or a sliding window of length 3) and asks whether this is a fundamental limitation of the approach or if extending to longer subsequences without a sliding window is straightforward. This is a relevant question that prompts the authors to consider the limitations of their approach and potentially explore extensions. However, the comment does not provide specific guidance or suggestions on how to address this limitation or how to extend the approach. While it identifies an area for potential improvement, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about whether it would make sense to include and learn AccNet as part of a larger predictor, such as for semantic segmentation, that uses similar operators. While the comment implies that the authors should consider this possibility, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to incorporate AccNet into a larger predictor or what specific aspects of the larger predictor should be considered. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 126,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether it would make sense to include and learn AccNet as part of a larger predictor, such as for semantic segmentation, that uses similar operators. This provides clear guidance on what the authors should consider, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a question about whether it would make sense to include and learn AccNet as part of a larger predictor, such as for semantic segmentation, that uses similar operators. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification or an inquiry, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the potential inclusion of AccNet as part of a larger predictor, such as for semantic segmentation, that uses similar operators. This is a thoughtful inquiry that prompts the authors to consider the broader applicability of their work and its potential integration into other contexts. However, the comment lacks specific guidance or suggestions on how to explore this possibility or what aspects of the larger predictor should be considered. While it provides a valuable idea for the authors to consider, it does not offer actionable steps or detailed feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights that the new proposed metric is only tested on a single dataset, which is a limitation. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue. There is no guidance on whether the authors should test the metric on additional datasets, how they might do so, or what specific datasets would be appropriate. Without any actionable advice or concrete steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a limitation in the paper, noting that the new proposed metric is only tested on a single dataset. However, it does not specify which part of the paper this limitation is discussed in, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the metric or dataset testing are problematic. Without clear guidance on where to address the issue or what specific concerns need to be addressed, the authors are left without a clear understanding of how to improve their work. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the new proposed metric is only tested on a single dataset, which is a limitation. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment points out a limitation in the paper, noting that the new proposed metric is only tested on a single dataset. This is a relevant observation that highlights a potential weakness in the study\"s generalizability and applicability. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve the testing of their metric on multiple datasets. Without actionable feedback or specific recommendations, the authors are left without a clear path to enhance their work. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the first three paragraphs of Section 2 need to be clarified to spell out the setting more clearly. It implies that the authors may be claiming credit for a more general approach than what is actually presented, which muddles the exposition. However, the comment does not provide specific guidance on how to clarify the setting or what aspects need to be addressed. The action is implicit and somewhat vague, as the authors are left to infer what changes are needed without concrete instructions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first three paragraphs of Section 2, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the exposition, suggesting that the setting needs to be clarified to avoid misleading the reader about the generality of the work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the first three paragraphs of Section 2 need to be clarified to spell out the setting more clearly. It suggests that the authors may be claiming credit for a more general approach than what is presented, which muddles the exposition. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand and address the issue. The lack of detailed justification or references makes the claim 3, as it requires the authors to infer the exact nature of the problem and how to resolve it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the exposition in the first three paragraphs of Section 2, suggesting that the setting needs to be clarified to avoid misleading the reader about the generality of the work. This feedback is clear and actionable, as it directs the authors to improve the clarity and accuracy of their presentation. However, the comment could be more helpful if it provided specific suggestions on how to clarify the setting or examples of what needs to be addressed. Overall, the comment is 4 as it points out a critical area for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the experiments, specifically questioning the choice of the old baseline and suggesting that the proposed method should be tested on newer 3D CNNs like X3D and SlowFast. The reviewer also asks for a comparison with these approaches to highlight the advantages of the proposed method. While the comment implies that the authors should test their method on these newer approaches and provide a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional experiments and comparisons. However, the comment provides a clear direction for improvement, making it 4.", "grounding_specificity_rationale": "The comment addresses the experiments, specifically questioning the choice of the old baseline and suggesting that the authors should test their method on newer 3D CNNs like X3D and SlowFast. It also asks for a comparison with these approaches to highlight the advantages of the proposed method. However, the comment does not explicitly mention which part of the paper discusses the experiments, making it weakly grounded. The authors can infer that it relates to the experimental section, but the lack of explicit reference makes it challenging to pinpoint the exact part of the paper being addressed. The comment is specific in detailing what needs to be addressed, such as testing on newer 3D CNNs and comparing with existing approaches. Therefore, this comment is weakly grounded but specific, aligning with the label 3.", "verifiability_rationale": "The review point questions the validity of the experiments by suggesting that the choice of the old baseline, such as R3D and C3D, may not be sufficient. It proposes that newer 3D CNNs like X3D and SlowFast should be considered to reduce computation complexity. The reviewer also asks for a comparison with these newer approaches to highlight the advantages of the proposed method. While the comment raises valid concerns about the experimental setup, it lacks specific examples or references to support the claim that newer approaches are more effective. This makes the claim 3, as it provides a logical basis for improvement but requires more detailed evidence or examples to fully substantiate the critique.", "helpfulness_rationale": "The review comment raises a valid concern about the experiments, specifically questioning the choice of the old baseline and suggesting that newer 3D CNNs like X3D and SlowFast should be considered to reduce computation complexity. It also asks for a comparison with these newer approaches to highlight the advantages of the proposed method. This feedback is clear and actionable, as it prompts the authors to consider expanding their experiments to include more recent and relevant approaches. By addressing these points, the authors can enhance the credibility and comprehensiveness of their experimental results. However, the comment could be more helpful if it provided specific suggestions on how to conduct these comparisons or what aspects to focus on. Overall, the comment is 4, as it directs the authors to improve their experimental setup and analysis."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises two specific concerns: the need for clarification on the precise bitrate range used for BDrate comparison and the suggestion to discuss or compare the proposed method with a related work on content adaptive algorithms in learned video compression. The reviewer provides a specific reference for the related work, which is a concrete suggestion for the authors to consider. However, the comment does not explicitly instruct the authors to include this discussion or comparison, leaving it as an implicit action. While the authors can infer that they should address these points, the lack of explicit guidance makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed method\" and the \"BDrate comparison,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a concern about the performance of the proposed method at different bitrates and suggests a related work for discussion or comparison. The comment provides a clear direction for the authors to address these issues, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises two claims: first, it suggests that the proposed method performs better at high bitrates but is close to baseline performance at low bitrates, and second, it recommends discussing or comparing the proposed method with a related work on content adaptive algorithms in learned video compression. The first claim is 3 as it provides a general observation about the method\"s performance at different bitrates, but it lacks specific data or examples to fully substantiate the claim. The second claim is 4 as it suggests a specific reference for comparison, which provides a clear direction for the authors to consider. However, the comment could be strengthened by providing more detailed reasoning or examples to fully support the first claim. Therefore, the overall comment is rated as 3.", "helpfulness_rationale": "The review comment provides two specific pieces of feedback that can be helpful for the authors. First, it points out a potential weakness in the performance of the proposed method at different bitrates, suggesting that it performs better at high bitrates but is close to baseline performance at low bitrates. This observation prompts the authors to consider and address this issue in their analysis. Second, the comment suggests discussing or comparing the proposed method with a related work on content adaptive algorithms in learned video compression, which could provide valuable insights and context for the authors. However, the comment could be more helpful if it included specific suggestions on how to incorporate this comparison or addressed potential challenges in doing so. Overall, the feedback is 4 as it identifies areas for improvement and provides a direction for further exploration, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should distinguish the \"allornothing\" or \"cutoff\" phenomenon from the usual statistical bounds that the machine learning and NeurIPS community is familiar with. While the comment implies that the authors should clarify this distinction, it does not provide specific guidance on how to make this distinction or what aspects of the paper need to be revised to achieve this. The action is implicit and somewhat vague, as the authors are left to infer the necessary changes without detailed instructions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should distinguish the \"allornothing\" or \"cutoff\" phenomenon from the usual statistical bounds that the machine learning and NeurIPS community is familiar with. However, it does not specify which part of the paper this distinction should be made in, nor does it provide details on how to make this distinction. Without explicit references to sections or examples, the authors cannot confidently determine where to address this feedback. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the authors should distinguish the \"allornothing\" or \"cutoff\" phenomenon from the usual statistical bounds that the machine learning and NeurIPS community is familiar with. However, the comment does not provide any supporting evidence, reasoning, or references to explain why this distinction is important or how it would benefit the paper. Without additional context or justification, the claim remains vague and 1, leaving the authors without a clear understanding of the issue or how to address it. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The comment suggests that the authors should distinguish the \"allornothing\" or \"cutoff\" phenomenon from the usual statistical bounds that the machine learning and NeurIPS community is familiar with. While it identifies a potential area for clarification, the comment lacks specificity and does not provide detailed guidance on how to make this distinction or what aspects of the paper need to be revised. The feedback is 3 as it points out a potential area for improvement, but it could be more actionable with additional details or examples. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point critiques the marginal improvements on three tasks over previous works and selfimplemented baselines, suggesting that further analysis beyond the main experiments is insufficient. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or what specific analyses should be conducted. The comment lacks actionable details, leaving the authors uncertain about how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the marginal improvements on three tasks over previous works and selfimplemented baselines, suggesting that further analysis beyond the main experiments is insufficient. However, it does not specify which parts of the paper these tasks or baselines are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. Additionally, the comment lacks specificity regarding what kind of further analysis is needed or how the authors could improve their analysis. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the improvements on three tasks over previous works and selfimplemented baselines are marginal, and further analysis beyond the main experiments is insufficient. However, the comment does not provide specific examples, detailed comparisons, or references to support this claim. Without concrete evidence or detailed reasoning, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that the improvements on three tasks over previous works and selfimplemented baselines are marginal, suggesting that further analysis beyond the main experiments is necessary. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this issue or conduct additional analysis. Without detailed feedback or examples, the authors are left without a clear understanding of what changes or improvements are needed to enhance their work. Therefore, the comment is 2, as it identifies a potential area for improvement but does not offer sufficient guidance to be actionable."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two main issues: the strong requirement of Gaussian features and noise for the theoretical result, and the lack of comparison with existing rates in the literature. While the comment identifies these as areas for improvement, it does not provide explicit instructions on how to address them. The authors are left to infer that they should relax the Gaussian assumption and conduct a comparison with existing rates, but the comment lacks concrete guidance on how to achieve these improvements. Therefore, the comment is 3, as it points out areas for improvement but does not provide detailed steps for execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"main (and only) theoretical result\" and the \"proposed algorithm,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the theoretical result, namely the strong requirement of Gaussian features and noise, and suggests comparing the rates achieved by the procedure with existing rates in the literature. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point claims that the main theoretical result in the paper provides utility guarantees only when the features and noise are Gaussian, which is a strong requirement on the data. It also suggests comparing the rates achieved by the procedure to existing rates in the literature. The comment provides a logical reasoning by pointing out the limitations of the theoretical result and the need for comparison with existing work. However, it lacks specific references or examples of previous algorithms that do not require this assumption, which would strengthen the claim. Therefore, the comment is 4, as it provides a clear rationale but could be further supported with additional evidence or references.", "helpfulness_rationale": "The review comment identifies a significant limitation in the paper, specifically the strong requirement of Gaussian features and noise for the theoretical result. It points out that this assumption is a strong constraint on the data, especially given that previous algorithms do not require it. Additionally, the comment suggests that the authors should compare the rates achieved by their procedure to existing rates in the literature, which would provide a more comprehensive evaluation of the algorithm\"s performance. This feedback is clear and actionable, as it highlights a critical area for improvement and offers a specific suggestion for enhancing the paper. However, it could be more helpful if it provided examples of previous algorithms that do not require this assumption or detailed guidance on how to conduct the rate comparison. Overall, the comment is 4, as it effectively guides the authors toward improving the theoretical foundation and evaluation of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that it would be beneficial to compare the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. This comment implies that the authors should include a comparison with the original approach, but it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to conduct the comparison or what aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests comparing the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. However, it does not specify which part of the paper this comparison should be included in, such as a specific section or analysis. This makes it weakly grounded, as the authors cannot confidently determine where to make these additions. The comment is specific in suggesting a comparison with the original approach, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it would be beneficial to compare the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. This claim is 3 as it provides a logical suggestion for enhancing the paper by comparing the proposed extension with a relevant prior work. However, the comment lacks specific details or references to the original approach, which would strengthen the justification for the comparison. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests a specific comparison that could be made to enhance the paper, namely comparing the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. This feedback is clear and actionable, as it provides a concrete suggestion for improving the draft by adding a relevant comparison. However, the comment could be more helpful if it explained why this comparison is important or how it would contribute to the paper\"s overall impact. Despite this, the suggestion is valuable and provides the authors with a clear direction for enhancing their work. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should add more experiments to demonstrate the effectiveness of their proposed method. It explicitly states that the authors should include additional baselines, specifically mentioning three works that focus on similar questions. This provides a clear and concrete action for the authors to take, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding more experiments to demonstrate the effectiveness of the proposed method, and it provides specific examples of works that focus on similar questions. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors should add more experiments to demonstrate the effectiveness of their proposed method. It provides specific examples of works that focus on similar questions, which is a clear and logical basis for the suggestion. However, the comment does not include detailed reasoning or references to these specific works, which would strengthen the justification. Therefore, the claim is 4, as it provides a solid foundation but lacks comprehensive evidence or references. This aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a specific weakness in the experimental section, noting that the authors have only compared their work with two baselines. It suggests that more experiments should be conducted to demonstrate the effectiveness of the proposed method, particularly by including additional baselines that focus on similar questions. This feedback is clear and actionable, providing the authors with a specific direction for improving their experimental setup. However, the comment could be more helpful if it included suggestions on which specific baselines to consider or how to structure the additional experiments. Overall, the comment is 4 as it guides the authors toward enhancing the robustness and comprehensiveness of their experimental evaluation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that the authors should present the average results on the test set with clearly defined error bars under different random seeds. This is a direct and concrete action that the authors can take to improve the credibility of their results. The comment provides specific guidance on what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Tables 1 and 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: presenting average results on the test set with clearly defined error bars under different random seeds. This provides clear guidance on how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the reported results on the dev set are insufficient for convincing the reader. The reviewer suggests presenting average results on the test set with clearly defined error bars under different random seeds. This claim is 3 as it provides a logical reasoning for why the current presentation of results is insufficient. However, the comment lacks specific examples or references to support the claim, such as comparisons with similar studies or detailed explanations of why the current approach is not convincing. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the presentation of results in Tables 1 and 2, where the authors report the best results on the dev set with hyperparameter search and model selection on the dev set. The reviewer suggests that this is insufficient for convincing the reader and strongly recommends presenting average results on the test set with clearly defined error bars under different random seeds. This feedback is clear and actionable, providing the authors with a specific direction to improve the credibility and robustness of their results. By addressing this feedback, the authors can enhance the transparency and reliability of their findings, making the comment 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should provide more values of alpha, specifically recommending 1e2 and 1e3, to improve the ablation study. This feedback is clear and provides concrete guidance on what the authors need to do to enhance their draft. The action is direct and specific, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 5.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the ablation study, namely the insufficient range of values for alpha (1e4, 1e1, 5e1) and recommends adding more values, such as 1e2 and 1e3. This provides clear guidance on what needs to be addressed to improve the study. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the ablation study on alpha is insufficient because it only considers a limited range of values (1e4, 1e1, 5e1). The reviewer recommends providing more values, such as 1e2 and 1e3, to improve the study. This claim is 3 as it highlights a specific gap in the study and suggests a way to address it. However, the comment lacks detailed reasoning or references to support why these additional values are necessary or how they would impact the study. Providing more context or examples would strengthen the justification, making the claim more verifiable. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the ablation study on alpha, noting that the range of values tested is insufficient. It suggests that the authors should provide more values, such as 1e2 and 1e3, to better understand the impact of alpha on the model. This feedback is clear and actionable, providing the authors with a concrete suggestion to enhance their study. By addressing this point, the authors can improve the robustness and comprehensiveness of their analysis. Therefore, the comment is rated as 4, as it offers valuable guidance for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about the methodology and dataset used in the paper. It asks for specific details regarding the number of topics used, the method for obtaining topicword parameters, the size of the AG news dataset, and the number of documents and vocabulary words in the training and testing sets. While these questions are explicit, they do not provide concrete guidance on how the authors should address them or what specific information should be included in the main paper. The authors are left with a clear understanding of what information is needed but without detailed instructions on how to present it. Therefore, the comment is 3, as it identifies specific areas for clarification but lacks detailed guidance on implementation.", "grounding_specificity_rationale": "The comment raises several questions about the methodology and dataset used in the paper, specifically asking for details on the number of topics used, the method for obtaining topicword parameters, the size of the AG news dataset, and the number of documents and vocabulary words in the training and testing sets. While the comment does not explicitly mention specific sections of the paper, the authors can infer that these questions pertain to the methodology and dataset sections. The questions are specific, as they request detailed information about the dataset and its parameters. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point consists of a series of questions seeking clarification on specific aspects of the methodology and dataset used in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and seek information that would help the authors clarify their work. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises several important questions about the methodology and dataset used in the paper. It asks for specific details regarding the number of topics used, the method for obtaining topicword parameters, the size of the AG news dataset, and the number of documents and vocabulary words in the training and testing sets. These questions are relevant and could help the authors clarify and improve the transparency of their work. However, the comment does not provide specific suggestions or guidance on how to address these questions or improve the paper. While it identifies areas that need clarification, it lacks actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment expresses a personal preference regarding the focus of the paper, suggesting that the zeroshot version and the connection to density estimation are distracting from the main point. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this perceived distraction or how to better align the paper with the reviewer\"s preference. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses a personal preference regarding the focus of the paper, suggesting that the zeroshot version and the connection to density estimation are distracting from the main point. However, it does not specify which part of the paper these elements are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. Additionally, the comment lacks specificity regarding what aspects of these elements are distracting or how they could be better integrated into the main focus. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses a subjective opinion about the focus of the paper, suggesting that the zeroshot version and the connection to density estimation are distracting from the main point. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why these aspects are distracting or how they could be better integrated. Without specific details or references, the claim lacks verifiability, making it difficult for the authors to understand and address the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses a personal preference regarding the focus of the paper, suggesting that the zeroshot version and the connection to density estimation are distracting from the main point. However, the comment does not provide any actionable feedback or suggestions for improvement. It lacks specificity and does not offer guidance on how the authors might better align their work with the reviewer\"s preference. Without actionable advice or constructive criticism, the comment does not help the authors in improving their draft. Therefore, it is rated as 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that more information is needed on the filtering process used to create the Arabic climate change QA dataset, specifically regarding the translation and filtering methodology. This provides a clear action for the authors to take, which is to provide additional details on these aspects. The comment is explicit and concrete, as it specifies exactly what information is missing and how the authors can address it. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"filtering process\" used to create the Arabic climate change QA dataset, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is lacking, namely more information on the translation and filtering methodology, which is necessary to assess the dataset quality. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the details around the filtering process used to create the Arabic climate change QA dataset are lacking, specifically regarding the translation and filtering methodology. This claim is 3 as it highlights a potential gap in the paper, but it lacks specific examples or references to support the assertion. The authors would need to provide additional information to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks detail, namely the filtering process used to create the Arabic climate change QA dataset. It highlights the need for more information on the translation and filtering methodology, which is crucial for assessing the dataset quality. This feedback is clear and actionable, as it directs the authors to provide additional details that could significantly enhance the comprehensiveness and credibility of their dataset. However, the comment could be more helpful if it offered suggestions on how to present this information or what specific aspects to focus on. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the experiment results could be enriched by including attacks with different strengths and by exploring how different thresholds influence detection performance. While the comment implies that the authors should expand their experiments to include these aspects, it does not provide specific guidance on how to implement these changes or what specific attacks or thresholds to consider. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experiment results could be enriched by including attacks with different strengths and exploring how different thresholds influence detection performance. However, it does not specify which part of the paper this feedback pertains to, such as a specific section or experiment. This lack of explicit reference makes it difficult for the authors to pinpoint the exact areas needing improvement. While the comment is specific in suggesting what could be added, it is 1 because it does not indicate where these additions should be made. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the experiment results could be enriched by including attacks with different strengths and exploring how different thresholds influence detection performance. However, the comment does not provide specific examples, references, or detailed reasoning to support why these additions would be beneficial or how they would enhance the study. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2, as it lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the experimental results, suggesting that the authors should enrich their experiments by including attacks with different strengths and exploring how different thresholds influence detection performance. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their study by expanding their experimental scope. However, the comment could be more helpful if it offered specific examples of attacks or thresholds to consider, which would provide even more guidance for the authors. Overall, the comment is 4 as it directs the authors to a meaningful area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that to evaluate the claim of reducing exposure bias, the authors should train a discriminator on generations from the learned model, similar to Figure 1. It also notes that this is different from Figure 4, as the discriminator is coadapting with the generator during training. While the comment implies an action, it does not provide explicit instructions on how to implement this evaluation or what specific steps to take. The authors can infer that they need to conduct this evaluation, but the lack of concrete guidance makes the action somewhat vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"Figure 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that training a discriminator on generations from the learned model is needed to evaluate the claim of reducing exposure bias. The comment provides a clear direction for the authors to address the evaluation aspect of their work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that to evaluate the claim of reducing exposure bias, the authors should train a discriminator on generations from the learned model, similar to Figure 1. It notes that this is different from Figure 4, as the discriminator is coadapting with the generator during training. The comment provides a logical reasoning for the evaluation process, suggesting a specific method to confirm the claim. However, it lacks detailed examples or references to support the claim or the reasoning fully. Therefore, the comment is 3, as it provides a clear direction but requires more detailed justification or examples to be 5.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for evaluating the claim of reducing exposure bias. It recommends training a discriminator on generations from the learned model, similar to Figure 1, to confirm the claim. This feedback is specific and offers a concrete method for the authors to validate their work, which is highly beneficial. However, the comment could be more helpful if it explained why this evaluation method is necessary or how it differs from Figure 4, as mentioned. Overall, the comment is 5 as it empowers the authors to improve their draft by providing a clear direction for evaluation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide information on how much performance difference using different image sizes and different variations of ResNets can lead to. This is an explicit request for additional data or analysis, but it does not specify how the authors should go about obtaining this information or what specific metrics or methods to use. While the action is clear, the lack of detailed guidance makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions line number 170, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing: information on how much performance difference using different image sizes and different variations of ResNets can lead to. This provides clear guidance on what the authors need to address in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification, asking for more information on how much performance difference using different image sizes and different variations of ResNets can lead to. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment suggests that the authors provide information on how much performance difference using different image sizes and different variations of ResNets can lead to. This is a clear and actionable suggestion that could help the authors improve their draft by addressing a specific gap in their analysis. However, the comment could be more helpful if it provided additional context or examples of how this information might be presented or analyzed. Overall, the feedback is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with further guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the algorithm should be presented and described in detail, which is a clear and explicit action for the authors to take. However, it does not provide specific guidance on how to present or describe the algorithm in detail, leaving the authors with a general idea of what needs to be done but without concrete steps to follow. While the action is explicit, the lack of detailed instructions makes it somewhat vague, as the authors may not be entirely sure of the exact changes needed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the algorithm should be presented and described in detail, which is a general request for improvement. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where the algorithm is discussed. Without explicit references to sections or figures, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspects of the algorithm need more detail or how it should be presented. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the algorithm should be presented and described in detail, which is a claim that requires justification. However, the comment does not provide any reasoning, examples, or references to support why this level of detail is necessary or how it would benefit the understanding of the proposed method. Without such evidence or explanation, the claim remains 1, as the authors are left without a clear understanding of what specific aspects need more detail or why. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the algorithm should be presented and described in detail, which is a valid point as it can help readers better understand the proposed method. However, the comment lacks specificity and does not provide guidance on how to achieve this level of detail or what aspects of the algorithm need more explanation. Without actionable suggestions or examples, the authors may find it challenging to implement the feedback effectively. Therefore, the comment is 3, as it identifies an area for improvement but does not provide enough detail to be fully actionable."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that it would be interesting to see a runtime comparison at test time, given the mention of using Chebyshev polynomials for speedup. While the comment implies that the authors should include a runtime comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to conduct the comparison or what aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that it would be interesting to see a runtime comparison at test time, given the mention of using Chebyshev polynomials for speedup. However, it does not specify which part of the paper discusses this possibility, making it weakly grounded. The comment is specific in suggesting a particular type of comparison that could be included, but without explicit references to sections or parts of the paper, the authors may find it challenging to pinpoint the exact area needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it would be interesting to see a runtime comparison at test time, given the mention of using Chebyshev polynomials for speedup. This is a request for additional information or analysis, rather than a claim or opinion that requires verification. It does not present subjective judgments, suggestions, or deductions that need to be supported by evidence or reasoning. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment suggests that it would be interesting to see a runtime comparison at test time, given the mention of using Chebyshev polynomials for speedup. This feedback is 3 as it points out a potential area for improvement in the paper, specifically suggesting a comparison that could enhance the understanding of the method\"s performance. However, the comment lacks specific guidance on how to conduct the comparison or what aspects to focus on, which limits its usefulness. To be more helpful, the comment could include suggestions on the methodology or metrics to use for the comparison. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the prompts in Table 6 and 7 are not wellorganized, with all sentences squeezed together. However, it does not provide any explicit or implicit suggestions on how the authors might improve the organization or formatting of the prompts. Without guidance on what specific changes could be made or how to address the issue, the authors are left without a clear path forward. The comment lacks actionable advice, leaving the authors without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 6 and 7,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by noting that the prompts are not wellorganized, with all sentences squeezed together. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the prompts in Table 6 and 7 are not wellorganized, with all sentences squeezed together. However, the comment does not provide any specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 2, as it lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the organization of prompts in Tables 6 and 7, noting that all sentences are squeezed together. This feedback is 3 as it points out a potential area for improvement in the presentation of the prompts. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending a more structured or visually appealing layout. While it highlights a problem, it does not offer actionable advice, making it 3 but incomplete."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the figures are not clear, specifically mentioning that the relationship between the subfigures in Figure 2 is confusing and that some modules, such as CMAF, L_BT, and VoLTA, are not labeled. This provides clear and direct actions for the authors to take, which is to clarify the relationships between the subfigures and label the missing modules. The feedback is specific and actionable, giving the authors concrete steps to improve the clarity of their figures. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the relationship between the subfigures is confusing and that some modules, such as CMAF, L_BT, and VoLTA, are not labeled. This provides clear guidance on what needs to be addressed to improve the clarity of the figures. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the figures are not clear, specifically mentioning that the relationship between subfigures in Figure 2 is confusing and that some modules are not labeled. This is a subjective claim that requires justification or examples to support the assertion. The comment lacks specific details or references to explain why the figures are unclear or how they could be improved. Without additional context or examples, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies specific issues with the clarity of the figures, particularly in Figure 2, where the relationship between subfigures is confusing and some modules are not labeled. This feedback is clear and actionable, as it provides the authors with a direct way to improve the clarity and readability of their figures. By addressing these issues, the authors can enhance the comprehensibility of their work for readers. However, the comment could be more helpful if it offered suggestions on how to clarify the relationships or label the missing modules. Overall, the comment is 4 as it effectively guides the authors toward improving the visual presentation of their results."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the impact of the number of images on model performance and the need to explain BYOL in the abstract. While it implies that the authors should address these questions, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should investigate and explain these aspects. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the impact of the number of images on model performance and the need to explain BYOL in the abstract. However, it does not specify which part of the paper these questions pertain to, making it weakly grounded. The comment is specific in its request for clarification on the impact of image number and the explanation of BYOL, but without clear grounding, the authors may struggle to identify the exact sections needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the impact of the number of images on model performance and the need to explain BYOL in the abstract. However, it does not provide any supporting evidence, reasoning, or references to justify these claims. The lack of detailed explanation or examples makes it difficult for the authors to understand the basis of the questions or how to address them. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises important questions about the impact of the number of images on model performance and the need to explain BYOL in the abstract. These are relevant points that could help the authors improve their draft by addressing potential gaps in their explanation or methodology. However, the comment lacks specificity and does not provide detailed guidance on how to address these questions or what specific aspects of BYOL should be explained. While it identifies areas for improvement, the feedback could be more actionable and comprehensive to be fully helpful. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of clarity regarding the effectiveness of the method, specifically the L_pixel component. It suggests that the authors provide stronger arguments or intuitions to explain why these particular losses are beneficial. While the comment implies that the authors should provide more detailed explanations, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not specify exactly what kind of arguments or intuitions are needed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper, namely the effectiveness of the method, particularly regarding the L_pixel component. It suggests that the authors provide stronger arguments or intuitions to explain why these particular losses are beneficial. However, the comment does not specify which part of the paper discusses the L_pixel component, making it weakly grounded. The comment is specific in its request for stronger arguments or intuitions, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the observed effects are strong but questions the clarity of why the method works, particularly regarding the L_pixel component. The reviewer suggests that providing stronger arguments or intuitions about why these particular losses are beneficial would be welcome. However, the comment lacks specific examples or references to support the claim that the method is unclear or that the L_pixel component is not wellexplained. Without detailed reasoning or evidence, the claim remains somewhat vague, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3, as it provides some justification but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the clarity of the method\"s effectiveness, particularly the L_pixel component. It suggests that the authors provide stronger arguments or intuitions to explain why these particular losses are beneficial. This feedback is clear and actionable, as it directs the authors to enhance their explanation of the method\"s workings. However, the comment could be more helpful if it offered specific suggestions or examples of what kind of arguments or intuitions would be most beneficial. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the sufficiency of the training data, specifically questioning whether 44k dialogues can capture a wide range of user traits and personalities across different content topics. The reviewer suggests that LLMs are typically trained on trillions of tokens, implying that the dataset size is insufficient. However, the comment does not provide explicit guidance on how the authors should address this concern or suggest ways to improve the dataset. The action is implicit and vague, as the authors are left to infer that they need to increase the dataset size but are not given specific instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the sufficiency of the training data, specifically questioning whether 44k dialogues are sufficient to capture a wide range of user traits and personalities across different content topics. The reviewer compares this dataset size to the typical training data for LLMs, which are often trained on trillions of tokens. However, the comment does not specify which part of the paper this concern pertains to, such as a specific section or analysis, making it weakly grounded. The comment is specific in its critique of the dataset size and its implications for capturing user traits and personalities, but without clear grounding, it aligns with a score of 2.", "verifiability_rationale": "The review point raises a concern about the sufficiency of the training data, specifically questioning whether 44k dialogues are sufficient to capture a wide range of user traits and personalities across different content topics. The reviewer compares this dataset size to the typical training data for LLMs, which are often trained on trillions of tokens. However, the comment lacks specific examples or references to support the claim that 44k dialogues are insufficient. The reasoning is logical but could be strengthened with more detailed evidence or references to similar datasets or studies. Therefore, the comment is 3, as it provides a logical basis for the claim but requires additional support to be fully convincing.", "helpfulness_rationale": "The review comment raises a concern about the sufficiency of the training data, specifically questioning whether 44k dialogues are sufficient to capture a wide range of user traits and personalities across different content topics. The reviewer compares this dataset size to the typical training data for LLMs, which are often trained on trillions of tokens, suggesting that the dataset may not be large enough to capture the necessary combinations of personalities and topics. While the comment identifies a potential weakness in the dataset, it lacks specific suggestions or guidance on how the authors might address this issue or improve the dataset. The feedback is 3 as it highlights an area for improvement, but it could be more actionable with additional details or recommendations. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point expresses skepticism about the use of binary classification as a baseline metric, questioning its suitability for assessing models\" understanding of finegrained errors like technique errors. However, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve their approach. The comment lacks actionable details, such as recommending alternative metrics or methods to assess the models\" understanding. As a result, the authors are left without a clear path forward to address the issue raised. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment questions the use of binary classification as a baseline metric, suggesting that it may not adequately assess models\" understanding of finegrained errors like technique errors. However, it does not specify which part of the paper discusses the binary classification baseline or where the issue with its suitability is addressed. The authors can infer that it relates to the methodology or results sections, but the comment lacks full grounding as it does not explicitly mention these sections. Additionally, while it raises a specific concern about the appropriateness of the baseline, it does not provide detailed guidance on how to address this issue or suggest alternative metrics. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point questions the use of binary classification as a baseline metric, suggesting that it may not adequately assess models\" understanding of finegrained errors like technique errors. The reviewer provides a logical reasoning by questioning the suitability of a coarsegrained binary classification for assessing a finegrained task. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to further explore the reasoning and evidence to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the suitability of binary classification as a baseline metric for assessing models\" understanding of finegrained errors like technique errors. It acknowledges the importance of the TAL task but questions the effectiveness of binary classification in capturing the nuances of the problem. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or explore alternative metrics or methods. While it identifies a potential weakness, it does not provide actionable feedback or detailed insights into how the authors might improve their draft. As a result, the comment is 3, as it prompts the authors to reconsider their approach but does not fully support them in making improvements."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the writing should be improved, indicating that certain points in the paper are unclear. However, it does not specify which points are unclear or provide guidance on how to improve the clarity. The action is implicit and vague, as the authors are left to infer which parts of the paper need improvement and how to achieve that. Without concrete examples or suggestions, the authors may struggle to determine the necessary changes. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the writing should be improved and mentions that some points in the paper are unclear. However, it does not specify which parts of the paper are unclear or provide any guidance on how to improve the clarity. Without explicit references to sections, figures, or specific content, the authors cannot confidently determine which parts of the paper need attention. The comment is 1 as it does not identify a specific area, and it is also not specific because it lacks details on what needs to be clarified. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the writing should be improved because some points in the paper are unclear. However, it does not provide specific examples or details about what is unclear or how the writing could be improved. Without concrete evidence or suggestions, the claim lacks verifiability, making it difficult for the authors to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the writing should be improved, indicating that some points in the paper are unclear. However, it lacks specificity and does not provide detailed guidance or examples of what needs to be clarified or improved. Without actionable feedback or suggestions, the authors are left without a clear understanding of how to address the issues identified. This makes the comment 2, as it points out a general area for improvement but does not offer meaningful guidance for the authors to enhance their draft."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should use other metrics, specifically BERTScore, to evaluate their results. This is an explicit suggestion that provides a clear action for the authors to take. The comment is also concrete, as it specifies the exact metric that should be used, giving the authors a direct and specific direction for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests using other metrics, specifically BERTScore, to evaluate the results. However, it does not specify which part of the paper this suggestion pertains to, such as the Results section or a specific table or figure. Without explicit references to the paper, the authors may find it challenging to determine where to incorporate this suggestion. The comment is specific in recommending the use of BERTScore, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests using other metrics, specifically BERTScore, to evaluate the results. However, it does not provide any reasoning or evidence to support why BERTScore is a better or more appropriate metric compared to the ones already used. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests using other metrics, specifically BERTScore, to evaluate the results. While it identifies a potential area for improvement, it lacks specificity and does not provide a rationale or examples of why BERTScore might be a better choice over the current metrics. The comment also does not offer guidance on how to implement this suggestion or address any concerns about the current evaluation methodology. As a result, the feedback is 3, as it points out a possible enhancement but does not fully support the authors in making the necessary changes. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should compare their SynTextBench metric to other metrics proposed in the literature, such as MMLU or Big Bench, to understand under what conditions one should use SynTextBench. While the comment implies that the authors should conduct this comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to conduct the comparison or what aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"SynTextBench metric,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests comparing the SynTextBench metric to other metrics proposed in the literature, such as MMLU or Big Bench, to understand under what conditions one should use SynTextBench. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that there has been a significant amount of work on LLM evaluation, with some metrics not satisfying the proposed desiderata. It further recommends comparing the SynTextBench metric to other metrics in the literature to understand its applicability. The comment provides a logical reasoning by referencing existing work and suggesting a specific comparison, which is a clear and actionable suggestion. However, it lacks specific references to the existing literature or detailed examples of metrics that do not satisfy the proposed desiderata. Therefore, the claim is 4, as it provides a solid basis for the suggestion but could be strengthened with more detailed references or examples.", "helpfulness_rationale": "The review comment provides a constructive suggestion for the authors to compare their SynTextBench metric with other metrics proposed in the literature, such as MMLU or Big Bench, to understand under what conditions one should use SynTextBench. This feedback is actionable and offers a clear direction for the authors to enhance their work by providing a context for their metric within the existing literature. However, the comment could be more helpful if it included specific examples or references to the other metrics, which would further guide the authors in making the comparison. Overall, the comment is 4 as it provides a valuable insight into improving the paper, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point highlights a general issue with the writing and annotations, stating that they are \"a little hard to follow.\" However, it does not provide any specific guidance or suggestions on how the authors might improve the clarity or readability of their draft. The comment lacks actionable details, such as identifying particular sections or aspects that need improvement or suggesting specific changes that could be made. As a result, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions \"poor writing and annotations,\" but it does not specify which parts of the paper are affected by these issues. Without explicit references to sections, tables, or figures, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specificity regarding what aspects of the writing or annotations are problematic, such as unclear terminology, inconsistent formatting, or missing explanations. As a result, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the writing and annotations are \"a little hard to follow,\" but it does not provide any specific examples or detailed reasoning to support this claim. Without concrete evidence or examples of what makes the writing or annotations difficult to follow, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a general issue with the writing and annotations, noting that they are \"a little hard to follow.\" However, it lacks specificity and does not provide any actionable feedback or suggestions on how the authors might improve the clarity or readability of their draft. Without detailed guidance or examples of what aspects need improvement, the authors are left without a clear understanding of how to address the issue. Therefore, the comment is 1, as it does not offer any actionable insights or direction for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the performance of the proposed method in Table 2, specifically regarding the evaluation metrics and the \"Twitter2017 $\rightarrow$ Twitter2015\" setting. It highlights a discrepancy between the overall F1 score and the F1 scores for individual types. While the comment identifies an area of concern, it does not provide explicit guidance or suggestions on how the authors should address this issue. The authors are left to infer that they should investigate and explain this discrepancy, but without concrete steps or suggestions, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a discrepancy in the performance of the proposed method in terms of achieving SOTA performances and the F1 scores for individual types. The comment raises a question about the performance in a specific setting, which provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the performance of the proposed method in Table 2, specifically regarding the evaluation metrics and the \"Twitter2017 $\rightarrow$ Twitter2015\" setting. It highlights a discrepancy between the overall F1 score and the F1 scores for individual types. While the comment identifies a potential issue, it does not provide any supporting evidence, reasoning, or references to substantiate the claim. The lack of detailed explanation or references makes it difficult for the authors to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the performance of the proposed method in Table 2, noting that only 8 of the 14 evaluation metrics achieve SOTA performances. It also questions the discrepancy between the overall F1 score and the F1 scores for individual types in a particular setting. This feedback is clear and actionable, as it prompts the authors to investigate and explain this discrepancy, which could be a critical point in the paper\"s evaluation. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered guidance on potential explanations. Overall, the comment is 4, as it directs the authors\" attention to a specific area needing clarification or improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of thorough exploration of the scalability bounds of FedDES and the absence of a clear discussion on memory requirements and computational complexity. While it identifies specific areas that need attention, it does not provide explicit guidance on how the authors should address these issues or what specific aspects should be included in the discussion. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand the discussion on scalability bounds, memory requirements, and computational complexity. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights a lack of thorough discussion on the scalability bounds of FedDES, specifically mentioning the absence of clear discussion on memory requirements and computational complexity. However, it does not specify which part of the paper this issue pertains to, such as a particular section or subsection. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing what is missing, namely a discussion on scalability bounds, memory requirements, and computational complexity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks a thorough discussion on the scalability bounds of FedDES, specifically mentioning the absence of clear discussion on memory requirements and computational complexity. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks depth and thoroughness, namely the discussion on scalability bounds and the absence of clear discussion on memory requirements and computational complexity. This feedback is valuable as it highlights a critical aspect of the paper that needs further exploration and clarification. However, the comment could be more helpful if it provided suggestions on how to address these issues or examples of what a comprehensive discussion might entail. Despite this, the comment is 3 as it directs the authors\" attention to an important area for improvement, prompting them to enhance their draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the setting of Unsupervised Online Adaptation, suggesting that it is not truly unsupervised because the training set requires annotations. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or clarify the setting. Without specific suggestions or instructions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec 3.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the setting of Unsupervised Online Adaptation is strange because it requires a training set with documents, queries, and labels, which contradicts the notion of unsupervised adaptation. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the setting of Unsupervised Online Adaptation is strange because it requires a training set with documents, queries, and labels, contradicting the notion of unsupervised adaptation. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the setting of Unsupervised Online Adaptation, pointing out that it requires a training set with documents, queries, and labels, which contradicts the notion of unsupervised adaptation. This feedback is 3 as it highlights a possible inconsistency in the paper, prompting the authors to reconsider their approach or clarify the setting. However, the comment lacks specific suggestions or guidance on how to address this issue, such as proposing alternative methods or explaining the rationale behind the current setup. To be more helpful, the comment could provide more detailed feedback or actionable advice. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should display the performance of accelerating SGMs by involving other baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. However, it does not provide specific guidance on which baselines to include or how to implement these suggestions. The action is implicit and somewhat vague, as the authors are left to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should display the performance of accelerating SGMs by involving other baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting alternative perspectives and baselines to consider, but without clear grounding, the authors may struggle to identify the exact sections that need revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should display the performance of accelerating SGMs by involving other baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. However, the comment does not provide specific examples or references to support the claim that these alternative perspectives are necessary or beneficial. Without detailed justification or evidence, the authors may find it challenging to understand the rationale behind this suggestion. Therefore, the comment is considered 2, as it lacks sufficient support to fully substantiate the claim.", "helpfulness_rationale": "The review comment suggests that the authors should display the performance of accelerating SGMs by involving other baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. This feedback is 3 as it identifies a potential area for improvement by suggesting alternative perspectives that could enhance the paper\"s contribution. However, the comment lacks specific guidance on which baselines to consider or how to implement these suggestions, leaving the authors with a general direction but not a detailed plan for improvement. Therefore, the comment is rated as 3, as it provides some insight but could be more actionable with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the synthetic experiment in a nonseparable case, questioning how the data distribution illustrated in Figure 1 is inseparable from the network model, given the nonlinear expression ability of neural networks. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on what specific aspects of the experiment or explanation need to be addressed or improved. Without actionable suggestions or a clear direction for the authors, this comment lacks any guidance on how to proceed. Therefore, it is rated as 1.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the synthetic experiment in a nonseparable case, mentioning Figure 1. This provides full grounding as it explicitly references a figure in the paper, allowing the authors to accurately identify the part of the paper being addressed. The comment is also specific because it questions the explanation of how the data distribution illustrated in Figure 1 is inseparable from the network model, given the nonlinear expression ability of neural networks. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the synthetic experiment in a nonseparable case, questioning how the data distribution illustrated in Figure 1 is inseparable from the network model, given the nonlinear expression ability of neural networks. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the synthetic experiment in a nonseparable case, questioning how the data distribution illustrated in Figure 1 is inseparable from the network model, given the nonlinear expression ability of neural networks. This is a valid point that prompts the authors to consider the rationale behind their experimental setup and the implications of the data distribution. However, the comment does not provide specific suggestions or guidance on how to address this issue or improve the explanation. While it identifies a potential weakness, it lacks actionable feedback, making it 3. The authors are given a direction to explore but without detailed guidance, the comment could be more helpful with additional context or suggestions. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the results are presented in a convoluted manner, specifically mentioning the disregard of safety violations in the first 1000 episodes. It questions the reason for presenting the results in this way, implying that the authors should clarify or restructure their presentation. However, the comment does not provide explicit guidance on how to address this issue or suggest specific changes to improve the clarity of the results. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the presentation but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the presentation of results, specifically mentioning the disregard of safety violations in the first 1000 episodes. This provides some level of grounding as it allows the authors to identify the part of the paper being discussed, such as the results section. However, the comment lacks specificity because it does not provide detailed guidance on how to improve the presentation or what specific aspects of the results are unclear. The authors are left to infer what changes are needed without explicit direction. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the results are presented in a convoluted manner, specifically mentioning the disregard of safety violations in the first 1000 episodes. The comment questions the reason for presenting the results in this way, suggesting that it may be unclear or misleading. However, the comment lacks specific examples or detailed reasoning to support the claim, making it difficult for the authors to understand the exact issue or how to address it. The lack of detailed justification or references makes the claim 3, as it requires more information to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of results, noting that the results disregard safety violations in the first 1000 episodes. It questions the reason for presenting the results in this way, suggesting that it may be unclear or misleading. This feedback is 3 as it points out a potential weakness in the presentation of results, prompting the authors to reconsider their approach. However, the comment lacks detailed guidance or suggestions on how to improve the presentation or address the issue, which would make it more actionable. Therefore, the comment is rated as 3, as it provides some insight but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to define the bounds for \tau_i^l, which is crucial for understanding the timewarp function. This is a clear and direct action that the authors can take to improve their draft. The comment provides specific guidance on what needs to be defined, making it 5. Therefore, this comment is rated as a 5 on the actionability scale.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"l111,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be defined, which is the bounds for \tau_i^l, and why it is important for understanding the timewarp function. This provides clear guidance on what the authors need to address in their draft. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification, specifically asking the authors to define the bounds for \tau_i^l. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely a request for additional information, making it a factual statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment is 5 as it provides specific and actionable feedback. It identifies a particular section of the paper (l111) and requests clarification on the bounds for \tau_i^l, which is crucial for understanding the timewarp function. This feedback is clear and direct, guiding the authors on what specific information is missing and how to improve their draft by providing this definition. By addressing this point, the authors can enhance the clarity and comprehensibility of their work, making the comment 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides a specific critique of a statement on line 134, pointing out that it is only true for a specific sigmoid function and suggesting that Theorem 4.1 should be elaborated on in the main text. While the comment identifies a potential area for improvement, it does not explicitly instruct the authors to make these changes or provide detailed guidance on how to elaborate on Theorem 4.1. The action is implicit and somewhat vague, as the authors can infer that they need to provide more explanation but may not be entirely sure of the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 134\" and \"Theorem 4.1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the statement on line 134 is only true for a specific sigmoid function and suggesting that Theorem 4.1 should be elaborated on in the main text. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point critiques a statement on line 134, suggesting that it is only true for a specific sigmoid function and that Theorem 4.1 should be elaborated on. The comment provides a logical reasoning by explaining the dependency on the maximum slope and the convergence to the nearest floatingpoint number. However, it lacks specific references or examples to fully substantiate the claim, making it 3. The authors would need to further explore the reasoning themselves to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific critique of a statement on line 134, pointing out that it is only true for a specific sigmoid function and suggesting that Theorem 4.1 should be elaborated on in the main text. This feedback is clear and actionable, as it identifies a potential misunderstanding in the text and offers a suggestion for improvement by elaborating on the theorem. However, the comment could be more helpful if it included additional guidance on how to elaborate on the theorem or what specific aspects should be clarified. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with further guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a concern about the efficiency of pairwise matching, suggesting that it is not suitable for practical application systems. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve efficiency or what specific changes could be made to enhance the practicality of the system. Without actionable suggestions or concrete steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a concern about the efficiency of pairwise matching, suggesting it is not suitable for practical application systems. However, it does not specify which part of the paper discusses this issue, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of efficiency are problematic or how they could be improved. Without clear guidance or references to specific sections, the authors cannot effectively address the feedback. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the efficiency of pairwise matching is low, making it difficult to use in practical application systems. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references to justify the assertion, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a potential issue with the efficiency of pairwise matching, suggesting that it may not be suitable for practical application systems. However, it lacks specificity and does not provide any actionable advice or suggestions on how the authors might address this concern. Without detailed guidance or examples, the authors are left without a clear understanding of what changes or improvements could be made to enhance the efficiency of their approach. As a result, the comment is not particularly helpful, as it identifies a problem but does not offer a path for resolution. Therefore, it aligns with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out a minor weakness in the allocation of Figure 1, suggesting that it is too naive. It also mentions that the authors could have edited the space of the main paper more wisely. However, the comment does not provide specific guidance on how to improve the allocation of Figure 1 or how to edit the space of the main paper more wisely. The actions are implicit and vague, leaving the authors without clear direction on how to address these issues. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment identifies a minor weakness in the allocation of Figure 1, suggesting that it is too naive. However, it does not specify which part of the paper this figure is located in, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment mentions that the authors could have edited the space of the main paper more wisely, but it does not provide specific guidance on what changes could be made or why the current allocation is considered naive. This lack of specificity and grounding makes it challenging for the authors to address the feedback effectively. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the allocation of Figure 1 is too naive and suggests that the authors could have edited the space of the main paper more wisely. However, the comment lacks specific examples, reasoning, or references to support these claims. Without detailed justification or evidence, the authors may find it challenging to understand and address the feedback effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a minor weakness in the allocation of Figure 1, suggesting that it is too naive. It also mentions that the authors could have edited the space of the main paper more wisely. However, the comment lacks specificity and does not provide detailed guidance or suggestions on how to improve the allocation of Figure 1 or how to edit the space of the main paper more effectively. Without actionable advice, the authors are left with a general idea of what needs improvement but without clear steps to take. Therefore, the comment is 2, as it provides some insight but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly instructs the authors to rewrite the first sentence of the abstract. This is a clear and direct action, leaving no ambiguity about what needs to be done. The comment provides a specific and concrete instruction, making it 5. The authors know exactly what step to take to improve their draft, which aligns with a score of 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first sentence of the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the need to rewrite the first sentence of the abstract. Therefore, this comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point is a request for a change, specifically asking for the first sentence of the abstract to be rewritten. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely a request for modification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment is clear and direct, instructing the authors to rewrite the first sentence of the abstract. This feedback is actionable and provides a specific area for improvement, which is beneficial for the authors. However, it lacks further explanation or guidance on how to improve the sentence or what aspects of it need revision. While it points out a clear issue, it does not offer detailed suggestions or examples to help the authors enhance their draft. Therefore, the comment is 3, as it provides a clear direction but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should consider using multiple train/test splits or folds to provide a more accurate illustration of the method\"s performance. While the comment implies that this is necessary, it does not explicitly instruct the authors to do so. Additionally, it provides a rationale for why this is important, mentioning the standard practice in most papers on GPs and the potential time constraints due to dataset size. However, the comment lacks concrete guidance on how to implement this suggestion, such as the number of splits or folds to use. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"nearly all experiments\" and \"the results are reported for a single heldout test set,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the authors should use multiple train/test splits or folds to provide a more accurate illustration of the method\"s performance. The comment provides a clear and specific suggestion for improvement, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors should use multiple train/test splits or folds to provide a more accurate illustration of the method\"s performance. The reviewer provides a logical reasoning by stating that this is a standard practice in most papers on GPs and that it would give a more accurate representation of the method\"s performance. However, the comment lacks specific examples or references to support the claim that using multiple splits is necessary or beneficial in the context of the paper. This makes the claim 3, as it provides a logical basis but lacks detailed evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the experimental setup, noting that the results are reported for a single heldout test set, which is not standard practice in most papers on GPs. The reviewer suggests that using multiple train/test splits or folds would provide a more accurate illustration of the method\"s performance. While the comment highlights an important area for improvement, it does not provide specific guidance on how to implement this suggestion, such as the number of splits or folds to use. Additionally, it does not explain why this is important or how it might impact the interpretation of the results. Therefore, the comment is 3 as it points out a potential issue but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the method is more complex than necessary and implies that there might be a simpler underlying principle driving the quality gains. However, it does not provide explicit guidance or suggestions on how to simplify the method or identify this underlying principle. The action is implicit and vague, as the authors are left to infer what changes might be needed without concrete instructions. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the method is more complex than necessary and implies that there might be a simpler underlying principle driving the quality gains. However, it does not specify which part of the paper this critique pertains to, such as a specific section, figure, or table. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the method are considered overly complex or how to simplify them. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the method is more complex than necessary and implies that there might be a simpler underlying principle driving the quality gains. However, the comment lacks specific examples, detailed reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the method is more complex than necessary and implies that there might be a simpler underlying principle driving the quality gains. While it identifies a potential issue with the complexity of the method, it lacks specificity and does not provide actionable guidance or suggestions on how to simplify the method or identify the underlying principle. The comment points out a possible area for improvement but does not offer detailed advice or examples, leaving the authors with limited insight into how to address the issue. Therefore, the comment is 2, as it provides some insight but lacks depth and actionable feedback."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point acknowledges the addition of a method to improve transferability as a positive step but dismisses it as not being a significant contribution. However, it does not provide any specific guidance or suggestions on how the authors might enhance their contribution or address the reviewer\"s concerns. The comment lacks actionable details, leaving the authors without a clear understanding of what changes or improvements are needed to address the issue. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper discusses the addition of a method to improve transferability. It also lacks specificity because it does not provide details on what aspects of the contribution are considered insignificant or how the authors might address this concern. Without clear references to the paper or specific suggestions for improvement, the authors cannot effectively respond to the feedback. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that adding a method to improve transferability is a positive step but not a significant contribution. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this addition is not significant. Without additional context or explanation, the claim remains 1, as the authors would have difficulty understanding the basis of the reviewer\"s opinion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment acknowledges the addition of a method to improve transferability as a positive step but dismisses it as not being a significant contribution. However, it does not provide any specific feedback or suggestions on how the authors might enhance their contribution or address the reviewer\"s concerns. The comment lacks actionable guidance or detailed critique, leaving the authors without a clear understanding of what improvements could be made to strengthen their work. As a result, the comment is 1, as it does not offer any constructive feedback for the authors to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the challenges when analyzing Adam under the (L0, L1)smoothness condition. It suggests that the authors should explain these challenges and differentiate them from the analysis in Zhang et al. While the comment implies that the authors should provide additional explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the challenges or differentiate the analysis. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper, namely the challenges when analyzing Adam under the (L0, L1)smoothness condition. It questions the clarity of the analysis and suggests that the authors should explain the challenges, particularly differentiating their approach from that of Zhang et al. This provides clear guidance on what needs to be addressed in the paper. However, the comment does not explicitly mention which section or part of the paper this issue pertains to, making it weakly grounded. Despite this, the comment is specific in detailing what needs to be clarified. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the clarity of the analysis when the authors analyze Adam under the (L0, L1)smoothness condition. It suggests that the analysis might be straightforward and asks for an explanation of the challenges, particularly differentiating it from the work of Zhang et al. While the comment raises a valid point, it lacks specific examples or detailed reasoning to support the claim that the analysis is not clear. This makes the claim 3, as it provides a direction for improvement but requires more detailed justification or examples to be 5. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the analysis of Adam under the (L0, L1)smoothness condition. It questions the clarity of the analysis and suggests that the authors should explain the challenges, particularly differentiating their approach from the work of Zhang et al. This feedback is clear and actionable, as it directs the authors to provide additional explanation and differentiation, which could enhance the comprehensibility and originality of their work. However, the comment could be more helpful if it provided specific suggestions on how to address the challenges or differentiate the analysis. Overall, the comment is 4, as it guides the authors toward improving their draft but could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point highlights that most person reID methods are based on pedestrian detectors (twostep methods) and mentions the existence of endtoend methods that combine detection and reID. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this information or how it relates to their work. Without any actionable suggestions or questions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions \"most of person reID methods\" and \"pedestrian detector\" without specifying which part of the paper these methods are discussed in. This makes it difficult for the authors to pinpoint the exact section being addressed. Additionally, the comment provides a general observation about the existence of endtoend methods but does not specify what needs to be addressed or improved regarding this observation. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point makes a factual statement about the basis of person reidentification methods, mentioning that most are based on pedestrian detectors (twostep methods) and that there are also endtoend methods that combine detection and reID. This statement is based on common knowledge in the field and does not require additional evidence or references to be considered factual. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a factual observation about the basis of person reidentification methods, noting that most are based on pedestrian detectors (twostep methods) and that there are also endtoend methods that combine detection and reID. However, the comment lacks any actionable feedback or suggestions for improvement. It does not identify specific weaknesses or areas that the authors should address in their work. Without guidance on how to enhance their approach or methodology, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to include additional citations to set their work in the context of other MultiAgent Reinforcement Learning (MARL) work, specifically mentioning recent papers on selfplay and populationplay with respect to exploration and coordination. The comment provides specific examples of papers that could be included, such as https://arxiv.org/abs/1806.10071 and https://arxiv.org/abs/1812.07019. This guidance is clear and concrete, giving the authors a direct action to take to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for additional citations to set the work in the context of other MultiAgent Reinforcement Learning (MARL) work, specifically referencing recent papers on selfplay and populationplay with respect to exploration and coordination. The authors can accurately identify the part of the paper that needs attention, which is the section on citations. The comment is also specific because it provides examples of relevant papers that could be included, such as https://arxiv.org/abs/1806.10071 and https://arxiv.org/abs/1812.07019. This level of detail helps the authors understand exactly what needs to be addressed, making the comment 5. Therefore, this comment aligns with a score of 5.", "verifiability_rationale": "The review point suggests that the paper lacks citations to place it in the context of other MultiAgent Reinforcement Learning (MARL) work, specifically mentioning recent papers on selfplay and populationplay with respect to exploration and coordination. The reviewer provides specific examples of papers that could be included, such as https://arxiv.org/abs/1806.10071 and https://arxiv.org/abs/1812.07019. This level of detail and reference to external works supports the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how these references would enhance the context of the paper. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the paper lacks citations to place it in the context of other MultiAgent Reinforcement Learning (MARL) work, particularly recent papers on selfplay and populationplay with respect to exploration and coordination. The comment provides specific examples of relevant papers, such as https://arxiv.org/abs/1806.10071 and https://arxiv.org/abs/1812.07019, which can guide the authors in selecting appropriate references. This feedback is clear and actionable, offering a concrete way for the authors to enhance the context and relevance of their work. However, the comment could be more helpful if it included a rationale for why these references are important or how they would contribute to the paper. Overall, the comment is 4, as it provides valuable guidance for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should compare their work with other selfsupervised learning methods that are not based on contrastive learning. This is an explicit action that provides a clear direction for the authors to follow. However, it does not specify which specific methods should be compared or how to conduct the comparison, leaving some room for ambiguity. While the action is explicit, it lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment suggests comparing the work with other selfsupervised learning methods that are not based on contrastive learning. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology, results, or discussion sections. Without explicit references to specific sections or elements of the paper, the authors cannot confidently determine where to incorporate this comparison. Additionally, the comment lacks specificity regarding which specific methods should be compared or how the comparison should be conducted. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that it would be beneficial to compare the work with other selfsupervised learning methods that are not based on contrastive learning. However, the comment does not provide any specific reasoning, examples, or references to support why this comparison is necessary or how it would enhance the paper. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should compare their work with other selfsupervised learning methods that are not based on contrastive learning. This feedback is 3 as it points out a potential gap in the paper\"s comparison and suggests a direction for further exploration. However, the comment lacks specificity regarding which specific methods should be considered or how the comparison should be conducted. Without detailed guidance, the authors may find it challenging to implement this suggestion effectively. Therefore, the comment is rated as 3, as it provides a general direction but lacks depth and actionable details."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the abstention process, specifically whether it is based on a prediction probability threshold or a decision threshold used by the models. It requests clarification from the authors on this matter. While the comment does not explicitly instruct the authors to provide clarification, it implies that they should address the question by clarifying the difference between the two thresholds. The action is implicit but concrete, as the authors know exactly what information is needed to clarify the issue. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the abstention process,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the basis of the abstention process, whether it is based on a prediction probability threshold or a decision threshold used by the models, and requests clarification on this point. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the abstention process, specifically whether it is based on a prediction probability threshold or a decision threshold used by the models. It does not contain any subjective claims, opinions, or suggestions that require verification. It is a factual question seeking clarification, which is consistent with the \"No\" label.", "helpfulness_rationale": "The review comment raises a question about the abstention process used in the paper, specifically whether it is based on a prediction probability threshold or a decision threshold used by the models. It requests clarification on this point, which is a relevant and important aspect of the methodology that could impact the interpretation of the results. However, the comment does not provide any suggestions or guidance on how the authors might clarify this aspect or improve their explanation. While it identifies a potential area for improvement, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point raises concerns about the conclusions being unconvincing and suggests that the results might be due to limited exploration of combination methods. It provides specific examples of works that have shown potential in rehearsalfree continual learning, such as R1, R2, and R3. While the comment implies that the authors should consider these works and their methods, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they should explore these methods further but are not given specific guidance on how to integrate them into their work. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific conclusions that are not convincing, such as the claim about continuous learning with unlabeled data accumulating noise. It also references specific works, such as R1, R2, and R3, which provide examples of methods that have shown potential in rehearsalfree continual learning. This allows the authors to accurately identify the parts of the paper being addressed and the specific issues raised. The comment is also specific because it provides examples of works that could be considered for comparison or improvement, offering clear guidance on how to address the concerns raised. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some conclusions are not convincing, specifically mentioning the claim about continuous learning with unlabeled data accumulating noise. The reviewer provides examples of works that have shown potential in rehearsalfree continual learning, such as R1, R2, and R3, which employ feature replay methods. This provides some support for the claim by referencing relevant literature, making the comment 4. However, the comment could be strengthened by providing more detailed comparisons or analyses of these works to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the conclusions presented in the paper, suggesting that they are not convincing. It provides a detailed example of a claim that is questioned, specifically regarding the accumulation of noise in continuous learning with unlabeled data. The comment also references relevant works, such as R1, R2, and R3, which have shown potential in rehearsalfree continual learning and employ featurereplay methods. This provides the authors with specific examples of works to consider and potentially integrate into their own research. By offering a critique and suggesting alternative approaches, the comment is 5 as it guides the authors toward improving the validity and depth of their conclusions. Therefore, it aligns with a score of 5."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the pretraining process for the cardiac signal representation learning model. It asks whether the model is pretrained on the entire dataset or just the training set, and if the latter, how well it generalizes to settings without associated labels. While the comment does not explicitly instruct the authors to provide this information, it implies that the authors should clarify this aspect in their paper. The action is implicit but concrete, as the authors know exactly what information is needed to address the question. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment raises a question about the pretraining process for the cardiac signal representation learning model, specifically asking whether it is trained on the entire dataset or just the training set. It also inquires about the generalization of the model to settings without associated labels. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The authors can infer that it relates to the methodology or experimental setup sections, but this inference is not direct. The comment is specific in its inquiry about the pretraining process and generalization, but without explicit grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point is a question seeking clarification about the pretraining process for the cardiac signal representation learning model. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises an important question about the pretraining process for the cardiac signal representation learning model. It asks whether the model is pretrained on the entire dataset or just the training set, and if the latter, how well it generalizes to settings without associated labels. This question is relevant and could help the authors clarify their methodology, potentially leading to improvements in the robustness and generalizability of their model. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as recommending a particular approach or methodology. While it identifies a critical area for improvement, the lack of detailed feedback limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the accuracy of the ground truth and the differences in the results reported in the ablation study. However, it does not provide explicit instructions or suggestions for the authors to address these questions or improve their draft. The authors are left to infer that they need to provide more detailed explanations or analyses to clarify these points. The action is implicit and somewhat vague, as it lacks concrete guidance on how to address the issues. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises questions about the accuracy of the ground truth and the differences in the results reported in the ablation study. However, it does not specify which part of the paper these questions pertain to, such as which sections or tables discuss the ground truth or the ablation study. Without explicit references, the authors cannot confidently determine the exact parts of the paper being addressed. Additionally, the comment lacks specificity regarding what needs to be clarified or improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point consists of two questions: one about the accuracy of the ground truth and the other about the differences in the results reported in the ablation study. Neither question contains a claim or opinion that requires verification. They are factual inquiries seeking clarification or additional information. Therefore, the label \"No\" is appropriate.", "helpfulness_rationale": "The review comment raises important questions about the accuracy of the ground truth and the differences in the results reported in the ablation study. It prompts the authors to consider whether the observed differences are due to noise or randomness in the training process, which is a valid concern for the robustness and reliability of the results. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address these questions or improve their analysis. While it identifies potential areas for clarification, the feedback is somewhat vague and incomplete, making it 3 but not fully comprehensive. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that no new evaluation metrics are proposed and that only existing metrics are linearly combined. It also suggests that the experimental analysis section should include an indepth exploration of the reasons for the experimental results. While the comment implies that the authors should provide more detailed analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to conduct the indepth exploration. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of new evaluation metrics and the linear combination of existing metrics in the experimental analysis section. It suggests that there should be an indepth exploration of the reasons for the experimental results. However, it does not specify which part of the experimental analysis section needs this exploration, making it weakly grounded. The comment is specific in its request for an indepth exploration, but without clear grounding, the authors may struggle to identify the exact sections that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that no new evaluation metrics are proposed and that only existing metrics are linearly combined. It further suggests that the experimental analysis section lacks an indepth exploration of the reasons for the results. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of detailed justification or evidence makes the claim 3, as it requires the authors to infer the specific issues and address them accordingly. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, noting that no new evaluation metrics are proposed and that only existing metrics are linearly combined. It also suggests that the experimental analysis section lacks an indepth exploration of the reasons for the results. This feedback is clear and actionable, as it highlights an area where the authors could enhance their work by introducing novel evaluation metrics or providing a more comprehensive analysis of the experimental results. However, the comment could be more helpful if it offered specific suggestions on how to introduce new metrics or conduct the indepth exploration. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about how historical observations are combined with inputs known over all time, given differences in sequence lengths. It also notes that the text mentions separate embedding and addition with positional encoding but lacks clarification on how the embeddings are combined and fed into the CSCM. While the comment identifies a gap in the explanation and suggests the need for clarification, it does not provide explicit instructions on how to address this issue. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more detailed explanations about the combination of embeddings and their use in the CSCM. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"historical observations\" and \"inputs known over all time,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning how these observations are combined, given differences in sequence lengths, and requests clarification on how embeddings are combined and fed into the CSCM. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about how historical observations are combined with inputs known over all time, given differences in sequence lengths. It also notes that the text mentions separate embedding and addition with positional encoding but lacks clarification on how the embeddings are combined and fed into the CSCM. While the comment identifies a gap in the explanation, it does not provide specific reasoning or examples to support the claim that further clarification is needed. The lack of detailed justification or references makes the claim 3, as the authors would need to infer the necessity of additional explanation. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the combination of historical observations and inputs known over all time, given differences in sequence lengths. It points out that the text mentions separate embedding and addition with positional encoding but lacks clarification on how these embeddings are combined and fed into the CSCM. This feedback is clear and actionable, as it directs the authors to provide more detailed explanations on this aspect of their methodology. By addressing this gap, the authors can enhance the clarity and comprehensibility of their work. However, the comment could be more helpful if it provided specific suggestions on how to present this information or examples of similar approaches. Overall, the comment is 4, as it effectively guides the authors toward improving their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the first two bullets about contributions in the introduction can be combined. This is an explicit action, as it directly instructs the authors to make a specific change to their draft. However, it does not provide detailed guidance on how to combine these bullets or what specific changes should be made to improve the clarity or flow of the text. While the action is explicit, it lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"first two bullets about contributions (at the end of the intro),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the suggestion to combine the first two bullets about contributions. This provides clear guidance on how to improve the draft. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the first two bullets about contributions in the introduction can be combined. However, it does not provide any reasoning or justification for why this combination would be beneficial or how it would improve the clarity or flow of the text. Without additional context or explanation, the authors may find it challenging to understand the rationale behind the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the first two bullets about contributions in the introduction can be combined, which is a specific and actionable piece of feedback. By combining these bullets, the authors can streamline their introduction and improve the clarity and coherence of their contributions section. However, the comment does not provide further explanation or reasoning behind this suggestion, such as how combining the bullets might enhance the reader\"s understanding or what specific benefits it would bring. While the feedback is clear and actionable, it could be more helpful if it included additional context or rationale. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the types of situations or social norms, such as physical or psychological safety, are not clear in the main paper. However, it does not provide explicit guidance on how the authors should clarify these aspects or what specific information should be included. The action is implicit, as the authors can infer that they need to provide more detail on these types of situations or norms, but the comment lacks concrete instructions on how to do so. Therefore, the comment is 3, as it identifies an area for improvement but does not specify how to address it.", "grounding_specificity_rationale": "The comment identifies a lack of clarity regarding the types of situations or social norms, such as physical or psychological safety, in the main paper. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in detailing what is unclear, but without explicit references to sections or parts of the paper, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the types of situations or social norms (e.g., physical or psychological safety) are not clear in the main paper. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed explanation or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific area where the paper lacks clarity, namely the types of situations or social norms (e.g., physical or psychological safety) that are not clearly defined. This feedback is 3 as it points out a potential gap in the paper that the authors need to address. However, it does not provide specific suggestions or guidance on how to clarify these aspects, leaving the authors with a general direction but without detailed instructions on how to improve the draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges the paper\"s potential benefit to the neuroscience community but questions its ability to improve over existing solutions. It suggests that the authors should demonstrate the algorithm\"s ability to correctly find closed contours and show stronger robustness against weak boundaries, particularly for bottomup methods. While the comment implies that the authors should refer to recent trends in the vision community, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to incorporate these references or demonstrate the improvements. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment acknowledges the paper\"s potential benefit to the neuroscience community but questions its ability to improve over existing solutions. It suggests that the authors should demonstrate the algorithm\"s ability to correctly find closed contours and show stronger robustness against weak boundaries, particularly for bottomup methods. However, the comment does not specify which part of the paper this feedback pertains to, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but without explicit references, it is challenging to pinpoint the exact location. The comment is specific in suggesting what needs to be addressed, such as demonstrating improvements over existing solutions and robustness against weak boundaries. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point acknowledges the paper\"s potential benefit to the neuroscience community but questions its ability to improve over existing solutions. It suggests that the authors should demonstrate the algorithm\"s ability to correctly find closed contours and show stronger robustness against weak boundaries, particularly for bottomup methods. The comment provides a logical reasoning by highlighting the importance of these aspects for the paper\"s contribution. However, it lacks specific references or examples to support the claim that existing solutions are insufficient or that the proposed method can indeed improve upon them. This makes the claim 3, as it provides a direction for improvement but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the paper\"s potential benefit to the neuroscience community but questions its ability to improve over existing solutions. It suggests that the authors should demonstrate the algorithm\"s ability to correctly find closed contours and show stronger robustness against weak boundaries, particularly for bottomup methods. This feedback is 3 as it identifies a specific area for improvement and provides a direction for the authors to enhance their work. However, the comment lacks detailed guidance or examples on how to demonstrate these improvements, which would make it more actionable. Therefore, it is rated as 3, as it provides some insight but not comprehensive guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly requests the inclusion of more baselines and testing in more domains, suggesting that the current choices of weighting and learning density functions are not strongly motivated. It also asks for stronger empirical results by comparing baselines with different design choices and testing in more domains. This feedback provides clear and concrete actions for the authors to take, such as conducting additional experiments and comparisons. The explicit nature of the request and the detailed guidance on what needs to be done make this comment 5.", "grounding_specificity_rationale": "The comment suggests that more baselines should be compared and more domains tested, and it questions the motivation behind the choices of weighting and learning density functions. However, it does not specify which parts of the paper these suggestions pertain to, making it weakly grounded. The comment is specific in its request for stronger empirical results, but without clear references to specific sections or elements of the paper, the authors may find it challenging to pinpoint the exact areas needing improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more baselines should be compared and more domains tested, and it questions the motivation behind the choices of weighting and learning density functions. The reviewer provides a logical reasoning by asking for stronger empirical results, which implies that the current results are not sufficiently robust. However, the comment lacks specific examples or references to support the claim that other design choices or domains should be tested. This makes the claim 3, as it provides a direction for improvement but lacks detailed justification or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a lack of motivation for the choices of weighting and the way of learning density functions, suggesting that more baselines and domains should be tested to strengthen the empirical results. It provides a clear and actionable suggestion for improvement by asking for stronger empirical evidence through comparisons with other design choices and testing in more domains. This feedback is specific and constructive, offering the authors a clear path to enhance the robustness and validity of their work. However, it could be more helpful if it included specific examples or references to guide the authors in selecting appropriate baselines or domains. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point suggests that the results of the proposed methods are not comparable to existing methods, implying that there is limited significance in the proposed methods. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to make the results more comparable or what specific changes could be made to enhance the significance of the proposed methods. Without actionable suggestions or concrete steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the results of the proposed methods are not comparable to existing methods, implying that there is limited significance in the proposed methods. However, it does not specify which results or methods are being compared, nor does it provide details on why the results are not comparable. This lack of specificity and grounding makes it difficult for the authors to identify the exact parts of the paper that need attention or improvement. The comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the results are not comparable to existing methods, suggesting that the proposed methods lack significance. However, the comment does not provide any supporting evidence, reasoning, or examples to justify this claim. Without specific comparisons or references to existing methods, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the results of the proposed methods are not comparable to existing methods, implying that there is limited significance in the proposed methods. However, the comment lacks specificity and does not provide any actionable feedback or suggestions on how the authors might address this issue. It does not offer guidance on how to make the results more comparable or what specific aspects of the proposed methods could be improved to enhance their significance. Without actionable advice or detailed feedback, the comment provides limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a perceived lack of novelty in the paper, noting that it is a straightforward application of existing literature, specifically DeCorr, in a specific application domain. It points out that the contribution is mainly the transposition of DeCorr\"s insights into graph collaborative filtering with different datasets and backbones. The comment also mentions modifications like different penalty coefficients for users and items but suggests that the paper lacks insights into the unique challenges of overcorrelation in recommender systems. While the comment identifies areas where the paper could be improved, it does not provide explicit guidance on how the authors should address these issues or what specific insights or modifications are needed. The action is implicit and somewhat vague, as the authors are left to infer what changes are necessary without concrete instructions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the novelty of the paper, specifically mentioning the application of existing literature, such as DeCorr, in a specific domain. It highlights the contribution as the transposition of DeCorr\"s insights into graph collaborative filtering with different datasets and backbones. The comment also mentions modifications like different penalty coefficients for users and items but suggests that the paper lacks insights into the unique challenges of overcorrelation in recommender systems. While the comment does not explicitly mention specific sections or figures, the authors can infer that it relates to the introduction and discussion sections, where the novelty and contributions of the paper are typically discussed. The comment is specific in detailing what aspects are lacking in terms of novelty and insights. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks novelty and is a straightforward application of existing literature, specifically DeCorr, in a specific application domain. The reviewer provides a detailed explanation of how the paper is a transposition of DeCorr\"s insights into graph collaborative filtering with different datasets and backbones. Additionally, the comment mentions modifications like different penalty coefficients for users and items but suggests that the paper lacks insights into the unique challenges of overcorrelation in recommender systems. This reasoning is clear and provides a logical basis for the claim, making it 4. However, the comment could be strengthened by referencing specific sections or examples where the lack of novelty is evident, which would further enhance its verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a perceived lack of novelty in the paper, noting that it is a straightforward application of existing literature, specifically DeCorr, in a specific application domain. It highlights the contribution as the transposition of DeCorr\"s insights into graph collaborative filtering with different datasets and backbones. The comment also mentions modifications like different penalty coefficients for users and items but suggests that the paper lacks insights into the unique challenges of overcorrelation in recommender systems. While the comment points out areas for improvement, it does not provide specific guidance or suggestions on how the authors might address these issues or enhance the novelty of their work. The feedback is 3 as it prompts the authors to consider the uniqueness of their contribution, but it lacks depth and actionable advice, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the choice of ELM (male/female) and whether it requires knowledge of the speaker\"s gender beforehand. It also suggests that the accuracy should be calculated after using a gender detection model in the pipeline. While the comment implies that the authors should address these issues, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the choice of ELM and its implications for accuracy. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the choice of ELM (male/female) and its implications for accuracy, suggesting that the accuracy should be calculated after using a gender detection model in the pipeline. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concern about the choice of ELM and its impact on accuracy, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the choice of ELM (male/female) and its implications for accuracy, suggesting that the accuracy should be calculated after using a gender detection model in the pipeline. The comment provides a logical reasoning by questioning the need for prior knowledge of the speaker\"s gender and the potential drawbacks of this approach. However, it does not provide specific examples or references to support the claim, making it 3. The authors would need to consider the implications of this choice themselves, which could be clarified with additional evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a pertinent question about the choice of ELM (male/female) and its implications for accuracy. It suggests that the accuracy should be calculated after using a gender detection model in the pipeline, which could be a drawback if the speaker\"s gender is required for inference. This feedback is clear and actionable, as it prompts the authors to consider the implications of their choice and potentially address the issue by clarifying the methodology or providing additional context. However, the comment could be more helpful if it offered specific suggestions on how to address this concern or provided examples of similar approaches in the literature. Overall, the comment is 4 as it directs the authors to a critical area that requires further consideration and improvement."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment states that the writing is difficult to follow in many places and suggests simplification. However, it does not provide specific examples or guidance on how to simplify the writing, nor does it specify which parts of the paper are particularly challenging to follow. The action is implicit and vague, as the authors are left to infer that they need to simplify the writing but without concrete steps or examples to guide them. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment indicates that the writing is difficult to follow in many places and suggests simplification. However, it does not specify which parts of the paper are problematic or provide examples of where the writing is unclear. This lack of specificity and grounding makes it difficult for the authors to identify and address the issues effectively. The comment is 1 as it does not point to specific sections or elements of the paper, and it is not specific because it lacks detailed guidance on what needs to be simplified. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the writing is difficult to follow in many places and suggests simplification. However, it does not provide specific examples or detailed reasoning to support this claim. Without concrete evidence or examples of where the writing is unclear, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a general issue with the writing being difficult to follow in many places, suggesting that it could be simplified. However, it lacks specificity and does not provide detailed guidance or examples of where the writing is unclear or how it could be simplified. Without actionable suggestions or detailed feedback, the authors are left with a vague understanding of what needs to be improved. This limits the comment\"s usefulness, making it 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment states that the paper is incremental and lacks technical substance, merely adding a new loss to a previous work. However, it does not provide any explicit or implicit actions for the authors to take to improve their draft. There is no guidance on how to enhance the technical content or what specific changes could be made to add more value. As a result, the authors are left without any actionable steps to address the feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the paper for being incremental and lacking technical substance, specifically mentioning that it adds a new loss to a previous work (31). However, it does not specify which part of the paper this critique pertains to, such as a particular section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its critique of the paper\"s lack of technical substance, but without clear grounding, it is difficult for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is incremental and lacks technical substance, stating that it merely adds a new loss to a previous work. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment critiques the paper for being incremental and lacking technical substance, specifically mentioning that it adds a new loss to a previous work. However, it does not provide any specific suggestions or guidance on how the authors could enhance the technical content or originality of their work. Without actionable feedback or constructive criticism, the authors are left without a clear path for improvement. Therefore, the comment is 1, as it does not offer any value to the authors in terms of enhancing their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors provide an intuition for the proof of Theorem 1 and asks questions about the invertible function $f^*$ and its dependence on the fixed $P^*$. It also inquires about the practical implications of determining which $P^*$ to fix. While the comment implies that the authors should address these points, it does not explicitly instruct them to do so. The actions are implicit and somewhat vague, as the authors need to infer that they should provide additional explanations and address the questions raised. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear questions and suggestions for improvement, such as requesting an intuition for the proof of Theorem 1 and asking about the dependence of the invertible function $f^*$ on the fixed $P^*$. The comment also inquires about the practical implications of determining which $P^*$ to fix. This level of detail and specificity helps the authors understand what needs to be addressed in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a series of questions and suggestions, such as requesting an intuition for the proof of Theorem 1 and asking about the dependence of the invertible function $f^*$ on the fixed $P^*$. These questions are not claims but rather requests for clarification or additional information. Therefore, the comment is factual and does not contain any subjective claims or opinions that require verification. It is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors include an intuition for the proof of Theorem 1. It also raises questions about the dependence of the invertible function $f^*$ on the fixed $P^*$ and asks whether certain distributions $P^*$ make it easier to determine $f^*$. Additionally, it inquires about the practical implications of determining which $P^*$ to fix. These questions and suggestions are clear and offer the authors a path to enhance the clarity and depth of their work. However, the comment could be more helpful if it provided additional guidance on how to address these questions or offered specific examples. Overall, the feedback is 4 as it directs the authors to areas that need further elaboration, making it a valuable contribution to the review process."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the inconsistency in the use of variables in equations (7) and (10), specifically questioning why one uses \"X\" and the other \"H^(1).\" While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this inconsistency. The authors are left to infer that they need to clarify the rationale behind the variable choices or potentially revise the equations. However, the action is implicit and somewhat vague, as it lacks specific instructions on how to resolve the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eqs. (7) and (10),\" allowing the authors to accurately identify the specific parts of the paper being addressed. It also specifies the issue by questioning the inconsistency in the use of variables \"X\" and \"H^(1)\" in these equations. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the inconsistency in the use of variables in equations (7) and (10), specifically noting that one uses \"X\" and the other \"H^(1).\" This is a factual observation that does not contain an opinion, judgment, or suggestion requiring verification. It is a request for clarification, which is a normal statement and should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the inconsistency in the use of variables in equations (7) and (10), noting that one uses \"X\" and the other \"H^(1).\" This is a clear and actionable feedback that prompts the authors to clarify the rationale behind the variable choices, potentially leading to a more coherent and consistent presentation of the equations. However, the comment does not provide suggestions on how to address this inconsistency or offer broader insights into the paper\"s content. While it identifies a specific area for improvement, it lacks depth and comprehensive guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the applicability of the model to realworld diffusion processes, suggesting that the authors provide empirical evidence to support this claim. While the comment implies that the authors should include empirical evidence, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to conduct the empirical evaluation or what aspects of the model should be tested. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the applicability of the model to realworld diffusion processes, suggesting that the authors provide empirical evidence to support this claim. However, it does not specify which part of the paper this concern pertains to, such as the methodology, results, or discussion sections. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing revision. The comment is specific in its request for empirical evidence but lacks grounding, as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the applicability of the model to realworld diffusion processes, suggesting that the authors provide empirical evidence to support this claim. However, the comment does not provide specific examples, references, or detailed reasoning to substantiate why the model might not be applicable in realworld scenarios. This lack of supporting evidence or detailed justification makes the claim 3, as the authors would need to infer the basis of the concern and develop their own evidence to address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical concern regarding the applicability of the model to realworld diffusion processes. It acknowledges the novelty and elegance of the proposed solutions but suggests that the authors provide empirical evidence to support the claim that the model captures the diffusion phenomena in realworld scenarios. This feedback is clear and actionable, as it directs the authors to address a specific area of concern that could significantly impact the practical relevance of their work. However, the comment could be more helpful if it provided guidance on how to conduct the empirical evaluation or what specific aspects of the model should be tested. Overall, the comment is 4, as it effectively points out a critical area for improvement and provides a clear direction for the authors to enhance their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "1", "actionability_rationale": "The review point states that the main contribution of combining attention with other linear mechanisms is not novel and that many alternatives exist, as noted in the paper. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue of nonnovelty or what specific alternatives should be considered. The comment lacks actionable advice, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the main contribution of the paper, which is the combination of attention with other linear mechanisms. However, it does not specify which part of the paper discusses this contribution, making it weakly grounded. The comment is specific in pointing out that the contribution is not novel and that alternatives exist, as noted in the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the main contribution of combining attention with other linear mechanisms is not novel, and it references the paper itself, noting that many alternatives exist. However, the comment does not provide specific examples or detailed reasoning to support the claim of nonnovelty. The reference to \"many alternatives\" is vague and lacks concrete evidence or references to substantiate the claim. This makes the comment 3, as it provides a general direction but lacks the necessary details for full verification.", "helpfulness_rationale": "The review comment points out that the main contribution of combining attention with other linear mechanisms is not novel, as noted in the paper itself. However, it does not provide any actionable feedback or suggestions for improvement. The comment lacks depth and does not offer any guidance on how the authors might address the issue of nonnovelty or explore alternative contributions. As a result, the comment is 1, as it does not provide the authors with any actionable insights or direction for enhancing their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the novelty of the paper, specifically mentioning that the ENCODE part is already proposed in 10 and that the incremental contribution lies in the decomposition part, which factorizes M_v into D and Phi_v. However, the comment does not provide any explicit or implicit actions for the authors to take in response to this critique. It lacks guidance on how the authors might address the perceived lack of novelty or improve their contribution. Without actionable suggestions or a clear direction for improvement, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the novelty of the paper, specifically mentioning the ENCODE part and the incremental contribution in the decomposition part. However, it does not specify which part of the paper these aspects are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its critique of the novelty, but it lacks grounding as it does not clearly identify the parts of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the novelty of the paper is limited, specifically mentioning that the ENCODE part is already proposed in 10 and that the incremental contribution lies in the decomposition part. However, the comment does not provide any references or detailed reasoning to support this claim, such as comparing the proposed method to the existing work in 10 or explaining how the decomposition part differs from previous approaches. Without specific evidence or detailed comparison, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment critiques the novelty of the paper, specifically pointing out that the ENCODE part is already proposed in 10 and that the incremental contribution lies in the decomposition part, which factorizes M_v into D and Phi_v. While the comment identifies a potential weakness in the paper\"s originality, it lacks depth and does not provide actionable suggestions for improvement. It does not offer guidance on how the authors might enhance the novelty or originality of their work, nor does it suggest ways to differentiate their contribution from existing literature. As a result, the comment is 3, as it highlights an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance comparison of the CLN (region proposal generation algorithm) proposed by A. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should conduct a performance comparison, how to do it, or what specific aspects should be considered. The comment lacks actionable details, leaving the authors uncertain about how to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the performance comparison of the CLN (region proposal generation algorithm) proposed by A. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the performance comparison are being questioned or how it should be conducted. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point consists of a question asking for a performance comparison with the CLN (region proposal generation algorithm) proposed by A. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for additional information or clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the performance comparison of the CLN (region proposal generation algorithm) proposed by A. While it identifies a potential area for improvement by suggesting a performance comparison, it lacks specificity and does not provide guidance on how to conduct such a comparison or what aspects should be considered. The comment is 3 as it points out a gap in the paper but does not offer actionable advice or detailed suggestions for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a specific issue with the presentation, noting that it is too equationdriven and that the notation in Chapter 3 is convoluted and hard to follow. It suggests that an illustrative figure of the key concepts in Section 3 would be helpful. While the comment implies that the authors should consider adding such a figure, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a figure and determine what specific concepts should be illustrated. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"chapter 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the presentation, noting that it is too equationdriven and that the notation is convoluted, making it hard to follow. The suggestion to include an illustrative figure of key concepts in section 3 is clear and provides a specific direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the presentation is too equationdriven and that the notation in Chapter 3 is convoluted, making it hard to follow. The suggestion to include an illustrative figure of key concepts in Section 3 is a logical recommendation to improve clarity. However, the comment lacks specific examples or detailed reasoning to support the claim that the notation is particularly challenging. This makes the claim 3, as it provides a general direction for improvement but lacks the depth needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation, noting that it is too equationdriven and that the notation, particularly in Chapter 3, is convoluted and hard to follow. It suggests that an illustrative figure of key concepts in Section 3 would be helpful. This feedback is clear and actionable, providing the authors with a specific direction for improving the clarity and accessibility of their work. By suggesting a visual aid, the comment offers a concrete way to enhance the readability and understanding of the content. However, it could be more helpful if it provided additional guidance on which specific concepts should be illustrated or how the figure should be structured. Overall, the comment is 4 as it effectively guides the authors toward improving the presentation of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the visual presentation of data in Figure 3 could be improved for better readability and aesthetic appeal, specifically mentioning the subscripts. However, it does not provide explicit guidance on how to enhance the visual presentation or what specific changes should be made. The action is implicit and somewhat vague, as the authors can infer that they need to improve the visual presentation but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular aspect of the visual presentation, namely the subscripts, and suggests that they could be improved for better readability and aesthetic appeal. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point claims that the visual presentation of data in Figure 3 could be improved for better readability and aesthetic appeal, specifically mentioning the subscripts. However, the comment does not provide any specific examples or detailed reasoning to support why the current presentation is inadequate or how it could be improved. Without additional context or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2, as it lacks sufficient evidence or explanation to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the visual presentation of data in Figure 3, noting that the subscripts could be improved for better readability and aesthetic appeal. This feedback is 3 as it points out a potential area for enhancement, which could improve the overall clarity and impact of the figure. However, the comment lacks detailed guidance or suggestions on how to enhance the visual presentation, such as proposing specific changes to the subscripts or offering examples of better practices. While it highlights an area for improvement, the feedback could be more actionable and comprehensive to be fully helpful. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the technical details and formulations are limited, suggesting that the main novelty lies in the scheme or procedure. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to enhance the technical details or formulations, nor is there a suggestion on how to clarify the novelty of the scheme or procedure. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions \"technical details and formulations\" as being limited, suggesting that the main novelty lies in the scheme or procedure. However, it does not specify which parts of the paper these details are lacking in, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in identifying the issue of limited technical details and formulations, but it lacks grounding as it does not explicitly mention a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the technical details and formulations are limited, suggesting that the main novelty lies in the scheme or procedure. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed justification or evidence, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a limitation in the technical details and formulations of the paper, suggesting that the main novelty lies in the scheme or procedure. However, it does not provide specific guidance or suggestions on how the authors might enhance these details or clarify the novelty. Without actionable feedback or examples, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the process of updating archetype positions after initialisation in Algorithm 2. It explicitly requests the authors to provide a comment on this aspect, which is a clear and direct action. The comment provides a specific area for clarification, making it easy for the authors to understand what needs to be addressed. Therefore, this comment is 5, as it gives the authors a clear direction on how to improve their draft by providing additional information.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of the unclear process of updating archetype positions after initialisation. The comment requests clarification on this aspect, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the process of updating archetype positions after initialisation in Algorithm 2. It does not contain any subjective claims, opinions, or suggestions that require verification. It is a factual question seeking clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the process of updating archetype positions after initialisation in Algorithm 2. It requests clarification from the authors, which is a clear and actionable suggestion for improvement. By addressing this point, the authors can enhance the clarity and comprehensibility of their work. However, the comment could be more helpful if it provided additional context or examples to guide the authors in their response. Overall, the feedback is 4 as it directs the authors to a critical area needing clarification, but it could be more comprehensive with further guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies several areas where additional information is missing from the empirical study, such as recording parameters for MRI, preprocessing steps, restingstate recording conditions, and a brief explanation of the harmonization technique. It also suggests mentioning the number of regions in the parcellation in the main text. These explicit requests provide clear and concrete actions for the authors to take, ensuring they know exactly what information to include in their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"empirical study\" and \"supplement,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details what information is missing, such as recording parameters for MRI, preprocessing steps, restingstate recording conditions, a brief explanation of the harmonization technique, and the number of regions in the parcellation. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of factual statements requesting additional information to be included in the supplement, such as recording parameters for MRI, preprocessing steps, restingstate recording conditions, and a brief explanation of the harmonization technique. It also suggests mentioning the number of regions in the parcellation in the main text. These are requests for clarification or additional details, which do not contain subjective opinions, judgments, or suggestions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies several important pieces of information that are missing from the empirical study, such as recording parameters for MRI, preprocessing steps, restingstate recording conditions, and a brief explanation of the harmonization technique. It also suggests mentioning the number of regions in the parcellation in the main text. These specific requests for additional information are clear and actionable, providing the authors with concrete steps to enhance the comprehensiveness and clarity of their study. By addressing these points, the authors can improve the transparency and rigor of their work. Therefore, the comment is 4, as it offers detailed and actionable feedback that can significantly benefit the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a contradiction between the statement in lines 4748 and the observation that overparameterization is beneficial for supervised learning of deep neural networks in practice. It also mentions theoretical works supporting the benefits of overparametrization. However, the comment does not provide specific guidance on how the authors should address this contradiction or integrate the theoretical works into their paper. The action is implicit and somewhat vague, as the authors are left to infer that they need to reconcile the conflicting statements and potentially include references to the theoretical works. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (4748) in the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it points out a contradiction between the statement about overparametrization and the observation that it is beneficial for supervised learning. Additionally, the comment provides a reference to theoretical works supporting the benefits of overparametrization, which further specifies the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a contradiction between the statement in lines 4748 and the observation that overparameterization is beneficial for supervised learning. It supports this claim by referencing theoretical works that demonstrate the benefits of overparametrization. However, the comment does not provide specific references to these theoretical works, which would strengthen the verifiability of the claim. While the mention of theoretical works provides some support, the lack of detailed references or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential contradiction in the paper regarding the statement that overparametrization leads to worse performance, while also noting that overparametrization is beneficial for supervised learning in practice. It provides a reference to theoretical works supporting the benefits of overparametrization, which could be helpful for the authors to address this contradiction. However, the comment could be more helpful if it offered specific suggestions on how to reconcile these conflicting statements or integrate the theoretical works into the paper. Overall, the comment is 3 as it points out an important issue but lacks detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the timeconsuming nature of the shape model training, which is trained in pixel level despite sparsity by landmarks, and the independent training on all font images and characters. It also mentions the highorder factor graph of the parsing model with four types of factors. The comment suggests that the processing efficiency of training and testing should be described and compared with existing work. While the comment identifies areas for improvement, it does not provide specific guidance on how to address these issues or what aspects of processing efficiency should be described or compared. The action is implicit and somewhat vague, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"shape model\" and \"parsing model,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the timeconsuming nature of the training process due to the pixellevel training of the shape model and the independent training on all font images and characters. Additionally, it suggests that the processing efficiency of training and testing should be described and compared with existing work. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the shape model training is timeconsuming due to its pixellevel training and independent training on all font images and characters. It also mentions the highorder factor graph of the parsing model with four types of factors. However, the comment lacks specific evidence or references to support these claims, such as comparisons with existing work or detailed explanations of the timeconsuming aspects. Without such evidence, the claim remains 3, as the authors would need to investigate and substantiate the claims themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas that could be improved in the paper. It points out the timeconsuming nature of the shape model training, which is trained in pixel level despite sparsity by landmarks, and the independent training on all font images and characters. It also mentions the highorder factor graph of the parsing model with four types of factors, suggesting that the processing efficiency of training and testing should be described and compared with existing work. This feedback is clear and actionable, as it highlights specific aspects of the methodology that could be improved and provides a direction for further analysis. However, the comment could be more helpful if it included specific suggestions on how to optimize the training process or references to existing work for comparison. Overall, the comment is 4, as it provides valuable insights for the authors to enhance their draft."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to include a discussion on the prompt dataset creation and its source for the fewshot case. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific area for enhancement, making it 5. The authors know exactly what needs to be added to their draft, and the feedback is concrete in its guidance. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that a discussion on the prompt dataset creation and its source for the fewshot case should be included. However, it does not specify which part of the paper this discussion should be added to, making it weakly grounded. The comment is specific in its request for a discussion on the prompt dataset and its source, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that a discussion on the prompt dataset creation and its source should be included. However, it does not provide any reasoning, examples, or references to support why this discussion is necessary or how it would enhance the paper. Without additional context or justification, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors include a discussion on the prompt dataset creation and its source for the fewshot case. This feedback is clear and actionable, as it directs the authors to a particular aspect of their work that could benefit from further elaboration. By addressing this suggestion, the authors can enhance the comprehensiveness and clarity of their paper. However, the comment could be more helpful if it provided additional context or examples on how this discussion might be structured or what specific details should be included. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that an ablation study on the weighting method of the crossentropy loss would be beneficial. It provides a specific example of a scenario where the weighting method might have helped, such as in the Atlantis game where repetitive background sounds could be addressed. While the comment implies that the authors should conduct this ablation study, it does not explicitly instruct them to do so. The action is concrete but implicit, as the authors can infer the need for an ablation study based on the suggestion. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment suggests conducting an ablation study on the weighting method of the crossentropy loss and provides a specific example from the Atlantis game, where repetitive background sounds could be addressed. However, it does not explicitly mention which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. The comment is specific in suggesting the ablation study and providing a scenario where it might be beneficial. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that an ablation study on the weighting method of the crossentropy loss would be beneficial, particularly in scenarios like the Atlantis game where repetitive background sounds could be addressed. The reviewer provides a specific example of a scenario where the weighting method might have helped, which adds some level of justification to the claim. However, the comment lacks detailed reasoning or references to support the claim that the weighting method would be beneficial in general. While the suggestion is logical, it requires more evidence or examples to be 5. Therefore, the comment is 3.", "helpfulness_rationale": "The review comment suggests conducting an ablation study on the weighting method of the crossentropy loss, which is a specific and actionable recommendation. It provides a concrete example from the Atlantis game, where repetitive background sounds could be addressed using the weighting method, which adds context and relevance to the suggestion. This feedback is clear and provides a clear direction for the authors to improve their draft by exploring the impact of different weighting methods on their model\"s performance. However, the comment could be more helpful if it included additional guidance on how to conduct the ablation study or what specific aspects to focus on. Overall, the comment is 4 as it offers a clear path for improvement but could be more comprehensive with further guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a critical weakness in the paper, namely the lack of novelty and incremental nature of the work. It points out that the paper addresses a particular problem of column operations in designing semantic parsers for TexttoSQL and that it designs a new dataset, which is a different train/test split of an existing dataset SQUALL. The comment also mentions another synthetic benchmark paper that is based on a single question template. However, the comment does not provide any explicit or implicit actions for the authors to take to address these issues. It lacks guidance on how the authors might enhance the novelty or incremental nature of their work, or how they could improve their dataset design. Without actionable suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a critical weakness in the paper, specifically the lack of novelty and incremental nature of the work. It provides specific details about the paper\"s focus on column operations in designing semantic parsers for TexttoSQL and the creation of a new dataset, which is a different train/test split of an existing dataset SQUALL. Additionally, it mentions another synthetic benchmark paper based on a single question template. However, the comment does not explicitly mention which part of the paper these issues are discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. The comment is specific in detailing the issues with novelty and incremental nature, providing a clear understanding of what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks novelty and is incremental in nature, specifically mentioning the use of a different train/test split of an existing dataset SQUALL. It also references another synthetic benchmark paper based on a single question template. However, the comment does not provide specific examples or detailed reasoning to support the claim of lack of novelty, making it difficult for the authors to understand the basis of the critique. The lack of detailed justification or references makes the claim 3, as the authors would need to invest effort to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical weakness in the paper, specifically the lack of novelty and incremental nature of the work. It points out that the paper addresses a particular problem of column operations in designing semantic parsers for TexttoSQL and that it designs a new dataset, which is a different train/test split of an existing dataset SQUALL. The comment also mentions another synthetic benchmark paper based on a single question template. While the comment highlights an important issue, it lacks specific suggestions or guidance on how the authors might address these concerns or enhance the novelty of their work. Without actionable feedback, the authors are left with a general understanding of the problem but without a clear path to improvement. Therefore, the comment is 3, as it provides insight into a significant weakness but lacks depth and actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to explain why removing certain assumptions, such as bounded variance and bounded gradients, is an important contribution. It suggests that this explanation should be supported by solid examples. This feedback provides a clear and direct action for the authors to take, specifying both what needs to be done (explaining the importance of removing these assumptions) and how to do it (using solid examples). The explicit nature of the instruction and the concrete guidance on how to implement it make this comment 5.", "grounding_specificity_rationale": "The comment suggests that the authors need to explain why removing certain assumptions, such as bounded variance and bounded gradients, is an important contribution. However, it does not specify which part of the paper this explanation should be included in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the importance of removing these assumptions and the need for solid examples to support this claim. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors need to explain why removing certain assumptions, such as bounded variance and bounded gradients, is an important contribution. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why these assumptions are significant or how their removal impacts the contribution of the paper. Without such support, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the authors need to provide more explanation and justification. It highlights the importance of removing certain assumptions, such as bounded variance and bounded gradients, and suggests that this should be supported by solid examples. This feedback is clear and actionable, as it directs the authors to enhance their contribution by providing a rationale for the significance of these assumptions and how their removal impacts the study. However, the comment could be more helpful if it offered suggestions on how to present these examples or provided additional context. Overall, the comment is 4 as it guides the authors toward improving their draft by addressing a critical aspect of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection. It suggests that labeled data could provide effective information for consistency training, but it does not explicitly instruct the authors to conduct this experiment or provide specific guidance on how to implement it. The comment implies an action by questioning the current approach and suggesting a potential improvement, but it lacks concrete details on how to execute this suggestion. Therefore, the comment is 3, as the authors can infer the need for further exploration but are not given explicit instructions on how to proceed.", "grounding_specificity_rationale": "The comment raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection. It suggests that labeled data could provide effective information for consistency training, but it does not specify which part of the paper this suggestion pertains to. The authors can infer that it relates to the methodology or experimental sections, but without explicit references, the comment is weakly grounded. However, it is specific in suggesting a potential improvement by utilizing labeled data for consistency training. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection. It suggests that labeled data could provide effective information for consistency training, but this claim is not fully supported by the provided references. The references are relevant to graph contrastive learning, but they do not directly address the specific question of using labeled data for consistency training. The comment lacks detailed reasoning or examples to fully substantiate the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection. It suggests that labeled data could provide effective information for consistency training, which might enhance the model\"s ability to deal with the task of graph anomaly detection. However, the comment does not provide specific guidance or suggestions on how to implement this idea or what specific aspects of the labeled data could be leveraged for consistency training. While it identifies a potential area for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is 3, as it provides a direction for exploration but lacks actionable steps for the authors to follow."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the experimental section needs to be reorganized and improved to better highlight the superiority of the method. It implies that the authors should restructure the experimental content in the main text to better showcase the advantages of their method. However, the comment does not provide specific guidance on how to reorganize the content or what changes should be made to improve the experimental section. While the action is implicit, it lacks concrete details on how to implement the suggested changes, making it 3.", "grounding_specificity_rationale": "The comment suggests that the experimental section needs to be reorganized and improved to better highlight the superiority of the method. It mentions that the current content does not effectively showcase the method\"s advantages, implying that the authors should restructure the experimental content. However, the comment does not specify which parts of the experimental section need reorganization or improvement, nor does it provide specific examples or suggestions for how to enhance the content. This lack of detail makes it difficult for the authors to pinpoint the exact areas needing attention. Therefore, the comment is weakly grounded as it does not identify a specific part of the paper, and it is not specific in detailing what needs to be addressed. As a result, the comment aligns with a score of 2.", "verifiability_rationale": "The review point suggests that the experimental section needs to be reorganized and improved to better highlight the superiority of the method. However, it does not provide specific examples or detailed reasoning to support this claim. The comment lacks concrete evidence or references to justify why the current organization is ineffective or how it could be improved. Without such details, the authors may find it challenging to understand and address the feedback effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental section, noting that it lacks clarity in highlighting the superiority of the method. It suggests that the experimental content should be reorganized to better showcase the advantages of the method. However, the comment does not provide detailed guidance or examples on how to reorganize the content or what specific aspects should be emphasized. While it points out a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides some direction but lacks depth and specificity."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the feasibility of implementing and testing concrete predictions based on the argument that recognition lists are recalled based on items. However, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve their approach. The comment lacks actionable details, such as recommending specific changes or experiments to test the feasibility of the proposed method. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper related to the argument that recognition lists are recalled based on items. However, it does not specify which part of the paper this argument is discussed in, making it weakly grounded. The comment provides some specificity by questioning the feasibility of implementing and testing concrete predictions based on this argument, but it lacks detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a claim about the feasibility of implementing and testing concrete predictions based on the argument that recognition lists are recalled based on items. The reviewer provides a logical reasoning by explaining that in the most common case of recognition, new items comprise the list of all items available in memory (minus the ones seen), and it is challenging to see how such an exhaustive list could be effectively implemented. This reasoning is based on common knowledge about memory processes and the limitations of exhaustive lists. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is 3, as it provides a logical basis but lacks detailed evidence or references.", "helpfulness_rationale": "The review comment raises a concern about the feasibility of implementing and testing concrete predictions based on the argument that recognition lists are recalled based on items. It provides a logical reasoning by explaining that in the most common case of recognition, new items comprise the list of all items available in memory (minus the ones seen), and it is challenging to see how such an exhaustive list could be effectively implemented. This feedback highlights a potential limitation in the approach and prompts the authors to consider the practicality of their method. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of alternative approaches. As it stands, the comment is 3 as it identifies a critical area for improvement but lacks detailed guidance. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should consider using better metadata embeddings for their zeroshot learning results on the CUB dataset. It references a specific paper, \"Learning Deep Representations of FineGrained Visual Descriptions, Reed et al, CVPR 2016,\" and suggests that the performance of the proposed method could be improved with better metadata embeddings. The comment explicitly instructs the authors to update their results with these improved embeddings, providing a clear and concrete action to take. The reference to a specific paper and the suggestion for improvement make the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3 page 7\" and \"attribute,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a suggestion for improvement by recommending the use of better metadata embeddings, referencing a specific paper and table for comparison. The comment also includes a request for the authors to update their results with these improved embeddings. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the metadata used for zeroshot learning on the CUB dataset, as presented in Table 3 on page 7, is \"attribute.\" The reviewer acknowledges that this choice is good for fair comparison but notes that better metadata embeddings are available, referencing a specific paper and table. The suggestion to explore the performance of the proposed method with better metadata embeddings is logical and provides a clear direction for improvement. However, the comment could be strengthened by including more detailed reasoning or examples from the referenced paper. Overall, the claim is 4, as it provides a logical basis for improvement but lacks comprehensive evidence or detailed examples.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the paper. It identifies a potential weakness in the choice of metadata embeddings for zeroshot learning on the CUB dataset, noting that better options are available. The reviewer references a specific paper and table that could be used for comparison, offering a clear direction for the authors to enhance their results. Additionally, the comment includes a request for the authors to update their results with these improved embeddings, which is a concrete step toward improving the paper. This feedback is detailed and constructive, making it 5 for the authors in refining their work. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the reasonableness of the German and Law school dataset having shorter training time in Gerrymandering compared to Independent. It also suggests that since the performance of ERM and plugin is similar to Kearns et al. in Experiment 2, the main advantage is computation time, it would be beneficial to have the code published. While the comment implies that the authors should address the discrepancy in training times and consider publishing the code, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the issue or what aspects of the code should be published. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the experiments\" and \"the German and Law school dataset,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a question about the reasonableness of the training time discrepancy between the German and Law school dataset and Independent, and suggests that the main advantage of ERM and plugin is their computation time. The comment further suggests that publishing the code would be beneficial. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the reasonableness of the German and Law school dataset having shorter training time in Gerrymandering compared to Independent. It also suggests that since the performance of ERM and plugin is similar to Kearns et al. in Experiment 2, the main advantage is computation time, it would be beneficial to have the code published. The comment provides a logical reasoning by comparing the performance of different methods and suggesting that the code should be published to support the claim. However, it lacks specific references or detailed explanations to fully substantiate the claim about the training time discrepancy. Therefore, the comment is 3, as it provides a logical basis but requires more detailed evidence to be 5.", "helpfulness_rationale": "The review comment raises a question about the reasonableness of the German and Law school dataset having shorter training time in Gerrymandering compared to Independent. It also suggests that since the performance of ERM and plugin is similar to Kearns et al. in Experiment 2, the main advantage is computation time, it would be beneficial to have the code published. This feedback is 3 as it points out a potential inconsistency in the experimental results and suggests a way to address it by publishing the code. However, the comment could be more helpful if it provided specific guidance on how to analyze or interpret the training time discrepancy or if it offered suggestions on how to improve the presentation of the results. Overall, the comment provides some direction for improvement but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a concern about the assumption for termination states of instructions, noting that it is expensive to label a large number of data manually. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting alternative methods or strategies for labeling data. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the assumption for termination states of instructions, which implies that it relates to the methodology or experimental setup. However, it does not specify which part of the paper discusses these assumptions, making it weakly grounded. The comment is specific in pointing out the issue with the assumption, noting that labeling a large number of data manually is expensive. This provides some guidance on what needs to be addressed, but without explicit references to sections or specific elements, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the assumption for termination states of instructions is strong and that labeling a large number of data manually is expensive. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 2, as it provides some insight but requires more detailed justification to be fully actionable.", "helpfulness_rationale": "The comment identifies a potential issue with the assumption for termination states of instructions, noting that it may be expensive to label a large number of data manually. However, it does not provide any suggestions or guidance on how the authors might address this issue or improve their methodology. Without actionable feedback or specific recommendations, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the nature of the contribution with respect to ECE_sweep is not clearly described in the text. It provides a concrete explanation of what the contribution amounts to, which is a way to choose the number of bins using data (i.e., autotuning a hyperparameter in the estimate). The reviewer suggests that the paper should be upfront about the contribution, indicating that the authors should clarify this aspect. While the comment provides a clear action, it does not offer specific guidance on how to present the contribution more clearly. Therefore, the comment is 4, as it identifies a specific issue and suggests a direction for improvement but lacks detailed instructions on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ECE_sweep,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what is missing in the text, namely, a clear description of the contribution with respect to ECE_sweep. The comment explains that the contribution amounts to a way to choose the number of bins using data, which is not fundamentally different from existing estimators. It suggests that the paper should be upfront about its contribution, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the nature of the contribution with respect to ECE_sweep is not clearly described in the text. The reviewer provides a concrete explanation of what the contribution amounts to, which is a way to choose the number of bins using data (i.e., autotuning a hyperparameter in the estimate). However, the comment does not provide specific references or examples to support the claim that this is not fundamentally different from existing estimators. While the reasoning is logical, the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks clarity, namely, the description of the contribution with respect to ECE_sweep. It provides a concrete explanation of what the contribution amounts to, which is a way to choose the number of bins using data (i.e., autotuning a hyperparameter in the estimate). The reviewer suggests that the paper should be upfront about its contribution, which would help readers understand the novelty and significance of the work. This feedback is clear and actionable, as it directs the authors to clarify their contribution and improve the clarity of their text. However, the comment could be more helpful if it offered specific suggestions on how to present the contribution more effectively. Overall, the comment is 4, as it provides valuable guidance for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential ambiguity in the paper regarding the use of the term \"Efficient Proxy.\" The reviewer suggests that the authors clarify whether they are referring to a specific proxy or a family of proxies. While the comment identifies a specific issue with the terminology, it does not provide explicit guidance on how to address this ambiguity. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the terminology and potentially provide examples or definitions to avoid confusion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the clarity of the term \"Efficient Proxy\" in the paper. It suggests that the authors need to clarify whether they are referring to a particular proxy or a family of proxies. However, it does not specify which part of the paper this ambiguity occurs in, making it weakly grounded. The comment is specific in detailing the issue with the terminology, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact location of the ambiguity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the clarity of the term \"Efficient Proxy\" in the paper. The reviewer suggests that the use of \"is\" implies a specific proxy, but the absence of a proxy named \"Efficient Proxy\" suggests it refers to a family of proxies. This comment highlights a potential ambiguity in the paper, but it does not provide specific examples or references to support the claim. The reasoning is logical but lacks detailed evidence or examples, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential ambiguity in the paper regarding the term \"Efficient Proxy.\" It points out that the use of \"is\" suggests a specific proxy, but the absence of a proxy named \"Efficient Proxy\" implies a family of proxies. This feedback highlights a specific area where the authors need to clarify their terminology to avoid confusion. While the comment effectively identifies a problem, it does not provide detailed guidance on how to resolve the ambiguity or suggest alternative phrasing. Therefore, the comment is 3, as it directs the authors to a specific area for improvement but lacks comprehensive guidance. It aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point describes the methods used in the paper, specifically mentioning the stacking of methods from Mirzasoleiman et al., 2020 and the Grouplearning setting, followed by the use of a classical method DBSCAN for clustering. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether this stacking is appropriate, if it should be modified, or if additional methods should be considered. Without any actionable suggestions or questions, the authors are left without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the stacking of methods from Mirzasoleiman et al., 2020 and the Grouplearning setting, followed by the use of a classical method DBSCAN for clustering. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it details the methods being used and the stacking approach, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point describes the methods used in the paper, specifically mentioning the stacking of methods from Mirzasoleiman et al., 2020 and the Grouplearning setting, followed by the use of a classical method DBSCAN for clustering. However, it does not express an opinion, make a claim, or suggest any changes. It is purely descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment provides a factual description of the methods used in the paper, specifically mentioning the stacking of methods from Mirzasoleiman et al., 2020 and the Grouplearning setting, followed by the use of a classical method DBSCAN for clustering. However, it does not offer any critique, suggestion, or feedback on the effectiveness or appropriateness of these methods. Without any actionable advice or guidance, the comment does not help the authors improve their draft. Therefore, it is rated as 1, aligning with a score of 1."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the model is overly simple, which is both a feature and a bug. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to make the model more complex or what specific aspects need improvement. Without actionable suggestions or concrete steps, the authors are left without a clear understanding of how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the model is overly simple, which is both a feature and a bug. However, it does not specify which part of the paper this assessment is based on, such as a particular model description or section. Without explicit references to specific sections or models, the authors cannot confidently determine which part of the paper the comment addresses. Additionally, the comment lacks specificity regarding what aspects of the model are considered overly simple or how this simplicity could be a bug. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the model is overly simple, which is both a feature and a bug. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why the model is considered overly simple. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment suggests that the model is overly simple, which is both a feature and a bug. However, it lacks specificity and does not provide any actionable feedback or suggestions for improvement. Without detailed guidance on how to address the simplicity or what aspects of the model need to be enhanced, the authors are left without a clear understanding of how to improve their draft. This makes the comment 2, as it identifies a potential issue but does not offer meaningful guidance for resolution."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should briefly mention the negligible computational cost of CHR, which is currently only discussed in the appendix, in the main paper. It also recommends providing a rough example of runtimes in the experiments to help readers interested in applying the method. While the comment implies that the authors should include this information, it does not explicitly instruct them to do so. The action is concrete in terms of what needs to be done, but it is implicit in the phrasing. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment suggests that the authors should mention the negligible computational cost of CHR, which is currently discussed only in the appendix, in the main paper. It also recommends providing a rough example of runtimes in the experiments to help readers interested in applying the method. While the comment does not explicitly mention a specific section or part of the paper, it implies that the authors should consider including this information in the main text. The suggestion is specific in terms of what needs to be addressed, but the lack of explicit grounding makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should mention the negligible computational cost of CHR, which is currently discussed only in the appendix, in the main paper. It also recommends providing a rough example of runtimes in the experiments to help readers interested in applying the method. The comment provides a logical reasoning for why this information should be included, as it can help motivate the method and aid readers in understanding its applicability. However, it does not provide specific examples or references to support the claim about the negligible computational cost, which would strengthen the justification. Therefore, the comment is 3, as it provides a clear rationale but lacks detailed evidence or examples.", "helpfulness_rationale": "The review comment suggests that the authors should briefly mention the negligible computational cost of CHR, which is currently discussed only in the appendix, in the main paper. This is a logical suggestion as it can help motivate the method and make it more accessible to readers. Additionally, the comment recommends providing a rough example of runtimes in the experiments, which could be beneficial for readers interested in applying the method. While the feedback is clear and actionable, it could be more helpful if it included specific examples or detailed guidance on how to present the computational cost information. Overall, the comment is 4 as it provides valuable insights for improving the paper, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the authors use the complexity of checking on the Witness oracle, which is polynomial time in the tabular case, as a way to address the problem. However, it suggests that this approach is not direct enough. While the comment implies that the authors should find a more direct way to address the problem, it does not provide specific guidance or suggestions on how to achieve this. The action is implicit and somewhat vague, as the authors are left to infer that they need to find a more direct solution but without concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the authors\" use of the complexity of checking on the Witness oracle, which is described as \"polynomial time\" in the tabular case. However, it does not specify which part of the paper this discussion is located in, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, while the comment suggests that the approach is not direct enough, it does not provide specific guidance on how to address this issue or what alternative methods could be considered. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the authors\" approach to addressing the problem is not direct enough, specifically mentioning the complexity of checking on the Witness oracle. However, the comment lacks specific reasoning or examples to support this claim, such as comparing it to alternative methods or providing a more direct approach. Without detailed justification or references, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a potential issue with the authors\" approach to addressing the problem, specifically noting that using the complexity of checking on the Witness oracle as a solution feels indirect. However, the comment does not provide specific suggestions or guidance on how the authors could address this issue or improve their approach. Without actionable feedback or detailed insights, the authors are left without a clear path to enhance their draft. Therefore, the comment is 2, as it identifies a potential weakness but lacks depth and actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should include additional baselines for code completion tasks. It recommends comparing with existing code completion commercial applications, such as Copilot, and testing them on a smaller subset of RepoEval. This feedback provides a clear and concrete action for the authors to take, specifying both the type of baselines to include and how to test them. The explicit nature of the suggestion and the detailed guidance on implementation make this comment 5.", "grounding_specificity_rationale": "The comment suggests including additional baselines for code completion tasks, specifically mentioning Copilot as a commercial application to compare with. It also recommends testing these baselines on a smaller subset of RepoEval. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the experimental setup or results section. The suggestion is specific in terms of what baselines to include and how to test them, providing clear guidance for improvement. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests including additional baselines for code completion tasks, specifically mentioning Copilot as a commercial application to compare with. The reviewer provides a logical reasoning for the suggestion, stating that it is essential to compare with stateoftheart code completion systems. However, the comment lacks specific examples or references to support the claim that Copilot is a relevant baseline or how it compares to other existing systems. This makes the claim 3, as it provides a general direction but lacks detailed evidence or examples to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors include additional baselines for code completion tasks. It recommends comparing with existing code completion commercial applications, such as Copilot, and testing them on a smaller subset of RepoEval. This feedback is clear and actionable, providing the authors with a concrete suggestion to enhance the comprehensiveness and validity of their experimental evaluation. By including these additional baselines, the authors can better position their work in relation to stateoftheart code completion systems, which is crucial for the credibility and impact of their research. However, the comment could be more helpful if it provided specific guidance on how to implement the comparison or what metrics to use. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a lack of clarity in the introduction, specifically regarding the modelling of curves, which are presumably related to tumour growth. However, it does not provide explicit guidance on how to address this issue or suggest specific changes that could improve clarity. The action is implicit, as the authors can infer that they need to clarify the context of the modelling, but it lacks concrete details on how to do so. Therefore, the comment is 3, as it identifies an area for improvement but does not provide detailed guidance on how to implement the suggested changes.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"second paragraph\" of the introduction, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of clarity regarding what is being modelled, particularly in relation to tumour growth. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the second paragraph in the introduction discusses modelling curves but does not make it immediately clear what is being modelled. The reviewer infers that it is related to tumour growth, but this inference is not explicitly stated in the paper. The comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the introduction, noting that the second paragraph discusses modelling curves but does not clarify what is being modelled, presumably tumour growth. This feedback is 3 as it points out a lack of clarity in the introduction, which could be addressed by providing more context or explanation. However, the comment does not offer specific suggestions or guidance on how to improve the clarity, such as recommending additional examples or explanations. While it highlights an area for improvement, the lack of detailed feedback limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance of the shiftedMNIST dataset, specifically why shift=0 performs better than shift~N(0,\u03c32). It suggests that the performance of the model and baselines should be shown on test samples from the observational (in) distribution. While the comment implies that the authors should provide additional analysis or results, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to conduct the analysis or what aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"shiftedMNIST,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the performance of shift=0 compared to shift~N(0,\u03c32) and suggesting that the performance of the model and baselines should be shown on test samples from the observational (in) distribution. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the performance of the shiftedMNIST dataset, specifically why shift=0 performs better than shift~N(0,\u03c32). It suggests that the performance of the model and baselines should be shown on test samples from the observational (in) distribution. While the comment questions the reasoning behind the results, it does not provide specific evidence or references to support the claim. The lack of detailed reasoning or examples makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered 2, as it requires more detailed justification to be 5.", "helpfulness_rationale": "The review comment raises a question about the performance of the shiftedMNIST dataset, specifically why shift=0 performs better than shift~N(0,\u03c32). It suggests that the performance of the model and baselines should be shown on test samples from the observational (in) distribution. This feedback is 3 as it identifies a potential area of confusion or inconsistency in the results and provides a suggestion for further analysis. However, the comment could be more helpful if it offered specific guidance on how to conduct this analysis or what aspects to focus on. Overall, the comment provides some direction for improvement but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper should provide more explanation to clarify the expected results and that the main contribution, the CBR, should be discussed with different optimization strategies and their corresponding results. It also asks for an example of what would happen by minimizing both terms in Eq 3 or only the first term. While the comment explicitly states the need for more explanation and discussion, it does not provide specific guidance on how to implement these suggestions. The authors are given a clear direction but lack detailed instructions on how to execute the actions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, providing more explanation to clarify the expected results and discussing different optimization strategies and their corresponding results. The comment also includes a specific example of what should be discussed, such as minimizing both terms in Eq 3 or only the first term. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper should provide more explanation to clarify the expected results and that the main contribution, the CBR, should be discussed with different optimization strategies and their corresponding results. The reviewer provides a specific example by asking what would happen by minimizing both terms in Eq 3 or only the first term. This level of detail and the inclusion of a concrete example contribute to the claim\"s verifiability. However, the comment could be strengthened by referencing similar works or providing additional context to fully substantiate the claim. Therefore, the comment is 4, as it provides a clear direction for improvement but lacks comprehensive evidence or references.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by suggesting that the authors provide more explanation to clarify the expected results. It also highlights the importance of discussing different optimization strategies and their corresponding results, particularly in relation to the main contribution of the paper, the CBR. The comment includes a concrete example by asking what would happen by minimizing both terms in Eq 3 or only the first term. This level of detail and specificity provides the authors with clear guidance on how to enhance their draft, making the comment 4. However, it could be more comprehensive by suggesting additional aspects to discuss or by offering specific examples of what should be included in the explanation. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests including a formal or intuitive definition of the treewidth, which is central to all the proofs in the paper. While the comment implies that the authors should provide this definition, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not specify how the definition should be presented or what level of detail is required. However, the authors can infer that they need to add a definition, making the comment 3.", "grounding_specificity_rationale": "The comment suggests including a formal or intuitive definition of the treewidth, which is central to all the proofs in the paper. However, it does not specify which part of the paper this definition should be included in, such as a specific section or proof. This makes it weakly grounded, as the authors cannot confidently determine where to insert the definition. The comment is specific in suggesting the inclusion of a definition, but without clear grounding, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests including a formal or intuitive definition of the treewidth, which is central to all the proofs in the paper. This is a request for clarification or additional information, not a claim or opinion. It does not require verification as it is a factual statement or a suggestion for improvement. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment suggests including a formal or intuitive definition of the treewidth, which is central to all the proofs in the paper. This feedback is clear and actionable, as it identifies a specific area where the paper could be improved by providing additional context or clarification for the readers. By addressing this suggestion, the authors can enhance the comprehensibility and accessibility of their work. However, the comment could be more helpful if it provided guidance on how to present the definition or where it should be included in the paper. Overall, the comment is 4 as it directs the authors to a meaningful improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about how information redundancy is built into the Fill, Propagate, Decode algorithms. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on what specific aspects of the algorithms need clarification or improvement, leaving the authors without a clear understanding of how to address the issue. Without actionable suggestions or concrete steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Fill, Propagate, Decode\" algorithms and the sentence \"Finally, by comparing the performance of the secret model with or without fusion, we conclude that the robustness of Cans largely comes from the information redundancy implemented in our design of the weight pool.\" This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it questions how information redundancy is built into the algorithms and provides a reference to the sentence where this claim is made. This level of detail helps the authors understand what needs to be clarified or improved. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the implementation of information redundancy in the Fill, Propagate, Decode algorithms. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim. The comment lacks specific details or examples that would help the authors understand the basis of the question or how to address it. As a result, the claim is 1, as it does not provide sufficient information for the authors to make improvements based on the feedback. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the implementation of information redundancy in the Fill, Propagate, Decode algorithms. It references a specific sentence in the paper where the authors claim that the robustness of Cans largely comes from the information redundancy implemented in the weight pool design. However, the comment does not provide any further explanation, analysis, or suggestions on how the authors might address this issue or improve their explanation. Without additional context or guidance, the authors are left without a clear understanding of what specific aspects of the implementation need clarification or improvement. Therefore, the comment is 2, as it identifies a potential area of concern but lacks depth and actionable feedback."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the importance of the model\"s novel feature, which involves using multiple INs at different speeds in the dynamics predictor. It suggests that the design choice should be ablated to determine its significance. The comment explicitly asks for an evaluation of the added complexity and whether one IN would suffice. This provides a clear and direct action for the authors to take, which is to conduct an ablation study to assess the impact of this feature. The feedback is specific and actionable, as it guides the authors on how to improve their draft by providing a concrete step to take. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment raises a question about the importance of a novel feature in the model, specifically the use of multiple INs at different speeds in the dynamics predictor. However, it does not specify which part of the paper discusses this feature, making it weakly grounded. The comment is specific in its request for an ablation study to determine the significance of this design choice and whether one IN would suffice. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point questions the importance of a novel feature in the model, specifically the use of multiple INs at different speeds in the dynamics predictor. It suggests that this design choice should be ablated to determine its significance. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this ablation is necessary or how it might impact the model\"s performance. Without such evidence or justification, the claim remains 1, as the authors are left without a clear understanding of the basis for the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises an important question about the significance of a novel feature in the model, specifically the use of multiple INs at different speeds in the dynamics predictor. It suggests that this design choice should be ablated to determine its importance and whether one IN would suffice. This feedback is clear and actionable, as it provides a specific direction for the authors to explore in their analysis. By conducting an ablation study, the authors can gain a better understanding of the impact of this feature on the model\"s performance. However, the comment could be more helpful if it offered additional guidance on how to conduct the ablation study or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors to a meaningful area for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that the opponent in the experiments does not aim to maximize the multiagent payoff proposed by the authors, which is why the opponent is outperformed. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve their draft. The comment lacks actionable advice, leaving the authors without a clear understanding of what steps to take to enhance their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the experiments, explaining why the opponent is outperformed in terms of the multiagent payoff. The comment provides a clear rationale for the observed outcome, which helps the authors understand what needs to be addressed. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the opponent in the experiments is outperformed because they do not aim to maximize the multiagent payoff proposed by the authors. The reviewer provides a specific example of the opponent maximizing classical SE and AE, which supports the claim. However, the comment could be strengthened by providing more detailed reasoning or examples of how the opponent\"s strategy differs from the authors\" proposed payoff. Overall, the claim is 4, as it provides a logical explanation but lacks comprehensive evidence or references. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the experiments, noting that the opponent is outperformed because they do not aim to maximize the multiagent payoff proposed by the authors. The reviewer provides a clear explanation by mentioning that the opponent maximizes classical SE and AE, which is different from the authors\" proposed payoff. This feedback is valuable as it highlights a potential weakness in the experimental setup and suggests that the authors should consider how their opponent\"s strategy aligns with their proposed payoff. However, the comment could be more helpful if it offered suggestions on how to address this issue or improve the experimental design. Overall, the comment is 4 as it provides a clear insight into a potential weakness in the experiments, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment expresses confusion about a statement in Theorem 5.1, suggesting that it might indicate a disadvantage of MMD DRO. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to clarify the statement, address the potential disadvantage, or improve the explanation of Theorem 5.1. Without any actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clarifies the confusion about the statement in Theorem 5.1, suggesting that it might indicate a disadvantage of MMD DRO. The comment provides a clear indication of what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point expresses confusion about a statement in Theorem 5.1, suggesting that it might indicate a disadvantage of MMD DRO. However, the comment does not provide any further explanation, reasoning, or examples to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the confusion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses confusion about a statement in Theorem 5.1, suggesting that it might indicate a disadvantage of MMD DRO. However, it does not provide any further explanation, reasoning, or suggestions on how to clarify the statement or address the potential disadvantage. Without additional context or guidance, the authors are left without actionable feedback to improve their draft. Therefore, the comment is 1, as it does not offer any constructive direction for the authors to enhance their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include experimental results that demonstrate the pure contribution of the proposed method by excluding the mixup technique used in LUMP. This feedback is explicit and provides a clear action for the authors to take, which is to conduct additional experiments to isolate the effects of the mixup technique. The comment is also concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the authors should include experimental results that demonstrate the pure contribution of the proposed method by excluding the mixup technique used in LUMP. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors should include experimental results that demonstrate the pure contribution of the proposed method by excluding the mixup technique used in LUMP. This claim is based on the observation that the mixup technique is also used in LUMP, which is mentioned in Section 4.2. The reviewer provides a logical reasoning for the suggestion, as it aims to isolate the effects of the proposed method from the mixup technique. However, the comment could be strengthened by providing specific examples or references to support the claim that the mixup technique is a significant factor in the results. Therefore, the comment is 4, as it provides a clear rationale but lacks detailed evidence or examples.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the experimental setup by suggesting that the authors should include experimental results that demonstrate the pure contribution of the proposed method by excluding the mixup technique used in LUMP. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the paper\"s experimental rigor and clarity. By following this advice, the authors can better isolate the effects of their proposed method and provide a more comprehensive evaluation of its contribution. However, the comment could be more helpful if it offered additional guidance on how to conduct these experiments or what specific aspects to focus on. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly asks for clarification regarding the object detection based attention, specifically whether it is performed on the image or on a convolutional feature map. It also inquires about the possibility of rescaling based on the receptive field to determine which image regions correspond to which spatial locations in the feature map. This feedback provides clear and direct actions for the authors to take, such as clarifying the methodology and potentially adding details about the rescaling process. The instructions are concrete and leave no ambiguity about what needs to be addressed, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"object detection based attention,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be clarified, namely whether the attention is performed on the image or on a convolutional feature map, and whether rescaling is done based on the receptive field. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a request for clarification regarding the object detection based attention, specifically whether it is performed on the image or on a convolutional feature map. It also asks about the possibility of rescaling based on the receptive field. This is a factual question seeking clarification, not a claim or opinion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 5 as it identifies a specific area of confusion in the paper regarding the object detection based attention. It asks for clarification on whether the attention is performed on the image or on a convolutional feature map, and whether rescaling is done based on the receptive field. This feedback is clear and actionable, providing the authors with a precise direction to improve their draft by clarifying these aspects. By addressing these points, the authors can enhance the clarity and comprehensibility of their work, making this comment 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the acceleration of NTK convergence in the highfrequency range using Fourier features. It asks whether the authors overlooked this aspect or if it is not analyzed in the paper. While the comment implies that the authors should address this theoretical support for the merits of Fourier features, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should include this analysis or explanation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the acceleration of NTK convergence in the highfrequency range using Fourier features. It asks whether this aspect is analyzed in the paper or if the authors have overlooked it. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the theoretical support for the merits of Fourier features, but without clear grounding, the authors may struggle to identify the exact section to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question seeking clarification on the acceleration of NTK convergence in the highfrequency range using Fourier features. It does not express an opinion, judgment, or suggestion that requires verification. The comment is purely factual and descriptive, fitting the \"No\" label.", "helpfulness_rationale": "The review comment raises a question about the acceleration of NTK convergence in the highfrequency range using Fourier features. It asks whether this aspect is analyzed in the paper or if the authors have overlooked it. This is a relevant inquiry that could help the authors clarify their theoretical support for the merits of Fourier features. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this issue. While it identifies a potential area for improvement, the feedback is somewhat vague, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the possibility of an error in the initial calibration steps (steps 1 & 2) that might explain the speed disparities observed between the RSPs and FDs. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should investigate this possibility, correct the calibration steps, or address the speed disparities in their analysis. The comment lacks actionable advice, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions Section III of the \"Recognition and Velocity Computation of Large Moving Objects in Images\" paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether an error in the initial calibration steps (steps 1 & 2) might explain the speed disparities observed between the RSPs and FDs. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the possibility of an error in the initial calibration steps (steps 1 & 2) that might explain the speed disparities observed between the RSPs and FDs. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment lacks specific details or examples that would help the authors understand the basis of the question or how to address it. As a result, the claim is 1, as it does not provide sufficient information for the authors to make improvements based on the feedback. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the possibility of an error in the initial calibration steps (steps 1 & 2) that might explain the speed disparities observed between the RSPs and FDs. While it identifies a potential issue, it lacks specific guidance or suggestions on how the authors might investigate or address this concern. The comment does not provide actionable steps or detailed feedback on how to improve the draft, leaving the authors with only a vague direction to explore. Therefore, the comment is 2, as it identifies a potential area for improvement but does not offer sufficient guidance to be actionable."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point acknowledges that the artificial networks trained using ASAP (and similar methods) may not necessarily resemble biological networks, except for the weight transport problem, which is of arguable importance. The reviewer clarifies that this observation does not affect the review given and does not hold the authors accountable. However, the comment does not provide any actionable advice or suggestions for the authors to address this issue or improve their draft. It lacks explicit guidance or concrete steps for the authors to take, leaving them without a clear understanding of how to proceed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment discusses the resemblance of artificial networks trained using ASAP (and similar methods) to biological networks, specifically questioning the importance of the weight transport problem. However, it does not specify which part of the paper this issue is addressed in, making it weakly grounded. The comment is specific in its critique of the resemblance to biological networks and the importance of the weight transport problem. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that artificial networks trained using ASAP (and similar methods) may not necessarily resemble biological networks, except for the weight transport problem, which is of arguable importance. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges that artificial networks trained using ASAP (and similar methods) may not necessarily resemble biological networks, except for the weight transport problem, which is of arguable importance. However, the reviewer clarifies that this observation does not affect the review given and does not hold the authors accountable. While the comment acknowledges a potential limitation, it does not provide any actionable feedback or suggestions for improvement. The authors are left without guidance on how to address this issue or enhance their work. Therefore, the comment is 1, as it lacks actionable insights or constructive feedback."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the impact of nonparametric emission distributions on inference tasks in a discrete HMM. It explicitly asks which of the common inference tasks (filtering, smoothing, and marginal observation likelihood) can be computed exactly or approximately with an NPSPECHMM. This question provides a clear and direct action for the authors to take, as it prompts them to clarify the relationship between the emission distributions and inference tasks. The comment is explicit and provides concrete guidance on what the authors need to address, making it 5.", "grounding_specificity_rationale": "The comment raises a question about the impact of nonparametric emission distributions on inference tasks in a discrete HMM, specifically asking which of the common inference tasks (filtering, smoothing, and marginal observation likelihood) can be computed exactly or approximately with an NPSPECHMM. However, it does not specify which part of the paper this question pertains to, leaving the authors to infer that it relates to the sections discussing inference or modeling. While the comment is specific in its inquiry, it lacks grounding as it does not explicitly mention a particular section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the impact of nonparametric emission distributions on inference tasks in a discrete HMM. It does not present a claim or opinion but rather seeks clarification through a question. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a critical question about the impact of nonparametric emission distributions on inference tasks in a discrete HMM. It specifically asks which of the common inference tasks (filtering, smoothing, and marginal observation likelihood) can be computed exactly or approximately with an NPSPECHMM. This question prompts the authors to clarify an important aspect of their work, which could lead to a more comprehensive understanding of the model\"s capabilities and limitations. However, the comment could be more helpful if it provided additional context or suggestions on how to address this issue. Overall, the feedback is 3 as it identifies a gap in the paper and encourages the authors to clarify a critical aspect of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about why the authors did not compare batch and greedy methods in the remaining 110 datasets, given that only 10 out of 120 datasets were considered in 7,12. While the comment implies that the authors should consider comparing these methods in the other datasets, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand their analysis to include more datasets. However, the comment provides a clear rationale for why this comparison might be beneficial, which could help guide the authors in making this decision. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the authors\" choice to only consider 10 out of 120 datasets in 7,12 and suggests comparing batch and greedy methods in the remaining 110 datasets. However, it does not specify which part of the paper this discussion is based on, such as a specific section or table where the datasets are mentioned. This lack of explicit grounding makes it difficult for the authors to pinpoint the exact part of the paper being addressed. The comment is specific in its suggestion to compare batch and greedy methods in the remaining datasets, but without clear grounding, it is 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point questions the authors\" decision to only consider 10 out of 120 datasets in 7,12 and suggests comparing batch and greedy methods in the remaining 110 datasets. However, the comment does not provide any reasoning or evidence to support why this comparison is necessary or beneficial. It lacks specific examples or references to justify the claim, making it difficult for the authors to understand the basis of the suggestion. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the authors\" choice to only consider 10 out of 120 datasets in 7,12 and suggests comparing batch and greedy methods in the remaining 110 datasets. While the comment identifies a potential area for expansion or improvement, it lacks specific guidance or suggestions on how the authors might address this issue. It does not provide actionable steps or detailed feedback on why this comparison is important or how it could impact the results or conclusions of the paper. As a result, the comment is 3, as it points out a potential area for enhancement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the motivation for the lowrank factorization in the introduction is unnecessary, given that the main result is about polytopes. If the result has implications for lowrank matrix factorization, the reviewer requests that these implications be explicitly discussed. While the comment implies that the authors should address the implications of their result for lowrank matrix factorization, it does not provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should discuss the implications and determine how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"motivation in the introduction with the lowrank factorization,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the implications of the main result for lowrank matrix factorization should be explicitly discussed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the motivation for lowrank factorization in the introduction is unnecessary, given that the main result is about polytopes. The reviewer requests that if the result has implications for lowrank matrix factorization, these implications should be explicitly discussed. However, the comment does not provide specific examples or references to support the claim that the motivation is unnecessary or that the implications should be discussed. This lack of detailed justification or evidence makes the claim 3, as the authors may need to infer the reasoning behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the motivation for the lowrank factorization in the introduction, suggesting that it may be unnecessary given the main focus on polytopes. It also requests that if the result has implications for lowrank matrix factorization, these implications should be explicitly discussed. This feedback is clear and actionable, as it directs the authors to reconsider the motivation and potentially expand their discussion to include implications for lowrank matrix factorization. However, the comment could be more helpful if it provided specific suggestions on how to integrate these implications into the paper. Overall, the comment is 4, as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point notes that the paper is incremental compared to a specific reference, 31, and describes the adaptation of the existing architecture for the multiperson case. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address the perceived incremental nature of the work or improve upon it. Without actionable suggestions or specific feedback, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions that the paper is incremental compared to reference 31 and describes the adaptation of the existing architecture for the multiperson case. However, it does not specify which part of the paper this observation is based on, making it difficult for the authors to pinpoint the exact sections that need attention. Additionally, the comment lacks specificity regarding what aspects of the paper are considered incremental or how the adaptation could be improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is incremental compared to reference 31, suggesting that the authors have adapted an existing architecture for the multiperson case. However, the comment does not provide any specific details or examples to support this claim, such as how the adaptation differs from the original work or what aspects of the paper are considered incremental. Without these details, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that the paper is incremental compared to a specific reference, 31, and describes the adaptation of the existing architecture for the multiperson case. However, it lacks specificity and does not provide any actionable feedback or suggestions for improvement. Without detailed guidance or constructive criticism, the authors are left without a clear understanding of how to address the perceived incremental nature of their work or how to enhance it. Therefore, the comment is 1, as it does not offer any actionable insights or direction for the authors to improve their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the method used to solve the minmin problem, specifically asking which method is being referred to. However, it does not provide any explicit or implicit action for the authors to take. The comment lacks guidance on how to address the question or improve the clarity of the paper. As a result, the authors are left without a clear understanding of what needs to be done to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the method used to solve the minmin problem, but it does not specify which part of the paper this issue is discussed in. The authors cannot confidently determine the exact section or context where this method is mentioned, making the comment weakly grounded. However, the comment is specific in its inquiry about the method used, which provides some guidance on what needs to be clarified. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point is a question seeking clarification about the method used to solve the minmin problem. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the method used to solve the minmin problem, specifically asking which method is being referred to. While it identifies a potential area of confusion or lack of clarity in the paper, it does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their draft. The comment lacks actionable feedback or constructive advice, leaving the authors without a clear path for improvement. Therefore, it is rated as 2, as it points out a problem but does not offer any actionable steps for resolution."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point questions the effectiveness of lower bound double qlearning, specifically mentioning the performance decrease in MsPacman and the convergence of algorithms in certain environments. It also raises concerns about overestimating the true maximum value. However, the comment does not provide explicit guidance or suggestions on how the authors might address these issues or improve their draft. The authors are left to infer that they need to provide evidence or reasoning to support the effectiveness of their method, but without concrete steps or examples, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the effectiveness of lower bound double qlearning, specifically mentioning the performance decrease in MsPacman and the convergence of algorithms in certain environments. However, it does not explicitly mention which part of the paper this discussion is based on, such as a specific section or figure. The authors can infer that it relates to the results or analysis sections, but this inference is not straightforward. The comment is specific in detailing the issues with the algorithm, but it lacks grounding as it does not directly reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the effectiveness of lower bound double qlearning is doubtful, citing specific examples from the MsPacman environment and other environments like WizardOfWor, Zaxxon RoadRunner, and BattleZone. It also mentions that the algorithm overestimates the true maximum value. However, the comment lacks detailed reasoning or evidence to support these claims, such as comparisons with other algorithms or references to studies that have evaluated the effectiveness of lower bound double qlearning. The lack of specific examples or references makes it difficult for the authors to understand and address the concerns raised. Therefore, the comment is considered 2, as it provides some basis for the claim but requires more detailed justification or evidence to be 5.", "helpfulness_rationale": "The review comment raises concerns about the effectiveness of lower bound double qlearning, specifically mentioning the performance decrease in MsPacman and the convergence of algorithms in certain environments. It also points out a potential issue with overestimating the true maximum value. While the comment identifies specific areas of concern, it lacks detailed guidance or suggestions on how the authors might address these issues or improve their methodology. The feedback is 3 as it highlights potential weaknesses, but it does not provide actionable steps for improvement. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance of DNN+MMA compared to vanilla DNN when lambda becomes small. It suggests that the performance should approach the vanilla methods from below, but it is unclear why the performance becomes worse. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern or what specific changes they should make to improve the draft. The action is implicit and somewhat vague, as the authors need to infer that they should investigate and clarify the performance trend. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig.34,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by questioning the performance trend of DNN+MMA compared to vanilla DNN when lambda becomes small. The reviewer provides a logical expectation that the performance should approach the vanilla methods from below, which helps the authors understand what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the performance of DNN+MMA compared to vanilla DNN when lambda becomes small, suggesting that the performance should approach the vanilla methods from below. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this expectation should hold. Without additional context or explanation, the claim remains vague and 1, leaving the authors without a clear understanding of the basis for the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the performance trend of DNN+MMA compared to vanilla DNN when lambda becomes small. It suggests that the performance should approach the vanilla methods from below, but it is unclear why the performance becomes worse. This feedback identifies a potential issue in the paper that the authors need to address, as it could impact the interpretation of the results. However, the comment lacks specific suggestions or guidance on how the authors might investigate or resolve this issue. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to elaborate on a specific aspect of their paper, namely the Hoeffding\"s bound and its applicability to stochastic algorithms. It provides a clear action for the authors to take, which is to expand on the explanation in the paper. However, the comment does not specify how the authors should elaborate on this topic, leaving some room for interpretation. While the action is explicit, the lack of detailed guidance makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 124125, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be elaborated on, namely the applicability of Hoeffding\"s bound to stochastic algorithms. The comment provides a clear direction for the authors to improve their explanation, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of factual statements and questions, making it a normal statement. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area of the paper where the authors could provide more elaboration, specifically regarding the applicability of Hoeffding\"s bound to stochastic algorithms. It points out that the authors should explain how the conditioning on the previous iterate further guarantees the validity of the Hoeffding inequality. This feedback is clear and actionable, as it directs the authors to enhance the clarity and depth of their explanation in the paper. However, the comment could be more helpful if it provided additional context or examples to guide the authors in elaborating on this topic. Overall, the comment is 4, as it effectively points out a gap in the paper and offers a clear direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests adding an optimizationbased metalearning approach to Table1, specifically mentioning MAML or implicitMAML. This is an explicit suggestion that provides a clear action for the authors to take, namely, to incorporate these approaches into their table. The comment is specific and concrete, as it identifies a particular area for improvement and provides examples of what could be added. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests adding an optimizationbased metalearning approach to Table1, specifically mentioning MAML or implicitMAML. However, it does not specify which part of Table1 this addition would be made to, nor does it provide details on how this approach would be integrated or what specific improvements it would bring. While the authors might infer that it relates to the experimental results or methodology sections, the comment lacks full grounding as it does not explicitly mention these sections. The suggestion is specific in terms of the type of approach to consider, but it is not fully grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests adding an optimizationbased metalearning approach to Table1, specifically mentioning MAML or implicitMAML. However, the comment does not provide any reasoning, examples, or references to support why this addition would be beneficial or how it would improve the paper. Without additional context or justification, the authors may find it challenging to understand the significance of this suggestion or how to implement it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests adding an optimizationbased metalearning approach to Table1, specifically mentioning MAML or implicitMAML. This feedback is 3 as it provides a specific suggestion for enhancing the paper by incorporating a particular type of approach. However, the comment lacks depth and does not explain why this addition would be beneficial or how it would improve the paper. It also does not provide guidance on how to integrate this approach or what specific aspects of the paper it would impact. While the suggestion is actionable, the lack of detailed explanation or context limits its helpfulness. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to use the terms \"causal mechanisms\" and \"causality\" carefully, as they are different from the term \"temporal relationship.\" This feedback provides a clear and direct action for the authors to take, ensuring they use the terms correctly. The comment is explicit and concrete, giving the authors precise guidance on how to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Page 1\" and the specific term \"causal mechanisms,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of the term \"causal mechanisms,\" pointing out that it should be differentiated from \"temporal relationship.\" Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the use of the term \"causal mechanisms\" on page 1. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the use of terminology on page 1, where the term \"causal mechanisms\" is used interchangeably with \"temporal relationship.\" It provides a clear and actionable suggestion to use the terms carefully, ensuring clarity and accuracy in the paper. This feedback is valuable as it helps the authors correct a potential misunderstanding or confusion in their work. However, the comment could be more helpful if it provided examples or further explanation of how to differentiate between these terms. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should include a discussion on how their results relate to the lower bounds on kernel learning using lowrank approximation, as mentioned in the reference \"On the Complexity of Learning with Kernels.\" While the comment implies that the authors should add this discussion, it does not provide specific guidance on how to integrate this information or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should include a discussion on how their results relate to the lower bounds on kernel learning using lowrank approximation, as mentioned in a reference. However, it does not specify which part of the paper this discussion should be included in, nor does it provide details on what aspects of the results should be discussed in relation to the reference. This makes it difficult for the authors to pinpoint the exact section that needs attention. The comment is weakly grounded as it does not specify the part of the paper being addressed, and it is not specific because it lacks detailed guidance on what needs to be discussed. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the authors should include a discussion on how their results relate to the lower bounds on kernel learning using lowrank approximation, as mentioned in a reference. However, the comment does not provide specific details or examples from the reference to support the claim, nor does it explain why this discussion is important or how it would enhance the paper. Without additional context or references, the authors may find it challenging to understand the significance of this suggestion. Therefore, the comment is considered 2, as it provides a general direction but lacks detailed justification or evidence.", "helpfulness_rationale": "The review comment suggests that the authors should include a discussion on how their results relate to the lower bounds on kernel learning using lowrank approximation, as mentioned in a reference. This feedback is 3 as it points out a potential area for improvement by suggesting a connection to existing literature. However, the comment lacks specificity and does not provide detailed guidance on how to integrate this discussion into the paper or what aspects of the results should be highlighted. While it identifies a relevant area for expansion, the lack of detailed suggestions limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the novelty and significance of using PCA to reduce interaction count, suggesting that it seems intuitive and lacks clarity. It questions the assumptions behind PCA and asks for clarification on how well these assumptions are met. While the comment implies that the authors should provide more information on the assumptions and their validity, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the assumptions and their impact on the results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises concerns about the novelty and significance of using PCA to reduce interaction count, suggesting that it seems intuitive and lacks clarity. It questions the assumptions behind PCA and asks for clarification on how well these assumptions are met. However, the comment does not specify which part of the paper discusses the use of PCA or where the assumptions are mentioned, making it weakly grounded. The comment is specific in its critique of the novelty and significance of the approach, but without clear grounding, the authors may struggle to identify the exact sections needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a claim about the novelty and significance of using PCA to reduce interaction count, suggesting that it seems intuitive and lacks clarity. The reviewer questions the assumptions behind PCA and asks for clarification on how well these assumptions are met. The comment references a specific paper by Dombrowski et al. (2022) to support the claim that PCA is a wellknown technique. However, the reference is not directly used to substantiate the claim about the assumptions or the lack of novelty, making the comment 3. The authors would need to further explore the referenced work to fully understand the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises concerns about the novelty and significance of using PCA to reduce interaction count, suggesting that it seems intuitive and lacks clarity. It questions the assumptions behind PCA and asks for clarification on how well these assumptions are met. While the comment identifies a potential weakness in the paper, it does not provide specific guidance or suggestions on how the authors might address these concerns or improve the clarity of their work. The feedback is 3 as it points out an area for improvement, but it lacks depth and actionable advice, leaving the authors with limited direction for enhancing their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the fewshot RC models considered in the paper, noting that they are not stateoftheart models. It questions how the performance of these models compares to relation extraction/generation models in fewshot settings. While the comment implies that the authors should provide a comparison or justification for their choice of models, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to address the comparison but are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"fewshot RC models\" considered in the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that these models are not stateoftheart and questions how their performance compares to relation extraction/generation models in fewshot settings. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the fewshot RC models considered in the paper are not stateoftheart models, providing specific examples of alternative models. This claim is supported by references to external works, which provides a clear basis for the assertion. However, the comment could be strengthened by including more detailed comparisons or analyses of the performance differences between the models. Overall, the claim is 4, as it provides sufficient evidence but lacks comprehensive evaluation. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the fewshot RC models considered in the paper, noting that they are not stateoftheart models. It questions how the performance of these models compares to relation extraction/generation models in fewshot settings, which is a relevant and important point for the authors to address. By highlighting this gap, the comment provides a clear direction for the authors to improve their work by either justifying their choice of models or conducting a comparative analysis. However, the comment could be more helpful if it offered suggestions on how to conduct this comparison or provided examples of stateoftheart models to consider. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly requests the authors to provide results regarding the discussion of using sequential MCB vs a single MCT layers for the decision head. This request is clear and direct, giving the authors a specific action to take. The comment provides a concrete suggestion on what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the discussion of using sequential MCB vs a single MCT layers for the decision head, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests the authors to speak about what was observed in this context, providing a clear direction for improvement. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point expresses interest in the discussion of using sequential MCB vs a single MCT layers for the decision head but notes that no results are shown. The comment requests the authors to speak about what was observed, indicating a gap in the paper that the authors should address. However, the comment does not provide any specific reasoning or evidence to support the claim that results should be included. Without additional context or justification, the authors may find it challenging to understand the importance of this request. Therefore, the comment is considered 2, as it lacks sufficient support to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a gap in the paper by noting that the discussion of using sequential MCB vs a single MCT layers for the decision head is interesting but lacks results. It provides a clear and actionable suggestion for the authors to speak about what was observed in this context, which could enhance the paper\"s content and provide valuable insights. However, the comment could be more helpful if it offered specific guidance on how to present these results or what aspects to focus on. Overall, the feedback is 4 as it directs the authors to a meaningful area for improvement, but it could be more comprehensive with additional suggestions or examples."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point consists of two parts: a request for sensitivity analysis regarding other hyperparameters and a list of minor language issues. The first part is explicit and actionable, as it clearly instructs the authors to conduct a sensitivity analysis on other hyperparameters. The second part is also explicit, as it provides specific examples of language issues that need to be corrected. However, the second part lacks concrete guidance on how to address the language issues, such as suggesting alternative phrasing or providing examples of correct usage. Overall, the comment is 4, as it provides clear actions but could be more detailed in the language correction suggestions.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper, such as \"above of (7),\" \"Theorem 1,\" and \"above of (14),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear examples of language issues that need correction, such as \"we typically considers,\" \"two permutation,\" and \"until converge.\" This level of detail guides the authors on what specific changes are needed to improve the language clarity. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts: a request for sensitivity analysis regarding other hyperparameters and a list of minor language issues. The first part is a suggestion for additional analysis, which is not a claim requiring verification. The second part is a request for proofreading and correction of language issues, which is a factual statement and does not contain a claim. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a mix of feedback. It suggests conducting a sensitivity analysis on other hyperparameters, which is a clear and actionable suggestion for improving the paper. This part of the comment is 5 as it guides the authors to explore an important aspect of their work that could enhance its robustness and applicability. However, the second part of the comment consists of minor language corrections, which are specific but not comprehensive. While these corrections are helpful for improving the paper\"s clarity, they are not as impactful as the suggestion for sensitivity analysis. Overall, the comment is 4, as it offers valuable guidance for improving the draft but could be more comprehensive in addressing both the language and the sensitivity analysis aspects."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the choice of 20 distribution sets and whether the number of distribution sets for each class can be controlled. It also asks what would happen if only a few distribution sets were selected. While the comment implies that the authors should clarify these points, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional information about the choice of distribution sets. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the choice of 20 distribution sets and whether the number of distribution sets for each class can be controlled. However, it does not specify which part of the paper discusses this choice, making it weakly grounded. The comment is specific in its questions about the choice of distribution sets and the potential impact of selecting fewer sets. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the choice of 20 distribution sets and whether the number of distribution sets for each class can be controlled. It also asks what would happen if only a few distribution sets were selected. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these questions are relevant or important. Without additional context or explanation, the authors may find it challenging to understand the significance of these questions or how to address them. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises questions about the choice of 20 distribution sets and whether the number of distribution sets for each class can be controlled. It also asks what would happen if only a few distribution sets were selected. While the comment identifies a potential area of concern, it lacks specific suggestions or guidance on how the authors might address these questions or improve their methodology. The feedback is 3 as it prompts the authors to consider these aspects, but it does not provide actionable steps or detailed advice for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the evaluative framework, noting that it is restricted to only three QuestionAnswering tasks and two language models. It suggests that the method\"s applicability to other reasoning or generation tasks or more advanced models, such as vicunna or alpaca, is uncertain. However, the comment does not provide explicit guidance or suggestions on how the authors might address this limitation or expand the scope of their evaluation. The action is implicit and vague, as the authors are left to infer that they should consider broader applicability but are not given specific steps to take. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the evaluative framework\"s scope, specifically mentioning the limitations of considering only three QuestionAnswering tasks and two language models. It raises concerns about the framework\"s applicability to other reasoning or generation tasks and more advanced models like vicunna or alpaca. However, the comment does not explicitly mention which part of the paper discusses the evaluative framework, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. The comment is specific in detailing the limitations and potential areas for expansion, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the evaluative framework is limited in scope, noting that it considers only three QuestionAnswering tasks and two language models. The comment suggests that the framework\"s applicability to other reasoning or generation tasks or more advanced models is uncertain. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence makes the claim 3, as the authors would need to infer the potential issues and address them without clear guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the evaluative framework, noting that it is restricted to only three QuestionAnswering tasks and two language models. It raises concerns about the framework\"s broader applicability and suggests that its potential to generalize to other reasoning or generation tasks or more advanced models, such as vicunna or alpaca, is uncertain. This feedback is 3 as it points out a specific area for improvement, prompting the authors to consider expanding the scope of their evaluation. However, the comment lacks detailed guidance or suggestions on how to address this limitation, such as recommending specific tasks or models to include. Therefore, while it provides some direction, it could be more helpful with additional details or actionable advice. Overall, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should showcase their approach using transformerbased (masked) language models instead of obsolete language models like ngram HMM and RNN, which are no longer commonly used. This comment explicitly states an action for the authors to take, which is to update their experiments to align with current NLP trends. The suggestion is clear and provides a concrete direction for the authors to follow, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"perplexity experiments\" and the use of \"obsolete language models\" like ngram HMM and RNN, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the language models used and suggests an alternative approach using transformerbased (masked) language models to better align with current NLP trends. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the perplexity experiments are conducted on obsolete language models, such as ngram HMM and RNN, which are no longer commonly used. The reviewer suggests that the authors should showcase their approach using transformerbased (masked) language models to better align with current NLP trends. While the claim is based on the observation that these models are outdated, it lacks specific references or detailed reasoning to support the assertion that transformerbased models are the current standard. The comment provides a suggestion for improvement but does not fully substantiate the claim, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the perplexity experiments, noting that they are conducted on obsolete language models (ngram HMM and RNN) that are no longer commonly used. It suggests that the authors should showcase their approach using transformerbased (masked) language models to better align the paper with current NLP trends. This feedback is clear and actionable, providing the authors with a concrete suggestion for improvement that can enhance the relevance and impact of their work. By addressing this feedback, the authors can ensure their paper is more aligned with current practices and standards in the field. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out a lack of clarity regarding the estimation of mu, which is the proportion of missing observations. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or improve the clarity of their discussion. The comment lacks actionable guidance, leaving the authors without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the estimation of mu, which is discussed in the paper. However, it does not specify which part of the paper this discussion occurs in, making it weakly grounded. The comment is specific in pointing out the lack of clarity regarding the estimation of mu, but it does not provide detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the discussion on the misestimation of mu is unclear, specifically questioning how mu, which represents the proportion of missing observations, can be estimated. However, the comment does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of clarity regarding the estimation of mu, which represents the proportion of missing observations. However, it does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their discussion. Without actionable feedback or specific recommendations, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point suggests a specific way to present the performance of the algorithm by considering the sensitivity to initialization. It provides a clear and concrete action for the authors to take, which is to present the performance as a function of the distance of initialization to the groundtruth. The comment also specifies the steps to follow, such as sampling matrices with varying distances and reporting the performance accordingly. This level of detail provides the authors with a clear understanding of what needs to be done to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests presenting the performance as a function of the distance of initialization to the groundtruth, which provides a clear and specific direction for improvement. However, it does not explicitly mention which part of the paper this suggestion pertains to, such as a specific section or figure. The authors can infer that it relates to the experimental results or methodology sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests presenting the performance as a function of the distance of initialization to the groundtruth, which is a logical and reasonable suggestion. The reviewer provides a clear explanation of how this could be done, including specific steps like sampling matrices with varying distances and reporting the performance accordingly. This reasoning is wellsupported and provides a clear path for the authors to follow, making the claim 5.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the presentation of the paper. It recommends presenting the performance as a function of the distance of initialization to the groundtruth, which could provide valuable insights into the algorithm\"s sensitivity to initialization. The comment offers a clear and detailed approach for implementing this suggestion, including specific steps like sampling matrices with varying distances and reporting the performance accordingly. This level of guidance empowers the authors to make a significant improvement in their draft, making the comment 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that only bounds in expectation are provided and asks for highprobability bounds. It also recommends using ensemble methods as performed in the experiments and suggests adding measures of robustness, such as error bars or standard deviation, to the experiments. While the comment implies that the authors should provide highprobability bounds and consider adding measures of robustness, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that only bounds in expectation are provided and asks for highprobability bounds. It also recommends using ensemble methods as performed in the experiments and suggests adding measures of robustness, such as error bars or standard deviation, to the experiments. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the experimental results or methodology sections. The comment is specific in detailing what needs to be addressed, such as providing highprobability bounds and adding measures of robustness. However, the lack of explicit section references makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that only bounds in expectation are provided and suggests that highprobability bounds would be beneficial. It also recommends using ensemble methods as performed in the experiments and suggests adding measures of robustness, such as error bars or standard deviation, to the experiments. The comment provides a logical reasoning for the suggestion, as ensemble methods are known to provide highprobability bounds, and the addition of measures like error bars or standard deviation would enhance the robustness analysis. However, the comment could be strengthened by providing specific examples or references to support the claim about ensemble methods and highprobability bounds. Overall, the claim is 4, as it provides a clear rationale but lacks detailed evidence or references. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a specific limitation in the paper, noting that only bounds in expectation are provided and suggests that highprobability bounds would be beneficial. It also recommends using ensemble methods as performed in the experiments and suggests adding measures of robustness, such as error bars or standard deviation, to the experiments. This feedback is clear and actionable, providing the authors with specific suggestions on how to enhance their work by addressing the lack of highprobability bounds and improving the robustness analysis. However, the comment could be more helpful if it included examples or references to support the use of ensemble methods or highprobability bounds. Overall, the comment is 4 as it guides the authors toward meaningful improvements in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges that the reviewer is not an expert in the area of pruning but expresses a belief that the results could be more impressive. It suggests that the results should be evaluated from additional aspects, such as actual latency on the target device, memory consumption during inference, and the actual network size. However, the comment does not provide explicit guidance on how to implement these evaluations or what specific metrics to use. The action is implicit and somewhat vague, as the authors can infer that they need to conduct additional analyses but are not given concrete steps to follow. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment acknowledges the reviewer\"s lack of expertise in the area of pruning but expresses a belief that the results could be more impressive. It suggests that the results should be evaluated from more aspects, such as actual latency on the target device, memory consumption during inference, and the actual network size. However, the comment does not specify which part of the paper these suggestions pertain to, making it weakly grounded. The authors might infer that it relates to the results section, but this inference is not explicit. The comment is specific in suggesting additional aspects for evaluation, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point expresses a subjective opinion that the results are less impressive and suggests that they should be evaluated from more aspects, such as actual latency on the target device, memory consumption during inference, and the actual network size. However, the comment lacks specific examples, detailed reasoning, or references to support the claim that the results are less impressive. The suggestion to evaluate from more aspects is logical but not fully substantiated, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the reviewer\"s lack of expertise in the area of pruning but expresses a belief that the results could be more impressive. It suggests that the results should be evaluated from more aspects, such as actual latency on the target device, memory consumption during inference, and the actual network size. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how to conduct these evaluations or what metrics to use. The feedback is 3 as it points out a direction for further analysis, but it could be more actionable with additional details. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point expresses concern about the lack of explicit enforcement of diversity in the model, despite the extensive motivation for diversity in the paper. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how to incorporate diversity into the model or suggestions for improvements. As a result, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the title, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the discrepancy between the extensive motivation for diversity and the lack of explicit enforcement of diversity in the model. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper extensively motivates \"diversity\" but does not enforce it explicitly in the model. The reviewer expresses disappointment at the lack of diversity enforcement, suggesting that the authors\" efforts to incorporate diversity were not realized. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. Without detailed justification or evidence, the claim remains 3, as it provides a general critique but lacks the necessary depth to fully substantiate the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the lack of explicit enforcement of diversity in the model, despite the extensive motivation for diversity in the paper. This feedback is valuable as it highlights a potential gap between the theoretical framework and its practical implementation. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or incorporate diversity into their model. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 3, as it provides insight but lacks depth and actionable steps."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that some experiments are missing, specifically mentioning contrastive learning and adversarial learning. This provides a clear and direct action for the authors to take, which is to include these experiments in their study. The comment is explicit and concrete, as it specifies exactly what experiments are missing and what needs to be added. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment mentions that \"some experiments are missing,\" specifically mentioning contrastive learning and adversarial learning. However, it does not specify which part of the paper these experiments should be included in, making it weakly grounded. The comment is specific in identifying the missing experiments, but without clear grounding, the authors may struggle to determine where these experiments should be integrated. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that \"some experiments are missing,\" specifically mentioning contrastive learning and adversarial learning. However, it does not provide any reasoning, examples, or references to support this claim. Without further explanation or evidence, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out that some experiments are missing, specifically mentioning contrastive learning and adversarial learning. This feedback is clear and actionable, as it provides the authors with a direct suggestion to enhance their study by including these experiments. However, the comment could be more helpful if it explained why these experiments are important or how they would contribute to the overall understanding of the research. Despite this, the feedback is 4 as it guides the authors toward a clear enhancement of their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to use DinoV2 Frechet Distances for comparisons, in addition to the widely used FID metric. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"FIDs\" and \"DinoV2 Frechet Distances,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the use of FIDs and suggests using DinoV2 Frechet Distances for comparisons, in addition to the widely used FID metric. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that FIDs have clear flaws and suggests using DinoV2 Frechet Distances for comparisons. However, it does not provide specific examples or detailed reasoning to support the claim about the flaws in FIDs. The reference to C is not sufficient to fully substantiate the claim, making it 3. The authors would need to investigate the referenced work to fully understand the basis of the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to consider using DinoV2 Frechet Distances for comparisons, in addition to the widely used FID metric. This feedback is specific and offers a concrete way to improve the evaluation methodology, which is particularly important in the context of image generation. By suggesting an alternative metric, the comment empowers the authors to enhance the rigor and relevance of their comparisons. However, the comment could be more helpful if it included a brief explanation of why DinoV2 Frechet Distances might be a better choice or how it addresses the flaws in FIDs. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the novelty of the paper, questioning whether it is merely an incremental improvement over a previous work. It asks for clarification on how the current paper differs from the referenced work and suggests that it might be applying a similar methodology to a new task. While the comment implies that the authors should provide a clear explanation of their novelty, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the issue of novelty and provide a detailed comparison with the referenced work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the novelty of the paper, specifically questioning whether it is merely an incremental improvement over a previous work. It references a specific paper, \"https://aclanthology.org/2021.findingsacl.57.pdf,\" which provides some grounding by indicating a specific work to compare against. However, the comment does not specify which part of the paper should be revised to address this concern, making it weakly grounded. The comment is specific in its request for clarification on the differences between the current paper and the referenced work, but it lacks detailed guidance on how to address the issue of novelty. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a claim about the novelty of the paper, suggesting that it is merely an incremental improvement over a previous work. The reviewer questions whether the paper differs significantly from the referenced work and implies that it might be applying a similar methodology to a new task. However, the comment lacks specific examples or detailed reasoning to support the claim of incremental novelty. Without additional context or evidence, the authors may find it challenging to address the concern effectively. Therefore, the claim is considered 2, as it provides some basis for the claim but requires more detailed justification.", "helpfulness_rationale": "The review comment raises a concern about the novelty of the paper, questioning whether it is merely an incremental improvement over a previous work. It specifically asks for clarification on how the current paper differs from the referenced work and suggests that it might be applying a similar methodology to a new task. This feedback is 3 as it prompts the authors to clarify the originality and distinctiveness of their work. However, the comment could be more helpful if it provided specific suggestions on how the authors might demonstrate the novelty or if it offered guidance on how to differentiate their work from the referenced paper. Overall, the comment provides a starting point for the authors to address a critical aspect of their paper, but it lacks depth and actionable advice, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the results in Table 2, specifically regarding the performance of the complete loss function compared to those with some terms missing. The reviewer questions the logic behind this observation, asking for an explanation. While the comment implies that the authors should provide an explanation for this unexpected result, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the question posed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the reported ablation studies, specifically questioning the performance of the complete loss function compared to those with some terms missing. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the results in Table 2, specifically the performance of the complete loss function compared to those with some terms missing. The reviewer points out that the complete loss function performed worse than expected, which is a claim that requires justification. However, the comment does not provide any supporting evidence, reasoning, or references to explain why this observation is unexpected or how it affects the overall results. Without additional context or explanation, the claim remains 1, as the authors would need to infer the basis of the question themselves. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the reported ablation studies in Table 2, noting that the complete loss function performed worse than expected for certain datasets. This observation raises a question about the logic behind the results, prompting the authors to provide an explanation. While the comment highlights a potential area of concern, it does not offer specific suggestions or guidance on how the authors might address this issue or improve their analysis. The feedback is 3 as it points out a potential problem, but it lacks depth and actionable advice, leaving the authors with a clear question to answer but without a clear path to improvement. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should consider introducing inverse triples in other embedding models besides CP and test such cases in their experiments. However, it does not provide explicit instructions on how to implement this suggestion or what specific models should be tested. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to address the suggestion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should consider introducing inverse triples in other embedding models besides CP and test such cases in their experiments. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the experimental setup or methodology, but the lack of explicit grounding makes it difficult to pinpoint the exact part of the paper being addressed. Additionally, the comment is specific in suggesting a potential extension of the work but lacks detailed guidance on how to implement it. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that introducing inverse triples might be useful in other embedding models besides CP, but the authors did not test such cases in their experiments. This is a claim that requires justification, as it implies a potential extension of the work. However, the comment lacks specific examples or references to other embedding models where inverse triples could be beneficial, making it difficult for the authors to understand the full context or significance of the suggestion. The lack of detailed reasoning or evidence makes the claim 3, as it provides a direction for further exploration but does not fully support the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should consider introducing inverse triples in other embedding models besides CP and test such cases in their experiments. This feedback is 3 as it identifies a potential extension of the work and provides a direction for further exploration. However, the comment lacks specific guidance on how to implement this suggestion or which other models should be considered, leaving the authors with a general idea but no detailed steps to follow. To be more helpful, the comment could include examples or references to other embedding models where inverse triples might be applicable. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that a statement in the abstract is unclear and suggests that it should be more highlevel, avoiding technicalities. However, it does not provide specific guidance on how to rephrase the statement or what aspects should be clarified. The action is implicit and somewhat vague, as the authors are left to infer that they need to simplify the language without detailed instructions on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the statement in the abstract, pointing out that it is unclear and suggesting that it should be more highlevel and avoid technicalities. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point claims that a statement in the abstract is unclear and suggests that it should be more highlevel. However, it does not provide any specific reasoning or examples to support why the statement is unclear or how it could be improved. Without detailed explanation or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of a statement in the abstract, noting that it is unclear and should be more highlevel. It provides a clear suggestion to avoid technicalities in the abstract, which is a valuable piece of feedback for the authors. However, the comment could be more helpful if it offered specific guidance on how to rephrase the statement or what aspects to focus on for clarity. Despite this, the feedback is 4 as it directs the authors to improve the clarity and accessibility of their abstract."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment suggests that there is room for improvement in the complexity of Algorithm 2, but it does not provide any explicit guidance or concrete suggestions on how to achieve this improvement. The authors are left to infer that they should enhance the algorithm\"s complexity, but without specific details or examples, it is difficult to determine what changes might be necessary. This lack of direction makes the comment vague and 1.", "grounding_specificity_rationale": "The comment refers to \"Algorithm 2,\" which provides full grounding as it allows the authors to accurately identify the specific part of the paper being addressed. However, the comment lacks specificity as it does not detail what aspects of the algorithm\"s complexity need improvement or how it could be enhanced. The authors are left to infer the specific areas that require attention, making the comment 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests that there is room for improvement in the complexity of Algorithm 2, but it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a potential area for improvement in the complexity of Algorithm 2, suggesting that there is room for enhancement. However, it lacks specificity and does not provide any guidance or suggestions on how the authors might improve the algorithm\"s complexity. Without actionable feedback or detailed advice, the authors are left without a clear path to address the issue. Therefore, the comment is 2, as it points out a possible area for improvement but does not offer meaningful guidance for the authors to act upon."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point critiques the use of GP as \"straightforward and naive,\" suggesting that dynamical modeling has been widely investigated in the GP community since the introduction of the Gaussian Process Dynamical Model in NIPS 2005. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this critique or improve their approach. Without actionable suggestions or specific feedback, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the use of GP as \"straightforward and naive,\" suggesting that dynamical modeling has been widely investigated in the GP community since the introduction of the Gaussian Process Dynamical Model in NIPS 2005. However, it does not specify which part of the paper this critique pertains to, such as a specific section or methodology, making it difficult for the authors to identify the exact area needing revision. The comment is specific in its critique of the GP approach but lacks grounding as it does not point to a particular part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the use of GP is \"kind of straightforward and naive\" and suggests that dynamical modeling has been widely investigated in the GP community since the introduction of the Gaussian Process Dynamical Model in NIPS 2005. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the GP approach is naive or that dynamical modeling has been extensively explored. Without these elements, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment critiques the use of GP as \"straightforward and naive,\" suggesting that dynamical modeling has been widely investigated in the GP community since the introduction of the Gaussian Process Dynamical Model in NIPS 2005. While the comment identifies a potential weakness in the paper, it lacks specific guidance or suggestions on how the authors might address this critique or improve their approach. Without actionable feedback or detailed advice, the authors are left without a clear path for improvement. Therefore, the comment is 2, as it points out a potential issue but does not provide sufficient direction for the authors to enhance their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the statement in the supplemental section D.4 regarding the necessity of smaller architectures for language models (LMs) compared to generative adversarial networks (GANs). The reviewer points out that this claim is not consistent with their experience and references a study by Zaremba et al. (2014) that trains 1500dimensional LSTMs on PTB. The comment also suggests that the baseline models may not be properly regularized and asks whether dropout is applied to the hidden states. While the comment raises a specific issue and provides a reference for comparison, it does not explicitly instruct the authors to revise or clarify their statement. The action is implicit and somewhat vague, as the authors need to infer that they should address the inconsistency and provide clarification on the regularization methods used. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"supplemental section D.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the statement about the necessity of smaller architectures for language models (LMs) compared to generative adversarial networks (GANs), provides a reference to Zaremba et al. (2014) to support the claim, and asks whether dropout is applied to the hidden states. This level of detail provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the statement in the supplemental section D.4 regarding the necessity of smaller architectures for language models (LMs) compared to generative adversarial networks (GANs). The reviewer provides a counterexample from Zaremba et al. (2014), which suggests that the baseline models may not be properly regularized. This provides a logical reasoning and a specific reference to support the claim, making it 4. However, the comment could be strengthened by further elaborating on the specific issues with the regularization methods or providing more detailed examples. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises a question about a specific statement in the supplemental section D.4 regarding the necessity of smaller architectures for language models (LMs) compared to generative adversarial networks (GANs). The reviewer provides a counterexample from Zaremba et al. (2014) to challenge the claim, suggesting that the baseline models may not be properly regularized. This feedback is valuable as it prompts the authors to reconsider their statement and potentially revise their analysis or provide additional evidence to support their claim. Additionally, the comment asks whether dropout is applied to the hidden states, which could be a relevant detail for the authors to clarify. However, the comment could be more helpful if it offered suggestions on how to address the issue or provided specific guidance on how to improve the regularization methods. Overall, the comment is 4 as it identifies a potential weakness and provides a reference for comparison, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that some ablations mentioned in previous sections are hard to locate in the following contents, suggesting that the writing could be improved in this part. However, it does not provide specific guidance on how to improve the writing or which ablations are particularly difficult to locate. The action is implicit and vague, as the authors are left to infer what changes are needed without concrete instructions. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment mentions \"some ablations\" that are hard to locate, but it does not specify which ablations or sections are being referred to. This lack of specificity makes it difficult for the authors to identify the exact parts of the paper that need improvement. Additionally, the comment does not provide any guidance on how to improve the writing or what specific issues need to be addressed. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that some ablations mentioned in previous sections are hard to locate in the following contents. However, it does not provide specific examples or detailed reasoning to support this claim. Without concrete evidence or references to the specific ablations or sections, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that some ablations mentioned in previous sections are difficult to locate in the following contents. This feedback highlights a potential problem with the organization or presentation of the ablation results, which could impact the clarity and comprehensibility of the paper. However, the comment lacks specificity and does not provide actionable guidance on how to improve the writing or where to locate the ablations. Without detailed suggestions or examples, the authors may struggle to address the issue effectively. Therefore, the comment is 3, as it points out a problem but does not fully support the authors in resolving it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the differential privacy application is \"halfbaked\" and encourages the authors to think through it more clearly. It also recommends moving the experimental results from the appendix to the main paper. While the comment implies that the authors should improve their work on differential privacy, it does not provide specific guidance on how to do so or what aspects need more attention. The suggestion to move the experimental results is explicit but lacks concrete details on how to implement this change. Therefore, the comment is 3, as it identifies areas for improvement but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"given2)5)\" and \"the differential privacy application,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the differential privacy application is \"halfbaked\" and encourages the authors to think it through more clearly. Additionally, it provides a suggestion to move the experimental results from the appendix to the main paper. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the differential privacy application is \"halfbaked\" and suggests that the authors should think it through more clearly. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide references to similar works or explain why the application is considered incomplete. Without such evidence or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the differential privacy application, suggesting that it is \"halfbaked\" and encourages the authors to think it through more clearly. It also highlights the novelty and interest of the online algorithm and robustness, which are separate from the differential privacy application. Additionally, the comment suggests moving the experimental results from the appendix to the main paper, which could improve the paper\"s flow and accessibility. While the comment provides some direction for improvement, it lacks specific suggestions or detailed guidance on how to enhance the differential privacy application or reorganize the experimental results. Therefore, it is 3, as it points out areas for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point claims that the contribution of multilingual chainofthought is incremental compared to the villa chainofthought. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how the authors might address this perceived lack of contribution or improve their work. Without any actionable suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment claims that the contribution of multilingual chainofthought is incremental compared to the villa chainofthought. However, it does not specify which part of the paper this observation is based on, nor does it provide details on what aspects of the contribution are considered incremental. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the contribution are considered incremental, leaving the authors without clear guidance on how to address the issue. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the contribution of multilingual chainofthought is incremental compared to the villa chainofthought. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the comparison or how to address the perceived lack of contribution. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment claims that the contribution of multilingual chainofthought is incremental compared to the villa chainofthought. However, it does not provide any specific details or examples to support this claim, nor does it offer suggestions for improvement or alternative approaches. Without actionable feedback or constructive criticism, the authors are left without a clear understanding of how to address the perceived lack of contribution or how to enhance their work. Therefore, the comment is 1, as it does not provide any value to the authors in terms of improving their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to provide the METEOR results, which is also reported in recent works. This is a clear and direct action for the authors to take, as it specifies exactly what needs to be included in the draft. The comment provides concrete guidance on how to implement the action, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need to provide METEOR results, which should be obvious to the authors. It also specifies what is missing by referencing recent works that report these results. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide METEOR results, which is also reported in recent works. However, the comment does not provide specific references to these recent works or explain why METEOR results are important or relevant to the paper. This lack of detailed justification or references makes the claim 3, as the authors may need to investigate the importance of METEOR results themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment is clear and actionable, instructing the authors to provide METEOR results, which is also reported in recent works. This feedback is specific and provides a direct suggestion for improvement, allowing the authors to address a gap in their draft. By including METEOR results, the authors can enhance the comprehensiveness and validity of their evaluation. However, the comment could be more helpful if it explained why METEOR results are important or how they relate to the paper\"s findings. Overall, the comment is 4 as it guides the authors toward a specific improvement, but it could be more comprehensive with additional context or justification."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the comparability of Geffect values across various unlearning objectives and approaches, suggesting that studying each learning objective in isolation may affect the comparability of results. However, it does not provide explicit guidance or suggestions on how the authors should address this concern or improve the comparability of their results. The comment implies that the authors should consider comparing results across different unlearning objectives and approaches, but it lacks concrete details on how to implement this comparison. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the paper studies the Geffects of each unlearning objective independently and in isolation, which raises concerns about the comparability of Geffect values across various unlearning objectives and approaches. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the comparability of Geffect values across various unlearning objectives and approaches, suggesting that studying each learning objective in isolation may affect the comparability of results. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The lack of evidence or detailed justification makes it difficult for the authors to understand and address the concern effectively. Therefore, the comment is considered 2, as it provides a general concern but lacks the necessary details for full verification.", "helpfulness_rationale": "The review comment identifies a potential issue with the methodology used in the paper, specifically the examination of Geffects of each unlearning objective in isolation. It raises a concern about the comparability of Geffect values across various unlearning objectives and approaches, which could impact the interpretation of results. However, the comment does not provide specific suggestions or guidance on how the authors might address this concern or improve the comparability of their results. While it highlights an important area for consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a potential issue but does not offer detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the reason for the information value being a stronger predictor for dialogue, referencing specific pages in the paper. It suggests that including an explanation from an existing linguistic theory would strengthen the paper. While the comment implies that the authors should consider this addition, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to incorporate an existing linguistic theory or what aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific pages (7 and 8) where the issue is discussed, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a question about the reason for the information value being a stronger predictor for dialogue and suggests that including an explanation from an existing linguistic theory would strengthen the paper. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the reason for the information value being a stronger predictor for dialogue, referencing specific pages in the paper. It suggests that including an explanation from an existing linguistic theory would strengthen the paper. However, the comment does not provide any specific references or detailed reasoning to support the claim that an existing linguistic theory could explain this phenomenon. The suggestion is 3, as it points to a potential area for improvement, but lacks the necessary evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a pertinent question about the reason for the information value being a stronger predictor for dialogue, referencing specific pages in the paper. It suggests that including an explanation from an existing linguistic theory would enhance the paper\"s strength. This feedback is clear and actionable, as it provides a specific area for improvement and a direction for the authors to explore. By addressing this suggestion, the authors can enhance the theoretical foundation and depth of their work. However, the comment could be more helpful if it included specific examples of existing linguistic theories or provided more detailed guidance on how to integrate them into the paper. Overall, the comment is 4, as it offers a constructive and actionable suggestion for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a missed opportunity in the paper to discuss the potential benefits of using AutoML approaches beyond improving raw performances. It suggests that the authors should comment on the \"hints\" that can be extracted from the found architecture and what the \"biggest takeaways\" might be. While the comment implies that the authors should address these aspects, it does not provide explicit instructions or concrete steps on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should discuss the potential benefits and takeaways of AutoML approaches. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of discussion on the potential benefits of using AutoML approaches beyond improving raw performances, specifically mentioning the extraction of \"hints\" that could be used in designing new network architectures. However, it does not specify which part of the paper this critique pertains to, such as a particular section or discussion where this aspect should be addressed. The authors can infer that it relates to the methodology or results sections, but the comment lacks explicit grounding. It is specific in detailing what the authors should discuss, namely the \"biggest takeaways\" from the found architecture, but without clear grounding, it aligns with a 3 label.", "verifiability_rationale": "The review point claims that the authors should discuss the potential benefits of using AutoML approaches beyond improving raw performances, specifically mentioning the extraction of \"hints\" that could be used in designing new network architectures. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion. The lack of detailed reasoning or evidence makes the claim 3, as the authors would need to infer the importance of discussing these aspects based on the general idea presented. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the paper by pointing out that the authors have not discussed the potential benefits of using AutoML approaches beyond improving raw performances. It suggests that the authors should comment on the \"hints\" that can be extracted from the found architecture and what the \"biggest takeaways\" might be. This feedback is clear and actionable, as it directs the authors to consider the broader implications of their work and how it could inform future network architecture design. However, the comment could be more helpful if it provided specific examples or suggestions on how to address this gap. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy in the definition of T_a(t), noting that it is used in Section 3.1 but is only defined in Section 4. This feedback is explicit and provides a clear action for the authors to take: they should define T_a(t) in Section 3.1 to ensure consistency and clarity. The comment is concrete because it specifies exactly what needs to be done to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1\" and \"Section 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out a discrepancy in the definition of T_a(t), which is used in one section but defined in another. This provides clear guidance on what needs to be addressed to ensure consistency and clarity in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about the usage and definition of T_a(t) in different sections of the paper. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that T_a(t) is used in Section 3.1 but is only defined in Section 4. This observation highlights a potential inconsistency or lack of clarity in the paper, which could impact the reader\"s understanding. However, the comment does not provide any suggestions or guidance on how to address this issue or improve the clarity of the paper. While it points out a problem, it lacks actionable feedback or detailed advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the main part, particularly the introduction, could be more concise and should include empirical results. However, it does not provide specific guidance on how to achieve this conciseness or what specific empirical results should be included. The action is implicit and somewhat vague, as the authors are left to infer what changes are needed without detailed instructions. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the main part, particularly the introduction, could be more concise and should include empirical results. However, it does not specify which part of the main section or the introduction is being referred to, making it difficult for the authors to pinpoint the exact areas needing improvement. Additionally, the comment lacks specificity regarding what aspects of the empirical results should be included or how they could be integrated. As a result, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the main part, particularly the introduction, could be more concise and should include empirical results. However, it does not provide any specific reasoning, examples, or references to support why the current content is not concise or why empirical results are necessary. Without additional context or justification, the authors may find it challenging to understand and address the feedback. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the main part of the paper, particularly the introduction, could be more concise and should include empirical results. While it identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on how to achieve conciseness or what specific empirical results should be included. The feedback is 3 as it points out a general area for improvement, but it does not offer actionable steps or detailed suggestions, leaving the authors with limited direction for enhancing their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper\"s primary contribution is an incremental advancement in efficiency over the TACTiS approach. It suggests that more substantial evidence or arguments are needed to establish this as a significant contribution to the field. However, the comment does not provide specific guidance on how the authors might achieve this or what additional evidence or arguments could be included. The action is implicit and vague, as the authors are left to infer that they need to provide more substantial evidence but are not given concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the paper\"s primary contribution, which is described as an incremental advancement in efficiency over the TACTiS approach. However, it does not specify which part of the paper discusses this contribution, making it weakly grounded. The comment is specific in its request for more substantial evidence or arguments to establish the contribution as significant. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper\"s primary contribution is an incremental advancement over the TACTiS approach, suggesting that more substantial evidence or arguments are needed to establish this as a significant contribution. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence makes the claim 3, as the authors would need to infer the gaps in the argument themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper\"s primary contribution, suggesting that it is an incremental advancement over the TACTiS approach. It highlights the need for more substantial evidence or arguments to establish this contribution as significant. While the comment points out an area for improvement, it lacks specific guidance or suggestions on how the authors might enhance their argument or provide additional evidence. This limits the comment\"s usefulness, as it provides insight but does not offer actionable steps for improvement. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point critiques the novelty and incremental nature of the paper, suggesting that the improvements on different datasets are trivial and that the topic has been extensively explored in previous works. However, it does not provide any specific guidance or suggestions for the authors to address these concerns. There is no explicit or implicit action for the authors to take, such as identifying areas for originality or suggesting ways to enhance the novelty of the work. As a result, the comment lacks actionability and provides no direction for improvement, making it 1.", "grounding_specificity_rationale": "The comment critiques the novelty and incremental nature of the paper, specifically mentioning that the improvements on different datasets are trivial and that the topic has been extensively explored in previous works. However, it does not specify which parts of the paper are being addressed, such as which datasets are being discussed or which previous works are being referenced. This lack of explicit references makes it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its critique of the novelty and incremental nature of the work but lacks grounding, as it does not clearly identify the parts of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the improvements on different datasets are trivial and that the novelty of the paper is limited, suggesting that the topic has been extensively explored in previous works. However, the comment lacks specific examples or references to support these claims, such as mentioning which previous works have addressed similar topics or how the current work compares to them. Without detailed evidence or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment critiques the novelty and incremental nature of the paper, suggesting that the improvements on different datasets are trivial and that the topic has been extensively explored in previous works. While it identifies a potential weakness in the paper, it lacks specific guidance or suggestions on how the authors might address this issue or enhance the novelty of their work. Without actionable feedback or constructive advice, the comment provides limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the improvements over baselines are marginal and within the error bar range, questioning the significance of the performance differences. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue of marginal improvements or how to improve the method\"s performance. Without actionable suggestions or a clear direction for improvement, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the performance of the method compared to baselines, specifically mentioning the error range and the claim of better performance. However, it does not specify which part of the paper discusses these results, making it weakly grounded. The comment is specific in detailing the issue with the performance differences, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the improvements over baselines are marginal and within the error bar range, questioning the significance of the performance differences. This claim is based on the observation that the error range is high, suggesting that the performance differences between some methods are not very significant. However, the comment lacks specific examples or detailed analysis to substantiate the claim, making it 3. The authors would need to further investigate the data and results to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment points out a potential issue with the paper\"s claims regarding the performance of the method compared to baselines. It highlights that the improvements are marginal and within the error bar range, questioning the significance of the performance differences. This feedback is 3 as it prompts the authors to reconsider their claims and potentially provide more detailed analysis or evidence to support their assertions. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as recommending additional experiments or analyses to clarify the performance differences. Therefore, it is rated as 3, as it identifies a potential weakness but does not provide comprehensive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of clarity regarding how to make the new proposed evaluation set more diverse and representative compared to the previous method. It also questions the selection of representative images. While the comment identifies a specific area needing clarification, it does not provide explicit guidance or suggestions on how the authors might address these issues. The action is implicit and somewhat vague, as the authors are left to infer what steps to take to improve the clarity of the evaluation set and selection process. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the clarity of how the new proposed evaluation set is more diverse and representative compared to the previous method, and how representative images are selected. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what is unclear, providing a clear direction for the authors to address. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the clarity of how the new proposed evaluation set is more diverse and representative compared to the previous method, and how representative images are selected. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is unclear or how it could be improved. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the clarity of how the new proposed evaluation set is more diverse and representative compared to the previous method. It also questions the selection of representative images. While the comment highlights an important issue, it lacks actionable suggestions or guidance on how the authors might address these concerns. Without specific advice or examples, the authors may find it challenging to make meaningful improvements to their draft. Therefore, the comment is 3, as it points out a weakness but does not provide sufficient direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the authors should include a background section on the basic RL framework, including elements of the MDP, trajectories, and policy, to clarify the RL context being considered. It also suggests providing a brief overview of the original DPO algorithm to distinguish the modifications proposed in the methods section. These actions are clear and concrete, giving the authors specific guidance on what needs to be added to their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests including a background section on the basic RL framework and a brief overview of the original DPO algorithm. While it does not explicitly mention specific sections of the paper, the authors can infer that these additions should be made in the introduction or background sections. The comment is specific in detailing what needs to be addressed, such as clarifying the RL context and distinguishing modifications from the original DPO algorithm. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper lacks a background section on the basic RL framework and a brief overview of the original DPO algorithm. This claim is supported by logical reasoning, as it explains that without these introductions, it is difficult to follow the subsequent sections. The comment provides a clear rationale for why these additions are necessary, making it 4. However, it could be strengthened by referencing specific elements of the RL framework or DPO algorithm that should be included, which would align with a score of 5.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of a background section on the basic RL framework and a brief overview of the original DPO algorithm. This feedback is clear and actionable, as it provides specific guidance on what the authors need to include to improve the clarity and comprehensiveness of their draft. By addressing these suggestions, the authors can enhance the reader\"s understanding of the context and the modifications proposed in the methods section. However, the comment could be more helpful if it offered examples or specific details on what should be included in these sections. Overall, the comment is 4, as it directs the authors toward a critical improvement in their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential limitation of the proposed method, specifically mentioning that it may face issues if users continuously add new languages due to limited model capacity. However, the comment does not provide any explicit or implicit actions for the authors to take in response to this limitation. It lacks guidance on how to address this issue or suggestions for potential solutions. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a potential limitation of the proposed method, specifically mentioning that it may face issues if users continuously add new languages due to limited model capacity. However, it does not specify which part of the paper discusses the proposed method or where this limitation is addressed. Without explicit references to sections, tables, or figures, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the method are affected by this limitation or how it could be addressed. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the proposed method may encounter a limitation if users continuously add new languages due to limited model capacity. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the limitation or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation of the proposed method, specifically mentioning that it may face issues if users continuously add new languages due to limited model capacity. This is a relevant observation that could impact the scalability and applicability of the method. However, the comment lacks specificity and does not provide any suggestions or guidance on how the authors might address this limitation or improve the method to accommodate additional languages. Without actionable feedback or detailed advice, the authors are left with a general awareness of the issue but without a clear path to resolution. Therefore, the comment is 3, as it points out a potential concern but does not fully support the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the S2D structure, specifically why the number of parameters does not change despite an increase in depth. The reviewer acknowledges that the efficiency could be improved but suggests that more details are needed regarding the parameters. While the comment implies that the authors should provide additional information on the parameters, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"S2D structure,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue regarding the number of parameters not changing despite an increase in depth, and it suggests that more details are needed on the parameters. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the S2D structure, specifically why the number of parameters does not change despite an increase in depth. The reviewer acknowledges that the efficiency could be improved but suggests that more details are needed regarding the parameters. While the comment provides a logical reasoning for the question, it lacks specific examples or references to support the claim about the parameters. This makes the claim 3, as it provides a basis for the question but requires further elaboration or evidence to be fully substantiated.", "helpfulness_rationale": "The review comment raises a specific question about the S2D structure, specifically why the number of parameters does not change despite an increase in depth. It acknowledges that the efficiency could be improved but suggests that more details are needed regarding the parameters. While the comment identifies a potential area for improvement, it lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue. The feedback is 3 as it prompts the authors to consider this aspect of their work, but it could be more actionable with additional details or examples. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the similarity of the proposed method to the approach in reference 10 and suggests that the method in 10 could also be equipped with scoring causal predictions and interventional data. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or whether they should consider incorporating these elements into their method. The comment lacks concrete actions or details on how to implement any changes, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the similarity of the proposed method to the approach in reference 10 and suggests that the method in 10 could also be equipped with scoring causal predictions and interventional data. However, it does not specify which part of the paper this comparison is based on, making it difficult for the authors to pinpoint the exact section that needs attention. The comment lacks specificity as it does not detail what aspects of the proposed method are similar or how they could be improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the similarity of the proposed method to the approach in reference 10 and suggests that the method in 10 could also be equipped with scoring causal predictions and interventional data. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. It lacks specific examples or detailed comparisons to justify the assertion, making it difficult for the authors to understand the basis of the comparison. As a result, the claim is 1, as it does not provide sufficient information for the authors to address the issue effectively.", "helpfulness_rationale": "The review comment raises a question about the similarity of the proposed method to the approach in reference 10 and suggests that the method in 10 could also be equipped with scoring causal predictions and interventional data. However, it does not provide specific guidance or suggestions on how the authors should address this issue or whether they should consider incorporating these elements into their method. The comment lacks actionable feedback and does not offer a clear path for improvement, making it 2. The authors are left with a vague understanding of the potential similarities and a question about the limitations of their approach, but without concrete steps to enhance their work. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a limitation in the Atari game results, noting that they are limited to a single game and a single baseline, making it difficult to interpret. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to expand the results, what additional games or baselines to include, or how to improve the interpretability of the results. Without specific suggestions or instructions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 7.2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the limitation of the Atari game results, which are limited to a single game and a single baseline, making it difficult to interpret. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the Atari game result (Section 7.2) is limited to a single game and a single baseline, making it difficult to interpret. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific limitation in the Atari game results, noting that they are limited to a single game and a single baseline, which makes it difficult to interpret. This is a clear and actionable feedback that highlights a weakness in the paper\"s presentation of results. However, the comment does not provide suggestions or guidance on how the authors might address this limitation, such as recommending additional games or baselines to include or suggesting ways to improve the interpretability of the results. While it points out a significant issue, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight into a critical area for improvement but lacks detailed guidance for the authors to effectively address it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide a more detailed explanation of why the GPC (benchmark) is performing better than BPC (their method). It implies that the authors should reiterate that the better performance of GPC is due to the bandit feedback and not using information about the form of the cost function. While the comment explicitly states the need for additional explanation, it does not provide specific guidance on how to present this information or what specific details to include. The action is explicit but somewhat vague, as the authors know they need to provide more context but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"presentation of the simulation study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the presentation, namely the lack of commentary on why the GPC (benchmark) is performing better than BPC (the authors\" method). The comment provides a suggestion for improvement by recommending that the authors reiterate the reason for the better performance, which is due to the bandit feedback and not using information about the form of the cost function. This level of detail provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the presentation of the simulation study does not provide sufficient explanation for why the GPC (benchmark) is performing better than BPC (the authors\" method). The reviewer suggests that the authors should reiterate that the better performance is due to the bandit feedback and not using information about the form of the cost function. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion. This makes the claim 3, as the authors would need to provide additional evidence or explanation to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of the simulation study, noting that the authors do not provide sufficient explanation for why the GPC (benchmark) is performing better than BPC (their method). It suggests that the authors should reiterate that the better performance is due to the bandit feedback and not using information about the form of the cost function. This feedback is clear and actionable, as it directs the authors to address a critical gap in their analysis. By providing this guidance, the comment helps the authors improve the clarity and comprehensiveness of their presentation, making it more valuable to readers. Therefore, the comment is rated as 4, as it offers specific suggestions for improvement but could be more comprehensive by providing additional context or examples."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the reported perplexities in Figure 1, which are over 30, and questions the contradiction with better BLEU scores. It also asks how perplexity was calculated. While the comment identifies a potential issue and requests clarification, it does not provide specific guidance on how the authors should address this contradiction or improve their calculations. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify their perplexity calculations and potentially reconcile the discrepancy with BLEU scores. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the high perplexity values reported in the figure and questions the contradiction with better BLEU scores. The comment further asks for clarification on how perplexity was calculated. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the high perplexity values reported in Figure 1, suggesting a contradiction with better BLEU scores. The reviewer asks for clarification on how perplexity was calculated. While the comment raises a valid concern, it lacks specific evidence or references to support the claim of high perplexity being contradictory to better BLEU scores. The request for clarification is reasonable, but the comment itself does not provide sufficient justification or evidence to fully substantiate the claim. Therefore, the comment is 3, as it requires additional information or explanation to be fully supported.", "helpfulness_rationale": "The review comment raises a concern about the high perplexity values reported in Figure 1, suggesting that they are contradictory to better BLEU scores. It questions the calculation of perplexity and requests clarification. While the comment identifies a potential issue, it lacks depth and does not provide specific suggestions or guidance on how the authors might address this contradiction or improve their calculations. The feedback is 3 as it prompts the authors to clarify their methodology, but it could be more actionable with additional details or examples. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the evaluation needs experiments on distributed deployment and a larger model. This provides clear guidance on what the authors need to do to improve their draft. The action is direct and concrete, as it specifies the exact experiments that should be conducted. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the evaluation needs experiments on distributed deployment and a larger model. However, it does not specify which part of the paper this feedback pertains to, such as the methodology or results sections. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing improvement. While the comment is specific in suggesting the need for experiments on distributed deployment and a larger model, it is 1 because it does not indicate where these changes should be made. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the evaluation needs experiments on distributed deployment and a larger model. However, it does not provide any supporting evidence, reasoning, or references to justify why these experiments are necessary or how they would improve the evaluation. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the evaluation section of the paper. It suggests that the evaluation should include experiments on distributed deployment and a larger model. This feedback is clear and actionable, providing the authors with a concrete direction to enhance the robustness and applicability of their evaluation. However, the comment could be more helpful if it explained why these experiments are necessary or how they would contribute to the paper\"s findings. Overall, the comment is 4 as it directs the authors to a meaningful enhancement of their evaluation, but it could be more comprehensive with additional context or rationale."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should provide a brief discussion on why rooted patterns are important and how they choose the roots. It also implies that if nonrooted patterns are sufficient, the discussion should be moved to the supplementary material. This feedback is clear and provides a direct action for the authors to take, making it 5. The authors know exactly what needs to be done to address the reviewer\"s concern, which is to either include a discussion on the importance of rooted patterns or move the discussion to the supplementary material if nonrooted patterns are sufficient. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"rooted patterns,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of elaboration on why rooted patterns are important and how they choose the roots. Additionally, it suggests that a brief discussion is expected or that the discussion should be moved to the supplementary material if nonrooted patterns are sufficient. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide a brief discussion on the importance of rooted patterns and how they choose the roots. It implies that this discussion is necessary for the sake of exposition. However, the comment does not provide specific reasoning or evidence to support why this discussion is crucial or how it would enhance the paper. Without detailed justification or examples, the claim remains somewhat vague, making it difficult for the authors to fully understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks clarity and provides a clear suggestion for improvement. It points out that the authors define rooted patterns but do not explain why they are important or how they choose the roots. The comment suggests that a brief discussion on these points is expected or that the discussion could be moved to the supplementary material if nonrooted patterns are sufficient. This feedback is actionable and provides a clear direction for the authors to enhance the clarity and comprehensiveness of their work. However, it could be more helpful if it included specific examples or further guidance on how to structure the discussion. Overall, the comment is 4, as it effectively guides the authors toward improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should include some failure cases and related discussion in their paper. While the comment implies that the authors should add this information, it does not provide specific guidance on which failure cases to include or how to structure the discussion. The action is implicit and somewhat vague, as the authors need to infer what specific failure cases to address and how to discuss them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests including failure cases and related discussion, but it does not specify which part of the paper this should be added to. The authors might infer that it relates to the results or discussion sections, but this inference is not explicit. The comment is specific in suggesting the inclusion of failure cases, but it lacks grounding as it does not identify a particular section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that including failure cases and related discussion would be beneficial. However, it does not provide any specific examples, reasoning, or references to support why this is necessary or how it would enhance the paper. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the importance of addressing failure cases. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that including failure cases and related discussion would be beneficial for the paper. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on how to incorporate failure cases or what aspects of the discussion should be focused on. The feedback is 3 as it points out a direction for enhancement, but it could be more actionable with additional details or examples. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the necessity of the base layer GNN encoding in the proposed method and suggests conducting an ablation study to determine its importance. While the comment implies that the authors should conduct an ablation study, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to conduct the ablation study or what aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the necessity of the base layer GNN encoding in the proposed method and suggests conducting an ablation study to determine its importance. However, it does not specify which part of the paper discusses this encoding, making it weakly grounded. The comment is specific in suggesting an ablation study to address the issue, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the necessity of the base layer GNN encoding in the proposed method and suggests conducting an ablation study to determine its importance. However, the comment does not provide any specific reasoning or evidence to support why the base layer GNN encoding is unclear or why an ablation study would be beneficial. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential area of confusion in the paper regarding the necessity of the base layer GNN encoding in the proposed method. It suggests conducting an ablation study to determine its importance, which is a clear and actionable piece of feedback. By recommending this additional analysis, the comment provides the authors with a specific direction for improving their draft. However, the comment could be more helpful if it explained why the base layer GNN encoding might be unnecessary or how it could impact the overall performance of the method. Overall, the comment is 4 as it offers a constructive suggestion for enhancing the paper."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should add an explicit discussion on the upper bounds of counting and potentially elaborate on empirical runtimes related to the computational complexity of counting homomorphisms. This feedback provides a clear and concrete action for the authors to take, ensuring they know exactly what needs to be addressed in their draft. The comment is explicit and provides specific guidance on how to improve the paper, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L 145\" and the specific topic of \"computational complexity of counting homomorphisms,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the need for an explicit discussion on upper bounds of counting and potential elaboration on empirical runtimes. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors do not adequately discuss the computational complexity of counting homomorphisms and suggests that they should add an explicit discussion on upper bounds and potentially elaborate on empirical runtimes. The comment provides a specific example from the paper (\"L 145\") to support the claim, which helps justify the need for additional discussion. However, it lacks detailed reasoning or references to specific methods or studies that could further substantiate the claim. While the comment provides a clear direction for improvement, it could be strengthened with more detailed evidence or examples. Therefore, the comment is 4, as it provides a solid basis for the claim but could benefit from additional support.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks depth, namely the discussion on the computational complexity of counting homomorphisms. It points out that the authors make only brief statements about this topic and suggests that the paper would benefit from explicitly adding upper bounds and potentially elaborating on empirical runtimes. This feedback is clear and actionable, providing the authors with a specific direction for improvement that could enhance the comprehensiveness and rigor of their work. However, the comment could be more helpful if it included examples or references to guide the authors in addressing this issue. Overall, the comment is 4 as it effectively directs the authors to a critical area for enhancement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should include a study of inference time, particularly comparing it to previous topdown and bottomup pose estimation methods. While the comment implies that this is an important aspect to consider, it does not explicitly instruct the authors to conduct this study or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to include a study of inference time but are not given detailed instructions on how to implement it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should include a study of inference time, particularly comparing it to previous topdown and bottomup pose estimation methods. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper that needs revision. While the comment is specific in suggesting a comparison with previous methods, it is 1 because it does not indicate where this comparison should be included. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should include a study of inference time, particularly comparing it to previous topdown and bottomup pose estimation methods. The claim is based on the premise that the current method is direct and does not require detection or keypoint grouping, which could potentially lead to faster inference. However, the comment lacks specific examples or references to previous methods that have been studied for inference time, making it difficult for the authors to fully understand the basis of the suggestion. The lack of detailed justification or evidence makes the claim 3, as it provides a general direction but requires more detailed support to be fully actionable.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting that the paper should include a study of inference time, particularly in comparison to previous topdown and bottomup pose estimation methods. This feedback is 3 as it points out a specific aspect that could enhance the paper\"s contribution and provide valuable insights into the efficiency of the proposed method. However, the comment lacks detailed guidance on how to conduct this study or what specific metrics to consider, which would make it more actionable. Additionally, it does not address other aspects of the paper, such as the methodology or results, limiting its comprehensive value. Therefore, the comment is rated as 3, as it provides a direction for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the claim about evolutionary dropout addressing internal covariate shift is limited, as it can only increase the variance of some lowvariance units. It further notes that batch normalization standardizes the variance and centers the activation, and recommends discussing these limitations explicitly. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to address the limitations or what specific aspects should be discussed. The action is implicit and somewhat vague, as the authors are left to infer the exact changes needed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific claim about evolutionary dropout addressing internal covariate shift, suggesting that it is limited in its ability to increase the variance of some lowvariance units. It also mentions batch normalization as a comparison, suggesting that it standardizes the variance and centers the activation. However, the comment does not specify which part of the paper discusses this claim, making it weakly grounded. The comment is specific in detailing the limitations of the claim and suggesting that these should be discussed explicitly. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the claim about evolutionary dropout addressing internal covariate shift is limited, as it can only increase the variance of some lowvariance units. The reviewer contrasts this with batch normalization, which standardizes the variance and centers the activation. While the comment provides a logical comparison, it lacks specific examples or references to support the claim fully. The reasoning is 3, as it highlights a potential limitation of the claim, but the lack of detailed evidence or references makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific limitation in the claim about evolutionary dropout addressing internal covariate shift, suggesting that it can only increase the variance of some lowvariance units. It contrasts this with batch normalization, which standardizes the variance and centers the activation. The comment provides a clear and actionable suggestion to discuss these limitations explicitly, which could help the authors refine their understanding and presentation of the topic. However, the comment could be more helpful if it offered additional context or examples to further guide the authors in addressing the issue. Overall, the feedback is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with further elaboration. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the author should provide more description about the contribution of the paper. However, it does not specify what aspects of the contribution should be elaborated on or how this description should be incorporated into the paper. The action is explicit in terms of adding more description, but it lacks concrete guidance on what specific aspects to focus on or how to present the contribution. As a result, the comment is 3, as the authors know they need to add more description but may struggle to determine the exact content or format of this addition.", "grounding_specificity_rationale": "The comment suggests that the author should provide more description about the contribution of the paper. However, it does not specify which part of the paper lacks this description or what specific aspects of the contribution need elaboration. Without explicit references to sections or examples, the authors cannot confidently determine which parts of the paper need improvement. This makes the comment weakly grounded, as the authors cannot pinpoint the exact areas needing attention. Additionally, the comment lacks specificity because it does not provide detailed guidance on what aspects of the contribution should be described. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the author should provide more description about the contribution of the paper. However, it does not provide any specific reasoning, examples, or references to support why this additional description is necessary or how it would enhance the paper. Without such details, the claim lacks verifiability, as the authors are left without a clear understanding of what aspects of the contribution need further elaboration. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the author should provide more description about the contribution of the paper. While it identifies a potential area for improvement, it lacks specificity and does not offer guidance on what aspects of the contribution should be elaborated upon or how to present them. Without detailed suggestions or examples, the authors may struggle to determine how to effectively address this feedback. Therefore, the comment is 2, as it points out a general area for improvement but does not provide actionable guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point provides several suggestions for improving the organization and clarity of the paper. It recommends separating the description of the main contributions, specifically the two types of attention for deep VAEs, into a dedicated section. Additionally, it suggests referencing normalization and feature scaling in a separate section. While these suggestions are explicit, they lack concrete details on how to implement them, such as specific sections where these changes should be made. The authors know what needs to be done but may struggle with the execution, making the comment 3.", "grounding_specificity_rationale": "The comment provides specific suggestions for improving the organization and clarity of the paper. It recommends separating the description of the main contributions, specifically the two types of attention for deep VAEs, into a dedicated section. It also suggests referencing normalization and feature scaling in a separate section. However, the comment does not explicitly mention which sections these changes should be made in, making it weakly grounded. The authors can infer that it relates to sections 2.3 and 2.4, but this inference is not as direct as it could be. The comment is specific in detailing what needs to be addressed, but the lack of explicit grounding limits its effectiveness. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of minor suggestions for improving the organization and clarity of the paper. It does not contain any subjective claims, opinions, or judgments that require verification. It is purely descriptive and does not present any claims that need to be substantiated. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback on how to improve the organization and clarity of the paper. It suggests separating the description of the main contributions, specifically the two types of attention for deep VAEs, into a dedicated section. This would help readers better understand the contributions and their significance. Additionally, it recommends referencing normalization and feature scaling in a separate section, which could enhance the comprehensiveness of the paper. While the comment is clear and provides valuable guidance, it could be more helpful if it included specific suggestions on where these changes should be implemented. Overall, the feedback is 4 as it directs the authors toward improvements that can enhance the clarity and structure of their work."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the performance differences between methods are minimal across evaluations, with differences less than 1 percentage point. It also mentions that the benchmarks are outdated and likely saturated. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the issue of minimal performance differences or outdated benchmarks. Without actionable suggestions or recommendations, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the performance differences between methods and the minimal variations across evaluations. It also references the outdated nature of the benchmarks, providing a specific reason for the minimal performance differences. However, the comment lacks specificity in terms of what needs to be addressed or how the authors should respond to the issue of outdated benchmarks. While it identifies the problem, it does not provide detailed guidance on how to improve the paper. Therefore, this comment is fully grounded but underspecific, aligning with a score of 4.", "verifiability_rationale": "The review point claims that the performance differences between methods are minimal, with variations less than 1 percentage point, and attributes this to random variation and outdated benchmarks. The claim is 3 as it provides a logical explanation for the minimal differences, but it lacks specific examples or references to substantiate the claim fully. The mention of an external reference, \"1 LoRA Learns Less and Forgets Less(https://arxiv.org/abs/2405.09673),\" could be used to support the claim but is not fully integrated into the reasoning. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, noting that the performance differences between methods are minimal across evaluations, with variations less than 1 percentage point. It suggests that this may be due to random variation and that the benchmarks are outdated and likely saturated. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve their work. Without actionable advice or detailed feedback, the authors are left without a clear path to enhance their draft. Therefore, the comment is 3, as it points out a potential weakness but does not provide sufficient direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and observations about the method\"s applicability and benefits. It questions why the method helps on Hopper, which has deterministic dynamics, and suggests evaluating it on domains with nondeterministic dynamics to assess its empirical efficacy. The comment also points out the absence of BEAR from the baselines and questions the method\"s benefits. While the comment raises important points for consideration, it does not provide explicit instructions or concrete suggestions for the authors to address these issues. The actions are implicit and somewhat vague, as the authors need to infer what steps to take to address the questions and concerns. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises several questions and observations about the method\"s applicability and benefits. It questions why the method helps on Hopper, which has deterministic dynamics, and suggests evaluating it on domains with nondeterministic dynamics to assess its empirical efficacy. The comment also points out the absence of BEAR from the baselines and questions the method\"s benefits. However, the comment does not specify which part of the paper these questions and observations are based on, making it difficult for the authors to pinpoint the exact sections that need attention. While the authors might infer that it relates to the methodology or results sections, the lack of explicit grounding makes it challenging to address the feedback effectively. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point consists of a series of questions and observations, each of which requires verification or further explanation. The first question about the method\"s applicability on Hopper, which has deterministic dynamics, is not supported by any evidence or reasoning. The second question about evaluating the method on domains with nondeterministic dynamics is a request for clarification, not a claim. The third question about the absence of BEAR from the baselines is a request for clarification, not a claim. Overall, the comment lacks verifiable claims or evidence, making it difficult for the authors to address the points effectively. Therefore, it is rated as 1.", "helpfulness_rationale": "The review comment raises several important questions and observations about the method\"s applicability and benefits. It questions why the method helps on Hopper, which has deterministic dynamics, and suggests evaluating it on domains with nondeterministic dynamics to assess its empirical efficacy. This is a valuable suggestion that could help the authors better understand and demonstrate the method\"s effectiveness. Additionally, the comment points out the absence of BEAR from the baselines, which could be a relevant comparison for the authors to consider. However, the comment lacks specific guidance or suggestions on how to address these questions or improve the draft. While it identifies areas for improvement, it does not provide detailed actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should provide a theoretical justification for why cotraining and weight averaging can improve results. While the comment implies that the authors should include this justification, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not specify the exact details of the theoretical justification that should be provided. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should provide a theoretical justification for why cotraining and weight averaging can improve results. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where these methods are discussed. Without explicit references to the paper, the authors may find it challenging to determine where to incorporate this feedback. The comment is specific in its request for a theoretical justification but lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should provide a theoretical justification for why cotraining and weight averaging can improve results. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should provide a theoretical justification for why cotraining and weight averaging can improve results. This is a valuable suggestion as it encourages the authors to deepen their understanding of the methods and their impact on performance. However, the comment could be more helpful if it provided specific guidance on what aspects of the theoretical justification should be included or how to approach it. While it identifies a critical area for improvement, the feedback lacks depth and actionable details, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide more details about the proposed method, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. While the comment implies that the authors should include these details, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to present these details. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that more details should be provided about the proposed method, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. However, it does not specify which part of the paper this information should be added to, making it weakly grounded. The comment is specific in detailing what additional information is needed, but without clear grounding, the authors may struggle to identify the exact sections that require revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more details should be provided about the proposed method, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. However, the comment does not provide any specific examples, reasoning, or references to support why these details are necessary or how they would improve the paper. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors should provide more details about their proposed method. It highlights the need to explain how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. This feedback is clear and actionable, as it directs the authors to enhance their explanation of a critical aspect of their methodology. However, the comment could be more helpful if it provided specific suggestions or examples on how to present these details effectively. Overall, the comment is 4 as it guides the authors toward improving their draft by addressing a key area of uncertainty."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential limitation of the proposed method, specifically its difficulty in detecting hallucinations in openended responses. It provides an example scenario where the prompt \"introduce a sports celebrity to me\" could lead to responses about different individuals, making it challenging to identify shared information for consistency checking. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their method. The action is implicit and somewhat vague, as the authors are left to infer that they should consider ways to enhance the method\"s ability to detect hallucinations in openended responses. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed method and provides a specific example scenario where the method might struggle to detect hallucinations in openended responses. It also specifies the issue by discussing the challenge of identifying shared information for consistency checking in responses to the prompt \"introduce a sports celebrity to me.\" This level of detail allows the authors to accurately identify the part of the paper being addressed and understand the specific concern, making the comment 5. Therefore, this comment aligns with a score of 5.", "verifiability_rationale": "The review point claims that the proposed method might struggle to detect hallucinations in openended responses, specifically in the context of a prompt like \"introduce a sports celebrity to me.\" The reviewer provides a specific example scenario to illustrate the challenge, which helps support the claim. However, the comment could be strengthened by providing more detailed reasoning or examples of how this issue might manifest or impact the method\"s performance. Overall, the claim is 4, as it provides a logical basis for the concern but lacks comprehensive evidence or references. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a potential limitation of the proposed method, specifically its difficulty in detecting hallucinations in openended responses. It provides a specific example scenario, \"introduce a sports celebrity to me,\" to illustrate the challenge of identifying shared information for consistency checking. This feedback is valuable as it highlights a specific area where the method might struggle, prompting the authors to consider ways to address this issue. However, the comment could be more helpful if it offered suggestions or potential solutions for improving the method\"s performance in such scenarios. Overall, the comment is 3 as it provides insight into a potential weakness but lacks actionable guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a lack of clarity regarding how theoretical findings relate to realworld deep learning models. It suggests that the authors should verify their conclusion about label noise and model size on MNIST and CNN. While the comment implies that the authors should conduct additional experiments to validate their findings, it does not provide specific guidance on how to conduct these experiments or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a lack of clarity regarding how theoretical findings relate to realworld deep learning models. It suggests verifying the conclusion about label noise and model size on MNIST and CNN. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in suggesting a way to address the issue by conducting additional experiments. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the theoretical findings are unclear in relation to realworld deep learning models and suggests verifying the conclusion about label noise and model size on MNIST and CNN. However, the comment lacks specific reasoning or evidence to support why these theoretical findings are unclear or how they differ from realworld applications. Without detailed justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the applicability of theoretical findings to realworld deep learning models. It suggests that the authors should verify their conclusion about label noise and model size on MNIST and CNN, which is a clear and actionable suggestion. This feedback provides the authors with a concrete step to take to improve the validity and relevance of their work. However, the comment could be more helpful if it included additional guidance on how to conduct these verifications or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors toward a meaningful improvement in their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the authors should mention that p(y|H_f^(tn)) has to be chosen Gaussian, as otherwise Kalman Filtering and Smoothing and CVI are not possible. It also notes that this assumption is later made in the ELBOs. This feedback provides a clear and direct action for the authors to take, specifying what needs to be mentioned and why. The comment is explicit and concrete, giving the authors precise guidance on how to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the part of the paper where the issue is addressed, specifically mentioning \"p(y|H_f^(tn))\" and \"ELBOs.\" This allows the authors to accurately identify the sections being addressed. The comment is also specific because it clearly specifies what needs to be addressed: the assumption that p(y|H_f^(tn)) has to be chosen Gaussian to make Kalman Filtering and Smoothing and CVI possible. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \"p(y|H_f^(tn)) has to be chosen Gaussian, as otherwise Kalman Filtering and Smoothing and CVI is not possible.\" This claim is supported by logical reasoning, as it explains that the choice of Gaussian distribution is necessary for specific methods like Kalman Filtering and Smoothing and CVI to be applicable. However, the comment could be strengthened by providing more detailed reasoning or references to specific methods or literature that rely on this assumption. Overall, the claim is 4, as it provides a logical basis but lacks comprehensive evidence or references. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improvement by pointing out that the paper should mention that p(y|H_f^(tn)) has to be chosen Gaussian to make Kalman Filtering and Smoothing and CVI possible. This feedback is clear and direct, offering a concrete step for the authors to take to enhance the clarity and completeness of their draft. By addressing this point, the authors can ensure that their readers fully understand the assumptions and limitations of their methods. Therefore, the comment is 5, as it empowers the authors to make a significant improvement in their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two main issues: the lack of qualitative experiments to demonstrate the validity of the conditional independence model and the need for additional experiments to validate the proposed test metric. The reviewer suggests providing illustrative experimental results, including a toy dataset to demonstrate the separability of inlier features and outlier features, and recommends visualizations or schematic diagrams to aid understanding. These suggestions are explicit and provide concrete guidance on how to address the issues, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"qualitative experiments\" and \"the conditional independence model,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear suggestions for improvement, such as conducting illustrative experiments, using a toy dataset, and providing visualizations or schematic diagrams to aid understanding. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a lack of qualitative experiments to demonstrate the validity of the conditional independence model and suggests providing illustrative experimental results. The reviewer also mentions the need for additional experiments to validate the proposed test metric and suggests visualizations or schematic diagrams to aid understanding. However, the comment lacks specific examples or references to support these claims, making it 3. The authors would need to infer the exact experiments or visualizations needed to address the concerns. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two key areas for improvement in the paper. First, it points out the lack of qualitative experiments to demonstrate the validity of the conditional independence model, suggesting the inclusion of illustrative experimental results and a toy dataset to demonstrate the separability of inlier features and outlier features. Second, it highlights the need for additional experiments to validate the proposed test metric, recommending the inclusion of visualizations or schematic diagrams to aid understanding. These suggestions are clear and actionable, providing the authors with specific directions to enhance the comprehensiveness and clarity of their work. However, the comment could be more helpful if it offered examples of how to conduct these experiments or visualizations. Overall, the feedback is 4, as it effectively guides the authors toward improving their draft."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the computational complexity of the proposed method compared to other methods. It explicitly asks the authors to compare the computational complexity, which is a direct and concrete action. The comment provides clear guidance on what the authors need to do to address this concern, making it 5.", "grounding_specificity_rationale": "The comment raises a question about the computational complexity of the proposed method compared to other methods. However, it does not specify which part of the paper discusses the online version of the algorithm or where the authors mention the impracticality of training multiple iterations/epochs with large models and datasets. This lack of explicit reference to a specific section or part of the paper makes it weakly grounded. The comment is specific in its request for a comparison of computational complexity with other methods, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question seeking clarification on the computational complexity of the proposed method compared to other methods. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a pertinent question about the computational complexity of the proposed method compared to other methods. It prompts the authors to provide a comparison, which is a valuable suggestion for improving the clarity and comprehensiveness of the paper. By addressing this point, the authors can enhance the transparency and credibility of their work. However, the comment could be more helpful if it provided specific guidance on how to conduct the comparison or what aspects to focus on. Overall, the feedback is 3 as it identifies an area for improvement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that systematically studying the impact of the cost of incentivization on performance would be beneficial. It provides an example of how this could be done, such as analyzing the reward incentives for various values of alpha and the collective return. The comment also offers a hypothesis about the roles of \"winners\" and \"cooperators\" and how the cost of incentivization affects these roles. While the comment implies an action, it does not explicitly instruct the authors to conduct this analysis, leaving some ambiguity. However, the concrete suggestion about analyzing the cost and reward incentives provides a clear direction for the authors to follow. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment suggests a specific analysis that would be beneficial, namely studying the impact of the cost of incentivization on performance. It provides a concrete example of how this could be done, such as analyzing the reward incentives for various values of alpha and the collective return. The comment also offers a hypothesis about the roles of \"winners\" and \"cooperators\" and how the cost of incentivization affects these roles. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the analysis or results sections where such an analysis could be included. The suggestion is specific in detailing what kind of analysis would be beneficial. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that systematically studying the impact of the cost of incentivization on performance would be beneficial. It provides a specific example of how this could be done, such as analyzing the reward incentives for various values of alpha and the collective return. The comment also offers a hypothesis about the roles of \"winners\" and \"cooperators\" and how the cost of incentivization affects these roles. This reasoning is logical and provides a clear direction for the authors to explore, making the claim 4. However, the comment could be strengthened by referencing similar studies or providing more detailed examples to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment suggests a valuable analysis that could be conducted to further explore the impact of the cost of incentivization on performance. It provides a specific example of how this analysis could be structured, such as examining the reward incentives for various values of alpha and the collective return. The comment also offers a hypothesis about the roles of \"winners\" and \"cooperators\" and how the cost of incentivization affects these roles. This feedback is clear and actionable, as it directs the authors to a specific area for further investigation and analysis. By suggesting a systematic study, the comment provides the authors with a concrete way to enhance their draft. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the approach description in Section 3 should be revised to make it easier to follow. It also provides a clear action for the authors to take, which is to use the additional page in the cameraready version to extend the approach description rather than adding more experiments. This guidance is specific and provides a concrete step for the authors to follow, ensuring they know exactly what needs to be done to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"\u00a7 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the approach description, indicating that it is difficult to follow and suggesting that it should be revised. The comment further provides a clear action for the authors to take, which is to use the additional page in the cameraready version to extend the approach description rather than adding more experiments. This level of detail and guidance makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the approach description in Section 3 is difficult to follow and suggests that it should be revised. However, the comment does not provide any specific examples or detailed reasoning to support this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the approach description in Section 3, noting that it is difficult to follow. It provides a clear and actionable suggestion for improvement by recommending that the authors use the additional page in the cameraready version to extend the approach description rather than adding more experiments. This feedback is valuable as it directs the authors to focus on enhancing the clarity and comprehensiveness of their approach description, which is crucial for readers to understand and evaluate the work. However, the comment could be more helpful if it included specific suggestions on how to improve the clarity or examples of what should be added to the approach description. Overall, the comment is 4 as it provides a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two areas for improvement in the experiments section. First, it suggests that the discussion lacks interpretive insights that would explain why the proposed gyrostructures outperform existing methods. Second, it points out the absence of comparisons with other stateoftheart methods that do not rely on gyrostructures, which could provide a clearer understanding of the proposed approach\"s performance. While the comment identifies specific areas for improvement, it does not provide explicit guidance on how to address these issues or what specific comparisons or insights should be included. The actions are implicit and somewhat vague, as the authors need to infer the exact steps to take to improve the discussion and comparisons. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiments part,\" allowing the authors to accurately identify the section being addressed. It is also specific because it details what is missing in the discussion, namely interpretive insights and comparisons with other stateoftheart methods that do not rely on gyrostructures. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, the comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point claims that the related discussion lacks interpretive insights and comparisons with other stateoftheart methods, which makes it unclear whether the proposed approach outperforms simpler or more commonly used techniques. The comment provides a logical reasoning by pointing out the absence of comparisons with other methods, which is a critical aspect of evaluating the proposed approach\"s performance. However, it does not provide specific examples or references to other stateoftheart methods that could be included for comparison. This lack of detailed evidence or references makes the claim 3, as the authors would need to infer the specific comparisons needed to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific areas for improvement in the experiments section. First, it points out the lack of interpretive insights in the discussion, which would help explain why the proposed gyrostructures outperform existing methods. Second, it notes the absence of comparisons with other stateoftheart methods that do not rely on gyrostructures, which could provide a clearer understanding of the proposed approach\"s performance. These observations are clear and actionable, as they guide the authors to enhance the interpretability and comprehensiveness of their experimental results. However, the comment could be more helpful if it provided specific suggestions on how to incorporate these comparisons or insights. Overall, the feedback is 4, as it directs the authors to important areas for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a difficulty in comprehending Figure 5 and suggests that more details about the two baselines presented in the figure are needed. It also points out that the authors only study CATER for Englishcentric datasets, while widespread text generation APIs support multiple languages. The reviewer implies that the authors could extend CATER to other languages in the future. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues or what specific details should be included. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details about the baselines and consider extending CATER to other languages. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what is missing in the figure, namely more details about the two baselines presented. Additionally, the comment provides a suggestion for future work, which is to extend CATER to other languages. This level of detail and specificity helps the authors understand what needs to be addressed and improved in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 5 is hard to comprehend and suggests that more details about the two baselines presented in the figure are needed. It also points out that the authors only study CATER for Englishcentric datasets, while widespread text generation APIs support multiple languages. The reviewer implies that the authors could extend CATER to other languages in the future. While the comment provides some reasoning by highlighting the need for more details and the potential for future work, it lacks specific examples or references to support the claim about the difficulty in understanding Figure 5. This makes the claim 3, as it provides a basis for improvement but requires more detailed justification or evidence to be 5.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 5, noting that it is hard to comprehend. It suggests that more details about the two baselines presented in the figure are needed, which is a clear and actionable piece of feedback. Additionally, the comment points out that the authors only study CATER for Englishcentric datasets, while widespread text generation APIs support multiple languages. This observation leads to a suggestion for future work, which is to extend CATER to other languages. The comment provides a constructive critique and offers a direction for improvement, making it 4 for the authors. However, it could be more helpful if it included specific suggestions on how to enhance the figure or what details to include. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the literature review needs improvement, specifically highlighting the lack of clarity regarding the main contribution and distinction from existing work, particularly in relation to GFlowNet for sequence generation. It suggests that the paper should provide a more explicit and comparative analysis of related work. This feedback is clear and provides a direct action for the authors to take, which is to enhance the literature review by clearly articulating the main contribution and distinguishing it from existing work. The comment is explicit and concrete, giving the authors a clear understanding of what needs to be addressed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"literature review\" section of the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it details what needs to be improved, namely the clarity of the main contribution and the distinction from existing work, particularly in relation to the utilization of GFlowNet for sequence generation. The comment provides a clear direction for the authors to enhance their literature review by providing a more explicit and comparative analysis of related work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the literature review is unclear regarding the main contribution and distinction from existing work, particularly in relation to the utilization of GFlowNet for sequence generation. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact issues or how to address them. The lack of detailed justification or examples makes the claim 3, as the authors would need to infer the specific areas needing improvement. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the literature review, noting that it lacks clarity regarding the main contribution and distinction from existing work, particularly in relation to the utilization of GFlowNet for sequence generation. It provides a clear and actionable suggestion to enhance the literature review by offering a more explicit and comparative analysis of related work. This feedback is valuable as it guides the authors on how to improve the clarity and depth of their literature review, which is crucial for establishing the novelty and significance of their work. However, the comment could be more helpful if it included specific examples or references to existing work that the authors should consider for comparison. Overall, the comment is 4, as it provides clear guidance for improvement but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that section 3.2 can be eliminated because readers are presumed to know about the GumbelSoftmax/Concrete distribution. However, it does not provide any specific guidance on how to address this suggestion or what alternative content could be included in its place. The action is explicit but lacks concrete details on how to implement the change, making it 3.", "grounding_specificity_rationale": "The comment suggests that section 3.2 can be eliminated because readers are presumed to know about the GumbelSoftmax/Concrete distribution. However, it does not specify which part of section 3.2 is being addressed or what specific content could be removed. The authors can infer that it relates to the discussion of the GumbelSoftmax/Concrete distribution, but the comment lacks detailed guidance on what needs to be addressed or improved. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that section 3.2 can be eliminated because readers are presumed to know about the GumbelSoftmax/Concrete distribution. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this assumption is valid or how it impacts the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The comment suggests that section 3.2 can be eliminated because readers are presumed to know about the GumbelSoftmax/Concrete distribution. While it identifies a potential area for improvement, it lacks specific guidance or reasoning on why this section is unnecessary or how it could be improved. The feedback is 3 as it points out a potential redundancy, but it does not provide actionable suggestions or detailed insights into how the authors might enhance their draft. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point provides two explicit suggestions for improving the experiments. First, it recommends adding performance on word similarity and sentence translation tasks, as done in the MUSE paper, to enhance the credibility of the framework\"s robustness and effectiveness. Second, it suggests including morphologically rich languages like Finnish and Hebrew, as well as lowresource languages, in the experiments. These suggestions are clear and concrete, giving the authors specific actions to take to improve their draft. The feedback is 5 as it provides direct guidance on how to enhance the experimental section of the paper.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides two distinct suggestions for improvement: (i) adding performance on word similarity and sentence translation tasks, as in the MUSE paper, to enhance credibility, and (ii) including morphologically rich languages like Finnish and Hebrew, as well as lowresource languages, in the experiments. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests adding performance on word similarity and sentence translation tasks, as done in the MUSE paper, to enhance the credibility of the framework. It also recommends including morphologically rich languages like Finnish and Hebrew, as well as lowresource languages, in the experiments. These suggestions are based on logical reasoning, as they aim to provide a more comprehensive evaluation of the framework\"s robustness and effectiveness. However, the comment lacks specific references to the MUSE paper or detailed examples of how these additions would enhance the experiments. Therefore, the claim is 4, as it provides a clear direction but could benefit from more detailed support.", "helpfulness_rationale": "The review comment provides two specific suggestions for improving the experiments in the paper. First, it recommends adding performance on word similarity and sentence translation tasks, as done in the MUSE paper, to enhance the credibility of the framework\"s robustness and effectiveness. This is a clear and actionable suggestion that could significantly strengthen the experimental section. Second, it suggests including morphologically rich languages like Finnish and Hebrew, as well as lowresource languages, in the experiments. This addition would provide a more comprehensive evaluation of the framework\"s performance across different language types. The feedback is detailed and offers concrete ways to enhance the paper, making it 5 for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point provides two explicit actions for the authors to take. First, it suggests that the link between IP and the terms/equations should be explained more explicitly and prominently, which is a clear and concrete instruction. Second, it requests that labels be included for subfigures in Figures 3 and 4, rather than just stating them in the captions. These actions are specific and provide clear guidance on how to improve the draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figs 3 and 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what needs to be addressed, namely the explanation of the link between IP and terms/equations, and the inclusion of labels for subfigures in Figures 3 and 4. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the link between IP and terms/equations could be explained more explicitly and prominently. It also requests the inclusion of labels for subfigures in Figures 3 and 4. However, the comment does not provide any reasoning or evidence to support why this explanation is necessary or how it would improve the paper. Without additional context or justification, the authors may find it challenging to understand the importance of these changes. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the link between IP and terms/equations should be explained more explicitly and prominently. It also requests the inclusion of labels for subfigures in Figures 3 and 4, rather than just stating them in the captions. This feedback is clear and directs the authors on how to improve the clarity and accessibility of their work. However, the comment could be more helpful if it explained why these changes are necessary or how they would enhance the paper. Overall, the feedback is 4 as it offers concrete steps for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the observations and conclusions are hidden in the experimental section and recommends highlighting them to better understand the tradeoffs between annotation effort and training performance. While the comment implies that the authors should make these observations and conclusions more prominent, it does not provide specific guidance on how to achieve this, such as suggesting where to place them or what format to use. The action is implicit and somewhat vague, making it 3.", "grounding_specificity_rationale": "The comment suggests that the observations and conclusions are hidden in the experimental section and recommends highlighting them to better understand the tradeoffs between annotation effort and training performance. However, it does not specify which part of the experimental section contains these observations or conclusions, making it difficult for the authors to pinpoint the exact areas needing attention. The comment is specific in suggesting what needs to be addressed, but it lacks grounding as it does not explicitly mention a specific section or figure. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the observations and conclusions are hidden in the experimental section, and it recommends highlighting them to better understand the tradeoffs between annotation effort and training performance. However, the comment does not provide specific examples or detailed reasoning to support why these observations and conclusions are currently hidden or how they could be better highlighted. Without additional context or evidence, the claim remains somewhat vague, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3, as it provides some justification but lacks detailed support.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the observations and conclusions are hidden in the experimental section. It suggests that highlighting these observations and conclusions would be beneficial for understanding the tradeoffs between annotation effort and training performance. This feedback is clear and actionable, as it provides a specific area for improvement that the authors can address to enhance the clarity and impact of their work. However, the comment could be more helpful if it offered suggestions on how to effectively highlight these observations and conclusions, such as through specific formatting or placement within the paper. Overall, the comment is 4, as it directs the authors to a critical area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should conduct ablation experiments on the modifications mentioned in Section 3.4 to validate the model performance further. This feedback is explicit and provides a clear action for the authors to take, which is to conduct additional experiments. The suggestion is concrete, as it specifies the type of experiments needed and the rationale behind them. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests conducting ablation experiments on the modifications mentioned in Section 3.4 to validate the model performance further. However, it does not specify which specific modifications are being referred to, nor does it provide details on what aspects of the model performance should be evaluated. This makes it difficult for the authors to pinpoint the exact parts of the paper that need attention. The comment is weakly grounded as it does not explicitly mention a specific section, and it is not specific because it lacks detailed guidance on what aspects of the ablation experiments should be focused on. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests conducting ablation experiments to validate the model performance further, specifically mentioning modifications in Section 3.4. However, the comment does not provide any reasoning or evidence to support why these modifications are significant or how they might impact the model performance. Without additional context or examples, the claim is vague and lacks verifiability. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests conducting ablation experiments on the modifications mentioned in Section 3.4 to validate the model performance further. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their study by testing the impact of individual modifications on the model performance. However, the comment could be more helpful if it specified which modifications should be tested or provided examples of how these experiments might be conducted. Despite this, the suggestion is valuable and offers a concrete way for the authors to improve their draft. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance of the KDE method when the decision space is beyond binary, as mentioned in Remark 1. It also references an alternative approach by Zhang et al. that does not seem to have this issue. The comment implies that the authors should consider comparing the performance of their method with other approaches on datasets with decision spaces beyond binary. However, the comment does not explicitly instruct the authors to conduct this comparison or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer that they should compare their method with others but are not given detailed instructions on how to execute this comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Remark 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the performance of the KDE method when the decision space is beyond binary and suggests comparing it with other approaches, such as Zhang et al. 44. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the performance of the KDE method when the decision space is beyond binary, as mentioned in Remark 1. It references an alternative approach by Zhang et al. 44 that does not seem to have this issue. The comment suggests comparing the performance of the KDE method with other approaches on datasets with decision spaces beyond binary. However, the comment lacks specific examples or detailed reasoning to support the claim that the KDE method would require more data in such scenarios. While it provides a logical suggestion for further exploration, the lack of detailed justification or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the performance of the KDE method when the decision space is beyond binary, as mentioned in Remark 1. It references an alternative approach by Zhang et al. that does not seem to have this issue. The comment suggests that the authors should consider comparing the performance of their method with other approaches on datasets with decision spaces beyond binary. This feedback is 3 as it identifies a potential area for improvement and suggests a specific direction for further exploration. However, the comment could be more helpful if it provided more detailed guidance on how to conduct this comparison or what specific aspects to focus on. Overall, the comment is 3, as it offers a clear direction for enhancing the paper but lacks depth and specificity in its suggestions."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises two questions: how the capacity of the SR model affects the FID and whether there are unexpected artifacts due to the proposed method being pipelined. However, it does not provide explicit instructions or suggestions on how the authors should address these questions or investigate the potential issues. The authors are left to infer that they need to explore these aspects further, but without concrete guidance on how to do so, the comment lacks actionability. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises two questions: how the capacity of the SR model affects the FID and whether there are unexpected artifacts due to the proposed method being pipelined. However, it does not specify which part of the paper these questions pertain to, making it difficult for the authors to identify the exact sections that need attention. The comment lacks specificity as it does not provide details on what aspects of the SR model capacity or the pipelining method are causing the unexpected artifacts. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point consists of two questions: \"How the capacity of the SR model affects the FID\" and \"whether there are unexpected artifacts due to the proposed method being pipelined.\" These are requests for clarification or additional information, not claims or opinions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises two questions: how the capacity of the SR model affects the FID and whether there are unexpected artifacts due to the proposed method being pipelined. While these questions are relevant and could lead to further exploration and clarification in the paper, the comment lacks specificity and actionable guidance. It does not provide suggestions on how to address these questions or improve the paper, leaving the authors with a general direction but no clear steps to take. Therefore, the comment is 2, as it identifies areas for improvement but does not offer detailed feedback or actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that Appendix A is left blank and that the purpose of Proposition B.1 in Appendix B is unclear. It suggests that the proposition might be meant to illustrate the classic partitioning principle of Kmeans, which is a wellknown concept in machine learning. The comment also notes that the authors\" socalled \"proof\" is missing. While the comment identifies specific issues and provides some context, it does not explicitly instruct the authors on how to address these issues or what specific actions to take. The feedback is 3 as it highlights areas that need clarification or improvement, but it lacks concrete guidance on how to implement these changes. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix A\" and \"Proposition B.1 in Appendix B,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issues with these sections, such as the blank appendix and the unclear purpose of the proposition. The comment provides a suggestion that the proposition might be meant to illustrate a wellknown concept in machine learning, which adds further clarity. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Appendix A is left blank and that the purpose of Proposition B.1 in Appendix B is unclear, suggesting it might be meant to illustrate a wellknown concept in machine learning. The reviewer also notes that the authors\" socalled \"proof\" is missing. While the comment identifies specific issues, it lacks detailed reasoning or references to support the claim that the proposition is merely meant to illustrate a wellknown concept. The absence of a proof is also not fully explained. Therefore, the comment is 3, as it provides some justification but lacks comprehensive evidence or detailed reasoning to fully substantiate the claims.", "helpfulness_rationale": "The review comment identifies several specific issues with the paper, including the absence of content in Appendix A and the unclear purpose of Proposition B.1 in Appendix B. It suggests that the proposition might be meant to illustrate a wellknown concept in machine learning, such as the classic partitioning principle of Kmeans. Additionally, the comment points out the lack of a proof for the proposition. This feedback is clear and actionable, as it directs the authors to clarify the purpose and content of these sections, potentially improving the comprehensibility and rigor of the paper. However, the comment could be more helpful if it provided specific suggestions on how to address these issues or offered examples of how to present the proof. Overall, the comment is 4, as it effectively guides the authors toward improving their draft."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the paper lacks additional necessary experiments, including comparison experiments, ablation studies, and hyperparameter analysis. This provides a clear action for the authors to take, which is to conduct these experiments to enhance the paper. However, the comment does not specify which experiments are most critical or how to conduct them, leaving some room for ambiguity. Despite this, the authors know exactly what needs to be done to improve their draft, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of additional necessary experiments, including comparison experiments, ablation studies, and hyperparameter analysis. This allows the authors to accurately identify the part of the paper being addressed, which is the experimental section. The comment is also specific because it clearly specifies what is missing in the experiments, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks additional necessary experiments, including comparison experiments, ablation studies, and hyperparameter analysis. However, it does not provide any specific examples, reasoning, or references to support why these experiments are necessary or how they would enhance the paper. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their draft by conducting these experiments. However, the comment could be more helpful if it suggested which specific comparisons or ablations would be most beneficial or provided examples of how these experiments could be conducted. Despite this, the comment is 4 as it directs the authors to a critical area for improvement in their experimental section."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the proposed model demonstrates impressive performance on various benchmarks, setting new stateoftheart (SOTA) scores. However, it implies that a more careful analysis is needed, particularly for \"old\" benchmarks where the data might have been indirectly seen by the model. The comment also recommends providing more details about the evaluation procedures. While the comment implies that the authors should conduct a more thorough analysis and provide additional details, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct a more detailed analysis and provide more evaluation details. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the proposed model demonstrates impressive performance on various benchmarks, setting new stateoftheart (SOTA) scores. It implies that a more careful analysis is needed, particularly for \"old\" benchmarks where the data might have been indirectly seen by the model. The comment also recommends providing more details about the evaluation procedures. However, it does not specify which benchmarks are considered \"old\" or how the data might have been indirectly seen, making it difficult for the authors to pinpoint the exact areas needing attention. The comment is fully grounded as it addresses the overall evaluation procedures, but it is underspecific due to the lack of detailed guidance. Therefore, this comment is categorized as 4.", "verifiability_rationale": "The review point claims that the proposed model demonstrates impressive performance on various benchmarks, setting new stateoftheart (SOTA) scores. It suggests that a more careful analysis is needed, particularly for \"old\" benchmarks where the data might have been indirectly seen by the model. The comment also recommends providing more details about the evaluation procedures. While the claim about the model\"s performance is factual, the suggestion for a more careful analysis and the mention of \"old\" benchmarks are not fully supported by specific examples or references. The lack of detailed reasoning or evidence makes the claim 3, as the authors would need to infer the specific issues and address them themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the impressive performance of the proposed model on various benchmarks, setting new stateoftheart (SOTA) scores. However, it suggests that a more careful analysis is needed, particularly for \"old\" benchmarks where the data might have been indirectly seen by the model. This implies that the authors should be cautious about the generalizability of their results and provide more details about the evaluation procedures. While the comment identifies a potential issue, it lacks specific suggestions or guidance on how to address it, such as recommending particular analyses or methods to ensure the robustness of the results. As a result, the feedback is 3, as it points out an area for improvement but does not provide detailed actionable steps for the authors to take."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the experiments should include collaborative games to evaluate the methods in both collaborative and competitive settings. While the comment implies that the authors should add collaborative games to their experiments, it does not provide specific guidance on which games to choose or how to implement them. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests adding collaborative games to the experiments to evaluate the methods in both collaborative and competitive settings. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. Without explicit references to specific sections or experiments, the authors cannot confidently determine where to incorporate this suggestion. The comment is specific in its request for collaborative games but lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the experiments should include collaborative games to evaluate the methods in both collaborative and competitive settings. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this would be interesting or beneficial. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the experiments should include collaborative games to evaluate the methods in both collaborative and competitive settings. This feedback is 3 as it identifies a potential area for improvement in the experimental design. However, the comment lacks specificity and does not provide guidance on how to implement collaborative games or what specific benefits might be gained from doing so. While it points out a direction for enhancement, it does not offer detailed actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the absence of experimental settings for Figures 1 to 9, which makes the results less convincing. However, it does not provide explicit guidance on what specific information should be included or how the authors should present it. The action is implicit, as the authors can infer that they need to provide experimental settings, but it lacks concrete details on how to do so. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment highlights the absence of experimental settings for Figures 1 to 9, which makes the results less convincing. However, it does not specify which part of the paper discusses these figures, making it difficult for the authors to pinpoint the exact sections that need revision. The comment is specific in identifying the issue of missing experimental settings, but it lacks grounding as it does not mention specific sections or figures. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experimental settings for Figures 1 to 9 are missing, which makes the results less convincing. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a significant issue with the paper, noting the absence of experimental settings for Figures 1 to 9, which makes the results less convincing. This is a critical observation that highlights a gap in the presentation of the experimental results, which is essential for the paper\"s credibility. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending the inclusion of specific details or methods. While it points out a significant weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight into a critical area for improvement but lacks detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential ambiguity in the rationale behind the proposed method, specifically questioning how it avoids impeding the learning of new task knowledge. While it identifies a gap in the explanation, it does not provide explicit guidance or suggestions on how the authors might clarify this aspect. The action is implicit and somewhat vague, as it leaves the authors to infer that they need to provide more detailed explanation but does not specify how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the rationale behind the work, which is based on the observation that current parameter isolation methods hinder the acquisition of new task knowledge. It also references the suggestion of pathway protection based on the sparsity exhibited by activation channels in deep networks. However, the comment is underspecific because it does not provide detailed guidance on what aspects of the explanation are ambiguous or how the authors might clarify the issue. The authors are given a general direction but lack specific instructions on how to address the ambiguity. Therefore, this comment is 4, aligning with category 4.", "verifiability_rationale": "The review point claims that the rationale behind the proposed method is ambiguous regarding how it avoids impeding the learning of new task knowledge. However, the comment does not provide specific examples or detailed reasoning to support this claim. The mention of parameter isolation methods and sparsity in deep networks is general and lacks concrete evidence or references to substantiate the critique. As a result, the claim is 3, as it identifies a potential issue but lacks sufficient detail or evidence to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a potential ambiguity in the rationale behind the proposed method, specifically questioning how it avoids impeding the learning of new task knowledge. It highlights a gap in the explanation by pointing out that some parameter isolation methods are tailored to leverage sparsity, which could be relevant to the authors\" approach. However, the comment does not provide specific suggestions or guidance on how the authors might clarify this aspect or improve their explanation. While it raises an important point, the feedback lacks actionable details, making it 3. The authors are given a direction to explore but are not fully equipped with the necessary information to address the issue effectively. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should integrate benchmark comparisons against stateoftheart fairness algorithms in the experimental section. This is a clear and direct action for the authors to take, as it specifies exactly what needs to be done to enhance the paper. The comment also provides a rationale for why this is important, highlighting the need for tangible evidence of the proposed method\"s performance and its positioning within the existing FairML research landscape. The action is concrete and direct, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the integration of benchmark comparisons against stateoftheart fairness algorithms. This provides clear guidance on how to enhance the paper by offering tangible evidence of the proposed method\"s performance and positioning it within the existing FairML research landscape. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper should include comparisons with existing fairness algorithms in the experimental section. The claim is supported by logical reasoning, as it highlights the importance of benchmarking to demonstrate the proposed method\"s performance and its positioning within the existing FairML research landscape. However, the comment could be strengthened by providing specific examples of stateoftheart fairness algorithms or references to relevant literature, which would make the claim 5. Therefore, the comment is 4, as it provides a clear rationale but lacks detailed references or examples.", "helpfulness_rationale": "The review comment identifies a significant gap in the experimental section by noting the absence of comparisons with existing fairness algorithms. It provides a clear and actionable suggestion to integrate benchmark comparisons against stateoftheart fairness algorithms, which would enhance the paper\"s credibility and position the ManyFairHPO framework within the existing FairML research landscape. This feedback is valuable as it guides the authors on how to strengthen their experimental section and provide a more comprehensive evaluation of their method. However, the comment could be more helpful if it included specific examples of algorithms to consider or detailed guidance on how to conduct these comparisons. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to discuss the iteration cost (computational budget) of the proposed method and suggests including the iteration cost of related methods, including baseline methods. This provides a clear and direct action for the authors to take, specifying what needs to be discussed and which methods should be considered. The feedback is concrete and actionable, as it gives the authors a specific task to address in their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need to discuss the iteration cost (computational budget) of the proposed method and related methods, including baseline methods. This allows the authors to accurately identify the part of the paper that needs revision. The comment is also specific because it clearly specifies what needs to be addressed, namely the iteration cost of the proposed method and related methods. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should discuss the iteration cost (computational budget) of the proposed method and related methods, including baseline methods. This is a request for additional information or analysis, rather than a claim or opinion that requires verification. The comment is factual and descriptive, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to include a discussion on the iteration cost (computational budget) of the proposed method and related methods, including baseline methods. This feedback is specific and offers a concrete way for the authors to enhance their paper by providing additional context and comparison with other methods. By addressing this point, the authors can improve the comprehensiveness and depth of their analysis, making the comment 4. However, the comment could be more helpful if it offered guidance on how to present this information or suggested specific metrics to consider. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the authors\" use of the center correlation metric, noting that it was deemed uninformative for discriminating model defenses but is used in Figure 4 A&B. The reviewer wonders why this metric was found useful in this context and not elsewhere, or what the authors meant by their statement on lines 8082. While the comment highlights a potential inconsistency or confusion, it does not provide explicit guidance or suggestions for the authors to address this issue. The action is implicit and somewhat vague, as the authors are left to infer that they should clarify their reasoning or provide additional context. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (8082) and figures (4 A&B) in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies the issue by questioning the authors\" use of the center correlation metric, which was previously deemed uninformative, and asking for clarification on why it was found useful in this context. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the authors\" use of the center correlation metric, noting that it was deemed uninformative for discriminating model defenses but is used in Figure 4 A&B. The reviewer wonders why this metric was found useful in this context and not elsewhere, or what the authors meant by their statement on lines 8082. This comment raises a logical inconsistency and seeks clarification, but it does not provide specific evidence or references to support the claim. The authors are left to infer the issue and address it themselves. Therefore, the comment is 3, as it highlights a potential issue but lacks detailed justification or evidence.", "helpfulness_rationale": "The review comment identifies a potential inconsistency in the authors\" use of the center correlation metric, which was previously deemed uninformative for discriminating model defenses but is used in Figure 4 A&B. The reviewer questions the authors\" reasoning and asks for clarification on why this metric was found useful in this context. This feedback is 3 as it points out a specific area of confusion or inconsistency in the paper, prompting the authors to clarify their rationale. However, the comment could be more helpful if it provided suggestions on how to address this inconsistency or offered alternative explanations. Overall, the comment is 3 as it directs the authors\" attention to a potential issue that needs clarification."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the term \"distributional generalization\" might be too strong to describe the empirical phenomenon presented in the paper. It provides a rationale for this suggestion by explaining that the phenomenon is more accurately described as the ideal of the total variation between the test and train distributions of the network\"s outputs vanishing to zero, which might not be the case. However, the comment does not explicitly instruct the authors to change the terminology or provide guidance on how to address this issue. The action is implicit and somewhat vague, as the authors can infer that they might need to reconsider the terminology but are not given specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the term \"distributional generalization,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear critique of the terminology used to describe the phenomenon, suggesting that it might be too strong and that the ideal of the total variation between the test and train distributions of the network\"s outputs vanishing to zero might not be the case. The comment offers a specific suggestion for improvement by proposing a more accurate description of the phenomenon. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the term \"distributional generalization\" might be too strong to describe the empirical phenomenon presented in the paper. The reviewer provides a logical reasoning by explaining that the phenomenon is more accurately described as the ideal of the total variation between the test and train distributions of the network\"s outputs vanishing to zero, which might not be the case. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to consider the reasoning and potentially conduct further analysis to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the terminology used to describe the empirical phenomenon presented in the paper. It suggests that the term \"distributional generalization\" might be too strong and proposes an alternative description based on the ideal of the total variation between the test and train distributions of the network\"s outputs vanishing to zero. This feedback is 3 as it points out a possible misalignment between the terminology and the actual phenomenon being described, offering a more accurate alternative. However, the comment could be more helpful if it provided specific examples or further elaborated on how the authors might address this issue in their draft. Overall, the comment provides a useful direction for improvement but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the phrase \"above/below diagonal\" is easier to interpret than \"above/below 45 degree,\" which is perceived as a local property. However, it does not provide explicit guidance on how the authors should address this issue or suggest alternative phrasing. The action is implicit and somewhat vague, as the authors are left to infer that they should consider revising the phrasing but are not given specific instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"above/below diagonal\" and \"above/below 45 degree,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for improvement, recommending the use of \"above/below diagonal\" instead of \"above/below 45 degree\" to avoid confusion. This specificity helps the authors understand what needs to be revised. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the phrase \"above/below diagonal\" is easier to interpret than \"above/below 45 degree,\" which is perceived as a local property. The reviewer provides a logical reasoning by explaining that the diagonal reference is more general and not specific to a local property, such as when the red line saturates. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to infer the reasoning fully, which could be challenging without additional context. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the phrasing used in the paper, suggesting that \"above/below diagonal\" is easier to interpret than \"above/below 45 degree.\" It provides a logical reasoning by explaining that the diagonal reference is more general and not specific to a local property, such as when the red line saturates. This feedback is 3 as it points out a specific area for improvement in the paper\"s language, which could enhance clarity for readers. However, the comment could be more helpful if it offered alternative phrasing or suggestions for improvement. Overall, the comment provides some guidance but lacks depth, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the lack of scientific insight provided by the model and formalism compared to prior taskoptimized approaches. It specifically questions whether the model is a prototype approximation to nonlinear RNN models and whether it provides an explanation for their emergent behavior. While the comment identifies a gap in the paper\"s explanation, it does not provide explicit guidance or suggestions on how the authors might address this issue. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide a clearer explanation of the model\"s contribution. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of scientific insight provided by the model and formalism compared to prior taskoptimized approaches. The comment questions whether the model is a prototype approximation to nonlinear RNN models and whether it provides an explanation for their emergent behavior. This level of detail provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the scientific insight provided by the model and formalism compared to prior taskoptimized approaches. It specifically challenges the claim that the model is a prototype approximation to nonlinear RNN models and questions whether it provides an explanation for their emergent behavior. The comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the basis of the critique. This results in a 2 rating, as the claim is not fully substantiated but provides some basis for questioning the paper\"s contribution.", "helpfulness_rationale": "The review comment raises a critical question about the scientific insight provided by the model and formalism compared to prior taskoptimized approaches. It specifically questions whether the model is a prototype approximation to nonlinear RNN models and whether it provides an explanation for their emergent behavior. This feedback is valuable as it prompts the authors to clarify the novelty and contribution of their work, which is essential for improving the draft. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address this issue. Overall, the comment is 3 as it identifies a key area for improvement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific observation from the experimental results, noting that the placement of adaptive convolutions seems to be important for performance. However, it does not provide explicit guidance or suggestions on how the authors should address this observation or conduct further analysis. The comment implies that the authors should investigate the impact of adaptive convolution placement, but it lacks concrete steps or actions for the authors to take. As a result, the comment is 3, as it identifies an area for potential improvement but does not provide detailed guidance on how to proceed.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular observation from the experimental results regarding the performance of adaptive convolutions and suggests that the placement of these convolutions is important. The comment further notes the absence of analysis or comments on this aspect, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the placement of adaptive convolutions is important based on the observation that ACNNv3 (all adaptive convolutions) performed worse than ACNNv2 (adaptive convolutions only in the last layer). However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide a clear explanation of why the placement of adaptive convolutions is crucial or how it affects performance. Without additional context or evidence, the claim remains somewhat vague, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3, as it provides some insight but lacks comprehensive support.", "helpfulness_rationale": "The review comment identifies a specific observation from the experimental results, noting that the placement of adaptive convolutions seems to be important for performance. It points out that ACNNv3 (all adaptive convolutions) performed worse than ACNNv2 (adaptive convolutions only in the last layer), suggesting that the placement of adaptive convolutions is crucial. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might analyze or address this observation. While it highlights an area for potential improvement, the feedback is somewhat vague and does not offer actionable steps for the authors to take. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors include a brief discussion on the empirical motivation for timevarying Q^t and S_t, as opposed to a fixed one as in Section 4.2. It provides a specific example of what could be discussed, such as the effect on the volatility of \u03b1_t and the average lengths of predictive intervals when Q^t and S_t vary with time. This feedback is explicit and provides concrete guidance on what the authors should discuss, making it 5.", "grounding_specificity_rationale": "The comment suggests including a brief discussion on the empirical motivation for timevarying Q^t and S_t, as opposed to a fixed one as in Section 4.2. It provides a specific example of what could be discussed, such as the effect on the volatility of \u03b1_t and the average lengths of predictive intervals when Q^t and S_t vary with time. While the comment does not explicitly mention a specific section, the authors can infer that it relates to the discussion section, where such a discussion could be included. The suggestion is specific in detailing what should be discussed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests including a discussion on the empirical motivation for timevarying Q^t and S_t, as opposed to a fixed one as in Section 4.2. It provides a specific example of what could be discussed, such as the effect on the volatility of \u03b1_t and the average lengths of predictive intervals when Q^t and S_t vary with time. This suggestion is supported by logical reasoning and a clear example, making it 5. The authors can understand the rationale behind the suggestion and how it could enhance their discussion, providing a clear path for improvement. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the discussion section of the paper. It recommends including a brief discussion on the empirical motivation for timevarying Q^t and S_t, as opposed to a fixed one as in Section 4.2. The comment offers a concrete example of what could be discussed, such as the effect on the volatility of \u03b1_t and the average lengths of predictive intervals when Q^t and S_t vary with time. This feedback is clear and provides the authors with a direct path to enhance their discussion, making it 5. By addressing this suggestion, the authors can significantly improve the comprehensiveness and depth of their paper. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment states that the paper is not easy to follow and lacks a clear intuition for how the pieces fit together, resulting in experiments that are difficult to understand. However, it does not provide specific guidance or suggestions on how the authors might improve the clarity or structure of the paper. The comment lacks actionable details, such as recommending specific changes to the presentation or experiments to enhance clarity. As a result, the authors are left without a clear understanding of what steps to take to address the issues raised. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment provides a general observation about the paper\"s lack of clarity and difficulty in understanding the pieces that fit together. However, it does not specify which parts of the paper are particularly challenging or what specific aspects need improvement. The authors might infer that the experiments are difficult to follow, but the comment lacks detailed guidance on how to address these issues. Therefore, the comment is weakly grounded as it does not identify a specific part of the paper, and it is not specific in detailing what needs to be addressed. This aligns with a score of 2.", "verifiability_rationale": "The review point claims that the paper is not easy to follow and lacks a clear intuition for how the pieces fit together. However, it does not provide specific examples or detailed reasoning to support this claim. The comment lacks concrete evidence or references to substantiate the assertion, making it difficult for the authors to understand and address the issue. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that it is not easy to follow and lacks a clear intuition for how the pieces fit together. This observation is important as it highlights a fundamental weakness in the paper\"s presentation and structure. However, the comment does not provide specific suggestions or guidance on how the authors might improve the clarity or organization of their work. Without actionable feedback, the authors are left without a clear path to address the issues raised. Therefore, the comment is 3, as it points out a critical area for improvement but lacks depth and specificity in its guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the scaling of the refined region vector, suggesting that it might only scale the most important regions by a factor of two before global pooling. It also asks whether having a scaling variable before the attention weight would help. While the comment implies that the authors should consider this scaling factor, it does not explicitly instruct them to do so or provide specific guidance on how to address the issue. The action is implicit and somewhat vague, as the authors can infer that they should consider the scaling factor but are not given concrete steps on how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 157,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the refined region vector, questioning the scaling factor and suggesting a potential improvement by introducing a scaling variable before the attention weight. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point raises a question about the scaling of the refined region vector, suggesting that it might only scale the most important regions by a factor of two before global pooling. The reviewer provides a logical reasoning by explaining the relationship between the attention weight and the scaling factor. However, the comment lacks specific references or examples to fully substantiate the claim, making it 3. The authors would need to further explore the implications of this scaling to fully understand the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a specific concern about the scaling of the refined region vector, suggesting that it might only scale the most important regions by a factor of two before global pooling. It questions whether having a scaling variable before the attention weight would help. This feedback is 3 as it identifies a potential issue with the scaling of the vector and prompts the authors to consider an alternative approach. However, the comment lacks depth and does not provide detailed guidance or suggestions on how to address this issue, such as proposing specific changes or alternatives. While it points out a potential area for improvement, it does not fully support the authors in making those improvements. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the LLM\"s performance on the ALFRED benchmark, attributing failures to goal misspecification. It explains that the LLM struggles to accurately recover the formal goal predicate, particularly when faced with ambiguities in human language. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to improve the LLM\"s performance or what specific changes should be made to enhance the recovery of formal goal predicates. Without actionable suggestions or concrete steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific issue with the LLM\"s performance on the ALFRED benchmark, particularly regarding goal misspecification. However, it does not specify which part of the paper discusses the LLM\"s performance or where the issue of goal misspecification is detailed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing the issue of goal misspecification and its impact on the LLM\"s performance, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that failures on the ALFRED benchmark are often due to goal misspecification, where the LLM does not accurately recover the formal goal predicate. The comment provides a logical explanation by mentioning the challenges posed by ambiguities in human language. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to further investigate the issue to fully understand and address the problem. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the LLM\"s performance on the ALFRED benchmark, attributing failures to goal misspecification. It explains that the LLM struggles to accurately recover the formal goal predicate, particularly when faced with ambiguities in human language. This feedback is valuable as it highlights a potential weakness in the LLM\"s performance and suggests a specific area for improvement. However, the comment lacks actionable suggestions or guidance on how the authors might address this issue, such as proposing methods to enhance the LLM\"s ability to interpret and recover formal goal predicates. While it provides insight into a critical area, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the improvement of the method over SOTA methods like IGEV and suggests that the authors analyze the distribution of disparities produced by IGEV compared to other baselines to determine why the effect is not significantly improved. It also questions whether it is difficult for SamplingGaussian to significantly improve iterative frameworks similar to IGEV. While the comment implies that the authors should conduct additional analysis and provide comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct the suggested analysis. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"this method\" and \"SOTA methods such as IGEV,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the improvement of the method over SOTA methods and suggesting an analysis of the distribution of disparities produced by IGEV compared to other baselines. Additionally, it raises a concern about the difficulty of improving iterative frameworks similar to IGEV. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a claim about the small improvement of the method over SOTA methods like IGEV and questions whether this implies a lack of multipeak distribution problems in iterative optimization schemes similar to IGEV. The reviewer suggests analyzing the distribution of disparities produced by IGEV compared to other baselines to determine why the effect is not significantly improved. Additionally, the reviewer questions the difficulty of improving iterative frameworks similar to IGEV. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion about the small improvement or the need for further analysis. This makes the claim 3, as it requires additional evidence or examples to fully substantiate the claims. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the small improvement of the method over SOTA methods like IGEV, questioning whether this implies a lack of multipeak distribution problems in iterative optimization schemes similar to IGEV. It suggests that the authors analyze the distribution of disparities produced by IGEV compared to other baselines to determine why the effect is not significantly improved. Additionally, the comment raises a concern about the difficulty of improving iterative frameworks similar to IGEV. While the comment identifies a potential weakness and provides a specific suggestion for further analysis, it could be more helpful by offering more detailed guidance on how to conduct the suggested analysis or by providing examples of similar studies that have successfully addressed this issue. Overall, the comment is 3 as it directs the authors to a specific area for improvement but lacks depth and detailed guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the paper is missing ablations and suggests that the authors include results using the GCPG model without pretrained initializations. This provides a clear and concrete action for the authors to take, as it specifies exactly what needs to be added to the draft. The comment is explicit and provides detailed guidance on how to improve the paper, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"results\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely ablations to determine the performance gain due to the task formulation and pretrained language models. The suggestion to include results using the GCPG model without pretrained initializations provides a concrete direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results are unclear regarding the contribution of the task formulation and pretrained language models to the performance gain. It suggests including results using the GCPG model without pretrained initializations to clarify this. The comment provides a logical reasoning for the need to clarify the contribution of each component, which is a common practice in evaluating model performance. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to infer the exact nature of the missing ablations and how they would address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of ablations to determine the contribution of the task formulation and pretrained language models to the performance gain. It provides a clear and actionable suggestion to include results using the GCPG model without pretrained initializations, which would help clarify the impact of each component. This feedback is valuable as it directs the authors to a specific area for improvement, offering a concrete step to enhance the clarity and comprehensiveness of their results. However, the comment could be more helpful if it provided additional context or examples on how to conduct these ablations or interpret the results. Overall, the comment is 4, as it effectively guides the authors toward improving their draft."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a specific issue with Figure 1, noting that it is difficult to understand what the axes represent. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion on how to clarify the axes or what information should be included to make them more understandable. Without any actionable advice or concrete steps, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the difficulty in understanding the axes of Figure 1. This provides clear guidance on what needs to be addressed to improve the clarity of the figure. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual statement describing a difficulty in understanding the axes of Figure 1. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 1, noting that it is difficult to understand what the axes represent. This feedback is 3 as it points out a potential area for improvement in the clarity of the figure. However, it lacks actionable suggestions or guidance on how the authors might address this issue, such as recommending additional labels, explanations, or alternative visualizations. Without specific advice, the authors may struggle to determine how to improve the figure\"s clarity. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that including results on ImageNet could make the proposed method more convincing. However, it does not provide explicit instructions on how to incorporate these results or what specific aspects of the proposed method should be evaluated on ImageNet. The action is implicit and somewhat vague, as the authors are left to infer that they should include ImageNet results but without detailed guidance on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that including results on ImageNet could make the proposed method more convincing. However, it does not specify which part of the paper should include these results or how they would enhance the method\"s credibility. Without explicit references to sections, figures, or specific aspects of the paper, the authors cannot confidently determine where to incorporate these suggestions. The comment is 1 and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1.", "verifiability_rationale": "The review point suggests that including results on ImageNet could make the proposed method more convincing. However, it does not provide any reasoning, examples, or references to support why ImageNet results would be more convincing or how they would enhance the method\"s credibility. The comment lacks specific details or evidence to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that including results on ImageNet could make the proposed method more convincing. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on how to incorporate ImageNet results or what specific aspects of the method should be evaluated on ImageNet. The feedback is 3 as it points out a direction for enhancement, but it does not offer detailed or actionable advice, leaving the authors with limited guidance on how to address the suggestion. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that direct runtime comparisons with existing methods are missing, emphasizing the need for such comparisons to demonstrate the efficiency of the proposed approach. The comment provides a clear and concrete action for the authors to take, which is to include direct runtime comparisons with existing methods. This feedback is 5 as it specifies exactly what the authors need to do to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for direct runtime comparisons with existing methods, which allows the authors to accurately identify the part of the paper that needs attention. It also specifies the issue by pointing out the absence of such comparisons and the importance of demonstrating the efficiency of the proposed approach. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that direct runtime comparisons with existing methods are missing, which is necessary to demonstrate the efficiency of the proposed approach. The reviewer provides a logical reasoning by stating that the proposed approach is based on implicit differentiation, which typically requires additional computational costs. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened by referencing specific existing methods or providing examples of how such comparisons would be beneficial. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out the absence of direct runtime comparisons with existing methods. It highlights the importance of such comparisons to demonstrate the efficiency of the proposed approach, particularly given the use of implicit differentiation, which is known to require additional computational costs. This feedback is clear and actionable, providing the authors with a concrete step to enhance their draft by including direct runtime comparisons. However, the comment could be more helpful if it suggested specific methods to compare against or provided guidance on how to conduct these comparisons. Overall, the comment is 4 as it directs the authors toward a meaningful enhancement of their work."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point claims that the proposed framework is a simple combination of metalearning and federated learning, and it does not identify any technical contribution. However, it does not provide any explicit or implicit suggestions for improvement or guidance on how the authors might address this critique. The comment lacks actionable details, leaving the authors without a clear understanding of what changes, if any, are needed to enhance their work. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment critiques the proposed framework as a simple combination of metalearning and federated learning, suggesting that it lacks technical contribution. However, it does not specify which part of the paper this critique is based on, such as a particular section or methodology. This makes it difficult for the authors to pinpoint the exact area that needs attention. Additionally, the comment lacks specificity regarding what aspects of the framework are considered simple or how it could be improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the proposed framework is a simple combination of metalearning and federated learning, suggesting that it lacks technical contribution. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references to what aspects of the framework are considered simple or how they could be improved, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment critiques the proposed framework as a simple combination of metalearning and federated learning, suggesting that it lacks technical contribution. However, it does not provide any specific feedback or suggestions on how the authors might enhance their work or address the perceived lack of technical contribution. Without actionable guidance or constructive criticism, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it is rated as 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the insufficient contribution of the paper, specifically noting that while the authors studied the connection between complementary and model robustness, they did not explore how to leverage this connection to improve robustness. The reviewer suggests that the paper should include more insightful findings or possible solutions beyond the analysis of the connection. While the comment implies that the authors should expand their work to provide more insights, it does not explicitly instruct them on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to add more depth to their findings. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the contribution of the paper, specifically critiquing the lack of further studies on how to leverage the connection between complementary and model robustness to improve robustness. However, it does not specify which part of the paper this critique pertains to, such as a particular section or analysis. The authors can infer that it relates to the conclusion or discussion sections, but this inference is not explicit. The comment is specific in detailing what is missing, namely more insightful findings or possible solutions, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the contribution of the paper is insufficient, specifically noting that the authors studied the connection between complementary and model robustness but did not explore how to leverage this connection to improve robustness. The reviewer suggests that the paper should include more insightful findings or possible solutions beyond the analysis of the connection. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion that the conclusion could be easily obtained. This makes the claim 3, as it requires further elaboration or evidence to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, specifically the lack of contribution beyond the analysis of the connection between complementary and model robustness. It points out that the paper does not explore how to leverage this connection to improve robustness, which is a critical area for further study. The comment provides a clear and actionable suggestion by recommending that the authors should include more insightful findings or possible solutions to enhance the paper\"s contribution. This feedback is valuable as it guides the authors on how to improve their work by offering a specific direction for future exploration. However, the comment could be more helpful if it provided examples or specific suggestions on what kind of insights or solutions could be explored. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the choice of focusing on which clusters are \"best\" rather than exploring the differences in representation between them, given the paper\"s motivation. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should reconsider their focus, but it lacks concrete details on how to make this change or what specific aspects of the representation differences should be explored. As a result, the action is implicit and vague, leaving the authors without clear direction on how to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment questions the focus of the paper on identifying \"best\" clusters rather than exploring differences in representation, given the paper\"s motivation. However, it does not specify which part of the paper this critique pertains to, such as a specific section or analysis, making it weakly grounded. The comment is specific in its critique of the focus on \"best\" clusters, but without clear grounding, the authors may struggle to identify the exact part of the paper that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the focus of the paper on identifying \"best\" clusters rather than exploring differences in representation, given the paper\"s motivation. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this choice is odd or how it deviates from the paper\"s motivation. Without additional context or explanation, the claim remains vague and 1, leaving the authors without a clear understanding of the issue or how to address it. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The comment questions the focus of the paper on identifying \"best\" clusters rather than exploring differences in representation, given the paper\"s motivation. This feedback highlights a potential mismatch between the paper\"s objectives and its approach, which could be a significant issue. However, the comment does not provide specific suggestions or guidance on how the authors might address this concern or what alternative approaches could be considered. While it identifies a potential weakness, it lacks actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out several issues with the organization and layout of the paper, including the font size of annotations in figures, the placement of figures and tables, and formatting errors. While the comment identifies specific problems, it does not provide explicit guidance on how to address these issues or suggest specific actions for improvement. The authors can infer that they need to improve the organization and layout of their paper, but the comment lacks concrete details on how to achieve this. Therefore, the comment is 3, as it highlights areas for improvement but does not provide detailed instructions on how to implement those changes.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific issues with the organization and layout of the paper, including the font size of annotations in figures, the placement of figures and tables, and formatting errors. The authors can accurately identify the parts of the paper being addressed, such as Figure 1, Figure 2, and Table 2. Additionally, the comment is specific because it details what is wrong with each of these elements, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is not well organized and provides specific examples of issues with the layout, such as font size, figure placement, and table insertion. However, it lacks detailed reasoning or references to support these claims, such as comparisons to other wellorganized papers or guidelines for proper layout. The comment provides some evidence through specific examples, but it does not fully substantiate the claim with comprehensive reasoning or references. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed justification to be fully convincing.", "helpfulness_rationale": "The review comment identifies several specific issues with the organization and layout of the paper, such as font size, figure placement, and table insertion. It provides clear and actionable feedback by pointing out specific areas that need improvement, such as the font size of annotations in figures and the placement of figures and tables. This feedback is valuable as it guides the authors on how to enhance the readability and clarity of their paper. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of wellorganized papers for reference. Overall, the comment is 4 as it effectively directs the authors to improve the organization and layout of their paper, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment raises two specific issues: the definition of \"upper faces\" of the convex hull and the lack of explicit definition for the variable \"p\" in the context of decision boundaries of neural networks. The comment suggests that the dual subdivision and projection \u03c0 need to be explained better, and it recommends moving the definition of \"p\" to a more appropriate location. These suggestions are explicit and provide clear guidance on what needs to be addressed and how to improve the draft. The authors know exactly what actions to take to enhance the clarity and coherence of their paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper that need clarification, such as the \"upper faces\" of the convex hull and the definition of the variable \"p\" in the context of decision boundaries of neural networks. This allows the authors to accurately identify the sections that require attention. The comment is also specific because it details what needs to be clarified or improved, such as explaining the dual subdivision and projection \u03c0 and defining the variable \"p.\" Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises two specific issues: the definition of \"upper faces\" of the convex hull and the lack of explicit definition for the variable \"p\" in the context of decision boundaries of neural networks. The comment suggests that these issues are problematic and need clarification. However, it does not provide any supporting evidence, reasoning, or references to substantiate why these issues are significant or how they impact the paper\"s clarity or validity. Without additional context or justification, the claims remain 1, as the authors are left without a clear understanding of the importance of these points. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies two specific areas that need clarification: the definition of \"upper faces\" of the convex hull and the lack of explicit definition for the variable \"p\" in the context of decision boundaries of neural networks. By pointing out these issues, the comment provides clear and actionable feedback that can help the authors improve the clarity and coherence of their paper. However, the comment could be more helpful if it offered suggestions on how to clarify these concepts or provided examples of how to define \"p\" more explicitly. Despite this, the feedback is 4 as it directs the authors to specific areas that require attention and improvement. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point expresses a lack of conviction regarding the idea that images and their augmentations should be treated separately, suggesting that they can be interchangeable. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this concern or what changes, if any, should be made to the draft. Without actionable suggestions or a clear direction for improvement, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses a lack of conviction regarding the idea that images and their augmentations should be treated separately, suggesting that they can be interchangeable. However, it does not specify which part of the paper this idea is discussed in, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the paper need to be revised or improved. Without explicit references to sections or detailed guidance, the authors cannot effectively address the feedback. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses a lack of conviction regarding the idea that images and their augmentations should be treated separately, suggesting that they can be interchangeable. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the reviewer\"s skepticism. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses a lack of conviction regarding the idea that images and their augmentations should be treated separately, suggesting that they can be interchangeable. However, the comment does not provide any specific reasoning or examples to support this claim, nor does it offer suggestions for improvement or alternative approaches. Without actionable feedback or detailed guidance, the authors are left without a clear understanding of how to address this concern or what changes might be beneficial. As a result, the comment is 1, as it does not provide any actionable insights or direction for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that some of the pieces are using existing methods, such as equation (12), and that the presentation of these methods is vague. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to improve the presentation or whether the authors should include more detailed explanations or references. Without actionable suggestions or concrete steps, the authors are left without a clear understanding of what changes are needed to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions specific elements, such as \"equation (12)\" and the presentation of methods, which provides full grounding as the authors can accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the presentation of these methods is vague and requires checking the original paper for understanding. This level of detail makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some of the pieces are using existing methods, such as equation (12), and that the presentation of these methods is vague. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact issues or how to address them. The lack of detailed evidence or examples makes the claim 3, as the authors would need to invest additional effort to determine the validity of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that some of the pieces are using existing methods and that the presentation of these methods is vague. This feedback is 3 as it points out a potential area for improvement, specifically the clarity of the presentation. However, the comment lacks actionable suggestions or guidance on how the authors might address this issue, such as recommending additional explanations or references. While it highlights a weakness, it does not provide enough detail or direction for the authors to effectively improve their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment indicates that the writing or presentation is \"jumbled\" at times, but it does not provide any specific examples or suggestions for improvement. It lacks explicit guidance or concrete actions for the authors to take to address the issue. The comment is vague and does not offer any actionable steps for the authors to enhance the clarity of their draft. As a result, the authors are left without a clear understanding of what needs to be done to improve the paper. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment indicates that the writing or presentation is \"jumbled\" at times, but it does not specify which parts of the paper are affected or what aspects are unclear. This makes it difficult for the authors to identify the exact sections that need attention. Additionally, the comment lacks specificity regarding what needs to be clarified or improved. Without detailed guidance, the authors cannot effectively address the issue. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the writing or presentation is \"jumbled\" at times, but it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed explanation or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment indicates that the writing or presentation is \"jumbled\" at times, suggesting that the paper may be difficult to follow. However, it lacks specificity and does not provide any actionable feedback or suggestions for improvement. Without detailed guidance on what aspects of the writing are unclear or how to improve clarity, the authors are left without a clear path to enhance their draft. Therefore, the comment is 1, as it does not offer any actionable insights or constructive feedback."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the total computational complexity of the method compared to other methods, such as emerging convolutions, and speculates about the potential power demand on a mobile device. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the question or what specific aspects of computational complexity or power demand should be considered. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the total computational complexity of the method compared to other methods, such as emerging convolutions, and speculates about the potential power demand on a mobile device. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, while it provides some context by mentioning emerging convolutions, it lacks specificity in terms of what aspects of computational complexity or power demand should be addressed. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the computational complexity of the method compared to other methods, such as emerging convolutions, and speculates about the potential power demand on a mobile device. However, it does not provide any specific evidence, references, or detailed reasoning to support the claim about the computational complexity or power demand. The comment lacks concrete examples or data to substantiate the claim, making it difficult for the authors to understand the basis of the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the total computational complexity of the method compared to other methods, such as emerging convolutions, and speculates about the potential power demand on a mobile device. While it identifies a potential area of concern, it lacks specificity and actionable guidance. The authors are left without clear instructions on how to address this issue or what specific aspects of computational complexity or power demand should be considered. Without detailed suggestions or examples, the comment provides limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point identifies a specific error in the authors\" statement regarding the Induction, Duplicate Token, and Previous Token heads attending to the S2 token. It corrects the authors\" claim by stating that these heads are active at the S2 token but do not primarily attend to it. This feedback is explicit and provides a clear correction, allowing the authors to make the necessary changes to their draft. The action is concrete, as it specifies the exact wording that needs to be corrected. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific part of the paper being addressed, \"In the base IOI circuit, the Induction, Duplicate Token, and Previous Token heads primarily attend to the S2 token,\" allowing the authors to accurately identify the section. It is also specific because it corrects the authors\" claim by stating that these heads are active at the S2 token but do not primarily attend to it, providing a clear and detailed explanation of what needs to be addressed. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors\" statement about the Induction, Duplicate Token, and Previous Token heads primarily attending to the S2 token is incorrect, as it contradicts the findings in Section 3 of Wang et al., 2023. The comment provides a specific reference to an external source, which is a common method of verification. This reference supports the claim, making it 5. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a specific error in the authors\" statement regarding the Induction, Duplicate Token, and Previous Token heads attending to the S2 token. It corrects the authors\" claim by stating that these heads are active at the S2 token but do not primarily attend to it, as per the findings in Section 3 of Wang et al., 2023. This feedback is clear and actionable, providing the authors with a precise correction to make in their draft. By addressing this error, the authors can ensure the accuracy and validity of their claims. Therefore, the comment is 5, as it offers specific and constructive guidance for improving the paper."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the scalability of the method, suggesting that a distributed version might be necessary to handle large datasets. However, it does not provide explicit guidance on how to address this issue or suggest specific steps to improve scalability. The comment implies that the authors should consider developing a distributed version of the method, but it lacks concrete details on how to implement this or what specific changes are needed. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the scalability of the method, suggesting that a distributed version might be necessary to handle large datasets. However, it does not specify which part of the paper discusses the method or its scalability, making it weakly grounded. The comment is specific in its critique of the method\"s scalability, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the method is not scalable and suggests that a distributed version might be necessary to handle large datasets. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without concrete evidence or examples of how the method fails to scale, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 2, as it provides some insight but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment raises a concern about the scalability of the method, suggesting that it may not be suitable for handling large datasets without a distributed version. This is a relevant observation that could impact the practicality and applicability of the method. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as proposing alternative approaches or suggesting ways to scale the method. Without actionable advice, the feedback is 3 as it identifies a potential limitation but does not provide a clear path for improvement. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two issues: first, it notes that the proposed sensitivelayer selection does not make a significant difference compared to randomized selection in terms of StableDiffusion, and second, it points out the lack of mathematical or theoretical justification for Algorithm.1. While the comment identifies these issues, it does not provide explicit guidance on how the authors should address them. The authors are left to infer that they need to provide more detailed analysis or justification for these aspects, but the comment lacks concrete suggestions on how to do so. Therefore, the comment is 3, as it points out areas for improvement but does not offer specific steps for the authors to take.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig.5\" and \"the third figure,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the proposed sensitivelayer selection does not make a significant difference compared to randomized selection in terms of StableDiffusion, and that the authors do not further discuss this observation. Additionally, it notes the lack of mathematical or theoretical justification for Algorithm.1. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed sensitivelayer selection does not make a significant difference compared to randomized selection in terms of StableDiffusion, and that the authors do not further discuss this observation. Additionally, it notes the lack of mathematical or theoretical justification for Algorithm.1. While the comment highlights specific observations and areas for improvement, it lacks detailed reasoning or references to support these claims. The absence of specific examples or detailed explanations makes it difficult for the authors to fully understand and address the issues raised. Therefore, the comment is considered 2, as it provides some basis for the claims but requires more detailed justification or evidence to be 5.", "helpfulness_rationale": "The review comment identifies two specific areas for improvement in the paper. First, it points out that the proposed sensitivelayer selection does not make a significant difference compared to randomized selection in terms of StableDiffusion, and suggests that the authors should further discuss this observation. This feedback is actionable as it highlights a potential gap in the paper that the authors can address by providing additional analysis or discussion. Second, the comment notes the lack of mathematical or theoretical justification for Algorithm.1, which is a critical aspect of the paper. This feedback is clear and provides a specific area for improvement, making it 4. However, the comment could be more comprehensive by suggesting ways to address the lack of justification or by offering examples of how to enhance the theoretical foundation. Overall, the comment is 4 as it directs the authors to important areas that need further development."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the triples denoted as $(e_1, r, e_2)$ should be presented in a tuplelike structure rather than as sets. This is a clear and direct action for the authors to take, as it specifies exactly what needs to be changed in the draft. The comment provides concrete guidance on how to improve the presentation of the data, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 122,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the presentation of triples, suggesting that they should be shown in a tuplelike structure rather than as sets. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the presentation of triples as $(e_1, r, e_2)$ should be changed to a tuplelike structure instead of sets. However, the comment does not provide any reasoning or evidence to support why this change is necessary or how it would improve the clarity or understanding of the data. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the presentation of data in the paper. By recommending that the triples denoted as $(e_1, r, e_2)$ should be presented in a tuplelike structure rather than as sets, the reviewer offers a clear and concrete way for the authors to enhance the clarity and readability of their work. This feedback is valuable as it directly addresses a potential confusion in the data representation, which could help the authors improve the overall quality of their draft. However, the comment could be more helpful if it explained why this change is important or how it might impact the understanding of the data. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional context or rationale."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the scalability of optimal quantization, noting that it is mentioned in the paper and is a bottleneck for achieving fast convergence in big data/big model settings. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the scalability of their method. The feedback lacks actionable details, such as recommending specific techniques or approaches to enhance scalability. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the scalability issue of optimal quantization, which is mentioned in the paper. It also mentions the paper\"s aim to speed up VI by fast convergence, which is a bottleneck for big data/big model settings. However, the comment does not specify which part of the paper discusses these issues, making it weakly grounded. The comment is specific in detailing the scalability problem and its impact on the method\"s effectiveness, but without explicit references to sections or parts of the paper, the authors may struggle to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that optimal quantization is not scalable, even with clustering before, and that it is a bottleneck for achieving fast convergence in big data/big model settings. The comment references the paper\"s mention of scalability issues and the aim to speed up VI by fast convergence. However, the claim lacks specific examples, detailed reasoning, or references to support the assertion that quantization is a bottleneck. This makes the claim 3, as it provides a general direction but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential scalability issue with the method, specifically mentioning that optimal quantization is not scalable, even with clustering before. It highlights that this bottleneck could hinder the paper\"s goal of achieving fast convergence in big data/big model settings. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the scalability of their method. While it points out a critical area for improvement, the feedback is incomplete and does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it offers insight into a potential weakness but does not fully support the authors in making improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to compare the effectiveness of their methodology, Contrastive Response Tuning, against existing methods like contrastive decoding. It also mentions that issues mentioned earlier should be addressed and suggests that the work should be considered for a more applicationoriented venue. The comment provides clear and specific actions for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Contrastive Response Tuning,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting a comparison with existing methods, such as contrastive decoding, and addressing the \"notations issues.\" This provides clear guidance on what needs to be improved, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the paper should compare its methodology, Contrastive Response Tuning, against existing methods like contrastive decoding. It mentions that this comparison is necessary to address issues mentioned earlier. However, the comment does not provide specific examples of these issues or references to existing methods that should be compared, making it 3. The suggestion is logical but lacks detailed justification or evidence, which would strengthen the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the paper should compare its methodology, Contrastive Response Tuning, against existing methods like contrastive decoding. This comparison is crucial for evaluating the effectiveness of the proposed method. Additionally, the comment highlights the need to address issues mentioned earlier, which could include specific notations issues. The suggestion to consider a more applicationoriented venue is also helpful, as it provides a potential direction for the paper. Overall, the comment is clear and constructive, offering the authors specific guidance on how to improve their draft. Therefore, it is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises several concerns about the algorithm\"s effectiveness and problem, specifically regarding the requirement for access to the entire training dataset. It also questions the comprehensiveness of the related validation experiments and the analysis of the algorithm\"s time complexity and efficiency. Additionally, the reviewer suggests that the authors should further clarify the technical contribution rather than focusing on the form of the attack. While the comment identifies several areas for improvement, it does not provide explicit instructions or concrete steps for the authors to follow. The actions are implicit and somewhat vague, as the authors need to infer what specific changes are needed to address these concerns. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses multiple aspects of the paper, including the effectiveness and problem of the algorithm, the comprehensiveness of related validation experiments, the time complexity of computation, and the efficiency of the algorithm. However, it does not specify which sections of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the impact of limited dataset access, the comprehensiveness of validation experiments, and the analysis of time complexity and efficiency. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises several claims, including the need for the algorithm to access the entire training dataset, the lack of comprehensive validation experiments, and the absence of analysis on time complexity and efficiency. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence or detailed justification makes it difficult for the authors to understand and address the concerns effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to fully substantiate the claims.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper. It highlights the issue of the algorithm\"s reliance on access to the entire training dataset, questioning how it would operate effectively with limited access. It also points out the lack of comprehensive validation experiments and analysis of time complexity and efficiency, suggesting that these aspects should be addressed. Additionally, the comment encourages the authors to clarify the technical contribution rather than focusing solely on the form of the attack. While the comment provides valuable insights and areas for improvement, it could be more helpful by offering specific suggestions or examples on how to address these issues. Overall, the feedback is 3 as it directs the authors\" attention to important aspects of their work that need further development."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a potential issue with the statement that \"every kernel can be described by a feature space parameterized by a neural network,\" pointing out that this is not true for RBF kernels. The reviewer suggests that the limitation should be made more clear. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to address this issue or what specific changes should be made to clarify the limitation. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the statement about kernels and neural networks. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"104,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the statement about kernels and neural networks, pointing out that it is not true for RBF kernels and that the limitation should be made more clear. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement \"every kernel can be described by a feature space parameterized by a neural network\" is not true, specifically mentioning RBF kernels and their infinitedimensional RKHS. The reviewer provides a logical reasoning by explaining that an NN with infinite width would be needed to represent the RBF kernel, which is not feasible in practice. This reasoning is clear and provides a logical basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the statement that \"every kernel can be described by a feature space parameterized by a neural network,\" pointing out that this is not true for RBF kernels. It provides a clear and logical explanation of why this claim is incorrect, noting that an NN with infinite width would be needed to represent the RBF kernel, which is not feasible in practice. The comment suggests that this limitation should be made more clear, offering a specific area for improvement. This feedback is clear and actionable, providing the authors with a concrete way to enhance the clarity and accuracy of their draft. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about how the linear attention handles autoregressive decoding during inference, specifically regarding the use of limited tokens for generating the next token. While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this concern. The authors are left to infer that they might need to clarify or address this issue in their draft, but without concrete steps or suggestions, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the linear attention mechanism\"s handling of autoregressive decoding during inference, specifically regarding the use of limited tokens for generating the next token. However, it does not specify which part of the paper discusses this aspect, making it weakly grounded. The comment is specific in its inquiry about the benefits of inference, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the linear attention mechanism\"s handling of autoregressive decoding during inference, specifically regarding the use of limited tokens for generating the next token. The comment is a request for clarification and does not contain a claim or opinion that requires verification. It is purely factual and descriptive, fitting the \"No\" label.", "helpfulness_rationale": "The review comment raises a pertinent question about the linear attention mechanism\"s handling of autoregressive decoding during inference. It points out a potential issue regarding the use of limited tokens for generating the next token, which could impact the benefits of inference. This feedback is valuable as it prompts the authors to consider and address a critical aspect of their methodology. However, the comment could be more helpful if it provided suggestions or examples on how to address this issue or improve the inference process. Overall, the comment is 3 as it identifies a potential weakness and encourages the authors to explore a relevant aspect of their work, but it lacks detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the possibility of Generalized Pattern Inference (GPI) with noise added reproducing the data similarly well as the original GPI model. It also suggests that other measures, such as behavioral trajectories or time to goal, could be used to demonstrate that GPI cannot have as good a fit with behavioral data. Additionally, the comment suggests that the approach is suitable for modeling pattern separation tasks, for which behavioral data is available, and recommends discussing this. While the comment implies that the authors should consider these points, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the questions or suggestions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the possibility of GPI with noise added reproducing the data similarly well and suggests using other measures, such as behavioral trajectories or time to goal, to demonstrate that GPI cannot have as good a fit with behavioral data. Additionally, the comment suggests discussing the suitability of the approach for modeling pattern separation tasks, for which behavioral data is available. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the possibility of Generalized Pattern Inference (GPI) with noise added reproducing the data similarly well as the original GPI model. It suggests that other measures, such as behavioral trajectories or time to goal, could be used to demonstrate that GPI cannot have as good a fit with behavioral data. The comment also mentions the suitability of the approach for modeling pattern separation tasks, for which behavioral data is available, and recommends discussing this. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that GPI with noise added cannot reproduce the data as well. This makes the claim 3, as it provides a logical direction for further exploration but requires more detailed evidence or examples to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the possibility of Generalized Pattern Inference (GPI) with noise added reproducing the data similarly well as the original GPI model. It suggests that other measures, such as behavioral trajectories or time to goal, could be used to demonstrate that GPI cannot have as good a fit with behavioral data. Additionally, the comment notes the suitability of the approach for modeling pattern separation tasks, for which behavioral data is available, and recommends discussing this. While the comment identifies a potential area for improvement and suggests specific measures to consider, it lacks detailed guidance on how to address these points or what specific aspects of the discussion should be included. The feedback is 3 as it provides direction for further exploration and discussion, but it could be more actionable with additional details or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should reproduce the results of the methods they are comparing using the same setting as the original paper, specifically using AdamW with cosine lr instead of Adam with fixed lr. This is a clear and direct action for the authors to take, as it provides a specific method for improving the fairness of the comparison. The comment also explains why this is necessary, highlighting that most recent methods have their code released, which makes it feasible for the authors to follow this suggestion. Therefore, the comment is 5, as it provides a concrete and explicit action for the authors to take.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed method\"s use of AdamW with cosine lr for training, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the unfairness of comparing methods using Adam with fixed lr, suggesting that the authors should reproduce the results using the same setting as the original paper. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method\"s comparison with other methods is unfair due to the use of AdamW with cosine lr for training, while the other methods use Adam with fixed lr. The reviewer suggests that the authors should reproduce the results using the same setting as the original paper, as most recent methods have their code released. This claim is 3 as it provides a logical reasoning for the unfairness of the comparison and suggests a specific action for improvement. However, the comment could be strengthened by providing specific examples or references to support the claim about the unfairness of the comparison. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the fairness of the comparison between the proposed method and other methods in the paper. It points out that the proposed method uses AdamW with cosine lr for training, while the other methods use Adam with fixed lr. The reviewer suggests that this discrepancy makes the comparison unfair and recommends that the authors reproduce the results using the same setting as the original paper, as most recent methods have their code released. This feedback is clear and actionable, providing the authors with a specific direction to improve the fairness and validity of their comparisons. However, it could be more helpful if it included suggestions on how to implement the suggested changes or addressed other potential issues with the comparison. Overall, the comment is 4, as it effectively guides the authors toward improving the fairness of their comparisons."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the utility of specific information provided in the feedback network, such as the incorrect phrase and corrected phrase, and the type of mistake. It asks for performance metrics with and without these types of information, as well as with just natural language feedback. While the questions imply that the authors should consider these aspects, they are not explicitly stated as actions. The authors can infer that they need to conduct additional analyses or experiments to address these questions, but the comment lacks concrete guidance on how to proceed. Therefore, the comment is 3, as it identifies areas for exploration but does not provide detailed instructions on how to implement them.", "grounding_specificity_rationale": "The comment raises questions about the utility of specific information provided in the feedback network, such as the incorrect phrase and corrected phrase, and the type of mistake. It also asks for performance metrics with and without these types of information, as well as with just natural language feedback. However, the comment does not specify which part of the paper these questions pertain to, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing what needs to be addressed, such as the performance metrics with and without certain types of information. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions seeking clarification and additional information about the feedback network. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the utility of specific information provided in the feedback network, such as the incorrect phrase and corrected phrase, and the type of mistake. It asks for performance metrics with and without these types of information, as well as with just natural language feedback. This feedback is 3 as it prompts the authors to consider the impact of different types of information on the performance of the feedback network. However, the comment lacks specific suggestions or guidance on how to address these questions or improve the draft. While it identifies areas for exploration, it does not provide actionable steps for the authors to take. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that Table 1 should include standard deviations and that the experiments should be more extensive to strengthen the submission. However, it does not provide specific guidance on how to achieve these improvements or what additional experiments should be conducted. The action is implicit and somewhat vague, as the authors are left to infer the specific steps needed to enhance the experiments. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the inclusion of standard deviations in Table 1. Additionally, it provides a suggestion for improvement by stating that the experiments should be more extensive, which is a clear and actionable point. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Table 1 should include standard deviations and that the experiments should be more extensive. However, it does not provide any supporting evidence, reasoning, or examples to justify why these additions would strengthen the submission. The comment lacks specific details or references to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 1, noting that it lacks standard deviations. It also suggests that the experiments could be more extensive to strengthen the submission. While the comment points out a clear area for improvement, it does not provide detailed guidance on how to address the issue or what specific experiments should be conducted. The feedback is 3 as it highlights a potential weakness, but it lacks depth and actionable suggestions, leaving the authors with a general direction but not a comprehensive plan for improvement. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests several actions to improve the paper, including restructuring the sections (introduction>method>experiments) and focusing more on the IEM in Figure 3, which is considered the main figure. It also recommends improving the visualization of Figures 7 and . While the comment provides explicit actions, it lacks specific guidance on how to implement these changes, such as what specific elements to focus on or how to improve the visualization. The authors know what needs to be done but may struggle with the execution details, making the comment 3.", "grounding_specificity_rationale": "The comment provides specific suggestions for improving the paper, such as restructuring the sections (introduction>method>experiments) and focusing more on the IEM in Figure 3, which is considered the main figure. It also recommends improving the visualization of Figures 7 and . However, the comment does not explicitly mention which sections are difficult to follow or where the figures are located, making it weakly grounded. The authors can infer that the issues are related to the structure and figures, but they cannot pinpoint the exact parts of the paper being addressed. Despite this, the comment is specific in its suggestions for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is difficult to follow and suggests improvements to the structure and focus on specific figures. However, it does not provide any specific examples or detailed reasoning to support why the paper is hard to follow or how the suggested changes would improve it. The comment lacks concrete evidence or references to substantiate the claim, making it difficult for the authors to understand and address the feedback effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies several areas where the paper could be improved, such as its structure and the focus on specific figures. It suggests restructuring the sections (introduction>method>experiments) and emphasizes the importance of the IEM in Figure 3, which is considered the main figure. Additionally, it recommends improving the visualization of Figures 7 and . While the comment provides actionable feedback, it could be more helpful by offering specific suggestions on how to improve the structure or visualization. Overall, the comment is 4 as it directs the authors to areas that need attention, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly requests information about the final learning rates used for the deep models, particularly for CIFAR10 and CIFAR100. It also highlights a concern about the potential impact of the learning rate search interval on the results. While the comment clearly identifies the need for additional information, it does not provide specific guidance on how the authors should address this concern or what steps to take to ensure the learning rate is within the optimal range. The action is explicit but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment requests information about the final learning rates used for the deep models, particularly for CIFAR10 and CIFAR100. It also raises a concern about the potential impact of the learning rate search interval on the results. However, the comment does not specify which part of the paper this information should be included in, making it weakly grounded. The authors can infer that it relates to the experimental setup or results sections, but without explicit references, it is challenging to pinpoint the exact location. The comment is specific in its request for learning rates and the potential impact on results, but the lack of grounding limits its effectiveness. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the learning rates used in the experiments, specifically for CIFAR10 and CIFAR100. It suggests that the authors should provide the final learning rates used, as the limited search interval could impact the results. This is a logical claim based on the methodology and potential limitations of the study. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to consider the reasoning and address the concern themselves, which is why the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the learning rates used in the experiments, particularly for CIFAR10 and CIFAR100. It suggests that the limited search interval for learning rates could impact the results if the optimal learning rate for the baseline is outside the tested range. This is a critical point that could affect the validity of the results and should be addressed by the authors. However, the comment does not provide specific guidance on how to address this issue or suggest alternative approaches. While it identifies a potential weakness, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the impact of mitigation strategies on the overall performance of the model, suggesting that there might be a tradeoff between reducing a particular behavior and maintaining high performance. However, it does not provide explicit guidance or suggestions on how the authors should address this concern or evaluate the impact of these strategies. The comment implies that the authors should consider the potential negative effects of these strategies on the model\"s utility, but it lacks concrete steps or actions for the authors to take. As a result, the comment is vague and does not provide actionable advice, making it barely actionable.", "grounding_specificity_rationale": "The comment addresses the impact of mitigation strategies on the overall performance of the model, specifically questioning whether these strategies might impair the model\"s utility. However, it does not specify which part of the paper discusses these mitigation strategies or where the authors should consider their impact. The authors can infer that it relates to the sections discussing model performance or mitigation strategies, but the comment lacks full grounding as it does not explicitly mention these sections. The comment is specific in detailing the concern about the tradeoff between reducing a particular behavior and maintaining high performance, but it does not provide detailed guidance on how to address this issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the impact of mitigation strategies on the overall performance of the model, suggesting that there might be a tradeoff between reducing a particular behavior and maintaining high performance. The comment provides a logical reasoning by stating that if these mitigation strategies significantly impair the model\"s utility, it might deter their adoption. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to further explore and substantiate the potential tradeoffs themselves to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the mitigation strategies used in the paper, specifically questioning their impact on the overall performance of the model. It highlights a common tradeoff between reducing a particular behavior and maintaining high performance, suggesting that if the mitigation strategies significantly impair the model\"s utility, it might deter their adoption. This feedback is 3 as it points out a critical area for consideration and potential consequences, prompting the authors to evaluate the effectiveness of their mitigation strategies. However, the comment lacks specific suggestions or guidance on how to address this concern, such as recommending alternative strategies or ways to balance performance and mitigation. Therefore, while it provides some insight, it could be more helpful with additional detail or actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the use of 6fold crossvalidation in the paper, questioning the necessity of this approach given that other papers in the field do not use crossvalidation. While the comment implies that the authors should provide a justification for their choice of crossvalidation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to explain the rationale behind their choice. However, the comment does provide some guidance by suggesting that the authors should clarify the reason for using crossvalidation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of 6fold crossvalidation for each dataset, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the necessity of crossvalidation, given that other papers in the field do not use it. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the necessity of using 6fold crossvalidation, given that other papers in the field do not use it. The comment provides a logical reasoning by pointing out the inconsistency in methodology across different papers, suggesting that the authors should clarify the rationale behind their choice. However, the comment lacks specific references to the other papers or detailed explanations of why crossvalidation is required in this context. This makes the claim 3, as it provides a basis for questioning but requires further elaboration or evidence to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s methodology, specifically questioning the use of 6fold crossvalidation when other papers in the field do not employ this approach. It highlights a lack of clarity regarding the rationale for using crossvalidation, which is an important aspect of experimental design. However, the comment could be more helpful if it provided suggestions on how the authors might address this issue, such as explaining the benefits of crossvalidation in their context or suggesting alternative methods for validation. Despite this, the comment is 3 as it prompts the authors to reconsider their methodology and provide a justification for their choice. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the results presented in Table 2, specifically noting that the proposed approaches only outperform the baselines in one setup out of three and that there is no consistent trend in the results. The reviewer suggests that additional experiments or more indepth analysis are needed to better justify the claims in the paper. While the comment implies that the authors should conduct further experiments or analysis, it does not provide specific guidance on what these experiments should entail or how to conduct them. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps without detailed instructions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the results, noting that the proposed approaches only outperform the baselines in one setup out of three and that there is no consistent trend in the results. The comment further suggests that additional experiments or more indepth analysis are necessary to better justify the claims in the paper. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with a score of 5.", "verifiability_rationale": "The review point claims that the results presented in Table 2 are insufficient to prove the benefits of the proposed methods, as the proposed approaches only outperform the baselines in one setup out of three, and there is no consistent trend in the results. The reviewer suggests that additional experiments or more indepth analysis are needed to better justify the claims. This claim is 3 as it provides a logical reasoning for the insufficiency of the current results, but it lacks specific examples or references to support the need for additional experiments. The authors would need to infer the exact nature of the additional experiments or analysis required. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the results presented in Table 2, noting that the proposed approaches only outperform the baselines in one setup out of three and that there is no consistent trend in the results. This feedback is valuable as it highlights a potential weakness in the paper\"s claims about the effectiveness of the proposed methods. The comment suggests that additional experiments or more indepth analysis are necessary to better justify the claims, providing clear and actionable guidance for the authors to improve their draft. However, the comment could be more helpful if it offered specific suggestions on what additional experiments or analyses might be beneficial. Overall, the comment is 4 as it effectively points out a critical area for improvement and provides a direction for further work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the effectiveness of the proposed engineering method for ReC but notes the incorporation of combinatorial and heuristic aspects, specifically mentioning the NonAmbiguous Query Generation procedure and its reliance on a sophisticated filtering template. The comment suggests that the authors clarify the impact of these heuristic components. While the action is explicit, it lacks concrete guidance on how the authors should clarify the impact of these components. The suggestion is 3 as it directs the authors to provide more information, but it does not specify the exact steps or details needed to address the issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"NonAmbiguous Query Generation procedure\" and the \"sophisticated filtering template,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of incorporating heuristic components and suggests that the authors clarify the impact of these components. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper presents a highly effective engineering method for ReC but notes the incorporation of combinatorial and heuristic aspects. The comment suggests that the authors clarify the impact of these heuristic components. However, the claim lacks specific examples or detailed reasoning to support the assertion about the effectiveness of the method or the impact of the heuristic components. Without such evidence or examples, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is rated as 3, as it provides some justification but lacks detailed support.", "helpfulness_rationale": "The review comment acknowledges the effectiveness of the proposed engineering method for ReC but points out the incorporation of combinatorial and heuristic aspects, specifically mentioning the NonAmbiguous Query Generation procedure and its reliance on a sophisticated filtering template. It suggests that the authors clarify the impact of these heuristic components, which is a valuable suggestion for improving the clarity and transparency of the paper. However, the comment could be more helpful if it provided specific guidance on how to address these issues or suggested alternative approaches. Overall, the feedback is 4 as it identifies a potential area for improvement and offers a clear direction for the authors to enhance their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises doubts about the feasibility of training the proposed method without using camera information, specifically questioning how the method can perform ray marching without knowing the viewpoint. The reviewer challenges the logic of the method by asking how the ray\"s origin is determined. While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors might address these concerns. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify or address the issue of ray marching without camera information. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 223,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the feasibility of training the proposed method without camera information, particularly regarding the use of \"CAD model correspondences\" and the determination of the ray\"s origin. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the feasibility of the proposed method by challenging the use of camera information for training. It raises logical concerns about how the method can perform ray marching without knowing the viewpoint and how the ray\"s origin is determined. However, the comment lacks specific examples or references to support these claims, making it 3. The authors would need to address these concerns themselves, which could be challenging without additional context or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical concern about the feasibility of the proposed method, specifically questioning how it can be trained without using camera information. It challenges the logic of the method by asking how ray marching can be performed without knowing the viewpoint and how the ray\"s origin is determined. This feedback is valuable as it highlights a potential flaw in the methodology that the authors need to address. However, the comment could be more helpful if it provided suggestions or examples on how to resolve this issue or offered alternative approaches. Despite this, the comment is 4 as it directs the authors\" attention to a significant weakness in their work, prompting them to reconsider and improve their method. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper would benefit from a more detailed comparison with related work, specifically focusing on the time complexity and competitiveness of prior art. While the comment implies that the authors should include a more detailed comparison, it does not provide specific guidance on how to conduct this comparison or what aspects to focus on. The action is implicit and somewhat vague, as the authors are left to infer the details of the comparison themselves. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper would benefit from a more detailed comparison with related work, specifically focusing on the time complexity and competitiveness of prior art. However, it does not specify which part of the paper this comparison should be included in, such as a specific section or table. The authors can infer that it relates to the discussion of related work, but the lack of explicit grounding makes it difficult to pinpoint the exact part of the paper being addressed. The comment is specific in suggesting a detailed comparison, but without full grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the paper would benefit from a more detailed comparison with related work, specifically focusing on the time complexity and competitiveness of prior art. This claim is 3 as it provides a clear suggestion for improvement, but it lacks specific examples or references to prior work that could be used for comparison. The authors would need to infer which prior works should be included in the comparison and how to conduct it effectively. Therefore, the comment is categorized as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, suggesting that a more detailed comparison with related work, particularly in terms of time complexity and competitiveness, would enhance the paper. This feedback is clear and actionable, as it provides a concrete direction for the authors to expand their analysis and improve the comprehensiveness of their work. However, the comment could be more helpful if it included specific examples or references to prior work that could be used for comparison. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests conducting experiments on more datasets to provide a more comprehensive evaluation of the proposed method. It also encourages experiments on the full dataset instead of the lowresource regime. While the comment implies that the authors should expand their experimental evaluation, it does not provide specific guidance on which datasets to use or how to conduct these experiments. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests conducting experiments on more datasets to provide a more comprehensive evaluation of the proposed method. It also encourages experiments on the full dataset instead of the lowresource regime. However, it does not specify which parts of the paper this suggestion pertains to, such as the methodology or results sections. The authors can infer that it relates to the experimental evaluation, but the comment lacks full grounding as it does not explicitly mention specific sections. It is specific in suggesting additional experiments, but the lack of grounding makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests conducting experiments on more datasets to provide a more comprehensive evaluation of the proposed method. It also encourages experiments on the full dataset instead of the lowresource regime. While the comment provides a logical reasoning for expanding the experimental evaluation, it lacks specific examples or references to datasets that could be used or to similar studies that have employed multiple datasets. This makes the claim 3, as the authors would need to infer which datasets might be appropriate and why they are necessary for a comprehensive evaluation. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the experimental evaluation by pointing out the lack of results on more datasets. It provides a clear and actionable suggestion to conduct experiments on more datasets to enhance the comprehensiveness of the evaluation. Additionally, it encourages experiments on the full dataset instead of the lowresource regime, which could provide a more robust assessment of the proposed method. This feedback is specific and offers a concrete direction for the authors to improve their draft, making it 4. However, it could be more helpful if it suggested specific datasets or provided additional context on why these datasets are important. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the clarity of how the generic argument task and the random argument task support the authors\" claims. It also criticizes the dataset transformation and experimental setup as cumbersome and unclear. However, the comment does not provide specific guidance on how the authors might clarify these aspects or improve the clarity of their work. The feedback lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about what actions to take. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises concerns about the clarity of how the generic argument task and the random argument task support the authors\" claims, as well as the complexity of the dataset transformation and experimental setup. However, it does not specify which sections of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact parts that need revision. The comment is specific in its critique of the dataset transformation and experimental setup, but it lacks grounding as it does not identify the specific sections being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the clarity of how the generic argument task and the random argument task support the authors\" claims. It also criticizes the dataset transformation and experimental setup as cumbersome and unclear. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issues effectively. The lack of detailed justification or references to specific sections of the paper makes the claim 3, as the authors would need to infer the exact areas needing improvement. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a lack of clarity in how the generic argument task and the random argument task support the authors\" claims. It also critiques the dataset transformation and experimental setup as cumbersome and unclear. While the comment highlights important areas for improvement, it does not provide specific suggestions or guidance on how the authors might address these issues. The feedback is 3 as it points out potential weaknesses, but it lacks actionable advice, making it difficult for the authors to effectively improve their draft. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about how the PL condition used in the paper compares to the PL conditions proposed in a specific reference, \"Global Convergence of ArbitraryBlock Gradient Methods for Generalized Polyak\u00c5\u0081ojasiewicz Functions\". However, it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on whether the authors should address this comparison, how they should do so, or what implications it might have for their work. Without any actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the comparison of the PL condition used in the paper with those proposed in a specific reference, \"Global Convergence of ArbitraryBlock Gradient Methods for Generalized Polyak\u00c5\u0081ojasiewicz Functions.\" However, it does not specify which part of the paper this comparison should be made in, nor does it provide details on what aspects of the PL conditions should be compared. This lack of explicit reference to a specific section or element of the paper makes it weakly grounded. Additionally, the comment lacks specificity as it does not detail what aspects of the PL conditions should be compared or how this comparison might impact the paper. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point is a question seeking clarification on the comparison of the PL condition used in the paper with those proposed in a specific reference. It does not contain an opinion, judgment, or suggestion that requires verification. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the comparison of the PL condition used in the paper with those proposed in a specific reference. While it identifies a potential area for further exploration or clarification, it lacks depth and does not provide specific guidance or suggestions on how the authors might address this comparison or its implications for their work. The comment highlights a gap in the paper but does not offer actionable advice or detailed feedback, leaving the authors with only a vague direction for improvement. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the use of AutoAugment as a stronger augmentation strategy, suggesting that information leakage is likely due to the policy being obtained by supervised training on ImageNet. It also questions the authors\" conclusion in Section 4.2 regarding the need for pretraining datasets to match the target dataset in terms of being object or scenecentric. The comment implies that this could be a setback for SSL algorithms that aim to learn more generic representations. However, it does not provide explicit guidance on how the authors should address these concerns or suggest specific actions to take. The feedback is implicit and somewhat vague, as it highlights potential issues but does not offer concrete steps for improvement. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.2\" and \"L114,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the authors\" conclusion regarding the need for pretraining datasets to match the target dataset in terms of being object or scenecentric, and whether this could be a setback for SSL algorithms. Additionally, it raises concerns about the use of AutoAugment as a stronger augmentation strategy, suggesting potential information leakage due to its policy being obtained by supervised training on ImageNet. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the use of AutoAugment as a stronger augmentation strategy, suggesting that information leakage is likely due to the policy being obtained by supervised training on ImageNet. It also questions the authors\" conclusion regarding the need for pretraining datasets to match the target dataset in terms of being object or scenecentric, suggesting it could be a setback for SSL algorithms. However, the comment lacks specific examples or references to support these claims, making it 3. The authors would need to further explore and substantiate the concerns raised to fully understand and address them. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the use of AutoAugment as a stronger augmentation strategy, suggesting that information leakage is likely due to the policy being obtained by supervised training on ImageNet. It also questions the authors\" conclusion regarding the need for pretraining datasets to match the target dataset in terms of being object or scenecentric, suggesting it could be a setback for SSL algorithms. While the comment identifies potential issues and raises thoughtprovoking questions, it lacks specific suggestions or guidance on how the authors might address these concerns or improve their draft. The feedback is 3 as it prompts the authors to consider these issues, but it could be more actionable with additional detail or direction. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper lacks analysis on the alignment of entity representations, particularly in the context of multilingual alignment. It explicitly recommends adding more analysis and suggests including visualizations or case studies for different language types, such as language families. Additionally, the reviewer expresses interest in whether entities from lowresourced languages are well aligned with highresourced ones. This feedback provides clear and concrete actions for the authors to take, including specific suggestions for additional analysis and visualizations. The explicit nature of the recommendations and the detailed guidance on what to include make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the languageagnostic characters of entity representations,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of analysis on the alignment of entity representations, particularly in the context of multilingual alignment. The comment suggests adding more analysis and provides specific examples, such as visualizations or case studies for different language types, which adds to the specificity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks analysis on the alignment of entity representations, particularly in the context of multilingual alignment. It suggests adding more analysis and provides specific examples, such as visualizations or case studies for different language types. The comment is 4 as it provides a clear suggestion for improvement and offers specific examples of what could be included. However, it lacks detailed reasoning or references to existing work that could further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks analysis, namely the alignment of entity representations across different languages. It suggests that the authors could enhance their analysis by including more discussion on multilingual alignment and providing visualizations or case studies for different language types, such as language families. Additionally, the reviewer expresses interest in whether entities from lowresourced languages are well aligned with highresourced ones, which could be a valuable addition to the paper. This feedback is clear and actionable, providing the authors with specific suggestions for improving their analysis and potentially expanding their work. However, it could be more helpful if it included examples or references to existing work on multilingual alignment, which would further guide the authors in implementing the suggestions. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a specific issue with the references list, noting that it contains duplicates and lacks publication venues and/or years for many of the papers. This feedback is explicit and provides clear guidance on what needs to be addressed: ensuring the references list is accurate and complete. The authors know exactly what action to take to improve their draft, which is to check and correct the references list. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"references list,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of duplicates and missing publication venues and/or years in the references list. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the references list contains duplicates and lacks publication venues and/or years for many of the papers. This is a factual statement that can be verified by checking the references list. However, the comment does not provide specific examples or detailed reasoning to support the claim, making it 3. The authors would need to manually check the references to confirm the issue, which is a straightforward but timeconsuming process. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the references list, noting that it contains duplicates and lacks publication venues and/or years for many of the papers. This feedback is actionable as it provides clear guidance on what needs to be corrected or updated in the references section. By addressing these issues, the authors can ensure the accuracy and completeness of their references, which is crucial for credibility and transparency in academic work. However, the comment could be more helpful if it included suggestions on how to identify and correct these errors or provided examples of how to format the references correctly. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the theoretical analysis in Theorem 1 is unclear and weak, and it suggests that the authors need to analyze and compare the theoretical results to other comparable methods. This feedback provides a clear action for the authors to take, which is to clarify the error bound in Theorem 1 and compare it to other methods. The comment is explicit and provides concrete guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the theoretical analysis, namely the lack of clarity regarding the error bound and the need for comparison with other methods. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the theoretical analysis in Theorem 1 is unclear and weak, specifically questioning the meaning of the error bound. However, the comment does not provide any further explanation, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the theoretical analysis in Theorem 1, noting that the error bound is unclear and suggesting that the authors should analyze and compare their results with other comparable methods. This feedback is clear and actionable, providing the authors with a direct path to improve their draft by clarifying the theoretical analysis and enhancing its relevance. However, the comment could be more helpful if it included specific suggestions on how to clarify the error bound or which comparable methods to consider. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their theoretical analysis."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about why explicit methods perform better than implicit methods on locomotion tasks and notes the absence of pseudocode for the proposed method. It provides two references for further reading, which could help the authors understand the context better. However, the comment does not explicitly instruct the authors to include the pseudocode or provide specific guidance on how to address the question about method performance. The action is implicit and somewhat vague, as the authors need to infer that they should include the pseudocode and address the question about method performance. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the performance of explicit methods compared to implicit methods on locomotion tasks and notes the absence of pseudocode for the proposed method. It also provides references for further reading. However, the comment does not specify which part of the paper discusses these methods or where the pseudocode should be included. The authors can infer that it relates to the methodology or results sections, but the lack of explicit grounding makes it weakly grounded. The comment is specific in its request for the pseudocode and the references provided, which could help the authors understand the context better. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the performance of explicit methods compared to implicit methods on locomotion tasks and notes the absence of pseudocode for the proposed method. It provides references for further reading, which could help the authors understand the context better. However, the comment does not provide specific reasoning or evidence to support the claim about the performance difference between explicit and implicit methods. The references are provided for background information, but they do not directly address the claim. Therefore, the comment is 3, as it lacks detailed justification for the claim about method performance and the need for pseudocode.", "helpfulness_rationale": "The review comment raises a question about the performance of explicit methods compared to implicit methods on locomotion tasks, which is a relevant and important point for the authors to address. It also notes the absence of pseudocode for the proposed method, which could be a significant gap in the paper. The comment provides references for further reading, which could help the authors understand the context better. However, the comment lacks specific guidance on how to address the question about method performance or how to include the pseudocode. While it identifies areas for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the use of lowresource language pairs in finetuning the multilingual model, suggesting that the improvement in translation quality from 1.2 to 2.0 is insignificant in a practical sense. It references a specific paper, \"Better FineTuning by Reducing Representational Collapse,\" which could provide additional context or guidance for the authors. However, the comment does not explicitly instruct the authors to address this issue or provide specific suggestions on how to improve the practical significance of the results. The action is implicit and somewhat vague, as the authors can infer that they need to address the practical significance of their results but are not given concrete steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of lowresource language pairs and the method like R3F to maintain the generalization ability of the model. It also references specific language translations from 1.2 to 2.0, allowing the authors to accurately identify the part of the paper being addressed. The comment is specific because it points out the insignificance of the improvement in a practical sense and references a relevant paper for further context. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the improvement in translation quality from 1.2 to 2.0 is insignificant in a practical sense. It references a specific paper, \"Better FineTuning by Reducing Representational Collapse,\" which provides some support for the claim. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced paper to fully substantiate the claim. Therefore, the comment is 4, as it provides a basis for the claim but lacks comprehensive evidence or detailed explanation.", "helpfulness_rationale": "The review comment identifies a specific issue with the use of lowresource language pairs in finetuning the multilingual model, suggesting that the improvement in translation quality from 1.2 to 2.0 is insignificant in a practical sense. It references a relevant paper, \"Better FineTuning by Reducing Representational Collapse,\" which could provide additional context or guidance for the authors. While the comment highlights a potential weakness, it lacks detailed suggestions or actionable steps for the authors to address this issue. It provides some insight but could be more helpful with specific guidance on how to improve the practical significance of the results. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should visualize the effect of the existing PU learning methods\" performance decline as the dimensionality of the data increases. This is an explicit request for a specific action, which is clear and concrete. The authors know exactly what they need to do to address the comment, making it 5.", "grounding_specificity_rationale": "The comment suggests that the authors should visualize the effect of the existing PU learning methods\" performance decline as the dimensionality of the data increases. It mentions the research motivation of the paper, which provides some context. However, the comment does not specify which part of the paper discusses this claim or where the visualization should be included. While the authors might infer that it relates to the introduction or results sections, the comment lacks full grounding as it does not explicitly mention these sections. The suggestion is specific in terms of what needs to be addressed, but the lack of explicit grounding makes it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that the authors should visualize the effect of the existing PU learning methods\" performance decline as the dimensionality of the data increases. The comment suggests that this visualization is important because it is the research motivation of the paper. However, the comment lacks specific examples, references, or detailed reasoning to support why this visualization is necessary or how it would contribute to the paper\"s motivation. Without such evidence or explanation, the claim remains somewhat vague and difficult for the authors to fully understand and address. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific claim made by the authors regarding the performance decline of existing PU learning methods as the dimensionality of the data increases. It suggests that the authors should visualize this effect, which is important for the research motivation of the paper. This feedback is clear and actionable, as it provides a direct suggestion for enhancing the paper\"s presentation and clarity. By visualizing the effect, the authors can better illustrate and substantiate their claim, which is crucial for the paper\"s impact. However, the comment could be more helpful if it provided additional guidance on how to visualize this effect or what specific aspects to focus on. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point identifies specific issues with the result description, noting that it is unnecessarily convoluted. It provides suggestions for improvement, such as referencing a related idea from 1 and suggesting a check for useful communication in light of 2. The comment also mentions that the differences in figures seem too small and that the topography plots indicate something reasonable. While the suggestions are explicit, they are not fully actionable as they do not provide detailed guidance on how to implement the changes or what specific aspects of the result description need to be clarified. The authors have a general direction to follow but may need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific examples of convoluted result descriptions, such as \"less likely to produce less easier to teach and less structured languages when no listener gets reset.\" This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it provides suggestions for improvement, such as referencing a related idea from 1 and suggesting a check for useful communication in light of 2. Additionally, it points out that the differences in figures seem too small and that the topography plots indicate something reasonable. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the result description is unnecessarily convoluted and suggests improvements based on references to external works. The comment provides specific examples of convoluted language and references two external works (1 and 2) to support the suggestion for improvement. This level of detail and reference to external sources makes the claim 4, as it provides a clear basis for the reviewer\"s critique and offers a path for the authors to address the issue. However, the comment could be strengthened by providing more detailed reasoning or examples within the paper itself, which would align with a score of 4.", "helpfulness_rationale": "The review comment identifies specific issues with the result description, noting that it is unnecessarily convoluted. It provides actionable suggestions for improvement by referencing a related idea from 1 and suggesting a check for useful communication in light of 2. Additionally, it points out that the differences in figures seem too small and that the topography plots indicate something reasonable. This feedback is clear and provides the authors with specific directions to enhance the clarity and relevance of their results. However, the comment could be more helpful if it included more detailed guidance on how to address the convoluted language or suggestions for rephrasing. Overall, the comment is 4 as it offers constructive feedback and actionable steps for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises concerns about the need for human labor in building text descriptions for each task and questions the optimal textual format for policy learning, which varies across tasks and models. It also mentions the potential scalability issue with longtext input. However, the comment does not provide explicit or implicit actions for the authors to take. It lacks specific guidance on how to address these concerns or improve the draft. Without actionable suggestions or concrete steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises concerns about the need for human labor in building text descriptions for each task and questions the optimal textual format for policy learning, which varies across tasks and models. It also mentions the potential scalability issue with longtext input. However, the comment does not specify which part of the paper these concerns relate to, making it difficult for the authors to identify the exact sections that need attention. Additionally, while it provides some specific issues, it lacks detailed guidance on how to address them. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises concerns about the need for human labor in building text descriptions for each task and questions the optimal textual format for policy learning, which varies across tasks and models. It also mentions the potential scalability issue with longtext input. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence or detailed justification makes it difficult for the authors to understand and address the concerns effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises concerns about the need for human labor in building text descriptions for each task and questions the optimal textual format for policy learning, which varies across tasks and models. It also mentions the potential scalability issue with longtext input. However, the comment does not provide specific suggestions or actionable feedback on how the authors might address these concerns or improve their draft. Without detailed guidance or constructive advice, the authors are left without a clear understanding of what steps to take to enhance their work. Therefore, the comment is rated as 2, as it identifies areas for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the performance improvement of the proposed methods, as shown in Figure 3, does not seem significant, particularly in the bank dataset where the improvement is only ~0.02. It suggests that using tables to directly show key improvements might be more intuitive and detailed. While the comment implies that the authors should consider presenting their results in a more detailed and intuitive manner, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should focus on presenting their results in a more detailed and intuitive way. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the performance improvement of the proposed methods does not seem significant, particularly in the bank dataset where the improvement is only ~0.02. The comment further suggests using tables to directly show key improvements, which provides a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance improvement of the proposed methods, as shown in Figure 3, is not significant, particularly in the bank dataset where the improvement is only ~0.02. The reviewer suggests using tables to directly show key improvements, which could be more intuitive and detailed. However, the comment lacks specific examples or references to support the claim about the lack of significance or the suggestion for using tables. Without detailed evidence or comparisons, the claim remains 3, as it provides a general observation but lacks the depth needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the performance improvement of the proposed methods, as shown in Figure 3, particularly in the bank dataset where the improvement is only ~0.02. It suggests that using tables to directly show key improvements might be more intuitive and detailed. This feedback is clear and actionable, as it provides a specific area for improvement and a concrete suggestion for enhancing the presentation of results. By addressing this feedback, the authors can better highlight the significance of their work and improve the clarity of their findings. However, the comment could be more helpful if it provided additional context or examples of how to present the results in tables. Overall, the comment is 4, as it offers valuable guidance for enhancing the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises several issues with the experimental validation, including the lack of consideration for deeper networks and the absence of a description of the optimization strategy, particularly the grid search for hyperparameter selection. It also mentions a minor issue with the positioning of the work with respect to related works, specifically the consideration of layer redundancy in network pruning. The comment provides a specific reference to a related work that addresses layer redundancy, which could help the authors better position their work. While the comment identifies several areas for improvement, it does not explicitly instruct the authors on how to address these issues, such as suggesting specific experiments or changes to the optimization strategy. The action is implicit and somewhat vague, as the authors need to infer the specific actions needed to improve their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses several issues with the experimental validation, including the lack of consideration for deeper networks and the absence of a description of the optimization strategy, particularly the grid search for hyperparameter selection. It also mentions a minor issue with the positioning of the work with respect to related works, specifically the consideration of layer redundancy in network pruning. The comment provides a specific reference to a related work that addresses layer redundancy, which helps ground the comment by suggesting a relevant context for the authors to consider. However, the comment does not explicitly mention which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the issues with the experimental validation and the related work context. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experimental validation is not convincing due to the lack of consideration for deeper networks and the absence of a description of the optimization strategy, including the grid search for hyperparameter selection. It also mentions a minor issue with the positioning of the work with respect to related works, specifically the consideration of layer redundancy in network pruning. The comment provides a specific reference to a related work that addresses layer redundancy, which supports the claim about the positioning of the work. However, the comment lacks detailed reasoning or examples to fully substantiate the claim about the experimental validation, making it 3. The authors would need to provide additional context or evidence to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the experimental validation and positioning of the work. It points out that only shallow networks (2 or 3 layers) are considered, which limits the generalizability of the results. Additionally, it notes the absence of a description of the optimization strategy, including the grid search for hyperparameter selection. This feedback is clear and actionable, as it highlights specific aspects that need to be addressed to strengthen the experimental validation and the paper\"s contribution. The comment also provides a specific reference to a related work on layer redundancy in network pruning, which could help the authors better position their work within the existing literature. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided more detailed guidance on improving the experimental setup. Overall, the comment is 4 as it directs the authors to important areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point suggests that the use of a specific type of loss in a particular setting might be novel, but it does not provide any evidence or reasoning to support this claim. The comment lacks explicit guidance or suggestions for the authors to address the issue of proving new theoretical results. Without any actionable steps or concrete details, the authors are left without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the use of a specific type of loss in a particular setting might be novel, but it does not prove any new theoretical results. However, it does not specify which part of the paper this claim pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what theoretical results are expected or how they could be proven. As a result, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the use of a specific type of loss in a particular setting might be novel, but it does not prove any new theoretical results. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the use of a specific type of loss in a particular setting might be novel, but it does not provide any new theoretical results. However, the comment lacks specificity and does not offer any actionable feedback or suggestions for improvement. It does not identify what theoretical results are expected or how the authors might address this issue. Without clear guidance or direction, the authors are left without a clear understanding of what needs to be done to enhance their work. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests a straightforward hypothesis about the two parts of the paper, namely that the trivial part is highly consistent with the training set or has typical object pose in the center of the images, while the impossible part might involve ambiguous labels, atypical object pose, or position. The reviewer questions whether the authors could provide more evidence to either prove or disprove this hypothesis. While the comment implies that the authors should provide additional evidence, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to provide this evidence. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests a hypothesis about the two parts of the paper, namely the trivial and impossible parts, and questions whether the authors could provide more evidence to either prove or disprove this hypothesis. However, it does not specify which sections or figures of the paper these parts are discussed in, making it weakly grounded. The comment is specific in detailing the hypothesis and suggesting a direction for further exploration, but without explicit references to the paper, the authors may find it challenging to pinpoint the exact areas needing attention. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests a hypothesis about the two parts of the paper, namely the trivial and impossible parts, and questions whether the authors could provide more evidence to either prove or disprove this hypothesis. The reviewer provides a logical reasoning by suggesting that the trivial part might be highly consistent with the training set or have typical object pose in the center of the images, while the impossible part might involve ambiguous labels, atypical object pose, or position. This reasoning is based on common sense and logical inference, making the claim 3. However, the comment lacks specific references or examples to fully substantiate the hypothesis, which would strengthen the verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests a hypothesis about the two parts of the paper, namely the trivial and impossible parts, and questions whether the authors could provide more evidence to either prove or disprove this hypothesis. It offers a logical explanation for the hypothesis, suggesting that the trivial part might be highly consistent with the training set or have typical object pose in the center of the images, while the impossible part might involve ambiguous labels, atypical object pose, or position. This feedback is 3 as it provides a direction for the authors to explore and potentially strengthen their analysis. However, it lacks specific guidance on how to conduct this exploration or what additional evidence might be needed, which limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that Section 3.2 is difficult to follow and recommends that the author improve it by providing more illustrations and examples. While the comment explicitly states that the author should improve the section, it does not provide specific guidance on how to enhance it or what kind of illustrations or examples would be most beneficial. The action is explicit but vague, as the authors are left to infer the exact changes needed without detailed guidance. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the section, namely that it is difficult to follow, and suggests improvements by recommending the addition of more illustrations and examples. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Section 3.2 is difficult to follow and suggests that the author improve it by providing more illustrations and examples. However, the comment does not provide any specific reasoning or examples to support why the section is challenging to follow. Without detailed justification or examples, the authors may find it difficult to understand and address the issue effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Section 3.2, noting that it is difficult to follow. It provides a clear suggestion for improvement by recommending the addition of more illustrations and examples. This feedback is actionable and offers a concrete way for the authors to enhance the clarity and comprehensibility of their work. However, the comment could be more helpful if it specified which aspects of the section are particularly challenging or provided examples of how illustrations or examples could be incorporated. Overall, the comment is 4 as it directs the authors toward a specific area for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests adding fullysupervised baselines for small models in Table 1 to better understand the gap between full supervision and selfsupervised learning (SSL) for these models. This comment explicitly states an action for the authors to take, which is to include additional baselines in the table. However, it does not provide specific guidance on which fullysupervised baselines to include or how to implement them. While the action is clear, the lack of detailed instructions makes the comment 3, as the authors know what needs to be done but may need to infer the specifics of the implementation.", "grounding_specificity_rationale": "The comment suggests adding fullysupervised baselines for small models in Table 1 to better understand the gap between full supervision and selfsupervised learning (SSL) for these models. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table. The authors can infer that it relates to the results or discussion sections, but this inference is not explicit. Additionally, the comment lacks specificity regarding which fullysupervised baselines should be added or how they would contribute to understanding the gap. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests adding fullysupervised baselines for small models in Table 1 to better understand the gap between full supervision and selfsupervised learning (SSL) for these models. The comment provides a logical reasoning for why this addition would be beneficial, as it would help clarify the performance gap between different supervision methods. However, it does not provide specific examples or references to support the claim, which could strengthen the argument. Therefore, the comment is 3, as it lacks detailed evidence but provides a clear rationale for the suggestion.", "helpfulness_rationale": "The review comment suggests adding fullysupervised baselines for small models in Table 1 to better understand the gap between full supervision and selfsupervised learning (SSL) for these models. This feedback is 3 as it identifies a potential area for improvement by suggesting a specific addition to the table. However, the comment lacks depth and does not provide detailed guidance on which fullysupervised baselines to include or how they might contribute to the understanding of the gap. While it points out a direction for enhancement, the authors may need to infer the specifics of the implementation, making the feedback 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the time complexity of the proposed algorithm, specifically regarding the calculation of the hypervolume in each step of LaMOO. It suggests that this computation could be timeconsuming for problems with many objectives, potentially making LaMOO impractical for such problems. While the comment implies that the authors should address this issue, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to analyze and address the time complexity issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Time Complexity\" and \"LaMOO,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a concern about the time complexity of the proposed algorithm, particularly in relation to the calculation of hypervolume for problems with many objectives. The comment provides a clear question about the practicality of the algorithm for such problems, which gives the authors a clear direction for addressing the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the time complexity of the proposed algorithm, specifically regarding the calculation of the hypervolume in each step of LaMOO. It suggests that this computation could be timeconsuming for problems with many objectives, potentially making LaMOO impractical for such problems. The comment provides a logical reasoning by pointing out the potential issue with the algorithm\"s scalability, which is a valid concern. However, it does not provide specific examples or references to support the claim, making it 3. The authors would need to further explore and substantiate the claim themselves to fully address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical question about the time complexity of the proposed algorithm, specifically regarding the calculation of the hypervolume in each step of LaMOO. It highlights a potential issue with the algorithm\"s scalability, particularly for problems with many objectives, which could make LaMOO impractical for such problems. This feedback is valuable as it prompts the authors to consider and address a significant limitation of their approach. However, the comment could be more helpful if it provided suggestions on how to mitigate this issue or offered examples of alternative approaches. Overall, the comment is 4 as it identifies a crucial area for improvement and encourages the authors to explore potential solutions."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should delve deeper into the limitations of evolutionary methods, specifically focusing on leveraging state, reactiveness, and learning during an episode. It also advises being honest and direct in their critique, suggesting that the title is too generic and vague. The comment implies that the authors should clarify what \"brittle convergence properties\" mean and mentions that DeepRL methods are widely adopted. While the comment provides some direction, it lacks specific guidance on how to address these points, such as suggesting particular aspects to explore or examples to include. The action is implicit and somewhat vague, making it barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the limitations of evolutionary methods and the need for deeper discussion on leveraging state, reactiveness, and learning during an episode. It also addresses the title, suggesting it is too generic and vague, and questions the meaning of \"brittle convergence properties.\" The comment provides specific feedback on what needs to be addressed, such as being more precise in the critique and clarifying the meaning of certain terms. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should delve deeper into the limitations of evolutionary methods, specifically focusing on leveraging state, reactiveness, and learning during an episode. The comment also critiques the title as being too generic and vague, suggesting that the authors should be more precise in their critique. However, the claim lacks specific examples or references to support the assertion that the current discussion on limitations is insufficient. Additionally, the comment questions the meaning of \"brittle convergence properties\" without providing context or explanation. This makes the claim 3, as it provides some reasoning but lacks detailed evidence or examples to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides some helpful feedback by suggesting that the authors should delve deeper into the limitations of evolutionary methods, specifically focusing on leveraging state, reactiveness, and learning during an episode. It also advises being honest and direct in their critique, noting that the title is too generic and vague. However, the comment lacks specificity and actionable guidance on how to address these points, such as suggesting particular aspects to explore or examples to include. While it identifies areas for improvement, the feedback could be more detailed and constructive to be fully helpful. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about the synthesis of the focal stack, the forward model of using a defocus map and an image to synthesize a defocused image, and how edges with depth discontinuities are handled. These questions imply that the authors need to provide more detailed explanations or descriptions in their paper. While the questions are explicit, they lack concrete guidance on how to address them, such as specific sections to update or examples to include. The authors can infer that they need to provide additional information, but the lack of detailed instructions makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the synthesis of the focal stack, the forward model, and how edges with depth discontinuities are handled. While it does not explicitly mention specific sections or figures, the authors can infer that these questions pertain to the methodology or results sections. The comment is specific in detailing what aspects need clarification, such as the synthesis process and handling of edges. However, because it does not explicitly mention the sections, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions seeking clarification on specific aspects of the methodology, such as the synthesis of the focal stack, the forward model, and the handling of edges with depth discontinuities. These questions are factual and do not contain subjective claims or opinions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises several important questions about the methodology and implementation of the focal stack synthesis, specifically asking for clarification on the forward model, the handling of edges with depth discontinuities, and the synthesis process. These questions are relevant and could help the authors improve the clarity and comprehensiveness of their paper. However, the comment lacks specific suggestions or guidance on how to address these questions, such as recommending additional explanations or examples. While it identifies areas for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the novelty of the specific components of the approach, such as the weak predictor and sampling strategy, by comparing them to existing methods. It highlights that the weak predictor is not novel, as it consists of MLP, Regression Tree, or Random Forest, which have been used for NAS performance prediction before. Additionally, it notes that the sampling strategy is similar to epsilongreedy and exactly the same as that in BRPNAS. The comment also points out that the results of WeakNAS are almost identical to BRPNAS, as shown in Table 2 in Appendix C. However, the comment does not provide any actionable advice or suggestions for the authors to address these issues or improve their work. It lacks guidance on how the authors might differentiate their approach or enhance its novelty. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific components of the approach, such as the weak predictor and the sampling strategy, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with these components, noting that they are not novel and are similar to existing methods, such as MLP, Regression Tree, or Random Forest, and that the sampling strategy is the same as that in BRPNAS. Additionally, it points out that the results of WeakNAS are almost identical to BRPNAS, as shown in Table 2 in Appendix C. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the specific components of the approach, such as the weak predictor and sampling strategy, are not novel and are similar to existing methods. It supports this claim by referencing previous works 2,3,7 that have used MLP, Regression Tree, or Random Forest for NAS performance prediction and by comparing the sampling strategy to epsilongreedy and BRPNAS. Additionally, it points out that the results of WeakNAS are almost identical to BRPNAS, as shown in Table 2 in Appendix C. This provides a clear and logical basis for the claim, making it 5. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment provides a detailed critique of the specific components of the approach, such as the weak predictor and the sampling strategy, by comparing them to existing methods and highlighting their lack of novelty. It references previous works that have used similar techniques, such as MLP, Regression Tree, or Random Forest, for NAS performance prediction, and notes that the sampling strategy is similar to epsilongreedy and the same as that in BRPNAS. The comment also points out that the results of WeakNAS are almost identical to BRPNAS, as shown in Table 2 in Appendix C. This feedback is valuable as it helps the authors understand the limitations of their approach and the need to differentiate it from existing methods. However, the comment could be more helpful if it offered suggestions on how to enhance the novelty or originality of the approach. Overall, the comment is 4, as it provides clear insights into the weaknesses of the approach but lacks specific guidance for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment raises two points. First, it notes that the paper discusses how KG handles the continuous task setting but lacks experiments with continuous tasks. Second, it questions why entropy methods for conditional optimization derived in Section 7 of the appendix are not included in the experiments and asks for a comparison with ConBO. Both points imply that the authors should include experiments with continuous tasks and consider including the entropy methods in their experiments. However, the comment does not explicitly instruct the authors to do so, leaving the action implicit. Additionally, while the comment suggests a comparison with ConBO, it does not provide specific guidance on how to conduct this comparison. Therefore, the comment is 3, as the authors can infer the need for additional experiments but lack detailed guidance on how to implement them.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 7 in the appendix,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the inclusion of experiments with continuous tasks and a comparison of entropy methods with ConBO. This provides clear guidance on what the authors need to do to improve their draft. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a claim about the lack of experiments with continuous tasks, despite the discussion of how KG handles the continuous task setting. It also questions the absence of entropy methods for conditional optimization derived in Section 7 of the appendix in the experiments and asks for a comparison with ConBO. While the comment highlights a potential gap in the experimental section, it lacks specific examples or references to support the claim. The reasoning is somewhat logical, but the lack of detailed evidence or examples makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered 2, as it provides some basis for the claim but requires more detailed justification.", "helpfulness_rationale": "The review comment identifies two specific areas for improvement in the paper. First, it points out that while the authors discuss how KG handles the continuous task setting, there are no experiments with continuous tasks. This feedback highlights a gap in the experimental section that the authors should address. Second, it questions the absence of entropy methods for conditional optimization derived in Section 7 of the appendix in the experiments and suggests a comparison with ConBO. This provides a clear and actionable suggestion for enhancing the paper by including additional experiments and comparisons. The comment is 4 as it offers specific and constructive feedback that can guide the authors in improving their draft. However, it could be more helpful if it provided more detailed guidance on how to conduct these experiments or comparisons. Therefore, the comment is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the difference between similarity and exit times in the context of unsupervised feature selection from a diffusion perspective. It explicitly requests a more detailed explanation from the authors to understand the difference. This feedback is clear and direct, providing a specific action for the authors to take to improve their draft. The request for a detailed explanation leaves no ambiguity about what the authors need to do, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"unsupervised feature selection from a diffusion perspective,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by questioning the difference between similarity and exit times in nature. The comment requests a more detailed explanation, which provides clear guidance on what the authors need to address. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the difference between similarity and exit times in the context of unsupervised feature selection from a diffusion perspective. It does not contain any subjective claims, opinions, or suggestions that require verification. It is a request for clarification, which is factual and does not necessitate verification. Therefore, the label \"No\" is appropriate.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the difference between similarity and exit times in the context of unsupervised feature selection from a diffusion perspective. It highlights a potential gap in the explanation provided by the authors, which could be addressed by providing a more detailed explanation. This feedback is clear and actionable, as it directs the authors to clarify a critical aspect of their work. However, it could be more helpful if it offered suggestions on how to present this explanation or provided examples to illustrate the difference. Overall, the comment is 4 as it guides the authors toward improving the clarity and comprehensiveness of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point raises questions about the calculation of precision, recall, and F1score for a 4class classification of breast density and suggests reporting AUC results for breast cancer detection. While the comment implies that the authors should provide more detailed information on their methodology and results, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include additional information. However, the comment does provide a concrete suggestion regarding the reporting of AUC results, which could guide the authors in improving their draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"4class classification of breast density\" and \"breast cancer detection,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the calculation of precision, recall, and F1score for the 4class classification and suggests reporting AUC results for breast cancer detection. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the calculation of precision, recall, and F1score for a 4class classification of breast density, and suggests reporting AUC results for breast cancer detection. The comment provides a logical reasoning by pointing out that AUC is a common metric used in breast cancer detection research, which could be more informative for comparisons. However, it does not provide specific examples or references to support why AUC is preferred over other metrics, nor does it explain how the authors might calculate AUC for their specific dataset. This makes the claim 3, as it lacks detailed justification or examples, but the authors can infer the need for additional information. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises important questions about the methodology used to calculate precision, recall, and F1score for a 4class classification of breast density, which is a critical aspect of the paper. It also suggests that reporting AUC results for breast cancer detection would be more informative, providing a specific and actionable suggestion for improvement. By addressing these points, the authors can enhance the clarity and comprehensiveness of their results, making the comment 5. However, the comment could be more helpful if it included examples or references to support the suggestion for AUC reporting, which would further guide the authors in implementing the change. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the novelty of the proposed modification to the transformer, specifically the crosslayer approach, and questions its significance in terms of machine learning insights. It also suggests that the improvements over other methods come from using a naive transformer rather than the proposed modification. While the comment highlights potential issues with the novelty and significance of the work, it does not provide explicit guidance or suggestions for improvement. The authors are left to infer that they might need to clarify the novelty and significance of their approach or address the critique regarding the improvements. However, the lack of concrete advice or specific actions makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 4 and 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the novelty of the proposed modification to the transformer, the limited improvement brought by the selfcross attention, and the main improvements coming from using a naive transformer. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed modification to the transformer, specifically the crosslayer approach, does not bring much insight in the field of machine learning and that the improvements over other methods come from using a naive transformer rather than the proposed modification. The reviewer supports this claim by referencing the ablation study (table 4 and 5), which shows that the selfcross attention brings limited improvement (<1%). However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim about the lack of novelty or significance of the proposed modification. While the reference to the ablation study provides some support, the comment is 3 due to the need for more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a critical evaluation of the novelty and significance of the proposed modification to the transformer, specifically the crosslayer approach. It highlights that while the authors have made a modification, it does not bring much insight in the field of machine learning. The comment also questions the significance of the improvements over other methods, noting that the main improvements come from using a naive transformer rather than the proposed modification. This feedback is 3 as it identifies a potential weakness in the paper\"s contribution and suggests that the authors may need to clarify the novelty and significance of their work. However, the comment could be more helpful if it offered specific suggestions on how to address these issues or provided examples of how to enhance the novelty and significance of the proposed modification. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that the authors should conduct experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE. This feedback provides a clear and direct action for the authors to take, ensuring that they understand what needs to be done to improve their draft. The comment is specific and concrete, as it identifies a particular area for expansion and provides examples of tasks that could be included. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiments\" and \"sentence similarity tasks and open domain QA tasks,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the experiments, namely their limited scope, and suggests conducting experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments are limited because they only cover sentence similarity tasks and open domain QA tasks, suggesting that there are many other tasks involving sentence pairs. The reviewer supports this claim by providing specific examples of sentence inference tasks like MNLI and RTE, which are common in the NLP field. This provides a clear and logical reasoning for the claim, making it 4. However, the comment could be strengthened by referencing additional tasks or studies that support the need for broader experimentation. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a limitation in the experiments, noting that they are limited to sentence similarity tasks and open domain QA tasks. It suggests that the authors should conduct experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE, which are common in the NLP field. This feedback is clear and actionable, providing the authors with a specific direction for expanding their experimental scope. By suggesting additional tasks, the comment offers a concrete way for the authors to enhance the comprehensiveness and relevance of their experiments. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to include the prompt in the appendix or supplement, if it was not already included. This provides a clear and direct action for the authors to take. Additionally, the comment includes minor comments about the abstract and Figure 2, which are not part of the main action but provide additional feedback. Overall, the comment is explicit and provides concrete guidance on what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the appendix or supplement, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the prompt should be included in the appendix or supplement, if it was not already there. The comment is specific in its request for the inclusion of the prompt, which provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the prompt should be included in the appendix or supplement, if it was not already there. This is a request for clarification or inclusion, not a claim that requires verification. The comment does not contain subjective opinions, judgments, or suggestions that would necessitate verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion to include the prompt in the appendix or supplement, if it was not already included. This feedback is valuable as it addresses a potential oversight in the paper and offers a specific action for the authors to take to improve the clarity and completeness of their work. Additionally, the comment includes minor comments about the abstract and Figure 2, which provide additional feedback on areas that could be improved. However, the comment could be more helpful if it explained why the prompt is important or how its inclusion would benefit the paper. Overall, the feedback is 4 as it guides the authors toward a specific improvement, but it could be more comprehensive with additional context or reasoning."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the theoretical proof for convergence, claiming it is trivial due to the noni.i.d. nature of $Z$ and the i.i.d. nature of $X$, which leads to a clear covariance matrix for $Z$. It suggests that previous theorems can be adapted with straightforward modifications, implying that the authors should provide a more substantial proof or discuss the implications of this observation. While the comment identifies an issue with the proof, it does not provide explicit instructions on how to address it or what specific modifications are needed. The action is implicit and somewhat vague, as the authors are left to infer the necessary changes without detailed guidance. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Assumption 4.1\" and \"Modification 1 in Appendix C,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the triviality of the convergence proof due to the noni.i.d. nature of $Z$ and the i.i.d. nature of $X$, which leads to a clear covariance matrix for $Z$. The comment further suggests that previous theorems can be adapted with straightforward modifications, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the theoretical proof for convergence appears trivial due to the noni.i.d. nature of $Z$ and the i.i.d. nature of $X$, which leads to a clear covariance matrix for $Z$. The reviewer supports this claim by referencing \"Modification 1 in Appendix C,\" suggesting that previous theorems can be adapted with straightforward modifications. This provides a logical reasoning and specific reference to support the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the theoretical proof for convergence, suggesting that it appears trivial due to the noni.i.d. nature of $Z$ and the i.i.d. nature of $X$, which leads to a clear covariance matrix for $Z$. The reviewer points out that previous theorems can be adapted with straightforward modifications, implying that the proof lacks substantial novelty and rigor. This feedback is clear and actionable, as it highlights a potential weakness in the paper and suggests a direction for improvement by discussing the implications of this observation. However, the comment could be more helpful if it provided specific suggestions on how to enhance the proof or what additional elements could be included to strengthen its novelty and rigor. Overall, the comment is 4, as it directs the authors to a critical area that requires attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the experimental setup borrowed from a previous study is only semireal, as multinode seed cascades are artificially created by merging singlenode seed cascades. It suggests that this should be clearly mentioned in the paper. This feedback provides a direct and concrete action for the authors to take, which is to clarify the experimental setup in the paper. The comment is explicit and provides clear guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental setup borrowed from 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the experimental setup, noting that it is only semireal due to the artificial creation of multinode seed cascades by merging singlenode seed cascades. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the experimental setup is only semireal because multinode seed cascades are artificially created by merging singlenode seed cascades. This claim is 3 as it provides a logical explanation for why the setup might not be fully realistic. However, the comment lacks specific examples or references to support the claim, which would strengthen the justification. Providing more detailed evidence or examples would enhance the verifiability of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental setup, noting that it is only semireal because multinode seed cascades are artificially created by merging singlenode seed cascades. This feedback is clear and actionable, as it directs the authors to clarify this aspect of their experimental setup in the paper. By addressing this point, the authors can enhance the transparency and realism of their experimental design, which is crucial for the credibility of their findings. However, the comment could be more helpful if it provided suggestions on how to improve the realism of the experimental setup or offered examples of how to present this information more clearly. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a potential contradiction in the paper, noting that it states both that the multienv model has an inevitable performance loss and that it outperforms the singleenv model due to knowledge sharing. The comment explicitly requests clarification on this apparent contradiction. This feedback is clear and direct, providing a specific action for the authors to take\u2014clarify the conflicting statements. The action is explicit and concrete, as it specifies what the authors need to do to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses a potential contradiction in the paper regarding the performance of the multienv model. It explicitly mentions that the model is stated to have an inevitable performance loss and also to outperform the singleenv model due to knowledge sharing. This provides full grounding as it allows the authors to accurately identify the part of the paper being addressed, specifically the sections discussing the performance of the multienv model. The comment is also specific because it clearly identifies the issue of conflicting statements and requests clarification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point identifies a potential contradiction in the paper, noting that it states both that the multienv model has an inevitable performance loss and that it outperforms the singleenv model due to knowledge sharing. The comment highlights this apparent contradiction and requests clarification. However, it does not provide any additional reasoning, examples, or references to support the claim of contradiction. Without further elaboration or evidence, the authors may find it challenging to understand the basis of the contradiction or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential contradiction in the paper regarding the performance of the multienv model. It points out that the model is stated to have an inevitable performance loss and also to outperform the singleenv model due to knowledge sharing. This feedback is clear and actionable, as it prompts the authors to clarify the apparent contradiction in their claims. By addressing this issue, the authors can ensure that their paper is more coherent and accurate. However, the comment could be more helpful if it provided suggestions on how to resolve the contradiction or offered additional context to better understand the issue. Overall, the comment is 4, as it directs the authors to a specific area needing clarification, but it could be more comprehensive with further guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the description of the metrics used in the paper is limited and recommends providing an explanation or citing the metrics. While the comment implies that the authors should either explain the metrics or cite them, it does not specify which metrics need clarification or how to present this information. The action is implicit and somewhat vague, as the authors are left to infer which metrics require attention and how to address the issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the description of metrics used in the paper, suggesting that it is limited and recommending an explanation or citation. However, it does not specify which part of the paper discusses the metrics, making it weakly grounded. The comment is specific in suggesting that an explanation or citation would be beneficial, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the description of the metrics used in the paper is limited and suggests that an explanation or citation would be beneficial. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. The lack of detailed reasoning or evidence makes the claim 2, as it provides some insight but requires more information to be fully actionable.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out that the description of the metrics used in the paper is limited. It suggests that an explanation of the metrics or a citation to them would be beneficial. This feedback is clear and actionable, as it directs the authors to enhance the clarity and context of their metrics, which is crucial for understanding the results and their significance. However, the comment could be more helpful if it provided examples of how to explain or cite the metrics effectively. Overall, the comment is 4 as it guides the authors toward improving the clarity and comprehensiveness of their work."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the meaning of \"learned MASK embedding\" in the SSL pretraining stage of the proposed method. While it identifies a specific area of confusion, it does not provide any explicit or implicit guidance on how the authors should address this issue. The comment lacks actionable details, such as suggesting ways to clarify the terminology or explaining its significance in the context of the paper. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the meaning of \"learned MASK embedding\" in the SSL pretraining stage of the proposed method. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs clarification. The comment is specific in identifying the term \"learned MASK embedding\" as unclear, but it lacks grounding because it does not provide a clear reference to the part of the paper where this term is used. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the meaning of \"learned MASK embedding\" in the SSL pretraining stage of the proposed method. However, it does not provide any supporting evidence, reasoning, or references to justify why this term is unclear or how it could be clarified. Without additional context or explanation, the authors may find it challenging to understand the basis of the comment or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the meaning of \"learned MASK embedding\" in the SSL pretraining stage of the proposed method. This is a clear and actionable feedback that prompts the authors to clarify the terminology used in their work. However, the comment does not provide any suggestions or guidance on how to address this issue, such as recommending alternative phrasing or explaining the concept in more detail. While it highlights a potential area for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is 3, as it points out a specific area for clarification but does not fully support the authors in making the necessary improvements."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the reported results are partially derivative, as they extend to hypernetworks of results already presented in the literature for standard networks. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue or improve their work. The comment lacks actionable details, such as recommending specific changes or improvements to the results or methodology. As a result, the authors are left without a clear understanding of what steps to take to address the concern. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the reported results are partially derivative, as they extend to hypernetworks of results already presented in the literature for standard networks. However, it does not specify which part of the paper this claim pertains to, such as a specific section, table, or figure. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the results are derivative or how they relate to the literature. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the reported results are partially derivative, as they extend to hypernetworks of results already presented in the literature for standard networks. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the reported results are partially derivative, as they extend to hypernetworks of results already presented in the literature for standard networks. However, it does not provide specific examples or references to support this claim, nor does it offer guidance on how the authors might address this issue or differentiate their work from existing literature. Without actionable feedback or suggestions for improvement, the comment lacks depth and does not effectively assist the authors in enhancing their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of specificity in the study\"s scope, suggesting that the work focuses on injecting a CoTbased approach into smallscale Language Models. It implies that additional relevant CoT baselines for incontext learning of Large Language Models, such as text003 and ChatGPT, are missing in Table 2 and 3. While the comment identifies a potential issue, it does not explicitly instruct the authors to include these baselines or specify how to address the lack of specificity in the study\"s scope. The action is implicit and somewhat vague, as the authors need to infer that they should include these baselines and clarify the scope of their study. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2 and 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of missing relevant CoT baselines for incontext learning of Large Language Models, such as text003 and ChatGPT. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the scope of the study is underspecified and suggests that the work focuses on injecting a CoTbased approach into smallscale Language Models. It further implies that additional relevant CoT baselines for incontext learning of Large Language Models, such as text003 and ChatGPT, are missing in Table 2 and 3. However, the comment lacks specific examples or references to support the claim about the missing baselines, making it 3. The authors would need to infer the missing information and potentially conduct additional research to address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the scope of the study, noting that it is underspecified and that the work seems to focus on injecting a CoTbased approach into smallscale Language Models. It suggests that additional relevant CoT baselines for incontext learning of Large Language Models, such as text003 and ChatGPT, are missing in Table 2 and 3. This feedback is clear and actionable, as it directs the authors to clarify the scope of their study and potentially include additional baselines to enhance the comprehensiveness of their analysis. However, the comment could be more helpful if it provided specific guidance on how to incorporate these baselines or what aspects of the study should be expanded to address the issue. Overall, the comment is 4, as it effectively points out a critical area for improvement and provides a clear direction for the authors to enhance their work."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that Figure 3 is difficult to read, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to improve the readability of the figure, such as suggesting ways to enhance the visual clarity or providing specific examples of what needs to be addressed. Without actionable advice or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the difficulty in reading the figure. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a factual statement describing the difficulty in reading Figure 3. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The comment points out a specific issue with Figure 3, noting that it is difficult to read. However, it lacks any actionable feedback or suggestions on how to improve the figure\"s readability. Without guidance on what aspects of the figure are causing the difficulty or how to address it, the authors are left without a clear path to enhance their draft. This makes the comment 3, as it identifies an issue but does not provide actionable advice, leaving the authors with limited guidance on how to improve their work."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the connection between the mentioned fact in the introduction and recent findings regarding the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this question or what steps they should take to clarify the connection. As a result, the authors are left without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction section, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the connection between the mentioned fact and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the connection between a statement in the introduction and recent findings regarding the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. However, it does not provide any supporting evidence, references, or detailed reasoning to substantiate the claim. The lack of specific examples or references makes it difficult for the authors to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the connection between a statement in the introduction and recent findings regarding the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. While it identifies a potential gap in the paper, it does not provide specific guidance or suggestions on how the authors might address this issue or clarify the connection. The comment lacks actionable feedback, leaving the authors with a vague understanding of what needs to be improved. Therefore, it is rated as 2, as it points out a potential area for improvement but does not offer detailed guidance for the authors to follow."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises two concerns: the replacement of a mathematical expression with an arbitrary parameter and the choice of a specific learning rate for SGD. The first concern is explicit, as it directs the authors to clarify the rationale behind the replacement. The second concern is also explicit, as it questions the justification for the learning rate choice. Both points provide clear actions for the authors to take, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper (lines 119121 and line 164), allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies the issues with the replacement of a mathematical expression with an arbitrary parameter and the lack of justification for the learning rate choice. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises two claims: the replacement of a mathematical expression with an arbitrary parameter and the choice of a specific learning rate for SGD. The first claim is supported by referencing specific lines in the paper (lines 119121), which provides a clear basis for the critique. The second claim questions the justification for the learning rate choice, but it does not provide specific reasoning or references to support why the Adam default value is more appropriate. This makes the claim 3, as it highlights a potential issue but lacks detailed justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper. First, it points out the replacement of a mathematical expression with an arbitrary parameter, which could potentially affect the accuracy or interpretation of the results. Second, it questions the choice of a specific learning rate for SGD, noting that it differs from the default value and lacks justification. These critiques are clear and actionable, as they prompt the authors to provide a rationale for these choices or consider alternative approaches. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of how to justify the choices. Overall, the feedback is 4, as it directs the authors to improve the clarity and justification of their methods, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to discuss a previous work, \"Domain Adaptation with AsymmetricallyRelaxed Distribution Alignment,\" and to illustrate the relationship between that work and their proposed method. It also suggests that the authors should explain why their method is better. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is explicit and detailed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about the lack of research focusing on the joint error for UDA, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by referencing a previous work, \"Domain Adaptation with AsymmetricallyRelaxed Distribution Alignment,\" and suggesting that the authors should discuss the relationship between this work and their proposed method. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the authors\" assertion about the lack of research on joint error for UDA is incorrect, as it has been studied in a previous work. The reviewer supports this claim by referencing a specific paper, \"Domain Adaptation with AsymmetricallyRelaxed Distribution Alignment,\" published in ICML2019. This reference provides a clear and specific example to substantiate the claim, making it 5. The reviewer also suggests that the authors should discuss the relationship between their work and the referenced paper, which further strengthens the justification. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a potential issue with the authors\" claim that there is no research focusing on the joint error for UDA, as this problem has already been studied in a previous work. It suggests that the authors should discuss this previous work and directly illustrate the relationship between it and their proposed method, providing a clear and actionable suggestion for improvement. By addressing this point, the authors can enhance the context and relevance of their work, making the comment 5. Therefore, the comment is rated as 5, consistent with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of justification for the need to design a new curriculum learning method for text graphs and points out that the research gap, such as why existing methods cannot be applied, is not discussed. While the comment identifies a gap in the paper, it does not provide explicit guidance on how to address this issue or suggest specific actions for the authors to take. The authors are left to infer that they need to provide a justification for the need for a new method and discuss the limitations of existing approaches. However, the lack of concrete suggestions or detailed guidance makes the action vague and difficult for the authors to implement effectively. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of justification for designing a new curriculum learning method for text graphs and the absence of discussion on why existing methods cannot be applied. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the need for designing a new curriculum learning method for text graphs is not justified and that the research gap, such as why existing methods cannot be applied, is not discussed. However, the comment lacks specific examples or references to existing methods that could be applied or detailed reasoning on why the current methods are insufficient. This makes the claim 3, as it highlights a potential gap but does not provide sufficient evidence or justification to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper regarding the justification for designing a new curriculum learning method for text graphs. It points out that the research gap, such as why existing methods cannot be applied, is not discussed. This feedback is clear and actionable, as it prompts the authors to address the lack of justification and provide a rationale for their approach. However, the comment could be more helpful if it offered specific suggestions on how to fill this gap or what aspects of existing methods might be insufficient. Overall, the comment is 4 as it directs the authors to a critical area needing improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should use powerful pretrained language models like BERT and XLNet as the base encoder for all methods and then compare the efficacy of the transfer parts instead of using ngram features. This comment provides a clear and explicit action for the authors to take, specifying exactly what needs to be done to improve their draft. The suggestion is concrete, as it outlines a specific approach to enhance the paper\"s methodology. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests using powerful pretrained language models like BERT and XLNet as the base encoder for all methods, rather than using ngram features. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the methodology or experimental setup, but the lack of explicit grounding makes it difficult to pinpoint the exact part of the paper being addressed. The comment is specific in suggesting a change in methodology, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point claims that powerful pretrained language models like BERT and XLNet can overcome the domainshift problem to some extent. However, it does not provide any supporting evidence, examples, or references to substantiate this claim. The lack of detailed reasoning or references makes it difficult for the authors to understand the basis of the suggestion or to assess its validity. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests using powerful pretrained language models like BERT and XLNet as the base encoder for all methods, rather than relying on ngram features. This feedback is 3 as it provides a specific suggestion for improving the methodology, which could enhance the paper\"s effectiveness. However, the comment lacks detailed reasoning or examples to support why this change would be beneficial or how it would address the domainshift problem. Additionally, it does not offer guidance on how to implement this change or what specific aspects of the paper might be affected. Therefore, while the suggestion is actionable, the comment could be more helpful with additional context and explanation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the complexity of the proposed method and its relationship to the baselines. It questions whether the performance gain is due to a specific module or simply from having more parameters. The comment suggests that the current ablation study does not provide definitive answers to these questions. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address it. The action is implicit and somewhat vague, as it lacks specific instructions on how to conduct the ablation study or which modules to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the complexity of the proposed method and its relationship to the baselines, specifically questioning whether the performance gain is due to a particular module or simply from having more parameters. However, it does not specify which part of the paper discusses the ablation study or the modules in question, making it weakly grounded. The comment is specific in detailing the issue with the ablation study and the need for clearer answers regarding the performance gain. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the complexity of the proposed method and its relationship to the baselines, questioning whether the performance gain is due to a specific module or simply from having more parameters. The comment highlights the lack of clarity in the current ablation study, which does not provide definitive answers to these questions. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to infer the exact nature of the problem and how to address it. Therefore, the comment is 3, as it provides a basis for the claim but requires further elaboration to be fully supported.", "helpfulness_rationale": "The review comment identifies a critical issue with the proposed method, specifically its complexity and the lack of clarity regarding the source of performance gains. It highlights the need for a more detailed ablation study to determine whether the performance improvement is due to a particular module or simply from having more parameters. This feedback is clear and actionable, as it points out a specific area where the authors can improve their draft by conducting a more thorough analysis. However, the comment could be more helpful if it provided suggestions on how to structure the ablation study or which modules to focus on. Overall, the comment is 4 as it directs the authors to a significant area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment provides a specific suggestion to improve the draft by requesting more explanation for the difference between two quantities and why it captures the difference in learning settings. This feedback is explicit and provides a clear action for the authors to take, which is to provide additional explanation in the manuscript. The comment also includes a subjective opinion about the acceptance of the paper, but this does not affect the actionability of the feedback. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 196197, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the need for more explanation regarding the difference between two quantities and why it captures the difference in learning settings. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a request for clarification regarding the explanation of the difference between two quantities and why it captures the difference in learning settings. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific feedback by pointing out a lack of explanation in the manuscript regarding the difference between two quantities and why it captures the difference in learning settings. This is a clear and actionable suggestion that can help the authors improve the clarity and comprehensibility of their work. However, the comment could be more helpful if it included additional guidance on how to address this issue, such as suggesting specific ways to explain the difference or providing examples of similar explanations in other papers. Despite this, the feedback is 4 as it directs the authors to a specific area needing improvement, offering a clear path for enhancement. Therefore, the comment is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks the authors to discuss the sensitivity of any fixed tuning parameters in the model, both in terms of strengths and weaknesses. This request is clear and provides a direct action for the authors to take, which is to include a discussion on the sensitivity of these parameters. The feedback is specific and concrete, leaving no ambiguity about what the authors need to do to address the comment. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly asks for a discussion on the sensitivity of fixed tuning parameters in the model, both in terms of strengths and weaknesses. This request is specific and provides clear guidance on what the authors should address. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but without explicit references, it is not fully grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point is a request for additional discussion, specifically asking the authors to address the sensitivity of fixed tuning parameters in the model. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification or expansion, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area for improvement by asking the authors to discuss the sensitivity of fixed tuning parameters in their model. This feedback prompts the authors to consider an important aspect of their methodology that may not have been fully explored or discussed in the draft. However, the comment lacks depth and does not provide specific guidance on how to approach this discussion or what aspects to focus on. While it points out a potential area for enhancement, it does not offer detailed suggestions or examples, leaving the authors with a general direction but without comprehensive guidance. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests an interesting extension to the proposed framework by exploring its compatibility with different policy gradient approaches. It also asks for clarification on the number of random seeds used for learning the policies (DDPO and IPPG). While the suggestion to explore different policy gradient approaches is implicit, it provides a clear direction for potential expansion of the work. The question about random seeds is explicit and provides a specific action for the authors to take. Overall, the comment is 4 as it offers a concrete suggestion for further exploration and a direct question for clarification.", "grounding_specificity_rationale": "The comment suggests an interesting extension to the proposed framework by exploring its compatibility with different policy gradient approaches. It also asks for clarification on the number of random seeds used for learning the policies (DDPO and IPPG). However, the comment does not specify which part of the paper this suggestion or question pertains to, making it weakly grounded. The authors can infer that it relates to the experimental section, but without explicit references, it is challenging to pinpoint the exact location. The comment is specific in suggesting an extension and asking for clarification on random seeds, but the lack of grounding limits its effectiveness. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests an interesting extension to the proposed framework by exploring its compatibility with different policy gradient approaches. It also asks for clarification on the number of random seeds used for learning the policies (DDPO and IPPG). However, the comment does not provide any supporting evidence, reasoning, or references to justify why this extension would be beneficial or how it might impact the results. The request for clarification on random seeds is a factual question that does not require verification. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests an interesting extension to the proposed framework by exploring its compatibility with different policy gradient approaches. This feedback provides a clear direction for the authors to consider, offering a potential avenue for expanding the scope of their work. Additionally, the comment includes a specific question about the number of random seeds used for learning the policies (DDPO and IPPG), which is a relevant detail that could impact the reproducibility and robustness of the results. While the comment is actionable and provides valuable insights, it could be more helpful if it offered guidance on how to conduct these experiments or what specific policy gradient approaches to consider. Overall, the comment is 4 as it directs the authors toward a meaningful extension and provides a specific question for clarification."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper\"s results and conclusions would be stronger if the analysis were applied to more datasets and more tasks. This is an explicit suggestion for the authors to expand their analysis to include multiple datasets and tasks. However, the comment does not provide specific guidance on which datasets or tasks to consider or how to implement this expansion. While the action is clear, the lack of concrete details makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper\"s results and conclusions would be stronger if the analysis were applied to more datasets and more tasks. However, it does not specify which part of the paper this critique is based on, such as a particular section or analysis that could be expanded. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in suggesting that the analysis should be applied to more datasets and tasks, but without grounding, it lacks clarity on where these improvements should be made. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper\"s results and conclusions would be stronger if the analysis were applied to more datasets and more tasks. This claim is based on a logical reasoning that broader analysis would provide a more comprehensive understanding of the model\"s performance. However, the comment lacks specific examples or references to support the claim, such as suggesting which additional datasets or tasks could be included. This makes the claim 3, as it provides a logical basis but lacks detailed evidence or examples to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the paper\"s evaluation, noting that it is based on only one dataset and one task. It suggests that the results and conclusions would be stronger if the analysis were applied to more datasets and tasks. This feedback is clear and actionable, as it provides a specific direction for the authors to expand their evaluation to enhance the robustness and generalizability of their findings. However, the comment could be more helpful if it offered suggestions on which additional datasets or tasks might be relevant or provided guidance on how to conduct a broader analysis. Overall, the comment is 4 as it directs the authors to a meaningful area for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the writing could be improved in some places, specifically mentioning a difficulty in interpreting \"definition 2.1\" regarding the \"relevant\" auxiliary model weights. While the comment identifies a potential issue, it does not provide explicit guidance on how to improve the writing or clarify the definition. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the definition but are not given specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"definition 2.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular issue with the interpretation of the \"relevant\" auxiliary model weights, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the writing could be improved, specifically mentioning a difficulty in interpreting \"definition 2.1\" regarding the \"relevant\" auxiliary model weights. However, the comment does not provide any further explanation or reasoning to support why the definition is difficult to interpret or how it could be improved. Without additional context or examples, the claim lacks sufficient justification, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the writing could be improved, pointing out a difficulty in interpreting \"definition 2.1\" regarding the \"relevant\" auxiliary model weights. This feedback is 3 as it directs the authors to a particular section of the paper that needs clarification. However, the comment lacks depth and does not provide specific suggestions or guidance on how to improve the definition or clarify the concept. While it highlights an area for improvement, it does not offer detailed actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper\"s reliance on MIA (Membership Inference Attack) testing as a metric for unlearning effectiveness is not robust enough for privacy guarantees. It recommends using ULiRA 1 instead. While the comment implies that the authors should consider an alternative method for evaluating unlearning effectiveness, it does not provide specific guidance on how to implement this change or why ULiRA is preferable. The action is implicit and somewhat vague, as the authors need to infer the need for a change and determine how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"MIA (Membership Inference Attack) Testing via Ulira,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the robustness of MIA testing for privacy guarantees and recommending the use of ULiRA 1. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper\"s reliance on MIA testing as a metric for unlearning effectiveness is not robust for privacy guarantees. It supports this claim by suggesting that the use of ULiRA 1 is recommended. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim about the robustness of MIA testing. While it provides a suggestion for improvement, the lack of detailed justification makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper\"s reliance on MIA testing as a metric for unlearning effectiveness, questioning its robustness for privacy guarantees. It provides a specific recommendation to use ULiRA 1 as an alternative, which could be a valuable suggestion for the authors to consider. However, the comment could be more helpful if it explained why ULiRA is a better choice or provided more detailed guidance on how to implement this change. Overall, the comment is 4 as it points out a critical area for improvement and offers a potential solution, but it could be more comprehensive with additional context and explanation. Therefore, it aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment raises a question about the applicability of the considerations in the paper to kernel (ridge) regression. It suggests that the paper could also be presented in the \"language of kernel interpolation/smoothing.\" However, the comment does not provide explicit instructions or concrete steps for the authors to follow. The action is implicit and somewhat vague, as it lacks specific guidance on how to incorporate the suggestion or address the question about applicability. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the applicability of the considerations in the paper to kernel (ridge) regression and suggests presenting the paper in the \"language of kernel interpolation/smoothing.\" However, it does not specify which part of the paper this question or suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to consider kernel regression and present the paper in a different context, but without clear grounding, the authors may struggle to identify the exact sections that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the applicability of the paper\"s considerations to kernel (ridge) regression and suggests presenting the paper in the \"language of kernel interpolation/smoothing.\" However, the comment does not provide any supporting evidence, reasoning, or references to justify why this should be the case. It lacks specific examples or detailed explanations that would help the authors understand the basis of the suggestion. As a result, the claim is 1, as it does not provide sufficient information for the authors to address the issue effectively.", "helpfulness_rationale": "The review comment raises a question about the applicability of the paper\"s considerations to kernel (ridge) regression and suggests presenting the paper in the \"language of kernel interpolation/smoothing.\" While it identifies a potential area for expansion or clarification, the comment lacks specificity and does not provide actionable guidance or suggestions for the authors to address this issue. The feedback is somewhat vague and does not offer detailed insights or steps for improvement, making it 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights several issues with the explanations and presentation of the paper, including the lack of detailed procedures and confusing figures. It suggests adding more details to the paper and/or supplementary information to improve clarity. Additionally, it recommends including error bars and pvalues for statistical inferences. While the comment provides explicit actions, such as adding more details and including specific elements like error bars, it does not specify how to implement these changes or provide detailed guidance on what specific information should be added. The actions are concrete but not fully detailed, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig. 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the explanations, noting that they are qualitative and lack detailed procedures or descriptions. The comment suggests adding more details to the paper and/or supplementary information to clarify the simulations. Additionally, it provides specific feedback on the need for error bars and pvalues for statistical inferences. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the explanations are qualitative and lacks detailed procedures, which is supported by the observation that figures are confusing and lack clear descriptions. The reviewer suggests adding more details to the paper and/or supplementary information to improve clarity. This claim is 3 as it provides a logical reasoning for the need for more detailed explanations, but it lacks specific examples or references to support the claim fully. The suggestion to include error bars and pvalues for statistical inferences is also a logical request but could be more robust with examples or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas where the paper could be improved, specifically regarding the qualitative nature of the explanations and the lack of detailed procedures or descriptions in the simulations. It highlights the confusion caused by figures, such as the lack of clarity regarding \"sample count\" in Figure 2. The comment provides actionable feedback by suggesting the addition of more details to the paper and/or supplementary information to enhance clarity. It also recommends including error bars and pvalues for statistical inferences, which would help substantiate the claims made in the paper. This feedback is clear and provides specific guidance on how to improve the draft, making it 4. However, it could be more comprehensive by offering suggestions on how to enhance the explanations or provide examples of detailed procedures. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that some claims in the paper may be inspired by existing studies and suggests that supportive references should be added. It provides a specific example by referencing lines 5564, where it identifies four critical factors affecting chainofthought prompting. The reviewer notes that these factors have been discussed in existing studies, implying that the authors should include references to these studies. While the comment explicitly states the need for references, it does not provide specific guidance on which studies to reference or how to integrate them into the text. The action is explicit but somewhat vague, as the authors know they need to add references but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lines 5564,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what needs to be addressed, namely the need to add supportive references for claims that may be inspired by existing studies. The comment provides a clear example of the factors discussed in the paper that have been covered in existing studies, offering a concrete basis for the authors to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some claims in the paper may be inspired by existing studies and suggests that supportive references should be added. The reviewer provides a specific example by referencing lines 5564, where the paper discusses four critical factors affecting chainofthought prompting. The reviewer notes that these factors have been discussed in existing studies, which provides some support for the claim. However, the comment lacks specific references to these existing studies, making it 3. The authors would need to search for these studies themselves to fully understand and address the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, noting that some claims may be inspired by existing studies and suggesting that supportive references should be added. It provides a specific example by referencing lines 5564, where the paper discusses four critical factors affecting chainofthought prompting. The reviewer points out that these factors have been discussed in existing studies, which is a valuable observation. However, the comment could be more helpful if it included specific references to these existing studies or provided guidance on how to integrate them into the paper. While it highlights an important area for improvement, the feedback lacks depth and actionable suggestions, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm, similar to prior works like Dagger and searn. This feedback provides a clear and explicit action for the authors to take, which is to include these settings in their paper. The comment also explains why this is important, as it would help the community by providing a comprehensive review of the advances in this area. The action is concrete and direct, making the comment 5.", "grounding_specificity_rationale": "The comment suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm, similar to prior works like Dagger and searn. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where these settings could be included. The authors can infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in suggesting what needs to be addressed, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm, similar to prior works like Dagger and searn. This claim is 3 as it provides a logical reasoning for improvement by referencing specific prior works. However, the comment lacks detailed examples or references to these prior works, which would strengthen the justification. The authors would need to infer the specific settings or knobs that should be included, making the claim 3.", "helpfulness_rationale": "The review comment suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm, similar to prior works like Dagger and searn. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their work by including these settings. By doing so, the paper would contribute to a comprehensive review of the advances in this area, benefiting the broader community. However, the comment could be more helpful if it provided examples of how these settings might be presented or suggested specific sections where they could be included. Overall, the comment is 4 as it offers a clear path for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that including \"a few more datasets\" would be appreciated, particularly for evaluating crosstask transferability. However, it does not specify which datasets should be included or how they would contribute to the evaluation of crosstask transferability. The action is implicit and lacks concrete details, making it difficult for the authors to know exactly what changes to make. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that including \"a few more datasets\" would be appreciated, particularly for evaluating crosstask transferability. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or analysis, making it difficult for the authors to identify the exact area needing improvement. Additionally, the comment lacks specificity regarding which datasets should be included or how they would contribute to the evaluation of crosstask transferability. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that including \"a few more datasets\" would be beneficial, particularly for evaluating crosstask transferability. However, the comment does not provide any specific reasoning or examples to support why additional datasets are necessary or how they would enhance the evaluation. Without detailed justification or references, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that including \"a few more datasets\" would be beneficial, particularly for evaluating crosstask transferability. While it identifies a potential area for improvement, the comment lacks specificity and does not provide guidance on which datasets should be included or how they would contribute to the evaluation. Without detailed suggestions or examples, the authors may find it challenging to implement the feedback effectively. Therefore, the comment is 2, as it points out a general area for improvement but does not offer actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the tasks used in the paper are somewhat standard and proposes that the authors could create unique tasks from the dataset to showcase the diversity of images and plots. It specifically mentions that tasks like Question Answering from images could be considered. While the comment implies that the authors should consider creating new tasks, it does not provide explicit instructions on how to do so or what specific tasks to explore. The action is implicit and somewhat vague, as the authors need to infer the need for new tasks and determine how to implement them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the tasks used in the paper are somewhat standard and proposes the creation of unique tasks to showcase the diversity of images and plots. It mentions specific examples, such as Question Answering from images, which could be considered. However, the comment does not explicitly mention which part of the paper discusses the tasks, making it weakly grounded. The authors can infer that it relates to the task description or methodology sections, but this inference is not as direct as it could be. The comment is specific in suggesting unique tasks and providing examples, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the tasks used in the paper are somewhat standard and proposes the creation of unique tasks to showcase the diversity of images and plots. The reviewer provides a specific example of a task that could be considered, such as Question Answering from images. This suggestion is supported by logical reasoning and a clear example, making the claim 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how these unique tasks could be implemented. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper by noting that the tasks used are somewhat standard, such as figure captioning and matching figures to captions. It suggests that the authors could create unique tasks from the dataset to showcase the diversity of images and plots, providing a specific example of a task like Question Answering from images. This feedback is clear and actionable, as it offers a concrete suggestion for enhancing the paper by introducing more diverse and innovative tasks. However, the comment could be more helpful if it provided additional guidance on how to develop these unique tasks or what specific aspects of the dataset could be leveraged. Overall, the comment is 4 as it directs the authors toward a meaningful improvement in their work."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights several issues with the MMD DRO method, specifically noting the lack of a tractable exact equivalent reformulation and the crudeness of the upper bound provided in Theorem 3.1. It also points out that the nonnegative constraint on the distribution is dropped, requiring further approximation even for a simple kernel ridge regression problem. Additionally, the comment suggests that assuming the loss function belongs to the RKHS is restrictive. While the comment identifies several areas of concern, it does not provide explicit guidance or suggestions on how the authors might address these issues. The actions are implicit and somewhat vague, as the authors are left to infer what changes might be necessary without concrete steps or examples. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"MMD DRO,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the tractability of the exact equivalent reformulation, the crudeness of the upper bound provided in Theorem 3.1, and the need for further approximation even for a simple kernel ridge regression problem. Additionally, it points out the restrictive assumption of the loss function belonging to the RKHS. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point claims that MMD DRO lacks a tractable exact equivalent reformulation, which is a severe drawback. It supports this claim by pointing out the crudeness of the upper bound provided in Theorem 3.1, which drops the nonnegative constraint on the distribution and requires further approximation even for a simple kernel ridge regression problem. Additionally, it mentions the restrictive assumption that the loss function belongs to the RKHS, as already noted by the authors. While the comment provides some reasoning and references to specific issues, it lacks detailed examples or references to fully substantiate the claim. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed evidence or examples to be fully convincing.", "helpfulness_rationale": "The review comment identifies several critical issues with the MMD DRO method, specifically noting the lack of a tractable exact equivalent reformulation, the crudeness of the upper bound provided in Theorem 3.1, and the need for further approximation even for a simple kernel ridge regression problem. It also points out the restrictive assumption that the loss function belongs to the RKHS, as already noted by the authors. While the comment highlights important weaknesses, it does not provide specific suggestions or guidance on how the authors might address these issues or improve their work. The feedback is 3 as it identifies areas for improvement, but it lacks actionable advice, making it difficult for the authors to effectively respond to the critique. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the relevance of the framework in relation to nonconvex losses and nonnorm type defenses. It asks whether the nonvanishing duality gap and the difficulty of maximization over nonnorm type constraints make the algorithm irrelevant or if it could still provide insights into the risk upperbound. Additionally, it poses a question about using the covariance or other statistics to design a better defense if the true mean is known through an oracle. While the comment raises important questions, it does not provide explicit instructions or concrete suggestions for the authors to address these concerns. The actions are implicit and somewhat vague, as the authors need to infer what steps to take to address the questions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"p.3, binary classification,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the relevance of the framework in relation to nonconvex losses and nonnorm type defenses, and it asks whether the nonvanishing duality gap and the difficulty of maximization over nonnorm type constraints make the algorithm irrelevant. Additionally, it poses a question about using the covariance or other statistics to design a better defense if the true mean is known through an oracle. This level of detail provides clear guidance on what aspects of the paper need further exploration or clarification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a series of questions and requests for clarification, such as the relevance of the framework to nonconvex losses and nonnorm type defenses, and whether the nonvanishing duality gap and difficulty of maximization over nonnorm type constraints make the algorithm irrelevant. It also asks about the potential use of covariance or other statistics to design a better defense if the true mean is known through an oracle. These questions are not claims or opinions but rather requests for clarification or additional information. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises several questions and points of interest regarding the relevance of the framework in relation to nonconvex losses and nonnorm type defenses. It asks whether the nonvanishing duality gap and the difficulty of maximization over nonnorm type constraints make the algorithm irrelevant or if it could still provide insights into the risk upperbound. Additionally, it poses a question about using the covariance or other statistics to design a better defense if the true mean is known through an oracle. While the comment identifies important areas for further exploration and clarification, it lacks specific suggestions or guidance on how the authors might address these questions or improve their draft. The feedback is 3 as it prompts the authors to consider these aspects, but it could be more actionable with additional direction or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the baselines in Figure 3, suggesting that the trained models could be sparsified to reduce the number of selected features and compare accuracy to the proposed model. While the comment implies that the authors should consider this approach, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement the suggestion or what specific features to consider. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a particular experiment to conduct, which is to sparsify the trained models and compare accuracy to the proposed model. This provides clear guidance on what the authors could do to improve their draft. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the baselines in Figure 3. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the baselines in Figure 3, suggesting that the trained models could be sparsified to reduce the number of selected features and compare accuracy to the proposed model. This is a 3 comment as it prompts the authors to consider an additional experiment or analysis that could enhance the paper. However, it lacks specific guidance or suggestions on how to implement this idea or what specific features to consider. While it provides a direction for improvement, it does not offer detailed actionable steps, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the Appendix H section should be reorganized because it is difficult to follow. However, it does not provide any specific guidance on how to reorganize the section or what changes should be made to improve its clarity. The action is explicit in terms of the need for reorganization, but it lacks concrete details on how to implement this change. As a result, the comment is 3, as the authors know they need to reorganize the section but may struggle to determine the exact steps to take.", "grounding_specificity_rationale": "The comment suggests that the Appendix H section should be reorganized because it is difficult to follow. However, it does not specify which part of the section is problematic or what specific issues need to be addressed for reorganization. This lack of detail makes it difficult for the authors to pinpoint the exact areas that need improvement. Additionally, the comment does not provide any context or examples to support the claim that the section is difficult to follow. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the Appendix H section should be reorganized because it is difficult to follow. However, the comment does not provide any specific reasoning, examples, or evidence to support why the section is challenging to follow. Without additional context or explanation, the authors may find it difficult to understand the basis of the claim and make necessary improvements. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the Appendix H section, noting that it is difficult to follow. However, it lacks detailed guidance or suggestions on how to reorganize the section to improve its clarity. Without actionable advice or examples, the authors are left with a general idea of what needs to be addressed but without a clear path to improvement. This makes the comment 3, as it points out a problem but does not provide sufficient direction for the authors to effectively address it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the paper is not written to be reproduced, even with the pseudocode provided in the supplementary material. It suggests that more details are needed, such as those related to the RNN implementation (e.g., number of units) and other technical details. While the comment identifies the issue and provides a general direction for improvement, it does not specify which specific details are missing or how the authors should address these gaps. The action is explicit but somewhat vague, as it lacks concrete guidance on how to implement the suggested improvements. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of the paper not being written to be reproduced, even with the pseudocode provided in the supplementary material. It suggests that more details are needed, such as those related to the RNN implementation and other technical details. However, the comment does not specify which part of the paper this issue pertains to, making it weakly grounded. The authors can infer that it relates to the methodology or experimental sections, but without explicit references, it is challenging to pinpoint the exact location. The comment is specific in detailing what is missing, such as details about the RNN implementation, but lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is not written to be reproduced, even with the pseudocode provided in the supplementary material. The reviewer suggests that more details are needed, such as those related to the RNN implementation and other technical details. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact areas that need improvement. The lack of detailed justification or evidence makes the claim 3, as it provides a general direction but requires more specific guidance to be fully actionable. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that it is not written to be reproduced, even with the pseudocode provided in the supplementary material. It points out that the paper is written to provide an intuitive understanding of the work but lacks the necessary details for actual reproduction. The comment specifies areas that need more detail, such as the RNN implementation and other technical details. This feedback is clear and actionable, as it provides the authors with a specific direction for improvement by highlighting what is missing in the paper. However, it could be more helpful if it offered suggestions on how to address these gaps or provided examples of what additional details might be needed. Overall, the comment is 4 as it effectively guides the authors toward improving the reproducibility of their work."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment raises a question about the model\"s ability to generate novel knowledge or testable hypotheses regarding neuron data. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or what specific steps should be taken to clarify the model\"s capabilities. Without actionable suggestions or a clear direction for improvement, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the model\"s ability to generate novel knowledge or testable hypotheses regarding neuron data. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs clarification. The comment lacks specificity as it does not provide details on what aspects of the model or methodology are unclear or how the authors might address this issue. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the model\"s ability to generate novel knowledge or testable hypotheses regarding neuron data. However, it does not provide any supporting evidence, reasoning, or examples to justify why this question is relevant or how it relates to the paper\"s content. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the model\"s ability to generate novel knowledge or testable hypotheses regarding neuron data. While it identifies a potential area of concern, it lacks specificity and does not provide any actionable suggestions or guidance for the authors to address this issue. The comment does not offer insights into how the authors might clarify or demonstrate the model\"s capabilities, leaving the authors without a clear path for improvement. As a result, the feedback is 2, as it points out a potential weakness but does not offer meaningful direction for enhancement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the keypoint mask averaged feature vector and whether it is obtained by multiplying each feature map elementwise by H_psi. This comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the question or improve the clarity of the section. As a result, the authors are left without any actionable steps to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"KeyQN section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the method used to obtain the keypoint mask averaged feature vector, asking whether it is obtained by multiplying each feature map elementwise by H_psi. This provides clear guidance on what aspect of the paper needs clarification. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the method used to obtain the keypoint mask averaged feature vector. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the method used to obtain the keypoint mask averaged feature vector, specifically asking whether it is obtained by multiplying each feature map elementwise by H_psi. While this question identifies a potential area of confusion or lack of clarity in the paper, it does not provide any actionable feedback or suggestions for improvement. The comment lacks depth and does not offer guidance on how the authors might clarify or improve this aspect of their work. As a result, the comment is 2, as it points out a potential issue but does not assist the authors in addressing it effectively."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the central contribution of the paper, specifically the use of ODEs to model weight evolution. It suggests that the paper does not provide a convincing analytical argument or empirical evidence to support the claim that neural ODEs exhibit inaccuracy when recomputing activations. While the comment implies that the authors should provide such evidence, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to address the issue of inaccuracy in neural ODEs. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the central contribution of the paper, which is modeling weight evolution using ODEs. It mentions a specific issue with neural ODEs, namely their inaccuracy when recomputing activations, and suggests that this problem was first reported in a previous paper. However, the comment does not specify which part of the paper discusses this issue or where the authors should address it. While it provides some context, it lacks full grounding as it does not explicitly mention a section or figure. The comment is specific in detailing the issue with neural ODEs and the need for analytical arguments or empirical evidence. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper does not provide a convincing analytical argument or empirical evidence to support the central contribution of modeling weight evolution using ODEs. The reviewer suggests that a previous paper first reported the issue of neural ODEs exhibiting inaccuracy when recomputing activations. However, the comment does not provide a reference to this previous paper, making it difficult for the authors to verify the claim. The lack of specific evidence or references leaves the claim 3, as the authors would need to investigate further to fully understand the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper\"s central contribution, which is the use of ODEs to model weight evolution. It points out that the paper does not provide a convincing analytical argument or empirical evidence to support the claim that neural ODEs exhibit inaccuracy when recomputing activations. This is an important observation that highlights a potential weakness in the paper\"s claims. However, the comment could be more helpful if it provided specific suggestions on how the authors might address this issue or what evidence could be included to strengthen their argument. Despite this, the comment is 3 as it directs the authors\" attention to a significant gap in their work that needs to be addressed. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that proving lower bounds for round complexity is a significant part of the work involved in proving results for batched ranking problems. It notes that the paper exploits an easy reduction from the problem of collaborative ranking, which makes the lower bound results follow as an easy corollary of the collaborative ranking results. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this observation or improve their draft. Without actionable suggestions or questions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the major chunk of work involved in proving results for batched ranking problems, specifically the lower bounds for round complexity. It mentions that the paper exploits an easy reduction from the problem of collaborative ranking, which makes the lower bound results follow as an easy corollary. However, the comment does not specify which part of the paper discusses these aspects, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but without explicit references, it is challenging to pinpoint the exact location. The comment is specific in detailing the issue with the lower bounds and their relation to collaborative ranking, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that proving lower bounds for round complexity is a significant part of the work involved in proving results for batched ranking problems. It further states that the paper exploits an easy reduction from the problem of collaborative ranking, which makes the lower bound results follow as an easy corollary of these collaborative ranking results. However, the comment lacks specific examples, references, or detailed reasoning to support the claim about the ease of the reduction or the implications of the lower bound results. Without these details, the authors may find it challenging to fully understand and address the critique. Therefore, the comment is considered 2, as it provides some justification but lacks sufficient evidence or explanation.", "helpfulness_rationale": "The review comment identifies a significant aspect of the paper\"s work, namely the lower bounds for round complexity in batched ranking problems. It notes that the paper exploits an easy reduction from the problem of collaborative ranking, which makes the lower bound results follow as an easy corollary. While the comment highlights an important aspect of the paper, it lacks specific suggestions or guidance on how the authors might address this observation or improve their draft. Without actionable feedback or detailed insights, the authors are left with a general understanding of the issue but without a clear path to improvement. Therefore, the comment is 3, as it provides some insight but lacks depth and specificity."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the prompting technique used in the study is basic and suggests that carefully curated prompts could lead to better results. However, it does not provide specific guidance on how to curate these prompts or what aspects of the current technique need improvement. The action is implicit and somewhat vague, as the authors are left to infer that they should explore more advanced prompting techniques but without concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment critiques the prompting technique used in the study, suggesting that it is basic and does not fully leverage the potential of LLMs. It implies that carefully curated prompts could lead to better results in generating systematic reviews. However, the comment does not specify which part of the paper discusses the prompting technique, making it weakly grounded. Additionally, while it provides a general suggestion for improvement, it lacks specificity in terms of what aspects of the prompting technique need to be addressed or how to curate better prompts. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the prompting technique used in the study is basic and does not fully leverage the potential of LLMs. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. The lack of evidence or detailed justification makes it difficult for the authors to understand and address the critique effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the study by pointing out that the prompting technique used is basic and may not fully leverage the potential of LLMs. It suggests that carefully curated prompts could lead to better results in generating systematic reviews. However, the comment lacks specificity and does not provide detailed guidance or examples on how to curate these prompts or what aspects of the current technique need improvement. While it highlights an area for potential enhancement, the feedback is somewhat vague and incomplete, making it 3 for the authors to consider but not fully actionable. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the performance of Table 4, noting that it is behind more recent models. It provides examples of models, GLaMM and UNINEXT, that have achieved better results on specific metrics. However, the comment does not explicitly instruct the authors to improve their results or suggest ways to address this issue. The action is implicit, as the authors can infer that they need to improve their performance, but it lacks concrete guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the performance of the model, noting that it is behind more recent models and provides examples of models that have achieved better results. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance in Table 4 is behind more recent models, specifically mentioning GLaMM and UNINEXT as examples. This claim is supported by providing specific metrics and results from these models, which helps verify the assertion. However, the comment could be strengthened by including more detailed comparisons or references to other relevant works. Overall, the claim is 4, as it provides sufficient evidence to support the assertion but lacks comprehensive references or additional context. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the performance of the model, as evidenced by the results in Table 4. It highlights that the performance on REC and RES is behind more recent models, such as GLaMM and UNINEXT, which have achieved better results on specific metrics. This feedback is clear and actionable, as it provides the authors with a direct comparison to recent models, allowing them to assess their own performance and potentially identify areas for improvement. However, the comment could be more helpful if it included suggestions on how to address this issue or provided additional context or references to guide the authors in making improvements. Overall, the comment is 4, as it effectively points out a weakness and offers a starting point for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the term \"evidence\" may be too strong in the context of the statement about Fig. 5, and proposes an alternative phrasing. However, it does not provide explicit guidance on how to revise the statement or what specific changes should be made. The action is implicit and somewhat vague, as the authors are left to infer that they should modify the wording but are not given concrete instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper is being addressed, such as a specific section, figure, or table. It also lacks specificity because it does not provide details on what aspect of the evidence is considered too strong or what the alternative phrasing should be. Without clear references or detailed feedback, the authors cannot effectively address the issue. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the term \"evidence\" may be too strong in the context of Fig. 5, proposing an alternative phrasing. However, the comment does not provide any reasoning or evidence to support why the original phrasing is too strong or how the alternative phrasing would be more appropriate. Without additional context or justification, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The comment suggests that the term \"evidence\" may be too strong in the context of Fig. 5, proposing an alternative phrasing. While this feedback identifies a potential issue with the language used, it lacks depth and does not provide specific guidance on how to improve the phrasing or what alternative wording might be more appropriate. The comment is 3 as it points out a minor issue, but it does not offer actionable advice or detailed suggestions for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a perceived limitation in the novelty of the proposed video storyboarding approach, specifically noting that the primary method relies on framewise SDSA, which mirrors the approach used in ConsiStory. The only notable difference is the use of CLIPseg and OTSU segmentation as mask sources instead of crossattention. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this limitation or enhance the novelty of their approach. The action is implicit and vague, as the authors are left to infer that they should explore ways to differentiate their method from existing approaches or provide additional justification for the novelty of their work. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the novelty of the proposed video storyboarding approach, specifically mentioning the reliance on framewise SDSA, which mirrors the approach used in ConsiStory. It also notes the use of CLIPseg and OTSU segmentation as mask sources instead of crossattention. However, the comment does not specify which part of the paper discusses these methods or their comparison to ConsiStory, making it weakly grounded. The comment is specific in detailing the limitations of novelty, but without clear grounding, the authors may struggle to identify the exact sections needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the novelty of the proposed video storyboarding approach is limited, specifically noting that the primary method relies on framewise SDSA, which mirrors the approach used in ConsiStory. The only notable difference is the use of CLIPseg and OTSU segmentation as mask sources instead of crossattention. While the comment provides some reasoning by comparing the approach to ConsiStory, it lacks specific examples or detailed analysis to fully substantiate the claim. The reference to ConsiStory is a starting point, but more detailed comparison or evidence would strengthen the argument. Therefore, the comment is 3, as it provides a basis for the claim but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential limitation in the novelty of the proposed video storyboarding approach, specifically noting that the primary method relies on framewise SDSA, which mirrors the approach used in ConsiStory. The comment highlights the use of CLIPseg and OTSU segmentation as mask sources as a minor difference compared to crossattention. While the comment points out a specific area for improvement, it lacks actionable suggestions or guidance on how the authors might enhance the novelty of their approach or differentiate it from existing methods. The feedback is 3 as it prompts the authors to consider the uniqueness of their work, but it could be more beneficial with additional direction or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the method\"s weakness would be more prominent in images with multiple objects or cluttered scenes. It implies that the authors should consider comparing their approach to previous methods on a dataset with such images. However, the comment does not explicitly instruct the authors to conduct this comparison or provide specific guidance on how to implement it. The action is implicit and somewhat vague, as the authors can infer the need for comparison but are not given detailed instructions on how to execute it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the method\"s weakness would be more prominent in images with multiple objects or cluttered scenes. It implies that the authors should consider comparing their approach to previous methods on a dataset with such images. However, the comment does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. Additionally, it lacks specificity regarding what aspects of the method should be compared or how the comparison should be conducted. As a result, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the method\"s weakness would be more prominent in images with multiple objects or cluttered scenes. It proposes a comparison with previous methods on a dataset with such images, which would be interesting. However, the comment lacks specific examples or references to previous works that have addressed this issue, making it difficult for the authors to fully understand the basis of the suggestion. The claim is 3 as it provides a logical reasoning for the comparison but lacks detailed evidence or references to support it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the method\"s applicability to images with multiple objects or cluttered scenes. It suggests that a comparison with previous methods on such datasets would be interesting, providing a clear direction for the authors to explore. However, the comment lacks specific guidance on how to conduct this comparison or what aspects to focus on, which limits its helpfulness. While it highlights an area for improvement, it does not offer detailed suggestions or actionable steps, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the proposed method achieves only a modest improvement over baselines, particularly on a small backbone like ResNet50. It suggests that the method might struggle on larger backbone models like SwinB or SwinL due to the introduction of global pooling. While the comment implies that the authors should test their method on larger models, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the issue or what specific tests to conduct. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed method\" and the \"relative gains\" achieved on different frameworks and tasks, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the proposed method only achieves a modest improvement over baselines, particularly on a small backbone like ResNet50. The comment further suggests that the method might struggle on larger backbone models like SwinB or SwinL due to the introduction of global pooling. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method achieves only modest improvements over baselines, particularly on a small backbone like ResNet50. It suggests that the method might struggle on larger backbone models due to the introduction of global pooling. The comment provides a logical reasoning by pointing out the potential limitations of the method on larger models, which is a reasonable inference based on the described characteristics. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to further explore and substantiate the claim themselves to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation in the proposed method, noting that the relative gains are not very strong, especially on a small backbone like ResNet50. It suggests that the method might struggle on larger backbone models due to the introduction of global pooling, which could limit its effectiveness on larger receptive fields. This feedback is 3 as it points out a specific area for improvement and provides a logical reasoning for why the method might not perform as well on larger models. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of alternative approaches that could be considered. Overall, the comment is 3, as it prompts the authors to consider the scalability of their method and its potential limitations."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the analysis of neural networks, suggesting that it contributes less and that the extension from linear models to wide fullyconnected neural networks is trivial. It also claims that the work bypasses the core problem of overparametrized neural networks. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address these critiques or improve their analysis. Without actionable suggestions or a clear direction for revision, the authors are left without a path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions sections 3.2 and 3.3, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the critique that the analysis of neural networks contributes less and that the extension from linear models to wide fullyconnected neural networks is trivial. The comment further specifies that the work bypasses the core problem of overparametrized neural networks by only considering easy wide fullyconnected neural networks. This level of detail provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of neural networks contributes less and that the extension from linear models to wide fullyconnected neural networks is trivial. It also suggests that the work bypasses the core problem of overparametrized neural networks by only considering easy wide fullyconnected neural networks. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. The lack of evidence or detailed justification makes it difficult for the authors to understand and address the critique effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment critiques the analysis of neural networks, suggesting that it contributes less and that the extension from linear models to wide fullyconnected neural networks is trivial. It also claims that the work bypasses the core problem of overparametrized neural networks by only considering easy wide fullyconnected neural networks. While the comment identifies a potential weakness in the analysis, it lacks specific suggestions or guidance on how the authors might address these issues or improve their work. The feedback is 3 as it points out a critical area for improvement, but it does not provide actionable steps or detailed advice, leaving the authors with a general understanding of what needs to be addressed. Therefore, the comment is rated as 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides a specific suggestion to include a reference to a relevant paper, \"Assessing Fire Safety using Complex Numerical Models with a Bayesian Multifidelity Approach (Stroh et al. 2017),\" which could help the authors contextualize their work. However, the comment also points out a potential inconsistency in the abstract and introduction regarding the term \"relatively inexpensive,\" which is not actionable advice. The suggestion to include a reference is explicit and concrete, while the critique of the abstract and introduction is vague and lacks guidance on how to address it. Therefore, the comment is 4, as it provides a clear action but also includes a less actionable aspect.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the multifidelity framework and sequential design for learning quantities (e.g. probabilities of threshold exceedance),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out a potential inconsistency in the abstract and introduction regarding the term \"relatively inexpensive.\" Additionally, it provides a reference to a relevant paper, \"Assessing Fire Safety using Complex Numerical Models with a Bayesian Multifidelity Approach (Stroh et al. 2017),\" which could help the authors contextualize their work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts: a suggestion to include a reference to a relevant paper and a critique of the abstract and introduction regarding the term \"relatively inexpensive.\" The suggestion to include a reference is supported by a specific citation, which provides a clear basis for the claim. However, the critique of the abstract and introduction lacks specific examples or detailed reasoning to support the claim of inconsistency. This makes the comment 3, as the authors would need to further explore the issue to fully understand and address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion to include a reference to a relevant paper, \"Assessing Fire Safety using Complex Numerical Models with a Bayesian Multifidelity Approach (Stroh et al. 2017),\" which could help the authors contextualize their work within the existing literature. This is a valuable piece of feedback that can guide the authors in enhancing the depth and relevance of their paper. Additionally, the comment points out a potential inconsistency in the abstract and introduction regarding the term \"relatively inexpensive,\" which could be confusing for readers. However, the comment does not offer specific guidance on how to address this inconsistency or improve the clarity of the text. While the suggestion to include a reference is actionable, the critique of the abstract and introduction is less so. Overall, the comment is 4, as it provides a clear suggestion for improvement but could be more comprehensive in addressing the identified issues."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the curated AH36M dataset is used for training and, if so, whether other methods like HMR and SPIN had access to this data during training for a fair comparison. While the comment implies that the authors should clarify this aspect, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the use of the curated AH36M dataset for training and whether other methods like HMR and SPIN had access to this data during training for a fair comparison. However, it does not specify which part of the paper this issue is addressed in, making it weakly grounded. The comment is specific in its inquiry about the use of the dataset and the fairness of comparisons, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper being discussed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the use of the curated AH36M dataset for training and whether other methods had access to this data during training for a fair comparison. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is a concern or how it affects the fairness of the comparison. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises an important question about the use of the curated AH36M dataset for training and whether other methods like HMR and SPIN had access to this data during training for a fair comparison. This is a relevant concern that could impact the validity of the experimental results and comparisons made in the paper. However, the comment lacks specificity and does not provide detailed guidance on how the authors might address this issue or what steps they should take to ensure a fair comparison. While it identifies a potential area for improvement, the feedback could be more actionable and helpful by suggesting specific ways to clarify or address the issue. Therefore, the comment is 3, as it provides some insight but lacks depth and actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to compare their results on the official COOC leader board on the blind test set, referencing a specific link to the competition results. It also suggests comparing to other approaches that have been proposed since the paper was published, mentioning specific examples of approaches that have won the challenge. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The explicit nature of the instructions and the specific examples make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"captioning experiment\" and the \"official COOC leader board on the blind test set,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the comparison of results on the official test set and the inclusion of comparisons to other approaches that have been proposed since the paper was published. This provides clear guidance on how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper should compare its results on the official COOC leader board on the blind test set, citing specific examples of approaches that have won the challenge and been evaluated on the blind challenge set. The reviewer provides a link to the competition results, which supports the claim by offering a clear reference for the authors to follow. This level of detail and specific references make the claim 5, as it provides a clear path for the authors to address the feedback. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment provides clear and actionable feedback by pointing out a specific issue with the paper\"s comparison to related work. It highlights that the paper only compares results on a not official test set or dev set, rather than the official COOC leader board on the blind test set. The reviewer suggests that the authors should compare their results on the official test set, referencing specific examples of approaches that have won the challenge and been evaluated on the blind challenge set. Additionally, the comment encourages the authors to compare their work to other approaches that have been proposed since the paper was published, suggesting that these newer approaches have significantly improved. This feedback is detailed and provides concrete steps for the authors to take to improve the validity and comprehensiveness of their comparisons. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the reliability of the experimental results, specifically in Table 1 where the MSE is significantly smaller than the MAE. However, it does not provide any explicit or implicit guidance on how the authors should address this issue or improve the reliability of their results. There is no suggestion for further analysis, correction, or clarification. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the experimental results, namely the concern about the validity of the results due to the significant difference between the MSE and MAE. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental results are unreliable, specifically in Table 1 where the MSE is significantly smaller than the MAE. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this discrepancy raises concerns about the validity of the results. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental results, noting that the MSE is significantly smaller than the MAE in Table 1, which raises concerns about the validity of the results. This is a clear and actionable feedback that highlights a potential problem with the experimental methodology or analysis. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the reliability of their results. While it points out a critical area for improvement, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point claims that the proposed meta algorithm is a direct extension of existing methods, suggesting that there is not much novelty in the methodology. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the lack of novelty or improve the methodology, nor are there suggestions for potential modifications or enhancements. As a result, the comment lacks any actionable advice, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the novelty of the methodology, specifically mentioning that the proposed meta algorithm is a direct extension of existing methods. However, it does not specify which part of the paper this critique pertains to, such as a particular section or methodology description. Without explicit references, the authors may find it challenging to pinpoint the exact areas needing revision. The comment is specific in its critique of the lack of novelty but lacks grounding, as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed meta algorithm is a direct extension of existing methods, suggesting a lack of novelty. However, the comment does not provide specific examples or references to existing methods that the proposed algorithm is based on, making it difficult for the authors to understand the basis of the claim. Without detailed evidence or examples, the claim remains vague and lacks sufficient justification, rendering it barely verifiable. Therefore, the comment is classified as 2.", "helpfulness_rationale": "The review comment points out a lack of novelty in the methodology, specifically noting that the proposed meta algorithm is a direct extension of existing methods. While this feedback identifies a potential weakness in the paper, it lacks actionable suggestions or guidance on how the authors might address this issue or enhance the novelty of their approach. Without specific advice or examples, the comment provides limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly questions the meaning of \"wrong\" at line 248 and suggests clarifying the concepts of good, bad, and wrong explanations before using them. This provides a clear and direct action for the authors to take, which is to clarify the terminology used in the paper. The comment is explicit and provides concrete guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions line 248, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the meaning of \"wrong\" and suggests clarifying the concepts of good, bad, and wrong explanations before using them. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the meaning of \"wrong\" at line 248 and suggests clarifying the concepts of good, bad, and wrong explanations. The comment does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment identifies a specific point in the paper where the term \"wrong\" is used without clarification, suggesting that the authors should clarify the meaning of good, bad, and wrong explanations before using these concepts. This feedback is clear and actionable, as it directs the authors to address a potential ambiguity in their work. By providing this guidance, the comment helps the authors improve the clarity and precision of their draft. However, it could be more helpful if it offered suggestions on how to clarify these concepts or provided examples of what constitutes a good or bad explanation. Overall, the comment is 4, as it effectively points out a specific area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the clarity of the concept of \"state\" and suggests that it represents the grid status (e.g., agent position) and is obtained after applying an action of the trace. It also questions whether \"elements\" in lines 186187 are equivalent to \"states\" or \"actions.\" The comment implies that the authors should provide more elaboration on this concept. While the action is implicit, it is concrete because it specifies what needs to be clarified and where in the text it should be addressed. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 186line 187,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the equivalence of \"elements\" to \"states\" or \"actions,\" which provides clear guidance on what needs to be clarified. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of the concept of \"state\" and suggests that it represents the grid status (e.g., agent position) and is obtained after applying an action of the trace. The reviewer questions whether \"elements\" in lines 186187 are equivalent to \"states\" or \"actions.\" This comment is 3 as it identifies a potential confusion in the paper and provides a specific line reference for clarification. However, it lacks detailed reasoning or examples to fully substantiate the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the concept of \"state\" in the paper. It questions whether \"elements\" in lines 186187 are equivalent to \"states\" or \"actions,\" suggesting that more elaboration is needed to clarify this concept. This feedback is clear and actionable, as it directs the authors to address a particular point of ambiguity in their draft. By providing a specific line reference, the comment offers a concrete starting point for improvement. However, it could be more helpful if it included suggestions on how to clarify the concept or examples of how to better explain it. Overall, the comment is 4, as it effectively guides the authors toward improving the clarity and comprehensibility of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a specific observation regarding the performance of the generator in Section 5.3, noting that a generator equipped with a standard RGCN as a discriminator tends to collapse after a certain number of iterations. The reviewer suggests that the reason behind this difference is essential to understand the mechanism by which the proposed method differs from previous ones. However, the comment points out that this explanation is missing from the current submission. The reviewer explicitly requests that the authors include an explanation for why the proposed module prevents the generator from collapsing. This feedback is clear and provides a concrete action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec 5.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the observation about the generator collapsing and requests an explanation for why the proposed module prevents this collapse. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed module prevents the generator from collapsing, while the standard RGCN as a discriminator tends to cause collapse. The reviewer suggests that understanding the reason behind this difference is essential to demonstrate the mechanism by which the proposed method differs from previous ones. However, the comment does not provide specific evidence, examples, or references to support this claim. The lack of detailed reasoning or references makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered 2, as it provides a logical basis for the claim but lacks sufficient evidence or examples to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a specific observation regarding the performance of the generator in Section 5.3, noting that a generator equipped with a standard RGCN as a discriminator tends to collapse after a certain number of iterations, while the proposed module does not. The reviewer suggests that understanding the reason behind this difference is crucial to demonstrate the mechanism by which the proposed method differs from previous ones. However, the comment points out that this explanation is missing from the current submission. By highlighting this gap and requesting an explanation, the comment provides clear and actionable feedback that can help the authors improve their draft. The suggestion is specific and offers a clear direction for enhancing the paper, making it 4. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a lack of clarity in the theoretical comparisons to adaptive learning of GPRGNN. However, it does not provide any explicit or implicit suggestions on how to address this issue or what specific aspects need clarification. The comment lacks actionable guidance, leaving the authors uncertain about how to improve their draft. Without concrete steps or examples, the authors are unable to make meaningful changes to their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment identifies a specific issue with the theoretical comparisons to adaptive learning of GPRGNN, but it does not specify which part of the paper this issue pertains to. The authors can infer that it might be related to the theoretical sections or discussions, but without explicit references, it is weakly grounded. The comment is specific in pointing out the lack of clarity in the theoretical comparisons, but it does not provide detailed guidance on how to address this issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the theoretical comparisons to adaptive learning of GPRGNN are not clear. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed explanation or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific area of concern regarding the clarity of theoretical comparisons to adaptive learning of GPRGNN. However, it lacks depth and does not provide any suggestions or guidance on how the authors might improve this aspect of their paper. Without actionable feedback or specific examples of what needs to be clarified, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the sufficiency of measuring object hallucination through only yes/no responses. It suggests that a yes response does not necessarily indicate that the model comprehends the presence of the object, as it may still produce incorrect objects in other tasks. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this concern or improve the measurement methodology. Without specific suggestions or instructions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the sufficiency of measuring object hallucination through only yes/no responses, suggesting that a yes response does not necessarily indicate comprehension. However, it does not specify which part of the paper this issue pertains to, such as a specific section or experiment where this measurement is discussed. Without explicit references or context, the authors cannot confidently determine which part of the paper needs attention. The comment is specific in its critique of the measurement method but lacks grounding, making it 2. Therefore, this comment aligns with a score of 2.", "verifiability_rationale": "The review point raises a question about the sufficiency of measuring object hallucination through only yes/no responses. It suggests that a yes response does not necessarily indicate comprehension, as the model may still produce incorrect objects in other tasks. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. The lack of evidence or detailed explanation makes it difficult for the authors to understand and address the concern fully. Therefore, the comment is considered 2, as it provides some insight but requires more detailed justification to be 5.", "helpfulness_rationale": "The review comment raises a valid concern about the sufficiency of measuring object hallucination through only yes/no responses. It points out that a yes response does not necessarily indicate that the model comprehends the presence of the object, as it may still produce incorrect objects in other tasks. This feedback is 3 as it prompts the authors to reconsider their measurement methodology and potentially explore more comprehensive approaches to assessing object hallucination. However, the comment lacks specific suggestions or guidance on how to address this issue, such as proposing alternative methods or metrics. To be more helpful, the comment could include actionable advice or examples of how to improve the measurement. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that there should be experiments and explanations regarding the different queries used in spatiotemporal representation, specifically mentioning spatial, temporal, and summary queries. It also asks what would happen if only spatial or temporal and summary queries were used. This provides clear and concrete guidance on what the authors need to do to improve their draft, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Experiments  Ablation,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing: experiments and explanations regarding the different queries used in spatiotemporal representation, such as spatial, temporal, and summary queries. The comment also provides a suggestion for what to explore, asking about the impact of using only spatial or temporal and summary queries. This level of detail and guidance makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the experiments should include an ablation study on the different queries used in spatiotemporal representation, such as spatial, temporal, and summary queries. It highlights the importance of this comparison to differentiate the work from VideoChatGPT and other works. However, the comment does not provide specific examples or references to support why this comparison is crucial or how it would impact the understanding of the results. While the suggestion is logical, it lacks detailed justification or evidence, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the experiments section, namely the need for an ablation study on the different queries used in spatiotemporal representation. It highlights the importance of this comparison to differentiate the work from VideoChatGPT and other works. The comment provides a clear and actionable suggestion by asking what would happen if only spatial or temporal and summary queries were used. This feedback is valuable as it directs the authors to conduct additional experiments and analysis, which could significantly enhance the comprehensiveness and depth of their results. However, the comment could be more helpful if it included specific examples or references to guide the authors in designing these experiments. Overall, the comment is 4, as it provides clear guidance for improvement but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests a potential restructuring of the paper by moving the first paragraph of Section 4 to Section 3 and placing the remainder of Section 4 before Section 3. While the comment implies an action, it does not provide explicit instructions on how to implement this restructuring or why it would improve the paper. The authors can infer that they need to rearrange the sections, but the comment lacks concrete guidance on how to achieve this. Therefore, the comment is 3, as it provides an idea but lacks detailed execution steps.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3 and Section 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting a potential restructuring of the sections to reduce redundancy. However, the comment does not provide detailed reasoning or examples of how the sections are redundant or how the suggested restructuring would improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Sections 3 and 4 are slightly redundant and proposes a restructuring to improve clarity. However, the comment does not provide specific examples or detailed reasoning to support why the sections are redundant or how the proposed restructuring would benefit the paper. Without additional context or evidence, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered 2, as it provides a suggestion but lacks sufficient justification or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with redundancy in Sections 3 and 4 of the paper. It suggests a restructuring of the sections to improve clarity by moving the first paragraph of Section 4 to Section 3 and placing the remainder of Section 4 before Section 3. This feedback is clear and actionable, providing the authors with a specific suggestion to enhance the organization and flow of their paper. However, the comment could be more helpful if it explained why the current structure is redundant or how the proposed restructuring would benefit the paper. Overall, the comment is 4 as it offers a constructive suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a lack of clarity regarding the connection between \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness.\" However, it does not provide explicit guidance or suggestions on how the authors might clarify this connection or improve the clarity of their work. The comment highlights an issue but lacks actionable advice, leaving the authors uncertain about how to address the identified problem. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment highlights a lack of clarity regarding the connection between \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness.\" However, it does not specify which part of the paper this issue pertains to, making it difficult for the authors to identify the exact sections that need revision. The comment provides some specificity by pointing out the lack of clarity, but it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that there is a lack of clarity regarding the connection between \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness.\" However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed explanation or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a lack of clarity regarding the connection between \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness.\" It points out that this lack of clarity is due to poor clarity in the paper. However, the comment does not provide specific suggestions or guidance on how the authors might improve the clarity or establish a clearer connection between these concepts. Without actionable advice or detailed feedback, the authors are left with a general understanding of the issue but without a clear path to resolution. Therefore, the comment is 3, as it highlights an area for improvement but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to provide a citation for the discussion of the \"kmax problem\" elsewhere. This is a clear and direct action that the authors can take to address the comment. The instruction is specific and leaves no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"the kmax problem,\" which allows the authors to identify the specific part of the paper being addressed. It also specifies the need for a citation, providing clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification, asking for a citation regarding the discussion of the \"kmax problem\" elsewhere. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is clear and specific in its request for a citation regarding the discussion of the \"kmax problem\" elsewhere. This feedback is actionable and provides a direct way for the authors to improve their draft by addressing a potential gap in their literature review. However, the comment could be more helpful if it provided context or explained why this information is important or relevant to the paper. Despite this, the comment is 4 as it guides the authors toward a specific improvement, making it a 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a lack of information regarding the estimation of the function for the optimal sequence length (Equation 1) and the reliability of the model. However, it does not provide explicit guidance on what the authors should do to address this issue. The comment implies that the authors should include this information, but it lacks concrete details on how to estimate the function or what specific aspects of reliability should be addressed. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper, namely the estimation of the function for the optimal sequence length (Equation 1) and the reliability of the model. However, it does not specify which part of the paper discusses this estimation or where the model reliability is discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact section being addressed. The comment is specific in its request for information on the estimation and reliability, but without explicit references to sections or figures, it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the lack of information on how the function for the optimal sequence length was estimated (Equation 1) and the reliability of the model. However, it does not provide any specific reasoning, examples, or references to support the claim. The comment is vague and lacks detailed justification, making it difficult for the authors to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, specifically the lack of information on how the function for the optimal sequence length was estimated (Equation 1) and the reliability of the model. This is a critical area that the authors need to address to ensure the validity and robustness of their work. However, the comment does not provide specific suggestions or guidance on how to estimate the function or improve the model\"s reliability. While it highlights an important issue, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a significant weakness but does not fully support the authors in addressing it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out a specific issue with the use of the word \"thousands\" in line 006, suggesting that it may not be accurate and recommending the addition of \"on the subword level.\" This feedback provides a clear and direct action for the authors to take, specifying exactly what needs to be changed in their draft. The comment is explicit and concrete, giving the authors a precise direction for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L006,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the use of \"thousands\" is not accurate and suggests adding \"on the subword level.\" This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the use of \"thousands\" in line 006 is not accurate and suggests adding \"on the subword level.\" However, the comment does not provide any supporting evidence or reasoning to justify why \"thousands\" is incorrect or how the addition of \"on the subword level\" would improve the accuracy. Without additional context or explanation, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the use of the word \"thousands\" in line 006, suggesting that it may not be accurate and recommending the addition of \"on the subword level.\" This feedback is clear and actionable, providing the authors with a precise suggestion for improvement. By addressing this point, the authors can enhance the accuracy and clarity of their draft. However, the comment could be more helpful if it explained why \"thousands\" is not accurate or how the addition would improve the draft. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context or reasoning. Therefore, it aligns with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises several issues that need to be addressed. First, it notes that some hyperparameters, such as regularization, are not given, which is an implicit request for the authors to provide this information. Second, it questions the y value at x=0 in the latent path figures, suggesting that it might be normalized to 0 and asking for clarification. This is an explicit request for clarification. Finally, the reviewer expresses interest in seeing further analysis on the model, specifically using interpolations. While the comment provides explicit actions for clarification and suggests additional analysis, it does not specify how to conduct the additional analysis. Therefore, the comment is 4, as it provides clear directions but lacks detailed guidance on the additional analysis.", "grounding_specificity_rationale": "The comment raises multiple issues, starting with the lack of information on hyperparameters, specifically mentioning regularization. It also questions the y value at x=0 in the latent path figures, suggesting it might be normalized to 0 and asking for clarification. Additionally, the reviewer expresses interest in seeing further analysis on the model, particularly using interpolations. While the comment does not explicitly mention specific sections or figures, the authors can infer that it relates to the sections discussing hyperparameters and the latent path figures. The comment is specific in detailing what needs to be clarified or improved, such as providing hyperparameter information and conducting further analysis. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises several claims, each of which requires verification. First, it claims that \"a number of hyperparameters (e.g. regularization) are not given,\" which is a subjective opinion that lacks specific examples or references to support the claim. Second, it questions the y value at x=0 in the latent path figures, suggesting it might be normalized to 0, but this is not substantiated with evidence or reasoning. Third, the reviewer expresses interest in seeing further analysis on the model, particularly using interpolations, but this is more of a suggestion than a claim. Overall, the comment lacks detailed justification or evidence for its claims, making it difficult for the authors to address the feedback effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper. It points out the lack of information on hyperparameters, specifically mentioning regularization, which is an important aspect of model training. This feedback is actionable as it prompts the authors to provide this information, which can help readers understand the experimental setup better. Additionally, the comment questions the y value at x=0 in the latent path figures, suggesting it might be normalized to 0 and asking for clarification. This is a specific and actionable request for clarification. The comment also expresses interest in seeing further analysis on the model, particularly using interpolations, which could provide additional insights. However, the comment could be more helpful if it offered suggestions on how to conduct this analysis or what specific aspects to focus on. Overall, the feedback is 4 as it identifies clear areas for improvement and provides actionable suggestions, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies two issues: forward referencing and the need for clearer explanations of contributions in the introduction. It also mentions that material supporting the main contributions is in the appendix rather than the main sections. While the comment highlights areas for improvement, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to clarify the contributions in the introduction and ensure that the main contributions are discussed in the main sections, but the comment lacks concrete guidance on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"the Introduction,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the need for clearer explanations of contributions and the placement of material supporting the main contributions in the appendix rather than the main sections. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is forward referencing in the paper, with material being introduced without proper explanation and then explained later. It also mentions that the main contributions are not clearly written in the introduction and that supporting material is in the appendix rather than the main sections. However, the comment lacks specific examples or references to substantiate these claims, making it difficult for the authors to understand the exact issues and address them effectively. The lack of detailed evidence or examples makes the claim 3, as it provides a general direction but requires more detailed justification for the authors to fully understand and address the issues.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper: forward referencing, where material is introduced without proper explanation, and the need for clearer explanations of contributions in the introduction. It also points out that material supporting the main contributions is in the appendix rather than the main sections, which could impact the reader\"s understanding. While the comment highlights important areas for improvement, it does not provide detailed guidance on how to address these issues or specific suggestions for reorganizing the content. The feedback is 3 as it directs the authors to areas that need clarification, but it could be more actionable with additional guidance. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the results presented in Table 1, specifically noting that it only shows results for the discriminative setting, which is known to not apply to real applications. The reviewer questions the results for the generative setting and requests clarification. While the comment implies that the authors should provide results for the generative setting, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to address the missing results but are not given specific guidance on how to present them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of results for the generative setting in Table 1, and questions the applicability of the discriminative setting to real applications. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the results presented in Table 1, specifically noting that it only shows results for the discriminative setting, which is known to not apply to real applications. The reviewer requests clarification on the results for the generative setting. This is a logical question that requires the authors to provide additional information or results to address the concern. However, the comment does not provide specific reasoning or evidence to support the claim that the discriminative setting is not applicable to real applications. Therefore, the claim is 3, as it lacks detailed justification but raises a valid point that the authors should address.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of results in the paper, noting that Table 1 only shows results for the discriminative setting, which is known to not apply to real applications. The reviewer questions the results for the generative setting and requests clarification. This feedback is clear and actionable, as it highlights a gap in the results presented and prompts the authors to provide additional information. By addressing this point, the authors can enhance the comprehensiveness and applicability of their results. However, the comment could be more helpful if it provided suggestions on how to present the generative setting results or why they are important. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the evaluation of the proposed approach for other language families, suggesting that its effectiveness is unknown. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to evaluate the approach for other language families or what specific steps should be taken to determine its effectiveness. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment highlights a gap in the evaluation of the proposed approach for other language families, suggesting that its effectiveness is unknown. However, it does not specify which part of the paper this issue pertains to, such as a specific section or analysis, making it weakly grounded. The comment is specific in identifying the lack of evaluation for other language families, but without clear grounding, the authors may struggle to determine where to address this issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the effectiveness of the proposed approach for other language families remains unknown. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a significant gap in the evaluation of the proposed approach, specifically noting that its effectiveness for other language families remains unknown. This is a valuable observation that highlights an area where the authors could expand their evaluation to provide a more comprehensive understanding of the approach\"s applicability. However, the comment lacks specific suggestions or guidance on how the authors might address this gap, such as proposing additional language families to test or suggesting evaluation methods. While it points out an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the related work section could be improved by describing the differences between the works mentioned. However, it does not provide specific guidance on how to achieve this improvement or which works need more detailed descriptions. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more detailed descriptions of the related works but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the related work section could be improved by describing the differences between the works mentioned. However, it does not specify which part of the related work section is lacking in clarity or which works need more detailed descriptions. This makes it difficult for the authors to pinpoint the exact areas that need attention. The comment is 1 as it does not identify a specific part of the paper, and it is also not specific because it lacks detailed guidance on what needs to be addressed. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the related work section could be improved by describing the differences between the works mentioned. However, it does not provide specific examples or detailed reasoning to support this claim. The comment lacks concrete evidence or references to illustrate which works are insufficiently described or how their differences could be better explained. Without this additional information, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific area for improvement in the related work section, noting that some works are mentioned but their differences are not described in sufficient detail. This feedback is 3 as it points out a potential weakness in the paper and suggests a direction for improvement. However, it lacks specificity and actionable guidance on how to enhance the related work section, such as which works need more detailed descriptions or what aspects should be highlighted. To be more helpful, the comment could provide examples or suggestions on how to effectively differentiate between related works. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the authors mention the importance of reliable PPP metrics for understanding PPP effects in different tasks but do not provide an explicit explanation or understanding of this concept. The reviewer asks the authors to explicitly explain what type of understanding one reaches by looking at PPP maps. This request is explicit and provides clear guidance on what the authors need to do to improve their draft. The action is concrete, as it specifies the type of explanation needed, making this comment 5.", "grounding_specificity_rationale": "The comment addresses the authors\" statement about the importance of reliable PPP metrics for understanding PPP effects in different tasks. However, it does not specify which part of the paper this statement is made in, making it weakly grounded. The comment is specific in its request for the authors to explicitly explain what type of understanding one reaches by looking at PPP maps. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the authors\" statement about the importance of reliable PPP metrics for understanding PPP effects in different tasks. It points out that the article does not provide an explicit explanation or understanding of this concept. The comment is 3 as it highlights a gap in the paper\"s explanation, but it lacks specific examples or references to support the claim. The authors would need to address this gap themselves to fully understand and improve their draft. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the explanation of the importance of reliable PPP metrics for understanding PPP effects in different tasks. It highlights the need for the authors to provide an explicit understanding of what type of insights can be gained from looking at PPP maps. This feedback is clear and actionable, as it directs the authors to clarify a critical aspect of their work that could enhance the reader\"s understanding. However, the comment could be more helpful if it offered specific suggestions on how to present this explanation or what aspects to focus on. Overall, the comment is 4, as it provides a clear direction for improvement but lacks detailed guidance, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of comparison with other stateoftheart methods, such as SpanBERT, which could impact the credibility of the paper. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific methods to include in the comparison. The action is implicit and somewhat vague, as the authors are left to infer that they need to conduct additional comparisons but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights a lack of comparison with other stateoftheart methods, specifically mentioning SpanBERT. However, it does not specify which part of the paper this comparison should be included in, such as the methodology or results sections. The authors can infer that it relates to the evaluation or comparison sections, but the comment lacks full grounding as it does not explicitly mention these sections. The comment is specific in identifying the need for comparison with SpanBERT, but it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors lack credibility due to not comparing their methods with other stateoftheart methods, specifically mentioning SpanBERT. This claim is 3 as it highlights a common practice in the field of comparing methods to establish credibility. However, the comment lacks specific examples or references to other works that have conducted such comparisons, which would strengthen the justification. The authors are left to infer the importance of this comparison without detailed guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of comparison with other stateoftheart methods, specifically mentioning SpanBERT. This feedback is valuable as it highlights an area where the paper could be strengthened by providing a more comprehensive evaluation of its methods. However, the comment does not offer specific suggestions on how to conduct these comparisons or which other methods should be included. While it provides a clear direction for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the details of the forwardprediction model are not well explained and suggests that Figure 2(b) should be redrawn to better represent the schematic representation of the forward prediction model. It also notes that connecting the text with the figure and equations is challenging. This feedback provides a clear and direct action for the authors to take, which is to redraw Figure 2(b) to improve its clarity and connection with the text. The comment is explicit and provides concrete guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2(b),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the figure, noting that it does not provide a schematic representation of the forward prediction model and that it is challenging to connect the text with the figure and equations. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the details of the forwardprediction model are not well explained, specifically mentioning that Figure 2(b) does not provide a schematic representation of the model. The reviewer suggests that the figure should be redrawn to improve clarity. While the comment identifies a specific issue with the figure, it lacks detailed reasoning or examples to support why the current representation is inadequate. The suggestion to redraw the figure is logical but could be strengthened with more detailed justification or references to similar practices in the field. Therefore, the claim is 3, as it provides a basis for improvement but requires more detailed justification.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the forwardprediction model, noting that Figure 2(b) does not provide a schematic representation and that it is challenging to connect the text with the figure and equations. This feedback is clear and actionable, as it suggests that the authors should redraw Figure 2(b) to better represent the model and improve the clarity of the text. By addressing this issue, the authors can enhance the comprehensibility of their work for readers. However, the comment could be more helpful if it provided additional guidance on how to improve the figure or suggested specific elements to include. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with further guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the training process for RBI, noting that it only considers rewarded actions and ignores rewardless actions that provide useful supervision. The reviewer suggests that this could be a significant factor contributing to the performance of FP + RBI over RBI alone. The comment implies that the authors should provide a stronger baseline than RBI, which is supervised by feedback, to prove the usefulness of FP. However, the comment does not explicitly instruct the authors to do so or provide specific guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors can infer the need for a stronger baseline but are not given concrete steps on how to achieve it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the training process for RBI, specifically noting that it only considers rewarded actions and ignores rewardless actions that provide useful supervision. The reviewer suggests that this could be a significant factor contributing to the performance of FP + RBI over RBI alone. However, the comment does not specify which part of the paper discusses RBI or FP, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors might have an idea of where this discussion is located, the lack of explicit grounding makes it weakly grounded. The comment is specific in identifying the issue with the training process and suggesting a potential improvement, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the training process for RBI, specifically noting that it only considers rewarded actions and ignores rewardless actions that provide useful supervision. The reviewer suggests that this could be a significant factor contributing to the performance of FP + RBI over RBI alone. The comment implies that the authors should provide a stronger baseline than RBI, which is supervised by feedback, to prove the usefulness of FP. However, the comment lacks specific examples or references to support the claim that rewardless actions are ignored, making it 3. The authors would need to further explore and substantiate the claim to fully understand its implications. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the training process for RBI, noting that it only considers rewarded actions and ignores rewardless actions that provide useful supervision. The reviewer suggests that this could be a significant factor contributing to the performance of FP + RBI over RBI alone. The comment implies that the authors should provide a stronger baseline than RBI, which is supervised by feedback, to prove the usefulness of FP. While the comment highlights an important issue and suggests a potential improvement, it lacks specific guidance or detailed suggestions on how to address this concern. The authors are left with a general idea of what needs to be improved but without clear steps to take. Therefore, the comment is 3, as it provides some direction but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the baseline methods are weak and not stateoftheart, and it suggests that the authors should discuss limitations. It also raises questions about the differences between the work and reinforcement learning, suggesting that the authors should discuss similarities and differences in the conclusion. While the comment implies that the authors should address these issues, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should discuss limitations and similarities to reinforcement learning. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the baseline methods, noting that they are weak and not stateoftheart, and suggests discussing limitations. It also raises questions about the differences between the work and reinforcement learning, suggesting a discussion on similarities and differences in the conclusion. However, the comment does not specify which baseline methods are weak or how they compare to stateoftheart methods, making it difficult for the authors to pinpoint the exact areas needing improvement. Additionally, while it mentions discussing limitations and similarities to reinforcement learning, it does not provide specific guidance on how to address these points. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the baseline methods are weak and not stateoftheart, and it suggests that the paper lacks a discussion of limitations. The reviewer also raises questions about the differences between the work and reinforcement learning, suggesting a discussion on similarities and differences in the conclusion. However, the comment does not provide specific examples or references to support the claim that the baseline methods are weak or that the paper lacks a discussion of limitations. The suggestion to discuss similarities and differences with reinforcement learning is logical but lacks detailed reasoning or evidence. Therefore, the claim is 3, as it provides a general direction but lacks specific support or examples.", "helpfulness_rationale": "The review comment identifies two main areas for improvement: the weakness of the baseline methods and the lack of discussion on limitations. It also raises questions about the differences between the work and reinforcement learning, suggesting that the authors should discuss similarities and differences in the conclusion. While the comment highlights important areas for enhancement, it lacks specific guidance or suggestions on how to address these issues. The authors are given a general direction but are left to determine the exact steps needed to improve their draft. Therefore, the comment is 3, as it provides some insight but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors clarify the distinction between the decisionmaker\"s interest in the true objective function and the noise, which is currently not represented clearly. It implies that the authors should make this distinction clearer upfront in the paper. While the comment explicitly states the need for clarification, it does not provide specific guidance on how to achieve this, such as suggesting changes to the wording or structure of the paper. The action is explicit but somewhat vague, as the authors know they need to clarify the distinction but may not be entirely sure of the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"formulation in this paper,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by pointing out the need to clarify the distinction between the decisionmaker\"s interest in the true objective function and the noise, which is currently not represented clearly. The comment provides a clear direction for improvement by suggesting that the authors make this distinction clearer upfront. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the expected performance under observation noise is typically used for evaluation because the decisionmaker is interested in the true objective function and the noise is assumed to be noise. It contrasts this with the formulation in the paper, where the decisionmaker does care about the noise and the objective function of interest is the stochastic noisy function. The comment suggests that this distinction should be made clearer upfront. While the claim is based on a logical reasoning about the typical evaluation practice and the paper\"s formulation, it lacks specific examples or references to support the assertion fully. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential confusion in the paper regarding the decisionmaker\"s interest in the true objective function versus the noise. It points out that the typical approach is to evaluate expected performance under observation noise, assuming the noise is misleading and not representative. However, the paper\"s formulation suggests that the decisionmaker does care about the noise, with the objective function of interest being the stochastic noisy function. The comment suggests that this distinction should be made clearer upfront, which is a valuable observation that could help the authors clarify their work. While the comment provides a clear direction for improvement, it could be more helpful if it offered specific suggestions on how to make this distinction clearer, such as by restructuring the text or providing examples. Overall, the comment is 4 as it highlights an important area for clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges the good performance of the method, particularly in Table 2, but questions the novelty and contribution of the method. It highlights that the main contribution is a new network design drawing inspiration from prior work for the sound source localization task. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the perceived lack of novelty or how to enhance the contribution of the work. Without actionable suggestions or specific feedback, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the performance of the method, particularly in Table 2, and questions the novelty and contribution of the method. It mentions the main contribution as a new network design drawing inspiration from prior work for the sound source localization task. However, the comment does not specify which part of the paper discusses the performance or contribution, making it weakly grounded. The authors can infer that it relates to the results or discussion sections, but this inference is not explicit. The comment is specific in questioning the novelty and contribution of the method, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the method\"s performance is good, especially in Table 2, but questions the novelty and contribution of the method. The reviewer suggests that the main contribution is a new network design drawing inspiration from prior work for the sound source localization task. While the comment provides some reasoning by mentioning the performance and the network design, it lacks specific examples or references to support the claim about the lack of novelty. This makes the claim 3, as it provides a basis for the critique but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the good performance of the method, particularly in Table 2, but questions the novelty and contribution of the method. It highlights that the main contribution is a new network design drawing inspiration from prior work for the sound source localization task. While the comment identifies a potential weakness in the novelty of the work, it lacks specific suggestions or guidance on how the authors might enhance the contribution or address the perceived lack of originality. The feedback is 3 as it points out an area for improvement, but it could be more actionable with additional details or recommendations. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the demonstration or results related to the model collapsing less than other methods. It also inquires about the occurrence of gradients becoming 0 and collapsing, as mentioned in line 159. While the comment implies that the authors should address these points, it does not explicitly instruct them to include specific demonstrations or results. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional information or analysis. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 159,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the demonstration or results related to the model collapsing less than other methods, and it seeks clarification on the occurrence of gradients becoming 0 and collapsing. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a series of questions seeking clarification and additional information. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a pertinent question about the demonstration or results related to the model collapsing less than other methods. It references a specific line in the paper (line 159) where the authors mention gradients becoming 0 and collapsing, and asks whether this is a common occurrence and if it was observed in the experiments. This feedback is 3 as it prompts the authors to provide additional information or analysis on this aspect of their work. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of how other methods might compare. Overall, the comment is 3 as it directs the authors to a specific area needing clarification but lacks depth in terms of actionable guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the problem formulation is unclear in the statement and introduction examples. However, it does not provide any explicit or implicit guidance on how to clarify the problem formulation or what specific aspects are unclear. Without additional details or suggestions, the authors are left without a clear understanding of what changes are needed to improve the clarity of the problem formulation. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment indicates that the problem formulation is unclear in the statement and introduction examples. However, it does not specify which parts of the statement or introduction are unclear, nor does it provide details on what aspects need clarification. This lack of specificity and lack of explicit references to sections or examples make it difficult for the authors to pinpoint the exact areas that need improvement. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the problem formulation is unclear in the statement and introduction examples. However, it does not provide any specific examples or detailed reasoning to support this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a potential issue with the clarity of the problem formulation in the statement and introduction examples. However, it lacks specificity and does not provide any actionable guidance or suggestions on how to improve the clarity. Without detailed feedback or examples of what needs to be clarified, the authors are left without a clear understanding of what changes are needed to address the issue. This makes the comment 3, as it points out a potential area for improvement but does not offer sufficient direction for the authors to effectively address it. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests conducting experiments with different LLM families, such as OPT, BLOOM, or other alternatives, to provide valuable insights into the method\"s applicability and generalizability. This feedback is clear and provides a concrete action for the authors to take, which is to conduct additional experiments. The suggestion is specific and leaves no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests conducting experiments with different LLM families, such as OPT, BLOOM, or other alternatives, to provide insights into the method\"s applicability and generalizability. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its request for additional experiments, but without clear grounding, the authors may struggle to determine where these experiments should be integrated. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests conducting experiments with different LLM families, such as OPT, BLOOM, or other alternatives, to provide insights into the method\"s applicability and generalizability. The comment is based on a logical reasoning that additional experiments could enhance the understanding of the method\"s applicability across various LLM families. However, it lacks specific examples or references to support the claim that these experiments are necessary or beneficial. The suggestion is 3 as it provides a logical rationale but lacks detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by noting the absence of experiments with different LLM families, such as OPT, BLOOM, or other alternatives. It suggests that conducting such experiments could provide valuable insights into the method\"s applicability and generalizability across various LLM families. This feedback is clear and actionable, as it offers a specific direction for the authors to enhance their study by expanding their experimental scope. However, the comment could be more helpful if it provided additional context or rationale for why these experiments are important or how they might impact the results. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point suggests that the method only works for generative models that can be finetuned as an in/outpainting model. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this limitation, whether it should be clarified, or if it should be expanded to include other types of models. Without any actionable steps or suggestions, the authors are left without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the method only works for generative models that can be finetuned as an in/outpainting model. However, it does not specify which part of the paper this claim is based on, such as a particular section, experiment, or methodology. Without explicit references or context, the authors cannot confidently determine which part of the paper this comment addresses. Additionally, the comment lacks specificity regarding what needs to be addressed or improved. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the method only works for generative models that can be finetuned as an in/outpainting model. However, it does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the method only works for generative models that can be finetuned as an in/outpainting model. While this observation highlights a potential limitation of the method, it does not provide any actionable feedback or suggestions for improvement. The comment lacks depth and does not offer guidance on how the authors might address this limitation or expand the applicability of their method. As a result, the comment is not particularly helpful for the authors in improving their draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a perceived disconnect between the first part of the paper, which involves curve finding, and the second part, which focuses on FGE. The reviewer suggests that the connection between these two parts is weak and that the initial expectation of the first part was not met. However, the comment does not provide explicit guidance on how to strengthen the connection or improve the clarity of the paper. While it identifies an issue, it lacks actionable advice or suggestions for the authors to address it. The feedback is vague and does not offer concrete steps for improvement, making it barely actionable.", "grounding_specificity_rationale": "The comment addresses a perceived disconnect between the first part of the paper, which involves curve finding, and the second part, which focuses on FGE. However, it does not specify which sections or parts of the paper these topics are discussed in, making it weakly grounded. The comment provides some specificity by explaining the reviewer\"s initial expectation of the first part and how it differs from the actual content. This provides some guidance on what the authors might need to clarify or revise. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the connection between the curve finding (the first part) and FGE (the second part) is weak. The reviewer provides a personal expectation of what the first part might entail, which is not met by the actual content. However, the comment lacks specific examples or detailed reasoning to support the claim that the connection is weak. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment identifies a perceived disconnect between the first part of the paper, which involves curve finding, and the second part, which focuses on FGE. It suggests that the initial expectation of the first part was not met, as the reviewer had anticipated a specific approach involving random weights and curve learning. However, the comment acknowledges that the approach could still work but notes its computational demands. While the comment highlights a potential issue, it lacks specific suggestions or guidance on how the authors might address this disconnect or improve the clarity of their work. The feedback is 3 as it points out a potential area for improvement, but it does not provide actionable steps for the authors to take. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include the results for linear scalarization with Concorde, a heuristicbased solver, for a better comparison. This is an explicit action with concrete details on how to implement it, as it specifies the exact method and comparison to be included. The authors know exactly what needs to be done to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2\" and \"Concorde,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the experimental results, namely the need to include the results for linear scalarization with Concorde for a better comparison. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the learningbased solvers are better than the heuristicbased solvers, except for the single objective TSP where the SOTA heuristicsolver (Concorde) performs best. The reviewer suggests including the results for linear scalarization with Concorde for a better comparison. This claim is 3 as it is based on the experimental results presented in the paper, but it lacks specific references or detailed reasoning to fully substantiate the claim. The suggestion to include additional results is logical, but the comment could be strengthened with more detailed justification or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental results, noting that the learningbased solvers outperform the heuristicbased solvers except for the single objective TSP, where the SOTA heuristicsolver (Concorde) performs best. The reviewer suggests including the results for linear scalarization with Concorde for a better comparison, which is a clear and actionable piece of feedback. This guidance helps the authors enhance the comprehensiveness and validity of their experimental analysis, making the comment 4. However, the comment could be more helpful if it provided additional context or explanation on why this comparison is important or how it might impact the overall conclusions. Therefore, the comment is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests moving some details from the appendix back into the main text and moving some background from Section 2 to the appendix instead. This feedback is explicit and provides a clear action for the authors to take, specifying which parts should be moved and where. The suggestion is concrete, as it outlines a specific change that would improve the clarity and accessibility of the paper. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental setup, tasks, and other details\" being moved to the appendix, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests moving some of these details back into the main text and moving some background from Section 2 to the appendix instead. This provides clear guidance on what needs to be addressed and how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that moving the experimental setup, tasks, and other details to the appendix makes it hard to interpret the paper. However, it does not provide specific examples or detailed reasoning to support this claim. The suggestion to move some details back into the main text and to move some background from Section 2 to the appendix is a logical next step, but the initial claim lacks sufficient evidence or justification. Therefore, the comment is 3, as it provides a direction for improvement but lacks detailed support for the initial claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the organization of the paper, noting that moving the experimental setup, tasks, and other details to the appendix makes it difficult to interpret the paper. It provides a clear and actionable suggestion to move some of these details back into the main text and to move some background from Section 2 to the appendix instead. This feedback is valuable as it guides the authors on how to improve the clarity and accessibility of their work. However, the comment could be more helpful if it included specific examples or details on which details should be moved back or which background should be moved to the appendix. Overall, the comment is 4 as it offers actionable advice, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly suggests that the authors should provide glosses in Figure 2. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific and concrete instruction on what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment suggests providing glosses in Figure 2, which implies that the reviewer is referring to a specific figure in the paper. However, it does not explicitly mention the figure number, making it weakly grounded. The comment is specific in its request for glosses, which clarifies what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that providing glosses in Figure 2 would be helpful. However, it does not provide any reasoning or evidence to support why glosses are necessary or how they would enhance the figure. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the authors should provide glosses in Figure 2. While this feedback is clear and actionable, it could be more helpful if it explained why glosses are necessary or how they would enhance the figure. Providing additional context or examples of how glosses could improve the figure would make the comment more comprehensive and beneficial for the authors. As it stands, the comment is 3 as it identifies a specific area for improvement but lacks depth and detailed guidance. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point notes that \"Memb\" is apparently the previous stateoftheart but lacks a reference. This implies that the authors should include a reference to support this claim. However, the comment does not explicitly instruct the authors to do so, leaving it as an implicit action. Additionally, it does not provide specific guidance on which reference to include or how to integrate it into the text. The action is inferred and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment mentions \"Memb,\" implying that it is a previous stateoftheart method. However, it does not specify which part of the paper this claim pertains to, such as a section or a discussion of related work. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in pointing out the lack of a reference for \"Memb,\" but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that \"Memb\" is the previous stateoftheart but lacks a reference. This is a subjective claim that requires justification or evidence to support the assertion. The comment does not provide any references, examples, or detailed reasoning to substantiate the claim, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that \"Memb\" is apparently the previous stateoftheart but lacks a reference. This feedback is 3 as it highlights a potential gap in the paper, specifically the absence of a reference to support the claim about \"Memb.\" However, the comment does not provide specific guidance on how to address this issue, such as suggesting which references to include or how to integrate them into the text. While it identifies a weakness, it lacks actionable advice, making it 3 but incomplete."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about why the authors did not consider finer grouping for quantization instead of pertensor and perchannel. However, it does not provide any explicit or implicit suggestions for how the authors might address this question or what specific actions they should take. The comment lacks actionable guidance, leaving the authors without a clear understanding of how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the choice of quantization grouping, specifically asking why finer grouping was not considered instead of pertensor and perchannel. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment where quantization is discussed. Without explicit references or context, the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its question about the choice of quantization grouping but lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point is a question asking why the authors did not consider finer grouping for quantization instead of pertensor and perchannel. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the choice of quantization grouping, specifically asking why finer grouping was not considered instead of pertensor and perchannel. While it identifies a potential area for improvement, it lacks depth and does not provide any suggestions or guidance on how the authors might address this issue. The comment does not offer actionable feedback or insights into why finer grouping might be beneficial or how it could be implemented. As a result, the comment is 2, as it points out a potential area for improvement but does not provide enough detail or direction for the authors to effectively address it."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests studying the impact of the ratio of unseen classes and provides an example of how the performance varies with different ratios of unseen classes. This comment explicitly states an action for the authors to take, which is to investigate the impact of the ratio of unseen classes. The suggestion is clear and provides a concrete example of what the authors should explore, making the comment 5.", "grounding_specificity_rationale": "The comment suggests studying the impact of the ratio of unseen classes and provides an example of how the performance varies with different ratios of unseen classes. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in detailing what needs to be studied, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests studying the impact of the ratio of unseen classes and provides an example of how the performance varies with different ratios of unseen classes. This suggestion is based on logical reasoning, as it proposes an additional aspect of the study that could provide valuable insights. However, the comment lacks specific references or detailed examples to fully substantiate the claim, making it 3. The authors would need to infer the potential benefits of this analysis and how it could impact their work. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests an additional aspect of the study that could provide valuable insights: the impact of the ratio of unseen classes. It provides a specific example of how the performance varies with different ratios of unseen classes, which is a clear and actionable suggestion for the authors to consider. By addressing this point, the authors could enhance the comprehensiveness and depth of their analysis, making the comment 4. However, the comment could be more helpful if it included a rationale for why this aspect is important or how it might impact the overall study. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the choice of using GRU for the Pyramid and LSTM for the sequential part, inquiring if the combination of two architectures is the reason for the improvements. While it highlights a potential inconsistency or rationale for the choice of architectures, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit and somewhat vague, as the authors are left to infer that they might need to provide a justification or explanation for their architectural choices. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the choice of using GRU for the Pyramid and LSTM for the sequential part, suggesting that the combination of two architectures might be the reason for improvements. However, it does not specify which part of the paper discusses these architectures, making it weakly grounded. The comment is specific in questioning the rationale behind the choice of architectures, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the choice of using GRU for the Pyramid and LSTM for the sequential part, suggesting that the combination of two architectures might be the reason for improvements. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this combination is significant or how it contributes to the improvements. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the choice of using GRU for the Pyramid and LSTM for the sequential part, suggesting that the combination of two architectures might be the reason for improvements. This is a relevant question that could help the authors clarify their methodology and provide a rationale for their architectural choices. However, the comment lacks depth and does not offer specific suggestions or guidance on how the authors might address this issue or improve their explanation. While it prompts the authors to consider the rationale behind their choices, it does not provide actionable feedback or detailed advice for improvement. Therefore, the comment is 3, as it identifies a potential area for clarification but lacks comprehensive guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the definition of \"active vertices\" in the context of line 135. While it does not explicitly instruct the authors to clarify or define this term, it implies that the authors should provide a clear definition or explanation. The action is implicit but concrete, as the authors can infer that they need to clarify the term \"active vertices\" in their draft. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 135,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the definition of \"active vertices,\" providing a clear direction for the authors to clarify this term. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification on the definition of \"active vertices\" in the context of line 135. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the definition of \"active vertices\" in the context of line 135, which is a specific and relevant point that could help clarify the paper. By asking for clarification, the reviewer prompts the authors to provide a clear definition or explanation, which can enhance the comprehensibility of the manuscript. However, the comment does not offer any suggestions or guidance on how to address this issue or improve the clarity of the text. While it identifies a potential area for improvement, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two main issues: the lack of mention of the inapplicability of the theory to the used model in the limitations section and the vague nature of the structural assumptions given in the appendix. It also suggests that the authors underestimate the current use of graph neural networks in industry and recommends providing more elaboration on potential negative societal impacts. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to clarify the limitations and provide more detailed information on the structural assumptions, as well as consider the societal impact of graph neural networks. However, the lack of concrete guidance on how to implement these changes makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"limitations\" section of the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of mention of the inapplicability of the theory to the used model, the vagueness of the structural assumptions given in the appendix, and the need for more elaboration on potential negative societal impacts of graph neural networks. This provides clear guidance on what needs to be addressed in the limitations section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not mention the inapplicability of its theory to the used model in the limitations section, which is a subjective opinion. The reviewer also suggests that the structural assumptions are vague and not clearly stated, which could be a valid observation. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to fully understand and address the issues. The suggestion to provide more elaboration on potential negative societal impacts of graph neural networks is also a subjective opinion without detailed justification. Therefore, the comment is 3, as it provides some reasoning but lacks specific evidence or examples to fully substantiate the claims.", "helpfulness_rationale": "The review comment provides a detailed critique of the paper, identifying several areas for improvement. It points out that the theory\"s applicability to the used model is not mentioned in the limitations section, which is a significant oversight. The comment also highlights the vagueness of the structural assumptions given in the appendix, making it difficult for readers to understand the limitations. Additionally, the reviewer suggests that the authors underestimate the current use of graph neural networks in industry and recommends providing more elaboration on potential negative societal impacts. This feedback is clear and actionable, offering specific areas for the authors to address and improve their draft. However, it could be more helpful if it included suggestions on how to clarify the structural assumptions or address the societal impact concerns. Overall, the comment is 4, as it provides valuable insights and guidance for enhancing the paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the meaning of \"epsilongreedy\" in the context of training and whether it is used in addition to the proposed strategy. While it does not explicitly instruct the authors to clarify or revise this part of the paper, the question implies that the authors should provide additional explanation or clarification. The action is implicit but clear, as the authors can infer that they need to address the confusion regarding the use of epsilongreedy. However, the comment lacks specific guidance on how to clarify this point, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section \"Appendix D.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the meaning of \"epsilongreedy\" and whether it is used in addition to the proposed strategy. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the meaning of \"epsilongreedy\" in the context of training and whether it is used in addition to the proposed strategy. However, it does not provide any additional context, reasoning, or references to support the claim or clarify the confusion. Without further explanation or evidence, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the meaning of \"epsilongreedy\" in the context of training and whether it is used in addition to the proposed strategy. This is a specific and relevant point that could help clarify the methodology used in the paper. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their explanation. While it identifies a potential area of confusion, it lacks actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the proposed method as a direct combination of GCN and normalizing flow, with the ultimate transformed distribution being replaced by a Gaussian mixture distribution. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the critique, improve the method, or provide additional context or justification. As a result, the comment lacks actionability and does not offer any direction for the authors to enhance their draft. Therefore, it is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment critiques the proposed method as a direct combination of GCN and normalizing flow, with the ultimate transformed distribution being replaced by a Gaussian mixture distribution. However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to identify the exact section that needs attention. Additionally, while the comment provides some insight into the method\"s novelty, it lacks specificity in terms of what aspects need improvement or clarification. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point critiques the proposed method as a direct combination of GCN and normalizing flow, with the ultimate transformed distribution being replaced by a Gaussian mixture distribution. The comment suggests that this approach lacks novelty, but it does not provide specific examples or references to support this claim. The reasoning is somewhat vague, as it does not elaborate on why the combination of GCN and normalizing flow is not innovative or how the use of a Gaussian mixture distribution affects the method\"s novelty. Therefore, the comment is classified as 2, as it provides some basis for the claim but lacks detailed justification or evidence.", "helpfulness_rationale": "The review comment critiques the proposed method as a direct combination of GCN and normalizing flow, with the ultimate transformed distribution being replaced by a Gaussian mixture distribution. It suggests that this approach lacks novelty, but it does not provide specific feedback or suggestions on how the authors could improve their work or address the perceived lack of originality. The comment identifies a potential weakness but lacks actionable guidance, making it 3 as it points out an area for improvement but does not offer detailed advice on how to enhance the draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point highlights a specific observation about the impact of the projection head (CNN layers) and the classification head (FCN layer). However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this observation or what changes, if any, should be made to improve the draft. Without actionable suggestions or questions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"projection head (CNN layers)\" and the \"classification head (FCN layer),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out a particular observation about the impact of these heads, which provides clear guidance on what needs to be addressed. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about the impact of the projection head (CNN layers) and the classification head (FCN layer). It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment points out a specific observation regarding the impact of the projection head (CNN layers) and the classification head (FCN layers). It notes that only the projection head is affected, while the classification head remains unchanged. However, the comment does not provide any context, explanation, or suggestions for why this observation is relevant or how it might impact the paper. Without additional information or guidance, the authors are left without a clear understanding of the significance of this observation or how to address it. As a result, the comment is 1, as it lacks actionable feedback or insight that could assist the authors in improving their draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the analogy between HOI analysis and Harmonic analysis is interesting but weak, noting that the problem contexts have only two \"basis\" (human and object) to form an HOI, and the decomposition/integration steps do not have a close connection with Fourier analysis as claimed. However, the comment does not provide explicit guidance or suggestions on how the authors might strengthen the link or improve the analogy. The action is implicit, as the authors can infer that they need to address the weak connection, but it lacks concrete details on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the analogy between HOI analysis and Harmonic analysis, specifically critiquing the weak link between the two. It mentions the problem context, which has only two \"basis\" (human and object) to form an HOI, and the lack of a close connection with Fourier analysis as claimed. However, the comment does not specify which part of the paper discusses this analogy, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might infer that it relates to the methodology or results sections, the comment lacks full grounding. It is specific in detailing the issue with the analogy but does not provide guidance on how to address it. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the analogy between HOI analysis and Harmonic analysis is weak, noting that the problem contexts have only two \"basis\" (human and object) to form an HOI, and the decomposition/integration steps do not have a close connection with Fourier analysis as claimed. The comment provides a logical reasoning by pointing out the limited basis and lack of connection with Fourier analysis, which helps the authors understand the critique. However, it could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is 3, as it provides a logical basis but lacks detailed evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, specifically the analogy between HOI analysis and Harmonic analysis. It points out that the link between the two is weak, noting that the problem contexts have only two \"basis\" (human and object) to form an HOI, and the decomposition/integration steps do not have a close connection with Fourier analysis as claimed. This feedback is 3 as it highlights an area where the paper may need further development or clarification. However, the comment lacks specific suggestions or guidance on how the authors might strengthen the analogy or address the disconnect. To be more helpful, the comment could include actionable advice or examples of how to improve the connection. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that dynamic precision control during training might only show meaningful performance gains on bitserial accelerators, while most existing ML accelerators use bitparallel fixedpoint numbers. This implies that the proposed methodology might be limited in its applicability. However, the comment does not provide explicit guidance or suggestions on how the authors might address this limitation or explore alternative applications. The action is implicit and vague, as it lacks concrete steps for the authors to take. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the potential limitations of the proposed methodology regarding dynamic precision control during training, specifically mentioning its applicability to bitserial accelerators. However, it does not specify which part of the paper discusses this aspect, making it weakly grounded. The comment is specific in detailing the potential restriction due to the use of bitparallel fixedpoint numbers in most existing ML accelerators. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that dynamic precision control during training might only show meaningful performance gains on bitserial accelerators, while most existing ML accelerators use bitparallel fixedpoint numbers. This claim is based on a logical inference about the applicability of the proposed methodology, but it lacks specific examples or references to support the assertion. The comment provides a reasonable basis for the claim, but the lack of detailed evidence or references makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation of the proposed methodology, specifically noting that dynamic precision control during training might only show meaningful performance gains on bitserial accelerators. It also points out that most existing ML accelerators use bitparallel fixedpoint numbers, which could restrict the implications of the proposed methodology. While the comment highlights an important consideration, it lacks specific suggestions or guidance on how the authors might address this limitation or explore alternative applications. The feedback is 3 as it prompts the authors to consider the broader applicability of their work, but it could be more actionable with additional insights or recommendations. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the generalizability of the model to focusing distances not present in the training data. It explicitly asks for an explanation of how the model performs on focusing distances other than those in the training data. This provides a clear and direct action for the authors to take, which is to address the generalizability issue by providing additional information or analysis. The comment is explicit and concrete, giving the authors a specific task to complete. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the generalizability of the model to focusing distances not present in the training data, and it asks for an explanation of how the model performs on these distances. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the generalizability of the model to focusing distances not present in the training data. It does not contain any subjective claims, opinions, or suggestions that require verification. It is a factual question seeking clarification, making it a normal statement. Therefore, the label \"No\" is appropriate.", "helpfulness_rationale": "The review comment raises a pertinent question about the generalizability of the model to focusing distances not present in the training data. By asking for an explanation of how the model performs on these distances, the reviewer encourages the authors to address a potential limitation of their work. This feedback is clear and actionable, as it prompts the authors to consider and discuss the model\"s performance on unseen data, which could significantly enhance the robustness and applicability of their findings. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered examples of how to evaluate generalizability. Overall, the comment is 4, as it directs the authors to an important area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point identifies a main weakness in the work, specifically the lack of technical novelty with respect to spatial transformer networks (STN) and the absence of comparisons to STN. It highlights that the proposed Xtransformation is similar to STN but applied locally, and mentions existing works that apply STN in a local pixel neighborhood. The comment also notes that PointNet uses a variant of STN in their network architecture, suggesting that the technical novelty is limited. Additionally, it points out the lack of empirical or conceptual comparisons to STN, which is considered important. While the comment identifies the issue and provides some context, it does not explicitly instruct the authors on how to address these concerns or improve the draft. The action is implicit and somewhat vague, as the authors need to infer that they should enhance the technical novelty and include comparisons to STN. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"spatial transformer networks (STN)\" and \"Xtransformation,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of technical novelty and the absence of comparisons to STN, which are important aspects of the work. The comment provides specific examples of existing works that use STN in a local pixel neighborhood and mentions PointNet as a reference. This level of detail makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the technical novelty of the work is limited due to its similarity to existing work, specifically spatial transformer networks (STN). It provides specific examples of existing works that use STN in a local pixel neighborhood and mentions PointNet as a reference. This detailed comparison and reference to existing literature provide a solid basis for the claim, making it 4. However, the comment could be strengthened by including more detailed comparisons or references to specific aspects of the work that are similar or different from STN. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant weakness in the work, specifically the lack of technical novelty with respect to spatial transformer networks (STN) and the absence of comparisons to STN. It highlights that the proposed Xtransformation is similar to STN but applied locally, and mentions existing works that apply STN in a local pixel neighborhood. Additionally, it points out that PointNet uses a variant of STN in their network architecture, suggesting that the technical novelty is limited. The comment also emphasizes the importance of empirical or conceptual comparisons to STN, which is crucial for evaluating the work\"s originality and contribution. This feedback is clear and actionable, as it directs the authors to enhance the technical novelty and include comparisons to STN, which would significantly improve the draft. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point consists of two parts: a correction of a typographical error and a suggestion to link theorems and corollaries to their corresponding proofs. The first part is explicit and actionable, as it clearly instructs the authors to correct the figure reference. The second part is also explicit and actionable, as it provides a specific action for the authors to take to improve the paper\"s readability. However, the comment does not provide detailed guidance on how to link the theorems and corollaries to their proofs, which could be more concrete. Overall, the comment is 4, as it provides clear actions but could be more detailed in some aspects.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Row 821 in Supp. Page 31,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out a typographical error (\"Fig.7\" should be \"Fig.12\") and suggests linking theorems and corollaries to their corresponding proofs to improve readability. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts: a correction of a typographical error and a suggestion to link theorems and corollaries to their corresponding proofs. The first part is factual and does not contain a claim, while the second part is a suggestion for improvement. The suggestion is logical and straightforward, aiming to enhance the paper\"s readability. However, it lacks specific examples or references to support the claim that this improvement is necessary or beneficial. Therefore, the comment is 4, as it provides a clear suggestion but lacks detailed justification or evidence.", "helpfulness_rationale": "The review comment provides two specific pieces of feedback. First, it corrects a typographical error by pointing out that \"Fig.7\" should be \"Fig.12\" in a specific row of the supplementary material. This is a clear and actionable suggestion that helps the authors improve the accuracy of their paper. Second, it suggests linking theorems and corollaries to their corresponding proofs, which would enhance the paper\"s readability and make it easier for readers to follow the logical flow. This is a constructive and actionable piece of feedback that could significantly improve the paper\"s clarity. However, the comment could be more helpful if it provided additional context or explanation for why these corrections are important. Overall, the feedback is 4 as it offers specific and actionable suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point consists of several questions and observations, each of which implies an action for the authors to take. For example, the comment questions the absence of a determiner in the definition at line 248 and asks for clarification on the selection of action verbs, classes, and action frames. While these questions imply that the authors should provide additional information or clarification, they do not explicitly instruct the authors to do so. The actions are implicit and somewhat vague, as the authors need to infer that they should address these points. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (248 and 306ff) and terms (\"action verbs,\" \"50 classes,\" and \"action frames\") that allow the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be clarified or addressed, such as the missing determiner, the selection of action verbs and classes, and the definition of \"action frames.\" This level of detail provides clear guidance on what needs to be improved, making the comment 5. Therefore, this comment aligns with a score of 5.", "verifiability_rationale": "The review point consists of a series of questions and observations, each of which seeks clarification or additional information. It does not contain subjective claims, opinions, or suggestions that require verification. The questions are factual and aim to gather more information, making them normal statements. Therefore, the label \"No\" is appropriate.", "helpfulness_rationale": "The review comment consists of a series of questions and observations that seek clarification on specific aspects of the paper. It questions the absence of a determiner in the definition at line 248, asks for clarification on the selection of action verbs and classes, and inquires about the definition of \"action frames.\" While these questions identify areas that need further explanation or clarification, they do not provide specific suggestions or guidance on how the authors might address these issues. The feedback is 3 as it prompts the authors to clarify certain aspects of their work, but it lacks actionable advice or detailed suggestions for improvement. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that some details are missing, specifically mentioning the design of rewards. However, it does not provide explicit guidance on what details are missing or how the authors should address this issue. The comment lacks concrete suggestions or examples, leaving the authors uncertain about how to improve their draft. As a result, the action is implicit and vague, making it barely actionable.", "grounding_specificity_rationale": "The comment mentions that \"some details are missing,\" specifically regarding the design of rewards. However, it does not specify which part of the paper this pertains to, such as a section or subsection, making it weakly grounded. The comment is specific in identifying the missing detail about the design of rewards, but without clear grounding, the authors may struggle to determine where to address this issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that \"some details are missing,\" specifically regarding the design of rewards. However, it does not provide any specific examples or detailed reasoning to support this claim. Without additional context or explanation, the authors may find it challenging to understand which details are missing or how to address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific area where the paper lacks detail, namely the design of rewards. This is a clear and actionable piece of feedback that can guide the authors in improving their draft by providing more information on this critical aspect. However, the comment could be more helpful if it offered suggestions on what specific details should be included or how the authors might approach the design of rewards. Despite this, the feedback is 3 as it directs the authors to a specific area needing attention, providing a starting point for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the paper regarding the fixed number of entities and the lack of generalization to different numbers of entities. However, it does not provide explicit guidance or suggestions on how the authors might address this issue. The comment implies that the authors should consider generalizing their model to different numbers of entities, but it does not specify how to achieve this or what specific steps to take. As a result, the action is implicit and vague, leaving the authors without clear direction on how to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the number of entities being fixed and the lack of generalization to different numbers of entities, as shown in figure 3 of INs. This provides full grounding as it explicitly mentions a specific figure and concept in the paper, allowing the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue of generalization and the need for flexibility in the number of entities. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the number of entities is fixed and questions how to generalize the model to different numbers of entities. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. The lack of evidence or detailed explanation makes it difficult for the authors to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the paper regarding the fixed number of entities and the lack of generalization to different numbers of entities. It points out that this issue is evident in Figure 3 of INs, which is a specific reference that helps the authors understand the context of the critique. However, the comment does not provide suggestions or guidance on how the authors might address this limitation or generalize their model. While it highlights an important area for improvement, the lack of actionable advice makes the feedback 3. The authors are given a clear indication of what needs to be addressed, but they are left without specific steps to take to improve their draft. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point acknowledges the incremental nature of the improvement over KNN based MT approaches, noting the lack of novelty but the significant engineering and execution effort. It also highlights the good experimental design. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the perceived weakness or how to improve the paper. Without actionable suggestions or specific feedback, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the incremental nature of the improvement over KNN based MT approaches, noting the lack of novelty but the significant engineering and execution effort. It also mentions the good experimental design. However, the comment does not specify which part of the paper this critique is based on, making it difficult for the authors to identify the exact sections that need attention. Additionally, while it provides some insight into the perceived weaknesses, it lacks specificity in terms of what needs to be addressed or improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the work is an incremental improvement over KNN based MT approaches, noting the lack of novelty but the significant engineering and execution effort. It also mentions the good experimental design. However, the comment lacks specific examples or references to support the claim of incremental improvement or the lack of novelty. Without detailed evidence or comparisons to other works, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is classified as 3, as it provides some justification but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment acknowledges the incremental nature of the improvement over KNN based MT approaches, noting the lack of novelty but the significant engineering and execution effort. It also mentions the good experimental design. However, the comment lacks specificity and actionable feedback, as it does not provide guidance on how the authors might address the perceived weakness or improve the paper. Without detailed suggestions or examples, the authors are left without a clear understanding of what steps to take to enhance their work. Therefore, the comment is 2, as it identifies a potential issue but does not offer meaningful guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should discuss the runtime of Prithvi WxC, given its large parameter count, as a potential limitation for applications that require computational cheapness. While the comment implies that the authors should include this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to discuss the runtime or what aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should discuss the runtime of Prithvi WxC, given its large parameter count, as a potential limitation for applications that require computational cheapness. However, it does not specify which part of the paper should include this discussion, making it weakly grounded. The comment is specific in its suggestion to address the runtime as a limitation, but without explicit references to sections or parts of the paper, the authors may find it challenging to pinpoint where this discussion should be included. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the selling point of MLbased emulators is their computational cheapness, and it suggests that the runtime of Prithvi WxC should be discussed due to its large parameter count. The comment provides a logical reasoning for why the runtime is important, as it could be a limitation for applications requiring computational cheapness. However, it lacks specific examples or references to support the claim about the large parameter count or the potential impact on runtime. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the point.", "helpfulness_rationale": "The review comment identifies a potential limitation of the Prithvi WxC model, specifically its large parameter count, which could impact its computational cheapness. It suggests that the authors should discuss the runtime of Prithvi WxC as a limitation for applications that require computational cheapness. This feedback is clear and actionable, as it provides a specific area for improvement by recommending the inclusion of runtime discussions. However, the comment could be more helpful if it offered guidance on how to measure or present the runtime data or suggested ways to mitigate the limitation. Overall, the comment is 4 as it directs the authors to a critical aspect of their work that needs further attention."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the paper may be overselling its method, which could make the contribution less clear. However, it does not provide specific guidance on how the authors should address this issue or what changes they should make to improve the clarity of the contribution. The comment lacks explicit instructions or concrete suggestions, leaving the authors uncertain about how to implement the feedback. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment suggests that the paper may be overselling its method, which could make the contribution less clear. However, it does not specify which part of the paper is being referred to, such as a particular section, figure, or table, making it difficult for the authors to pinpoint the exact area needing revision. Additionally, the comment lacks specificity regarding what aspects of the method are being oversold or how the contribution could be clarified. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper may be overselling its method, which could make the contribution less clear. However, the comment does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed justification or references to particular aspects of the paper that are being oversold, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment suggests that the paper may be overselling its method, which could make the contribution less clear. However, it does not provide specific examples or details on what aspects of the method are being oversold or how the contribution could be clarified. Without actionable feedback or suggestions for improvement, the authors are left without a clear understanding of what changes are needed to address the issue. This lack of specificity and guidance makes the comment 2, as it does not offer meaningful direction for enhancing the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the model description could be improved by presenting the generative process in separate steps and by including a notation table. While the comment implies that these changes would enhance understanding, it does not provide explicit instructions on how to implement them or what specific steps should be taken. The authors can infer that they need to restructure the model description and consider adding a notation table, but the comment lacks concrete guidance on how to achieve these improvements. Therefore, the comment is 3, as it identifies an area for improvement but does not provide detailed instructions on how to execute it.", "grounding_specificity_rationale": "The comment suggests improvements to the model description, specifically mentioning the need for a better presentation of the generative process in separate steps and the inclusion of a notation table. However, it does not specify which part of the paper this feedback pertains to, such as a particular section or figure where the model description is presented. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing revision. While the comment is specific in suggesting improvements, it is 1 because it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the model description could be improved by presenting the generative process in separate steps and by including a notation table. However, the comment does not provide specific examples or detailed reasoning to support why these changes would enhance understanding or improve the clarity of the model description. Without additional context or evidence, the authors may find it challenging to understand the exact nature of the suggested improvements. Therefore, the comment is considered 2, as it provides some guidance but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the model description, suggesting that the generative process could be better understood if presented in separate steps. It also mentions the need for a notation table to enhance clarity. While the comment highlights important aspects for improvement, it lacks detailed guidance or examples on how to implement these suggestions. The feedback is 3 as it points out areas for enhancement, but it could be more actionable with additional details or specific recommendations. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the writing could be improved, noting that it took effort to understand the main idea and theoretical analysis. However, it does not provide specific guidance on how to improve the writing or what aspects need attention. The action is implicit and vague, as the authors are left without clear direction on how to address the issue. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the writing could be improved, noting that it took effort to understand the main idea and theoretical analysis. However, it does not specify which parts of the paper are particularly challenging or what specific aspects of the writing need improvement. Without explicit references to sections, figures, or specific issues, the authors cannot confidently determine which parts of the paper need revision. Additionally, the comment lacks specificity regarding what improvements are needed, such as clarity, organization, or coherence. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the writing could be improved, noting that it took effort to understand the main idea and theoretical analysis. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks evidence or references to substantiate why the writing is challenging or how it could be improved. Without additional context or explanation, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges that the writing could be improved, noting that it took effort to understand the main idea and theoretical analysis. However, it does not provide specific suggestions or guidance on how to improve the writing, such as identifying areas of confusion or recommending ways to enhance clarity. Without actionable feedback or detailed advice, the authors are left without a clear path to address the issue. Therefore, the comment is 2, as it highlights a potential problem but lacks the depth and specificity needed to guide the authors in making improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a specific issue with the sentence in lines 1217 of the abstract, noting that it is cumbersome and can be made clearer. However, it does not provide explicit guidance on how to improve the clarity or suggest specific changes that could be made. The action is implicit, as the authors can infer that they need to simplify the sentence, but the comment lacks concrete details on how to achieve this. Therefore, the comment is 3, as it points out an area for improvement but does not offer detailed guidance on how to address it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific sentence in lines 1217 of the abstract, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the sentence is cumbersome and can be made clearer. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the sentence in lines 1217 of the abstract is cumbersome and can be made clearer. However, it does not provide any specific reasoning or examples to support why the sentence is cumbersome or how it could be improved. Without detailed justification or suggestions, the claim lacks verifiability, making it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the sentence in lines 1217 of the abstract, noting that it is cumbersome and could be made clearer. This feedback is 3 as it points out a potential area for improvement, suggesting that the authors should consider revising the sentence for clarity. However, the comment lacks detailed guidance or suggestions on how to achieve this clarity, such as proposing alternative phrasing or restructuring the sentence. While it provides some direction, it could be more helpful with additional details or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a concern about the unfairness of comparing the domainspecific model trained on Pix3D with zeroshot singleimage 3D reconstruction models. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how to address the issue of unfairness or suggestions for alternative comparisons or experiments. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the domainspecific model\" and \"Pix3D,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the comparison to zeroshot singleimage 3D reconstruction models, pointing out that such comparisons are unfair. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the comparison between the domainspecific model trained on Pix3D and zeroshot singleimage 3D reconstruction models is unfair. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is unfair. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a potential issue with the fairness of the comparison between the domainspecific model trained on Pix3D and zeroshot singleimage 3D reconstruction models. However, it does not provide any suggestions or guidance on how the authors might address this issue or improve the fairness of their comparisons. Without actionable feedback or specific recommendations, the comment lacks depth and does not offer much value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the evaluation is limited, primarily relying on four OCR QA datasets, and suggests that more scenarios like the LLaVA benchmark should be included, especially in ablation studies. While the comment implies that the authors should expand their evaluation to include additional scenarios, it does not provide specific guidance on which scenarios to consider or how to incorporate them into the ablation studies. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig 4(5),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the limited evaluation, relying on only four OCR QA datasets, and suggests that more scenarios like the LLaVA benchmark should be included, especially in ablation studies. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the evaluation is limited, primarily relying on four OCR QA datasets, and suggests that more scenarios like the LLaVA benchmark should be included. The comment references Figure 4(5), which the authors admit may be unreliable, providing some justification for the claim. However, the comment lacks specific examples or detailed reasoning about why the LLaVA benchmark would be beneficial or how it could improve the evaluation. This makes the claim 3, as it provides a basis for the suggestion but requires more detailed justification or examples to be fully convincing.", "helpfulness_rationale": "The review comment identifies a limitation in the evaluation section, noting that it primarily relies on four OCR QA datasets. It acknowledges the authors\" admission that this evaluation may be unreliable, as seen in Figure 4(5). The comment suggests that more scenarios, such as the LLaVA benchmark, should be included, especially in ablation studies. This feedback is clear and actionable, providing the authors with a specific direction for improving their evaluation by expanding the scope to include additional benchmarks. However, the comment could be more helpful if it offered guidance on how to incorporate these additional benchmarks or provided examples of how they might impact the results. Overall, the comment is 4 as it effectively points out a limitation and suggests a way to address it, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the abstract visual reasoning tasks, describing them as unintuitive and overly difficult. It questions the complexity of the tasks, suggesting that simpler ones might be more effective. The reviewer also expresses difficulty in solving the tasks and questions the interpretation of the models\" learning. However, the comment does not provide explicit guidance or suggestions for how the authors might address these concerns or improve the tasks. While it identifies areas for potential improvement, it lacks actionable details or concrete steps for the authors to follow. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises concerns about the abstract visual reasoning tasks, specifically mentioning their unintuitiveness and difficulty. It questions the complexity of the tasks and suggests that simpler ones might be more effective. However, the comment does not specify which part of the paper these tasks are discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing the issues with the tasks, such as their complexity and potential for interpretation, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses concerns about the abstract visual reasoning tasks, describing them as unintuitive and overly difficult. The reviewer questions the complexity of the tasks and suggests that simpler ones might be more effective. However, the comment lacks specific examples or references to support the claim that the tasks are overly difficult or confusing. Without detailed evidence or reasoning, the claim remains 3, as the authors would need to infer the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises concerns about the abstract visual reasoning tasks, describing them as unintuitive and overly difficult. It questions the complexity of the tasks and suggests that simpler ones might be more effective. The reviewer also expresses difficulty in solving the tasks and questions the interpretation of the models\" learning. However, the comment lacks specific suggestions or guidance on how the authors might address these concerns or simplify the tasks. While it identifies a potential issue, it does not provide actionable feedback or detailed insights into how the authors might improve their work. Therefore, the comment is 3, as it highlights an area for improvement but does not offer comprehensive guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the evaluation of weak supervision could be improved by questioning the realism of the evaluated tweets. It points out that the prompt requires all structured elements for perspectives to be present in the generated tweets, which may not be the most realistic. Additionally, it critiques the generation of authors, noting that the use of \"author embeddings\" is not realistic. While the comment identifies specific areas for improvement, it does not provide explicit guidance on how to address these issues or what specific changes should be made. The action is implicit and somewhat vague, as the authors can infer that they need to improve the realism of the evaluation and generation, but they are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"weak supervision\" and \"evaluated tweets,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the realism of the evaluated tweets and the prompt, as well as critiquing the generation of authors. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that weak supervision could be better evaluated, specifically questioning the realism of the evaluated tweets and the prompt. It provides a detailed critique of the prompt, noting that it requires all structured elements for perspectives to be present in the generated tweets, which may not be the most realistic. Additionally, it critiques the generation of authors, stating that the use of \"author embeddings\" is not realistic. While the comment provides specific examples and reasoning, it could be strengthened by referencing similar studies or practices that support the claim. Overall, the comment is 4, as it provides a clear and logical argument but lacks comprehensive references. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by questioning the realism of the evaluated tweets and the prompt used for weak supervision. It points out that the prompt requires all structured elements for perspectives to be present in the generated tweets, which may not be the most realistic. Additionally, it critiques the generation of authors, noting that the use of \"author embeddings\" is not realistic. This feedback is clear and actionable, as it directs the authors to reconsider the realism of their evaluation and prompts them to make improvements in this area. However, the comment could be more helpful if it offered suggestions on how to enhance the realism of the evaluation or provided examples of more realistic approaches. Overall, the comment is 4, as it effectively guides the authors toward improving their draft by identifying specific areas for enhancement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to include keypoint detection results in the experiments section. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific and concrete suggestion, leaving no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly instructs the authors to include keypoint detection results in the experiments section, providing clear guidance on what needs to be addressed. This makes the comment fully grounded, as the authors can accurately identify the part of the paper being addressed. Additionally, the comment is specific because it clearly specifies what needs to be included, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for additional information, specifically asking for the inclusion of keypoint detection results in the experiments section. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a clear and specific suggestion for improvement by requesting the inclusion of keypoint detection results in the experiments section. This feedback is actionable and directly addresses a gap in the paper, offering a concrete way for the authors to enhance their draft. By including these results, the authors can provide a more comprehensive evaluation of their work, which is beneficial for both the paper and the readers. However, the comment could be more helpful if it explained why these results are important or how they would contribute to the paper\"s findings. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about whether the grid search of the learning rate is done on the validation set. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this question or what steps to take to clarify this aspect of the methodology. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the grid search of the learning rate, specifically asking if it is done on the validation set. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its inquiry about the validation set, but it lacks grounding as it does not provide a clear reference to the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the grid search of the learning rate, specifically asking if it is done on the validation set. This is a factual inquiry that does not contain a claim or opinion requiring verification. It is a request for clarification, which is not considered a claim. Therefore, the label \"No\" is appropriate.", "helpfulness_rationale": "The review comment raises a question about the grid search of the learning rate, specifically asking if it is done on the validation set. While this is a relevant inquiry, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve their methodology. Without actionable feedback or additional context, the authors are left without a clear understanding of what steps to take to enhance their work. Therefore, the comment is 2, as it identifies a potential area of concern but does not offer meaningful guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the number of discourse relations in Table A2, suggesting that it might be an artifact of the colloquial language or a misclassification of relations. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue or whether it is a concern that needs to be addressed. Without any actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table A2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the number of discourse relations in the treebank, suggesting that it might be an artifact of the colloquial language or a misclassification of relations. This provides clear guidance on what aspect of the paper needs further clarification or investigation. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the number of discourse relations in Table A2, suggesting that it might be an artifact of the colloquial language or a misclassification of relations. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the number of discourse relations in Table A2, suggesting that it might be an artifact of the colloquial language or a misclassification of relations. This is a relevant observation that could lead to further investigation or clarification in the paper. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or what steps they should take to improve their analysis. While it identifies a potential area of concern, it does not provide actionable feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the racial and economic diversity of the sample and the generalizability of the results to other groups, particularly marginalized ones. While it implies that the authors should consider these aspects, it does not explicitly instruct them to address these issues or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to consider these factors but are not given concrete steps on how to incorporate them into their analysis. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L393,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the racial and economic diversity of the sample and the generalizability of the results to other groups, particularly marginalized ones. This provides clear guidance on what aspects need to be considered or addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the racial and economic diversity of the sample and the generalizability of the results to other groups, particularly marginalized ones. However, it does not provide any supporting evidence, reasoning, or references to justify why these aspects are important or how they might impact the results. The comment is more of a suggestion for the authors to consider these factors rather than a claim that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises an important question about the racial and economic diversity of the sample and the generalizability of the results to other groups, particularly marginalized ones. This is a relevant concern that could impact the validity and applicability of the study. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or conduct further analysis to ensure inclusivity. While it highlights a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it prompts the authors to consider an important aspect of their study but does not fully support them in making improvements."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges that the output quality is reasonable but notes that it is still far from realistic. It references recent GAN works that have achieved amazing quality in synthesized results, suggesting that the bar has risen significantly in recent years. The reviewer implies that there is still room for improvement in result quality, but does not provide specific guidance on how to achieve this improvement. The comment also mentions the limited novelty, low resolution output, and high hardware requirement, which could be considered as reasons for rejection. However, the feedback lacks explicit actions or concrete suggestions for the authors to address these issues. As a result, the comment is vague and does not provide actionable steps for the authors to improve their draft, making it barely actionable.", "grounding_specificity_rationale": "The comment addresses the output quality of the paper, noting that it is reasonable but still far from realistic. It references recent GAN works that have achieved impressive results, suggesting that the bar has risen significantly. The reviewer implies that there is room for improvement in result quality. However, the comment does not specify which part of the paper discusses the output quality, making it weakly grounded. It is specific in identifying the issue with the output quality and referencing recent GAN works, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the output quality is reasonable but still far from realistic, referencing recent GAN works that have achieved impressive results. The reviewer suggests that the bar for output quality has risen significantly in recent years, implying that the current results are not up to par. However, the comment lacks specific examples or references to these recent GAN works, making it difficult for the authors to fully understand and address the critique. The claim is 3 as it provides a general context but lacks detailed evidence or examples to substantiate the claim fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges that the output quality is reasonable but notes that it is still far from realistic, particularly in comparison to recent GAN works that have achieved impressive results. The reviewer suggests that there is room for improvement in result quality, which is a valid observation. However, the comment lacks specificity and actionable feedback on how the authors might improve the output quality or what specific aspects need attention. Additionally, the comment mentions the limited novelty, low resolution output, and high hardware requirement, which could be considered as reasons for rejection. While it identifies some areas for improvement, the feedback is incomplete and does not provide detailed guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the use of soft labels in conjunction with CRM and Cross Entropy, specifically questioning why the authors did not extend the curve further. It also expresses concern about the hyperparameters used for the leftmost plots. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their draft. The feedback lacks concrete actions or details on how to implement changes, leaving the authors uncertain about what steps to take. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises concerns about the use of soft labels in conjunction with CRM and Cross Entropy, specifically questioning why the authors did not extend the curve further. It also expresses concern about the hyperparameters used for the leftmost plots. However, the comment does not specify which part of the paper these concerns relate to, such as a specific section, figure, or table. This lack of explicit grounding makes it difficult for the authors to pinpoint the exact areas needing attention. Additionally, while the comment provides some specific feedback on the use of soft labels and hyperparameters, it does not specify what needs to be addressed or improved. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises concerns about the use of soft labels in conjunction with CRM and Cross Entropy, specifically questioning why the authors did not extend the curve further. It also expresses concern about the hyperparameters used for the leftmost plots. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the concerns effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises concerns about the use of soft labels in conjunction with CRM and Cross Entropy, specifically questioning why the authors did not extend the curve further. It also expresses concern about the hyperparameters used for the leftmost plots. While the comment identifies potential issues, it lacks specific guidance or suggestions on how the authors might address these concerns or improve their draft. The feedback is 3 as it points out areas that need clarification or improvement, but it does not provide actionable steps or detailed advice. Therefore, it aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the traditional experiment for unseen characters is presented as an afterthought and recommends adding more evaluation in this direction, specifically on classifying unseen words. It also suggests adding translations to Figure 6 for readers who do not speak Chinese. While the comment provides explicit actions, it lacks concrete details on how to implement these suggestions, such as specific evaluation metrics or methods to use for the additional evaluation. The authors know what needs to be done but may not be entirely sure of the exact steps to take. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding translations to Figure 6 for readers who do not speak Chinese, providing a clear direction for improvement. Additionally, the comment specifies that the traditional experiment for unseen characters is presented as an afterthought and recommends adding more evaluation in this direction, specifically on classifying unseen words. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the traditional experiment for unseen characters is presented as an afterthought and recommends adding more evaluation in this direction. It also suggests adding translations to Figure 6 for readers who do not speak Chinese. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that the experiment is underdeveloped or that translations would enhance understanding. This makes the claim 3, as it provides a direction for improvement but requires more detailed justification or evidence to be fully convincing.", "helpfulness_rationale": "The review comment provides a constructive suggestion for improving the paper by recommending more evaluation in the direction of classifying unseen words. It also suggests adding translations to Figure 6 to enhance accessibility for readers who do not speak Chinese. While the comment identifies a potential area for expansion and offers a specific suggestion, it could be more helpful if it provided additional context or examples of how this evaluation might be conducted. Overall, the feedback is 4 as it offers actionable guidance for enhancing the paper, but it could be more comprehensive with further elaboration."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the small number of images in the VioT dataset, questioning its ability to validate the approach. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue. There is no guidance on whether additional images should be included, how the dataset could be expanded, or what specific steps the authors should take to improve the dataset\"s validity. Without actionable advice or concrete steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"VioT dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the small number of images in each category, which the reviewer feels is insufficient to validate the approach. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the number of images in the VioT dataset is insufficient to validate the approach. However, it does not provide any supporting evidence, reasoning, or references to justify why 20 images per category are inadequate. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment points out a potential issue with the VioT dataset, specifically noting that the number of images provided (20 per category) may be insufficient to validate the approach. This is a relevant observation that could impact the robustness and generalizability of the results. However, the comment lacks specificity and does not provide actionable advice or suggestions on how the authors might address this issue. Without guidance on how to expand the dataset or improve its validity, the feedback is 3 as it highlights a potential concern but does not fully support the authors in making improvements. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights several issues with the paper, including its lack of intuitive explanations for mathematical derivations, insufficient figure captions, and the need for additional explanations and legends. The reviewer also mentions that Figures 1 and 2 did not contribute much to their understanding and required multiple readings. While the comment identifies specific areas that need improvement, it does not provide explicit guidance on how to address these issues or what specific changes should be made. The actions are implicit and somewhat vague, as the authors are left to infer the necessary steps without concrete instructions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as the mathematical derivations, figure captions, and figures 1 and 2. This allows the authors to accurately identify the sections being addressed. The comment is also specific because it details what is lacking, such as intuitive explanations for mathematical derivations, more detailed figure captions, and explanations of the colors used in Figure 2. The feedback provides clear guidance on what needs to be improved, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper is hard to follow and suggests that more intuitive explanations are needed for the mathematical derivations. It also criticizes the figure captions for lacking explanations and legends, specifically mentioning the need for an explanation of the colors in Figure 2. The reviewer further states that Figures 1 and 2 did not contribute much to their understanding and required multiple readings. While the comment provides some reasoning by pointing out specific issues with the figures and captions, it lacks detailed examples or references to support the claim that the paper is hard to follow. The feedback is 3, as it identifies specific areas for improvement but could be strengthened with more detailed justification or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas where the paper could be improved, including the lack of intuitive explanations for mathematical derivations, insufficient figure captions, and the need for additional explanations and legends. It also points out that Figures 1 and 2 did not contribute much to the reviewer\"s understanding and required multiple readings. This feedback is 4 as it provides clear and actionable suggestions for enhancing the clarity and accessibility of the paper. However, it could be more helpful if it offered specific examples or guidance on how to improve the figure captions or mathematical explanations. Overall, the comment is valuable for guiding the authors in making significant improvements to their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point consists of multiple observations and suggestions. It explicitly states that the text in Table 1 is too small and hard to read, providing a clear action for the authors to improve the readability of their tables. Additionally, it points out that Algorithm 1 is missing a gradient symbol in line 4, which is also an explicit action for the authors to take. The comment further suggests referencing specific works related to private stochastic convex optimization, providing concrete examples of relevant literature. This level of detail and specificity makes the comment 5, as it clearly guides the authors on what changes to make to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 1\" and \"Algorithm 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the text size in Table 1 and the missing gradient symbol in Algorithm 1, providing clear guidance on what needs to be addressed. Additionally, it suggests referencing specific works related to private stochastic convex optimization, which adds further specificity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of multiple observations and suggestions, each of which is verifiable. The first claim about the text in Table 1 being too small and hard to read is supported by the observation itself, which is a straightforward fact. The second claim about Algorithm 1 missing a gradient symbol in line 4 is also verifiable, as it is a specific observation that can be easily confirmed. The third claim regarding references is supported by the inclusion of specific references to relevant works, providing a clear basis for the suggestion. Overall, the comment is 5 as it provides explicit, specific, and robust evidence for each claim, making it clear and actionable for the authors.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by identifying two issues with the paper: the text in Table 1 is too small and hard to read, and Algorithm 1 is missing a gradient symbol in line 4. These observations are clear and direct, allowing the authors to make immediate improvements to their draft. Additionally, the comment suggests referencing specific works related to private stochastic convex optimization, which is a valuable addition that can enhance the paper\"s context and relevance. The feedback is comprehensive and constructive, making it 5 for the authors to improve their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the ResNet in the experiments in section 7.1 shares parameters between residual blocks. It suggests that a potentially interesting baseline would be to compare to a deeper ResNet with parameter sharing, which would be equivalent to an ODE net with a fixed timestep Euler integrator. While the comment implies that the authors should consider this comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement the suggested comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 7.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about whether the ResNet in the experiments shares parameters between residual blocks and suggests a potentially interesting baseline for comparison. The comment provides a clear suggestion for improvement by recommending a deeper ResNet with parameter sharing as a baseline. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about whether the ResNet in the experiments shares parameters between residual blocks. It suggests a potentially interesting baseline for comparison, which is a deeper ResNet with parameter sharing, equivalent to an ODE net with a fixed timestep Euler integrator. However, the comment does not provide any evidence, reasoning, or references to support the claim that this comparison would be interesting or beneficial. The suggestion is based on logical reasoning but lacks specific examples or references to substantiate the claim. Therefore, the comment is 3, as it provides a logical suggestion but lacks detailed justification or evidence.", "helpfulness_rationale": "The review comment raises a question about whether the ResNet in the experiments in section 7.1 shares parameters between residual blocks. It suggests that a potentially interesting baseline for comparison would be a deeper ResNet with parameter sharing, which would be equivalent to an ODE net with a fixed timestep Euler integrator. This feedback is 3 as it provides a specific suggestion for an additional comparison that could enhance the experimental setup. However, the comment lacks detailed guidance on how to implement this comparison or why it would be beneficial, which limits its usefulness. To be more helpful, the comment could include more detailed instructions or rationale for the suggested comparison. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the motivation behind the crossencoder architecture, specifically addressing the claim that it \"ignores crossentity comparison\" and \"attends to all candidates at once.\" The reviewer acknowledges that the architecture may not be as finegrained as claimed. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the issue or improve the motivation, leaving the authors without a clear path forward. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the motivation behind the crossencoder architecture, specifically challenging the claim that it \"ignores crossentity comparison\" and \"attends to all candidates at once.\" However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its critique of the motivation, but it lacks grounding as it does not reference a particular section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point challenges the motivation behind the crossencoder architecture, specifically disputing the claim that it \"ignores crossentity comparison\" and \"attends to all candidates at once.\" The reviewer provides a logical reasoning by explaining that the architecture may not be as finegrained as claimed. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to further explore the architecture\"s capabilities to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the motivation behind the crossencoder architecture, specifically challenging the claim that it \"ignores crossentity comparison\" and \"attends to all candidates at once.\" The reviewer acknowledges that the architecture may not be as finegrained as claimed. However, the comment does not provide specific suggestions or guidance on how the authors might improve the motivation or clarify the architecture\"s capabilities. Without actionable feedback or detailed advice, the authors are left without a clear path to address the issue. Therefore, the comment is 3, as it identifies a potential weakness but lacks depth and actionable guidance."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point criticizes the use of an \"antiquated\" GNN model and method, stating that it negatively impacts the performance of the framework. It also mentions that the baseline algorithms/methods are antiquated. However, the comment does not provide any explicit or implicit suggestions for improvement or specific actions the authors should take to address these issues. There is no guidance on whether the authors should update their model, use more recent methods, or provide justification for their choice of methods. As a result, the authors are left without a clear understanding of how to improve their draft based on this feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment criticizes the use of an \"antiquated\" GNN model and method, which it claims negatively impacts the performance of the framework. It also mentions that the baseline algorithms/methods are antiquated. However, the comment does not specify which part of the paper discusses these models or methods, making it difficult for the authors to identify the exact sections that need attention. Additionally, while it highlights the issue of antiquated models, it does not provide specific suggestions or details on how to address this issue. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the use of an \"antiquated\" GNN model and method negatively impacts the performance of the framework. However, it does not provide specific examples or references to support this claim, such as comparing the performance with more recent models or methods. The lack of detailed evidence or references makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the use of an \"antiquated\" GNN model and method, which it claims negatively impacts the performance of the framework. It also mentions that the baseline algorithms/methods are antiquated. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address these issues. Without detailed feedback or recommendations, the authors are left without a clear understanding of what steps to take to improve their work. Therefore, the comment is 2, as it highlights a problem but does not offer meaningful guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a lack of clarity in Figure 1 regarding how the proposed method produces the type of explanation mentioned. It suggests that additional adhoc postanalysis is needed to extract shared motifs to explain a set of instances. While the comment implies that the authors should provide more detailed explanations or analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the explanation but are not given specific guidance on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the explanation in Figure 1, noting the lack of clarity regarding how the proposed method produces the type of explanation mentioned. The comment further suggests that additional adhoc postanalysis might be necessary to extract shared motifs, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the explanation in Figure 1 is unclear and suggests that additional adhoc postanalysis is needed to extract shared motifs. However, the comment does not provide specific examples or detailed reasoning to support this claim. The reference to \"Line 48\" is not sufficient to fully substantiate the claim, as it does not provide context or explanation. This lack of detailed justification makes the claim 3, as the authors would need to infer the exact nature of the issue and how to address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the explanation in Figure 1, noting that it is unclear how the proposed method produces the type of explanation mentioned. It suggests that additional adhoc postanalysis might be necessary to extract shared motifs, which could help explain a set of instances. This feedback is clear and actionable, as it points out a potential weakness in the paper and provides a direction for improvement by suggesting additional analysis. However, the comment could be more helpful if it offered specific guidance on how to conduct this analysis or what aspects to focus on. Overall, the comment is 4, as it directs the authors to enhance the clarity and comprehensiveness of their explanations, but it could be more detailed to be fully comprehensive."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises several issues, including the lack of comparison with other models besides GPT2, confusion in sections of the paper, a missing citation or reference in Line 99, and an unreferenced notation in Line 165. The comment acknowledges the authors\" effort to address limitations but does not provide specific guidance on how to address these issues. The actions are implicit and somewhat vague, as the authors are left to infer what needs to be done without concrete instructions. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines and sections of the paper, allowing the authors to accurately identify the parts being addressed. It specifies the issues with the paper, such as the lack of comparison with other models, confusion in sections, a missing citation or reference, and an unreferenced notation. The comment also acknowledges the authors\" effort to address limitations. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises several claims, including the lack of comparison with other models, confusion in sections, a missing citation, and an unreferenced notation. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issues effectively. The mention of the authors\" effort to acknowledge limitations is a factual statement, but it does not contribute to the verifiability of the other claims. Therefore, the comment is considered 2, as it provides some support but lacks detailed justification for the claims.", "helpfulness_rationale": "The review comment identifies several issues with the paper, including the lack of comparison with other models, confusion in sections, a missing citation or reference, and an unreferenced notation. It also acknowledges the authors\" effort to address limitations. While the comment highlights important areas for improvement, it lacks specific suggestions or guidance on how to address these issues. The authors are left with a general understanding of what needs to be fixed but without detailed instructions on how to make the necessary improvements. Therefore, the comment is 3, as it provides some direction but not comprehensive guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that a more comprehensive and dataintensive analysis would significantly improve the paper. However, it acknowledges that this is not a strong negative point given the paper\"s short length. The comment does not provide explicit guidance on how to implement a more comprehensive analysis or what specific aspects should be included. The action is implicit and vague, as the authors are left to infer that they should expand their analysis but without concrete steps or examples. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that a more comprehensive and dataintensive analysis would improve the paper, but it does not specify which part of the paper this analysis should focus on or what specific aspects need improvement. The authors cannot confidently determine which sections or aspects of the paper are being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity regarding what a more comprehensive analysis should entail or how it would improve the paper. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that a more comprehensive and dataintensive analysis would improve the paper, but it acknowledges that this is not a strong negative point given the paper\"s short length. The comment does not provide specific examples, references, or detailed reasoning to support the claim that a more comprehensive analysis would significantly enhance the paper. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges that the paper is short and suggests that a more comprehensive and dataintensive analysis would significantly improve it. However, it does not provide specific guidance or suggestions on how to achieve this improvement, such as what aspects of the analysis should be expanded or what additional data could be included. The comment lacks actionable feedback and does not offer a clear path for the authors to enhance their work. As a result, it is 2, as it identifies a potential area for improvement but does not provide sufficient detail or direction for the authors to act upon."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should cite works on metalearning, even though they do not directly target continual learning. It also implies that the authors should distinguish between different approaches in metalearning and link them more heavily to the work on RL for architecture search and/or as optimizers for learning. While the comment provides a clear direction for the authors to expand their citations and make connections between different approaches, it does not specify which specific works should be cited or how to make these connections. The action is explicit but somewhat vague, as the authors know they need to expand their citations and make connections but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should cite works on metalearning, even though they do not directly target continual learning. It also implies that the authors should distinguish between different approaches in metalearning and link them more heavily to the work on RL for architecture search and/or as optimizers for learning. While the comment does not explicitly mention specific sections or parts of the paper, it does provide a clear direction for the authors to expand their citations and make connections between different approaches. The authors can infer that this pertains to the sections discussing related work or literature review, as these are typically where citations are included. However, the comment lacks specific details on which works should be cited or how to make these connections, making it weakly grounded but specific. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should cite works on metalearning, even though they do not directly target continual learning. It also implies that the authors should distinguish between different approaches in metalearning and link them more heavily to the work on RL for architecture search and/or as optimizers for learning. While the comment provides a logical reasoning for why these connections should be made, it lacks specific references or examples of works that should be cited. This makes the claim 3, as the authors would need to conduct additional research to fully understand and implement the suggested changes. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential gap in the paper by suggesting that the authors should explore a deeper connection between their work and metalearning, even though the latter does not directly target continual learning. It provides a clear direction for the authors to expand their citations and make connections between different approaches, particularly those related to RL for architecture search and/or as optimizers for learning. This feedback is actionable and offers a specific area for improvement, making it 4. However, the comment could be more helpful if it included specific suggestions on which works to cite or how to make these connections more explicit. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the lack of lexical and syntactic diversity in the teacher feedback, suggesting that it might be autogenerated. It asks whether the authors intend to use human turkers or generate different types of feedback to make it more realistic. While the comment implies that the authors should consider these options, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement the suggested changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the lack of lexical and syntactic diversity in the teacher feedback, assuming it is autogenerated. It raises a question about whether the authors intend to use human turkers or generate different types of feedback to make it more realistic. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing the issue of diversity and suggesting potential solutions, but without explicit grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point raises a concern about the lack of lexical and syntactic diversity in the teacher feedback, suggesting that it might be autogenerated. The reviewer asks whether the authors intend to use human turkers or generate different types of feedback to make it more realistic. While the comment identifies a potential issue, it lacks specific examples or references to support the claim that the feedback is autogenerated or that diversity is lacking. The suggestion for human turkers or diverse feedback is logical but not fully substantiated, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the teacher feedback, noting a lack of lexical and syntactic diversity. It raises a question about whether the feedback is autogenerated and suggests that using human turkers or generating different types of feedback could make it more realistic. This feedback is 3 as it points out a potential weakness in the methodology and provides a direction for improvement by suggesting ways to enhance the diversity and realism of the feedback. However, the comment could be more helpful if it offered specific guidance on how to implement these suggestions or provided examples of diverse feedback. Overall, the comment is 3, as it prompts the authors to consider an important aspect of their methodology but lacks detailed guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly recommends comparing the performance of the proposed method with two specific works: \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MADX: An AdapterBased Framework for MultiTask CrossLingual Transfer.\" This provides a clear and direct action for the authors to take, as it specifies which works to compare their method with. The recommendation is concrete, as it outlines a specific task and references two relevant studies. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the recommendation to compare the performance with specific works: \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MADX: An AdapterBased Framework for MultiTask CrossLingual Transfer.\" This allows the authors to accurately identify the part of the paper being addressed, which is the performance evaluation section. The comment is also specific because it clearly specifies what needs to be addressed, namely, the comparison with these two works. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests comparing the performance of the proposed method with two specific works: \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MADX: An AdapterBased Framework for MultiTask CrossLingual Transfer.\" This recommendation is based on the premise that these works are relevant and could provide a useful comparison. However, the comment does not provide detailed reasoning or evidence to support why these particular works should be included in the comparison. While the suggestion is logical, it lacks specific justification or references to the works, making it 3. The authors would need to independently investigate the relevance of these works to fully understand the basis of the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the paper by recommending a comparison of the proposed method with two existing works: \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MADX: An AdapterBased Framework for MultiTask CrossLingual Transfer.\" This recommendation is clear and could help the authors enhance the comprehensiveness and relevance of their performance evaluation. However, the comment could be more helpful if it included a rationale for why these specific works should be considered or how they might contribute to the discussion. Overall, the feedback is 4 as it offers a concrete step for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the absence of standard deviations in the paper, which makes it difficult to determine if the best method is truly the best or if other RF configurations have similar performance. While the comment implies that the authors should include standard deviations to provide more robust analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to include standard deviations but are not given specific guidance on how to implement this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment highlights the absence of standard deviations in the paper, which affects the evaluation of the best method\"s performance. However, it does not specify which part of the paper this issue pertains to, such as specific figures or tables where standard deviations should be included. This lack of explicit reference makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in pointing out the need for standard deviations to ensure the best method\"s superiority, but without grounding, it remains 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that the absence of standard deviations makes it difficult to determine the true superiority of the best method. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant omission in the paper, namely the absence of standard deviations, which is crucial for evaluating the performance of the best method. By pointing out this gap, the comment highlights a critical area that needs attention and improvement. However, the comment does not provide specific guidance on how to address this issue, such as suggesting which standard deviations should be included or how to present them effectively. While it directs the authors\" attention to an important aspect of their analysis, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is 3, as it provides insight but lacks actionable guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the applicability of the approach to more general settings, suggesting that the authors consider extending their approach to broader scenarios. While the comment implies that the authors should explore this possibility, it does not provide explicit instructions or concrete steps on how to achieve this. The action is implicit and somewhat vague, as the authors need to infer that they should consider expanding their approach and determine how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the applicability of the approach to more general settings, suggesting that the authors consider extending their approach to broader scenarios. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for an extension to more general settings, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the applicability of the approach to more general settings, suggesting that the authors consider extending their approach to broader scenarios. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this extension would be beneficial or how it could be achieved. Without additional context or examples, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the applicability of the approach to more general settings, suggesting that the authors consider extending their approach to broader scenarios. While it identifies a potential limitation and provides a direction for improvement, it lacks specific guidance or suggestions on how to achieve this extension. The comment is 3 as it prompts the authors to think about the generalizability of their approach, but it does not offer detailed advice or actionable steps for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that providing computation, algorithm, or implementation details would be beneficial for readers. However, it does not specify which parts of the paper these details should be included in or how they should be presented. The action is implicit and somewhat vague, as the authors are left to infer that they need to add these details but are not guided on how to do so. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that providing computation, algorithm, or implementation details would be beneficial for readers. However, it does not specify which part of the paper these details should be included in, making it weakly grounded. The comment is specific in suggesting what kind of details should be added, but without clear grounding, the authors may struggle to determine where these details should be incorporated. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that providing computation, algorithm, or implementation details would be beneficial for readers. However, it does not offer any specific reasoning, examples, or references to support why these details are necessary or how they would enhance the paper. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment suggests that providing computation, algorithm, or implementation details would be beneficial for readers. While it identifies a potential area for improvement, it lacks specificity and does not offer guidance on which details should be included or how they should be presented. The feedback is 3 as it points out a general area for enhancement, but it does not provide actionable steps or detailed suggestions for improvement. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly asks a question about the choice of p < 0.4 in Algorithm 1. This is a clear and direct request for clarification, providing the authors with a specific action to take. The comment is explicit and concrete, as it specifies exactly what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks a clear question about the choice of p < 0.4, which provides a direct point of focus for the authors to address. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the choice of p < 0.4 in Algorithm 1. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment is highly specific and actionable, as it directly questions the choice of p < 0.4 in Algorithm 1. This prompts the authors to provide a clear explanation or justification for this choice, which is crucial for the understanding and reproducibility of their work. By addressing this point, the authors can enhance the transparency and credibility of their methodology. The comment is clear and concise, offering a specific area for improvement that is directly relevant to the paper\"s content. Therefore, it is 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to provide explanations and analysis for Figures 1, 2, and 3 in Section 5. It also specifies the need to clarify the presence of negative numbers in Figure 1 and the implications of Figures 2 and 3. This feedback is clear and provides concrete actions for the authors to take, ensuring they know exactly what needs to be addressed in their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 5\" and \"Figures 1, 2, and 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what is missing\u2014explanations and analysis for the figures, as well as clarification on the negative numbers in Figure 1 and the implications of Figures 2 and 3. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors have failed to provide explanations or analysis for Figures 1, 2, and 3 in Section 5. It specifically mentions the need for clarification regarding negative numbers in Figure 1 and the implications of Figures 2 and 3. However, the comment does not provide any reasoning or examples to support why these explanations or analyses are necessary or how they would enhance the paper. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, specifically noting the absence of explanations or analysis for Figures 1, 2, and 3 in Section 5. It also highlights the need for clarification regarding negative numbers in Figure 1 and the implications of Figures 2 and 3. This feedback is clear and actionable, providing the authors with specific areas to address and improve their draft. By suggesting the inclusion of explanations and analysis, the comment offers a direct path for enhancing the paper\"s clarity and comprehensiveness. However, it could be more helpful if it provided guidance on how to approach these explanations or analysis. Overall, the comment is 4, as it effectively directs the authors to enhance their manuscript."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point highlights two areas for improvement: the lack of analysis on the effectiveness of each data augmentation method and the need to compare the approach to other paraphrasing methods, such as EDA or LLMbased paraphrasing. It suggests that references to specific works, such as 1 and 2, could provide additional context. While the comment implies that the authors should conduct a more comprehensive analysis and comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of analysis on the effectiveness of each data augmentation method, allowing the authors to identify the specific part of the paper being addressed. It also specifies the need for a comparison with other paraphrasing methods, such as EDA or LLMbased paraphrasing, to clarify the unique advantages of their method. The comment provides specific suggestions for improvement, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that there is insufficient analysis of the effectiveness of each data augmentation method and suggests comparing the approach to other paraphrasing methods, such as EDA or LLMbased paraphrasing. The comment provides references to specific works, 1 and 2, which could support the claim. However, the references are not directly cited within the text, making it somewhat challenging for the authors to fully understand the basis of the claim. Therefore, the comment is 4, as it provides some support but lacks detailed explanation or direct integration of the references within the text.", "helpfulness_rationale": "The review comment identifies a significant gap in the analysis of the paper, specifically the lack of analysis on the effectiveness of each data augmentation method. It suggests that comparing the approach to other paraphrasing methods, such as EDA or LLMbased paraphrasing, would clarify the unique advantages of the method. The comment provides specific references to relevant works, which can guide the authors in enhancing their analysis and understanding of their approach. This feedback is clear and actionable, offering a concrete direction for improvement that can significantly enhance the paper. Therefore, the comment is 5."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests conducting an ablation study to evaluate the net effect of each component in the proposed model. It provides specific examples of experiments that could be conducted, such as learning the model with a typical knowledge distillation loss or distilling a Hydra architecture with MMD loss. This feedback is explicit and provides concrete guidance on how to improve the draft by conducting additional experiments. The authors know exactly what actions to take to enhance their study, making this comment 5.", "grounding_specificity_rationale": "The comment suggests conducting an ablation study to evaluate the net effect of each component in the proposed model, specifically mentioning \"learning with MMD\" and \"typical knowledge distillation loss\" as examples. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or experiment. While the authors might infer that it relates to the methodology or results sections, the lack of explicit grounding makes it difficult to pinpoint the exact part of the paper being addressed. The comment is specific in suggesting the need for an ablation study and provides examples of experiments to consider, but the lack of explicit grounding limits its effectiveness. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests conducting an ablation study to evaluate the net effect of each component in the proposed model. It provides specific examples of experiments that could be conducted, such as learning the model with a typical knowledge distillation loss or distilling a Hydra architecture with MMD loss. However, the comment does not provide any supporting evidence or reasoning to justify why an ablation study is necessary or how it would improve the paper. The suggestion is logical but lacks detailed justification or examples, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment suggests conducting an ablation study to evaluate the net effect of each component in the proposed model. It provides specific examples of experiments that could be conducted, such as learning the model with a typical knowledge distillation loss or distilling a Hydra architecture with MMD loss. This feedback is clear and actionable, offering the authors a concrete way to improve their draft by providing a more comprehensive evaluation of their model. However, the comment could be more helpful if it explained why an ablation study is necessary or how it would enhance the understanding of the model\"s components. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the performance of a model that assigns all negative samples to a distractor class. While it implies that the authors should consider this scenario, it does not provide explicit guidance on how to address this question or what specific actions should be taken. The action is implicit and somewhat vague, as the authors are left to infer that they should investigate this scenario and potentially include it in their analysis. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment poses a question about the performance of a model that assigns all negative samples to a distractor class. However, it does not specify which part of the paper this question pertains to, such as a specific section, experiment, or analysis. Without explicit references or context, the authors cannot confidently determine where this question should be addressed in the paper. Additionally, the comment lacks specificity regarding what aspects of performance are being questioned or how this scenario relates to the overall study. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification on the performance of a specific model scenario. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment poses a question about the performance of a model that assigns all negative samples to a distractor class. While it highlights an interesting scenario that the authors might consider, it lacks specificity and does not provide any actionable feedback or suggestions for improvement. The comment does not offer guidance on how to address this scenario or why it is relevant to the paper. As a result, the authors are left without clear direction on how to enhance their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a trend in the performance of RLCD compared to RLAIF, noting that the advantage shrinks as the model size increases. It also raises a question about the scalability of RLCD to larger language models. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their draft. The action is implicit and vague, as it lacks concrete steps or recommendations for the authors to follow. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Tab. 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the observation about the shrinking advantage of RLCD over RLAIF as the model size increases, and it raises a question about the scalability of RLCD to larger language models. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the advantage of RLCD over RLAIF shrinks as the model size increases, referencing Table 2. However, it does not provide specific data or examples from Table 2 to support this claim, making it difficult for the authors to verify the assertion. The comment also raises a question about the scalability of RLCD to larger language models, but without further elaboration or evidence, it remains a speculative suggestion. Therefore, the comment is considered 2, as it provides some support but lacks detailed evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment highlights a trend in the performance of RLCD compared to RLAIF, noting that the advantage of RLCD over RLAIF shrinks as the model size increases. It raises a question about the scalability of RLCD to larger language models, suggesting that it remains to be seen whether RLCD (or RLCDRescore) can scale to yet larger language models. While the comment identifies an important observation and raises a relevant question, it lacks specific suggestions or guidance on how the authors might address this issue or improve their work. The feedback is 3 as it points out a potential limitation, but it could be more actionable with additional insights or recommendations. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies the lack of quantitative analysis on computational gains and suggests that specific measurements or comparisons should be included to substantiate the claims. It provides clear guidance by specifying what kind of quantitative analysis would be beneficial, such as GPU hours, memory usage, or training time. This feedback is explicit and concrete, giving the authors a direct and detailed action to take to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of quantitative analysis on computational gains, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely specific measurements or comparisons to substantiate the claimed computational benefits. The comment provides a clear direction for improvement by suggesting the inclusion of quantitative analysis, such as GPU hours, memory usage, or training time. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks specific measurements or comparisons to substantiate the claimed computational benefits of replacing the MAE model with a CNNbased data augmentation strategy. The reviewer suggests that a quantitative analysis, such as GPU hours, memory usage, or training time, would provide stronger evidence of the efficiency improvements in DQ V2. This claim is 4 as it provides a clear suggestion for what kind of evidence would strengthen the paper\"s claims. However, it lacks specific examples or references to existing literature or benchmarks that could further substantiate the need for such quantitative analysis. Therefore, the comment is categorized as 4.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of quantitative analysis on computational gains. It highlights the importance of specific measurements or comparisons to substantiate the claimed benefits of replacing the MAE model with a CNNbased data augmentation strategy. The suggestion to include quantitative analysis, such as GPU hours, memory usage, or training time, provides clear and actionable guidance for the authors to strengthen their claims and improve the robustness of their findings. This feedback is valuable as it directs the authors to a specific area for improvement, making it 4. However, it could be more helpful if it offered examples or references to similar studies that have successfully implemented such analyses. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the time taken by COLMAP and scenebyscene finetuning should be considered when comparing the method, as it renders the method less efficient for certain scenes. However, the comment does not provide explicit guidance on how the authors should account for this time or how it affects the efficiency comparison. The action is implicit and lacks concrete details on how to address the issue, making it 3.", "grounding_specificity_rationale": "The comment suggests that the time taken by COLMAP and scenebyscene finetuning should be considered when comparing the method, which implies that the efficiency of the method is being discussed. However, the comment does not specify which part of the paper this comparison is made in, nor does it provide details on what specific aspects of efficiency are being addressed. Without explicit references to sections or figures, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what needs to be addressed or improved in terms of efficiency. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the time taken by COLMAP and scenebyscene finetuning should be considered when comparing the method, implying that this factor affects the efficiency of the method. However, the comment does not provide any specific data, examples, or references to support this claim. Without detailed evidence or reasoning, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the efficiency of the method being evaluated, specifically mentioning the time taken by COLMAP and scenebyscene finetuning. This is a relevant observation that could impact the overall efficiency comparison of the method. However, the comment lacks specificity and does not provide actionable guidance on how the authors might address this issue or improve the efficiency comparison. Without detailed suggestions or examples, the authors are left with a general understanding of the problem but without clear steps to take to resolve it. Therefore, the comment is 3, as it highlights an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the timing of the results reporting, suggesting that the results are only presented after a significant amount of training has occurred. It speculates that early in training, the model parameters might be \"garbage\" and that the planning component of the network could potentially harm the performance. The reviewer wonders if the CNN could perform reasonably well with less data. While the comment implies that the authors should consider reporting results at different stages of training and potentially explore the performance of the CNN with less data, it does not provide explicit instructions or concrete steps for the authors to follow. The action is implicit and somewhat vague, making it barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the timing of the results reporting, suggesting that the results are only presented after a significant amount of training has occurred. It speculates that early in training, the model parameters might be \"garbage\" and that the planning component of the network could potentially harm the performance. The reviewer also wonders if the CNN could perform reasonably well with less data. However, the comment does not explicitly mention which part of the paper this issue pertains to, such as specific sections or figures where results are presented. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing the concern about the timing of results reporting and the potential impact of early training, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the timing of the results reporting, suggesting that the results are only presented after a significant amount of training has occurred. The reviewer speculates that early in training, the model parameters might be \"garbage\" and that the planning component of the network could potentially harm the performance. This is a subjective claim based on the reviewer\"s observations and assumptions, as it lacks specific evidence or references to support the assertion that the model parameters are \"garbage\" or that the planning component is detrimental. The comment also includes a question about the CNN\"s performance with less data, which is more of a request for clarification rather than a claim. Therefore, the comment is considered 2, as it provides some reasoning but lacks detailed evidence or references to fully substantiate the claims.", "helpfulness_rationale": "The review comment raises a concern about the timing of the results reporting, suggesting that the results are only presented after a significant amount of training has occurred. It speculates that early in training, the model parameters might be \"garbage\" and that the planning component of the network could potentially harm the performance. The reviewer also wonders if the CNN could perform reasonably well with less data. While the comment identifies a potential issue with the timing of results reporting and suggests exploring the performance of the CNN with less data, it lacks specific guidance or actionable steps for the authors to address these concerns. The feedback is 3 as it prompts the authors to consider alternative reporting methods and the impact of early training, but it could be more beneficial with additional detail or suggestions for improvement. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about how the authors handle concepts (multiple entity mentions referring to the same entity) in the DocRED dataset. It explicitly asks whether the documents are considered as an entire sentence and requests clarification on this aspect. While the comment does not provide specific guidance on how to address these questions, it does prompt the authors to consider and clarify these aspects in their manuscript. The action is explicit but somewhat vague, as it lacks detailed instructions on how to address the issues. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises questions about how the authors handle concepts (multiple entity mentions referring to the same entity) in the DocRED dataset. It explicitly mentions \"DocRED,\" providing full grounding as the authors can accurately identify the part of the paper being addressed. The comment is specific in its request for clarification on how the documents are considered and how concepts are handled. However, it does not specify where in the manuscript this information is currently missing, which would make it 5. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions seeking clarification on how the authors handle concepts (multiple entity mentions referring to the same entity) in the DocRED dataset. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises important questions about how the authors handle concepts (multiple entity mentions referring to the same entity) in the DocRED dataset. It specifically asks whether the documents are considered as an entire sentence and requests clarification on this aspect. This feedback is valuable as it prompts the authors to address a potential gap in their manuscript, which could lead to a more comprehensive understanding of their methodology. However, the comment could be more helpful if it provided specific suggestions or examples on how to address these questions. Overall, the comment is 3 as it identifies a critical area for clarification but lacks detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the clarity of the main contribution, specifically questioning the motivation behind the PBSD component. It suggests that the performance gain is mostly attributed to PBSD, which is a component related to supervised contrastive learning (DSCL). The reviewer asks for additional motivations for PBSD beyond improving the discriminative power of the learned representation on tail classes. While the comment implies that the authors should clarify the contribution and motivation of PBSD, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed explanations. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the main contribution of the paper, specifically questioning the motivation behind the PBSD component. It references the ablation study, which suggests that the performance gain is mostly from PBSD, and asks for additional motivations beyond improving the discriminative power of the learned representation on tail classes. However, the comment does not explicitly mention which section of the paper discusses the main contribution or the ablation study, making it weakly grounded. The comment is specific in detailing what needs to be addressed regarding the motivation for PBSD. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a claim about the main contribution of the paper being unclear, specifically questioning the motivation behind the PBSD component. The reviewer provides a logical reasoning by pointing out that the performance gain is mostly attributed to PBSD, which is a component related to supervised contrastive learning (DSCL). However, the comment lacks specific examples or references to support the claim that the DSCL part is the primary motivation. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, specifically the lack of clarity regarding the main contribution. It points out that the performance gain is mostly attributed to the PBSD component, which is related to supervised contrastive learning (DSCL). The reviewer questions the motivation for PBSD beyond improving the discriminative power of the learned representation on tail classes. This feedback is 3 as it prompts the authors to clarify the main contribution and motivation of their work. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or offered examples of how to better articulate the contribution. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the tester for the spread parameter immediately yields an (\u03f5,\u03b4)identity tester as well. It specifically mentions a scenario where the distance between two distributions is large, suggesting that the tester might not handle this case. While the comment implies that the authors should clarify this aspect, it does not provide explicit instructions on how to address the issue or what specific steps to take. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the relationship between the tester and the (\u03f5,\u03b4)identity tester. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether the tester for the spread parameter immediately yields an (\u03f5,\u03b4)identity tester and provides a specific example involving (\u03c0,\u03d5) pairs where \u03d5=\u03d50 but dK(\u03c00,\u03c0) is large. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the relationship between the tester for the spread parameter and the (\u03f5,\u03b4)identity tester. It provides a specific example involving (\u03c0,\u03d5) pairs where \u03d5=\u03d50 but dK(\u03c00,\u03c0) is large, suggesting that the tester might not handle this case. However, the comment lacks detailed reasoning or references to support the claim that the tester does not immediately yield an (\u03f5,\u03b4)identity tester. The authors would need to infer the issue and potentially conduct additional analysis to address it. Therefore, the comment is 3, as it provides a basis for the claim but requires further elaboration or evidence to be fully substantiated.", "helpfulness_rationale": "The review comment raises a question about the relationship between the tester for the spread parameter and the (\u03f5,\u03b4)identity tester. It specifically points out a scenario where the distance between two distributions is large, suggesting that the tester might not handle this case. This feedback is 3 as it identifies a potential gap in the paper and prompts the authors to clarify or address this issue. However, the comment could be more helpful if it provided additional guidance on how to resolve this concern or suggested specific steps for improvement. Overall, the comment is 3, as it directs the authors\" attention to a specific area that needs clarification but lacks detailed guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a lack of clarity regarding the detailed distribution of the proposed dataset. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on what specific information should be included or how the authors should present the distribution. Without actionable suggestions or concrete steps, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a lack of clarity regarding the detailed distribution of the proposed dataset. However, it does not specify which part of the paper this issue pertains to, such as a specific section or table where the distribution is discussed. Without explicit references or context, the authors cannot confidently determine which part of the paper needs revision. Additionally, the comment lacks specificity regarding what aspects of the distribution are unclear or what additional information is needed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the detailed distribution of the proposed dataset is unclear. However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific area of concern regarding the detailed distribution of the proposed dataset, which is an important aspect of the paper. However, it lacks depth and does not provide any suggestions or guidance on how the authors might clarify or improve this aspect of their work. Without actionable feedback or specific recommendations, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, the comment is 2, as it points out a problem but does not offer a path to resolution."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the proposed method is limited to supervised training due to the need for annotated labels for learning semantic tokens. It implies that a selfsupervised pretraining approach without annotations could be more appealing. While the comment highlights a potential limitation and suggests an alternative approach, it does not provide explicit guidance on how to implement this suggestion or what specific changes should be made to the draft. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps without detailed instructions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the proposed method is limited to supervised training due to the need for annotated labels for learning semantic tokens. It implies that a selfsupervised pretraining approach without annotations could be more appealing. However, the comment does not specify which part of the paper discusses the proposed method or where the limitation is mentioned. This makes it difficult for the authors to pinpoint the exact section that needs attention. Additionally, while the comment provides a suggestion for improvement, it lacks specificity in detailing how the authors might implement a selfsupervised approach or what specific aspects of the current method need to be addressed. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the proposed method is limited to supervised training due to the need for annotated labels for learning semantic tokens. It suggests that a selfsupervised pretraining approach without annotations could be more appealing. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that a selfsupervised approach would be more appealing. The lack of evidence or detailed justification makes it difficult for the authors to understand and address the critique effectively. Therefore, the comment is considered 2, as it provides a general suggestion but lacks the necessary details to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a limitation of the proposed method, which requires annotated labels for learning semantic tokens, thereby limiting its application to supervised training. It suggests that a selfsupervised pretraining approach without annotations could be more appealing. While the comment highlights a potential area for improvement, it lacks specific guidance or suggestions on how the authors might implement a selfsupervised approach or address the limitation. The feedback is 3 as it points out a weakness but does not provide actionable steps for improvement, leaving the authors with a general direction but no detailed guidance. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should demonstrate the scalability of their method, LFF, by showing its effectiveness on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. This is an explicit suggestion that provides a clear direction for the authors to expand their experiments. However, the comment does not specify how the authors should implement this suggestion, such as which specific tasks to consider or how to measure scalability. While the action is explicit, the lack of concrete guidance makes it 3.", "grounding_specificity_rationale": "The comment suggests that the authors should demonstrate the scalability of their method, LFF, by showing its effectiveness on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting the types of tasks that could be used to demonstrate scalability, but without explicit references to sections or figures, the authors may find it challenging to pinpoint where to incorporate this feedback. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that continuous control experiments are typically performed on simple and lowdimensional tasks, such as cartpole or mountain car, and recommends demonstrating the scalability of LFF by applying it to more challenging tasks with higher input dimensionality, such as locomotion of ants or humanoids. This claim is 3 as it provides a logical reasoning for the suggestion, noting the current limitations of the experiments and proposing a way to address them. However, the comment lacks specific examples or references to support the claim about the challenges of higher input dimensionality tasks, which would strengthen the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation in the current experiments, noting that most continuous control experiments are performed on simple and lowdimensional tasks. It suggests that to fully demonstrate the scalability of the proposed method, LFF, the authors should show its effectiveness on more challenging tasks with higher input dimensionality, such as locomotion of ants or humanoids. This feedback is clear and actionable, as it provides a specific direction for the authors to expand their experiments and demonstrate the broader applicability of their method. However, the comment could be more helpful if it offered guidance on how to design or conduct these more complex experiments. Overall, the comment is 4, as it effectively points out a gap in the current work and provides a clear path for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests two specific changes: first, to include a statement about the change in linear regions in output space after a citation in the abstract, and second, to provide learning curves for all experiments in an appendix. Both suggestions are explicit and provide clear guidance on what the authors need to do to improve their draft. The feedback is concrete and actionable, as it specifies exactly what needs to be added or included. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for improving the abstract by including a statement about the change in linear regions in output space after a citation. Additionally, it suggests including learning curves for all experiments in an appendix. This level of detail and specificity helps the authors understand exactly what needs to be addressed and how to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests a change in the abstract by recommending the inclusion of a specific statement about the change in linear regions in output space after a citation. It also suggests providing learning curves for all experiments in an appendix. While the comment provides a clear suggestion for improvement, it lacks detailed reasoning or evidence to support why these changes are necessary or beneficial. The suggestion is 3, as it offers a specific direction for improvement but does not fully justify the need for these changes. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting a change in the abstract to include a statement about the change in linear regions in output space after a citation. This recommendation would help clarify the paper\"s contribution and enhance its clarity. Additionally, the comment suggests including learning curves for all experiments in an appendix, which would provide a more comprehensive view of the results. This feedback is clear and offers concrete steps for improvement, making it 5 for the authors. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the paper considers MULT as the only deep learningbased baseline that considers crosssensory interaction, despite the fact that it was proposed in 2019 and is considered \"out of fashion.\" However, the comment does not provide any explicit or implicit actions for the authors to take. It does not suggest alternative baselines, recommend updating the literature review, or provide guidance on how to address this issue. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the paper \"MISA: ModalityInvariant and Specific Representations for Multimodal Sentiment Analysis, ACM MM 2020,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the paper considers MULT as the only deep learningbased baseline that considers crosssensory interaction, despite the fact that it was proposed in 2019 and is considered \"out of fashion.\" This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper considers MULT as the only deep learningbased baseline that considers crosssensory interaction, despite the fact that it was proposed in 2019 and is considered \"out of fashion.\" However, the comment does not provide any supporting evidence, references, or reasoning to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that the paper considers MULT as the only deep learningbased baseline that considers crosssensory interaction, despite the fact that it was proposed in 2019 and is considered \"out of fashion.\" This observation highlights a potential weakness in the paper\"s literature review, as it may not be uptodate with the latest developments in the field. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or update their literature review. While it identifies a relevant area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 3, as it provides some insight but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the comparison against other models in the experiments is unclear due to the omission of the value of the used ranks for all the models. It provides a clear action for the authors to take, which is to compare the tensor completion results for all the models with the same number of model parameters. The reviewer suggests a method for computing the number of model parameters, which is a concrete step for the authors to follow. This feedback is explicit and provides detailed guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiments\" and \"tensor completion results,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the comparison against other models, namely the omission of the value of the used ranks for all the models, which makes it difficult to make a fair comparison. The comment further suggests a method for computing the number of model parameters, providing a concrete step for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the comparison against other models in the experiments is unclear due to the omission of the value of the used ranks for all the models. The reviewer suggests that to show the superiority of TW over TT and TR, the authors must compare the tensor completion results for all the models with the same number of model parameters. This claim is 3 as it provides a logical reasoning for the need to include the value of the used ranks and suggests a method for fair comparison. However, the comment lacks specific examples or references to support the claim fully, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the experimental comparison, noting that the value of the used ranks for all the models is omitted, making it difficult to make a fair comparison. It provides a clear and actionable suggestion for improvement by recommending that the authors compare the tensor completion results for all the models with the same number of model parameters. This feedback is valuable as it guides the authors on how to enhance the clarity and fairness of their experimental results. However, the comment could be more helpful if it included specific examples or detailed guidance on how to compute the number of model parameters. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two issues: the normalization module appearing different in the two versions, despite the text suggesting it is the same, and the need for standardization of pictograms in figures. It also mentions a confusion in Figure 4 regarding the 0/50 latency range and the 2.5/4.0 MAE, where the chosen symbols overlap. Additionally, it notes minor textual issues on page 4. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to address these issues, such as suggesting ways to standardize the pictograms or clarify the symbols in Figure 4. The authors can infer that they need to make these changes, but the lack of concrete guidance makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 4\" and \"pag. 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the normalization module, the need for standardization of pictograms in figures, and the confusion in Figure 4 regarding the 0/50 latency range and the 2.5/4.0 MAE. Additionally, it points out minor textual issues on page 4. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point raises several claims, including the need for standardization of pictograms in figures and the confusion in Figure 4 regarding the 0/50 latency range and the 2.5/4.0 MAE. However, the comment lacks specific reasoning or examples to support these claims, such as explaining why the normalization module appears different in the two versions or how the standardization of pictograms would improve the figures. Without detailed justification or evidence, the claims remain vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies several issues with the paper, including a discrepancy in the normalization module between the two versions, the need for standardization of pictograms in figures, and confusion in Figure 4 regarding the 0/50 latency range and the 2.5/4.0 MAE. It also mentions minor textual issues on page 4. While the comment highlights specific areas for improvement, it lacks detailed guidance or suggestions on how to address these issues, such as proposing specific changes to the normalization module or providing examples of how to standardize pictograms. The feedback is 3 as it points out areas that need attention, but it could be more actionable with additional details or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the author\"s claim regarding the removal of subdivision splines and the potential extra computation cost involved. It questions whether the proposed algorithm is detailed enough to remove these splines and addresses a specific aspect of the theoretical part of the paper. While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this concern. The action is implicit and somewhat vague, as it points out a gap in the theoretical explanation but does not offer concrete steps for improvement. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"theoretical part\" of the paper, allowing the authors to accurately identify the section being addressed. It is also specific because it questions the detailed explanation of the proposed algorithm and its potential impact on computation cost. The comment clearly specifies what needs to be addressed, namely, the lack of detailed explanation regarding the removal of subdivision splines and the potential extra computation cost. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the author\"s claim about the removal of subdivision splines and the potential extra computation cost involved. It highlights a gap in the theoretical explanation of the proposed algorithm, suggesting that the authors should provide more details on how the algorithm removes subdivision splines. The comment is 3 as it identifies a specific area of concern and points out a potential issue, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to address this gap in the theoretical explanation to fully understand and respond to the comment. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the theoretical part of the paper, where the authors claim that subdivision splines can be removed to find winning tickets, but the proposed algorithm is not detailed enough to explain how this removal is achieved. The comment raises a pertinent question about the potential extra computation cost involved in this process. This feedback is clear and actionable, as it highlights a gap in the theoretical explanation that the authors need to address. By pointing out this issue, the comment provides the authors with a specific area to improve their draft, making it 4. However, it could be more helpful if it offered suggestions on how to address the computation cost concern or provided examples of similar approaches. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that certain terms, such as W1, W2, W, and V, are not defined in the paper. It suggests that these terms might refer to the Encoder and Decoder networks, but this inference is not explicitly stated. The comment provides a clear indication of what needs to be addressed, which is the definition of these terms. However, it lacks specific guidance on how to define them or where to include the definitions in the paper. While the action is implicit, it is concrete once the authors understand the issue. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper where terms are not defined, such as \"p.3, A4, eq.3.\" This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what is missing, namely the definitions of W1, W2, W, and V. This provides clear guidance on what needs to be addressed to improve the draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements about the absence of definitions for certain terms (W1, W2, W, and V) in the paper. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a significant issue by pointing out that certain terms, such as W1, W2, W, and V, are not defined in the paper. This is a critical oversight that can lead to confusion for readers. The comment provides specific examples of where these terms are used, allowing the authors to easily locate and address the issue. By highlighting the need for definitions, the comment offers clear and actionable feedback that can help the authors improve the clarity and comprehensibility of their draft. However, the comment could be more helpful if it suggested where these definitions should be included or provided examples of how they might be defined. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the process of generating negative chips from a lightweight RPN. It asks whether these negative chips are fixed or updated during the training of the RPN. Additionally, it inquires if alternating between generating negative chips and training the network would improve performance. While the comment does not explicitly instruct the authors to provide clarification or conduct an experiment, it does imply that the authors should address these questions to improve the clarity and understanding of their work. The action is implicit but concrete, as it suggests that the authors should clarify the process and potentially explore the impact of alternating between these steps. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment raises a question about the process of generating negative chips from a lightweight RPN, specifically asking whether these chips are fixed or updated during training. It also inquires about the potential impact of alternating between generating negative chips and training the network on performance. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The authors might infer that it relates to the methodology or experimental design sections, but this is not explicitly stated. The comment is specific in its inquiry about the process and potential impact, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point consists of a series of questions seeking clarification about the process of generating negative chips from a lightweight RPN and the potential impact of alternating between generating negative chips and training the network. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises an important question about the process of generating negative chips from a lightweight RPN, specifically asking whether these chips are fixed or updated during training. It also inquires about the potential impact of alternating between generating negative chips and training the network on performance. While the comment identifies a potential area of confusion or improvement, it lacks specific suggestions or guidance on how the authors might address this issue. The feedback is 3 as it prompts the authors to clarify their methodology, but it could be more actionable with additional details or suggestions. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the applicability of the proposed approach to patients who are firsttime visitors without historical reports. It suggests that the authors should evaluate the approach on both new and old patients. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to conduct these evaluations or what metrics to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the applicability of the proposed approach to patients who are firsttime visitors without historical reports. It suggests that the authors should evaluate the approach on both new and old patients. However, the comment does not specify which part of the paper this issue pertains to, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but the lack of explicit reference makes it challenging to pinpoint the exact location. The comment is specific in suggesting a particular evaluation, but without grounding, it is difficult for the authors to address it effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the applicability of the proposed approach to patients who are firsttime visitors without historical reports. It suggests that the authors should evaluate the approach on both new and old patients. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this evaluation is necessary or how it would impact the study. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a valid concern about the applicability of the proposed approach to patients who are firsttime visitors without historical reports. It suggests that the authors should evaluate the approach on both new and old patients to ensure its effectiveness in different scenarios. This feedback is 3 as it identifies a potential limitation in the study and provides a clear direction for further evaluation. However, the comment could be more helpful if it offered specific suggestions on how to conduct these evaluations or what metrics to focus on. Overall, the comment provides a useful insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper lacks an indepth analysis of why inverse scaling occurs over compute. It implies that the authors should provide an analysis to explain this training dynamic, which would strengthen the paper. While the comment explicitly states the need for an analysis, it does not provide specific guidance on how to conduct this analysis or what aspects to focus on. The action is clear but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment suggests that the paper lacks an indepth analysis of why inverse scaling occurs over compute. It implies that the authors should provide an explanation for this training dynamic. However, the comment does not specify which part of the paper lacks this analysis, making it weakly grounded. The authors might infer that it relates to the experimental results or methodology sections, but this is not explicitly stated. The comment is specific in suggesting the need for an analysis, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point claims that the paper lacks an indepth analysis of why inverse scaling occurs over compute. It suggests that providing such an analysis would strengthen the paper. However, the comment does not offer any specific reasoning, examples, or references to support the claim that an indepth analysis is necessary or how it would improve the paper. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a lack of indepth analysis in the paper, specifically regarding the inverse scaling over compute. It suggests that the authors should provide an analysis to explain this training dynamic, which would strengthen the paper. While the comment highlights an important area for improvement, it does not provide specific guidance or suggestions on how to conduct this analysis or what aspects to focus on. The feedback is 3 as it points out a gap in the paper but lacks depth and actionable advice, making it difficult for the authors to fully address the issue. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out a lack of mathematical definition for architectural details, such as multihead attention, and questions the split arrow in Figure 2. It suggests that the authors provide a formal definition to help readers understand the model better. The comment is explicit in its request for a mathematical definition and provides a specific example to clarify, making it 5. The authors know exactly what needs to be done to improve their draft by providing the requested formal definition.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2 right, bottom right,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely a formal definition of the architectural details, such as multihead attention, and questions about the split arrow in Figure 2. The comment provides a clear direction for improvement by suggesting that a formal definition would help readers understand the model better. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the lack of mathematical definition for architectural details, specifically mentioning multihead attention. It also asks for clarification about the split arrow in Figure 2, suggesting that it represents inputs for the attention layer. The comment provides a logical reasoning by pointing out the need for formal definitions to aid reader understanding. However, it lacks specific references or examples from the literature to fully substantiate the claim. While the reasoning is sound, the absence of detailed references or examples makes the claim 3, as it requires additional effort from the authors to fully understand and address the feedback.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks mathematical definition, particularly in the architectural details of the model, such as multihead attention. It questions the split arrow in Figure 2 and suggests that it represents inputs for the attention layer, asking whether the same vectors are used for keys and values. The comment provides a clear and actionable suggestion by recommending a formal definition to help readers understand the model better. This feedback is valuable as it directs the authors to enhance the clarity and comprehensiveness of their work. However, it could be more helpful if it included specific guidance on how to provide this formal definition. Overall, the comment is 4, as it effectively points out a gap in the paper and offers a constructive suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the assumption that each individual\"s data is iid drawn from the same distribution, which is necessary for the proposed algorithm to work. The reviewer questions the validity of this assumption and suggests that it is unjustifiable in practice. While the comment highlights a potential issue with the algorithm\"s assumptions, it does not provide explicit guidance on how the authors should address this concern or suggest alternative approaches. The action is implicit and somewhat vague, as the authors are left to infer that they need to justify or revise the assumption, but without concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 5.1\" and \"Theorem 6 and Theorem 7,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the proposed algorithm, namely the assumption that each individual\"s data is iid drawn from the same distribution, and questions the validity of this assumption in practice. The comment provides a detailed critique of the theoretical foundation of the algorithm, which helps the authors understand the specific areas that need attention. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a claim about the assumption that each individual\"s data is iid drawn from the same distribution, which is necessary for the proposed algorithm to work. The reviewer questions the validity of this assumption, suggesting that it is unjustifiable in practice due to the diversity of users\" preferences. The comment provides a logical reasoning by pointing out the inconsistency between the theoretical assumption and practical reality, which is a common issue in many machine learning applications. However, the comment could be strengthened by providing specific examples or references to support the claim further. Overall, the claim is 4, as it provides a logical argument but lacks detailed evidence or references, aligning with a score of 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed algorithm, specifically questioning the assumption that each individual\"s data is iid drawn from the same distribution. This is a critical point that could impact the validity of the results and the theoretical foundation of the algorithm. The reviewer provides a logical reasoning by questioning how Theorem 6 can be applied to prove Theorem 7 without this assumption. Additionally, the comment highlights a practical concern by suggesting that users\" preferences for emojis are likely to be different, making the assumption less justifiable. While the comment effectively points out a significant flaw in the algorithm\"s assumptions, it could be more helpful by suggesting alternative approaches or ways to address this issue. Overall, the feedback is 4 as it provides clear insights into a critical area that needs attention, but it could be more comprehensive with additional guidance on how to resolve the issue."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should consider making the policy nonfixed to allow for more complex tasks, as described in the last paragraph of the paper. It implies that the authors should compare their results with a reinforcement learning algorithm baseline. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors to make this change or to include a specific comparison. The action is implicit and somewhat vague, as the authors need to infer that they should modify the policy and conduct a comparison. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the setting with a fixed policy is a subset of reinforcement learning and implies that the authors should consider making the policy nonfixed to allow for more complex tasks. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the discussion of the policy, but the lack of explicit grounding makes it difficult to pinpoint the exact part of the paper being addressed. The comment is specific in suggesting a way to enhance the complexity of the tasks and compare with a reinforcement learning baseline, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the setting with a fixed policy is a subset of reinforcement learning and implies that the authors should consider making the policy nonfixed to allow for more complex tasks. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this suggestion is necessary or beneficial. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the setting with a fixed policy is a subset of reinforcement learning and implies that the authors should consider making the policy nonfixed to allow for more complex tasks. It also suggests that the authors should compare their results with a reinforcement learning algorithm baseline. While the comment identifies a potential area for improvement by suggesting a more complex setting and a comparison with a reinforcement learning baseline, it lacks specific guidance on how to implement these suggestions or what aspects of the policy should be made nonfixed. The feedback is 3 as it provides a direction for enhancing the paper, but it could be more actionable with additional details or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the paper primarily focuses on explaining multitask models, which limits its applicability. However, it does not provide any explicit or implicit actions for the authors to take to address this limitation. There is no guidance on how to broaden the applicability or what specific changes should be made to improve the paper. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment suggests that the paper primarily focuses on explaining multitask models, which limits its applicability. However, it does not specify which part of the paper this focus is discussed in, nor does it provide details on how the applicability could be broadened. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention. Additionally, the comment lacks specificity regarding what aspects of applicability are limited or how they could be improved. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper primarily focuses on explaining multitask models, which limits its applicability. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references to what aspects of applicability are limited or how the focus could be broadened, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment points out that the paper primarily focuses on explaining multitask models, which limits its applicability. However, it does not provide any specific suggestions or guidance on how the authors might broaden the applicability or address this limitation. Without actionable feedback or detailed advice, the comment lacks depth and does not offer much value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the literature review, noting that it ignores several papers that are relevant to the topic. It suggests that the authors should consider including papers like VRMARINA and DASHAMVR, which satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. While the comment implies that the authors should expand their literature review to include these papers, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add these references to their literature review. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"next section\" and the \"literature review,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the literature review, namely the omission of relevant papers like VRMARINA and DASHAMVR, which satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. The comment provides specific examples of papers that should be included, which helps the authors understand what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the literature review ignores several papers that are relevant to the topic, specifically mentioning VRMARINA and DASHAMVR. The reviewer provides a specific reason for the omission, stating that these papers satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. This reasoning is clear and provides a logical basis for the claim, making it 4. However, the comment could be strengthened by including references or citations to these papers, which would fully verify the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the literature review, noting that it ignores several papers that are relevant to the topic. It provides specific examples of papers, VRMARINA and DASHAMVR, which satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. This feedback is clear and actionable, as it directs the authors to expand their literature review to include these relevant works. By doing so, the authors can ensure their paper is more comprehensive and uptodate. However, the comment could be more helpful if it explained why these papers are relevant or how they relate to the current work. Overall, the comment is 4 as it provides specific guidance for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point consists of two questions: the first asks for additional insights into modest performance gains on Clothing1M, and the second inquires about the algorithm\"s performance on other realworld datasets like WebVision, evaluated by DivideMix. These questions are explicit and seek specific information from the authors. However, they do not provide any guidance or suggestions on how the authors should address these questions or improve their draft. The lack of actionable advice makes it difficult for the authors to know exactly what steps to take in response to the questions. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment consists of two questions, each of which seeks additional information or clarification. The first question asks for insights into modest performance gains on Clothing1M, while the second inquires about the algorithm\"s performance on other realworld datasets like WebVision, evaluated by DivideMix. However, the comment does not specify which part of the paper these questions pertain to, making it difficult for the authors to identify the exact sections that need attention. Additionally, while the questions are specific in nature, they lack grounding as they do not point to a particular part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of two questions seeking additional insights and performance evaluations. It does not contain any claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the \"No\" label.", "helpfulness_rationale": "The review comment consists of two questions seeking additional insights and performance evaluations. While it prompts the authors to provide more information, it does not offer any specific suggestions or guidance on how to improve the draft. The questions are relevant and could lead to valuable additions to the paper, but without actionable feedback or suggestions, the comment is 3. The authors are left with a clear understanding of what information is needed but without a clear path to address it. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should conduct additional experiments on different famous LLMs, such as LLaMA and Falcon, to serve as benchmark baselines. While the comment implies that the authors should expand their experimental scope, it does not provide specific guidance on which LLMs to focus on, how to conduct the experiments, or what specific aspects to test. The action is implicit and somewhat vague, as the authors need to infer the details of the suggested experiments. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should conduct additional experiments on different famous LLMs, such as LLaMA and Falcon, to serve as benchmark baselines. However, it does not specify which part of the paper this suggestion pertains to, making it difficult for the authors to identify the exact section that needs revision. The comment is specific in suggesting the need for additional experiments but lacks grounding as it does not reference a particular section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should conduct additional experiments on different famous LLMs, such as LLaMA and Falcon, to serve as benchmark baselines. The comment provides a logical reasoning for this suggestion, as it highlights the importance of including a broader range of LLMs to ensure comprehensive evaluation. However, it lacks specific examples or references to support the claim that these additional LLMs are necessary or relevant. This makes the claim 3, as the authors would need to further justify the inclusion of these specific LLMs in their experiments. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper\"s experimental scope by suggesting that the authors should include additional experiments on different famous LLMs, such as LLaMA and Falcon, to serve as benchmark baselines. This feedback is 3 as it points out an area for improvement, encouraging the authors to broaden their experimental evaluation to include more diverse LLMs. However, the comment lacks specific guidance on how to conduct these additional experiments or what specific aspects to focus on, which could be beneficial for the authors. Therefore, the comment is rated as 3, as it provides a direction for improvement but lacks detailed actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the paper should describe the hyperparameters used by each defense and how they are derived. It also suggests that a maximally charitable evaluation would involve optimizing hyperparameters against the attack and showing the amount of clean data needed to remove the attack. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what needs to be added to their draft. The comment is explicit and detailed, making it 5.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the description of hyperparameters used by each defense and how they are derived. It also suggests a maximally charitable evaluation of defenses, which involves optimizing hyperparameters against the attack and showing the amount of clean data needed to remove the attack. However, the comment does not explicitly mention which part of the paper this issue pertains to, such as a particular section or table. While the authors can infer that it relates to the methodology or results sections, the lack of explicit grounding makes it weakly grounded. The comment is specific in detailing what needs to be addressed, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that the paper lacks information on hyperparameters used by each defense and how they are derived. It suggests that a maximally charitable evaluation would involve optimizing hyperparameters against the attack and showing the amount of clean data needed to remove the attack. While the comment provides a logical reasoning for why this information is important, it does not include specific examples or references to support the claim. This makes the claim 3, as the authors would need to infer the importance of these details based on the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical gap in the paper regarding the description of hyperparameters used by each defense and how they are derived. It suggests that a maximally charitable evaluation would involve optimizing hyperparameters against the attack and showing the amount of clean data needed to remove the attack. This feedback is clear and actionable, providing the authors with specific guidance on what information is missing and how to improve their analysis. By addressing these points, the authors can enhance the comprehensiveness and rigor of their defense evaluation. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the choice of mean pooling for tokens and suggests considering other pooling strategies. While it implies that the authors should explore alternative pooling methods, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to explore or evaluate other pooling strategies. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L235,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the choice of mean pooling for tokens and suggests considering other pooling strategies. The comment provides a clear direction for the authors to explore alternative approaches, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the choice of mean pooling for tokens and suggests considering other pooling strategies. However, it does not provide any specific reasoning, examples, or references to support why mean pooling might not be the best choice or how other pooling strategies could be beneficial. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a question about the choice of mean pooling for tokens, suggesting that other pooling strategies could be considered. While it identifies a potential area for improvement, it lacks depth and does not provide specific guidance or examples of alternative pooling strategies that could be explored. The comment is 3 as it prompts the authors to consider other options, but it does not offer detailed suggestions or actionable steps for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that, in addition to the number of queries, the real search cost (e.g., in terms of GPU days) should be compared in Table 3. This comment explicitly states an action for the authors to take, which is to include the real search cost in their comparison. However, it does not provide specific guidance on how to calculate or present this information, leaving some room for interpretation. While the action is clear, the lack of detailed instructions makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests comparing the real search cost (e.g., in terms of GPU days) in addition to the number of queries. This provides clear guidance on what needs to be addressed in the table. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that, in addition to the number of queries, the real search cost (e.g., in terms of GPU days) should be compared in Table 3. This is a suggestion for improvement, not a claim or opinion that requires verification. It is a request for additional information to be included in the table, which is a factual statement. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the paper. It identifies a particular table (Table 3) and suggests comparing the real search cost, such as in terms of GPU days, in addition to the number of queries. This feedback is clear and offers a concrete way for the authors to enhance their analysis and presentation of results. By addressing this suggestion, the authors can provide a more comprehensive and detailed evaluation of their work. However, the comment could be more helpful if it explained why this comparison is important or how it would benefit the paper. Overall, the comment is 4 as it guides the authors toward a specific improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the training details of the VQGAN model, specifically whether it is pretrained or only trained on the 88,635 images from the Computer Vision Figures dataset. While the comment implies that the authors should provide these details, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include this information. However, the comment does provide a clear direction on what details are missing, which makes it 3. Therefore, this comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment raises a question about the training details of the VQGAN model, specifically whether it is pretrained or only trained on the 88,635 images from the Computer Vision Figures dataset. While it does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or experimental setup sections. The comment is specific in its request for clarification on the training details, providing clear guidance on what information is missing. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the training details of the VQGAN model, specifically whether it is pretrained or only trained on the 88,635 images from the Computer Vision Figures dataset. This is a factual question seeking clarification, rather than a claim or opinion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the training details of the VQGAN model, asking whether it is pretrained or only trained on the 88,635 images from the Computer Vision Figures dataset. This is a clear and actionable request for clarification, as it prompts the authors to provide additional information that could be crucial for understanding the model\"s training process. By addressing this point, the authors can enhance the transparency and comprehensiveness of their methodology section. However, the comment could be more helpful if it provided context or explained why this information is important. Overall, the feedback is 4 as it directs the authors to a specific area needing clarification, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the proposed methods, DualIS and DualDIS, noting that they do not perform well on some crossmodel retrieval tasks, as evidenced by the performance in MSVD (Table 3). However, the comment does not provide any explicit or implicit suggestions for improvement or guidance on how the authors might address this issue. It lacks actionable details, such as recommending alternative approaches or suggesting ways to enhance the methods\" performance. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"DualIS and DualDIS\" and \"MSVD (Table 3),\" allowing the authors to accurately identify the specific parts of the paper being addressed. It also specifies the issue by pointing out that the proposed methods do not perform well on some crossmodel retrieval tasks, as evidenced by the performance in MSVD. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed methods, DualIS and DualDIS, are not generic on some crossmodel retrieval tasks, citing the performance in MSVD (Table 3) as evidence. However, the comment does not provide specific details or examples of how the performance is lacking or what aspects of the methods are not generic. This lack of detailed explanation or references makes it difficult for the authors to understand and address the issue. Therefore, the claim is considered 2, as it provides some evidence but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment points out a specific issue with the proposed methods, DualIS and DualDIS, noting that they do not perform well on some crossmodel retrieval tasks, as evidenced by the performance in MSVD (Table 3). This feedback is 3 as it identifies a potential weakness in the paper\"s methodology, prompting the authors to consider whether their methods are applicable to a broader range of tasks. However, the comment lacks actionable suggestions or guidance on how the authors might address this issue or improve the performance of their methods. To be more helpful, the comment could include recommendations for alternative approaches or ways to enhance the methods\" performance. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights an incomplete study, specifically noting that the relationship between the top selected patches and the disease has not been established. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to establish this relationship, what specific steps should be taken, or what additional analysis or experiments might be necessary. As a result, the authors are left without a clear understanding of how to improve their draft in response to this feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights an issue with the study, specifically noting that the relationship between the top selected patches and the disease has not been established. However, it does not specify which part of the paper this issue pertains to, such as a particular section, table, or figure. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what needs to be addressed or how to establish this relationship. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the study is incomplete because the relationship between the top selected patches and the disease has not been established. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the study, noting that the relationship between the top selected patches and the disease has not been established. This is a critical observation that highlights a fundamental weakness in the paper, as understanding this relationship is crucial for the validity and applicability of the study. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this issue. Without detailed feedback or suggestions for improvement, the authors are left with a general understanding of the problem but without a clear path forward. Therefore, the comment is 3, as it points out a significant issue but does not fully support the authors in resolving it."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a discrepancy between the theme of the paper and the performance of FedSP in Tables 1 and 2 on certain datasets. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting ways to improve the performance of FedSP or explaining the discrepancy. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment refers to the performance of FedSP in Tables 1 and 2, indicating that it is not the best on some datasets. However, it does not specify which part of the paper these tables are located in, making it difficult for the authors to pinpoint the exact section being addressed. The comment is specific in pointing out the performance issue but lacks grounding as it does not explicitly mention the section or table numbers. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the performance of FedSP is not the best in Table 1 and Table 2 on some datasets, suggesting a discrepancy between the theme of the paper and the actual performance. However, the comment lacks specific examples or detailed comparisons to support this claim. Without concrete evidence or references to the datasets or performance metrics, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 2, as it provides some insight but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment points out a discrepancy between the theme of the paper, which is primarily about FedSP, and the performance of FedSP in Tables 1 and 2 on certain datasets. This observation highlights a potential issue with the paper\"s focus and the accuracy of its claims. However, the comment does not provide any actionable suggestions or guidance on how the authors might address this discrepancy or improve the performance of FedSP. Without specific feedback or recommendations, the authors are left without a clear path to enhance their draft. Therefore, the comment is 2, as it identifies a problem but lacks depth and actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment raises several questions and suggestions regarding specific aspects of the paper. It explicitly asks why the authors did not specify what Omega is at line 178 and suggests being more explicit about the OMD algorithm and the link function. Additionally, it inquires about the specific theorem in reference 32 that is being referred to for the regret guarantee. These questions and suggestions provide clear and explicit actions for the authors to take, such as specifying Omega, being more explicit about OMD, and clarifying the link function and theorem reference. The feedback is concrete and direct, giving the authors a clear understanding of what needs to be addressed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions line 178, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as explaining what Omega is, being more explicit about the OMD algorithm, and clarifying the link function and the theorem reference in 32. This provides clear guidance on what the authors need to revise or clarify. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions and requests for clarification, such as \"Why not say what Omega is here\" and \"What link function?\" It does not contain subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by questioning the lack of clarity in the paper regarding the definition of Omega, the OMD algorithm, the link function, and the specific theorem in reference 32 that is being referred to for the regret guarantee. This feedback is clear and directs the authors to clarify these aspects, which can significantly improve the comprehensibility and rigor of the paper. By addressing these points, the authors can enhance the transparency and accuracy of their work. Therefore, the comment is rated as 5, as it offers detailed guidance that can lead to substantial improvements in the draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point states that the models are learned directly from pixels without a Markovian state, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how this observation should impact the draft or what changes, if any, should be made. Without any actionable suggestions or questions, the authors are left without a clear understanding of how to address this feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions that the models are learned directly from pixels without a Markovian state, but it does not specify which part of the paper this observation pertains to. Without explicit references to sections, tables, or figures, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspect of the models or the learning process is being critiqued. As a result, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the models are learned directly from pixels without a Markovian state. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this critique or how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that the models are learned directly from pixels without a Markovian state, which is a relevant observation that could impact the understanding of the models\" behavior. However, the comment lacks specificity and does not provide any guidance or suggestions on how this observation might affect the paper or how the authors could address it. Without actionable feedback or suggestions for improvement, the comment is not particularly helpful to the authors in enhancing their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment acknowledges the usefulness of the sequence example at different steps of the paper but expresses surprise at the mention of a \"common\" practice in the context of CRF, specifically the use of the Hamming distance over entire parts of the sequence. The reviewer suggests that the authors should provide references for this approach, which is an explicit and concrete action. By specifying the need for references, the authors know exactly what to do to address the comment. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Example 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular practice mentioned in Example 2, namely the use of the Hamming distance over entire parts of the sequence, which the reviewer claims is not a common approach. The comment further suggests that the authors should provide references for this approach, which adds specificity to the feedback. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point expresses surprise at the mention of a \"common\" practice in the context of CRF, specifically the use of the Hamming distance over entire parts of the sequence. The reviewer claims to be unaware of this approach and suggests that the authors provide references. While the comment highlights a potential gap in the literature, it lacks specific examples or detailed reasoning to fully substantiate the claim. The request for references is a logical next step, but the comment itself is 3 due to the lack of detailed evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the usefulness of the sequence example at different steps of the paper but expresses surprise at the mention of a \"common\" practice in the context of CRF, specifically the use of the Hamming distance over entire parts of the sequence. The reviewer suggests that this approach is not commonly used and requests references to support this claim. This feedback is 4 as it identifies a potential gap in the literature and provides a clear action for the authors to take by suggesting they include references to substantiate their claim. However, the comment could be more helpful if it offered additional context or explanation about why this approach is not commonly used, which would further guide the authors in understanding the issue. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests changing the name of the \"Evaluation\" element to \"Metrics\" to avoid confusion with the more general term \"evaluation.\" It also implies that the corresponding sections can be removed and the metrics can be mentioned briefly along with the datasets or in the captions of the tables. While the comment provides a clear action to change the name, it lacks specific guidance on how to integrate the metrics into the text or what specific sections should be removed. The authors know they need to make these changes but may struggle with the execution, making the comment 3.", "grounding_specificity_rationale": "The comment suggests changing the name of the \"Evaluation\" element to \"Metrics\" and implies that the corresponding sections can be removed. It also mentions that the metrics can be briefly mentioned along with the datasets or in the captions of the tables. However, the comment does not specify which sections or tables are being referred to, making it weakly grounded. The suggestion to change the name and remove sections is specific, but without clear references to the parts of the paper being addressed, the authors may find it challenging to implement the changes. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests changing the name of the \"Evaluation\" element to \"Metrics\" to avoid confusion with the more general term \"evaluation.\" It also implies that the corresponding sections can be removed and the metrics can be mentioned briefly along with the datasets or in the captions of the tables. The comment provides a logical reasoning for the change, suggesting that the current name might be misleading due to its broader meaning. However, it lacks specific examples or references to support the claim that most metrics are wellknown and used as standard practice. This makes the claim 3, as it provides a rationale but lacks detailed evidence or examples to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests a change in the name of the \"Evaluation\" element to \"Metrics,\" arguing that \"evaluation\" can have a more general meaning. It also implies that the corresponding sections can be removed and the metrics can be briefly mentioned along with the datasets or in the captions of the tables, as most metrics are wellknown and used as standard practice. This feedback is clear and actionable, providing the authors with a specific suggestion to improve the clarity and organization of their paper. However, it could be more helpful if it included examples of how to integrate the metrics into the text or provided more detailed guidance on what sections should be removed. Overall, the comment is 4 as it offers a constructive suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point states that, like most work on pruning, it is not yet possible to realize efficiency gains on GPU. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or suggestions for potential solutions. The comment lacks actionable details, leaving the authors without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions \"most work on pruning\" without specifying which part of the paper it addresses, making it difficult for the authors to identify the exact section being referred to. Additionally, it does not provide specific details or examples of what needs to be addressed regarding the realization of efficiency gains on GPU. This lack of grounding and specificity makes it challenging for the authors to understand the feedback and take appropriate action. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that \"it is not yet possible to realize efficiency gains on GPU,\" which is a subjective opinion based on the current state of research in pruning. However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a potential limitation in the work, noting that, like most work on pruning, it may not yet be possible to realize efficiency gains on GPU. However, the comment lacks specificity and does not provide any actionable advice or suggestions for improvement. It does not offer guidance on how the authors might address this issue or explore alternative approaches to achieve efficiency gains on GPU. Without actionable feedback or constructive suggestions, the comment does not help the authors in improving their draft. Therefore, it is rated as 1."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the numerical evaluation, specifically noting that the method is only evaluated on synthetic data and that the comparison with 5 is not fair due to the different complexity of the problem. However, the comment does not provide explicit guidance on how the authors should address these issues. It lacks concrete suggestions or actions for improving the evaluation or making it more fair. The authors are left to infer that they need to expand the evaluation to realworld data and consider the complexity of the problem, but without specific instructions, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the numerical evaluation and the comparison with a specific reference, 5, which is mentioned as being designed for a more complex problem. However, it does not specify which part of the paper discusses the numerical evaluation or the comparison with 5, making it weakly grounded. The comment is specific in detailing the issue with the evaluation, namely the use of synthetic data and the unfair comparison with 5. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the numerical evaluation is not fully convincing because the method is only evaluated on synthetic data, and the comparison with 5 is not fair due to the different complexity of the problem. The comment provides a logical reasoning by pointing out the limitations of the evaluation setup and the unfair comparison with 5. However, it lacks specific examples or references to substantiate the claim further, such as detailed comparisons or analyses of the differences in complexity. This makes the claim 3, as it provides a basis for the critique but requires more detailed evidence to fully support the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant limitation in the numerical evaluation of the method, noting that it is only evaluated on synthetic data. It also points out that the comparison with 5 is not fair due to the different complexity of the problem, specifically mentioning that 5 is designed for a more complex problem. This feedback is valuable as it highlights a critical weakness in the evaluation process and suggests that the authors should consider expanding their evaluation to realworld data and addressing the unfair comparison. However, the comment could be more helpful if it provided specific suggestions on how to address these issues, such as recommending additional datasets or methods for comparison. Overall, the comment is 3 as it directs the authors to a key area for improvement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether studying the number of bits in logits helps against a larger epsilon in the PGD attack. It suggests that having a 32bit logit should improve robustness against a more powerful adversary. While the comment implies that the authors should consider this experiment, it does not explicitly instruct them to conduct it. The action is implicit and somewhat vague, as the authors are left to infer that they should explore this aspect. However, the comment does provide a concrete suggestion about the potential impact of the experiment on strengthening the paper. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the study of the number of bits in logits and their impact on robustness against a larger epsilon in the PGD attack. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment does provide some specificity by suggesting that having a 32bit logit might improve robustness, but it lacks detailed guidance on how to address this question or where to incorporate it into the paper. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a question about the impact of the number of bits in logits on robustness against a larger epsilon in the PGD attack. The comment suggests that having a 32bit logit might improve robustness, but it does not provide any evidence or references to support this claim. The reasoning is based on intuition, which is not sufficient to fully substantiate the claim. Therefore, the comment is considered 2, as it lacks detailed justification or evidence to fully support the claim.", "helpfulness_rationale": "The review comment raises an interesting question about the potential impact of the number of bits in logits on robustness against a larger epsilon in the PGD attack. It suggests that having a 32bit logit might improve robustness, which is a logical inference based on the authors\" work. However, the comment does not provide specific guidance or suggestions on how the authors might explore this question or incorporate it into their study. While it identifies a potential area for further investigation, it lacks actionable advice or detailed feedback, making it 3. The authors are left with a general idea but no clear direction on how to address it. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to clarify the difference between the meta solvers and the centralized RL where agents share weights. It provides a specific example from Foester et al. (2016) to guide the authors on how to make this distinction clearer. This feedback is direct and provides concrete guidance on what the authors need to do to improve their draft. The action is explicit and detailed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"meta solvers\" and \"centralized RL,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by asking for clarification on the difference between meta solvers and centralized RL, where agents share weights. Additionally, it provides a specific reference to Foester et al. (2016) to guide the authors on how to address this issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the meta solvers are centralized controllers and suggests that the authors clarify the difference between these solvers and centralized RL where agents share weights. The reviewer supports this claim by referencing Foester et al., Learning to communicate with deep multiagent reinforcement learning, NIPS 2016, which provides a specific example of a related work. This reference helps substantiate the claim and provides a clear basis for the authors to understand and address the issue. Therefore, the comment is 4, as it offers a logical reasoning and a specific reference to support the claim.", "helpfulness_rationale": "The review comment identifies a potential confusion in the paper regarding the distinction between meta solvers and centralized RL, where agents share weights. It suggests that the authors clarify this difference, providing a specific reference to Foester et al. (2016) as an example of related work. This feedback is clear and actionable, as it directs the authors to a specific area of confusion and offers a concrete reference to help them clarify their work. By addressing this issue, the authors can enhance the clarity and comprehensiveness of their draft. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the notation used for M_T is not clear and recommends providing examples to explain it. This feedback is explicit and provides a clear action for the authors to take, which is to include examples to clarify the concept. The suggestion is concrete, as it specifies what the authors need to do to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Page 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the notation used for M_T, suggesting that it is not clear and recommending the inclusion of examples to explain it. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the notation used for M_T is not clear and suggests providing examples to explain it. However, the comment does not provide any specific reasoning or examples to support why the notation is unclear or how examples would improve clarity. Without additional context or explanation, the claim lacks sufficient justification, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the notation used for M_T on page 3, suggesting that it is not clear and may be difficult to understand. It provides a clear and actionable suggestion to improve the draft by recommending the inclusion of examples to explain M_T. This feedback is valuable as it directs the authors to a specific area that needs clarification, offering a concrete step to enhance the comprehensibility of their work. However, the comment could be more helpful if it provided additional context or examples of how M_T is currently used, which would further guide the authors in making the necessary improvements. Overall, the comment is 4, as it effectively points out a potential issue and offers a constructive suggestion for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the necessity of detecting both entities in Figure 2, suggesting that knowing the long entity might be sufficient. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should address this question, modify their approach, or provide additional explanation. The comment lacks actionable details, leaving the authors uncertain about how to respond. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the necessity of detecting both entities in the example and asks for clarification on the difference between detecting both entities and just knowing the long one. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5.", "verifiability_rationale": "The review point is a question seeking clarification about the necessity of detecting both entities in Figure 2. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the necessity of detecting both entities in Figure 2, suggesting that knowing the long entity might be sufficient. This is a valid point that prompts the authors to reconsider the relevance and importance of their approach. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve their methodology. While it identifies a potential area for improvement, the feedback is somewhat vague and does not offer actionable steps for the authors to take. Therefore, the comment is 3, as it provides some insight but lacks comprehensive guidance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about Theorem 1, specifically regarding the upper bound when there is a separate node with 0 neighbors. The reviewer acknowledges that the theorem seems correct but points out an exception that is not true. However, the comment does not provide any explicit guidance or suggestions on how the authors should address this issue or explain the exception. The action is implicit, as the authors need to infer that they should clarify or revise the theorem to account for this exception. The feedback is vague because it does not specify how to resolve the issue or what changes are needed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the correctness of the theorem when there is a separate node with 0 neighbors, which is not true. The comment raises a specific concern about the exception and asks for an explanation, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the correctness of Theorem 1 by pointing out an exception when there is a separate node with 0 neighbors. The reviewer acknowledges that the theorem seems correct but highlights a potential issue with the upper bound being 0, which is not true. However, the comment does not provide any further explanation, examples, or references to support the claim or suggest how the authors might address this exception. Without additional context or reasoning, the claim remains 3, as it identifies a potential issue but lacks detailed justification or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the correctness of Theorem 1, specifically regarding the upper bound when there is a separate node with 0 neighbors. The reviewer acknowledges that the theorem seems correct but points out an exception that is not true. This feedback is 3 as it identifies a potential issue with the theorem and prompts the authors to consider and address this exception. However, the comment lacks specific guidance or suggestions on how to resolve the issue or explain the exception, which would make it more actionable. Therefore, the comment is rated as 3, as it provides some insight but does not fully support the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a gap in the analysis regarding the detection of rumors generated by GPT, suggesting that further analysis or solutions should be proposed. It questions why GPTgenerated rumors are as difficult to detect as natural rumors, given that both are written by humans. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to conduct this analysis or propose solutions. The action is implicit and somewhat vague, as the authors are left to infer what kind of analysis or solutions are needed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the handling of rumors generated by GPT,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue by questioning the analysis of why GPTgenerated rumors are as difficult to detect as natural rumors, given that both are written by humans. The comment suggests that further analysis or solutions should be proposed to address this gap. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks analysis or solutions regarding the detection of rumors generated by GPT, specifically questioning why GPTgenerated rumors are as difficult to detect as natural rumors. The reviewer provides a logical reasoning by pointing out that both GPTgenerated and natural rumors are written by humans, and therefore, the difficulty in detection should be similar. However, the comment does not provide specific examples or references to support this claim, making it 3. The authors would need to further explore the reasoning and evidence themselves to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks analysis or solutions regarding the detection of rumors generated by GPT. It questions why GPTgenerated rumors are as difficult to detect as natural rumors, given that both are written by humans. This feedback is clear and actionable, as it prompts the authors to further explore and analyze this aspect of their work. By addressing this gap, the authors can enhance the comprehensiveness and depth of their analysis, which is crucial for improving the draft. However, the comment could be more helpful if it provided specific suggestions or examples of how to approach this analysis. Overall, the comment is 4, as it directs the authors to a critical area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "1", "actionability_rationale": "The review point critiques the technical contribution of the paper, specifically noting that Section 4 is more about heuristics than a formal and principled solution. However, it does not provide any explicit or implicit suggestions for improvement or guidance on how the authors might address this issue. The comment lacks actionable details, leaving the authors without a clear understanding of what changes or additions are needed to enhance the technical contribution. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment critiques the technical contribution of the paper, specifically mentioning that Section 4 is more about heuristics than a formal and principled solution. However, it does not specify which part of Section 4 is being referred to, making it difficult for the authors to pinpoint the exact issue. The comment is specific in its critique of the technical contribution but lacks grounding as it does not identify the specific sections or elements being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the technical contribution is limited, specifically mentioning that Section 4 is more about heuristics than a formal and principled solution. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or references to what constitutes a formal and principled solution, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment critiques the technical contribution of the paper, specifically noting that Section 4 is more about heuristics than a formal and principled solution. While it identifies a potential weakness in the paper, it lacks actionable feedback or suggestions for improvement. The comment does not provide guidance on how the authors might enhance the technical contribution or address the critique, leaving the authors without a clear path for improvement. As a result, the comment is not particularly helpful, as it does not offer actionable insights or constructive feedback to assist the authors in enhancing their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses regret that the probability mass function is not fully exploited in the paper, specifically mentioning the use of a quasiuniform distribution in MixBoost. The reviewer suggests that considering various probability mass functions could add depth to the experimental setting. However, the comment does not provide explicit guidance on how to implement this suggestion or what specific probability mass functions should be considered. The action is implicit and somewhat vague, as the authors are left to infer that they should explore different probability mass functions but without concrete steps or examples. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the use of the probability mass function in MixBoost, specifically mentioning the quasiuniform distribution and suggesting that considering various probability mass functions could add depth to the experimental setting. However, it does not explicitly mention which part of the paper discusses this aspect, making it weakly grounded. The comment is specific in detailing the issue with the current approach and suggesting a potential improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses regret that the probability mass function is not fully exploited in the paper, specifically mentioning the use of a quasiuniform distribution in MixBoost. The reviewer suggests that considering various probability mass functions could add depth to the experimental setting. However, the comment lacks specific examples or references to support the claim that different probability mass functions would be beneficial. The suggestion is based on intuition and logical reasoning, but without detailed evidence or examples, it remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting that the probability mass function could be more fully exploited in the paper. It points out that the quasiuniform distribution used in MixBoost is based on a single parameter, which may limit the depth of the experimental setting. The reviewer provides a logical suggestion to consider various probability mass functions, which could add depth to the experiments. However, the comment lacks specific guidance on how to implement this suggestion or what specific probability mass functions should be considered. While it highlights a relevant area for improvement, the feedback could be more actionable with additional details. Therefore, the comment is 3, as it provides insight but lacks depth and specificity in its suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the fairness of comparing the accuracies of different models, specifically mentioning ChatGPT and other models. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue of fairness in the comparison or what steps to take to improve the draft. The comment lacks actionable advice, leaving the authors without a clear understanding of what needs to be done to enhance their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the fairness of comparing the accuracies of different models, specifically mentioning ChatGPT and other models. However, it does not specify which part of the paper this comparison is discussed in, making it difficult for the authors to identify the exact section that needs attention. The comment lacks specificity as it does not detail what aspect of the comparison is unfair or how it should be addressed. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the fairness of comparing the accuracies of different models, specifically mentioning ChatGPT and other models. However, it does not provide any supporting evidence, reasoning, or references to justify why this comparison might be unfair. The comment lacks specific examples or detailed analysis to substantiate the claim, making it difficult for the authors to understand the basis of the question. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a question about the fairness of comparing the accuracies of different models, specifically mentioning ChatGPT and other models. While it identifies a potential issue with the comparison, it does not provide any actionable guidance or suggestions for the authors to address this concern. The comment lacks depth and does not offer any specific advice on how the authors might improve their draft to resolve the issue of fairness in the comparison. As a result, the feedback is 2, as it points out a potential problem but does not assist the authors in making meaningful improvements to their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to include references to specific works, particularly a, which uses supervised learning in QBF solving. It also suggests discussing connections with a, which is relevant to the topic. This feedback provides a clear and concrete action for the authors to take, ensuring they know exactly what references to include and how to discuss them. The comment is explicit and provides detailed guidance, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the references that are missing, allowing the authors to accurately identify the part of the paper that needs attention. It also specifies what is missing by suggesting the inclusion of references to a, which uses supervised learning in QBF solving. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that certain references are relevant to the topic and suggests discussing connections with a specific reference, a. However, it does not provide detailed reasoning or examples to support why these references are relevant or how they should be integrated into the paper. The mention of a is vague, and the comment lacks specific references or detailed explanations to substantiate the claim. This makes the comment 3, as it provides a general direction but lacks the necessary details for full verification.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out missing references that are relevant to the topic. It suggests discussing connections with a particular reference, a, which uses supervised learning in QBF solving. This feedback is clear and actionable, as it provides the authors with a concrete step to enhance their draft by incorporating relevant references and discussing their connections. However, the comment could be more helpful if it explained why these references are important or how they relate to the paper\"s content. Overall, the comment is 4 as it guides the authors toward improving the comprehensiveness and relevance of their references."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the mono tonic relationship between the degree of a singletask predictor participation and the weight of the corresponding task loss can be replaced by other relationships. It suggests that explaining this point may be beneficial. While the comment implies that the authors should explore alternative relationships, it does not provide explicit guidance on how to do so or what specific alternatives to consider. The action is implicit and somewhat vague, as the authors need to infer that they should investigate other relationships and explain their findings. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"mono tonic relationship\" and \"the degree of a singletask predictor participation,\" allowing the authors to accurately identify the part of the paper being addressed. It also provides a specific suggestion to explore alternative relationships and explains the potential benefit of doing so. However, the comment could be more specific by elaborating on why the mono tonic relationship is important or how it affects the results. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about whether the mono tonic relationship between the degree of a singletask predictor participation and the weight of the corresponding task loss can be replaced by other relationships. The reviewer suggests that explaining this point may be beneficial. However, the comment lacks specific examples or references to support the claim that other relationships could be explored. The inclusion of a reference to a relevant work by Navon et al. provides some context but does not fully substantiate the claim. Therefore, the comment is 3, as it provides a basis for exploration but requires more detailed justification or examples to be 5.", "helpfulness_rationale": "The review comment raises a question about the mono tonic relationship between the degree of a singletask predictor participation and the weight of the corresponding task loss. It suggests that this relationship could be replaced by other relationships and encourages the authors to explain this point further. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might explore alternative relationships or explain the current relationship more effectively. The feedback is 3 as it prompts the authors to consider a deeper analysis of this aspect, but it could be more actionable with additional details or examples. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the privacy preservation of the approach compared to other federated learning methods and questions the relevance of using traffic signal control as an example. However, it does not provide explicit guidance or suggestions for the authors to address these concerns. The authors are left to infer that they need to clarify the privacy aspects of their approach and potentially reconsider the choice of example. While the comment implies an action, it lacks concrete details on how to implement these changes, making it 3.", "grounding_specificity_rationale": "The comment raises questions about the privacy preservation of the approach compared to other federated learning methods and questions the relevance of using traffic signal control as an example. However, it does not specify which part of the paper discusses these issues, making it weakly grounded. The comment is specific in its critique of the approach and the choice of example, but without clear references to specific sections, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions and critiques, such as questioning the privacy preservation of the approach and the relevance of using traffic signal control as an example. These are not claims that require verification or justification, as they are merely seeking clarification or expressing skepticism. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the privacy preservation of the approach compared to other federated learning methods and questions the relevance of using traffic signal control as an example. It challenges the authors to clarify the privacy aspects of their approach and suggests that the choice of example may not be the most appropriate. However, the comment lacks specific guidance or suggestions on how the authors might address these concerns or improve their draft. While it identifies areas for improvement, it does not provide actionable feedback or detailed advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a specific issue with the hyperlinks for footnotes 3 and 4, indicating that they do not seem to work. This is an explicit statement that clearly directs the authors to check and fix the hyperlinks. The action is concrete, as it specifies exactly what needs to be done to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"footnote 3 and 4,\" allowing the authors to accurately identify the specific parts of the paper being addressed. It is also specific because it clearly specifies the issue of broken hyperlinks, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about the functionality of hyperlinks in the paper, specifically noting that footnotes 3 and 4 do not seem to work. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the hyperlinks for footnotes 3 and 4, noting that they do not seem to work. This is a clear and actionable piece of feedback that the authors can address directly by checking and fixing the hyperlinks. However, the comment does not provide any additional context or suggestions on how to ensure the hyperlinks function correctly or why this issue might be important. While it highlights a specific problem, it lacks depth and does not offer broader guidance for improvement. Therefore, the comment is 3, as it provides a clear action but lacks comprehensive feedback."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests revising the discussion, particularly in the modeling section, to make it clearer. It provides a specific example of what needs to be improved, such as formalizing the architecture in section 2 and clarifying the role of Label Embeddings. While the comment implies that these changes are necessary, it does not explicitly instruct the authors to make these revisions. The action is concrete but stated implicitly, making the comment 4.", "grounding_specificity_rationale": "The comment suggests revising the discussion, particularly in the modeling section, to make it clearer. It provides a specific example of what needs to be improved, such as formalizing the architecture in section 2 and clarifying the role of Label Embeddings. This provides clear guidance on what needs to be addressed. However, the comment does not explicitly mention which part of the modeling section is unclear, making it weakly grounded. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests revising the discussion, particularly in the modeling section, to make it clearer. It provides a specific example of what needs to be improved, such as formalizing the architecture in section 2 and clarifying the role of Label Embeddings. The comment also points out a potential misunderstanding regarding the figure, suggesting that the Label Embeddings are external parameters rather than the output of the encoder. This feedback is specific and provides clear guidance on how to improve the paper. However, it does not include references or detailed reasoning beyond the examples provided, which could strengthen the justification. Therefore, the comment is 4, as it provides a clear direction for improvement but lacks comprehensive evidence or references.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting revisions to the discussion, particularly in the modeling section. It highlights that the current form of the discussion is not clear enough and offers a concrete example of what needs to be improved, such as formalizing the architecture in section 2 and clarifying the role of Label Embeddings. This guidance is clear and actionable, giving the authors a direct path to enhance the clarity and comprehensiveness of their work. However, the comment could be more helpful if it included additional suggestions or examples of how to improve the discussion further. Overall, the feedback is 4 as it effectively directs the authors toward specific improvements that can enhance the quality of their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the description of the neural network in Section 528 is hard to understand and recommends starting the section with the final paragraph, which is clearer. This feedback provides a clear and explicit action for the authors to take, which is to restructure the section to improve clarity. The suggestion is concrete, as it specifies exactly what needs to be done to enhance the readability of the section. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 528,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the description of the neural network, noting that it is hard to understand but becomes clearer in the final paragraph. The comment provides a clear suggestion to start the section with the final paragraph, which offers a concrete way to improve the clarity of the section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the description of the neural network in Section 528 is hard to understand but becomes clearer in the final paragraph. However, the comment does not provide any specific examples or detailed reasoning to support this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 2, as it lacks sufficient evidence or justification to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the description of the neural network in Section 528, noting that it becomes clearer in the final paragraph. It provides a clear and actionable suggestion to improve the draft by recommending that the authors start the section with the final paragraph, which is clearer. This feedback is valuable as it directly addresses a potential source of confusion in the paper and offers a concrete way to enhance its readability. However, the comment could be more helpful if it provided additional context or examples of what makes the final paragraph clearer. Overall, the comment is 4, as it guides the authors toward a specific improvement that can enhance the clarity of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the limitations of the model, specifically whether it is possible to train it towards attentionbased encoderdecoder training. While the comment implies that the authors should consider this possibility, it does not provide explicit guidance or suggestions on how to implement this change or what specific steps to take. The action is implicit and somewhat vague, as the authors need to infer that they should explore this possibility and determine how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the limitations of the model, specifically whether it is possible to train it towards attentionbased encoderdecoder training. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment. This lack of grounding makes it difficult for the authors to identify the exact part of the paper being addressed. The comment is specific in its suggestion to explore attentionbased training, but without clear grounding, it is challenging for the authors to determine where to focus their attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the limitations of the model, specifically whether it is possible to train it towards attentionbased encoderdecoder training. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this change would be beneficial or how it might impact the model\"s performance. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the limitations of the model, specifically whether it is possible to train it towards attentionbased encoderdecoder training. While it identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance or suggestions on how the authors might explore this possibility or what specific changes could be made to the model. The comment is 3 as it prompts the authors to consider an alternative approach, but it does not offer actionable steps or detailed feedback to enhance the draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the attack methods used in the paper, describing them as naive and suggesting that other classical attack methods in NLP should be considered. However, it does not provide explicit guidance on which specific attack methods should be used or how to incorporate them into the paper. The comment mentions two examples of attack methods but does not instruct the authors to include them or explain how they would fit into the current framework. The action is implicit and somewhat vague, as the authors are left to infer that they should explore additional attack methods but without concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment critiques the attack methods used in the paper, describing them as naive and suggesting that other classical attack methods in NLP should be considered. It mentions two specific attack methods that are considered in the paper and provides examples of other relevant papers. However, the comment does not specify which part of the paper discusses these attack methods, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but the exact location is not explicitly mentioned. The comment is specific in suggesting alternative attack methods and providing references, which is a strength. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the attack methods used in the paper are naive and suggests that other classical attack methods in NLP should be considered. The reviewer provides examples of such methods by referencing specific papers. This provides a reasonable basis for the claim, as it offers specific references to support the suggestion of using alternative attack methods. However, the comment could be strengthened by providing more detailed reasoning or examples of how these alternative methods might be applied or improve the paper. Overall, the claim is 4, as it is supported by references but could benefit from additional explanation or examples.", "helpfulness_rationale": "The review comment identifies a weakness in the paper by describing the attack methods as naive and suggesting that other classical attack methods in NLP should be considered. It provides specific examples of alternative attack methods and references relevant papers, which is a valuable contribution. However, the comment could be more helpful if it offered a more detailed explanation of why the current attack methods are inadequate or how the suggested methods might improve the paper. Additionally, it could provide guidance on how to incorporate these alternative methods into the paper. Despite these limitations, the comment does offer actionable feedback by pointing out a specific area for improvement, making it 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights that the mitigation methods affect the image generation capabilities of diffusion models, potentially leading to lower image quality. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how to address the issue, such as suggesting ways to mitigate the impact or improve the image quality. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions \"mitigation methods\" and \"image generation capabilities of diffusion models,\" but it does not specify which part of the paper these issues are discussed in. This makes it difficult for the authors to identify the exact sections that need attention. Additionally, the comment lacks specificity regarding what aspects of the image generation capabilities are affected or how the mitigation methods lead to lower image quality. Without clear grounding and specificity, the authors are left without a clear understanding of what needs to be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that \"mitigation methods affect the image generation capabilities of diffusion models, which can lead to lower image quality.\" However, it does not provide any supporting evidence, examples, or references to substantiate this claim. The lack of detailed reasoning or specific examples makes it difficult for the authors to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the mitigation methods used in the paper, suggesting that they may affect the image generation capabilities of diffusion models, leading to lower image quality. However, the comment lacks specificity and does not provide any actionable advice or suggestions on how the authors might address this issue or improve the image quality. Without detailed guidance or examples, the authors are left without a clear understanding of what steps to take to resolve the problem. Therefore, the comment is 2, as it highlights a potential concern but does not offer meaningful guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment expresses surprise at the dominance of function words over content words in a Japanese sentence, but it does not provide any explicit or implicit actions for the authors to take. There is no suggestion for further analysis, clarification, or improvement. The comment lacks actionable guidance, leaving the authors without a clear understanding of what steps, if any, they should take in response to this observation. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by expressing surprise at the dominance of function words over content words in a Japanese sentence. However, the comment does not provide further details or suggestions on how to address this observation, making it specific. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point expresses surprise at the dominance of function words over content words in a Japanese sentence, but it does not provide any supporting evidence, reasoning, or references to justify this observation. The comment lacks specific examples or explanations that would help the authors understand the basis of the surprise or how this observation relates to the paper\"s content. As a result, the claim is 1, as it does not provide sufficient information for the authors to address the issue or improve their work.", "helpfulness_rationale": "The comment expresses surprise at the dominance of function words over content words in a Japanese sentence, but it does not provide any further context, analysis, or suggestions for improvement. It lacks depth and actionable feedback, leaving the authors without a clear understanding of the issue or how to address it. Without additional guidance or explanation, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should use the minimal kmeans objective over multiple seeds as a baseline instead of the average of kmeans objectives with multiple seeds. The comment provides specific references to support this suggestion, which is a concrete action for the authors to take. The references offer a clear direction on how to implement the suggested change, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of the average of kmeans objectives with multiple seeds as a baseline, allowing the authors to accurately identify the part of the paper being addressed. It also provides specific suggestions for improvement by recommending the use of the minimal kmeans objective over multiple seeds. The comment is specific because it offers a clear alternative and references relevant literature, providing detailed guidance for the authors to consider. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the average of kmeans objectives with multiple seeds is not the most appropriate baseline and proposes using the minimal kmeans objective instead. This suggestion is supported by references to two external works that provide evidence and reasoning for the claim. The references offer specific examples and arguments, making the claim 5. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by recommending the use of the minimal kmeans objective over multiple seeds as a baseline, rather than the average of kmeans objectives with multiple seeds. This suggestion is based on references to relevant literature, which offers a clear and actionable direction for the authors to enhance their work. By providing specific references and a rationale for the change, the comment is 5 as it empowers the authors to make a meaningful improvement to their draft. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the relationship between uncertainty calibration and temperature calibration, specifically questioning the need for both in the context of the regularization term H. It suggests that the authors clarify this point by explaining the role of H in uncertainty calibration and how it relates to temperature calibration. Additionally, it points out a potential contradiction in the paper regarding the effect of reducing entropy, which is against the paper\"s motivation to calibrate networks. While the comment identifies specific areas for clarification, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to clarify the relationship between uncertainty and temperature calibration and reconcile the contradiction regarding entropy reduction. However, the lack of detailed guidance makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (155160) in the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the relationship between uncertainty and temperature calibration, particularly regarding the regularization term H. The comment further clarifies the confusion by pointing out a potential contradiction in the paper regarding the effect of reducing entropy. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a claim about the relationship between uncertainty calibration and temperature calibration, specifically questioning the need for both in the context of the regularization term H. The reviewer provides a detailed explanation of the apparent contradiction, referencing specific lines in the paper (155160) to support their claim. This level of detail and reference to specific sections of the paper makes the claim 4, as it provides a clear basis for the authors to address the issue. However, the comment could be strengthened by including additional references or examples to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential confusion in the paper regarding the relationship between uncertainty calibration and temperature calibration, specifically questioning the need for both in the context of the regularization term H. It points out a contradiction in the paper, where reducing entropy is suggested to make predictions more confident, which is against the paper\"s motivation to calibrate networks. The comment provides clear and actionable feedback by asking the authors to clarify this point and reconcile the apparent contradiction. This guidance is valuable as it directs the authors to address a specific issue that could impact the clarity and coherence of their work. However, the comment could be more helpful if it offered suggestions on how to resolve the contradiction or provided additional context. Overall, the comment is 4, as it effectively highlights a critical area for clarification and improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the importance of including a reference to the idea of unrolling, which was first proposed in \"Lista\" by Yann LeCun. It suggests that the paper should discuss the similarities and differences between the proposed work and Lista, and place itself in an appropriate context. While the comment implies that the authors should include this reference and discussion, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to integrate this reference or discussion into the paper. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the idea of unrolling, which is closely related to the paper, and references the work of Lista by Yann LeCun. This allows the authors to accurately identify the part of the paper being addressed, specifically the context and positioning of the proposed work. The comment is also specific because it clearly specifies what is missing, namely a reference to the idea of unrolling and a discussion of the similarities and differences between the proposed work and Lista. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that an important reference is missing, specifically the idea of unrolling, which was first proposed in \"Lista\" by Yann LeCun. The reviewer provides a direct reference to the Lista paper, which supports the claim by offering a specific source for the idea of unrolling. This level of detail and reference makes the claim 5, as it provides a clear and direct link to the missing reference. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a significant omission in the paper, namely the lack of reference to the idea of unrolling, which was first proposed in the Lista paper by Yann LeCun. It highlights the importance of discussing the similarities and differences between the proposed work and Lista, as well as placing the paper in an appropriate context. This feedback is clear and actionable, as it directs the authors to include a reference to Lista and to discuss the context of their work. By addressing this omission, the authors can enhance the comprehensiveness and relevance of their paper. However, the comment could be more helpful if it provided specific guidance on how to integrate this reference or discussion into the paper. Overall, the comment is 4, as it identifies a critical gap and offers a clear direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to explain the linear program in Theorem 3 intuitively, noting that it would be beneficial for the reader. The comment provides a clear action for the authors to take, which is to explain the objective and constraints in (3). This feedback is direct and concrete, giving the authors a specific task to address. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the need for an intuitive explanation of the linear program in Theorem 3, including the objective and constraints in (3). This provides clear guidance on what the authors should focus on to improve their draft. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the linear program in Theorem 3 should be explained intuitively, noting that it would help the reader understand the objective and constraints. This is a request for clarification rather than a claim, as it does not express an opinion or judgment about the paper. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by suggesting that the linear program in Theorem 3 should be explained intuitively. It acknowledges that Theorem 3 is a main theorem but points out that the reader would benefit from an explanation of the objective and constraints in (3). This feedback is clear and actionable, providing the authors with a direct suggestion on how to enhance the clarity and accessibility of their work. However, the comment could be more helpful if it included examples or additional guidance on how to present the explanation. Overall, the comment is 4 as it offers a constructive suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises questions about the clarity of Algorithm 2, specifically regarding the computation of \"avg\" and the meaning of \"j\" and \"i\"\". It also suggests updating one node based on results from multiple connected nodes, which is an implicit action. However, the comment does not provide explicit guidance on how to address these issues or clarify the algorithm. The authors can infer that they need to provide more detailed explanations or updates, but the action is not directly stated, and the feedback lacks concrete steps for improvement. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the algorithm, noting that \"avg\" is computed but not used, and questions the meaning of \"j\" and \"i\".\" This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the clarity of Algorithm 2, specifically regarding the computation of \"avg\" and the meaning of \"j\" and \"i\".\" The reviewer suggests that the authors update their response to address these concerns. However, the comment does not provide any additional context, reasoning, or examples to support the claim that the algorithm is unclear. Without further explanation or evidence, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises several specific concerns about the clarity and implementation of Algorithm 2. It questions whether it is possible to update one node based on results from multiple connected nodes and points out that \"avg\" is computed but not used. Additionally, it asks for clarification on the meaning of \"j\" and \"i\".\" These questions and observations are clear and actionable, providing the authors with specific areas to address and clarify in their draft. By addressing these points, the authors can enhance the clarity and comprehensibility of their work. However, the comment could be more helpful if it offered suggestions on how to improve the algorithm or provided additional context. Overall, the feedback is 4 as it directs the authors to specific areas needing clarification and improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point indicates that the paper is not polished and lacks details in related work, experiments, and writing. However, it does not provide specific guidance on what details are missing or how the authors should address these issues. The comment refers to another section for more details, but without explicit instructions or concrete suggestions, the authors are left without a clear path for improvement. This lack of specificity and actionable advice makes the comment 1.", "grounding_specificity_rationale": "The comment indicates that the paper is not polished and lacks details in related work, experiments, and writing. However, it does not specify which parts of the paper are lacking in detail or what specific aspects need improvement. Additionally, it does not provide any references or examples to support the claim, making it difficult for the authors to pinpoint the exact areas needing attention. The comment is 1 as it does not identify specific sections or elements of the paper, and it is not specific because it lacks detailed guidance on what needs to be addressed. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is not polished and lacks details in related work, experiments, and writing. However, it does not provide specific examples or evidence to support this claim, such as mentioning which aspects of the related work are missing or how the experiments could be improved. The reference to \"Clarity, Quality, Novelty And Reproducibility\" does not provide sufficient detail or context to substantiate the claim. As a result, the comment lacks verifiability, making it difficult for the authors to understand and address the issues effectively. Therefore, it is rated as 1.", "helpfulness_rationale": "The review comment indicates that the paper is not polished and lacks details in related work, experiments, and writing. However, it does not provide specific examples or guidance on what details are missing or how the authors could improve these areas. The reference to \"Clarity, Quality, Novelty And Reproducibility\" suggests that more detailed feedback can be found in those sections, but without elaboration, the comment remains vague and unhelpful. As it stands, the comment does not offer actionable advice or insights that would assist the authors in improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the accuracy drop in Figure 5 after a certain order of around 45, asking whether it is due to overfitting. While the comment implies that the authors should provide an explanation for this observation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to address the issue but are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the accuracy drop after a certain order and asks for an explanation, specifically whether it is due to overfitting. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the accuracy drop in Figure 5 after a certain order. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the accuracy drop in Figure 5 after a certain order, specifically asking whether it is due to overfitting. This is a relevant and important question that could help the authors understand the behavior of their model and potentially identify areas for improvement. However, the comment does not provide any suggestions or guidance on how the authors might investigate or address this issue. While it prompts the authors to consider a potential explanation, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that some natural ablation studies are missing, specifically questioning how scratchGAN would perform if pretraining is included. It also highlights the importance of this baseline, given the central argument against pretraining. While the comment implies that the authors should include these ablation studies, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to conduct these ablation studies or what specific aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that some natural ablation studies are missing, specifically questioning how scratchGAN would perform if pretraining is included. It also highlights the importance of this baseline, given the central argument against pretraining. However, the comment does not specify which part of the paper these ablation studies should be included in, making it weakly grounded. The comment is specific in its suggestion to include these ablation studies, but without clear grounding, the authors may struggle to identify the exact section where this feedback is relevant. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that some natural ablation studies are missing, specifically questioning how scratchGAN would perform if pretraining is included. The comment highlights the importance of this baseline, given the central argument against pretraining. However, the comment lacks specific examples or detailed reasoning to support why these ablation studies are crucial or how they would contribute to the paper. Without additional context or evidence, the claim remains somewhat vague, making it difficult for the authors to fully understand and address the suggestion. Therefore, the comment is rated as 3, as it provides some justification but lacks detailed support.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that natural ablation studies are missing, particularly questioning how scratchGAN would perform if pretraining is included. This feedback is actionable as it highlights a crucial baseline that could strengthen the paper\"s argument against pretraining. The comment also includes minor comments and questions, which provide additional context and direction for the authors. However, the comment could be more helpful if it offered specific suggestions on how to conduct these ablation studies or what aspects to focus on. Overall, the feedback is 4 as it directs the authors to a significant area for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to mention a specific detail regarding the preprocessing and evaluation in SI 6.5. It provides clear guidance on what needs to be added to the draft, making the action concrete and direct. The authors know exactly what needs to be done to address the comment, ensuring a high level of actionability. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"SI 6.5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be mentioned regarding the preprocessing and evaluation, which is different from Mnih et al. 7. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should mention a specific difference in preprocessing and evaluation compared to Mnih et al. 7. This is a factual statement that does not require verification or justification. It is a request for clarification or additional information, not an opinion or claim that needs to be substantiated. Therefore, the label \"No\" is appropriate.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improvement by directing the authors to mention a particular difference in preprocessing and evaluation compared to a referenced work. This feedback is clear and concise, offering a straightforward way for the authors to enhance their draft by addressing a potential oversight. By including this information, the authors can provide a more comprehensive and accurate context for their work. However, the comment could be more helpful if it explained why this difference is important or how it impacts the results. Overall, the comment is 4 as it guides the authors toward a specific improvement, but it could be more comprehensive with additional context or explanation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the paper regarding the lack of reported metrics that demonstrate the efficiency of the proposed method compared to previous work. While the comment identifies a specific area for improvement, it does not provide explicit guidance on what metrics should be included or how to measure efficiency. The action is implicit and somewhat vague, as the authors need to infer that they should include metrics to demonstrate efficiency. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of reported metrics that demonstrate the efficiency of the proposed method compared to previous work. However, it does not specify which part of the paper discusses the advantages over previous work, making it weakly grounded. The comment is specific in pointing out the absence of efficiency metrics, which is a clear indication of what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks metrics to demonstrate the efficiency of the proposed method compared to previous work. However, it does not provide specific examples of what metrics should be included or how the current metrics are insufficient. This lack of detailed justification or references makes the claim 3, as the authors would need to infer the specific metrics needed to address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting that while the authors discuss the advantages of their method over previous work in terms of efficiency, they do not provide any metrics to substantiate these claims. This feedback is valuable as it highlights a critical area for improvement, specifically the need to include efficiency metrics to support the claims made in the paper. However, the comment could be more helpful if it suggested specific metrics or methods for measuring efficiency, which would provide the authors with more actionable guidance. Overall, the comment is 3 as it points out a key weakness in the paper but lacks depth in suggesting how to address it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly requests more details on the statespace, actions, and the space in which theta lies. It suggests that the authors should be precise in their descriptions rather than leaving the reader to guess. This feedback provides a clear and direct action for the authors to take, which is to provide more detailed information in the draft. The comment is explicit and concrete, giving the authors a specific task to complete. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L81,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the need for more detailed information about the statespace, actions, and the space in which theta lies. The comment provides a clear direction for improvement by suggesting that the authors should be precise in their descriptions rather than leaving the reader to guess. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a series of questions seeking clarification on specific aspects of the paper, such as the nature of the statespace, actions, and the space in which theta lies. The reviewer suggests that these details should be provided for clarity. However, the comment does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks clarity, namely the details about the statespace, actions, and the space in which theta lies. It suggests that the authors should provide more detailed information to enhance the reader\"s understanding. While the comment highlights an important aspect for improvement, it does not offer specific suggestions or guidance on how to address these details. The feedback is 3 as it points out a weakness but lacks actionable advice, making it a 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point compares the effectiveness of the method on general reasoning tasks versus mathematic reasoning, suggesting that the method is less effective on general reasoning tasks. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how to improve the method\"s performance on general reasoning tasks or suggestions for further analysis or experimentation. As a result, the authors are left without any actionable steps to address the issue, making the comment 1.", "grounding_specificity_rationale": "The comment compares the effectiveness of the method on general reasoning tasks versus mathematic reasoning, but it does not specify which part of the paper this comparison is based on. The authors cannot confidently determine which sections or results are being referred to, making the comment weakly grounded. Additionally, the comment lacks specificity as it does not provide details on what aspects of the method are ineffective or how they could be improved. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the method is less effective on general reasoning tasks compared to mathematic reasoning. However, it does not provide any supporting evidence, examples, or references to substantiate this claim. Without specific examples or data to back up the assertion, the comment lacks verifiability. Therefore, it is classified as 1.", "helpfulness_rationale": "The review comment points out a potential limitation of the method, noting that it is less effective on general reasoning tasks compared to mathematic reasoning. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve the method\"s performance on general reasoning tasks. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should consider using LiDARbased segmentation as the downstream task instead of object detection, citing the need for accurate locations and poses in benchmark metrics like KITTI and Waymo. While the comment implies a change in the choice of downstream task, it does not provide explicit guidance on how to implement this change or why LiDARbased segmentation is the preferred choice. The authors can infer that they should consider this suggestion, but the lack of concrete details or rationale makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should consider using LiDARbased segmentation as the downstream task instead of object detection, citing the need for accurate locations and poses in benchmark metrics like KITTI and Waymo. However, it does not specify which part of the paper discusses the choice of downstream task, making it weakly grounded. The comment is specific in its suggestion to use LiDARbased segmentation and provides a rationale for why this choice is better suited for the task. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that LiDARbased segmentation is a better choice for the downstream task compared to object detection, citing the need for accurate locations and poses in benchmark metrics like KITTI and Waymo. The claim is 3 as it provides a logical reasoning for the preference of LiDARbased segmentation, particularly in the context of benchmark metrics. However, the comment lacks specific examples or references to support the claim fully, making it difficult for the authors to fully understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should consider using LiDARbased segmentation as the downstream task instead of object detection, citing the need for accurate locations and poses in benchmark metrics like KITTI and Waymo. This feedback is 3 as it provides a specific suggestion for improvement, offering a potential alternative approach that could enhance the paper\"s results. However, the comment lacks detailed reasoning or examples to fully support the claim, which would make it more actionable and comprehensive. The authors are given a direction to consider but are not provided with a clear path to implement the suggested change. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential contradiction between the objective of Eq (12) and the IPO (Infinite Product Optimization). However, it does not provide any explicit or implicit guidance on how the authors should address this contradiction or what specific changes should be made to resolve it. The comment lacks actionable details, such as suggesting ways to reconcile the objectives or explaining how the authors might clarify the contradiction. Without concrete instructions or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions \"Eq (12)\" and \"IPO,\" which allows the authors to identify the specific part of the paper being addressed. However, it does not specify what aspect of Eq (12) is in contradiction with IPO, nor does it provide details on how to resolve this contradiction. This lack of specificity makes it difficult for the authors to understand the exact issue and how to address it. Therefore, the comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point claims that there is a contradiction between the objective of Eq (12) and the Infinite Product Optimization (IPO). However, the comment does not provide any further explanation, examples, or references to support this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of the contradiction or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential contradiction between the objective of Eq (12) and the Infinite Product Optimization (IPO). This is a relevant observation that could impact the validity of the paper\"s claims or the interpretation of the results. However, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might address this contradiction or clarify the issue. Without actionable feedback or detailed advice, the authors are left without a clear path to improve their draft. Therefore, the comment is 3, as it points out a potential issue but does not offer sufficient guidance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the adaptation capacity of the proposed visual memory, specifically questioning whether it can accommodate new concepts effectively. The reviewer provides a rationale for this concern, suggesting that while DINO representations may contain rich geometric information, the adaptation capacity might be limited for concepts where class labels correlate more with semantics rather than geometry. However, the comment does not provide explicit guidance or suggestions on how the authors might address this concern or improve the adaptation capacity. The action is implicit and somewhat vague, as the authors are left to infer that they should explore or address the issue of adapting to new concepts, but without concrete steps or examples. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the adaptation capacity of the proposed visual memory, specifically questioning whether it can accommodate new concepts effectively. It provides a rationale for this concern, suggesting that while DINO representations may contain rich geometric information, the adaptation capacity might be limited for concepts where class labels correlate more with semantics rather than geometry. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the discussion of the visual memory or adaptation capacity, but the exact section is not specified. The comment is specific in detailing the concern about adaptation capacity and the potential limitations, but without explicit grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point raises a concern about the adaptation capacity of the proposed visual memory, specifically questioning whether it can accommodate new concepts effectively. The reviewer provides a logical reasoning by suggesting that while DINO representations may contain rich geometric information, the adaptation capacity might be limited for concepts where class labels correlate more with semantics rather than geometry. This reasoning is based on a logical inference and common knowledge about the nature of DINO representations. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is 3, as it provides a logical basis but lacks detailed evidence or references.", "helpfulness_rationale": "The review comment raises a valid concern about the adaptation capacity of the proposed visual memory, specifically questioning whether it can effectively accommodate new concepts. The reviewer provides a logical reasoning by suggesting that while DINO representations may contain rich geometric information, the adaptation capacity might be limited for concepts where class labels correlate more with semantics rather than geometry. This feedback is 3 as it highlights a potential limitation in the paper and prompts the authors to consider this aspect further. However, the comment could be more helpful if it offered specific suggestions or examples on how to address this concern or improve the adaptation capacity. Overall, the comment provides a valuable insight but lacks actionable guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a potential source of confusion in Algorithm 1, specifically regarding the use of $p$ to denote the phase mixing probability and the dummy variable in the inner loop in Phase 2. While the comment identifies a specific issue, it does not provide explicit guidance on how to address this confusion or suggest alternative terminology or explanations. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the notation or terminology, but they are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of potential confusion regarding the use of $p$ to denote the phase mixing probability and the dummy variable in the inner loop in Phase 2. This provides clear guidance on what needs to be addressed to improve the clarity of the algorithm description. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about potential confusion in the notation used in Algorithm 1. It does not express an opinion, judgment, or suggestion that requires verification. It is purely descriptive and does not contain any claims or subjective statements. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a potential source of confusion in the notation used in Algorithm 1, specifically regarding the use of $p$ to denote both the phase mixing probability and the dummy variable in the inner loop in Phase 2. This feedback is clear and actionable, as it points out a specific area where the authors might need to clarify their notation or terminology to improve the clarity of their algorithm description. However, the comment could be more helpful if it provided suggestions on how to resolve the confusion or offered alternative terminology to avoid ambiguity. Despite this, the comment is 4 as it directs the authors to a specific area that needs attention, providing them with a clear path to improve their draft. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment provides explicit suggestions for improvement, such as including a more detailed mathematical formulation in the appendix and adding more text labels to the figure. It also suggests reworking the figure to better align with the main contribution of the paper. These actions are clearly stated and provide concrete guidance on how to enhance the draft. The authors know exactly what changes to make to improve their work, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the highlevel description and the figure, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides detailed feedback on how to improve the figure, suggesting the addition of more text labels and reworking it to better align with the main contribution of the paper. The comment also suggests including a more detailed mathematical formulation in the appendix. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the highlevel description is helpful for understanding the approach intuitively but lacks a more detailed (e.g., mathematical) formulation. It also critiques the figure for being confusing, suggesting that it is too abstract and lacks text labels. The reviewer provides a specific suggestion to rework the figure to better align with the main contribution of the paper, which is improvements on the WiC task. This feedback is 4 as it provides a clear rationale for the critique and offers a specific suggestion for improvement. However, it could be strengthened by referencing similar figures or studies that effectively depict the WiC task. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides actionable feedback by suggesting that the paper could benefit from a more detailed mathematical formulation, particularly in the appendix. It also critiques the figure for being too abstract and suggests adding more text labels to improve clarity. Additionally, the comment offers a specific suggestion to rework the figure to better align with the main contribution of the paper, which is improvements on the WiC task. This feedback is clear and provides concrete steps for the authors to enhance the comprehensibility and relevance of their work. However, it could be more helpful if it included additional suggestions or examples of how to improve the mathematical formulation or rework the figure. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that including additional benchmarking tasks outside of AitW would be beneficial. However, it does not specify which specific tasks should be included or how they would contribute to the paper. The action is implicit and lacks concrete details, leaving the authors to infer what additional tasks might be relevant. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests including additional benchmarking tasks outside of AitW, but it does not specify which part of the paper this suggestion pertains to. The authors cannot confidently determine which section or context this feedback relates to, making it weakly grounded. However, the comment is specific in suggesting the inclusion of additional benchmarking tasks, providing a clear direction for improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that including additional benchmarking tasks outside of AitW would be beneficial. However, it does not provide any specific examples, reasoning, or references to support why these additional tasks are necessary or how they would enhance the paper. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the suggestion, rendering the claim 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The comment suggests that including additional benchmarking tasks outside of AitW would be beneficial. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on which specific tasks should be included or how they might enhance the paper. The feedback is 3 as it points out a direction for expansion, but it could be more actionable with additional details or examples. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The review point points out a specific issue with the abstract, where the authors claim that the proposal distribution upper bounds the target everywhere, which is not true as the authors themselves clarify in the text. However, the comment does not provide any explicit or implicit action for the authors to take. It does not suggest how the authors should address this issue or clarify the discrepancy in the abstract. Without guidance on how to resolve the contradiction or improve the clarity of the abstract, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular issue with the abstract, namely that the authors require the proposal distribution to upper bound the target everywhere, which is not true as the authors themselves clarify in the text. This provides clear guidance on what needs to be addressed in the abstract. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors require the proposal distribution to upper bound the target everywhere, which is not true as the authors themselves clarify in the text. This claim is based on a specific observation within the paper, which provides a clear and direct contradiction to the authors\" claim. The reasoning is logical and straightforward, making the claim 5. The authors can easily verify the claim by referring to the text where the clarification is made. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a specific issue with the abstract, where the authors claim that the proposal distribution upper bounds the target everywhere, which is not true as the authors themselves clarify in the text. This feedback is valuable as it points out a contradiction in the abstract, which can lead to confusion for readers. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or clarify the discrepancy. While it highlights a critical problem, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment raises questions about the policy gradient in Equation 6 and its relation to the optimal solution in Equation 5. It suggests that the authors clarify whether the policy gradient is solving the optimal problem and whether convergence leads to the optimal solution. Additionally, it points out a minor grammatical error in Line 78 and a potential typo in Line 132. While the comment identifies specific areas for clarification and correction, it does not provide explicit instructions on how to address these issues. The actions are implicit and somewhat vague, as the authors need to infer that they should clarify the relationship between the equations and correct the grammatical errors. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines and equations in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it raises questions about the policy gradient in Equation 6 and its relation to the optimal solution in Equation 5, suggesting that clarification is needed. Additionally, it points out minor grammatical errors in Lines 78 and 132, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a series of questions and suggestions, such as clarifying the relationship between equations and correcting grammatical errors. These are factual statements that do not contain subjective opinions, claims, or suggestions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises several specific questions and points out minor grammatical errors, which is helpful for the authors. It questions the relationship between the policy gradient in Equation 6 and the optimal solution in Equation 5, suggesting that clarification is needed. This feedback prompts the authors to consider the implications of their equations and potentially improve the clarity of their work. Additionally, pointing out minor grammatical errors in Lines 78 and 132 helps the authors maintain a professional tone in their writing. However, the comment could be more helpful if it provided additional context or suggestions on how to address the questions about the equations. Overall, the feedback is 4 as it directs the authors to specific areas that need attention, but it could be more comprehensive with further guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should discuss the limitations of freezing the partitioning in the first iteration, which is a risky choice that makes strong assumptions about the coverage of the initial data. This feedback provides a clear and direct action for the authors to take, which is to address the limitations of this approach. The comment is explicit and concrete, as it specifies exactly what the authors need to do to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 192,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with freezing the partitioning in the first iteration, noting that it makes strong assumptions about the coverage of the initial data. The comment further suggests that the authors should discuss the limitations of this approach. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with a score of 5.", "verifiability_rationale": "The review point claims that freezing the partitioning in the first iteration is a risky choice that makes strong assumptions about the coverage of the initial data. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this choice is risky or what specific limitations it might pose. Without additional context or explanation, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the methodology, specifically the choice to freeze the partitioning in the first iteration. It points out that this approach makes strong assumptions about the coverage of the initial data, which could be a risky choice. The comment suggests that the authors should discuss the limitations of this approach, providing a clear and actionable piece of feedback. By addressing this concern, the authors can enhance the robustness and transparency of their methodology. However, the comment could be more helpful if it offered specific suggestions on how to discuss these limitations or alternative approaches to consider. Overall, the feedback is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the need for clarification on several aspects of the approach, particularly regarding how the approach allows for knowledge about objects to interact with knowledge about verbs to overcome reporting bias. However, it does not provide explicit guidance on what specific aspects need clarification or how the authors should address these concerns. The comment suggests that the paper lacks a clear explanation of the overall approach and its benefits, but it does not offer concrete steps for improvement. As a result, the authors are left with a general idea of what needs to be clarified but without detailed instructions on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment highlights the need for clarification on several aspects of the approach, particularly regarding how the approach allows for knowledge about objects to interact with knowledge about verbs to overcome reporting bias. However, it does not specify which parts of the paper need clarification, making it weakly grounded. The comment is specific in identifying the lack of clarity regarding the approach and its benefits, but it lacks detailed guidance on what specific aspects need to be clarified. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that many aspects of the approach need clarification and questions the understanding of how the approach allows for knowledge about objects to interact with knowledge about verbs to overcome reporting bias. However, the comment does not provide specific examples or detailed reasoning to support these claims. The lack of concrete evidence or references makes it difficult for the authors to understand and address the issues raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that many aspects of the approach need clarification. It specifically questions how the approach allows for knowledge about objects to interact with knowledge about verbs to overcome reporting bias, which is a critical aspect of the methodology. However, the comment lacks specificity and does not provide detailed guidance or suggestions on how the authors might clarify these aspects. While it highlights an important area for improvement, the lack of actionable feedback limits its usefulness to the authors. Therefore, the comment is 3, as it points out a key area for improvement but does not offer detailed guidance on how to address it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the decision to use early stopping based only on link prediction accuracy should be explained. It implies that the authors should provide a rationale for this choice, such as why not using an average with type accuracy. While the comment explicitly states that an explanation is needed, it does not provide specific guidance on how to construct this explanation or what aspects to consider. The action is explicit but somewhat vague, as the authors know they need to provide an explanation but may not be entirely sure of the exact details to include. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"590,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the decision to use early stopping only by link prediction accuracy and suggests that an explanation should be provided, such as why not using an average with type accuracy. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the decision to use early stopping based only on link prediction accuracy should be explained. It questions the rationale behind this choice and suggests considering an average with type accuracy. However, the comment does not provide any specific reasoning or evidence to support why this alternative approach should be considered or why the current method is insufficient. Without additional context or justification, the claim remains somewhat vague and lacks verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the decision to use early stopping based only on link prediction accuracy. It suggests that this choice should be explained, potentially by considering an average with type accuracy. This feedback is clear and actionable, as it directs the authors to provide a rationale for their decision, which could enhance the clarity and comprehensiveness of the paper. However, the comment could be more helpful if it offered additional suggestions or examples on how to construct this explanation. Overall, the comment is 4, as it provides a clear direction for improvement but lacks depth in detailed guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the feasibility of setting a reasonable classimbalanced task in the context of fewshot learning, where there are only a few examples for each class. It explicitly asks the authors to explain this aspect with concrete details. This feedback is clear and direct, providing a specific action for the authors to take. The authors know exactly what is being asked of them and how to address the issue, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the phrase \"sampling classimbalanced tasks,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the feasibility of setting a reasonable classimbalanced task in the context of fewshot learning and asks for concrete details on how to address this issue. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the feasibility of setting a classimbalanced task in the context of fewshot learning, where there are only a few examples for each class. It does not contain a claim or opinion but rather seeks clarification from the authors. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a pertinent question about the feasibility of setting a reasonable classimbalanced task in the context of fewshot learning, where there are only a few examples for each class. It challenges the authors to explain how they would approach this issue with concrete details. This feedback is valuable as it prompts the authors to clarify an important aspect of their methodology, which could lead to a more robust and comprehensive understanding of their work. However, the comment could be more helpful if it provided suggestions or examples on how to address this challenge. Overall, the comment is 3 as it identifies a critical area for clarification but lacks detailed guidance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the chatgpt baseline as rudimentary and suggests that testing a fewshot approach and incorporating discourse relation information in the prompts might yield better results. However, it does not provide explicit instructions or concrete steps for the authors to follow. The comment implies that these additions could enhance the paper\"s evaluation, but it lacks specific guidance on how to implement them. The action is implicit and somewhat vague, making it barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"chatgpt baseline\" and the \"fewshot approach,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the rudimentary nature of the chatgpt baseline and suggesting improvements, such as testing the fewshot approach and incorporating discourse relation information in the prompts. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the chatgpt baseline is rudimentary and suggests that testing a fewshot approach and incorporating discourse relation information in the prompts might yield better results. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. The suggestion to include discourse relation information is not fully explained, and the claim about the rudimentary nature of the chatgpt baseline is not substantiated with evidence or comparisons. This makes the claim 3, as it provides a general direction for improvement but lacks detailed justification or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a weakness in the chatgpt baseline, noting that it is rudimentary and lacks testing of a fewshot approach. It suggests that incorporating discourse relation information in the prompts, possibly through a ChainofThought style approach, could yield better results. This feedback is clear and actionable, as it provides a specific direction for improvement by suggesting an additional evaluation method. However, the comment could be more helpful if it offered more detailed guidance on how to implement the suggested approach or provided examples of similar studies that have successfully incorporated discourse relation information. Overall, the comment is 4 as it offers a constructive suggestion for enhancing the paper\"s evaluation, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the authors do not provide sufficient details on how the ground truth of sensitivity is achieved, specifically regarding the process of pruning. While the comment highlights a gap in the explanation, it does not provide explicit guidance on what additional information should be included or how the authors should address this issue. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more detailed explanations about the pruning process. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 238239, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of detailed explanation on how the ground truth of sensitivity is achieved, particularly regarding the process of pruning. The comment provides a clear direction for the authors to improve their draft by detailing the pruning process. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors do not provide sufficient details on how the ground truth of sensitivity is achieved, specifically regarding the process of pruning. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or explanation, the authors may find it challenging to understand the exact nature of the issue or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the authors have not provided sufficient details, specifically regarding the process of achieving the ground truth of sensitivity. It points out that the explanation in lines 238239 is insufficient, as it only mentions \"pruning\" without elaborating on the actual method used. This feedback is clear and actionable, as it directs the authors to provide more detailed information on the pruning process, which could significantly enhance the clarity and comprehensibility of the paper. However, the comment could be more helpful if it suggested specific aspects of the pruning process that need to be explained or provided examples of how other papers have addressed similar issues. Overall, the comment is 4, as it effectively guides the authors toward improving their draft by addressing a critical gap in the explanation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to present the results comparing standard vs. evolutional dropout on shallow models as a mean over many runs (at least 10), ideally with errorbars. It also notes that the plotted curves are from single runs and might be subject to significant fluctuations, suggesting that the models are small and should not be an excuse for not providing statistics. This feedback is clear and provides concrete steps for the authors to take, ensuring they know exactly what changes to make to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the results comparing standard vs. evolutional dropout on shallow models, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely presenting the results as a mean over many runs (at least 10) with errorbars, and explaining why the current presentation might be subject to significant fluctuations. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the results comparing standard vs. evolutional dropout on shallow models should be presented as a mean over many runs, ideally with errorbars, to account for potential fluctuations. The reviewer provides a logical reasoning by noting that the plotted curves are from single runs, which could lead to significant fluctuations due to the small size of the models. This reasoning is clear and provides a basis for the suggestion, making the claim 4. However, the comment could be strengthened by providing specific examples or references to support the claim about the need for statistical analysis. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides clear and actionable feedback by suggesting that the results comparing standard vs. evolutional dropout on shallow models should be presented as a mean over multiple runs, ideally with errorbars, to account for potential fluctuations. This recommendation is important for ensuring the robustness and reliability of the results, particularly given the small size of the models. The comment is specific and offers a concrete suggestion for improvement, making it 5 for the authors to enhance the quality and clarity of their draft. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment provides explicit feedback on specific sections of the paper, indicating that the reviewer has difficulty understanding the content and suggests that the authors clarify their explanations. The comment explicitly states that the paragraph from lines 156 to 166 is unclear and that the figure is hard to understand. It also provides a concrete suggestion to clarify the explanation of the dashed lines in the figure. This feedback is clear and actionable, as it directs the authors to specific parts of the paper that need improvement and offers a concrete way to address the issue. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific lines (L156166) that are unclear, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the paragraph, noting that the reviewer has difficulty understanding it and suggesting that the authors clarify their explanation. Additionally, the comment provides specific feedback on the figure, stating that the dashed lines are too vague to be understood concretely. This level of detail and specificity helps the authors understand what needs to be addressed in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paragraph from lines 156 to 166 is unclear and that the figure is hard to understand. The reviewer provides specific examples, such as the difficulty in understanding the dashed lines in the figure, which helps to substantiate the claim. However, the comment lacks detailed reasoning or references to support why the paragraph is unclear or how the figure could be improved. While the examples provide some basis for the claim, the lack of comprehensive explanation or references makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on two distinct issues: the clarity of a particular paragraph and the understanding of a figure. It identifies the paragraph from lines 156 to 166 as unclear, suggesting that the authors clarify their explanation. Additionally, it points out that the figure is hard to understand due to vague explanations, such as the dashed lines indicating the agent\"s ability to plan ahead. This feedback is clear and actionable, as it directs the authors to specific parts of the paper that need improvement and offers concrete suggestions on how to enhance clarity. By addressing these issues, the authors can significantly improve the readability and comprehensibility of their draft. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the evaluation metric should be mentioned in the text to better understand the scale of the improvement and for comparability with the results reported in the paper. It also points out the specific expression used in Fern\u00e1ndezGonz\u00e1lez and G\u00f3mezRodr\u00edguez (2020) to clarify the evaluation metric. This feedback is explicit and provides concrete guidance on what needs to be done, making it 5. The authors know exactly what needs to be added to their draft to improve clarity and comparability. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lines (078079 / Line 08) where the issue is located, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the evaluation metric should be mentioned to better understand the scale of the improvement and for comparability with the results reported in the paper. Additionally, it provides a specific example of the expression used in Fern\u00e1ndezGonz\u00e1lez and G\u00f3mezRodr\u00edguez (2020) to clarify the evaluation metric. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the evaluation metric should be mentioned to better understand the scale of the improvement and for comparability with the results reported in the paper. It references a specific expression used in Fern\u00e1ndezGonz\u00e1lez and G\u00f3mezRodr\u00edguez (2020) to clarify the evaluation metric. This provides a clear and specific reference to support the claim, making the comment 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how the evaluation metric impacts the results. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the evaluation metric should be mentioned in the text to better understand the scale of the improvement and for comparability with the results reported in the paper. It references a specific expression used in Fern\u00e1ndezGonz\u00e1lez and G\u00f3mezRodr\u00edguez (2020) to clarify the evaluation metric, which is a concrete example that can guide the authors in improving their draft. This feedback is clear and detailed, offering the authors a direct path to enhance the clarity and comprehensibility of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point raises an interesting question about how DVP performs on videos of different lengths. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should investigate this further, include additional analysis, or address this issue in their paper. The comment lacks actionable details, leaving the authors uncertain about how to proceed. Therefore, it is 1.", "grounding_specificity_rationale": "The comment raises an interesting question about how DVP performs on videos of different lengths. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspect of DVP\"s performance on differentlength videos is being questioned. Without clear grounding or specificity, the authors are left without a clear understanding of what needs to be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification about how DVP performs on videos of different lengths. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises an interesting question about how DVP performs on videos of different lengths. However, it does not provide any actionable feedback or suggestions for the authors to address this question or improve their draft. The comment lacks specificity and does not offer any guidance on how the authors might explore or investigate this aspect further. As a result, the comment is 1, as it does not provide the authors with any actionable insights or direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to evaluate the approximation error by calculating the actual KLdivergence and checking whether it approaches zero. This is a clear and direct action that the authors can follow to address the concern. The comment provides a specific method for evaluation, making it 5. Therefore, this comment aligns with a score of 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the proposed training objective, namely the omission of the KLdivergence term in equation (3). The comment further suggests evaluating the approximation error by calculating the actual KLdivergence and checking whether it approaches zero. This provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point claims that the proposed training objective has ignored the KLdivergence term in equation (3) and suggests evaluating the approximation error by calculating the actual KLdivergence. This is a logical claim that requires verification through calculations or experiments to determine the accuracy of the approximation. However, the comment does not provide specific examples or references to support the claim, making it 3. The authors would need to conduct additional analysis to fully substantiate the claim, which is a minor gap in the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed training objective, noting that it has ignored the KLdivergence term in equation (3). It suggests that the authors evaluate the approximation error by calculating the actual KLdivergence and checking whether it indeed approaches zero. This feedback is clear and actionable, providing the authors with a concrete step to take to address the concern. By suggesting a method for evaluation, the comment offers a direct path for improvement, making it 5. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that it would be interesting to further discuss or specify the situations where the losses are particularly helpful, such as for specular areas. While the comment implies that the authors should provide additional discussion or examples, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that it would be interesting to further discuss or specify the situations where the losses are particularly helpful, such as for specular areas. However, it does not specify which part of the paper this discussion should be added to, making it weakly grounded. The comment is specific in suggesting a particular area of interest, namely the situations where the losses are beneficial. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it would be interesting to further discuss or specify the situations where the losses are particularly helpful, such as for specular areas. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this discussion would be beneficial or how it could enhance the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that it would be interesting to further discuss or specify the situations where the losses are particularly helpful, such as for specular areas. This feedback provides a clear direction for the authors to enhance their paper by offering a specific area for additional discussion or analysis. However, the comment could be more helpful if it included suggestions on how to approach this discussion or what aspects to focus on. Despite this, the feedback is actionable and encourages the authors to expand their work, making it 4. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the major contributions of the paper are unclear and that analyzing previous work does not constitute a contribution. However, it does not provide any explicit or implicit guidance on how the authors should address this issue or clarify their contributions. There is no suggestion on what specific aspects of the paper should be highlighted as contributions or how the authors might reframe their work to better articulate its contributions. Without actionable advice or concrete steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the lack of clarity regarding the paper\"s major contributions, specifically questioning whether analyzing previous work constitutes a contribution. However, it does not specify which part of the paper this issue pertains to, such as a particular section or discussion where the contributions are outlined. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its critique of the contributions, but without clear grounding, it remains 2. Therefore, this comment aligns with a score of 2.", "verifiability_rationale": "The review point claims that the major contributions of the paper are unclear and that analyzing previous work does not constitute a contribution. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide references to other works that have made significant contributions or explain why analyzing previous work is insufficient. Without these details, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, namely the lack of clarity regarding its major contributions. It points out that analyzing previous work alone does not constitute a contribution, which is a valid critique. However, the comment does not provide specific suggestions or guidance on how the authors might clarify or enhance their contributions. Without actionable advice or examples, the authors are left without a clear path to improve their draft. Therefore, the comment is 3, as it highlights an important area for improvement but lacks depth and specificity in its feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly points out that Algorithm 2 does not specify how to determine n_t and questions the meaning of \"appropriate number\" in line 225. It also mentions that the answer is not found in reference 30. This feedback provides clear and direct actions for the authors to take: they need to clarify how n_t is determined and explain the meaning of \"appropriate number\" in line 225. The comment is explicit and provides concrete guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 2\" and \"line 225,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of determining n_t and the meaning of \"appropriate number\" in line 225, and it references a specific reference 30 where the answer is not found. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the clarity of Algorithm 2 by pointing out that it does not specify how to determine n_t and questions the meaning of \"appropriate number\" in line 225. The reviewer also mentions that the answer is not found in reference 30. This provides a clear and specific critique, but it lacks additional context or references to fully substantiate the claim. The authors would need to address these points to clarify the algorithm, but the comment itself does not provide detailed reasoning or evidence to fully support the claim. Therefore, the comment is 3, as it highlights areas for improvement but requires further elaboration from the authors.", "helpfulness_rationale": "The review comment identifies a specific issue with Algorithm 2, noting that it does not specify how to determine n_t and questions the meaning of \"appropriate number\" in line 225. It also mentions that the answer is not found in reference 30. This feedback is clear and actionable, as it directs the authors to clarify these aspects of their algorithm, which is crucial for the paper\"s comprehensibility and reproducibility. By addressing these points, the authors can significantly improve the clarity and transparency of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the claims about the mixing time being \"even better\" in practice, stating that the evidence provided is insufficient and limits the usefulness for practitioners. However, it does not provide explicit guidance or suggestions on how the authors could improve the evidence or support for these claims. The comment lacks actionable details, such as recommending specific experiments or analyses that could strengthen the evidence. As a result, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the claims about the mixing time being \"even better\" in practice, suggesting that the evidence provided is insufficient. However, it does not specify which part of the paper these claims are made in, nor does it provide details on what specific evidence is lacking or how it could be improved. Without explicit references to sections, figures, or specific claims, the authors cannot confidently determine which parts of the paper need revision. This lack of grounding and specificity makes it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the evidence provided to support the claim that \"in practice the mixing time is even better\" is insufficient. However, the comment does not provide specific examples or detailed reasoning to substantiate this claim. Without additional context or references, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the claims made in the paper regarding the mixing time being \"even better\" in practice. It points out that the evidence provided is insufficient, limiting the usefulness of the claims for practitioners. However, the comment does not provide specific suggestions or guidance on how the authors could strengthen the evidence or improve the claims. Without actionable feedback or detailed advice, the authors are left with a general understanding of the issue but without a clear path to address it. Therefore, the comment is 3, as it highlights a critical area for improvement but lacks depth and specificity in its guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests extending the protected feature \"A\" to a vector form, implying that it currently represents a single attribute. However, it does not provide explicit instructions on how to implement this suggestion or what specific attributes should be included in the vector form. The action is implicit and somewhat vague, as the authors need to infer that they should expand the feature \"A\" into a vector representation and determine which attributes to include. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests extending the protected feature \"A\" to a vector form, implying that it currently represents a single attribute. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where the protected feature is discussed. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. The comment is specific in suggesting a potential improvement, but without clear grounding, it is challenging for the authors to address it effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests extending the protected feature \"A\" to a vector form, implying that it currently represents a single attribute. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this extension would be beneficial or how it might improve the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests extending the protected feature \"A\" to a vector form, implying that it currently represents a single attribute. This feedback is 3 as it provides a potential direction for improvement, suggesting that the authors might consider expanding the feature to include multiple attributes. However, the comment lacks specificity and does not provide detailed guidance on how to implement this suggestion or what specific attributes should be included in the vector form. While it offers a general idea for enhancement, the lack of detailed instructions limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point raises several questions and suggestions regarding the notation and computation details in the paper. It explicitly asks for clarification on how the vectors are represented and suggests denoting this explicitly. Additionally, it inquires about the normalization of vectors and the method used for computing nearest neighbors. These questions and suggestions provide clear and concrete actions for the authors to take, such as clarifying the notation and sharing computation details. The feedback is explicit and provides specific guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 223,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear suggestions for clarification, such as denoting the vector representations of words, asking about normalization, and specifying the method used for computing nearest neighbors. The comment details what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a series of questions and suggestions, such as asking for clarification on the notation and computation details. It does not contain subjective opinions, judgments, or claims that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 5 as it provides specific and actionable feedback. It identifies a potential issue with the notation used in the paper, suggesting that the authors clarify the meaning of \"x and t\" in the equations. Additionally, it raises questions about the normalization of vectors and the method used for computing nearest neighbors, which are important details that could impact the interpretation of the results. By addressing these points, the authors can enhance the clarity and comprehensibility of their work. The comment is detailed and constructive, offering clear guidance on how to improve the draft, making it 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point expresses a belief that the proposed transductive method is not very novel, suggesting that it is related to a common way to incorporate unlabeled data in semisupervised methods. However, the comment does not provide any specific guidance or suggestions on how the authors might address this concern or improve the novelty of their method. It lacks explicit instructions or concrete details on what the authors should do to enhance the novelty of their approach. As a result, the comment is vague and does not offer actionable advice, making it 1.", "grounding_specificity_rationale": "The comment suggests that the proposed transductive method is not very novel, as it is related to a common way to incorporate unlabeled data in semisupervised methods. However, it does not specify which part of the paper this claim pertains to, such as a specific section or methodology discussion. This lack of grounding makes it difficult for the authors to identify the exact part of the paper being addressed. Additionally, while the comment provides some insight into the potential lack of novelty, it does not specify what aspects of the method are not novel or how they could be improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the proposed transductive method is not very novel, suggesting that it is related to a common way to incorporate unlabeled data in semisupervised methods. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses a belief that the proposed transductive method is not very novel, suggesting that it is related to a common way to incorporate unlabeled data in semisupervised methods. However, the comment lacks specificity and does not provide any detailed reasoning or examples to support this claim. It does not offer actionable feedback or suggestions for improvement, leaving the authors without a clear understanding of how to address the perceived lack of novelty. As a result, the comment is 1, as it does not provide any constructive guidance for the authors to enhance their work."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a specific issue with the feature comparison in the paper, noting that it is shallow and missing two relevant papers. However, it does not provide explicit guidance on how to address this issue or suggest which specific features should be compared or how to incorporate the missing papers. The action is implicit, as the authors can infer that they need to expand the feature comparison to include these papers, but the comment lacks concrete details on how to implement this change. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment identifies a specific issue with the feature comparison in the paper, noting that it is shallow and missing two relevant papers. However, it does not specify which part of the paper this feature comparison is discussed in, nor does it provide details on which specific features are missing or how they should be incorporated. This makes it difficult for the authors to pinpoint the exact sections that need revision. The comment is weakly grounded as it does not specify the part of the paper being addressed, and it is not specific because it lacks detailed guidance on what needs to be addressed. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the feature comparison in the paper is shallow and missing two relevant papers. However, it does not provide any specific examples or references to these missing papers, nor does it explain why the current feature comparison is insufficient. Without detailed justification or evidence, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the feature comparison in the paper, noting that it is shallow and missing two relevant papers. This feedback is clear and actionable, as it directs the authors to expand their feature comparison to include these missing papers. However, the comment could be more helpful if it provided specific suggestions on which features to compare or how to incorporate the missing papers into the analysis. Despite this, the comment is 4 as it highlights a critical area for improvement and guides the authors toward enhancing the depth and comprehensiveness of their feature comparison. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should use the word \"equivalent\" more cautiously, particularly if the equivalence is not verified. This is a clear and direct action for the authors to take, as it specifies what needs to be done to improve the draft. The comment provides a concrete suggestion, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (8, 56, 70, and 93) where the word \"equivalent\" is used. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it suggests a more cautious usage of the word \"equivalent,\" particularly if the equivalence is not verified. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the usage of the word \"equivalent\" should be more cautious, particularly if the equivalence is not verified. This is a subjective claim that requires justification or evidence to support the need for caution. The comment does not provide specific examples or references to substantiate why the usage of \"equivalent\" is problematic or how it could be improved. Without additional context or reasoning, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies specific instances where the word \"equivalent\" is used and suggests that its usage should be more cautious, particularly if the equivalence is not verified. This is a clear and actionable piece of feedback that can help the authors refine their language and ensure that their claims are supported by evidence. However, the comment could be more helpful if it provided examples of how the authors might rephrase their statements to be more accurate or if it suggested alternative language to use. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the effectiveness of the multiview clustering approach, specifically questioning the usefulness of the other views when the paraphrase similarity view consistently outperforms them. The reviewer suggests that a more detailed analysis of the differences and similarities between these views is needed to draw solid conclusions. While the comment implies that the authors should conduct a more detailed analysis, it does not provide explicit instructions on how to achieve this or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors can infer that they need to conduct a more detailed analysis but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"multiview clustering approach\" and the \"paraphrase similarity view,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the effectiveness of the other views and suggesting that a more detailed analysis is needed to understand the differences and similarities between these views. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the effectiveness of the multiview clustering approach, specifically noting that the paraphrase similarity view consistently outperforms the other views. The reviewer suggests that without a more detailed analysis of the differences and similarities between these views, it is difficult to draw solid conclusions about their usefulness. While the comment highlights a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to conduct further analysis to address the concern, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the multiview clustering approach, noting that the paraphrase similarity view consistently outperforms the other views. It questions the usefulness of the other views and suggests that a more detailed analysis is needed to understand the differences and similarities between these views. This feedback is clear and actionable, as it points out a gap in the analysis and provides a direction for improvement by recommending a more comprehensive evaluation of the different views. However, the comment could be more helpful if it offered specific suggestions on how to conduct this analysis or what aspects to focus on. Overall, the comment is 4, as it effectively guides the authors toward enhancing their analysis and understanding of the multiview clustering approach."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of clarity in the explanation of the architecture used for the experiments, noting that the authors refer to an external source for details. This implies that the authors should provide a more detailed explanation of the architecture within the paper, making it selfcontained. While the comment identifies the need for improvement, it does not provide specific guidance on how to enhance the explanation or what details should be included. The action is implicit and somewhat vague, as the authors can infer that they need to improve the explanation but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"architecture used for the experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity in the explanation of the architecture and the reliance on an external source for details. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point claims that the paper lacks selfcontained information because it refers to an external source for details on the architecture used for experiments. However, the comment does not provide specific examples or references to the external source, making it difficult for the authors to understand the exact issue or how to address it. The lack of detailed explanation or references makes the claim 3, as the authors would need to invest effort to identify and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the architecture used for the experiments is not clearly explained within the paper. Instead, the authors refer to an external source for details, which makes the paper less selfcontained. This feedback is clear and actionable, as it highlights a critical area for improvement that the authors need to address to enhance the comprehensibility and selfsufficiency of their work. However, the comment could be more helpful if it provided specific suggestions on how to improve the explanation of the architecture within the paper. Overall, the comment is 4, as it directs the authors to a key area that needs attention, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that BertScore and BLEURT are inconsistently typeset throughout the paper, suggesting that consistency should be maintained. This provides a clear and direct action for the authors to take, which is to ensure that these terms are consistently typeset across the paper. The comment is specific and provides a concrete step for the authors to follow, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"BertScore and BLEURT,\" allowing the authors to accurately identify the parts of the paper where these terms are inconsistently typeset. It also specifies the issue by suggesting that consistency should be maintained, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about the inconsistent typesetting of \"BertScore\" and \"BLEURT\" throughout the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the terms \"BertScore\" and \"BLEURT\" are inconsistently typeset throughout the paper. This feedback is clear and actionable, as it provides a straightforward suggestion to maintain consistency in the typesetting of these terms. By addressing this issue, the authors can improve the professionalism and clarity of their paper. However, the comment could be more helpful if it provided additional context or explained why consistency is important. Overall, the feedback is 4, as it directs the authors to a specific improvement that can enhance the quality of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point identifies several specific issues with the presentation quality of the paper, such as the use of \"\" in tables, the lack of informative \"Dataset\" columns, and the management of Figure 3 and Table 2. However, it does not provide explicit guidance on how to address these issues or suggest specific actions for improvement. The authors can infer that they need to improve the presentation quality, but the comment lacks concrete details on how to do so. Therefore, the comment is 3, as it identifies areas for improvement but does not provide detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific aspects of the paper, such as Figures 1&2, tables with a \"\" for the method, the \"Dataset\" columns in the tables, the management of Figure 3 and Table 2, and a \"*\" appearing in Table 1 with no indication of meaning. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it details what aspects of the presentation quality are considered weaknesses, providing clear guidance on what needs to be improved. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point identifies specific issues with the presentation quality of the paper, such as the use of \"\" in tables, the lack of informative \"Dataset\" columns, and the management of Figure 3 and Table 2. However, it does not provide detailed reasoning or examples to support why these aspects are considered weaknesses or how they impact the overall quality of the paper. The comment lacks specific references or evidence to substantiate the claim, making it difficult for the authors to understand and address the issues effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail and justification.", "helpfulness_rationale": "The review comment identifies specific issues with the presentation quality of the paper, such as the use of \"\" in tables, the lack of informative \"Dataset\" columns, and the management of Figure 3 and Table 2. It also points out the appearance of a \"*\" in Table 1 without explanation. While the comment highlights areas for improvement, it does not provide detailed guidance or suggestions on how to address these issues. The feedback is 3 as it directs the authors\" attention to specific aspects of the presentation that need attention, but it lacks actionable advice or examples of how to improve these areas. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include related experiments that demonstrate the effectiveness of the \"information axis\" tool. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on what kind of experiments should be conducted or how to implement them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should include related experiments to demonstrate the effectiveness of the \"information axis\" tool. However, it does not specify which part of the paper this suggestion pertains to, such as the conclusion or a specific section where the tool is discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the inclusion of related experiments, but without clear grounding, it remains 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the paper uses much analysis to justify the effectiveness of the \"information axis\" tool but lacks related experiments to demonstrate its practical application. The comment is based on the reviewer\"s observation that the conclusion does not include such experiments. However, it does not provide specific examples or references to support the claim that related experiments are necessary or how they would enhance the paper. The lack of detailed reasoning or evidence makes the claim 3, as the authors would need to infer the need for additional experiments based on the reviewer\"s suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential gap in the paper by suggesting that the authors should include related experiments to demonstrate the effectiveness of the \"information axis\" tool. This feedback is 3 as it points out an area for improvement, encouraging the authors to provide practical applications or examples of the tool\"s utility. However, the comment lacks specificity and does not offer detailed guidance on what kind of experiments should be conducted or how to integrate them into the paper. While it provides a direction for improvement, it could be more helpful with additional details or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the text in lines 293295 makes the above point unclear and difficult for readers to understand. It suggests that the results are acceptable, but it does not provide specific guidance on how to clarify the text or improve its clarity. The action is implicit, as the authors need to infer that they should revise the text to make it clearer. Additionally, the comment lacks concrete details on how to achieve this clarity, making it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific lines (293295) where the issue is identified, allowing the authors to accurately pinpoint the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity in the text and the difficulty for readers to understand and evaluate the results. The comment provides a clear direction for improvement by suggesting that the text should be clarified to make the point more understandable. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the text in lines 293295 makes the point unclear and difficult for readers to understand. However, it does not provide any specific examples or detailed reasoning to support this claim. The comment lacks evidence or explanation, making it difficult for the authors to understand the basis of the critique. Without additional context or examples, the claim remains 1, as the authors are left without a clear understanding of what needs to be addressed or improved. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the text in lines 293295, suggesting that it makes the point unclear and difficult for readers to understand. This feedback is 3 as it points out a potential area for improvement, allowing the authors to focus their attention on clarifying the text. However, the comment lacks detailed guidance or suggestions on how to improve the clarity, such as proposing alternative phrasing or additional explanations. While it provides some direction, it could be more helpful with more specific feedback. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a significant issue with the organization and clarity of the proofs, noting that they are difficult to follow and rigorously check for correctness. It specifically mentions Lemma 3 and questions whether the result holds for any polynomial function. This feedback provides a clear and explicit action for the authors to improve the organization and clarity of their proofs, as well as to address the specific concern about Lemma 3. The comment is 5 as it identifies a specific area for improvement and provides a concrete question to consider, giving the authors clear guidance on how to enhance their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lemma 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue of poor organization and clarity in the proofs, providing a concrete example with the question about Lemma 3. This level of detail helps the authors understand what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point claims that the proof is not well organized and difficult to follow, providing a specific example with Lemma 3. The reviewer questions whether the result holds for any polynomial function, which is a logical and relevant inquiry. However, the comment lacks detailed reasoning or examples to fully substantiate the claim about the overall organization and clarity of the proofs. While it provides a specific question, it does not offer comprehensive evidence or justification for the broader claim. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed support to be fully convincing.", "helpfulness_rationale": "The review comment identifies a significant issue with the organization and clarity of the proofs, noting that they are difficult to follow and rigorously check for correctness. It provides a specific example by questioning whether the result in Lemma 3 holds for any polynomial function, which is a concrete and actionable suggestion for the authors to address. This feedback is clear and provides a clear direction for improvement, making it 4. However, it could be more helpful if it offered additional guidance on how to improve the organization or clarity of the proofs. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should conduct experiments on realworld datasets instead of synthetic datasets, particularly for the outofdistribution setting. This is an explicit suggestion that provides a clear action for the authors to take. However, the comment does not specify which realworld datasets should be used or how to conduct the experiments, leaving some room for ambiguity. While the action is explicit, the lack of concrete details makes it 3.", "grounding_specificity_rationale": "The comment suggests that the paper should conduct experiments on realworld datasets instead of synthetic datasets, particularly for the outofdistribution setting. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper that needs revision. Additionally, while the comment provides a specific suggestion for improvement, it does not specify why conducting experiments on realworld datasets is necessary or how it would address the issue. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the paper should conduct experiments on realworld datasets instead of synthetic datasets, particularly for the outofdistribution setting. This claim is based on the premise that the paper claims to address realistic scenarios, which implies that realworld datasets are more appropriate for evaluation. However, the comment lacks specific reasoning or examples to support why realworld datasets are necessary or how they would provide a more accurate evaluation. Without detailed justification or references, the claim remains 3, as the authors would need to infer the rationale themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the paper should conduct experiments on realworld datasets instead of synthetic datasets, particularly for the outofdistribution setting. This feedback is 3 as it highlights a potential limitation in the current experimental setup and provides a specific suggestion for improvement. However, the comment lacks detailed guidance on which realworld datasets to use or how to conduct the experiments, which would make the feedback more actionable. Additionally, it does not explain why realworld datasets are more appropriate for the outofdistribution setting, leaving the authors with some uncertainty about the rationale behind the suggestion. Therefore, the comment is rated as 3, as it provides a direction for improvement but lacks depth and specificity."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point claims that the proposed approach to pretraining has limited novelty because it follows the strategies used in ELECTRA. However, it does not provide any specific guidance or suggestions on how the authors could address this issue or improve the novelty of their approach. The comment lacks actionable details, such as recommending alternative strategies or suggesting ways to differentiate the approach from ELECTRA. As a result, the authors are left without a clear understanding of what steps to take to enhance the novelty of their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the novelty of the proposed approach to pretraining, stating that it \"more or less just follows the strategies used in ELECTRA.\" However, it does not specify which part of the paper this critique pertains to, such as a specific section or methodology discussion. Without explicit references, the authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity regarding what aspects of the approach are similar to ELECTRA or how the authors could differentiate their work. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the proposed approach to pretraining has limited novelty because it \"more or less just follows the strategies used in ELECTRA.\" However, the comment does not provide any specific examples, comparisons, or references to support this claim. Without detailed evidence or reasoning, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment points out that the proposed approach to pretraining has limited novelty because it follows the strategies used in ELECTRA. However, it does not provide any specific examples or details on how the approach is similar to ELECTRA or how it could be improved to enhance novelty. Without actionable suggestions or constructive feedback, the authors are left without a clear understanding of what aspects of their approach need to be revised or how to differentiate it from existing methods. As a result, the comment is 1, as it does not offer any guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the motivation for using the Newton algorithm in Section 4 is lacking and proposes that a bisecting line search would suffice for a 1dimensional line search on a convex function. It questions the impact of quadratic convergence on the algorithm\"s runtime and suggests conducting experiments to motivate the need for the analysis/algorithm. While the comment implies that the authors should provide more motivation and conduct experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the motivation and conduct experiments. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the motivation for using the Newton algorithm, questioning its necessity and suggesting that a bisecting line search would suffice. The comment further specifies that experiments could help motivate the need for the analysis/algorithm. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the motivation for using the Newton algorithm in Section 4 is lacking and suggests that a bisecting line search would suffice for a 1dimensional line search on a convex function. The reviewer questions the impact of quadratic convergence on the algorithm\"s runtime and suggests conducting experiments to motivate the need for the analysis/algorithm. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion about the impact of quadratic convergence on runtime. This makes the claim 3, as it requires further elaboration or evidence to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper\"s motivation for using the Newton algorithm, suggesting that a bisecting line search would suffice for a 1dimensional line search on a convex function. It questions the impact of quadratic convergence on the algorithm\"s runtime and suggests conducting experiments to motivate the need for the analysis/algorithm. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their draft by conducting experiments to demonstrate the significance of the Newton algorithm. However, the comment could be more helpful if it included suggestions on how to design these experiments or what specific aspects to focus on. Overall, the comment is 4, as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the proposed upweighing and KNN methods, suggesting that they do not appear to be idiomspecific based on the results shown in Figure 3. The comment implies that the methods are not effective in distinguishing between idiomatic and random data, and it concludes that the results indicate that better NMT systems are also better at idiomatic translations. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their methods. The action is implicit and vague, as the authors are left without clear direction on how to enhance their work. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the proposed upweighing and KNN methods\" and refers to Figure 3, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the methods, noting that the impact on idiomatic versus random data is similar for most language and score combinations, leading to the conclusion that the methods are not idiomspecific. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed upweighing and KNN methods do not appear to be idiomspecific, as the impact on idiomatic versus random data is similar for most language and score combinations. The comment supports this claim by referencing Figure 3, which provides a visual representation of the results. This visual evidence helps substantiate the claim, making it 4. However, the comment could be strengthened by providing more detailed analysis or examples from Figure 3 to fully support the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a critical analysis of the proposed upweighing and KNN methods, suggesting that they do not appear to be idiomspecific based on the results shown in Figure 3. It points out that the impact on idiomatic versus random data is similar for most language and score combinations, leading to the conclusion that the methods are not effective in distinguishing between idiomatic and random data. This feedback is valuable as it highlights a potential limitation of the proposed methods and suggests that the results may not be as idiomspecific as claimed. However, the comment could be more helpful if it offered suggestions on how to address this issue or improve the methods to better capture idiomspecific characteristics. Overall, the comment is 3 as it identifies a weakness but lacks actionable guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential confusion regarding the number of biases and kernels in the model. It suggests that the resulting volume should be WxHx1 and the bias should be a scalar, but the authors only found a hyperparameter for the feed forward models described in section 3.4. The comment implies that the authors should clarify this aspect of their model, but it does not provide explicit instructions on how to do so. While the action is implicit, it is 3 as it points out a specific area for clarification. However, the lack of concrete guidance on how to address the issue limits the actionability.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 3.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the confusion regarding the number of biases and kernels in the model, suggesting that the resulting volume should be WxHx1 and the bias should be a scalar. The comment clarifies that the authors only found a hyperparameter for the feed forward models described in section 3.4, which is confusing. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the resulting volume should be WxHx1 and the bias should be a scalar, suggesting that the authors may have misunderstood the number of biases and kernels in their model. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential confusion regarding the number of biases and kernels in the model, suggesting that the resulting volume should be WxHx1 and the bias should be a scalar. It points out that the authors only found a hyperparameter for the feed forward models described in section 3.4, which is confusing. This feedback is clear and actionable, as it highlights a specific area where the authors need to clarify their model architecture. By addressing this issue, the authors can improve the clarity and comprehensibility of their work. However, the comment could be more helpful if it provided additional guidance on how to resolve the confusion or suggested specific ways to clarify the model structure. Overall, the comment is 4, as it directs the authors to a critical area for improvement but could be more comprehensive with further guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests showing the smoothed GT shapes in Figures 3 and 5 to improve the understanding of the reconstruction quality. While the suggestion is explicit, it lacks concrete details on how to implement this change, such as whether the smoothed GT shapes should be added as an overlay or as a separate figure. The comment also mentions a \"minor concern,\" but this is not elaborated upon, leaving the authors uncertain about its significance. Therefore, the action is explicit but somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment suggests showing the smoothed GT shapes in Figures 3 and 5 to improve the understanding of the reconstruction quality. However, it does not specify which part of the paper these figures are located in, making it weakly grounded. The comment is specific in suggesting a particular change to improve the clarity of the figures, but without explicit references to the figures, the authors may struggle to identify the exact sections needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests showing the smoothed GT shapes in Figures 3 and 5 to improve the understanding of the reconstruction quality. This is a request for clarification or enhancement, not a claim or opinion that requires verification. It is a factual statement that does not need justification or evidence. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment suggests a specific improvement to the figures by recommending the inclusion of smoothed GT shapes in Figures 3 and 5. This suggestion is clear and actionable, as it provides a concrete way for the authors to enhance the clarity and understanding of their results. By showing the smoothed GT shapes, the authors can better demonstrate the quality of the reconstruction, which is a valuable addition to the figures. However, the comment does not elaborate on why this suggestion is important or how it would impact the overall understanding of the paper. While it offers a specific improvement, it could be more helpful with additional context or explanation. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the generalizability of the method to other domains and questions the selection of event types from Freebase. It explicitly asks for clarification on how the event types were selected and what the coverage is on the 33 event types in the ACE data. These questions provide clear and direct actions for the authors to take, such as providing more information on the selection process and coverage. The feedback is explicit and concrete, giving the authors specific steps to address the concerns. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment raises concerns about the generalizability of the method and questions the selection of event types from Freebase. It specifically mentions Section 2, line 262, which provides some grounding by indicating the part of the paper where the issue is discussed. However, it does not specify what needs to be addressed in this part, such as how the event types were selected or what the coverage is on the 33 event types in the ACE data. While the authors can infer that the comment relates to the selection of event types, the lack of specificity in detailing what needs to be addressed makes it 2. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point raises concerns about the generalizability of the method and questions the selection of event types from Freebase. It specifically asks for clarification on how the event types were selected and what the coverage is on the 33 event types in the ACE data. However, the comment does not provide any supporting evidence, reasoning, or references to justify these concerns. Without additional context or explanation, the authors may find it challenging to address the issues raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the generalizability of the method to other domains, specifically questioning the selection of event types from Freebase and the coverage on the 33 event types in the ACE data. This feedback is clear and actionable, as it prompts the authors to provide more information on the selection process and coverage, which could enhance the transparency and applicability of their method. However, the comment could be more helpful if it suggested specific ways to address these concerns or provided examples of how to improve generalizability. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to include important references for domain adaptation and to discuss them in the revised manuscript. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and concrete, making it 5.", "grounding_specificity_rationale": "The comment suggests that the paper lacks important references for domain adaptation and instructs the authors to include them in the revised manuscript. However, it does not specify which references are missing or which parts of the paper should include these references. Without explicit guidance on where to incorporate these references, the authors may find it challenging to identify the exact sections that need revision. The comment is weakly grounded as it does not specify the part of the paper being addressed, and it is not specific about the references that are missing. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the paper lacks important references for domain adaptation and suggests that the authors should include them. However, the comment does not provide specific examples of the missing references or explain why they are crucial. Without detailed justification or references to support the claim, the authors may find it challenging to understand the importance of these references and how to incorporate them into their manuscript. Therefore, the claim is considered 2, as it lacks sufficient evidence or explanation to fully substantiate the need for these references.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of important references for domain adaptation. It provides a clear and actionable suggestion for the authors to include these references and discuss them in the revised manuscript. This feedback is valuable as it directs the authors to a specific area for improvement, ensuring that their work is more comprehensive and aligned with current literature. However, the comment could be more helpful if it specified which references are missing or why they are crucial for the paper. Overall, the comment is 4 as it guides the authors toward enhancing the depth and relevance of their work."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the SCNN getting \"lucky\" on domain pricing, suggesting that the chosen hyperparameters might be at the end of the searched range and that the distance to the next best model is suspiciously large. However, it does not provide explicit guidance on how the authors should address these concerns or what specific actions they should take to improve their draft. The comment implies that the authors should investigate the hyperparameters and their placement within the search range, but it lacks concrete instructions on how to do so. As a result, the comment is 3, as it identifies an area for investigation but does not provide detailed guidance on how to proceed.", "grounding_specificity_rationale": "The comment raises concerns about the SCNN getting \"lucky\" on domain pricing, suggesting that the chosen hyperparameters might be at the end of the searched range and that the distance to the next best model is suspiciously large. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment does provide some specificity by suggesting that the authors should investigate the hyperparameters and their placement within the search range. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the SCNN getting \"lucky\" on domain pricing, suggesting that the chosen hyperparameters might be at the end of the searched range and that the distance to the next best model is suspiciously large. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 2, as it provides some basis for concern but requires more detailed justification.", "helpfulness_rationale": "The review comment raises a concern about the SCNN getting \"lucky\" on domain pricing, suggesting that the chosen hyperparameters might be at the end of the searched range and that the distance to the next best model is suspiciously large. This is a relevant observation that could indicate a potential issue with the model\"s performance. However, the comment does not provide specific suggestions or guidance on how the authors might address this concern or improve their draft. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a potential issue but does not fully support the authors in resolving it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that some aspects of the experimental setup are unclear or poorly motivated, specifically regarding corpora and datasets. However, it does not provide explicit guidance on what needs to be clarified or improved. The authors can infer that they need to provide more detailed information about the corpora and datasets used in the experiments, but the comment lacks concrete suggestions on how to achieve this. As a result, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment mentions \"some aspects of the experimental setup\" as being unclear or poorly motivated, specifically regarding corpora and datasets. However, it does not specify which part of the paper these aspects are discussed in, making it weakly grounded. The comment is specific in identifying the issue with corpora and datasets, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing clarification. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that \"some aspects of the experimental setup were unclear or poorly motivated,\" specifically regarding corpora and datasets. However, it does not provide any specific examples or detailed reasoning to support this claim. Without additional context or explanation, the authors may find it challenging to understand which aspects are unclear or how they could be improved. Therefore, the comment is considered 2, as it lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The comment identifies a specific issue with the experimental setup, noting that some aspects are unclear or poorly motivated, particularly regarding corpora and datasets. This feedback is 3 as it points out a potential area for improvement, prompting the authors to clarify and motivate their experimental choices. However, the comment lacks detailed guidance or suggestions on how to address these issues, such as specific questions to consider or examples of how to improve the clarity. While it provides some direction, it could be more helpful with additional details or actionable advice. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the size of the model, specifically its depth or number of parameters, in comparison to competing approaches. It also points out that the authors mention the model consists of 4 hourglass modules but do not specify the size of each module. This feedback implies that the authors should provide more detailed information about the model\"s size, which is an implicit action. However, the comment does not explicitly instruct the authors to include this information, and it lacks concrete guidance on how to present this data. Therefore, the comment is 3, as the authors can infer the need for additional information but are not given specific instructions on how to implement it.", "grounding_specificity_rationale": "The comment raises a question about the size of the model, specifically its depth or number of parameters, in comparison to competing approaches. It also points out that the authors mention the model consists of 4 hourglass modules but do not specify the size of each module. This provides a clear indication of what needs to be addressed, namely the size of the model and its components. However, the comment does not explicitly mention which part of the paper this information should be included in, such as the methodology or results sections. While the authors can infer that it relates to the methodology or results, the lack of explicit grounding makes it weakly grounded. The comment is specific in detailing what is missing, so it is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the size of the model, specifically its depth or number of parameters, in comparison to competing approaches. It points out that the authors mention the model consists of 4 hourglass modules but do not specify the size of each module. This is a factual observation that does not contain a claim or opinion requiring verification. It is a request for clarification or additional information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a pertinent question about the size of the model, specifically its depth or number of parameters, in comparison to competing approaches. It points out that the authors mention the model consists of 4 hourglass modules but do not specify the size of each module. This feedback is valuable as it highlights a gap in the paper that could be addressed to provide a more comprehensive understanding of the model\"s architecture. However, the comment could be more helpful if it suggested ways to present this information or offered guidance on how to compare the model\"s size to others. Despite this, the comment provides a clear direction for improvement, making it 4. Therefore, it aligns with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a specific issue with the claim that PACE addresses a gap in climate emulation by treating it as a diagnostictype prediction, noting that prior work (e.g., ClimateBench or ClimateSet) already does this. However, the comment does not provide explicit guidance on how the authors should address this issue or clarify the claim. It lacks concrete suggestions on how to revise the claim or what additional information should be included to make it clearer. As a result, the authors are left with an implicit action to clarify the claim but without detailed guidance on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim that \"To address this gap, we propose PACE, which treats climate emulation as a diagnostictype prediction,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that prior work (e.g., ClimateBench or ClimateSet) already addresses this gap, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement \"To address this gap, we propose PACE, which treats climate emulation as a diagnostictype prediction\" is misleading because prior work (e.g., ClimateBench or ClimateSet) already addresses this gap. The comment provides a specific example of prior work that contradicts the claim, which is a clear and logical reasoning supporting the claim. This makes the comment 5, as it provides a direct and specific reference to external work that challenges the claim. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a specific issue with the claim that PACE addresses a gap in climate emulation by treating it as a diagnostictype prediction. It points out that prior work, such as ClimateBench or ClimateSet, already addresses this gap, making the claim misleading. This feedback is clear and actionable, as it prompts the authors to clarify their claim or provide a more nuanced explanation of how PACE differs from existing work. However, the comment could be more helpful if it suggested ways to address this issue or provided examples of how PACE might offer unique contributions. Overall, the comment is 4 as it directs the authors to a critical area needing clarification, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests moving some visual results from the supplementary material to the main paper, specifically mentioning the lack of visual results on crowd density estimation, which is the main experiment. It also suggests condensing the figures illustrating the proposed network architecture to make space for visual results. While the comment provides a clear action to improve the paper by adding visual results, it does not specify which specific visual results should be included or how to present them. The authors know they need to add visual results but may struggle with the execution details. Therefore, the comment is 4, as it provides a clear direction but lacks concrete guidance on implementation.", "grounding_specificity_rationale": "The comment suggests moving some visual results from the supplementary material to the main paper, specifically mentioning the lack of visual results on crowd density estimation, which is the main experiment. It also suggests condensing the figures illustrating the proposed network architecture to make space for visual results. The comment is fully grounded as it explicitly mentions the main paper and the lack of visual results on crowd density estimation, allowing the authors to accurately identify the parts being addressed. It is also specific because it provides clear guidance on what needs to be addressed, such as moving visual results and condensing figures. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests moving some visual results from the supplementary material to the main paper, specifically mentioning the lack of visual results on crowd density estimation, which is the main experiment. The comment provides a logical reasoning for the suggestion, as it highlights the importance of visual results in the main paper and the potential to condense figures to make space for them. However, it does not provide specific examples or references to support the claim that the current visual results are insufficient or that the proposed changes would improve the paper. Therefore, the comment is 3, as it provides a logical basis for the suggestion but lacks detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by recommending the inclusion of visual results on crowd density estimation, which is the main experiment. It also suggests condensing the figures illustrating the proposed network architecture to make space for these visual results. This feedback is specific and offers a concrete way for the authors to enhance the visual representation of their work, which can significantly improve the clarity and impact of the paper. However, the comment could be more helpful if it provided examples of how to present the visual results or suggested specific aspects to focus on. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in the draft."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the potential impact of not knowing that a test example is crucially different, such as the patient in Figure 8 being British. It suggests that using the American corpus to explain this example might be problematic. However, the comment does not provide explicit guidance or suggestions on how to address this issue or what actions the authors should take to improve their draft. The question is posed in a way that requires the authors to infer that they should consider the implications of such differences and potentially address them in their work. Since the action is implicit and lacks concrete details, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the potential impact of not knowing that a test example is crucially different, such as the patient in Figure 8 being British. It suggests that using the American corpus to explain this example might be problematic. However, the comment does not specify which part of the paper this issue pertains to, such as a specific section or figure where this discussion is relevant. Additionally, while it raises a concern, it does not provide specific guidance on how to address this issue or what changes should be made. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a question about the potential impact of not knowing that a test example is crucially different, such as the patient in Figure 8 being British. It suggests that using the American corpus to explain this example might be problematic. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim. Without additional context or examples, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises an important question about the potential impact of not knowing that a test example is crucially different, such as the patient in Figure 8 being British. It suggests that using the American corpus to explain this example might be problematic and asks whether this can be detected with the corpus residual value. This question is relevant and prompts the authors to consider the implications of such differences in their work. However, the comment lacks specific guidance or suggestions on how to address this issue or improve the draft. While it identifies a potential area of concern, it does not provide actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point questions the choice of the WebQuestionsSP dataset as the testbed and suggests using the more popular WebQuestions benchmark set instead. It provides a rationale for this suggestion, stating that NSM only requires weak supervision and that using WebQuestions would be more intuitive and straightforward, allowing for direct comparison with mainstream QA research. While the comment implies that the authors should consider using a different dataset, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement the suggested change. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the choice of dataset, specifically the WebQuestionsSP dataset, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear rationale for why the authors should consider using the more popular WebQuestions benchmark set instead, explaining that NSM only requires weak supervision and that using WebQuestions would be more intuitive and straightforward, facilitating direct comparison with mainstream QA research. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the choice of the WebQuestionsSP dataset as the testbed and suggests using the more popular WebQuestions benchmark set instead. The reviewer provides a rationale for this suggestion, stating that NSM only requires weak supervision and that using WebQuestions would be more intuitive and straightforward, allowing for direct comparison with mainstream QA research. This reasoning is logical and provides a clear basis for the suggestion, making the claim 4. However, the comment could be strengthened by referencing specific studies or examples that support the claim about the superiority of WebQuestions. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment questions the choice of the WebQuestionsSP dataset as the testbed and suggests using the more popular WebQuestions benchmark set instead. It provides a rationale for this suggestion, stating that NSM only requires weak supervision and that using WebQuestions would be more intuitive and straightforward, allowing for direct comparison with mainstream QA research. This feedback is clear and actionable, as it offers a specific alternative dataset that could enhance the paper\"s relevance and comparability. However, the comment could be more helpful if it included additional guidance on how to implement this change or addressed potential challenges in switching datasets. Overall, the comment is 4, as it provides valuable insight into improving the paper\"s dataset choice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that the paper should include analysis or results on datasets other than CIFAR derivatives, specifically mentioning ImageNet derivatives. It provides a clear action for the authors to take by recommending that they present results on ImageNet1k or ImageNet100 in the main paper. The comment is explicit and provides concrete guidance on what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for analysis or results on datasets other than CIFAR derivatives, specifically suggesting ImageNet derivatives. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what is missing, namely the analysis or results on ImageNet1k or ImageNet100. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper lacks analysis or results on datasets other than CIFAR derivatives, specifically mentioning ImageNet derivatives. The reviewer provides a clear and logical reasoning for why this is important, emphasizing the need to verify the effectiveness of the framework on a more challenging dataset like ImageNet1k or ImageNet100. This reasoning is supported by the suggestion to present these results in the main paper. The comment is 4 as it provides a logical argument and a clear direction for improvement, but it could be strengthened with specific references or examples from the literature. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the lack of analysis or results on datasets other than CIFAR derivatives. It suggests that verifying the effectiveness of the framework on ImageNet1k or ImageNet100 is important and recommends presenting these results in the main paper. This feedback is clear and actionable, providing the authors with a specific direction to enhance the comprehensiveness and robustness of their results. By addressing this suggestion, the authors can strengthen their paper and provide a more comprehensive evaluation of their framework. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should consistently refer to BigFive and MBTI as datasets throughout the paper, rather than treating them as models to be extended. The comment provides a clear and explicit action for the authors to take, specifying that they should either consistently refer to them as datasets or provide an extended explanation for why they are addressing them differently. This feedback is concrete and direct, giving the authors a clear understanding of what needs to be changed in their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Abstract\" and \"Introduction\" sections, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the inconsistency in referring to BigFive and MBTI as models in the abstract and introduction, while they are used as datasets in the experiments. The comment provides a clear suggestion to either consistently refer to them as datasets or provide an extended explanation for the different treatment. This level of detail makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that BigFive and MBTI are inconsistently referred to as models in the abstract and introduction, while they are used as datasets in the experiments. The reviewer provides a clear and logical reasoning for this inconsistency, suggesting that the authors should either consistently refer to them as datasets or provide an extended explanation for the different treatment. This reasoning is based on a logical expectation for consistency in terminology and provides a clear direction for the authors to address the issue. Therefore, the comment is 5.", "helpfulness_rationale": "The review comment identifies a specific inconsistency in the paper, noting that BigFive and MBTI are referred to as models to be extended in the abstract and introduction, while they are used as datasets in the experiments. The reviewer suggests that the authors should either consistently refer to them as datasets or provide an extended explanation for the different treatment. This feedback is clear and actionable, as it points out a potential confusion in the paper and offers a straightforward solution. By addressing this inconsistency, the authors can improve the clarity and consistency of their work. Therefore, the comment is rated as 4, as it provides valuable guidance for enhancing the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the need for clearer clarification of the advantages of DIMES, specifically its ability to overcome generalization gaps in TSP instances through direct RL training and meta finetuning. It also suggests comparing DIMES with other methods on TSP100, both with and without metalearning. While the comment implies that the authors should provide more detailed explanations and comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer what needs to be done but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"generalization to the specific TSP instances (the finetuning step in DIMES)\" and \"DIMES\"s own advantages (direct RL training for largescale problems + meta finetuning),\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be clarified, namely the difference between DIMES and other methods on TSP100 with and without metalearning. This provides clear guidance on what the authors need to address. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper should clarify the advantages of DIMES, specifically its ability to overcome generalization gaps in TSP instances through direct RL training and meta finetuning. The reviewer acknowledges that these are DIMES\"s own advantages but emphasizes the need for clearer clarification. Additionally, the comment suggests comparing DIMES with other methods on TSP100, both with and without metalearning. While the comment provides a logical reasoning for the need to clarify the advantages, it lacks specific examples or references to support the claim. This makes the comment 3, as it provides a clear direction for improvement but requires more detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the need for clearer clarification of DIMES\"s advantages in overcoming generalization gaps in TSP instances. It acknowledges that these advantages are related to direct RL training for largescale problems and meta finetuning but suggests that the difference should be more explicitly stated in the paper. Additionally, the comment suggests an interesting comparison of DIMES with other methods on TSP100, both with and without metalearning, to further explore the paper\"s contributions. This feedback is clear and actionable, providing the authors with specific directions to enhance the clarity and depth of their work. However, it could be more helpful if it included suggestions on how to present the comparison or clarify the advantages. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly requests information about the final thresholds used for the results and suggests sharing the full set of hyperparameters for reproducibility purposes. This feedback provides clear and direct actions for the authors to take, ensuring that they know exactly what information to include in their draft. The request for final thresholds and hyperparameters is specific and concrete, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"final thresholds\" used for the results, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what is missing, namely the full set of hyperparameters, which would enhance reproducibility. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point requests information about the final thresholds used for the results and suggests sharing the full set of hyperparameters for reproducibility purposes. These are factual requests for additional information, which do not contain subjective claims or opinions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment requests specific information about the final thresholds used for the results and suggests sharing the full set of hyperparameters for reproducibility purposes. This feedback is clear and actionable, as it directly addresses a potential gap in the paper\"s presentation of results and methodology. By providing this information, the authors can enhance the transparency and reproducibility of their work, which is crucial for the scientific community. However, the comment could be more helpful if it included suggestions on how to present this information or why it is important for reproducibility. Overall, the feedback is 4 as it provides clear guidance for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the claim that the readability of RC datasets does not directly affect question difficulty. It suggests that this claim depends on the method or features used for answer detection, such as POS/dependency parse features. While the comment identifies a potential limitation in the claim, it does not provide explicit guidance on how the authors should address this issue or suggest specific changes to their analysis. The action is implicit and somewhat vague, as the authors are left to infer that they need to consider the impact of different methods or features on their analysis. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific claim made in the paper regarding the relationship between the readability of RC datasets and question difficulty. It suggests that this claim depends on the method or features used for answer detection, such as POS/dependency parse features. However, the comment does not specify which part of the paper this claim is made in, making it weakly grounded. The authors can infer that it relates to the dataset analysis or methodology sections, but this inference is not direct. The comment is specific in detailing the potential dependency on the method or features used, which provides some guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point challenges the claim that the readability of RC datasets does not directly affect question difficulty, suggesting that this depends on the method or features used for answer detection, such as POS/dependency parse features. The comment provides a logical reasoning by pointing out a potential dependency on the method used, which is a valid critique. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to further explore this aspect to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation in the claim that the readability of RC datasets does not directly affect question difficulty. It suggests that this claim may depend on the method or features used for answer detection, such as POS/dependency parse features. This feedback is 3 as it points out a specific area where the authors might need to consider the impact of their methodology on their findings. However, the comment does not provide detailed guidance on how to address this issue or suggest alternative methods or features to explore. While it highlights a potential weakness, it lacks depth and actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the writing quality of the paper should be improved, specifically mentioning that the authors spend the same space on explaining basic memory networks and then the forward model. It also notes that the related work section lacks coverage of more reinforcement learning tasks in the literature. However, the comment does not provide explicit guidance on how to improve the writing quality or what specific changes should be made to address the issues with the related work section. The action is implicit and somewhat vague, as the authors are left to infer what specific improvements are needed without concrete instructions. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment provides a general observation about the writing quality, mentioning that the authors spend the same space on explaining basic memory networks and then the forward model. It also notes a missing piece in the related work section regarding more reinforcement learning tasks in the literature. However, the comment does not specify which sections of the paper these issues pertain to, making it weakly grounded. The authors can infer that it relates to the sections on memory networks and related work, but this inference is not explicit. The comment is specific in identifying areas for improvement, such as the writing quality and related work coverage. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the writing quality of the paper should be improved, specifically mentioning that the authors spend the same space on explaining basic memory networks and then the forward model. It also notes a missing piece in the related work section regarding more reinforcement learning tasks in the literature. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the exact issues and how to address them. The lack of detailed justification or references makes the claim 3, as the authors would need to infer the specific areas needing improvement. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific areas for improvement: the writing quality and the related work section. It points out that the authors spend the same space on explaining basic memory networks and then the forward model, suggesting that this could be improved by focusing on more relevant content. Additionally, it notes that the related work section lacks coverage of more reinforcement learning tasks in the literature, which is an important area for the paper to address. However, the comment does not provide detailed suggestions or examples on how to enhance the writing quality or what specific tasks should be included in the related work section. While it highlights areas for improvement, the feedback could be more actionable and comprehensive to be fully helpful. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential issue with the first column of Qo being replaced by vo to form P\"o, which makes the first state unreachable but from a terminating state. The reviewer assumes that either Ass.1 (finite length of an option) or Ass.2 (finite length of a path) is violated. However, the comment does not provide explicit guidance on how the authors should address this issue or which assumption should be revised. The action is implicit and vague, as the authors are left to infer that they need to clarify or revise the assumptions, but without specific instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 140,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the first column of Qo is replaced by vo to form P\"o, which makes the first state unreachable but from a terminating state. The comment further assumes that either Ass.1 (finite length of an option) or Ass.2 (finite length of a path) is violated. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the first column of Qo being replaced by vo to form P\"o, which makes the first state unreachable but from a terminating state. The reviewer assumes that either Ass.1 (finite length of an option) or Ass.2 (finite length of a path) is violated. However, the comment does not provide specific reasoning or examples to support this assumption, making it difficult for the authors to understand the basis of the claim. The lack of detailed explanation or references leaves the claim 3, as the authors would need to infer the reasoning themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the first column of Qo being replaced by vo to form P\"o, which makes the first state unreachable but from a terminating state. The reviewer assumes that either Ass.1 (finite length of an option) or Ass.2 (finite length of a path) is violated. This feedback highlights a specific area of concern that the authors need to address, such as clarifying the assumptions or revising the model to ensure the first state is reachable. However, the comment lacks detailed guidance on how to resolve the issue or what specific changes should be made. While it points out a potential problem, it does not provide actionable steps for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the assumption that d_e are good replacements for entity embeddings has been tested. While it implies that the authors should test this assumption, the comment does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to test this assumption or what specific tests should be conducted. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about an assumption made in the paper, specifically whether d_e are good replacements for entity embeddings. However, it does not specify which part of the paper this assumption is discussed in, making it weakly grounded. The comment is specific in its inquiry about the testing of this assumption, but without explicit references to sections or parts of the paper, the authors may find it challenging to pinpoint the exact area needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about an assumption made in the paper, specifically whether d_e are good replacements for entity embeddings. However, it does not provide any supporting evidence, reasoning, or references to justify why this assumption should be tested or how it might impact the paper. Without additional context or explanation, the claim remains 1, as the authors are left without guidance on how to address this concern. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a critical question about an assumption made in the paper, specifically whether d_e are good replacements for entity embeddings. This is an important point that the authors should address to ensure the validity and robustness of their work. However, the comment lacks specificity and does not provide guidance on how to test this assumption or what specific tests should be conducted. While it identifies a potential area for improvement, the lack of detailed feedback limits its helpfulness. Therefore, the comment is 3, as it prompts the authors to consider a critical aspect of their work but does not fully support them in making improvements."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point criticizes the use of a table to present factors, suggesting that it does not provide additional information compared to pure text. However, it does not offer any explicit or implicit actions for the authors to take. There is no guidance on how to improve the presentation of the factors or what specific changes should be made to enhance the clarity or effectiveness of the information. Without any actionable suggestions or concrete steps, the authors are left without a clear understanding of how to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment criticizes the use of a table to present factors, suggesting that it does not provide additional information compared to pure text. However, it does not specify which table or section of the paper this critique pertains to, making it difficult for the authors to identify the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the table are problematic or how the information could be improved. Without clear grounding and specificity, the authors are left without a clear understanding of what needs to be addressed. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that \"making the factors in a table does not help convey more messages than pure text\" and that \"there is no more information at all.\" However, the comment lacks any supporting evidence, reasoning, or examples to substantiate this claim. Without specific examples or references to what information might be missing or how the table could be improved, the authors are left without a clear understanding of the critique. This makes the claim 1, as it does not provide sufficient justification or context for the authors to address the issue effectively. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment criticizes the use of a table to present factors, suggesting that it does not provide additional information compared to pure text. However, it lacks specificity and does not offer any actionable suggestions or guidance on how the authors might improve the presentation of the factors or enhance the clarity of the information. Without detailed feedback or constructive advice, the authors are left without a clear understanding of what changes could be made to address the issue. Therefore, the comment is 1, as it does not provide any actionable insights or direction for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point poses a question about the number of different kinds of physical interactions that can be present in a simulation. However, it does not provide any explicit or implicit actions for the authors to take. The question is not phrased as a suggestion or a request for clarification, leaving the authors without any guidance on how to address the issue. As a result, the comment lacks actionability and does not provide any direction for improvement. Therefore, it is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment poses a question about the number of different kinds of physical interactions that can be present in a simulation. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure where this information might be discussed. Without explicit references or context, the authors cannot confidently determine which part of the paper the comment addresses. Additionally, the comment lacks specificity as it does not provide guidance on what aspects of the simulation are being questioned or how to address the issue. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification about the number of different kinds of physical interactions that can be present in a simulation. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment poses a question about the number of different kinds of physical interactions that can be present in a simulation. While it highlights an area that might need clarification, it does not provide any actionable feedback or suggestions for improvement. The authors are left without guidance on how to address this question or what implications it might have for their work. As a result, the comment is not helpful, as it does not offer any actionable insights or direction for the authors to enhance their draft. Therefore, it aligns with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the authors\" approach to pruning, noting that it primarily works with large networks trained in distributed settings. It suggests that the authors should consider finding global top Q values of the metric over the average of gradients to avoid breaking acceleration techniques like quantization and sparsification. While the comment implies that the authors should address this issue, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore this aspect of their work. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper related to pruning, mentioning that it primarily works with large networks trained in distributed settings. It suggests that the authors should consider finding global top Q values of the metric over the average of gradients to avoid breaking acceleration techniques like quantization and sparsification. However, the comment does not explicitly mention which part of the paper discusses pruning or where this issue should be addressed, making it weakly grounded. The comment is specific in detailing the potential issue and suggesting a solution, but without clear grounding, the authors may struggle to identify the exact section needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that pruning primarily works with large networks trained in distributed settings and suggests that the authors should consider finding global top Q values of the metric over the average of gradients to avoid breaking acceleration techniques like quantization and sparsification. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that finding global top Q values is necessary or how it would impact acceleration techniques. The lack of supporting evidence or detailed explanation makes it difficult for the authors to understand and address the concern fully. Therefore, the comment is considered 2, as it provides some insight but requires more detailed justification to be 5.", "helpfulness_rationale": "The review comment identifies a potential issue with the authors\" approach to pruning, noting that it primarily works with large networks trained in distributed settings. It suggests that the authors should consider finding global top Q values of the metric over the average of gradients to avoid breaking acceleration techniques like quantization and sparsification. This feedback is 3 as it points out a specific area for improvement and provides a suggestion for addressing it. However, the comment could be more helpful if it offered additional guidance on how to implement this suggestion or provided examples of how this approach might impact the acceleration techniques. Overall, the comment is 3 as it directs the authors\" attention to a potential issue and offers a starting point for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the potential swapping of subfigures in Figures 1 and 2. While it implies that the authors should check for this mistake, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to verify or correct the issue. The authors can infer that they need to check the figures for consistency, but the comment does not provide detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figs 1 and 2,\" allowing the authors to accurately identify the specific parts of the paper being addressed. It is also specific because it raises a question about the potential swapping of subfigures, which provides clear guidance on what needs to be checked for accuracy. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question asking about the potential swapping of subfigures in Figures 1 and 2. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the potential swapping of subfigures in Figures 1 and 2. While it identifies a potential issue, it lacks depth and does not provide any guidance or suggestions on how the authors might address this concern. The comment does not offer actionable feedback or insights into how the authors might verify or correct the issue, leaving the authors with only a vague indication of a possible problem. Therefore, the comment is 2, as it points out a potential issue but does not provide sufficient guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges the positive impact of the dropout probe, noting that it improves sensitivity and finds a causal role for syntactic representations. However, it also raises a concern about the potential increase in false positives. The reviewer suggests that this should be a substantial part of the discussion, implying that the authors should address this issue in their paper. While the comment highlights a potential concern, it does not provide explicit guidance on how to address it or what specific aspects should be discussed. The action is implicit and somewhat vague, as the authors are left to infer that they should discuss the tradeoff between sensitivity and false positives. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"dropout probe,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights the positive impact of the dropout probe in finding a causal role for syntactic representations and raises a concern about the potential increase in false positives. The comment suggests that this issue should be a substantial part of the discussion, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point acknowledges the positive impact of the dropout probe in improving sensitivity and finding a causal role for syntactic representations. It also raises a concern about the potential increase in false positives, suggesting that this should be a substantial part of the discussion. The comment provides a logical reasoning by pointing out the tradeoff between sensitivity and false positives, which is a common concern in machine learning. However, it does not provide specific examples or references to support the claim about the risk of false positives, making it 3. The authors would need to further explore and substantiate this claim themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the positive impact of the dropout probe in improving sensitivity and finding a causal role for syntactic representations. It also raises a concern about the potential increase in false positives, suggesting that this should be a substantial part of the discussion. This feedback is 3 as it identifies a potential tradeoff that the authors should consider and address in their paper. However, the comment lacks specific suggestions or guidance on how to balance sensitivity and false positives, or how to discuss this tradeoff effectively. While it points out an important area for consideration, it does not provide detailed actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point criticizes the paper for not discussing and comparing various exploration methods in RL literature, such as countbased methods and intrinsic motivations like RND and ICM. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific methods for comparison. The action is implicit, as the authors can infer that they need to include a discussion and comparison of these methods, but the comment lacks concrete details on how to implement this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment critiques the paper for not discussing and comparing various exploration methods in RL literature, such as countbased methods and intrinsic motivations like RND and ICM. However, it does not specify which part of the paper this critique pertains to, making it difficult for the authors to identify the exact section that needs revision. The comment is specific in detailing the missing discussion and comparison, but it lacks grounding as it does not explicitly mention a particular section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is not sound because it does not discuss and compare various exploration methods in RL literature, such as countbased methods and intrinsic motivations like RND and ICM. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence makes the claim 3, as the authors would need to infer the importance of these methods and their relevance to the paper. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out that it does not discuss and compare various exploration methods in RL literature, such as countbased methods and intrinsic motivations like RND and ICM. This feedback is clear and actionable, as it highlights an important area for improvement that could enhance the paper\"s contribution and relevance. However, the comment could be more helpful if it provided specific suggestions on how to incorporate these methods or what aspects to focus on in the comparison. Despite this, the comment is 4 as it directs the authors to a critical area that needs attention, providing a clear path for improvement. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the annotations in Figure 4 should be enlarged for better visibility. This is an explicit action that provides a clear direction for the authors to improve their draft. The comment specifies exactly what needs to be done, making it 5. The authors know exactly how to apply this feedback by enlarging the annotations in Figure 4, ensuring that the figure is more legible and informative.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the annotations in Figure 4 should be enlarged for better visibility. This provides clear guidance on how to improve the figure, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a request for clarification or improvement regarding the visibility of annotations in Figure 4. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a factual statement about the figure, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the draft. It identifies a particular issue with the visibility of annotations in Figure 4 and recommends enlarging them for better clarity. This feedback is clear and direct, offering the authors a concrete step to enhance the legibility and effectiveness of their figure. By addressing this suggestion, the authors can improve the overall quality and readability of their work. However, the comment could be more helpful if it explained why the annotations are currently difficult to see or how enlarging them would benefit the reader. Overall, the comment is 4 as it provides a clear direction for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review comment points out that multiple entities exist in both sentences and documents, even in relation classification tasks, which is not limited to documentlevel RE or joint entity and relation extraction. However, it does not provide any explicit or implicit action for the authors to take. There is no suggestion for improvement, clarification, or additional information that the authors should consider. As a result, the comment lacks any actionable guidance, leaving the authors without a clear understanding of how to address the issue. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 2627, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clarifies that multiple entities exist in both sentences and documents, even in relation classification tasks, which is not limited to documentlevel RE or joint entity and relation extraction. This provides clear guidance on what the authors need to address in their paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual statement describing the existence of multiple entities in both sentences and documents, even in relation classification tasks. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment points out a factual observation about the existence of multiple entities in both sentences and documents, even in relation classification tasks. However, it does not provide any actionable feedback or suggestions for improvement. The comment lacks depth and does not offer any guidance on how this observation might impact the paper or how the authors could address it. As a result, the comment is 1, as it does not assist the authors in enhancing their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and concerns about the paper, including the impact of inference slowdown, the coefficient in line 307, the lack of hyperparameter details, and the clarity of the writing. While the comment identifies areas that need clarification or improvement, it does not provide explicit instructions or concrete suggestions on how the authors should address these issues. The authors can infer that they need to provide more detailed explanations and potentially conduct additional experiments to address the concerns raised, but the feedback lacks specificity and actionable steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises several questions and concerns about the paper, including the impact of inference slowdown, the coefficient in line 307, the lack of hyperparameter details, and the clarity of the writing. However, it does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its critique, but it lacks grounding as it does not identify the specific sections or parts of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several questions and concerns about the paper, including the impact of inference slowdown, the coefficient in line 307, the lack of hyperparameter details, and the clarity of the writing. While the comment identifies specific areas that need clarification or improvement, it does not provide detailed reasoning or evidence to support these claims. The lack of specific examples or references makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment raises several important questions and concerns about the paper, including the impact of inference slowdown, the coefficient in line 307, the lack of hyperparameter details, and the clarity of the writing. While it identifies specific areas that need clarification or improvement, it does not provide detailed guidance or suggestions on how the authors might address these issues. The comment highlights potential weaknesses but lacks actionable advice, making it 3. The authors are given some direction but are left to figure out the specifics of how to improve their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests replacing the term \"stateoftheart\" with \"very high performing model\" or a similar phrase in line 152. This is an explicit action that provides a clear direction for the authors to make a specific change in their draft. The comment is concrete because it specifies what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 152,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests replacing the term \"stateoftheart\" with \"very high performing model\" or a similar phrase, providing clear guidance on what needs to be changed. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the model by Dozat and Manning (2016) is no longer stateoftheart, and it recommends replacing the term \"stateoftheart\" with \"very high performing model\" or a similar phrase. However, the comment does not provide any supporting evidence or reasoning to justify why the model is no longer stateoftheart. Without additional context or references, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the terminology used in the paper, suggesting that the term \"stateoftheart\" may no longer be accurate for the model mentioned. It provides a clear and actionable suggestion to replace it with a more appropriate term, such as \"very high performing model.\" This feedback is valuable as it helps the authors maintain the accuracy and relevance of their claims, ensuring that their draft remains uptodate and credible. However, the comment could be more helpful if it included additional context or justification for why the original term is no longer accurate. Overall, the comment is 4, as it provides a specific and actionable suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies several subjective statements that need to be supported with proofs and references. It also highlights the challenges of seeking an effective architecture and the sensitivity of image recovery performance to neural architecture choices. Additionally, it points out the need for a detailed explanation regarding the use of multiscale features and when to fuse them. While the comment implies that the authors should provide additional evidence and explanations, it does not explicitly instruct them on how to do so. The action is implicit and somewhat vague, as the authors are left to infer the specific steps needed to address the issues. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"some subjective statements\" and \"proofs and references,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, such as providing detailed explanations and references to support subjective statements. Additionally, it provides specific examples of issues related to the choice of neural architecture and multiscale feature fusion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some subjective statements are inappropriate and requires proofs and references to support them. It also highlights the challenges of seeking an effective architecture and the sensitivity of image recovery performance to neural architecture choices. The comment further mentions the need for a detailed explanation regarding the use of multiscale features and when to fuse them. While the comment identifies areas that need clarification, it lacks specific examples or references to support the claims, making it 3. The authors would need to provide additional evidence or reasoning to fully substantiate the claims, which is a minor gap in the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas where the paper could be improved, specifically regarding subjective statements that lack supporting evidence or references. It highlights the need for proofs and references to substantiate claims, particularly in relation to the challenges of seeking an effective architecture and the sensitivity of image recovery performance to neural architecture choices. Additionally, the comment points out the need for a detailed explanation regarding the use of multiscale features and when to fuse them. While the comment provides clear guidance on what needs to be addressed, it could be more helpful by offering specific suggestions on how to provide these proofs or references. Overall, the feedback is 4 as it directs the authors to enhance the rigor and clarity of their claims, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point asks for a comparison of the proposed method with prior art, but it does not provide any guidance on how to conduct this comparison or what specific aspects should be considered. The action is implicit and vague, as the authors are left to infer that they need to provide a comparison but without concrete details on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the comparison of the proposed method with prior art, but it does not specify which part of the paper this comparison should be included in. The authors cannot confidently determine which section or subsection this comment pertains to, making it weakly grounded. However, the comment is specific in its request for a comparison with prior art, which provides some guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point is a question seeking clarification on how the proposed method compares with prior art. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a critical question about the comparison of the proposed method with prior art. This is an important aspect that the authors need to address to provide context and relevance for their work. However, the comment lacks specificity and does not offer any guidance or suggestions on how to conduct this comparison or what specific aspects should be considered. While it identifies a key area for improvement, the lack of detailed feedback limits its helpfulness. Therefore, the comment is 3, as it points out an important area for improvement but does not provide actionable steps for the authors to take."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the analyses could be more detailed, specifically mentioning the \"language/nationality\" data that includes various languages and nationalities. The reviewer expresses curiosity about potential biases and interesting observations that could be made by comparing these different languages/nationalities. While the comment implies that the authors should expand their analysis to include more detailed comparisons, it does not provide explicit instructions on how to do so or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should explore these comparisons further. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the analyses could be more detailed, specifically mentioning the \"language/nationality\" data and the potential for interesting observations by comparing different languages and nationalities. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or analysis. The authors can infer that it relates to the data analysis or results section, but this inference is not explicit. The comment is specific in suggesting a potential area for improvement, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the analyses could be more detailed, specifically mentioning the \"language/nationality\" data and the potential for interesting observations by comparing different languages and nationalities. The reviewer provides a specific example of the data, which includes Japanese, Chinese, English, Arabic, and German, indicating that there are ~20 different types. This provides some context and a basis for the suggestion, but it lacks detailed reasoning or references to support the claim that biases towards different languages/nationalities are different. The comment is 3 as it highlights a potential area for improvement but requires more detailed justification or examples to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, suggesting that the analyses could be more detailed. It provides a concrete example by mentioning the \"language/nationality\" data, which includes various languages and nationalities, and points out that biases towards different languages/nationalities might be interesting to explore. This feedback is actionable as it encourages the authors to expand their analysis to include more detailed comparisons, which could lead to valuable insights. However, the comment could be more helpful if it offered specific suggestions on how to conduct these comparisons or what aspects to focus on. Overall, the comment is 4 as it directs the authors to a potential area for enhancement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether there are other properties of features that could be used besides norm. It implies that the authors should consider exploring additional properties to enhance their approach design. However, the comment does not provide explicit guidance on how to identify or evaluate these properties or suggest specific actions to take. The action is implicit and somewhat vague, as the authors need to infer that they should explore other properties and determine how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the use of other properties of features besides norm, suggesting that it is necessary and helpful for the approach design. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for alternative properties to be considered, but without clear grounding, the authors may struggle to determine where this feedback fits into the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the use of other properties of features besides norm, suggesting that it is necessary and helpful for the approach design. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is important or how it would benefit the approach. Without additional context or explanation, the claim remains vague and 1, leaving the authors without a clear understanding of the basis for the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the use of other properties of features besides norm, suggesting that it is necessary and helpful for the approach design. This is a relevant point that could prompt the authors to consider expanding their analysis to include other properties, potentially leading to a more comprehensive understanding of their approach. However, the comment lacks specificity and does not provide detailed guidance on how to explore or evaluate these additional properties. While it identifies a potential area for improvement, the feedback could be more actionable with additional suggestions or examples. Therefore, the comment is 3, as it provides some direction but lacks depth and specificity."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies several weaknesses in the method, including its reliance on previous methods and the lack of network changes or losses. It also questions the use of two SIRENs for f and d, suggesting that d might be a simpler network. While the comment highlights areas for improvement, it does not provide explicit instructions or concrete suggestions on how the authors should address these issues. The actions are implicit and somewhat vague, as the authors need to infer what changes are needed and how to implement them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"W2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the weaknesses, such as the method being constructed on top of previous methods and the lack of network changes or losses. Additionally, it questions the use of two SIRENs for f and d, suggesting that d might be a simpler network. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a claim about the method being constructed on top of previous methods, questioning the novelty of the approach. It also questions the use of two SIRENs for f and d, suggesting that d might be a simpler network. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to fully understand and address the concerns. The lack of detailed reasoning or evidence makes the claim 3, as it requires more information to be fully substantiated.", "helpfulness_rationale": "The review comment identifies several weaknesses in the method, specifically noting that it is mostly constructed on top of previous methods and lacks network changes or losses. It questions the use of two SIRENs for f and d, suggesting that d might be a simpler network. This feedback is clear and actionable, as it points out specific areas where the authors could improve their method by introducing novel network changes or simplifying the network architecture. However, the comment could be more helpful if it provided additional suggestions or examples of how to address these issues. Overall, the comment is 4 as it directs the authors to areas that need further development, but it could be more comprehensive with more detailed guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point critiques the redundancy of RQ1 and suggests an alternative analysis that could be more interesting. It provides a specific suggestion for an additional analysis that would be beneficial, particularly regarding the effect of explicit hate information on implicit hate speech detection performance and its impact on RQ2 and RQ3 tsne plots. The reference to a previous work supports the suggestion, making the action concrete and explicit. The authors are given clear guidance on how to enhance their analysis, which is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"RQ1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the redundancy of RQ1 and suggesting an alternative analysis that would be more interesting. The comment provides a specific suggestion for an additional analysis, which is clear and actionable. Additionally, it references a previous work, which further supports the suggestion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that RQ1 is redundant and suggests an alternative analysis that would be more interesting. The reviewer provides a specific suggestion for an additional analysis regarding the effect of explicit hate information on implicit hate speech detection performance and its impact on RQ2 and RQ3 tsne plots. This suggestion is supported by a reference to a previous work, which adds credibility to the claim. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced work to fully substantiate the claim. Overall, the comment is 4, as it provides a clear direction for improvement but lacks comprehensive evidence or detailed reasoning.", "helpfulness_rationale": "The review comment identifies a potential redundancy in the paper\"s RQ1, suggesting that it does not add any extra information for the audience. It provides a specific and actionable suggestion for an alternative analysis that could be more interesting, focusing on the effect of explicit hate information on implicit hate speech detection performance and its impact on RQ2 and RQ3 tsne plots. The reference to a previous work further supports the suggestion, offering a concrete example of a similar analysis. This feedback is clear and constructive, guiding the authors on how to enhance their study by providing a more comprehensive and relevant analysis. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the differences between the current work and other papers focusing on semantic face editing, specifically mentioning a reference 1. While it implies that the authors should elaborate on these differences, the comment does not provide explicit guidance on how to address this point. The action is implicit and somewhat vague, as it lacks specific instructions on what aspects to focus on or how to present the comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the differences between the current work and other papers focusing on semantic face editing, specifically mentioning a reference 1. While it does not explicitly mention a specific section of the paper, the authors can infer that it relates to the discussion or results section where comparisons with other works are typically made. The comment is specific in its request for elaboration on the differences, providing a clear direction for the authors to address. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the differences between the current work and other papers focusing on semantic face editing, specifically mentioning a reference 1. This is a request for clarification rather than a claim, as it does not express an opinion, judgment, or suggestion. It is purely factual and does not require verification. Therefore, the label \"No\" is appropriate.", "helpfulness_rationale": "The review comment raises a pertinent question about the differences between the current work and other papers focusing on semantic face editing, specifically mentioning a reference 1. This prompts the authors to clarify and differentiate their work from existing literature, which is a valuable contribution to the paper. However, the comment could be more helpful if it provided specific suggestions on how to present these differences or what aspects to emphasize. While it identifies an area for improvement, it lacks detailed guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that footnotes are used excessively in the paper, which is distracting and should be moved into the main body of the paper. It provides a specific example of where this could be done, suggesting that details around parameter settings could be moved to the appendix. This feedback is clear and provides concrete guidance on how to improve the draft by reducing the use of footnotes and reorganizing content. The authors know exactly what action to take and how to implement it, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of footnotes, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the excessive use of footnotes and suggests moving content from the footnotes to the main body of the paper. Additionally, it provides a concrete example of where this could be done, such as moving details about parameter settings to the appendix. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that footnotes are used excessively in the paper, which is distracting and should be moved into the main body of the paper. The reviewer provides a specific example by suggesting that details around parameter settings could be moved to the appendix. This reasoning is logical and provides a clear basis for the claim, making it 4. However, the comment could be strengthened by providing more examples or specific instances of excessive footnotes, which would further support the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the excessive use of footnotes in the paper, which is distracting and should be moved into the main body of the paper. It provides a clear and actionable suggestion by recommending that details around parameter settings, for example, could be moved to the appendix. This feedback is valuable as it helps the authors reorganize their content to improve readability and clarity. However, the comment could be more helpful if it provided additional guidance on how to effectively integrate the footnotes into the main text or suggested alternative ways to present the information. Overall, the comment is 4 as it offers actionable advice for improving the draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the effectiveness of the GS module in propagating context information and improving the effective receptive field. It suggests that the authors should compute the effective receptive field from a reference, which is provided in the comment. This feedback is explicit and provides a clear action for the authors to take, which is to compute and report the effective receptive field after applying the GS module. The comment is 5 as it specifies exactly what the authors need to do to address the concern.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"GS module,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the effective receptive field and suggests that it can be computed from a reference provided in the comment. This provides clear guidance on what aspect of the paper needs further exploration or clarification. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the effectiveness of the GS module in propagating context information and improving the effective receptive field. It suggests that the authors should compute the effective receptive field from a reference provided in the comment. However, the comment does not provide the reference itself, leaving the authors to infer the source of the claim. This makes the claim 3, as it lacks specific evidence or references to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the effectiveness of the GS module in propagating context information and improving the effective receptive field. It suggests that the authors should compute the effective receptive field from a reference provided in the comment. This feedback is clear and actionable, as it directs the authors to a specific area for further exploration and analysis. By addressing this point, the authors can provide a more comprehensive understanding of their method\"s impact on the effective receptive field, which is crucial for evaluating the performance of their model. However, the comment could be more helpful if it included suggestions on how to compute or interpret the effective receptive field. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the objective for the LSTM part would remain the same for both pretraining and finetuning, with the addition of a head to compute value functions for states in the finetuning stage. While the comment implies that the authors should consider this approach, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement the suggested change. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"LSTM part\" and the \"finetuning stage,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the objective for the LSTM part, suggesting that the objective remains the same for pretraining and finetuning and proposing an additional head for computing value functions in the finetuning stage. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point suggests that the objective for the LSTM part would remain the same for both pretraining and finetuning, with the addition of a head to compute value functions for states in the finetuning stage. This claim is based on logical reasoning, as it explains how the objective could be achieved by adding a head to the network. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to infer the exact details of the proposed change, which could be challenging without further explanation. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and specific suggestion for improving the paper by explaining the objective for the LSTM part in both pretraining and finetuning stages. It suggests that the authors may simply add another head to the network to compute value functions for states during finetuning. This feedback is actionable and offers a concrete way for the authors to enhance their draft, making it 4. However, the comment could be more helpful if it included additional context or explanation on why this approach might be beneficial or how it could impact the overall methodology. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the rationale behind combining G4RL with HRAC (HRACG4RL) and whether G4RL requires HRAC\"s regularization in the latent space. While it does not explicitly instruct the authors to provide an explanation or address these questions, the comment implies that the authors should clarify these aspects. The action is implicit but clear, as the authors can infer that they need to provide an explanation or clarification. However, the comment lacks concrete guidance on how to address these questions, making it 3.", "grounding_specificity_rationale": "The comment raises questions about the rationale behind combining G4RL with HRAC (HRACG4RL) and whether G4RL requires HRAC\"s regularization in the latent space. However, it does not specify which part of the paper discusses this combination or where the authors should address these questions. The authors can infer that it relates to the methodology or results sections, but the comment lacks full grounding as it does not explicitly mention these sections. The comment is specific in its questions about the rationale and requirements, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point consists of questions seeking clarification about the rationale behind combining G4RL with HRAC (HRACG4RL) and whether G4RL requires HRAC\"s regularization in the latent space. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the rationale behind combining G4RL with HRAC (HRACG4RL) and whether G4RL requires HRAC\"s regularization in the latent space. This feedback prompts the authors to clarify the reasoning behind their approach, which is crucial for understanding the methodology and its implications. However, the comment does not provide specific suggestions or guidance on how to address these questions or improve the clarity of the explanation. While it identifies a potential area for improvement, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should acknowledge older works in the related works section, specifically mentioning the use of supervised, multilingual systems. While the comment implies that the authors should include these older works, it does not provide specific examples or guidance on which older works to include or how to integrate them into the related works section. The action is implicit and somewhat vague, as the authors need to infer which older works to include and how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"related works\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests acknowledging older works in the context of using supervised, multilingual systems. This provides clear guidance on what needs to be addressed in the related works section. Therefore, the comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point suggests that the authors should acknowledge older works in the related works section, specifically mentioning the use of supervised, multilingual systems. However, the comment does not provide specific examples or references to these older works, making it difficult for the authors to understand which works should be included. Without detailed guidance or references, the claim lacks sufficient support, making it 2. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment suggests that the authors should acknowledge older works in the related works section, specifically mentioning the use of supervised, multilingual systems. This feedback is 3 as it points out a potential gap in the literature review, encouraging the authors to include relevant older works. However, the comment lacks specificity and does not provide examples or guidance on which older works should be included or how to integrate them into the related works section. While it identifies an area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the results in Table 2, specifically the comparison between linear/exponentialdecay sampling and uniform sampling. The reviewer suggests that if the predictor is accurate on the good subregion, as argued by the authors, increasing the sampling probability for topperforming predicted architectures should lead to better performance than uniform sampling. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their analysis. The action is implicit and vague, as the authors are left to infer that they need to clarify or further explore the results in Table 2. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the results, questioning the logic behind the comparison between linear/exponentialdecay sampling and uniform sampling. The comment provides a clear rationale for why the results are confusing and suggests a potential explanation for the observed underperformance. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the results in Table 2, specifically the comparison between linear/exponentialdecay sampling and uniform sampling. The reviewer suggests that if the predictor is accurate on the good subregion, as argued by the authors, increasing the sampling probability for topperforming predicted architectures should lead to better performance than uniform sampling. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the results in Table 2, specifically the comparison between linear/exponentialdecay sampling and uniform sampling. It suggests that if the predictor is accurate on the good subregion, as argued by the authors, increasing the sampling probability for topperforming predicted architectures should lead to better performance than uniform sampling. This feedback is 3 as it points out a potential inconsistency or misunderstanding in the results, prompting the authors to reconsider their analysis or provide further explanation. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as recommending additional experiments or analyses. Therefore, while it identifies a potential area for improvement, it does not provide comprehensive or actionable feedback, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights concerns about the time complexity of the method, specifically mentioning the use of an itemoriented autoencoder, the elementwise function, and the large number of hidden units. However, it does not provide explicit guidance or suggestions on how the authors might address these issues or improve the time complexity. The comment lacks actionable details, such as recommending optimizations or alternative approaches, leaving the authors uncertain about how to proceed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the time complexity of the method, specifically mentioning the use of an itemoriented autoencoder, the elementwise function, and the large number of hidden units. However, it does not specify which part of the paper discusses these aspects, making it weakly grounded. The comment is specific in detailing the concerns about time complexity, but without clear references to the paper, the authors may struggle to pinpoint the exact sections needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the time complexity seems high, providing three reasons: the use of an itemoriented autoencoder, the elementwise function, and the large number of hidden units. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of evidence or detailed explanation makes the claim 3, as the authors would need to infer the potential issues and address them without clear guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the time complexity of the method, specifically mentioning the use of an itemoriented autoencoder, the elementwise function, and the large number of hidden units. This feedback is 3 as it points out a specific area that could be improved, such as optimizing the time complexity. However, the comment lacks detailed suggestions or guidance on how the authors might address these issues, leaving the authors with a general understanding of the problem but without actionable steps to take. To be more helpful, the comment could include recommendations or examples of how to optimize the time complexity or reduce the computational burden. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the figures would be clearer if they specified \"pretrained solution encoders & solution decoders,\" as there are multiple types of autoencoders. This feedback provides a clear and explicit action for the authors to take, which is to modify the figures to include this information. The suggestion is concrete, as it specifies exactly what needs to be changed to improve the clarity of the figures. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figures,\" allowing the authors to accurately identify the specific parts of the paper being addressed. It is also specific because it provides a clear suggestion for improvement, recommending that the figures should specify \"pretrained solution encoders & solution decoders\" to clarify the types of autoencoders used. This level of detail guides the authors on what changes to make to enhance the clarity of their figures. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the figures would be clearer if they specified \"pretrained solution encoders & solution decoders,\" as there are multiple types of autoencoders. This claim is 3 as it provides a logical reasoning for the suggestion, but it lacks specific examples or references to support the assertion that the current figures are unclear. The authors would need to infer the exact nature of the confusion based on the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the clarity of the figures by recommending that they specify \"pretrained solution encoders & solution decoders,\" as there are multiple types of autoencoders. This feedback is clear and actionable, offering the authors a concrete way to enhance the clarity and comprehensibility of their figures. By addressing this suggestion, the authors can improve the readability and understanding of their work for both reviewers and readers. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks for information about the computation required to implement the experiments, including how long they took and on what kind of hardware. This request provides a clear and direct action for the authors to take, as it specifies exactly what information is needed. The authors know exactly what to include in their draft to address this feedback. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly asks for information about the computation required to implement the experiments, including how long they took and on what kind of hardware. This request is specific and provides clear guidance on what the authors need to address. However, it does not specify which part of the paper this information should be included in, making it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point is a request for additional information about the computation required to implement the experiments and the duration and hardware used. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment requests additional information about the computation required to implement the experiments, including the duration and hardware used. This feedback is 3 as it prompts the authors to provide more detailed information about the experimental setup, which can be beneficial for readers interested in replicating or understanding the experiments. However, the comment does not offer specific suggestions on how to present this information or why it is important, leaving the authors with a general direction but without detailed guidance. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the application of the meta sampler and suggests that the authors provide more discussion on this aspect. It also asks when the meta sampler is applied. While the comment implies that the authors should provide additional discussion and clarify the timing of the meta sampler\"s application, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed information. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the meta sampler\" and \"the linear classifier,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the authors should provide more discussion on the application of the meta sampler and when it is applied (which epoch). This provides clear guidance on what the authors need to address in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification on the application of the meta sampler. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the application of the meta sampler, inquiring whether it is used in a decoupled manner and, if so, when it is applied. This feedback is 3 as it prompts the authors to clarify an aspect of their methodology that may not be fully explained in the paper. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered guidance on how to present the information more clearly. Overall, the comment identifies a potential area for improvement but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should use fairnessaware metrics like Equality odds (EO) and conduct more experiments on datasets like COMPAS and Drug Consumption. It also encourages the authors to follow a specific AAAI paper that they have cited. While the comment implies that the authors should incorporate these suggestions, it does not provide explicit instructions on how to implement them or what specific changes to make. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of a \"vanilla metric\" and the lack of related fairnessaware metrics like Equality odds (EO). It also suggests conducting more experiments on datasets like COMPAS and Drug Consumption, referencing a specific AAAI paper. This provides clear guidance on what needs to be addressed and where, making it easy for the authors to identify the relevant parts of the paper. The comment is also specific because it provides a clear suggestion for improvement and references a relevant paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors use their own defined \"vanilla metric\" and lack related fairnessaware metrics like Equality odds (EO). It suggests conducting more experiments on datasets like COMPAS and Drug Consumption and references a specific AAAI paper for guidance. The claim is 3 as it provides a specific suggestion for improvement and references a relevant paper, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to explore the referenced paper to understand the context fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the use of a \"vanilla metric\" without considering related fairnessaware metrics like Equality odds (EO). It suggests that the authors conduct more experiments on datasets like COMPAS and Drug Consumption, referencing a specific AAAI paper for guidance. This feedback is clear and actionable, providing the authors with a concrete suggestion for improvement and a reference to follow. However, the comment could be more helpful if it explained why these fairnessaware metrics are important or how they might impact the results. Overall, the comment is 4 as it directs the authors toward a specific area for improvement, but it could be more comprehensive with additional context or explanation."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests considering additional baselines, specifically Rope and Alibi relative positional embeddings, to verify the performance improvement resulting from the changes proposed in the paper. While the comment implies that the authors should include these baselines, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide detailed guidance on how to incorporate these baselines or what specific aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests considering additional baselines, specifically Rope and Alibi relative positional embeddings, to verify the performance improvement obtained by the changes proposed in the paper. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the results discussion. This lack of explicit reference makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the inclusion of these baselines, but without clear grounding, it aligns with a score of 2.", "verifiability_rationale": "The review point suggests considering additional baselines, specifically Rope and Alibi relative positional embeddings, to verify the performance improvement obtained by the changes proposed in the paper. However, the comment does not provide any reasoning or evidence to support why these specific baselines are relevant or how they would contribute to the verification process. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests considering additional baselines, specifically Rope and Alibi relative positional embeddings, to verify the performance improvement obtained by the changes proposed in the paper. This feedback is 3 as it provides a specific suggestion for enhancing the experimental validation of the paper. However, the comment lacks depth and does not explain why these particular baselines are relevant or how they might contribute to the evaluation. While it points the authors in a direction for improvement, it could be more helpful with additional context or rationale. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies two missing elements in the paper: the value of neighborhood size h and an analysis of its influence on the model\"s performance, as well as the use of different hyperparameter sets per dataset. It suggests that the authors provide insights into how performance varies with a constant set of parameters. These actions are clear and concrete, giving the authors specific tasks to address in their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"value of neighborhood size h\" and the \"analysis of its influence over the model\"s performance,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what is missing, namely an analysis of the influence of h on performance and the use of different hyperparameter sets per dataset. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper lacks an analysis of the value of neighborhood size h and its influence on the model\"s performance, which is considered a key parameter of the proposed strategy. It also notes the use of different hyperparameter sets per dataset, suggesting that this is not ideal. The comment provides a logical reasoning for the importance of analyzing the neighborhood size and its impact on performance, as well as the need for consistency in hyperparameter sets. However, it does not provide specific examples or references to support the claim, making it 3. The authors would need to infer the importance of these elements based on the provided reasoning. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two important areas for improvement in the paper. First, it points out the absence of an analysis of the value of neighborhood size h and its influence on the model\"s performance, which is a key parameter of the proposed strategy. This feedback is actionable as it suggests that the authors should provide insights into how the value of h affects the model\"s performance, offering a clear direction for enhancing the paper. Second, the comment highlights the use of different hyperparameter sets per dataset, which is not ideal, and asks for insights into how performance varies with a constant set of parameters. This feedback is also actionable, as it prompts the authors to consider standardizing their hyperparameter sets across datasets. Overall, the comment is clear and provides specific suggestions for improvement, making it 5 for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the impact of imperfect multimodal data on the model, specifically addressing the effects of missing modalities on the construction of polynomial tensors. While it does not explicitly instruct the authors to address this issue, it implies that the authors should consider and discuss this aspect in their paper. The question is somewhat vague, as it does not provide specific guidance on how to investigate or address the issue. However, the authors can infer that they need to explore the effects of missing data on the model and its ability to infer missing modalities. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the impact of imperfect multimodal data on the model, specifically addressing the effects of missing modalities on the construction of polynomial tensors. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its inquiry about the effects of missing data and the model\"s ability to infer missing modalities, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the impact of imperfect multimodal data on the model, specifically addressing the effects of missing modalities on the construction of polynomial tensors. The comment does not present a claim or opinion but rather poses a question seeking clarification. It is purely factual and does not require verification, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises an important question about the impact of imperfect multimodal data on the model, specifically addressing the effects of missing modalities on the construction of polynomial tensors. It prompts the authors to consider the potential compounding effects of missing data and how the model might leverage additional modalities to infer missing ones. This feedback is 3 as it identifies a potential area for further exploration and discussion in the paper. However, it lacks specific guidance or suggestions on how the authors might address this issue, such as proposing methods or experiments to investigate the effects. To be more helpful, the comment could include actionable steps or examples to guide the authors in improving their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the SST dataset, specifically asking for statistics on the times negation or intensity words take effect. It suggests showing the frequency of words like \"nothing\" and how often they change the polarity of the context. While the comment implies that the authors should provide these statistics, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include these statistics and how to present them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"General Discussion\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the SST dataset and suggests showing statistics on the times negation or intensity words take effect, such as the frequency of words like \"nothing\" and their impact on polarity. This provides clear guidance on what additional information could be included to enhance the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question and a suggestion regarding the SST dataset. It asks for statistics on the times negation or intensity words take effect, such as the frequency of words like \"nothing\" and their impact on polarity. This is a request for additional information or analysis, rather than a claim or opinion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the SST dataset, suggesting that the authors provide statistics on the times negation or intensity words take effect. It specifically mentions the word \"nothing\" and its impact on polarity, which is a clear and actionable suggestion for improving the paper. By addressing this point, the authors can enhance the comprehensiveness and depth of their analysis, providing readers with a more detailed understanding of the dataset. However, the comment could be more helpful if it included additional suggestions or examples of how these statistics might be presented or analyzed. Overall, the feedback is 4 as it provides a clear direction for enhancing the paper, but it could be more comprehensive with further guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the stability of the OGEAug on OOD benchmarks, specifically mentioning the DrugOOD dataset and the SPE method. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should verify the stability of their method on these benchmarks, but it lacks concrete details on how to do so. As a result, the action is implicit and vague, leaving the authors uncertain about the specific steps to take. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific concern about the stability of the OGEAug method on OOD benchmarks, particularly mentioning the DrugOOD dataset and the SPE method. However, it does not specify which part of the paper discusses these benchmarks or methods, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the stability issue but lacks grounding, as it does not explicitly mention the relevant sections of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors have not verified the stability of the OGEAug method on OOD benchmarks, specifically mentioning the DrugOOD dataset and the SPE method. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific concern about the stability of the OGEAug method on OOD benchmarks, particularly mentioning the DrugOOD dataset and the SPE method. This feedback is relevant and actionable, as it highlights an area where the authors could strengthen their evaluation by verifying the stability of their method on these benchmarks. However, the comment could be more helpful if it provided suggestions on how to conduct this verification or what specific aspects of stability should be evaluated. Despite this, the comment is 3 as it directs the authors to a critical area for improvement in their evaluation process."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to expand the related work section by comparing their work to strong baselines that use coordinates. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and concrete, making it 5.", "grounding_specificity_rationale": "The comment explicitly instructs the authors to expand the related work section by comparing their work to strong baselines that use coordinates. This provides clear guidance on what needs to be addressed, making the comment fully grounded. However, it does not specify which part of the related work section requires expansion or which baselines should be compared, leaving some room for ambiguity. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests expanding the related work section by comparing the work to strong baselines that use coordinates. However, it does not provide any specific examples, references, or detailed reasoning to support why this comparison is necessary or how it would enhance the paper. The lack of supporting evidence or detailed justification makes the claim difficult for the authors to understand and address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion to expand the related work section by comparing the work to strong baselines that use coordinates. This feedback is valuable as it directs the authors to enhance the context and relevance of their work by highlighting its relationship to existing strong baselines. However, the comment could be more helpful if it specified which baselines should be considered or provided examples of how to make these comparisons. Despite this, the feedback is 4 as it guides the authors toward a specific improvement that can strengthen their draft. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the experiments in the paper are limited to a single seed, which makes it difficult to assess the significance of performance differences and the impact of the proposed cycle consistency loss on convergence. The reviewer suggests conducting multiple seed experiments to provide a more robust evaluation. This feedback is clear and provides a direct action for the authors to take, which is to conduct additional experiments with multiple seeds. The suggestion is concrete, as it specifies exactly what needs to be done to improve the evaluation. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the issue of singleseed experiments, which limits the assessment of performance differences and the impact of the proposed cycle consistency loss. However, it does not specify which part of the paper discusses these experiments, making it weakly grounded. The comment is specific in suggesting the need for multiple seed experiments to provide a more robust evaluation. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments in the paper are limited to a single seed, which makes it difficult to assess the significance of performance differences and the impact of the proposed cycle consistency loss on convergence. The reviewer suggests conducting multiple seed experiments to provide a more robust evaluation. This claim is 3 as it provides a logical reasoning for the need for multiple seed experiments to ensure the robustness of the results. However, the comment lacks specific examples or references to support the claim that singleseed experiments are insufficient. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant limitation in the paper\"s experimental setup, specifically the use of a single seed for training. It highlights the difficulty in assessing the significance of performance differences and the impact of the proposed cycle consistency loss on convergence due to this limitation. The reviewer suggests conducting multiple seed experiments to provide a more robust evaluation. This feedback is clear and actionable, offering a specific improvement that the authors can implement to enhance the credibility and robustness of their results. However, the comment could be more helpful if it provided guidance on how to conduct these multiple seed experiments or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors toward a critical area for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation of the proposed method, noting that it requires an entire multiGPU setup for optimizations, which may limit its accessibility to potential users. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this issue, such as suggesting alternative approaches or optimizations that could make the method more accessible. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a limitation of the proposed method, specifically mentioning that it requires an entire multiGPU setup for optimizations, which may limit its accessibility to potential users. However, it does not specify which part of the paper discusses this requirement or where the authors should address this issue. The authors can infer that it relates to the methodology or experimental setup sections, but the comment lacks full grounding as it does not explicitly mention these sections. Additionally, while it identifies a potential limitation, it does not provide specific guidance on how to address it or suggest alternative approaches. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the proposed method requires an entire multiGPU setup for optimizations, which limits its accessibility to potential users. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references to justify the need for a multiGPU setup, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation of the proposed method, noting that it requires an entire multiGPU setup for optimizations, which may limit its accessibility to potential users. This is a relevant observation that could impact the practicality and applicability of the method. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this issue. Without detailed feedback or recommendations, the authors are left without a clear path to improve their draft. Therefore, the comment is 3, as it points out a limitation but does not fully support the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests comparing the current system, which captures semantics through RNNbased models, with another system that also captures semantics. It implies that the authors should consider Ref2 as a strong baseline for comparison. However, the comment does not provide specific guidance on how to implement this comparison or what aspects to focus on. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to improve their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests comparing the current system, which captures semantics through RNNbased models, with another system that also captures semantics. It implies that Ref2 could be a strong baseline for comparison. However, the comment does not specify which part of the paper this comparison should be made in, nor does it provide detailed guidance on how to implement this comparison. The authors can infer that it relates to the methodology or results sections, but the lack of explicit grounding and specificity makes it difficult for them to address the feedback effectively. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests comparing the current system, which captures semantics through RNNbased models, with another system that also captures semantics. It references Ref2 as a potential strong baseline for comparison. However, the comment lacks specific details or examples to support why Ref2 is a suitable baseline or how it would enhance the comparison. The suggestion is 3 as it provides a general direction but lacks the necessary depth and evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests comparing the current system, which captures semantics through RNNbased models, with another system that also captures semantics. It implies that this comparison could provide valuable insights into the performance of the current system. Additionally, the comment references Ref2 as a potential strong baseline for comparison, which could help the authors benchmark their work effectively. However, the comment lacks specific guidance on how to implement this comparison or what aspects to focus on, which limits its helpfulness. While it provides a direction for improvement, it could be more actionable with detailed suggestions. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the user decoder\"s use of information from the agent decoder, specifically asking why it only uses information up to time step t and not from all time steps. While the comment implies that the authors should clarify this aspect, it does not provide explicit guidance on how to address the issue or suggest specific changes to make. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional explanation or clarification. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the user decoder\"s use of information from the agent decoder, specifically asking why it only uses information up to time step t and not from all time steps. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its inquiry about the use of information, but without clear grounding, the authors may struggle to identify the exact section being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point is a question seeking clarification about the user decoder\"s use of information from the agent decoder. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the user decoder\"s use of information from the agent decoder, specifically asking why it only uses information up to time step t and not from all time steps. This is a relevant question that could help the authors clarify their methodology and potentially improve the clarity of their paper. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their explanation. While it identifies a potential area for improvement, it lacks actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the difference in ICL performance when ablating induction heads versus FV heads could be influenced by the \"location\" of these heads within the model. It implies that a controlled baseline should be included, which ablates heads at different locations in the model. While the comment identifies a potential confounding factor and suggests a way to address it, it does not provide specific guidance on how to implement this controlled baseline or what specific locations should be tested. The action is explicit but somewhat vague, as the authors know they need to include a controlled baseline but may not be entirely clear on how to execute it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"induction heads\" and \"FV heads,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the \"location\" of these heads within the model could be a confounding factor affecting the ICL performance. The comment further suggests a controlled baseline that ablates heads at different locations in the model. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the difference in ICL performance when ablating induction heads versus FV heads could be influenced by the \"location\" of these heads within the model. The reviewer provides a logical reasoning by pointing out that induction heads and FV heads are located at different layers, which could be a confounding factor. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to consider this reasoning and potentially conduct additional experiments to verify the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential confounding factor in the analysis of induction heads and FV heads, suggesting that the \"location\" of these heads within the model could influence the ICL performance. It provides a clear and actionable suggestion to include a controlled baseline that ablates heads at different locations in the model. This feedback is valuable as it directs the authors to consider a critical aspect of their experimental design that could impact the results. However, the comment could be more helpful if it offered specific guidance on how to implement this controlled baseline or what locations to test. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that a section on synonym identification is missing under similarity measurement, suggesting that the authors should include this section to describe how the multiplechoice task is approached. This feedback provides a clear and direct action for the authors to take, specifying exactly what needs to be added to their draft. The comment is explicit and concrete, giving the authors a clear understanding of what needs to be done to improve their paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions a missing section on synonym identification under similarity measurement, providing full grounding as the authors can accurately identify the part of the paper being addressed. It also specifies what is missing, namely a description of how the multiplechoice task is approached, which provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that a section on synonym identification is missing under similarity measurement, which would describe how the multiplechoice task is approached. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this section is necessary or how it would improve the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the importance of this section or how to address it. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks a section on synonym identification under similarity measurement, which would describe how the multiplechoice task is approached. This feedback is clear and actionable, as it provides a direct suggestion for improving the paper by adding a section that could enhance the understanding of the methodology. However, the comment could be more helpful if it offered additional guidance on what aspects should be included in this section or how it would contribute to the overall understanding of the paper. Despite this, the comment is 4 as it directs the authors to a specific area for improvement, making it a 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that an overview of the workflow and the model would be beneficial for understanding the work as a whole. However, it does not provide explicit guidance on how to create this overview or what specific elements should be included. The action is implicit and somewhat vague, as the authors can infer that they need to provide an overview but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that an overview of the workflow and the model would be beneficial for understanding the work as a whole. However, it does not specify which part of the paper lacks this overview or where it should be included. The authors can infer that it might be in the introduction or the methodology section, but this inference is not explicit. The comment is specific in suggesting what is needed, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that an overview of the workflow and the model would be beneficial for understanding the work as a whole. However, it does not provide any specific reasoning, examples, or references to support why this overview is necessary or how it would improve the paper. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment suggests that an overview of the workflow and the model would be beneficial for understanding the work as a whole. This feedback is 3 as it identifies a potential area for improvement by highlighting the need for a more comprehensive introduction. However, the comment lacks specificity and does not provide detailed guidance on how to incorporate this overview or what elements should be included. While it points out a general area for enhancement, it does not offer actionable steps or suggestions for improvement, leaving the authors with a vague idea of what needs to be addressed. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the potential bias in the sketch due to the need to compute the statistical dimension d_lambda of the design matrix A. It suggests that this computation requires the same runtime as solving the ridge regression problem, which could defeat the purpose of the approach. The comment implies that the authors should address this issue by discussing it in the paper, but it does not provide explicit instructions on how to do so. While the action is implicit, it is 3 as it points out a potential issue that the authors should consider. However, the lack of concrete guidance on how to address the issue limits its actionability.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the computation of the statistical dimension d_lambda of the design matrix A, which is crucial for debiasing the sketch. It also mentions a similar issue when computing the surrogate sketch. However, the comment does not specify which part of the paper discusses these issues, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but without explicit references, it is challenging to pinpoint the exact location. The comment is specific in detailing the issue and its potential impact on the approach, but the lack of grounding limits its effectiveness. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the statistical dimension d_lambda of the design matrix A is necessary for debiasing the sketch, but it cannot be computed accurately without the same runtime as solving the ridge regression problem. The reviewer suggests that this could introduce bias, potentially defeating the purpose of the approach. The comment provides a logical reasoning based on the computational complexity of the problem, but it lacks specific examples or references to support the claim fully. This makes the claim 3, as the authors would need to further explore and substantiate the issue themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the debiasing of the sketch, specifically the need to compute the statistical dimension d_lambda of the design matrix A. It points out that this computation requires the same runtime as solving the ridge regression problem, which could introduce bias and potentially defeat the purpose of the approach. The comment also mentions a similar issue when computing the surrogate sketch. While the comment highlights a critical concern, it does not provide specific suggestions or guidance on how the authors might address this issue or mitigate the potential bias. The feedback is 3 as it alerts the authors to a potential weakness in their approach, but it lacks actionable advice for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to redefine Figure 3, specifying that the expected quantities are scalars but are shown as a vector. This provides a clear and direct action for the authors to take, ensuring that the figure accurately represents the data. The comment is specific and concrete, leaving no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the redefinition of the figure to show scalar quantities instead of vectors. This provides clear guidance on how to improve the figure, making the comment 5.", "verifiability_rationale": "The review point is a request for clarification regarding the representation of quantities in Figure 3. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the paper. It identifies a potential issue with the representation of quantities in Figure 3, noting that the expected quantities are scalars but are shown as vectors. This feedback is clear and direct, guiding the authors on how to correct this misrepresentation, which could enhance the clarity and accuracy of their presentation. However, the comment could be more helpful if it explained why this misrepresentation is important or how it affects the interpretation of the results. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional context or explanation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the proposed models are useful for learning representations for lowfrequency words but lacks empirical evidence to support this claim. It suggests that the authors should explore this aspect further by providing empirical evidence. While the comment implies that the authors should conduct additional analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to conduct the analysis or what metrics to use. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the aspect of the paper being addressed, namely the proposed models\" usefulness for learning representations for lowfrequency words. It also specifies the issue by pointing out the lack of empirical evidence to test the hypothesis and the need for deeper exploration. However, it does not provide specific guidance on how to address these issues or what additional evidence or analysis would be beneficial. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed models are useful for learning representations for lowfrequency words but lacks empirical evidence to support this claim. The reviewer suggests that the authors should explore this aspect further, which is a reasonable request. However, the comment does not provide specific examples or references to support the claim, making it 3. The authors would need to infer the reasoning behind the suggestion and potentially conduct additional research to address the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks empirical evidence to support its claim about the usefulness of the proposed models for learning representations of lowfrequency words. It suggests that the authors should explore this aspect further by providing empirical evidence, which is a clear and actionable piece of feedback. However, the comment could be more helpful if it offered specific suggestions on how to conduct this empirical analysis or what metrics to use. Despite this, the feedback provides a valuable direction for the authors to enhance their draft, making it 4. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the resolution of the 3D voxel and its impact on the network\"s computational and memory costs. It suggests that studying the importance of the global feature in Section 4.2 by comparing with different resolutions of voxel features would be more convincing. The comment also points out that reducing the resolution to 1x1x1 is equivalent to using a single global feature. While the comment implies that the authors should conduct this comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct the suggested comparison. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the resolution of the 3D voxel and its impact on the network\"s computational and memory costs. The comment suggests studying the importance of the global feature by comparing with different resolutions of voxel features, which provides a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the resolution of the 3D voxel and its impact on the network\"s computational and memory costs. It suggests that studying the importance of the global feature by comparing with different resolutions of voxel features would be more convincing. The comment also points out that reducing the resolution to 1x1x1 is equivalent to using a single global feature. While the comment provides a logical reasoning for the suggestion, it lacks specific examples or references to support the claim about the computational and memory costs. This makes the claim 3, as the authors would need to conduct additional analysis to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a pertinent question about the resolution of the 3D voxel and its impact on the network\"s computational and memory costs. It suggests that studying the importance of the global feature by comparing with different resolutions of voxel features would be more convincing. The comment also points out that reducing the resolution to 1x1x1 is equivalent to using a single global feature, which could be a valuable insight for the authors. While the comment identifies a potential area for improvement, it lacks specific guidance on how to conduct the comparison or what specific resolutions to consider. This limits the comment\"s helpfulness, as it provides a direction but not a detailed roadmap for improvement. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that it is difficult to see trends in Table 3, particularly regarding the behavior of PM+CL compared to PM or CL alone. It also suggests that it would be interesting to see development set trends with respect to these hyperparameters. While the comment implies that the authors should provide additional analysis or trends, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to add more analysis but are not given specific guidance on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular issue with the trends in the table, noting that PM+CL behaves differently than either PM or CL alone. The comment further suggests that it would be interesting to see development set trends with respect to these hyperparameters. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that it is difficult to see trends in Table 3, particularly regarding the behavior of PM+CL compared to PM or CL alone. The reviewer also suggests that it would be interesting to see development set trends with respect to these hyperparameters. While the comment highlights a potential issue with the table, it lacks specific examples or detailed reasoning to support the claim that the trends are unclear. This makes the comment 3, as it points out a potential issue but does not provide sufficient evidence or explanation to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 3, noting that it is difficult to see trends in the behavior of PM+CL compared to PM or CL alone. It suggests that it would be interesting to see development set trends with respect to these hyperparameters. This feedback is clear and actionable, as it points out a potential area for improvement in the analysis and presentation of results. By suggesting a specific enhancement, the comment provides the authors with a concrete direction for enhancing the clarity and comprehensiveness of their findings. However, it could be more helpful if it included additional guidance on how to present these trends or suggestions for alternative visualizations. Overall, the comment is 4, as it effectively guides the authors toward improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a difficulty in understanding Figure 5 due to the presence of many lines on top of each other. It suggests that the authors could report flops or model size to make the metrics more concrete. While the comment implies that the authors should include additional information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to report flops or model size. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the figure, namely the difficulty in understanding due to the overlapping lines, and suggests that reporting flops or model size would make the metrics more concrete. This provides clear guidance on what needs to be addressed to improve the figure. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that it is difficult to understand Figure 5 due to the presence of many lines on top of each other. It suggests that the authors could report flops or model size to make the metrics more concrete. However, the comment lacks specific examples or detailed reasoning to support why these additional metrics would improve understanding or make the figure more concrete. Without such evidence or explanation, the claim is 3, as it provides a suggestion but lacks sufficient justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 5, noting that it is difficult to understand due to the presence of many lines on top of each other. It suggests that the authors could improve the figure by reporting flops or model size, which would make the metrics more concrete. This feedback is clear and actionable, providing the authors with a specific suggestion to enhance the clarity and comprehensibility of their figures. However, the comment could be more helpful if it included additional guidance on how to report flops or model size effectively. Overall, the comment is 4 as it directs the authors toward a meaningful improvement in their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point indicates that some details of the proposed method are missing, as noted in the questions section below. However, it does not specify which details are missing or how the authors should address this issue. The comment lacks explicit guidance or concrete suggestions on what needs to be added or clarified, leaving the authors uncertain about how to improve their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment indicates that some details of the proposed method are missing, as noted in the questions section below. However, it does not specify which part of the paper these questions are from, nor does it provide details on what specific details are missing. This lack of explicit reference to a specific section or element of the paper makes it difficult for the authors to pinpoint the exact areas needing attention. Additionally, the comment lacks specificity regarding the missing details, leaving the authors uncertain about what needs to be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that \"some details of the proposed method are missing,\" but it does not provide any specific examples or reasoning to support this claim. Without detailed explanation or references to what details are missing, the authors may find it challenging to understand and address the issue. The comment lacks verifiability as it does not provide sufficient evidence or justification for the claim, making it difficult for the authors to improve their work based on this feedback. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment indicates that some details of the proposed method are missing, as noted in the questions section below. However, it does not specify which details are missing or provide any guidance on how the authors might address this issue. Without specific feedback or suggestions, the authors are left without actionable insights to improve their draft. The comment lacks depth and clarity, making it 2 at best. Therefore, it aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should evaluate the performance of EIGNN with respect to oversmoothing under standard settings on realworld datasets, particularly in comparison with variants that focus on dealing with oversmoothing, such as GCNII. This comment explicitly states a specific action for the authors to take, which is to conduct additional evaluations and comparisons. However, it does not provide detailed guidance on how to implement these evaluations or what specific metrics to use. While the action is clear, the lack of concrete details on execution makes the comment 3.", "grounding_specificity_rationale": "The comment suggests evaluating the performance of EIGNN with respect to oversmoothing under standard settings on realworld datasets, particularly in comparison with variants focusing on dealing with oversmoothing, such as GCNII. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the evaluation or results sections, but this inference is not explicit. The comment is specific in suggesting a particular comparison and evaluation, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it would be interesting to see how EIGNN performs with respect to oversmoothing under standard settings on realworld datasets, particularly in comparison with variants focusing on dealing with oversmoothing, such as GCNII. This claim is 3 as it provides a logical suggestion for further evaluation and comparison, which could enhance the paper\"s contribution. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand the basis of the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests an interesting direction for further evaluation by proposing a comparison of EIGNN with respect to oversmoothing under standard settings on realworld datasets. It specifically mentions the need to compare with variants focusing on dealing with oversmoothing, such as GCNII. This feedback is clear and actionable, as it provides a specific area for the authors to explore and potentially enhance their work. However, the comment could be more helpful if it included suggestions on how to conduct these comparisons or what specific metrics to use. Overall, the comment is 4 as it guides the authors toward a meaningful extension of their work, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that Figure 4 is confusing and that the columns are not explained in the text or caption. This provides a clear action for the authors to take, which is to clarify the meaning of the columns in the figure by either adding an explanation in the text or updating the caption. The feedback is explicit and provides concrete guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the confusion regarding the meaning of the columns in the figure. The comment highlights the lack of explanation in the text or caption, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 4 is confusing because the columns are not explained in the text or caption. However, it does not provide any further explanation or reasoning to support this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the confusion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 4, noting that the columns are confusing and not explained in the text or caption. This feedback is clear and actionable, as it directs the authors to clarify the meaning of the columns in the figure by either adding an explanation in the text or updating the caption. By addressing this feedback, the authors can enhance the clarity and accessibility of their work, making the comment 4. However, the comment could be more helpful if it provided suggestions on how to clarify the figure or offered examples of how to improve the explanation. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the absence of an ablation analysis in the main paper, which makes it challenging to identify the source of a small performance gain. While the comment implies that an ablation analysis should be included, it does not explicitly instruct the authors to conduct one. The action is implicit and somewhat vague, as the authors can infer that they need to add an ablation analysis but are not provided with specific guidance on how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of ablation analysis in the main paper, which makes it difficult to identify the source of a small performance gain. However, it does not specify which part of the paper this issue pertains to, such as a specific section or experiment. The authors can infer that it relates to the results or methodology sections, but this inference is not explicit. The comment is specific in pointing out the need for an ablation analysis, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the lack of ablation analysis makes it difficult to identify the source of a small performance gain. This is a subjective opinion based on the reviewer\"s expectation of what should be included in the paper. However, the comment does not provide specific examples or detailed reasoning to support why an ablation analysis is necessary or how it would improve the paper. Without additional context or evidence, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of an ablation analysis, which would help pinpoint the source of a small performance gain. This feedback is valuable as it highlights a critical area for improvement that could enhance the paper\"s clarity and understanding of the results. However, the comment does not provide specific suggestions or guidance on how to conduct the ablation analysis or what components to focus on. While it directs the authors to a necessary step, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a finding from Figure 2, stating that when the number of classes is large, the noise rate of similarity labels is less than that of class labels. It also mentions the use of \"Th.\" However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how this finding should be addressed, whether it needs further exploration, or how it impacts the paper\"s conclusions. Without any actionable advice or suggestions, the authors are left without a clear understanding of what steps to take in response to this observation. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment refers to Figure 2, which allows the authors to identify the specific part of the paper being addressed. It specifies that when the number of classes is large, the noise rate of similarity labels is less than that of class labels. However, it does not provide any further details or suggestions on how this observation should be addressed or what implications it has for the paper. The comment lacks specificity regarding what needs to be done to improve the paper based on this finding. Therefore, the comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point makes a factual observation about the noise rate of similarity labels compared to class labels, as shown in Figure 2. It does not express an opinion, judgment, or suggestion that requires verification. The statement is purely descriptive and does not contain any claims or requests for changes. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment makes a factual observation about the noise rate of similarity labels compared to class labels, as shown in Figure 2. It notes that when the number of classes is large, the noise rate of similarity labels is less than that of class labels. However, the comment does not provide any context, analysis, or suggestions for how this observation might impact the paper or what implications it has for the authors\" work. Without additional context or guidance, the authors are left without actionable feedback on how to address this observation or its significance. Therefore, the comment is 2, as it identifies a potential area of interest but lacks depth and actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the hypothesis is interesting but not well verified by the designed experiment. It highlights a specific issue with the experimental setup, noting that the base model is trained on the adversarial set only, while models in conventional methods are trained on both the original training set and the generated adversarial examples. The reviewer recommends comparing the model trained on the original dataset with that trained on the mixture to highlight the impact of the augmented adversarial examples. This feedback is explicit and provides a clear action for the authors to take, making it 5. The authors know exactly what needs to be done to improve the experiment and its motivation, which is to make it more convincing. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the experimental setup, suggesting a comparison between models trained on the original dataset and those trained on the mixture to highlight the impact of augmented adversarial examples. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the hypothesis is interesting but not well verified by the designed experiment. It provides a specific critique of the experimental setup, noting that the base model is trained on the adversarial set only, while models in conventional methods are trained on both the original training set and the generated adversarial examples. The reviewer suggests comparing the model trained on the original dataset with that trained on the mixture to highlight the impact of the augmented adversarial examples. This feedback is supported by logical reasoning and a clear explanation of the issue, making it 4. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental setup, noting that the base model is trained on the adversarial set only, while models in conventional methods are trained on both the original training set and the generated adversarial examples. The reviewer suggests comparing the model trained on the original dataset with that trained on the mixture to highlight the impact of the augmented adversarial examples. This feedback is clear and actionable, providing the authors with a specific direction to improve the validity and persuasiveness of their experimental results. By addressing this critique, the authors can strengthen the motivation and impact of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point states that the CNN experiments are not fully convincing, but it does not provide any specific details or suggestions on how to improve them. There is no explicit or implicit action for the authors to take, nor are there any concrete steps outlined to enhance the credibility of the experiments. As a result, the comment lacks actionability, leaving the authors without guidance on how to address the issue. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment mentions that the CNN experiments are not fully convincing, but it does not specify which part of the paper these experiments are discussed in, nor does it provide details on what aspects of the experiments are not convincing. This lack of specificity and grounding makes it difficult for the authors to identify the exact areas that need improvement. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the CNN experiments are not fully convincing, but it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment indicates that the CNN experiments are not fully convincing, but it does not provide any specific details or examples to support this claim. Without additional context or suggestions for improvement, the authors are left without actionable feedback on how to enhance the credibility of their experiments. The comment lacks depth and specificity, making it 2 at best. Therefore, it aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should compare their results with stateoftheart (SoTA) approaches, specifically mentioning HateXplain models. This is an explicit action that provides a clear direction for the authors to follow. The suggestion is concrete, as it specifies a particular model to compare with, making it easy for the authors to understand and implement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests comparing the results with stateoftheart (SoTA) approaches, specifically mentioning HateXplain models. However, it does not specify which part of the paper this comparison should be made in, such as the results section or a specific experiment. This lack of explicit reference to a particular section makes it weakly grounded. The comment is specific in suggesting a comparison with HateXplain models, which provides a clear direction for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests comparing the results with stateoftheart (SoTA) approaches, specifically mentioning HateXplain models. This is a request for additional analysis or comparison, but it does not contain a claim or opinion that requires verification. It is a suggestion for improvement, which is factual and does not necessitate verification. Therefore, the label \"No\" is appropriate.", "helpfulness_rationale": "The review comment suggests that the authors should compare their results with stateoftheart (SoTA) approaches, specifically mentioning HateXplain models. This feedback is clear and actionable, providing a specific direction for the authors to enhance their work by benchmarking against established models. However, the comment could be more helpful if it explained why this comparison is important or how it would contribute to the paper\"s significance. Despite this, the suggestion is valuable and offers a concrete step for the authors to take, making it 4. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the rationale behind using freezing in the MLS selection process and suggests using an adaptive method instead. While the comment implies that the authors should provide a clearer explanation for their choice of freezing, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify their reasoning. However, the comment does provide a concrete suggestion for an alternative approach, which could guide the authors in improving their draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment questions the rationale behind using freezing in the MLS selection process and suggests using an adaptive method instead. However, it does not specify which part of the paper discusses the freezing method or where the adaptive method is mentioned. This makes it difficult for the authors to pinpoint the exact section that needs attention. While the comment is specific in its critique, it lacks grounding as it does not explicitly mention the relevant sections or figures. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the rationale behind using freezing in the MLS selection process and suggests using an adaptive method instead. However, the comment does not provide any supporting evidence, reasoning, or references to justify why freezing is not appropriate or why an adaptive method would be better. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment questions the rationale behind using freezing in the MLS selection process and suggests using an adaptive method instead. While it identifies a potential area for improvement, it lacks depth and does not provide specific guidance or suggestions on how the authors might address this issue. The comment points out a specific aspect of the methodology that could be clarified or improved, but it does not offer detailed advice or examples on how to make these changes. As a result, the feedback is 3, as it prompts the authors to reconsider their approach but does not fully support them in making those changes."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the issue addressed in the existing work is also solved in the proposed knowledgeCLIP model. It suggests that the authors perform a similar analysis, such as adding negation or changing entities in text, to see if the KGaugmented method can robustly handle these changes. While the comment implies that the authors should conduct this analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement the suggested analysis. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about whether the issue addressed in existing work is also solved in the proposed knowledgeCLIP model. It suggests that the authors perform a similar analysis, such as adding negation or changing entities in text, to see if the KGaugmented method can robustly handle these changes. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. It is specific in suggesting a particular analysis that could be conducted, but without explicit references to the paper, the authors may find it challenging to pinpoint the exact section needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about whether the issue addressed in existing work is also solved in the proposed knowledgeCLIP model. It suggests that the authors perform a similar analysis, such as adding negation or changing entities in text, to see if the KGaugmented method can robustly handle these changes. The comment references an external work (https://arxiv.org/abs/2104.06378) that has done closelyrelated analyses, providing some support for the suggestion. However, the comment lacks specific examples or detailed reasoning from the authors\" work, making it 3. The authors would need to further develop the claim with their own analysis to fully substantiate it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises an interesting question about whether the issue addressed in existing work is also solved in the proposed knowledgeCLIP model. It suggests that the authors perform a similar analysis, such as adding negation or changing entities in text, to see if the KGaugmented method can robustly handle these changes. This feedback is 3 as it provides a specific suggestion for further analysis that could enhance the paper. However, the comment could be more helpful if it offered more detailed guidance on how to conduct this analysis or what specific aspects to focus on. Overall, the comment provides a valuable direction for the authors to consider, but it lacks depth and actionable details, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point raises two specific issues with the paper. First, it questions the use of p m in the numerator and p c in the denominator in Eq. 3, asking for clarification on the reason for this choice. Second, it suggests that the authors consider adding the variance for further improvement in Alg. 2, and it recommends replacing \u03bc f with \u03bc g to maintain consistency with Eq. The comment provides explicit actions for the authors to take, such as clarifying the reasoning behind the equation and considering the addition of variance. The suggestions are concrete and direct, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq. 3\" and \"Alg. 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the confusion regarding the use of p m and p c in Eq. 3 and suggests adding the variance for further improvement in Alg. 2. Additionally, it provides a suggestion to replace \u03bc f with \u03bc g to maintain consistency with Eq. This level of detail and specificity helps the authors understand exactly what needs to be addressed and improved in their draft. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a specific issue with the use of p m in the numerator and p c in the denominator in Eq. 3, questioning the reasoning behind this choice. It also suggests that the authors consider adding the variance for further improvement in Alg. 2 and recommends replacing \u03bc f with \u03bc g to maintain consistency with Eq. These suggestions are based on logical reasoning and a desire for clarity and consistency in the paper. However, the comment lacks specific references or detailed explanations to fully substantiate the claims, making it 3. The authors would need to provide additional context or justification to fully understand and address the points raised. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper. First, it points out a potential confusion in Eq. 3, where the use of p m in the numerator and p c in the denominator is questioned. The reviewer asks for clarification on the reason for this choice, which is a clear and actionable suggestion for the authors to address. Second, the comment suggests that the authors consider adding the variance for further improvement in Alg. 2, which is a constructive and specific recommendation. Additionally, the comment provides a suggestion to replace \u03bc f with \u03bc g to maintain consistency with Eq., which is another actionable point. The feedback is detailed and offers clear guidance on how to improve the draft, making it 5 for the authors. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the computational cost of the proposed approach and suggests that the paper should provide a more comprehensive discussion on the computational complexity. It also questions whether the approach becomes prohibitive in certain settings. While the comment implies that the authors should address these concerns, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide a more detailed analysis of the computational complexity and its implications. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of computational cost, specifically questioning the lack of a comprehensive discussion on the computational complexity of the proposal. It also raises a concern about whether the approach becomes prohibitive in certain settings. However, the comment does not specify which part of the paper discusses the computational cost, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but the exact location is not explicitly mentioned. The comment is specific in detailing what needs to be addressed, such as a more comprehensive discussion on computational complexity. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the computational cost of the proposed approach, questioning the lack of a comprehensive discussion on the computational complexity. The reviewer suggests that the paper should provide more details on this aspect, particularly regarding whether the approach becomes prohibitive in certain settings. However, the comment does not provide specific examples or references to support the claim that the computational cost is significant or that it should be discussed further. The lack of detailed justification or evidence makes the claim 3, as the authors would need to infer the importance of this issue based on the reviewer\"s suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper regarding the computational cost of the proposed approach. It points out that while the paper mentions the additional cost did not lead to significant delays in computation, it lacks a comprehensive discussion on the computational complexity of the proposal. The comment also raises a question about whether the approach becomes prohibitive in certain settings. This feedback is clear and actionable, as it prompts the authors to provide a more detailed analysis of the computational complexity and its implications. However, it could be more helpful if it offered specific suggestions on how to address these concerns, such as recommending a particular method for analyzing computational complexity. Overall, the comment is 4 as it directs the authors to an important area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide more explanation about how novel values in the test set are handled. This is an explicit request for additional clarification, which is clear and actionable. The authors know exactly what needs to be done to improve their draft by adding more explanation on this topic. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions line 97, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the authors should provide more explanation about how novel values in the test set are handled. This provides clear guidance on what needs to be addressed to improve the clarity of the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide more explanation about how novel values in the test set are handled. This is a request for clarification rather than a claim or opinion. It does not contain any subjective statements, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment suggests that the authors should provide more explanation about how novel values in the test set are handled. This is a specific and actionable piece of feedback that can help the authors clarify an aspect of their methodology that may be unclear to readers. By addressing this suggestion, the authors can enhance the clarity and comprehensibility of their paper. However, the comment could be more helpful if it provided additional context or examples of what specific information should be included. Overall, the feedback is 4 as it directs the authors to a particular area for improvement, but it could be more comprehensive with further guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a missing indepth analysis of the experimental results, specifically questioning why the improvements of models are limited on the offense detection dataset and significant on the coarse stereotype set. While the comment identifies a gap in the analysis, it does not provide explicit guidance on how the authors should address this issue or what specific aspects of the analysis should be included. The action is implicit and somewhat vague, as the authors are left to infer that they need to conduct a more detailed analysis but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"experimental results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a missing indepth analysis and provides a concrete example of what is lacking: the analysis of why improvements are limited on the offense detection dataset and significant on the coarse stereotype set. This provides clear guidance on what the authors need to address in their analysis. Therefore, the comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point claims that there is a missing indepth analysis of the experimental results, specifically questioning why the improvements of models are limited on the offense detection dataset and significant on the coarse stereotype set. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks depth, namely the analysis of experimental results. It points out a discrepancy in the improvements of models on different datasets, specifically questioning why the improvements are limited on the offense detection dataset and significant on the coarse stereotype set. This feedback is clear and actionable, as it prompts the authors to conduct a more indepth analysis to understand and explain these differences. However, the comment could be more helpful if it provided suggestions on how to approach this analysis or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests several specific actions for the authors to take, including training on labeled data, incorporating input mask explanation annotations for a few examples, and using modern backbone baselines for feature extraction. The reviewer also provides a concrete suggestion to increase the number of convolutional layers to ensure robustness. While the comment is explicit in its actions, it does not provide detailed guidance on how to implement these suggestions, such as specific methods or techniques to use for training or feature extraction. Therefore, the comment is 4, as the authors know what needs to be done but may need further guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific aspects of the paper, such as the \"new method of training on the labeled data\" and the suggestion to use modern backbone baselines like Resnet50 or DenseNet121. It also specifies the issue with the current approach, noting that \"3 conv layers is definitely too small for anything nonsynthetic.\" The comment is specific in its suggestions for improvement, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the proposed method of training on labeled data and incorporating input mask explanation annotations for a few examples might not be effective, citing the failure of similar robustness/domain invariance interventions in the past. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to fully understand and address the concern. The lack of detailed evidence or references limits the verifiability of the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback, suggesting improvements to the methodology and experimental setup. It recommends training on labeled data and incorporating input mask explanation annotations for a few examples, which could enhance the robustness and domain invariance of the model. Additionally, it advises using modern backbone baselines for feature extraction, noting that the current number of convolutional layers is insufficient. While the comment acknowledges the reviewer\"s skepticism about the effectiveness of the proposed approach, it does not let this opinion hinder the constructive nature of the feedback. The suggestions are clear and actionable, making the comment 5 for the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should ensure that the baseline is fully tuned with the same resources as the proposed method to ensure a fair comparison. This is an explicit action, as it directly instructs the authors to address a specific issue related to the hyperparameter tuning of the baseline. However, the comment does not provide detailed guidance on how to implement this action, such as which hyperparameters to focus on or how to conduct the tuning. While the action is clear, the lack of concrete details makes it 3.", "grounding_specificity_rationale": "The comment addresses the introduction of multiple hyperparameters and the extensive hyperparameter search, specifically mentioning \"temperature, penalty, and threshold.\" However, it does not specify which part of the paper discusses these hyperparameters or the hyperparameter search, making it weakly grounded. The comment is specific in suggesting that the baseline should be fully tuned with similar resources as the proposed method for a fair comparison. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper introduces multiple hyperparameters and conducts an extensive hyperparameter search, which could impact the fairness of the comparison with the proposed method. The reviewer recommends ensuring that the baseline is fully tuned with similar resources as the proposed method. However, the comment lacks specific examples or references to support the claim about the impact of hyperparameter tuning on the fairness of the comparison. Without detailed evidence or examples, the claim remains 3, as the authors would need to infer the importance of this suggestion based on the general reasoning provided. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the fairness of the comparison between the proposed method and the baseline due to the extensive hyperparameter search. It suggests that ensuring the baseline is fully tuned with similar resources as the proposed method could be important for a fair comparison. This feedback is 3 as it highlights a specific area for improvement and provides a clear direction for the authors to consider. However, it lacks detailed guidance on how to conduct the hyperparameter tuning or which specific parameters to focus on, which would make the comment more actionable. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies a mistake in the definition of perplexity and provides a correction. It also points out that the equation presented does not look like perplexity but rather like crossentropy. This feedback is clear and provides direct guidance on what needs to be corrected in the draft. The authors know exactly what needs to be changed to ensure accuracy in their definitions and equations. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper, \"L259\" and \"Eq1,\" allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies the issue with the definition of perplexity and provides a correction, stating that it is not what perplexity is and that the equation presented does not look like perplexity but rather like crossentropy. This level of detail guides the authors on what needs to be corrected in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the definition of perplexity at line 259 is incorrect and that the equation presented (Eq1) does not look like perplexity but rather like crossentropy. This claim is verifiable as it provides a clear and specific correction to the definition of perplexity, which is a wellestablished concept in natural language processing. The comment also references the equation, which allows the authors to verify the claim and make necessary corrections. Therefore, the comment is 5.", "helpfulness_rationale": "The review comment identifies a specific error in the definition of perplexity, pointing out that the explanation provided in the paper is incorrect. It also corrects the equation presented, noting that it does not look like perplexity but rather like crossentropy. This feedback is clear and actionable, as it directly addresses a misunderstanding in the paper and provides a correction. By pointing out these errors, the comment empowers the authors to make necessary changes to improve the accuracy and clarity of their draft. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should add more baselines for graph classification tasks, specifically mentioning MVGRL4 and gptgnn5 as examples. It also requests that these baselines be tested on common datasets. This feedback provides a clear and concrete action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The suggestion is explicit and detailed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"graph classification task,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by pointing out the absence of certain baselines, such as MVGRL4 and gptgnn5, and suggests adding more baselines from graph contrastive learning and testing them on common datasets. This provides clear guidance on what needs to be addressed and how to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the baseline for the graph classification task is insufficient, specifically mentioning the absence of MVGRL4 and gptgnn5. The reviewer suggests adding more baselines from graph contrastive learning and testing them on common datasets. While the comment identifies a specific issue with the baseline, it lacks detailed reasoning or examples to support why these particular baselines are necessary or how they would improve the study. The suggestion to add more baselines is logical, but the lack of detailed justification or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific weakness in the paper, namely the insufficiency of the baseline for the graph classification task. It points out the absence of certain baselines, such as MVGRL4 and gptgnn5, and suggests that the authors should add more baselines from graph contrastive learning and test them on common datasets. This feedback is clear and actionable, providing the authors with a concrete direction for improving their draft by expanding the baseline comparison. However, the comment could be more helpful if it included specific suggestions on which additional baselines to consider or why these particular ones are relevant. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the evaluation of the proposed strategies, specifically the consideration of purifying the input image before passing it to the model and the potential structural damage to the edge map. It suggests evaluating the proposed defense against an adversarial attack that minimizes structural alterations to the edge map while mislead the model predictions. This feedback provides a clear and explicit action for the authors to take, which is to conduct a specific evaluation against an adversarial attack that optimizes perturbations to maintain structural integrity. The comment is 5 as it specifies the exact evaluation that needs to be performed to address the concern.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the evaluation of the proposed strategies, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the concern about the evaluation of the proposed defense against an adversarial attack that minimizes structural alterations to the edge map while mislead the model predictions. This provides clear guidance on what needs to be addressed in the evaluation section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the evaluation of the proposed strategies, specifically the consideration of purifying the input image before passing it to the model and the potential structural damage to the edge map. The reviewer suggests evaluating the proposed defense against an adversarial attack that minimizes structural alterations to the edge map while mislead the model predictions. This claim is 3 as it provides a logical reasoning for the need to evaluate the defense against a specific type of adversarial attack. However, the comment lacks specific examples or references to support the claim fully, making it difficult for the authors to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical area for improvement in the evaluation of the proposed strategies. It highlights a specific concern about the evaluation of the defense against an adversarial attack that minimizes structural alterations to the edge map while mislead the model predictions. This feedback is clear and actionable, as it suggests a specific type of evaluation that could be conducted to strengthen the defense mechanism. By pointing out this gap in the evaluation process, the comment provides valuable guidance for the authors to enhance the robustness and effectiveness of their proposed strategies. However, the comment could be more helpful if it included suggestions on how to implement this evaluation or provided examples of similar approaches. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the experimental results, noting that they lack standard deviations, which makes it difficult to assess the significance of the results. This comment provides a clear and explicit action for the authors to take: they should include standard deviations in their experimental results to allow for a more accurate evaluation of the results\" significance. The feedback is direct and provides a concrete step for the authors to follow, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the results, namely the absence of standard deviations, which makes it difficult to judge the significance of the results. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental results lack standard deviations, which makes it difficult to judge the significance of the results. This is a factual statement that does not require verification or justification. It is a request for clarification or improvement, not an opinion or suggestion that needs to be substantiated. Therefore, the label \"No\" is appropriate.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental results, noting that the lack of standard deviations makes it challenging to assess the significance of the results. This feedback is clear and actionable, as it provides a direct suggestion for improvement by recommending the inclusion of standard deviations. By addressing this point, the authors can enhance the clarity and robustness of their experimental findings, which is crucial for the credibility of their work. However, the comment could be more helpful if it provided additional context or examples on how standard deviations can be incorporated or why they are important. Overall, the comment is 4, as it directs the authors to a specific area for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the quality of the generated images by the proposed method, noting that while good continuous control is achieved, the realism of the generated results is limited. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks specific suggestions or guidance on how to improve the quality of the generated images or what aspects of the realism need to be enhanced. Without actionable advice, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the quality of the generated images by the proposed method, specifically mentioning the limited realism of the results shown in the paper and supplemental material. However, it does not specify which part of the paper or supplemental material this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the realism of the generated results, but without clear grounding, the authors may struggle to identify the exact sections that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the quality of the generated images by the proposed method is limited, specifically mentioning the lack of realism in the results shown in the paper and supplemental material. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the quality of the generated images by the proposed method, noting that while good continuous control is achieved, the realism of the generated results is limited. This feedback is 3 as it points out a potential weakness in the paper, prompting the authors to consider ways to improve the realism of their generated images. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending techniques or methods to enhance realism. Without actionable advice, the authors may find it challenging to know where to focus their efforts for improvement. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the statement in lines 559560 is not entirely true and provides a correction by explaining that in Cycle Consistency loss, iterations can be performed between two phases of reconstructions with separate standard backpropagation processes. This feedback is clear and provides a direct action for the authors to correct their statement. The comment is specific and actionable, as it guides the authors on how to revise their draft to ensure accuracy. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 559560, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it corrects a statement by explaining that in Cycle Consistency loss, iterations can be performed between two phases of reconstructions with separate standard backpropagation processes. This provides clear guidance on what needs to be revised in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement in lines 559560 is not entirely true. It provides a specific correction by explaining that in Cycle Consistency loss, iterations can be performed between two phases of reconstructions with separate standard backpropagation processes. This detailed explanation supports the claim, making it 4. However, the comment could be strengthened by referencing specific literature or examples to further substantiate the correction. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific error in the paper, pointing out that the statement in lines 559560 is not entirely true. It provides a clear and actionable correction by explaining that in Cycle Consistency loss, iterations can be performed between two phases of reconstructions with separate standard backpropagation processes. This feedback is valuable as it helps the authors correct a factual error in their draft, ensuring the accuracy and clarity of their work. However, the comment could be more helpful if it also suggested how this correction might impact the overall understanding of the paper or its methodology. Overall, the comment is 4, as it provides clear guidance for improvement but could be more comprehensive with additional context or suggestions. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the term \"hyperspectral\" is confusing and provides a clear explanation of what hyperspectral imaging is. This feedback is direct and actionable, as it instructs the authors to avoid using the term \"hyperspectral\" and instead use \"hyperspectral imaging,\" which is the correct terminology. The comment provides a concrete action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the term \"hyperspectral,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the term \"hyperspectral\" and provides a correct definition of \"hyperspectral imaging.\" This level of detail guides the authors on what needs to be corrected, making the comment 5.", "verifiability_rationale": "The review point claims that the term \"hyperspectral\" is confusing and provides a definition of hyperspectral imaging. This claim is 5 as it is supported by a clear explanation of what hyperspectral imaging is and why the term \"hyperspectral\" might be confusing. The comment provides a logical reasoning and a precise definition, making it easy for the authors to understand and address the issue. Therefore, the comment is categorized as 5.", "helpfulness_rationale": "The review comment identifies a specific terminology issue, clarifying that the term \"hyperspectral\" is confusing and provides a correct definition of \"hyperspectral imaging.\" This feedback is actionable and helpful as it guides the authors to use the correct terminology, which can improve the clarity and accuracy of their paper. However, the comment could be more helpful if it also suggested alternative ways to describe the imaging technique or provided context on why the terminology is important. Overall, the comment is 4 as it directs the authors to a clear improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide more detailed ablation studies to demonstrate how each component contributes to the final performance improvements. It specifically mentions the need to explain how the performance of combining the Linformer and the window attention in Big Bird is achieved. While the comment implies that the authors should conduct additional analyses, it does not provide explicit instructions on how to implement these analyses or what specific metrics to focus on. The action is implicit and somewhat vague, as the authors can infer the need for more detailed ablation studies but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions sections 3 and 4, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the authors should provide more detailed ablation studies to demonstrate how each component contributes to the final performance improvements. The comment provides a specific example of how the performance of combining the Linformer and the window attention in Big Bird could be analyzed. This level of detail makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the ablation studies in Sections 3 and 4 could be improved by providing more detailed explanations of how each component contributes to the final performance improvements. The reviewer provides a specific example of how the performance of combining the Linformer and the window attention in Big Bird could be analyzed. This level of detail and suggestion makes the claim 4, as it offers a clear direction for improvement. However, the comment could be strengthened by referencing similar studies or providing additional examples to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors should provide more detailed ablation studies to demonstrate how each component contributes to the final performance improvements. It specifically mentions the need to explain how the performance of combining the Linformer and the window attention in Big Bird is achieved. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the paper\"s analysis and clarity. However, the comment could be more helpful if it offered additional guidance on how to conduct these ablation studies or what specific metrics to focus on. Overall, the comment is 4 as it directs the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the role of visual information in the paper and questions the effectiveness of the ablation study. It points out that the performance of the model without the perception module is similar to the model with the perception module, and the implementation detail of the model without perception is unknown. Additionally, it suggests that the improvements are not significant given the sample size of 1000 users. While the comment identifies areas of concern, it does not provide explicit guidance on how to address these issues or improve the draft. The authors are left with a general understanding of what needs to be clarified or improved but without concrete steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 10,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the ablation study, questioning the effectiveness of the visual information and the implementation detail of the model without perception. The comment further critiques the experiment results, suggesting that the improvements are not significant given the sample size. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point claims that the role of visual information is unknown and questions the effectiveness of the ablation study. It provides specific examples from Table 10, where the performance of the model without the perception module is similar to the model with the perception module, and the implementation detail of the model without perception is unknown. Additionally, the comment suggests that the improvements are not significant given the sample size of 1000 users. This reasoning is 4 as it provides specific examples and logical arguments to support the claim. However, the comment could be strengthened by referencing similar studies or providing more detailed analysis of the sample size and its impact on significance. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper, specifically questioning the role of visual information and the effectiveness of the ablation study. It points out that the performance of the model without the perception module is similar to the model with the perception module, and the implementation detail of the model without perception is unknown. Additionally, the comment raises concerns about the significance of the improvements given the sample size of 1000 users. This feedback is clear and actionable, as it highlights specific areas that need clarification or further investigation, such as the role of visual information and the robustness of the results. However, the comment could be more helpful if it provided suggestions on how to address these issues or improve the study. Overall, the comment is 4, as it effectively guides the authors toward improving their draft by identifying key areas of concern."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a lack of clarity in the notation for results, specifically questioning the meaning of \"%p\" in the claim of a 3%p improvement for CIFAR10. While the comment identifies a specific issue with the notation, it does not provide explicit guidance on how to address it or suggest alternative ways to present the results. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the notation but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue with the notation for results, specifically questioning the meaning of \"%p\" in the claim of a 3%p improvement for CIFAR10. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue with the notation, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the notation for results is unclear, specifically questioning the meaning of \"%p\" in the claim of a 3%p improvement for CIFAR10. This is a factual statement that requires no verification, as it is a direct observation about the clarity of the notation. The comment does not contain subjective opinions, suggestions, or judgments that would require justification or evidence. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the notation used in the results section, specifically questioning the meaning of \"%p\" in the claim of a 3%p improvement for CIFAR10. This feedback is clear and actionable, as it directs the authors to clarify the notation used in their results to ensure that readers understand the reported improvements. However, the comment could be more helpful if it provided suggestions on how to improve the clarity of the notation or offered examples of how to present the results more effectively. Despite this, the comment is 4 as it highlights a critical area for improvement and guides the authors toward enhancing the clarity of their results presentation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point identifies an incorrect assertion made by the authors regarding the Central Limit Theorem (CLT) on line 238. It clarifies that the CLT does not guarantee Gaussianity in a nonasymptotic regime and does not hold for a finite linear combination of arbitrary random variables. However, the comment does not provide explicit guidance on how the authors should correct this assertion or what specific changes should be made to the draft. The action is implicit and somewhat vague, as the authors can infer that they need to revise their statement, but they are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 238,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the authors\" claim about the Central Limit Theorem (CLT), pointing out that it makes multiple incorrect assertions. The comment provides a detailed explanation of why the claim is incorrect, which helps the authors understand what needs to be revised. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors\" statement regarding the Central Limit Theorem (CLT) is incorrect. It provides a detailed explanation of why the claim is invalid, specifically noting that the CLT does not guarantee Gaussianity in a nonasymptotic regime and does not hold for a finite linear combination of arbitrary random variables. This reasoning is clear and logical, providing a robust basis for the claim. Therefore, the comment is 5.", "helpfulness_rationale": "The review comment identifies a specific issue with the authors\" claim regarding the Central Limit Theorem (CLT) on line 238. It points out that the statement is incorrect, as the CLT does not guarantee Gaussianity in a nonasymptotic regime and does not hold for a finite linear combination of arbitrary random variables. This feedback is clear and actionable, as it provides the authors with a precise correction to their claim, which is crucial for the accuracy and validity of their work. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided additional context or references to support the correction. Overall, the comment is 4, as it effectively directs the authors to a critical error in their draft and guides them toward a more accurate understanding of the CLT."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to analyze the time complexity of the proposed policies mentioned in Section 4. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific task that needs to be addressed, making it 5. The authors know exactly what needs to be done to enhance their paper, and the feedback is concrete in its guidance. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. This provides full grounding. However, the comment lacks specificity as it does not detail what aspects of the time complexity analysis are required or how it should be conducted. The authors are given a general direction but not specific guidance on what needs to be addressed. Therefore, this comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point is a request for additional analysis, specifically asking for the time complexity of the proposed policies to be analyzed. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification or additional information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area for improvement by requesting an analysis of the time complexity of the proposed policies mentioned in Section 4. This feedback is clear and actionable, as it provides a direct suggestion for enhancing the paper by addressing a critical aspect of the methodology. However, the comment could be more helpful if it included guidance on how to conduct this analysis or what specific aspects of time complexity should be considered. Despite this, the feedback is 4 as it directs the authors to a meaningful improvement that could strengthen their work. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the use of an automatic metric (TSS) instead of a human metric for evaluating style control in the human evaluation. It suggests that this choice weakens the convincingness of the human evaluation. While the comment highlights a potential issue, it does not provide explicit guidance on what the authors should do to address this concern. The action is implicit, as the authors need to infer that they should consider using a human metric for evaluation. Additionally, the comment lacks concrete details on how to implement this change or what specific human metric to use. Therefore, the comment is 3, as it points out an issue but does not provide clear steps for resolution.", "grounding_specificity_rationale": "The comment questions the use of an automatic metric (TSS) instead of a human metric for evaluating style control in the human evaluation. However, it does not specify which part of the paper discusses the human evaluation or where the use of TSS is mentioned. This makes it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the evaluation method but lacks grounding, as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the use of an automatic metric (TSS) instead of a human metric for evaluating style control in the human evaluation. The reviewer claims that this choice weakens the convincingness of the human evaluation. However, the comment lacks specific reasoning or examples to support why a human metric would be more appropriate or how the use of TSS affects the evaluation. Without detailed justification or references, the claim remains 3, as the authors would need to infer the reasoning behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the choice of using an automatic metric (TSS) instead of a human metric for evaluating style control in the human evaluation. It highlights a potential weakness in the evaluation methodology, suggesting that the use of an automatic metric may weaken the convincingness of the human evaluation. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or what alternative human metrics could be considered. While it identifies a potential problem, it lacks actionable advice, making it 3. The authors are given some insight into a possible weakness but are not fully supported in improving their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that including experiments across more diverse domains would strengthen the paper. While the comment implies that the authors should expand their experiments, it does not provide specific guidance on which domains to consider or how to conduct these experiments. The action is implicit and somewhat vague, as the authors need to infer that they should expand their experiments and determine the specific domains themselves. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that including experiments across more diverse domains would strengthen the paper. However, it does not specify which part of the paper the current experiments are located in, nor does it provide details on which specific domains should be considered. This makes it difficult for the authors to pinpoint the exact sections that need revision. The comment is specific in suggesting the need for more diverse experiments, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments \"succinctly prove the point that the authors try to make\" and suggests that including experiments across more diverse domains would strengthen the paper. However, the comment does not provide any specific examples, reasoning, or references to support why the current experiments are insufficient or how including diverse domains would enhance the paper. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges that the experiments successfully prove the authors\" point but suggests that including experiments across more diverse domains would strengthen the paper. This feedback is 3 as it identifies a potential area for improvement by suggesting a broader scope of experiments. However, the comment lacks specific guidance on which domains to consider or how to conduct these additional experiments, leaving the authors with a general direction but not a detailed plan for enhancement. Therefore, the comment is rated as 3, as it provides some insight but does not fully support the authors in making significant improvements to their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point acknowledges that the LUQ is straightforward to design once the goal is clear and that the approaches in Section 5 are standard and explored in previous literature. The reviewer suggests that the main contribution of the paper is demonstrating that a simple combination of existing techniques can achieve surprisingly good accuracy. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might enhance their contribution or improve the draft. Without actionable suggestions or feedback, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the design of the LUQ and the approaches in Section 5, suggesting that they are straightforward and standard. However, it does not specify which part of the paper discusses the LUQ or the approaches in Section 5, making it weakly grounded. The comment is specific in its critique of the contribution, suggesting that the main contribution is showing the effectiveness of existing techniques rather than proposing novel ones. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the LUQ is straightforward to design and that the approaches in Section 5 are standard and explored in previous literature. The reviewer suggests that the main contribution of the paper is demonstrating the effectiveness of existing techniques rather than proposing novel ones. However, the comment lacks specific references or examples to support the claim that the approaches are standard or explored in previous literature. This makes it difficult for the authors to fully understand and address the critique. Therefore, the comment is considered 2, as it provides some justification but lacks detailed evidence or references.", "helpfulness_rationale": "The review comment acknowledges that the LUQ is straightforward to design once the goal is clear and that the approaches in Section 5 are standard and explored in previous literature. It suggests that the main contribution of the paper is demonstrating the effectiveness of existing techniques rather than proposing novel ones. While the comment provides some insight into the paper\"s contribution, it lacks actionable feedback or suggestions for improvement. It does not offer guidance on how the authors might enhance their work or address the critique, leaving the authors with limited direction for improving their draft. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the training of RegMixup, suggesting that it sees 2x samples per iteration, which could lead to unfair comparisons with other methods. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific actions to improve the fairness of the comparison. The feedback is implicit and lacks concrete details on how to resolve the problem, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"RegMixup,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of the training process seeing 2x samples per iteration, which could lead to unfair comparisons with other methods. The comment provides a clear explanation of the problem, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the training of RegMixup sees 2x samples per iteration, which could lead to unfair comparisons with other methods. However, the comment does not provide any supporting evidence, such as specific examples or references to other methods, to substantiate this claim. The lack of detailed reasoning or references makes it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the training process of RegMixup, suggesting that it sees 2x samples per iteration, which could lead to unfair comparisons with other methods. This is a relevant observation that could impact the validity of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the fairness of the comparisons. While it highlights a potential problem, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about relaxing the need to visit all ballaction pairs with each iteration, suggesting that the authors consider making minimal assumptions or partially covering them. While the comment implies that the authors should explore these possibilities, it does not provide explicit instructions or concrete steps on how to implement these ideas. The action is implicit and somewhat vague, as the authors need to infer that they should consider these options and determine how to address them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it directly addresses the previous remark about relaxing the need to visit all ballaction pairs with each iteration. This allows the authors to accurately identify the part of the paper being discussed. However, the comment is underspecific because it does not provide detailed guidance on what assumptions or partial coverage could be considered or how they might impact the analysis. The authors are given a general direction but lack specific instructions on how to address the issue. Therefore, this comment is 4, aligning with category 4.", "verifiability_rationale": "The review point is a question seeking clarification on how to relax the need to visit all ballaction pairs with each iteration. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information or clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment builds upon a previous remark by asking for clarification on how to relax the need to visit all ballaction pairs with each iteration. It suggests exploring minimal assumptions or partial coverage as potential solutions. While the comment provides a direction for further exploration, it lacks specific guidance or detailed suggestions on how to implement these ideas. The authors are given a general prompt to consider alternative approaches, but the feedback could be more actionable with additional details or examples. Therefore, the comment is 3, as it offers a starting point for further investigation but does not fully guide the authors in making significant improvements to their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should include more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of their proposed technique to tasks with different levels of reasoning requirements. While the comment implies that the authors should expand their dataset selection, it does not provide specific guidance on which datasets to include or how to incorporate them into the study. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the suggestion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests including more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of the proposed technique. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. The authors can infer that it relates to the experimental setup or results, but the lack of explicit grounding makes it difficult to pinpoint the exact part of the paper being addressed. The comment is specific in suggesting the inclusion of additional datasets, but without clear grounding, it aligns with a 3 label.", "verifiability_rationale": "The review point suggests that the authors should include more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of their proposed technique. However, the comment does not provide any reasoning, examples, or references to support why these specific datasets are necessary or how they would contribute to the study. Without additional context or justification, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the authors should include more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of their proposed technique. This feedback is 3 as it identifies a potential area for improvement by suggesting additional datasets that could enhance the study\"s scope and applicability. However, the comment lacks specific guidance on which datasets to include or how to integrate them into the existing experimental setup. While it provides a direction for expansion, it does not offer detailed actionable steps, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the choice of baseline methods could be improved, particularly for evaluating the appearance decomposition part. It provides specific examples of baseline methods that could be used, such as RefNeRF and MipNerf, for different scenarios. This feedback is clear and provides concrete guidance on how to enhance the evaluation by including additional baselines. The authors know exactly what needs to be done to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"baseline methods\" and the \"appearance decomposition part,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear suggestions for improving the choice of baselines, recommending specific methods like RefNeRF and MipNerf for different scenarios. This level of detail guides the authors on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point suggests that the choice of baseline methods could be improved, particularly for evaluating the appearance decomposition part. It provides specific examples of baseline methods that could be used, such as RefNeRF and MipNerf, for different scenarios. This level of detail and the inclusion of references to existing methods provide a clear and logical basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples for why these specific baselines are relevant and how they would enhance the evaluation. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting improvements to the choice of baseline methods for evaluating the appearance decomposition part of the paper. It recommends comparing to existing methods like RefNeRF and MipNerf, which are relevant to the specific scenarios discussed. This guidance is clear and offers a concrete way for the authors to enhance the evaluation of their work, making the comment 4. However, it could be more comprehensive by explaining why these specific baselines are important or how they would contribute to the evaluation. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the biggest concern during reading is the lack of implementation details of the proposed methods, which should have been described in Section 4.1. This provides a clear and direct action for the authors to take, which is to include the implementation details in the specified section. The comment is explicit and concrete, as it specifies exactly what needs to be done to address the concern. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of implementation details of the proposed methods. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the biggest concern during reading is the lack of implementation details of the proposed methods. It suggests that these details should have been described in Section 4.1. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the missing details. Without detailed justification or examples, the claim remains somewhat vague, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the lack of implementation details of the proposed methods. It suggests that these details should have been included in Section 4.1, which is dedicated to implementation details. This feedback is clear and actionable, as it directs the authors to a specific section where they can address the issue. By providing this guidance, the comment is 4, as it empowers the authors to make a targeted improvement to their draft. However, it could be more helpful if it offered suggestions on what specific implementation details should be included or how to present them effectively. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the absence of empirical evaluation and comparison with other methods, which is a significant concern. It also notes the lack of practical value and theoretical argumentation for the contribution. While the comment identifies the need for empirical evaluation and comparison, it does not provide specific guidance on how to address these issues or what aspects should be evaluated. The authors are left with a general understanding of what needs to be improved but without concrete steps to take. Therefore, the comment is 3, as it highlights important areas for improvement but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment addresses the lack of empirical evaluation, comparison with other methods, and the absence of a theoretical argument for the contribution\"s practical value. However, it does not specify which sections of the paper these issues pertain to, making it weakly grounded. The comment is specific in detailing what is missing, such as empirical evaluation and comparison with other methods, as well as the need for a theoretical argument for practical value. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks empirical evaluation, comparison with other methods, and a theoretical argument for the contribution\"s practical value. However, it does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The comment suggests that the theoretical contributions may be significant but does not elaborate on how this could be demonstrated. Without detailed justification or examples, the claim remains 3, as it lacks the necessary evidence to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies several critical weaknesses in the paper, including the lack of empirical evaluation, comparison with other methods, and a theoretical argument for the contribution\"s practical value. It highlights the importance of these elements, especially in the context of a conference like NeurIPS, where practical relevance is often a key consideration. However, the comment does not provide specific suggestions or guidance on how the authors might address these issues, such as recommending specific metrics for evaluation or suggesting potential comparisons. While it points out important areas for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight into the paper\"s weaknesses but lacks detailed guidance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation of the paper, noting that while the method discussed can be applied in general MDPs, it is primarily focused on navigation problems. It suggests that combining RL and planning has already been discussed in PRMRL~1 and asks whether such algorithms can be applied to more general tasks. However, the comment does not provide explicit guidance or suggestions on how the authors should address this limitation or explore the application to more general tasks. The action is implicit and vague, as it lacks concrete steps or details on how to implement the suggested exploration. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a limitation of the paper, noting that while the method discussed can be applied in general MDPs, it is primarily focused on navigation problems. It suggests that combining RL and planning has already been discussed in PRMRL~1 and asks whether such algorithms can be applied to more general tasks. However, the comment does not specify which part of the paper discusses the method or where the limitation is mentioned, making it weakly grounded. The comment is specific in suggesting a potential direction for further exploration, but it lacks detailed guidance on how to address the limitation or expand the application. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the method discussed in the paper can be applied in general MDPs but is limited to navigation problems. It suggests that combining RL and planning has already been discussed in PRMRL~1 and asks whether such algorithms can be applied to more general tasks. However, the comment lacks specific examples or detailed reasoning to support the claim that the method is limited to navigation problems. The reference to PRMRL~1 is not sufficient to substantiate the claim, as it does not provide a direct comparison or analysis of the limitations. Therefore, the comment is considered 2, as it provides some support but lacks detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, noting that while the method discussed can be applied in general MDPs, it is primarily focused on navigation problems. It suggests that combining RL and planning has already been discussed in PRMRL~1 and asks whether such algorithms can be applied to more general tasks. This feedback is 3 as it points out a specific area for potential expansion or exploration, encouraging the authors to consider broader applications of their method. However, the comment lacks detailed guidance or suggestions on how to address this limitation or expand the application, which would make it more actionable. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the suitability of feature spaces for 1NN classification and suggests that feature dimensions should be individually standardized to avoid potential issues. While the comment identifies a potential problem and provides a solution, it does not explicitly instruct the authors to make these changes. The action is implicit and somewhat vague, as the authors need to infer that they should address the issue by standardizing feature dimensions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 213,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the feature spaces and suggests a potential solution by recommending individual standardization of feature dimensions. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the suitability of feature spaces for 1NN classification and suggests that feature dimensions should be individually standardized to avoid potential issues. The comment provides a logical reasoning by explaining that feature spaces that are not close to a spherical Gaussian may perform poorly. This reasoning is based on a common understanding of the properties of 1NN classification and the potential impact of feature space characteristics. However, the comment does not provide specific examples or references to support the claim, which would strengthen the argument. Therefore, the comment is 3, as it provides a logical basis but lacks detailed evidence or references.", "helpfulness_rationale": "The review comment identifies a potential issue with the suitability of feature spaces for 1NN classification, specifically mentioning that feature spaces that are not close to a spherical Gaussian may perform poorly. It provides a suggestion to address this issue by standardizing feature dimensions individually. This feedback is clear and actionable, offering the authors a specific direction to improve their draft by considering the impact of feature space characteristics on classification performance. However, the comment could be more helpful if it provided additional context or examples to further clarify the issue. Overall, the comment is 4 as it provides valuable guidance for enhancing the paper."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment provides explicit feedback on specific lines in section 3.1, pointing out that the statement \"Then the state changes and environment gives a reward\" is not true of standard MDP formulations. It also notes that it is unclear whether each action is a single feature or the power set. The comment suggests making the description more clear, which is a direct and concrete action for the authors to take. The feedback is clear and actionable, as it specifies exactly what needs to be addressed and how to improve the clarity of the description. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in section 3.1, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out that the statement \"Then the state changes and environment gives a reward\" is not true of standard MDP formulations and suggests making the description more clear regarding whether each action is a single feature or the power set. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point claims that the statement \"Then the state changes and environment gives a reward\" is not true of standard MDP formulations and suggests that it may be misleading. The reviewer provides a logical reasoning by stating that in standard MDPs, rewards are not necessarily given after each action. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened by referencing specific MDP formulations or providing examples to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by pointing out a potential misunderstanding in the description of the MDP formulation. It highlights that the statement \"Then the state changes and environment gives a reward\" is not true of standard MDP formulations, as rewards are not necessarily given after each action. Additionally, it notes that it is unclear whether each action is a single feature or the power set, suggesting that the description could be made more clear. This feedback is clear and actionable, guiding the authors to clarify their description and ensure accuracy in their presentation of the MDP formulation. Therefore, the comment is rated as 5, as it offers detailed and constructive suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that other baselines, such as those discussed in related work 29, 5, 6, should also be included. It implies that the authors should consider adding these baselines to their study. However, the comment does not provide explicit guidance on which specific baselines to include or how to integrate them into the paper. While the action is implicit, it is somewhat vague as it lacks concrete details on how to implement the suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including other baselines, such as those discussed in related work 29, 5, 6, and implies that this would enhance the paper. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting the inclusion of additional baselines, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that other baselines should be included, referencing specific works from the related work section. The reviewer acknowledges that the authors have addressed their concerns in the response, which is a positive step. However, the comment lacks specific reasoning or examples to support why these additional baselines are necessary or how they would enhance the paper. This makes the claim 3, as it provides some justification but lacks detailed evidence or references to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that including other baselines, such as those discussed in related work, would enhance the paper. It acknowledges that the authors have addressed the reviewer\"s concerns in their response, which is a positive step. However, the comment could be more helpful if it provided specific examples of additional baselines or detailed guidance on how to integrate them into the paper. While it identifies a potential area for improvement, the feedback lacks depth and actionable suggestions, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a specific issue with the use of the phrase \"to meet\" in the paper, noting that it is difficult to understand. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion on whether the phrase should be rephrased, removed, or clarified. Without actionable advice or concrete steps, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific line number (\"line 280\") where the issue with the phrase \"to meet\" is observed. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue with the phrase \"to meet,\" indicating that it is difficult to understand. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the phrase \"to meet\" is difficult to understand, specifically mentioning its use on line 280. However, the comment does not provide any further explanation or context to support why this phrase is problematic or how it could be improved. Without additional details or examples, the claim lacks sufficient justification, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the use of the phrase \"to meet\" in the paper, noting that it is difficult to understand. However, it does not provide any suggestions or guidance on how to address this issue or improve the clarity of the text. Without actionable feedback or examples of how to rephrase or clarify the language, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, as it points out a potential issue but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about other limitations of the method, specifically asking if the network is shallow in the graph case. This implies that the authors should consider discussing additional limitations beyond the shallow network issue. However, the comment does not provide explicit guidance on how to address this question or what specific limitations should be discussed. The action is implicit and somewhat vague, as the authors need to infer that they should expand on limitations and potentially address the shallow network issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about other limitations of the method, specifically asking if the network is shallow in the graph case. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for additional information on limitations, but without clear grounding, the authors may struggle to determine where to address this point. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question seeking clarification on other limitations of the method, specifically asking if the network is shallow in the graph case. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about other limitations of the method, specifically asking if the network is shallow in the graph case. While it identifies a potential area for improvement, it lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or explore other limitations. The comment is 3 as it prompts the authors to consider additional limitations, but it does not offer actionable advice or detailed feedback on how to enhance the draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the work would be more convincing if it was also evaluated in machine translation, which exhibits lower uncertainties per word. While the comment implies that the authors should consider evaluating their method in machine translation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement this evaluation or what aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"answer generation and summarization,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the work would be more convincing if it were evaluated in machine translation, which exhibits lower uncertainties per word. This provides clear guidance on what the authors need to address to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the work would be more convincing if it were evaluated in machine translation, which exhibits lower uncertainties per word. The reviewer provides a logical reasoning by contrasting the tasks used in the evaluation (answer generation and summarization) with machine translation, suggesting that the latter is closer to \"open domain\" generation. However, the comment lacks specific examples or references to support the claim that machine translation is a more appropriate evaluation task. This makes the claim 3, as it provides a logical basis but requires further elaboration or evidence to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential limitation in the evaluation of the proposed method, noting that it only uses answer generation and summarization tasks, which are closer to \"open domain\" generation rather than \"close domain\" generation like machine translation. The reviewer suggests that the work would be more convincing if it were also evaluated in machine translation, which exhibits lower uncertainties per word. This feedback is clear and actionable, as it provides a specific suggestion for improving the evaluation of the method. However, it could be more helpful if it offered additional guidance on how to conduct the machine translation evaluation or what specific aspects to focus on. Overall, the comment is 4, as it directs the authors to a potential area for improvement but could be more comprehensive with further guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the dropout process, specifically asking for clarification on the dropping rate and the number of masks generated. While the comment does not explicitly instruct the authors to provide this information, it implies that the authors should address these questions by including the requested details in their response. The action is implicit but concrete, as the authors know exactly what information is needed to clarify the dropout process. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the reading of the response letter,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for clarification on the dropping rate and the number of masks generated in the dropout process. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification on the dropout process, specifically asking for the dropping rate and the number of masks generated. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises specific questions about the dropout process, seeking clarification on the dropping rate and the number of masks generated. While it identifies a gap in the explanation of the dropout method, it does not provide suggestions or guidance on how to address these questions or improve the clarity of the paper. The comment is 3 as it points out an area that needs further elaboration, but it lacks actionable advice or detailed feedback that would empower the authors to make significant improvements. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the effectiveness of the proposed twostage optimization approach needs further justification. It suggests that showing the performance drop on fusion models is not sufficient and that comparisons with other singlestage attacks are needed to demonstrate effectiveness. The comment also highlights the importance of proper benchmarks and comparisons with other stateoftheart (SOTA) algorithms to justify the technical contributions. This feedback provides clear and concrete actions for the authors to take, such as conducting additional comparisons and benchmarks, which makes the comment 5.", "grounding_specificity_rationale": "The comment addresses the effectiveness of the proposed twostage optimization approach, specifically mentioning the need for further justification and comparisons with other singlestage attacks. However, it does not specify which part of the paper discusses the twostage optimization approach, making it weakly grounded. The comment is specific in detailing what is missing, such as comparisons with other SOTA algorithms and benchmarks, which would help justify the effectiveness of the technical contributions. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the effectiveness of the proposed twostage optimization approach needs further justification. It argues that showing the performance drop on fusion models is not sufficient and suggests that comparisons with other singlestage attacks are needed. The comment also highlights the importance of proper benchmarks and comparisons with other stateoftheart (SOTA) algorithms to justify the technical contributions. While the comment provides a logical reasoning for the need for additional comparisons, it lacks specific examples or references to other SOTA algorithms or benchmarks, which would strengthen the argument. Therefore, the claim is 3, as it provides a clear direction for improvement but lacks detailed evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a critical area for improvement in the paper, specifically the need for further justification of the effectiveness of the proposed twostage optimization approach. It points out that merely showing the performance drop on fusion models is insufficient and suggests that comparisons with other singlestage attacks are necessary to demonstrate the approach\"s effectiveness. Additionally, the comment highlights the importance of proper benchmarks and comparisons with other stateoftheart (SOTA) algorithms to justify the technical contributions. This feedback is clear and actionable, providing the authors with specific directions to enhance the justification and credibility of their work. However, it could be more helpful if it included suggestions on how to conduct these comparisons or benchmarks. Overall, the comment is 4, as it effectively guides the authors toward improving the robustness and clarity of their technical contributions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a specific sentence that is confusing and suggests that the authors reread it to understand its meaning. While the comment identifies a potential issue, it does not provide explicit guidance on how to clarify the sentence or improve its clarity. The action is implicit and somewhat vague, as the authors are left to infer that they need to revise the sentence for better clarity. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific sentence range (9395) that is confusing, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the confusion regarding the sentence and suggesting that it is not immediately clear what is meant. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that a specific sentence is confusing and suggests that the reviewer had to reread it to understand it. However, the comment does not provide any reasoning or examples to support why the sentence is confusing or how it could be clarified. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to address the issue effectively. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific sentence in the paper (lines 9395) that is confusing and suggests that the authors reread it to understand its meaning. While the comment highlights a potential issue, it does not provide specific guidance or suggestions on how to clarify the sentence or improve its clarity. The feedback is 3 as it points out a specific area that needs attention, but it lacks depth and actionable advice, leaving the authors with only a general direction for improvement. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out an inconsistency between Figures 1 and 2, specifically noting that Figure 2 shows one encoderdecoder per auxiliary task, while Figure 1 shows a single shared encoderdecoder for multiple tasks. This feedback is explicit and provides a clear action for the authors to take: reconcile the inconsistency between the figures. The comment is also concrete, as it specifies the exact issue and guides the authors on how to address it. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig 1\" and \"Fig 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the inconsistency between the figures, noting that Figure 2 shows one encoderdecoder per auxiliary task, while Figure 1 shows a single shared encoderdecoder for multiple tasks. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 1 is inconsistent with Figure 2, specifically noting that Figure 2 shows one encoderdecoder per auxiliary task, while Figure 1 shows a single shared encoderdecoder for multiple tasks. This claim is based on a direct observation of the figures, which is a factual statement. However, the comment does not provide any additional reasoning or context to support why this inconsistency is significant or how it affects the paper\"s conclusions. Therefore, the claim is 3, as it requires further explanation or examples to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a specific inconsistency between Figures 1 and 2, noting that Figure 2 shows one encoderdecoder per auxiliary task, while Figure 1 shows a single shared encoderdecoder for multiple tasks. This feedback is clear and actionable, as it points out a discrepancy that the authors need to address to ensure consistency and clarity in their figures. By highlighting this issue, the comment provides the authors with a direct path to improve the presentation of their work. However, it could be more helpful if it included suggestions on how to reconcile the inconsistency or why it matters. Overall, the comment is 4, as it effectively guides the authors toward improving the clarity and accuracy of their figures."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether each node can attend to its own lowerlevel representation, suggesting that it may only attend to neighboring nodes based on the description of N_l^(s) in equation 2. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this question or clarify the issue, leaving the authors without a clear understanding of what steps to take to improve their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises a question about whether each node can attend to its own lowerlevel representation, based on the description of N_l^(s) in equation 2. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its question about the attention mechanism, but without explicit references to sections or equations, the authors may struggle to pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about whether each node can attend to its own lowerlevel representation, based on the description of N_l^(s) in equation 2. This is a claim that requires verification, as it suggests a limitation or misunderstanding in the paper. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim. Without additional context or explanation, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the attention mechanism in the paper, specifically whether each node can attend to its own lowerlevel representation. It references equation 2 and the description of N_l^(s) to support the question. While the comment identifies a potential area of confusion or misunderstanding, it does not provide specific guidance or suggestions on how the authors might clarify or address this issue. The feedback is 3 as it prompts the authors to reconsider their explanation of the attention mechanism, but it lacks actionable advice or detailed suggestions for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly requests clarification on how the inequality after line 433 follows from Lemma 7. It suggests that the authors should facilitate the reading by stating how Lemma 7 is used in this context. This feedback provides a clear and direct action for the authors to take, which is to include an explanation of the connection between Lemma 7 and the subsequent inequality. The comment is explicit and provides concrete guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 433\" and \"Lemma 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by questioning the connection between the inequality after line 433 and Lemma 7. The comment suggests that the authors should clarify how Lemma 7 is used to derive the inequality, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the logical connection between an inequality after line 433 and Lemma 7, suggesting that the authors should clarify how Lemma 7 is used to derive the inequality. However, the comment does not provide any specific reasoning or evidence to support why the connection is unclear or how it should be clarified. Without additional context or explanation, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the logical flow of the paper, questioning how an inequality after line 433 follows from Lemma 7. It suggests that the authors should clarify the connection between these elements, which is a valuable observation that could help improve the clarity and coherence of the paper. However, the comment could be more helpful if it provided additional guidance on how to make this connection clearer or offered specific suggestions for restructuring the text. Despite this, the feedback is 3 as it directs the authors to a potential area of improvement, prompting them to enhance the logical structure of their work."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies several issues with the paper, including the lack of clarity in the main contribution and the unclear explanation of how the proposed method copes with dynamic largescale multitasking. It also points out that the automation aspect is unclear. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues. The actions are implicit and somewhat vague, as the authors are left to infer what specific changes are needed to clarify the main contribution and the automation aspect. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the main contribution of the paper, which is unclear, and points out that the proposed method\"s ability or applicability is either overstated or not wellsupported. It also mentions that the main idea of how the proposed method copes with dynamic largescale multitasking is unclear and that the automation aspect is unclear. However, the comment does not specify which sections of the paper these issues pertain to, making it weakly grounded. The comment is specific in detailing what is unclear about the main contribution and the automation aspect. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the main contribution of the paper is unclear and that the proposed method\"s ability or applicability is either overstated or not wellsupported. It also mentions that the main idea of how the proposed method copes with dynamic largescale multitasking is unclear and that the automation aspect is unclear. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of detailed justification or references makes the claim 3, as the authors would need to invest effort to determine the exact issues and address them. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several critical issues with the paper, specifically the lack of clarity in the main contribution and the unclear explanation of how the proposed method copes with dynamic largescale multitasking. It also points out that the automation aspect is unclear. These are important areas that the authors need to address to improve the clarity and impact of their work. However, the comment does not provide specific suggestions or guidance on how to clarify these aspects, such as what additional information or examples could be included to enhance the explanation. While it highlights key areas for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to compare their method to token pruning and token combination baselines, in addition to the BERTbaseline. This provides a clear and direct action for the authors to take, ensuring that their experimental comparison is strengthened. The comment is specific and concrete, as it outlines exactly what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the experiment comparison, specifically mentioning the need to compare the method to token pruning and token combination baselines, in addition to the BERTbaseline. This provides clear guidance on what needs to be addressed in the experimental section. However, the comment does not explicitly mention which part of the paper discusses the experiment comparison, making it weakly grounded. The authors can infer that it relates to the experimental results or methodology sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiment comparison is weak because the authors only compare their method to the BERTbaseline. It suggests that the authors should compare their method to token pruning and token combination baselines. This claim is 3 as it provides a logical reasoning for the need to include additional baselines for a more comprehensive comparison. However, the comment lacks specific examples or references to support why these additional baselines are necessary or how they would enhance the comparison. Providing such details would strengthen the justification for the claim, making it more verifiable. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific weakness in the experimental comparison, noting that the authors only compare their method to the BERTbaseline. It suggests that the authors should include comparisons with token pruning and token combination baselines, which would provide a more comprehensive evaluation of their method. This feedback is clear and actionable, offering a concrete suggestion for improving the experimental section of the paper. By addressing this point, the authors can enhance the robustness and validity of their results. Therefore, the comment is rated as 4, as it provides valuable guidance for improving the draft."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should demonstrate the possible weaknesses of their proposed model. However, it does not provide any explicit guidance or concrete suggestions on how to do so. The action is implicit and vague, as the authors are left to infer that they need to address potential limitations or weaknesses but without specific instructions on how to identify or present them. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the authors should demonstrate the possible weaknesses of their proposed model. However, it does not specify which part of the paper this critique pertains to, nor does it provide details on what specific weaknesses should be addressed. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine where to focus their efforts. Additionally, the comment lacks specificity regarding the nature of the weaknesses that should be demonstrated. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the authors did not demonstrate the possible weaknesses of the proposed model. However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without specific details or references to what weaknesses should have been addressed, the comment lacks verifiability. Therefore, it is rated as 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by noting that the authors have not demonstrated the possible weaknesses of their proposed model. This is a critical area for improvement, as understanding and addressing potential limitations is essential for the robustness and credibility of the work. However, the comment lacks specificity and does not provide actionable guidance on how the authors might identify and address these weaknesses. Without detailed suggestions or examples, the authors are left with a general direction but no clear steps to take. Therefore, the comment is 3, as it highlights an important area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises questions about the novelty and originality of the proposed methodology, specifically asking for comparisons with other extractthengenerate methodologies and questioning the lack of a Related Work section. While the comment implies that the authors should address these issues, it does not provide explicit instructions or concrete suggestions on how to do so. The authors can infer that they need to include a Related Work section and compare their methodology with existing ones, but the comment lacks detailed guidance on how to conduct these comparisons or what specific aspects to focus on. Therefore, the comment is 3, as it identifies areas for improvement but lacks detailed instructions on how to implement them.", "grounding_specificity_rationale": "The comment raises questions about the novelty and originality of the proposed methodology, specifically asking for comparisons with other extractthengenerate methodologies and questioning the lack of a Related Work section. However, it does not specify which part of the paper these concerns relate to, such as a particular section or methodology description. The authors can infer that it pertains to the methodology or related work sections, but this inference is not explicit. The comment is specific in its critique of the lack of comparisons and the absence of a Related Work section, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the novelty and originality of the proposed methodology, specifically asking for comparisons with other extractthengenerate methodologies and questioning the lack of a Related Work section. The comment suggests that the paper lacks context and comparison with existing work, which is a valid concern. However, the comment does not provide specific examples or references to existing work that could be used for comparison, making it 3. The authors would need to conduct their own research to address these concerns, which adds some effort but is not insurmountable. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises important questions about the novelty and originality of the proposed methodology, specifically asking for comparisons with other extractthengenerate methodologies and questioning the lack of a Related Work section. It also points out the absence of experiments with other extractthengenerate methods using the proposed model, which is a significant gap in the paper. While the comment identifies critical areas for improvement, it does not provide specific suggestions or guidance on how the authors might address these issues. The feedback is 3 as it highlights important gaps in the paper, but it could be more actionable with additional guidance or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the need to train multiple models to test the approach and suggests exploring unlabelled data or applying constraints to improve model stability. While the comment implies that the authors should consider these alternatives, it does not provide explicit instructions or concrete steps on how to implement these suggestions. The action is implicit and somewhat vague, as the authors are left to infer the specific changes needed without detailed guidance. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises concerns about the need to train multiple models to test the approach and suggests exploring unlabelled data or applying constraints to improve model stability. However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in suggesting alternative approaches but lacks grounding, as it does not reference any particular part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses a subjective opinion about the need to train multiple models to test the approach, describing it as \"not particularly appealing.\" However, the comment does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this opinion or how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the need to train multiple models to test the approach, describing it as \"not particularly appealing.\" It suggests exploring alternative methods, such as using unlabeled data or applying constraints, to improve model stability. While the comment identifies a potential issue and offers a direction for improvement, it lacks specific guidance or detailed suggestions on how to implement these alternatives. The feedback is 3 as it provides a general direction for exploration, but it could be more actionable with additional details or examples. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the introduction of related work is insufficient and recommends providing more work on GLN to highlight the advantages or differences of the proposed method, such as the difference from BGLN. While the comment implies that the authors should expand the related work section, it does not specify which specific aspects of GLN or BGLN should be discussed or how to present them. The action is implicit and somewhat vague, as the authors are left to infer what additional information should be included and how to structure it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the introduction of related work, specifically mentioning the need for more work on GLN to highlight the advantages or differences of the proposed method, such as the difference from BGLN. However, it does not specify which part of the introduction is insufficient or where the additional work on GLN should be included. The authors can infer that it relates to the related work section, but the comment lacks full grounding as it does not explicitly mention the section. It is specific in suggesting what needs to be addressed, such as highlighting the differences from BGLN. Therefore, this comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the introduction of related work is insufficient and suggests that more work on GLN should be included to highlight the advantages or differences of the proposed method. However, the comment does not provide specific examples or references to support this claim, nor does it explain why the current introduction is insufficient. Without detailed justification or evidence, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the introduction of related work, noting that it is insufficient and suggests that more work on GLN should be included to highlight the advantages or differences of the proposed method. This feedback is 3 as it points out a potential weakness in the paper and provides a direction for improvement by recommending a focus on GLN and its differences from BGLN. However, the comment lacks detailed guidance on how to incorporate this additional work or what specific aspects of GLN should be emphasized. To be more helpful, the comment could include suggestions on how to structure the related work section or provide examples of relevant literature to consider. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the use of hyperparameters in Moon\"s approach, specifically questioning why only one dropout rate is used while Variational dropout has multiple parameters. This comment implies that the authors should provide a justification or explanation for this choice. However, it does not explicitly instruct the authors to do so or offer guidance on how to address the issue. The action is implicit and somewhat vague, as the authors can infer that they need to provide an explanation but are not given specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the use of hyperparameters in Moon\"s approach, specifically questioning why only one dropout rate is used while Variational dropout gets multiple parameters. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its inquiry about the hyperparameters, but it lacks grounding as it does not reference a particular section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point is a question seeking clarification about the use of hyperparameters in Moon\"s approach, specifically regarding the choice of a single dropout rate compared to multiple parameters in Variational dropout. It does not contain an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the use of hyperparameters in Moon\"s approach, specifically questioning why only one dropout rate is used while Variational dropout has multiple parameters. This is a relevant observation that could lead to a deeper understanding of the methodology and its implications. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their explanation. While it identifies a potential area for clarification, it lacks actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should include largerscale experiments with nontrivial dynamics, such as gridworlds with walls and other nontrivial tiles. It also implies that the current experiments may not be sufficient to judge the method\"s scalability. The comment provides a specific suggestion by mentioning videogame domains as a potential area for experimentation, noting that simulators for such experiments are publicly available. This feedback is explicit and provides concrete guidance on how to expand the experiments, making it 5.", "grounding_specificity_rationale": "The comment suggests including largerscale experiments with nontrivial dynamics, such as gridworlds with walls and other nontrivial tiles. It also mentions the need for experiments on videogame domains, which are publicly available. However, the comment does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The authors can infer that it relates to the experimental section, but the lack of explicit reference makes it challenging to pinpoint the exact part of the paper being addressed. The comment is specific in suggesting the types of experiments to include, but without explicit grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the paper should include largerscale experiments with nontrivial dynamics, such as gridworlds with walls and other nontrivial tiles. The reviewer questions whether the lack of such experiments is due to time constraints or a potential scalability issue with the method. The comment provides a specific suggestion for experiments on videogame domains, noting that simulators for such experiments are publicly available. This reasoning is 3 as it offers a logical argument and a specific suggestion for improvement, but it lacks detailed evidence or references to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the experimental setup by suggesting the inclusion of largerscale experiments with nontrivial dynamics, such as gridworlds with walls and other nontrivial tiles. It questions whether the current experiments are sufficient to judge the method\"s scalability and suggests that experiments on videogame domains would be more convincing. The comment provides specific examples and references to publicly available simulators, offering actionable guidance for the authors to enhance their experimental section. This feedback is clear and constructive, making it 5 for the authors to improve their draft. Therefore, the comment is rated as 5."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of quantitative measurement regarding the extent of occupation bias relative to real distributions in society. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what specific measurements could be used. The comment lacks actionable guidance, leaving the authors uncertain about how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue regarding the lack of quantitative measurement of occupation bias relative to real distributions in society. However, it does not specify which part of the paper this critique pertains to, such as a particular section or analysis. Without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area needing revision. The comment is specific in identifying the absence of quantitative measurement but lacks grounding, making it 2. Therefore, this comment aligns with a score of 2.", "verifiability_rationale": "The review point claims that the authors did not propose any quantitative measurement to assess the extent of occupation bias relative to real distributions in society. However, the comment does not provide any supporting evidence, reasoning, or examples to justify this claim. Without specific references or detailed explanations, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks quantitative measurement to assess the extent of occupation bias relative to real distributions in society. This is a relevant observation that could help the authors improve their work by suggesting a potential direction for further analysis or evaluation. However, the comment does not provide specific guidance on how to implement such measurements or what specific metrics could be used. While it highlights an important area for improvement, the lack of actionable suggestions limits its helpfulness. Therefore, the comment is 3, as it provides insight but lacks depth and detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that no information from 2hop neighbors is included, suggesting that this method is simple but unclear in its effectiveness. While the comment implies that the authors should provide more information on the effectiveness of the method, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to explain the effectiveness of the method. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment mentions that \"no information from 2hop neighbors is included,\" which implies that it is referring to a specific method or section of the paper. However, it does not explicitly mention which part of the paper this information is missing from, making it weakly grounded. The comment is specific in pointing out the lack of information from 2hop neighbors and questioning the effectiveness of the method. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that \"no information from 2hop neighbors is included,\" suggesting that this method is simple but unclear in its effectiveness. However, the comment lacks specific examples or detailed reasoning to support why the inclusion of 2hop neighbor information would improve the method\"s effectiveness. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment points out a specific omission in the paper, noting that no information from 2hop neighbors is included. It also questions the effectiveness of the method, suggesting that it is unclear why the method is effective. While the comment identifies a gap in the paper and raises a valid concern, it lacks specific suggestions or guidance on how the authors might address this issue or improve the clarity of the method\"s effectiveness. The feedback is 3 as it directs the authors\" attention to a critical area needing further explanation, but it could be more actionable with additional details or examples. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly recommends using a real DICOM image instead of a PNG image for the experiment data and suggests using the FastMRI challenge dataset. It also advises comparing inference speed between different methods. These actions are clear and provide concrete guidance on how to improve the draft. The authors know exactly what changes to make to enhance their work. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of a real DICOM image instead of a PNG image, which allows the authors to accurately identify the part of the paper being addressed. It also provides specific suggestions, such as recommending the FastMRI challenge dataset and comparing inference speed between different methods. This level of detail and explicit guidance makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point suggests using a real DICOM image instead of a PNG image for the experiment data and recommends the FastMRI challenge dataset. It also advises comparing inference speed between different methods. However, the comment lacks specific reasoning or evidence to support why using a real DICOM image is preferable or how the FastMRI dataset would be beneficial. Without detailed justification or examples, the claim remains 3, as the authors would need to infer the rationale themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by recommending the use of a real DICOM image instead of a PNG image for the experiment data. It also suggests using the FastMRI challenge dataset and comparing inference speed between different methods. This feedback is clear and offers concrete steps for the authors to improve their experimental setup and analysis. By addressing these points, the authors can enhance the validity and comprehensiveness of their study. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point poses a question about what would happen if the original CAD model is already associated with spatiallyvarying (SV) BRDF maps. However, it does not provide any explicit or implicit actions for the authors to take. The question is not phrased as a suggestion or a request for clarification, leaving the authors without any guidance on how to address this issue. As a result, the comment lacks actionability, as it does not offer any direction for improvement or change in the draft. Therefore, it is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment poses a question about a specific scenario involving the original CAD model and SV BRDF maps. However, it does not specify which part of the paper this scenario is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment lacks specificity as it does not provide details on what the authors should consider or address regarding this scenario. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification about a specific scenario involving the original CAD model and SV BRDF maps. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment poses a question about a specific scenario involving the original CAD model and SV BRDF maps. While it highlights a potential area of interest, it does not provide any actionable feedback or suggestions for improvement. The authors are left without guidance on how to address this scenario or what implications it might have for their work. Without specific advice or direction, the comment does not offer much value in helping the authors enhance their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that additional evaluation, particularly on CIFAR10 in the full label and lower label scenarios, would be beneficial. However, it does not provide explicit instructions on how to conduct this evaluation or what specific aspects should be evaluated. The action is implicit and somewhat vague, as the authors can infer that they need to conduct additional evaluations but are not given concrete guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that more evaluation would be welcome, particularly on CIFAR10 in the full label and lower label scenarios. However, it does not specify which part of the paper this evaluation should be added to, making it weakly grounded. The comment is specific in suggesting a particular scenario for evaluation, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area needing improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more evaluation would be welcome, particularly on CIFAR10 in the full label and lower label scenarios. However, it does not provide any specific reasoning or evidence to support why this additional evaluation is necessary or how it would benefit the paper. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that more evaluation would be beneficial, particularly on CIFAR10 in the full label and lower label scenarios. This feedback is 3 as it identifies a specific area where the authors could enhance their work by providing additional evaluation. However, the comment lacks depth and does not offer specific guidance on what aspects of the evaluation should be focused on or how to conduct the additional analysis. While it points out a potential improvement, it does not provide detailed actionable steps, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises questions about the comparability of the results in Table 2, specifically regarding the use of different amounts of data in the comparisons. The reviewer suggests that comparisons should be made using the same amount of data, pointing out specific examples where this is not the case. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern or suggest specific actions to take. The authors can infer that they need to ensure consistency in the data used for comparisons, but the comment lacks concrete details on how to implement this change. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the comparability of the results in Table 2, specifically regarding the use of different amounts of data in the comparisons. The comment provides examples of where this issue arises, such as comparing H>N and H>B with H>N+B, and H>N>H with H>N+B>H. This level of detail helps the authors understand what needs to be addressed in the table. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the comparability of results in Table 2, specifically questioning whether the comparisons are made using the same amount of data. The reviewer provides specific examples, such as comparing H>N and H>B with H>N+B, and H>N>H with H>N+B>H, to illustrate the issue. This level of detail and specific examples provide a clear basis for the claim, making it 4. However, the comment could be strengthened by further explaining why this issue is important or how it affects the interpretation of the results. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises a valid concern about the comparability of results in Table 2, specifically questioning whether the comparisons are made using the same amount of data. It provides specific examples where the data used for comparisons is not consistent, such as comparing H>N and H>B with H>N+B, and H>N>H with H>N+B>H. This feedback is clear and actionable, as it prompts the authors to ensure that their comparisons are made using the same amount of data, which is crucial for accurate analysis and interpretation of results. However, the comment could be more helpful if it suggested ways to address this issue, such as adjusting the experimental setup or providing additional explanations in the text. Overall, the comment is 4 as it identifies a significant issue and provides a clear direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises several issues, including the counterintuitive placement of a section at the end of the paper and questions about the application of Algorithm 1 with different iterations. It also points out a lack of reference to Laplacian eigenmaps and a missing citation in the introduction. While the comment identifies specific areas that need attention, it does not provide explicit instructions on how to address these issues or what changes should be made. The authors can infer that they need to clarify the placement of the section, explain the application of Algorithm 1 with different iterations, and ensure proper references and citations. However, the lack of concrete guidance makes the actions somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines and figures in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it details the issues with the placement of a section, the application of Algorithm 1, the lack of reference to Laplacian eigenmaps, and the missing citation in the introduction. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises several claims, each of which requires verification. The first claim about the counterintuitive placement of a section is not supported by any reasoning or evidence, making it difficult for the authors to understand the basis of the critique. The second claim about the application of Algorithm 1 with different iterations lacks specific examples or references to support the assertion that larger T is not considered. The third claim regarding the lack of reference to Laplacian eigenmaps and its citation in the introduction is 3, as it points out a specific omission that could be addressed. However, the comment does not provide detailed reasoning or references to fully substantiate the claim. Overall, the review point contains a mix of verifiable and 1 claims, making it 3.", "helpfulness_rationale": "The review comment raises several issues that could be addressed to improve the paper. It points out a counterintuitive placement of a section at the end of the paper, which could be confusing for readers. It also questions the application of Algorithm 1 with different iterations and suggests that larger T is not considered, which could be a significant oversight. Additionally, the comment notes the lack of reference to Laplacian eigenmaps and a missing citation in the introduction, which could impact the paper\"s coherence and completeness. While the comment identifies specific areas for improvement, it does not provide detailed guidance on how to address these issues or what specific changes should be made. The feedback is 3 as it highlights important areas for revision, but it could be more actionable with additional suggestions or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the inclusion of Section 2.1, suggesting that Batch Normalization is a general technique and that the description of the proposed methodology could be better used to provide greater motivation and intuition for the proposed Conditional Batch Normalization (CBN) approach. While the comment implies that the authors should reconsider the inclusion of Section 2.1 and focus more on the motivation and intuition for CBN, it does not explicitly instruct the authors to make these changes. The action is implicit and somewhat vague, as the authors need to infer that they should restructure the content to better align with the paper\"s focus. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the section, questioning the inclusion of Batch Normalization as a general technique and suggesting that the time spent describing the ResNet architecture could be better used to provide greater motivation and intuition for the proposed Conditional Batch Normalization (CBN) approach. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the inclusion of Section 2.1, suggesting that Batch Normalization is a general technique and that the description of the proposed methodology could be better used to provide greater motivation and intuition for the proposed Conditional Batch Normalization (CBN) approach. The comment provides a logical reasoning by pointing out that Batch Normalization is a general technique, which implies that the section might not be necessary. However, it lacks specific examples or references to support the claim that the time spent on describing the ResNet architecture could be better utilized. This makes the claim 3, as it provides a logical basis but requires more detailed justification or evidence to be fully convincing.", "helpfulness_rationale": "The review comment questions the inclusion of Section 2.1, suggesting that Batch Normalization is a general technique and that the description of the proposed methodology could be better used to provide greater motivation and intuition for the proposed Conditional Batch Normalization (CBN) approach. It highlights a potential redundancy in the content and offers a constructive suggestion for improving the paper by focusing more on the motivation and intuition for the proposed method. While the comment identifies a specific area for improvement, it could be more helpful if it provided additional guidance on how to restructure the content or what specific aspects of the proposed method should be emphasized. Overall, the comment is 3 as it points out a potential issue and offers a direction for improvement, but it lacks detailed guidance that would make it more actionable."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential issue with the explanation of equation (1), questioning how a dense projection matrix could result in a sparse matrix. The reviewer suggests that multiplying by a dense matrix would not lead to sparsity, implying that the authors should clarify their reasoning. While the comment identifies a specific area of confusion, it does not provide explicit guidance on how to address the issue or clarify the explanation. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional explanation or clarification. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L122\" and \"equation (1),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the logic behind assuming a dense projection matrix resulting in a sparse matrix, providing a clear direction for the authors to clarify their explanation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the logic behind assuming a dense projection matrix resulting in a sparse matrix, suggesting that multiplying by a dense matrix would not lead to sparsity. The comment provides a logical reasoning by questioning the assumption, which is based on common knowledge about matrix multiplication. However, it does not provide specific examples or references to fully substantiate the claim. Therefore, the comment is 3, as it requires additional context or evidence to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the explanation of equation (1), questioning how a dense projection matrix could result in a sparse matrix. It points out a potential logical inconsistency in the authors\" reasoning, which is a valuable observation that could help the authors clarify their explanation. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as proposing alternative explanations or suggesting additional context. While it highlights a critical area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the statement about initialization should be more carefully stated, as initialization plays a role in the context of NGD, which is a discretization of NGF. The reviewer references a specific paper by Kunstner et al. (2019) to support this claim. While the comment implies that the authors should revise their statement on initialization, it does not provide explicit guidance on how to make the statement more accurate or detailed. The reference to the external work is a helpful starting point, but the authors still need to determine how to apply this information to their draft. Therefore, the comment is 3, as it identifies an area for improvement but lacks concrete instructions on how to address it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Initialization,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the statement about initialization should be more carefully stated, particularly in the context of NGD being a discretization of NGF and the role of initialization as a pretraining step. The comment provides a reference to a specific paper by Kunstner et al. (2019), which supports the claim and offers a potential direction for further exploration. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that initialization plays a role in the context of NGD, which is a discretization of NGF. It suggests that initialization should be considered as a pretraining step, and the statement about initialization should be more carefully stated. The comment references a specific paper by Kunstner et al. (2019) to support the claim, which provides a clear and logical basis for the suggestion. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced paper to fully substantiate the claim. Overall, the comment is 4, as it provides a solid foundation for the claim but could benefit from additional elaboration.", "helpfulness_rationale": "The review comment identifies a potential issue with the statement about initialization in the context of NGD, which is a discretization of NGF. It suggests that initialization should be considered as a pretraining step, providing a reference to a specific paper by Kunstner et al. (2019) to support this claim. This feedback is 3 as it points out a specific area for improvement and offers a reference to explore further. However, the comment could be more helpful if it provided more detailed guidance on how to incorporate the pretraining concept into the draft or if it offered additional examples or explanations to clarify the role of initialization. Overall, the comment is 3, as it directs the authors to a potential enhancement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the extraction of named entities from the datasets is unclear and recommends an Englishproofreading to improve the readability of the paper. While the comment implies that the authors should clarify the extraction process, it does not provide specific guidance on how to do so or what aspects of the extraction method need clarification. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to improve the clarity. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the clarity of named entity extraction from datasets and suggests an Englishproofreading to improve readability. However, it does not specify which part of the paper discusses the extraction process, making it weakly grounded. The comment is specific in suggesting an Englishproofreading, but it lacks detailed guidance on what aspects of the extraction process need clarification. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the extraction of named entities from datasets is unclear and suggests an Englishproofreading to improve readability. However, it does not provide any specific examples, reasoning, or references to support the claim about the clarity of the extraction process. The suggestion for an Englishproofreading is a general recommendation without detailed justification or evidence of how it would improve the paper. Therefore, the comment is considered 2, as it lacks sufficient support for the claim about the extraction process and the need for an Englishproofreading.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the clarity of named entity extraction from datasets. It suggests that an Englishproofreading could significantly improve the readability of the paper. While the comment highlights a potential issue, it lacks detailed guidance or suggestions on how to improve the clarity of the extraction process. The feedback is 3 as it points out a specific area for improvement, but it could be more actionable with additional details or examples. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment consists of two parts. The first part, \"for every arm a\" implies there is a single optimistic parameter, but of course it depends on a,\" is a clarification question that does not provide any explicit or implicit action for the authors to take. The second part, \"Why not choose T_0 = m Sqrt(T)? Then the condition becomes B > Sqrt(m) T^(3/4), which improves slightly on what you give,\" suggests an alternative approach to the condition and provides a concrete suggestion for improvement. However, it does not explicitly instruct the authors to make this change. Overall, the comment provides some guidance but lacks explicit instructions, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions line numbers \"L200\" and \"L303,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides a critique of the statement \"for every arm a\" and suggests an alternative approach to the condition by asking \"Why not choose T_0 = m Sqrt(T)?\" This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts: a claim about the implication of \"for every arm a\" and a suggestion for an alternative approach to the condition. The first part is a factual observation, as it describes the implication of the statement \"for every arm a\" and does not require verification. The second part is a suggestion for improvement, which is supported by logical reasoning and a specific alternative approach. However, it lacks references or detailed explanations to fully substantiate the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific critique of the statement \"for every arm a\" and suggests an alternative approach to the condition by asking \"Why not choose T_0 = m Sqrt(T)?\" This feedback is clear and actionable, as it points out a potential improvement in the paper and offers a concrete suggestion for enhancing the analysis. By addressing this critique, the authors can strengthen their argument and potentially improve the overall quality of their work. However, the comment could be more helpful if it explained why the suggested alternative approach is beneficial or how it aligns with the paper\"s objectives. Overall, the comment is 4, as it provides valuable guidance for improvement but could be more comprehensive with additional context or explanation."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a specific issue with the definition of L and E, noting that they should be defined in the immediate vicinity and that their formatting is inconsistent. While the comment identifies a clear action for the authors to take\u2014clarifying the definitions and formatting of L and E\u2014it does not provide detailed guidance on how to implement these changes. The authors know what needs to be done but may not be entirely sure of the exact steps to follow. Therefore, the comment is 4, as it provides a clear direction but lacks detailed instructions.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 296,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the inconsistency in the definition and formatting of L and E, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about the formatting and definition of L and E in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely descriptive and factual, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the formatting and definition of L and E in the paper, noting that they should be defined in the immediate vicinity and that their formatting is inconsistent. This feedback is clear and actionable, as it directs the authors to clarify the definitions and ensure consistent formatting throughout the paper. By addressing these issues, the authors can improve the clarity and readability of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to present these definitions or why they are important. Overall, the comment is 4 as it provides clear guidance for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment indicates that the experimental section is weak and suggests that more experiments are needed. However, it does not provide any specific guidance on what additional experiments should be conducted or how they should be designed. The action is implicit and vague, as the authors are left to infer what specific experiments are necessary without concrete details or examples. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment indicates that the experimental section is weak and suggests that more experiments are needed. However, it does not specify which part of the experimental section is weak or what specific experiments are required. This lack of detail makes it difficult for the authors to pinpoint the exact areas needing improvement. The comment is 1 as it does not identify a specific section or element of the paper, and it is not specific because it lacks detailed guidance on what additional experiments should be conducted. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the experimental section is weak and suggests that more experiments are needed. However, it does not provide any specific reasoning, examples, or references to support this claim. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a weakness in the experimental section, noting that it is \"a little weak\" and suggesting that more experiments are required. However, it lacks specificity and does not provide any guidance on what additional experiments should be conducted or how they might improve the current experimental setup. Without detailed suggestions or examples, the authors are left with a general idea of what needs improvement but without actionable steps to take. This makes the comment 3, as it points out an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and other parameterefficient finetuning techniques beyond LoRA and SPP. While the comment implies that the authors should include additional comparisons, it does not specify which models or techniques should be considered or how to conduct these comparisons. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and other parameterefficient finetuning techniques beyond LoRA and SPP. However, it does not specify which parts of the paper should include these comparisons or which models or techniques should be considered. This lack of specificity and grounding makes it difficult for the authors to identify where and how to address the suggestion. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and other parameterefficient finetuning techniques beyond LoRA and SPP. However, the comment does not provide specific examples or references to support this claim, nor does it explain why these comparisons are necessary or how they would enhance the paper. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and other parameterefficient finetuning techniques beyond LoRA and SPP. This feedback is 3 as it points out a potential area for improvement by encouraging the authors to broaden their comparisons. However, the comment lacks specificity and does not provide guidance on which models or techniques should be considered or how to conduct these comparisons. While it identifies a direction for enhancement, it does not offer detailed actionable steps, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment consists of a series of grammatical corrections and clarifications. Each correction is explicit and provides clear guidance on how to modify the text, making the actions concrete. The authors know exactly what changes to make to improve the clarity and correctness of their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment consists of a series of grammatical corrections and clarifications, each of which is specific and actionable. However, it does not provide any context or grounding for where these corrections are needed in the paper. The authors may have to search through the document to identify the specific lines mentioned, making it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of grammatical corrections and clarifications, which are factual and do not require verification. It does not contain subjective opinions, claims, or suggestions that would necessitate verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a series of grammatical corrections and clarifications, which are important for the clarity and correctness of the manuscript. Each correction is specific and actionable, guiding the authors on how to improve the language and grammar of their paper. However, the comment does not offer any broader insights or suggestions for improving the content or methodology of the paper. While it is helpful in terms of language and grammar, it lacks depth and does not provide comprehensive feedback for enhancing the overall quality of the draft. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the inversion of matrix determination or the division of the number of samples is being referred to. It also mentions a mistake in equations, but it does not specify which equations or what the mistake is. The comment lacks explicit guidance or concrete suggestions on how to address the issue, leaving the authors uncertain about the exact action needed. The action is implicit and vague, making it barely actionable.", "grounding_specificity_rationale": "The comment mentions \"W4 \u2013 Mistakes in Eqs,\" which provides some grounding as it implies that the issue is related to equations in the paper. However, it does not specify which equations are incorrect or what the specific mistake is, making it difficult for the authors to pinpoint the exact part of the paper being addressed. The comment is specific in identifying a potential issue with equations but lacks full grounding because it does not explicitly mention the section or page where the equations are located. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the interpretation of a specific equation, specifically whether it refers to the inversion of a matrix or the division of the number of samples. This is a factual question that does not contain an opinion, claim, or suggestion requiring verification. It is purely descriptive and does not fit the criteria for a claim. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the interpretation of a specific equation, specifically whether it refers to the inversion of a matrix or the division of the number of samples. This is a clear and specific observation that could help the authors clarify a potential misunderstanding in their work. However, the comment does not provide any guidance on how to address this issue or suggest ways to improve the clarity of the equation. While it identifies a potential area for improvement, it lacks actionable feedback or detailed suggestions, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point states that the paper is somewhat incremental and that the developed model is a straightforward extension of the GAN for static images. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the perceived incremental nature of the work or suggestions for improving the model. Without any actionable advice or specific feedback, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the paper is somewhat incremental and that the developed model is a straightforward extension of the GAN for static images. However, it does not specify which part of the paper this assessment is based on, making it difficult for the authors to identify the exact sections that need attention. Additionally, the comment lacks specificity regarding what aspects of the paper are considered incremental or how the model could be improved. Without clear grounding and specificity, the authors are left without a clear understanding of what needs to be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is somewhat incremental and that the developed model is a straightforward extension of the GAN for static images. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, it is difficult for the authors to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper is somewhat incremental, as it is a straightforward extension of the GAN for static images. However, it does not provide any specific feedback or suggestions on how the authors might improve their work or address the perceived incremental nature of the paper. Without actionable advice or constructive criticism, the comment lacks helpfulness, leaving the authors without a clear path for improvement. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the performance of the LDA+LSTM baseline in terms of the topic switch percent metric. While it does not explicitly instruct the authors to conduct a specific analysis or provide detailed guidance on how to address this curiosity, it does imply that the authors should consider evaluating the performance of this baseline. The action is implicit and somewhat vague, as it lacks concrete steps for the authors to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiment section\" and the \"baseline\" that combines LDA and LSTM, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the performance of the baseline in terms of the topic switch percent metric, providing a clear direction for the authors to address. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the performance of a specific baseline in terms of the topic switch percent metric. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the performance of the LDA+LSTM baseline in terms of the topic switch percent metric. This is a clear and actionable suggestion that prompts the authors to consider evaluating the performance of their baseline in a particular aspect. By asking for this information, the comment encourages the authors to provide a more comprehensive analysis of their results, which could enhance the clarity and depth of their findings. However, the comment could be more helpful if it provided additional context or suggestions on how to approach this evaluation. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with further guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the clarity of the motivation for the task and the potential downstream applications or benefits of amodal tracking. It also questions how uncertainty in amodal predictions might be handled or utilized. While the comment identifies areas that need clarification, it does not provide explicit instructions or concrete suggestions on how the authors should address these issues. The authors can infer that they need to provide more detailed explanations and examples, but the comment lacks specific guidance on how to do so. Therefore, the comment is 3, as it highlights important areas for improvement but does not offer detailed steps for execution.", "grounding_specificity_rationale": "The comment addresses the motivation of the task, specifically questioning the clarity of the motivation and the potential downstream applications or benefits of amodal tracking. It also raises concerns about the quality of annotations and the handling of uncertainty in amodal predictions. However, the comment does not explicitly mention which part of the paper discusses the motivation or the potential applications, making it weakly grounded. The authors can infer that it relates to the introduction or motivation sections, but this inference is not as direct as it could be. The comment is specific in detailing what needs to be addressed, such as the motivation and potential applications, as well as the handling of uncertainty. Therefore, the comment is weakly grounded but specific, aligning with the label 3.", "verifiability_rationale": "The review point raises concerns about the clarity of the motivation for the task and the potential downstream applications or benefits of amodal tracking. It questions the quality of annotations due to uncertainty in amodal predictions. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. The absence of concrete evidence or detailed justification makes it difficult for the authors to understand and address the issues raised. Therefore, the comment is considered 2, as it provides some basis for the claims but requires more detailed support to be 5.", "helpfulness_rationale": "The review comment raises important questions about the motivation and potential applications of the task, specifically addressing the challenges of predicting the state of objects when they are totally occluded. It also questions the quality of annotations and the handling of uncertainty in amodal predictions. While the comment identifies critical areas for clarification and improvement, it does not provide specific suggestions or guidance on how the authors might address these issues. The feedback is 3 as it highlights key areas that need further elaboration, but it lacks actionable advice, making it difficult for the authors to make significant improvements to their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of sufficient evidence to support the claim about the synergies between DQD and PPO. It specifically points out that the main paper does not mention the TD3GA algorithm, which is crucial for understanding these synergies. The comment also suggests that the comparison to TD3GA should be central to the study, as it relates to the central claim about using onpolicy RL better fitting the DQD framework. While the comment identifies a specific issue and suggests a comparison that should be included, it does not provide explicit instructions on how to address the issue or conduct the comparison. The action is implicit and somewhat vague, as the authors know they need to provide more evidence and include a comparison to TD3GA, but they are not given detailed guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the claim about the synergies between DQD and PPO, specifically questioning the lack of evidence and mentioning the TD3GA algorithm. However, it does not explicitly mention which part of the paper discusses these synergies or where the TD3GA algorithm is mentioned, if at all. The authors can infer that it relates to the methodology or results sections, but this inference is not straightforward. The comment is specific in pointing out the lack of evidence and the importance of the TD3GA algorithm, but it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the claim about the synergies between DQD and PPO is insufficiently backed up, specifically noting the absence of mention of the TD3GA algorithm in the main paper. The reviewer suggests that the comparison to TD3GA is crucial to understand these synergies. This claim is 3 as it highlights a gap in the paper\"s discussion and suggests a specific comparison that could strengthen the argument. However, the comment lacks detailed reasoning or references to support the claim fully, making it 3. The authors would need to address the gap themselves to fully understand and improve the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the claim about the synergies between DQD and PPO, noting that the main paper does not mention the TD3GA algorithm, which is crucial for understanding these synergies. It also suggests that the comparison to TD3GA should be central to the study, as it relates to the central claim about using onpolicy RL better fitting the DQD framework. This feedback is clear and actionable, as it points out a gap in the paper\"s discussion and provides a specific direction for improvement. By addressing this issue, the authors can strengthen their argument and enhance the comprehensiveness of their work. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the unexpected performance of the treesliced Wasserstein distance compared to the original optimal transport distance, as observed in Sections 6.1 and 6.2. It explicitly asks for an explanation of this phenomenon, providing a clear and direct action for the authors to take. The comment is specific in its request for an explanation, which makes it 5. The authors know exactly what they need to do to address the reviewer\"s concern: provide an explanation for the observed performance difference. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sections 6.1 and 6.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the unexpected performance of the treesliced Wasserstein distance compared to the original optimal transport distance, prompting the authors to explain this observation. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the unexpected performance of the treesliced Wasserstein distance compared to the original optimal transport distance, as observed in Sections 6.1 and 6.2. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is a factual observation seeking clarification, making it a normal statement. Therefore, the label \"No\" is appropriate.", "helpfulness_rationale": "The review comment identifies a surprising observation in the paper, specifically noting that the treesliced Wasserstein distance outperforms the original optimal transport distance in Sections 6.1 and 6.2. It raises a question about the reason for this unexpected performance, which is a relevant and important point for the authors to address. By prompting the authors to explain this phenomenon, the comment provides a clear direction for improvement and encourages the authors to enhance the clarity and understanding of their results. However, the comment could be more helpful if it offered suggestions on how to approach this explanation or provided examples of potential reasons for the observed performance difference. Overall, the comment is 4 as it directs the authors to a critical area needing clarification, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a slight confusion regarding the use of the word \"confident\" in the context of ceterus paribus convexity. It suggests that the author might be referring to human interpretability rather than model confidence, and recommends a slight rephrasing to clarify this point. While the comment identifies a potential issue and suggests a specific action (rephrasing), it does not provide detailed guidance on how to rephrase the sentence. The action is explicit but somewhat vague, as the authors know what needs to be addressed but may not be entirely sure of the exact wording. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the phrase \"We have found it easier to be confident about applying ceterus paribus convexity,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a confusion regarding the use of the word \"confident\" and suggests that it might refer to human interpretability rather than model confidence. The comment provides a clear suggestion for rephrasing to clarify this point. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the use of the word \"confident\" in the context of ceterus paribus convexity, suggesting that it might refer to human interpretability rather than model confidence. The reviewer provides a logical reasoning by questioning the intended meaning of the word \"confident,\" which helps clarify the issue. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to infer the suggestion to rephrase the sentence to clarify the intended meaning. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential confusion in the use of the word \"confident\" in the context of ceterus paribus convexity, suggesting that it might refer to human interpretability rather than model confidence. The reviewer provides a clear suggestion for rephrasing the sentence to clarify this point, which is a valuable contribution to the authors\" understanding and clarity of their work. However, the comment could be more helpful if it offered additional context or examples to further guide the authors in making the necessary changes. Overall, the feedback is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with further elaboration. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights several issues with the presentation of empirical findings, including missing axis labels, randomly masked out portions of curves, single seed experiments, and the use of only two smallscale datasets and a single architecture type for core findings. While the comment identifies specific areas that need improvement, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they should add axis labels, clarify the masking of curves, conduct multiple seed experiments, and expand the dataset and architecture types for core findings. However, the lack of concrete guidance on how to implement these changes makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figures\" and \"empirical results,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as missing axis labels, randomly masked out portions of curves, single seed experiments, and the use of only two smallscale datasets and a single architecture type for core findings. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper lacks \"polishing\" in its figures and empirical results, which impede clarity and confidence in the empirical findings. It provides specific examples, such as missing axis labels, randomly masked out portions of curves, and the use of single seed experiments. Additionally, it points out that core findings are based on two smallscale datasets and a single architecture type. These details provide a clear basis for the claim, making it 4. However, the comment could be strengthened by referencing specific standards or best practices in experimental design, which would further support the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies several specific issues with the presentation of empirical findings, including missing axis labels, randomly masked out portions of curves, single seed experiments, and the use of only two smallscale datasets and a single architecture type for core findings. These points are clear and actionable, providing the authors with concrete areas to address in order to improve the clarity and confidence in their empirical results. However, the comment could be more helpful by suggesting specific ways to address these issues, such as recommending the inclusion of multiple seeds or the use of larger datasets. Despite this, the feedback is 4 as it directs the authors to important aspects of their work that need improvement. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the paper would benefit from reporting the results of the label noise experiment on imagenet with 1000 classes, specifically focusing on the nontail classes. This suggestion is explicit and provides a clear action for the authors to take, which is to include these additional results. The comment also explains why this is important, noting that it would further stress test the conjecture and provide valuable insights, even if the phenomenon weakens in this setting. The feedback is concrete and actionable, as it specifies exactly what the authors need to do to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the paper would benefit from reporting the results of the label noise experiment on imagenet with 1000 classes, specifically focusing on the nontail classes. This provides a clear and specific suggestion for improvement, indicating what additional data would strengthen the case. However, the comment does not explicitly mention which part of the paper this suggestion pertains to, such as a specific section or experiment. While the authors might infer that it relates to the label noise experiment, the lack of explicit grounding makes it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that reporting the results of the label noise experiment on imagenet with 1000 classes would strengthen the case and further stress test the conjecture. The comment provides a logical reasoning for why this additional data would be valuable, even if the phenomenon weakens in this setting. However, it does not provide specific examples or references to support the claim, which could strengthen the argument. Therefore, the comment is 3, as it provides a logical basis but lacks detailed evidence or references.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the paper. It recommends that the authors report the results of the label noise experiment on imagenet with 1000 classes, specifically focusing on the nontail classes. This suggestion is clear and offers a concrete way to strengthen the case and further test the conjecture. By including these additional results, the authors can gain a deeper understanding of the phenomenon and its robustness across different settings. The comment also acknowledges that even if the phenomenon weakens in this setting, the numbers are still worth seeing. This feedback is 5 as it provides a clear direction for enhancing the paper with valuable insights."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the choice of the number of weight updates as a metric instead of the number of network updates, given that the brain operates in parallel. It suggests that the authors provide additional feedback to improve the paper. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so or provide specific guidance on how to improve the paper. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional feedback and are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the choice of the number of weight updates as a metric instead of the number of network updates, given that the brain operates in parallel. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for additional feedback to improve the paper, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the choice of the number of weight updates as a metric, suggesting that the number of network updates might be a more appropriate metric given the parallel nature of brain operations. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the number of network updates would be a better metric. Without additional context or explanation, the claim remains vague and 1, leaving the authors without a clear understanding of the basis for the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the choice of the number of weight updates as a metric, suggesting that the number of network updates might be a more appropriate metric given the parallel nature of brain operations. This is a valid point that prompts the authors to reconsider their choice of metric and provides a direction for improvement. However, the comment lacks specific suggestions or examples on how to address this issue, such as proposing alternative metrics or explaining why network updates might be more relevant. While it identifies a potential area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the real scenarios where the objective given by the adversarial prediction accuracy, as proposed by the authors, differs from classical prediction accuracy. However, it does not provide any explicit or implicit actions for the authors to take. The question is more of a request for clarification, leaving the authors without a clear direction on how to address the issue. Since the comment lacks actionable guidance, it is rated as 1.", "grounding_specificity_rationale": "The comment raises a question about the real scenarios where the objective given by the adversarial prediction accuracy, as proposed by the authors, differs from classical prediction accuracy. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs clarification. The comment is 1 as it does not refer to any specific part of the paper, and it is also not specific because it lacks details on what aspects of the objective or scenarios need clarification. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point poses a question about the real scenarios where the objective given by the adversarial prediction accuracy, as proposed by the authors, differs from classical prediction accuracy. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the real scenarios where the objective given by the adversarial prediction accuracy, as proposed by the authors, differs from classical prediction accuracy. This is a valid inquiry that could help the authors clarify the practical relevance and application of their proposed method. However, the comment does not provide any suggestions or guidance on how the authors might address this question or improve their draft. It lacks actionable feedback, leaving the authors with only a vague idea of what needs to be clarified. Therefore, the comment is 2, as it identifies a potential area for improvement but does not offer specific guidance or suggestions for the authors to follow."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights several issues with the evaluation in the paper, including the lack of transparency regarding the experiment setup, the absence of information on the number of different sets of incontent examples used, and the reliance on a single dataset. The comment suggests that the evaluation is not comprehensive and lacks generalizability. While the comment identifies specific areas that need improvement, it does not provide explicit guidance on how to address these issues or what specific changes should be made. The authors can infer that they need to provide more detailed information about the experiment setup and potentially conduct additional experiments to improve the comprehensiveness and generalizability of the evaluation. However, the lack of concrete suggestions makes the action somewhat vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the evaluation section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the evaluation, such as the lack of transparency regarding the experiment setup, the absence of information on the number of different sets of incontent examples used, and the reliance on a single dataset. This provides clear guidance on what needs to be addressed to improve the comprehensiveness and generalizability of the evaluation. Therefore, this comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point claims that the evaluation in the paper is not comprehensive and lacks transparency regarding the experiment setup. It provides specific examples, such as the absence of information on the number of different sets of incontent examples used and the reliance on a single dataset, which may limit generalizability. The comment is supported by logical reasoning and specific examples, making it 4. However, it could be strengthened by providing more detailed suggestions or references to best practices in experimental design. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies several weaknesses in the evaluation section of the paper, specifically noting the lack of transparency regarding the experiment setup and the absence of information on the number of different sets of incontent examples used. It also points out that the evaluation relies solely on one dataset, which may limit the generalizability of the results. This feedback is clear and actionable, as it highlights specific areas where the authors can improve their evaluation methodology. By addressing these issues, the authors can enhance the comprehensiveness and robustness of their experimental results. However, the comment could be more helpful if it provided specific suggestions on how to address these concerns, such as recommending the inclusion of multiple datasets or the use of different sets of incontent examples. Overall, the comment is 4, as it directs the authors to important areas for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point claims that the contrastive learning framework used in the paper is the same as SimCLR. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, whether it is a concern or a suggestion for improvement. Without any actionable steps or suggestions, the authors are left without a clear understanding of what needs to be done in response to this comment. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment claims that the contrastive learning framework used in the paper is the same as SimCLR. However, it does not specify which part of the paper this claim pertains to, such as a specific section, figure, or table. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the framework are identical or how this similarity affects the paper. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the contrastive learning framework used in the paper is the same as SimCLR. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the comparison or how it affects their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment claims that the contrastive learning framework used in the paper is the same as SimCLR. However, it does not provide any context, explanation, or justification for this claim, nor does it offer any suggestions for improvement or guidance on how the authors might address this issue. Without additional information or actionable feedback, the comment lacks value and does not assist the authors in enhancing their draft. Therefore, it is rated as 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the submission would benefit from additional attention to related work, specifically mentioning references 1, 2, and 3. However, it does not provide explicit guidance on how the authors should incorporate these references or what specific aspects of the related work should be addressed. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand their discussion of related work but without detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the submission would benefit from additional attention to related work, specifically mentioning references 1, 2, and 3. However, it does not specify which part of the paper should include this additional attention or how it should be integrated. The authors can infer that it relates to the literature review or discussion sections, but the comment lacks full grounding as it does not explicitly mention these sections. Additionally, while it suggests a specific area for improvement, it does not provide detailed guidance on what aspects of the related work should be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the submission would benefit from additional attention to related work, specifically mentioning references 1, 2, and 3. However, the comment does not provide any further explanation or justification for why these specific references are relevant or how they could enhance the paper. Without additional context or reasoning, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the submission would benefit from additional attention to related work, specifically mentioning references 1, 2, and 3. While it identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on how the authors should incorporate these references or what aspects of the related work should be addressed. The comment is 3 as it points out a gap in the paper but does not offer actionable advice for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the absence of a comparison against existing text GANs, specifically mentioning the lack of testing with the pretrained version of SeqGAN. While the comment implies that the authors should include such comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to conduct the comparison or which existing text GANs to consider. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment highlights the absence of a comparison against existing text GANs, specifically mentioning the lack of testing with the pretrained version of SeqGAN. However, it does not specify which part of the paper this critique pertains to, such as a specific section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its critique of the lack of comparison and testing with SeqGAN, but without explicit references to sections or experiments, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there is no comparison against existing text GANs, specifically mentioning the lack of testing with the pretrained version of SeqGAN. This claim is 3 as it highlights a gap in the paper\"s evaluation process. However, the comment lacks specific examples of existing text GANs or detailed reasoning on why this comparison is important. Providing such examples or references would strengthen the justification for the claim, making it more verifiable. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of a comparison against existing text GANs, specifically mentioning the lack of testing with the pretrained version of SeqGAN. This feedback is valuable as it highlights an important area for improvement, namely the need to benchmark the proposed method against established alternatives. However, the comment could be more helpful if it provided specific suggestions on which existing text GANs to consider or how to conduct the comparison. Despite this, the comment is 4 as it directs the authors to a critical aspect of their work that requires further exploration and validation. Therefore, it aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper should have focused more on the algorithmic aspects of the solution, implying that the novelty of the paper is limited once the concept of Blackwell winner is proposed. However, it does not provide explicit guidance on how the authors should address this issue or what specific aspects of the algorithm should be explored. The action is implicit and vague, as the authors are left to infer that they need to expand their discussion on the algorithmic aspects but are not given concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the paper should have focused more on the algorithmic aspects of the solution, implying that the novelty of the paper is limited once the concept of Blackwell winner is proposed. However, it does not specify which part of the paper should have included more algorithmic aspects or how the authors could address this issue. Without explicit references to specific sections or examples, the authors cannot confidently determine which parts of the paper need revision. The comment is 1 and lacks specificity, making it difficult for the authors to understand and address the feedback. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the paper should have focused more on the algorithmic aspects of the solution, implying that the novelty of the paper is limited once the concept of Blackwell winner is proposed. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper should have focused more on the algorithmic aspects of the solution, implying that the novelty of the paper is limited once the concept of Blackwell winner is proposed. While it identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue or what aspects of the algorithm should be explored. The comment provides a general direction but does not offer actionable steps, making it 3 as it points out a weakness but does not fully support the authors in improving their draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that including a comparison to one of the methods mentioned in the computer vision setting would be more beneficial than comparing to lossbased sampling. The reviewer acknowledges that these methods may not always be applicable and typically require a supervised setup, but suggests that some of them could be adapted to language tasks relatively easily. While the comment implies that the authors should consider including such a comparison, it does not explicitly instruct them to do so or provide specific guidance on how to adapt these methods to language tasks. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take and how to implement the suggestion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests including a comparison to one of the methods mentioned in the computer vision setting, rather than comparing to lossbased sampling. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in suggesting a particular comparison, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that including a comparison to one of the methods mentioned in the computer vision setting would be more beneficial than comparing to lossbased sampling. The reviewer acknowledges that these methods may not always be applicable and typically require a supervised setup, but suggests that some of them could be adapted to language tasks relatively easily. While the comment provides a logical reasoning for the suggestion, it lacks specific examples or references to support the claim that these methods could be adapted. This makes the claim 3, as the authors would need to explore and justify the adaptation themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that including a comparison to one of the methods mentioned in the computer vision setting would be more beneficial than comparing to lossbased sampling. The reviewer acknowledges that these methods may not always be applicable and typically require a supervised setup, but suggests that some of them could be adapted to language tasks relatively easily. This feedback is 3 as it provides a specific suggestion for improvement, offering a potential direction for the authors to enhance their work. However, the comment could be more helpful if it provided examples of specific methods or detailed guidance on how to adapt them to language tasks. Overall, the comment is 3, as it offers a clear direction for improvement but lacks depth and detailed guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to estimate the time complexity of the learning algorithm to prove its scalability properties. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific task that needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"time complexity of the learning algorithm,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the estimation of the time complexity to prove scalability properties. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the time complexity of the learning algorithm should be explicitly estimated to prove its scalability properties. This is a logical claim that is based on a common understanding of scalability analysis in algorithms. However, the comment does not provide specific examples or references to support the claim, which would strengthen the justification. Therefore, the claim is 4, as it requires additional evidence or examples to fully substantiate the suggestion.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by explicitly estimating the time complexity of the learning algorithm. This is important for proving the scalability properties of the algorithm, which is a critical aspect of its evaluation. By addressing this feedback, the authors can enhance the rigor and comprehensiveness of their work. However, the comment could be more helpful if it included specific guidance on how to estimate the time complexity or examples of similar approaches. Overall, the feedback is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should consider connecting the third point of definition one to the properties of universal kernels, specifically referencing chapter 4 of Steinwart and Christmann. While the comment implies that the authors should explore this connection, it does not provide explicit instructions on how to make this connection or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the third point of definition one,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting a connection to properties of universal kernels, referencing chapter 4 of Steinwart and Christmann. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests a connection between the third point of definition one and the properties of universal kernels, referencing chapter 4 of Steinwart and Christmann. This provides a specific reference to support the claim, making the comment 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how this connection might be made, which would align with a score of 4.", "helpfulness_rationale": "The review comment suggests a potential connection between the third point of definition one and the properties of universal kernels, as discussed in chapter 4 of Steinwart and Christmann. This feedback is 3 as it points out a possible area for further exploration or elaboration in the paper. However, the comment lacks specific guidance on how to make this connection or what aspects of the universal kernels should be considered. While it provides a direction for the authors to consider, it does not offer detailed actionable steps, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the discussion around equation (10) is terse and not clearly explained. However, it does not provide any explicit or implicit suggestions on how to improve the explanation or what specific aspects need clarification. Without guidance on how to enhance the clarity or what additional information should be included, the authors are left without a clear understanding of what changes are needed. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"equation (10),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the terseness and lack of clarity in the discussion around equation (10). This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the discussion around equation (10) is terse and not clearly explained. However, it does not provide any specific examples or detailed reasoning to support this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the discussion around equation (10), noting that it is terse and not clearly explained. This feedback is 3 as it points out a potential area for improvement in the paper. However, it lacks depth and does not provide specific suggestions or guidance on how to enhance the clarity of the discussion. Without actionable advice, the authors may struggle to determine exactly what changes are needed to improve the explanation. Therefore, the comment is rated as 3, aligning with a score of 3."}
