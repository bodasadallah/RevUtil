{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper lacks an exploration of the theoretical properties of the proposed algorithm, specifically its convergence properties. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion of what aspects of the theory should be investigated or how to demonstrate convergence properties. Without specific instructions or examples, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment indicates that the paper lacks an exploration of the theoretical properties of the proposed algorithm, specifically its convergence properties. However, it does not specify which part of the paper this critique pertains to, such as a particular section or analysis. Without explicit references to specific sections or discussions, the authors cannot confidently determine where to address this feedback. Additionally, the comment lacks specificity regarding what aspects of the theory need to be explored or how convergence properties should be demonstrated. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper lacks an exploration of the theoretical properties of the proposed algorithm, specifically its convergence properties. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting that it lacks an exploration of the theoretical properties of the proposed algorithm, specifically its convergence properties. This feedback is important as it highlights a critical area for improvement that could strengthen the theoretical foundation of the work. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending particular theoretical analyses or methods to explore convergence properties. While it points out a key area for enhancement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the description of HIERENC is unclear and suggests that the input (h_i) to the temporal network is the average of the representations of all instantiations of context filled by every possible entity in the vocabulary. The reviewer questions the validity of this approach, stating that only one of these instantiations is likely to be correct and that this could introduce noise. While the comment identifies a potential issue with the description and suggests a possible reason for concern, it does not provide explicit guidance on how to clarify the description or address the potential noise issue. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the description and potentially explore alternative approaches. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"HIERENC,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by describing the unclear description of HIERENC and providing a detailed explanation of what is unclear. This provides clear guidance on what needs to be clarified or improved in the description. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the description of HIERENC is unclear and suggests that the input (h_i) to the temporal network is the average of the representations of all instantiations of context filled by every possible entity in the vocabulary. The reviewer questions the validity of this approach, stating that only one of these instantiations is likely to be correct and that this could introduce noise. While the comment provides a logical reasoning for the potential issue, it lacks specific examples or references to support the claim fully. The authors would need to further explore and substantiate the reasoning to fully understand and address the concern. Therefore, the comment is 3, as it provides a logical basis but requires additional evidence or examples to be 5.", "helpfulness_rationale": "The review comment identifies a specific issue with the description of HIERENC, suggesting that the input (h_i) to the temporal network is the average of the representations of all instantiations of context filled by every possible entity in the vocabulary. The reviewer questions the validity of this approach, noting that only one of these instantiations is likely to be correct and that this could introduce noise. This feedback is clear and actionable, as it highlights a potential weakness in the methodology and provides a specific critique that the authors can address by clarifying the description or exploring alternative approaches. However, the comment could be more helpful if it offered suggestions on how to improve the description or alternative methods to consider. Overall, the comment is 4, as it directs the authors to a critical area that needs clarification or improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the rationale behind selecting only 10 answers from all correct answers and whether this affects the underestimation of performances. While it implies that the authors should provide an explanation or justification for this selection, the comment does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to address the issue but are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the rationale behind selecting only 10 answers from all correct answers and whether this affects the underestimation of performances. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the selection process and its potential impact on performance estimation. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point is a question seeking clarification about the rationale behind selecting only 10 answers from all correct answers and whether this affects the underestimation of performances. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the rationale behind selecting only 10 answers from all correct answers and whether this affects the underestimation of performances. While it identifies a potential issue, it does not provide any suggestions or guidance on how the authors might address this concern or improve their methodology. The comment lacks depth and actionable feedback, leaving the authors with only a vague understanding of what needs to be clarified or improved. Therefore, it is 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies a potential inconsistency in the paper regarding the selection of sentences from raw data and the presence of syntactic information. It suggests that the authors should revise the description to clarify that the data selected is a subset of Li et al. (2019a)\"s dataset. The comment provides a specific example of how the description could be improved, making it clear and precise. This feedback is explicit and concrete, giving the authors a direct and detailed action to take. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (226238 and 242244) in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies the issue, which is the apparent contradiction between suggesting the selection of sentences from raw data and the presence of syntactic information. The comment further suggests that the data selected is a subset of Li et al. (2019a)\"s dataset and provides a specific example of how the description could be improved. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about a potential inconsistency in the paper regarding the selection of sentences from raw data and the presence of syntactic information. The reviewer suggests that the data selected is a subset of Li et al. (2019a)\"s dataset and provides a specific example of how the description could be improved. This feedback is 4 as it identifies a specific issue and provides a clear suggestion for improvement. However, it lacks detailed references or examples from Li et al. (2019a) to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential inconsistency in the paper regarding the selection of sentences from raw data and the presence of syntactic information. It suggests that the data selected is a subset of Li et al. (2019a)\"s dataset and provides a specific example of how the description could be improved by mentioning Li et al. (2019a) earlier. This feedback is clear and actionable, offering the authors a concrete way to enhance the clarity and precision of their description. By addressing this issue, the authors can improve the comprehensibility of their work for readers. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point questions the purpose of the average duration reported in Table 1 and asks for an explanation of what it includes. This implies that the authors should provide a supporting explanation for the average duration reported in the table. However, the comment does not explicitly instruct the authors to include this explanation or specify how to present it. The action is implicit and somewhat vague, as the authors can infer that they need to provide an explanation but are not given detailed guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the purpose of the average duration reported in the table and asks for an explanation of what it includes. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the purpose of the average duration reported in Table 1 and asks for an explanation of what it includes. This is a request for clarification rather than a claim, as it does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment questions the purpose of the average duration reported in Table 1 and asks for an explanation of what it includes. This is a relevant inquiry that could help clarify the significance of the data presented in the table. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the clarity of the table. While it identifies a potential area for improvement, it lacks actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the interpretation of results shown in Table 3, specifically regarding the comparison of NVSB to GT Mel A for Chinese MOSQ and the overlapping 95% CI for Baseline and NVSB in Chinese and English MOSV. While the comment highlights areas of confusion, it does not provide explicit instructions or suggestions on how the authors should address these questions or improve their interpretation. The authors are left to infer that they need to clarify the results themselves, but without concrete guidance on how to do so, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issues with the interpretation of the results, particularly regarding the comparison of NVSB to GT Mel A for Chinese MOSQ and the overlapping 95% CI for Baseline and NVSB in Chinese and English MOSV. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements and questions about the interpretation of results in Table 3, without making any subjective claims, opinions, or suggestions. It does not require verification or justification, as it is purely descriptive and does not present any arguments or judgments that need to be supported. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises specific questions about the interpretation of results shown in Table 3, specifically regarding the comparison of NVSB to GT Mel A for Chinese MOSQ and the overlapping 95% CI for Baseline and NVSB in Chinese and English MOSV. While it identifies areas of confusion, it does not provide suggestions or guidance on how the authors might address these questions or improve the clarity of their results. The comment highlights a need for clarification but lacks actionable feedback, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point points out a specific issue with the formatting of Table 2 and Table 3, noting that some items have spaces between accuracy and standard deviation, while others do not. This observation is explicit and provides a clear action for the authors to take, which is to ensure consistency in the formatting of these tables. However, the comment does not specify how the authors should address this issue or provide guidance on how to achieve consistency. While the action is explicit, the lack of detailed instructions makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2 and Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue of inconsistent spacing between accuracy and standard deviation, which affects the beauty of the tables. This provides clear guidance on what needs to be addressed to improve the presentation of the results. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about the formatting of tables, specifically noting inconsistencies in the spacing between accuracy and standard deviation. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment points out a specific formatting issue in Tables 2 and 3, noting that some items have spaces between accuracy and standard deviation, while others do not. This observation is relevant and could affect the visual appeal of the tables. However, the comment does not provide any guidance or suggestions on how the authors might address this issue or why it is important to do so. Without actionable advice or context, the feedback is 3, as it highlights a potential area for improvement but lacks depth and specificity. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies specific issues with the references, such as missing antecedents and incorrect capitalization or bibliographic details. It provides explicit actions for the authors to take, such as checking the references for format and correcting any errors. The feedback is clear and concrete, leaving no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"both tasks,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be addressed, such as checking the references for format and correcting capitalization and bibliographic details. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements and requests for clarification, such as checking the references for format and correcting capitalization. It does not contain subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies specific issues with the references, such as missing antecedents and incorrect capitalization or bibliographic details. It provides clear and actionable feedback by suggesting that the authors check the references for format and correct any errors. This guidance is valuable as it directly addresses a concrete issue that can be easily rectified, helping the authors improve the accuracy and professionalism of their references. However, the comment could be more helpful if it provided examples of correct formatting or detailed guidance on how to correct the errors. Overall, the feedback is 4 as it offers actionable steps for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a specific issue with the organization of Section 3.2, noting that the explanations for features are intertwined and confusing. It suggests that the section would be more coherent if it had separate paragraphs dedicated to each of the lexical features and sentencelevel features. While the comment provides a clear action for the authors to take\u2014organizing the section into separate paragraphs\u2014it does not offer detailed guidance on how to implement this change or what specific content should be included in each paragraph. The action is explicit but somewhat vague, as it lacks concrete steps for execution. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the explanations for features being intertwined and confusing, and it provides a suggestion for improvement by recommending separate paragraphs for lexical features and sentencelevel features. This level of detail helps the authors understand what needs to be addressed and how to improve the organization of the section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the explanations for features in Section 3.2 are intertwined and confusing, suggesting that the section would be more coherent with separate paragraphs dedicated to lexical features and sentencelevel features. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the exact issues or how to address them. The lack of detailed justification or examples makes the claim 3, as the authors may struggle to fully grasp the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the organization of Section 3.2, noting that the explanations for features are intertwined and confusing. It suggests that the section would be more coherent if it were organized with separate paragraphs dedicated to each of the lexical features and sentencelevel features. This feedback is clear and actionable, providing the authors with a concrete suggestion for improving the clarity and structure of their paper. By following this advice, the authors can enhance the readability and comprehensibility of their work. However, the comment could be more helpful if it included specific examples or detailed guidance on how to separate the paragraphs. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of clarity regarding how the proposed models compare to models that only consider different senses but not sememes. It suggests that the MST baseline might be an example of such a model and notes that the emphasis is on soft vs. hard word sense disambiguation rather than on the comparison with other models. The comment implies that the paper would be stronger with the inclusion of more baselines based on related work. While the comment identifies a specific area for improvement, it does not provide explicit instructions on how to implement this suggestion, such as which models to include or how to structure the comparison. The action is implicit and somewhat vague, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed models\" and the \"MST baseline,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of clarity in comparing the proposed models to those that only consider different senses but not sememes. Additionally, it suggests the inclusion of more baselines based on related work to strengthen the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the comparison between the proposed models and models that only consider different senses but not sememes is unclear. It suggests that the MST baseline might be an example of such a model and notes that the emphasis is on soft vs. hard word sense disambiguation rather than on the comparison with other models. The comment implies that the paper would be stronger with the inclusion of more baselines based on related work. While the comment provides some reasoning by mentioning the MST baseline, it lacks specific examples or detailed comparisons to support the claim fully. The suggestion for more baselines is logical but could be strengthened with additional references or detailed explanations. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed evidence or examples to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the comparison of the proposed models with models that only consider different senses but not sememes. It suggests that the MST baseline might be an example of such a model and points out that the emphasis is on soft vs. hard word sense disambiguation rather than on the comparison with other models. The comment provides a clear and actionable suggestion for improvement by recommending the inclusion of more baselines based on related work. This feedback is valuable as it directs the authors to a specific area that needs further clarification and provides a concrete step to enhance the paper. However, the comment could be more helpful if it offered specific examples of models to include or detailed guidance on how to structure the comparison. Overall, the comment is 4, as it effectively guides the authors toward improving the clarity and comprehensiveness of their work."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a lack of clarity regarding how the frame similarity factors and attributes similarity factors are selected. However, it does not provide any explicit guidance or suggestions on how the authors might clarify this aspect of their work. The action is implicit, as the authors can infer that they need to provide more detailed information on the selection process, but it lacks concrete steps or examples to guide them. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment identifies a specific issue regarding the selection of frame similarity factors and attributes similarity factors, but it does not specify which part of the paper this issue is discussed in. The authors can infer that it might be related to the methodology or results sections, but without explicit references, the comment is weakly grounded. It is specific in detailing the issue of clarity regarding the selection process, which provides some guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the clarity of how frame similarity factors and attributes similarity factors are selected. However, it does not provide any specific examples, reasoning, or references to support this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the comment or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific area of confusion regarding the selection of frame similarity factors and attributes similarity factors. This feedback is 3 as it points out a potential issue that the authors need to address to improve the clarity and comprehensibility of their work. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might clarify this aspect of their methodology. To be more helpful, the comment could include examples or explanations of what information should be included to address the issue. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should include discussions on the convergence of the proposed joint learning process, specifically for RNN and CopyRNN, to help readers understand how stable points in the probabilistic metric space are obtained. This feedback is explicit in its request for additional discussion and provides a clear direction for the authors to improve their draft. However, it does not specify the exact content or depth of the discussion required, which could be more concrete. Therefore, the comment is 4, as it provides a clear action but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment suggests that discussions are needed on the convergence of the proposed joint learning process, specifically for RNN and CopyRNN, to help readers understand how stable points in the probabilistic metric space are obtained. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its request for additional discussion on convergence, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact location for improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that discussions are needed on the convergence of the proposed joint learning process, specifically for RNN and CopyRNN, to help readers understand how stable points in the probabilistic metric space are obtained. The comment implies that without such discussions, it may be difficult to replicate the results. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the current explanation is insufficient. This makes the claim 3, as it provides a general direction for improvement but lacks the necessary details to fully substantiate the need for additional discussion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by suggesting that discussions on the convergence of the proposed joint learning process are needed. It highlights the importance of understanding how stable points in the probabilistic metric space are obtained, which is crucial for replicating the results. While the comment provides a clear direction for improvement, it lacks detailed guidance on what specific aspects of the convergence process should be discussed or how to present this information. This limits the comment\"s usefulness, as it does not fully empower the authors to make the necessary improvements. Therefore, the comment is 3, as it points out a critical area for enhancement but does not provide comprehensive guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point provides explicit actions for the authors to take. It suggests discussing the results for the task of inferring knowledge on objects and includes results for model (B), while also recommending using consistent terminology for the model in Tables 1 and 2. Additionally, it questions why objects are not mentioned in relation to \"latent in verbs.\" These suggestions are clear and concrete, giving the authors specific steps to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (681 and 778) in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it provides clear suggestions for improvement, such as discussing results for the task of inferring knowledge on objects and including results for model (B), and it questions the omission of objects in relation to \"latent in verbs.\" This level of detail guides the authors on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point consists of a series of requests for clarification and suggestions for improvement, such as discussing results for the task of inferring knowledge on objects and including results for model (B). It also questions the omission of objects in relation to \"latent in verbs.\" These are factual statements or requests for clarification, not claims that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback, addressing two distinct areas for improvement. First, it suggests discussing the results for the task of inferring knowledge on objects, which is a relevant and important aspect of the paper. Second, it points out the inconsistency in terminology used for the model in Tables 1 and 2, recommending the use of consistent terminology. Additionally, it questions the omission of objects in relation to \"latent in verbs,\" prompting the authors to clarify this aspect. These suggestions are clear and actionable, offering the authors concrete steps to enhance the clarity and completeness of their draft. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the work is a straightforward extension of existing retrofitting work and recommends adding additional baselines, such as character embeddings. While the comment implies that the authors should include these baselines, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to implement the suggested baselines or what other baselines might be relevant. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the work is a straightforward extension of existing retrofitting work and recommends adding additional baselines, such as character embeddings. However, it does not specify which part of the paper this comment pertains to, making it weakly grounded. The comment is specific in suggesting the addition of character embeddings as baselines, which provides some guidance on what could be improved. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the work is a \"fairly straightforward extension of existing retrofitting work\" and suggests adding additional baselines, such as character embeddings. However, the comment lacks specific examples or references to support the claim that the work is a straightforward extension or to justify the need for additional baselines. Without detailed evidence or reasoning, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is classified as 2.", "helpfulness_rationale": "The review comment points out that the work is a straightforward extension of existing retrofitting work and suggests adding additional baselines, such as character embeddings. While it identifies a potential area for improvement, the comment lacks specificity and does not provide detailed guidance on how to implement these additional baselines or why they would be beneficial. The feedback is 3 as it prompts the authors to consider expanding their work, but it could be more actionable with additional details or examples. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the paper relies on supplemental space to contain its content, which makes it dependent on the supplemental material. It specifically mentions Section 3.1 and references to Supplemental Figure 6, as well as the model comparison and span versus sentence investigation. However, the comment does not provide explicit guidance on how the authors should address this issue or improve the paper. The action is implicit, as the authors can infer that they need to make the paper more selfcontained, but the comment lacks concrete details on how to achieve this. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper, including \"S3.1\" and \"Sup. Fig. 6,\" allowing the authors to accurately identify the parts being addressed. It also specifies the issue by pointing out that the paper relies on supplemental space and is not truly independent, particularly in the context of references to supplemental figures and model comparisons. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper relies on supplemental space to contain its content, making it dependent on the supplemental material. It specifically mentions Section 3.1 and references to Supplemental Figure 6, as well as the model comparison and span versus sentence investigation. However, the comment lacks specific examples or detailed reasoning to support the claim that the paper is not truly independent. While it highlights certain sections that rely on supplemental material, it does not provide a comprehensive analysis or evidence to substantiate the claim. This makes the comment 3, as it points out potential issues but requires more detailed justification to be fully convincing.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that it relies heavily on supplemental space to contain its content, which makes it dependent on the supplemental material. It specifically mentions Section 3.1 and references to Supplemental Figure 6, as well as the model comparison and span versus sentence investigation. This feedback is valuable as it highlights a potential weakness in the paper\"s independence and selfcontainedness. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending ways to integrate the supplemental material more effectively into the main text. Despite this, the comment is 4 as it directs the authors\" attention to a critical area that needs improvement. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies several weaknesses in the paper, specifically related to the experiments. It notes that the experiments are limited to an extremely lowresource regime, which may not be representative of realworld applications, and that sentence classification is an easier task. The reviewer suggests that the proposed augmentation method could be applied to more NLP tasks, but this is not demonstrated in the paper. While the comment highlights areas for improvement, it does not provide explicit or concrete actions for the authors to take. The feedback is 3 as it points out specific issues, but it lacks detailed guidance on how to address them, such as suggesting additional experiments or tasks to explore. Therefore, the comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment identifies specific weaknesses in the paper, particularly related to the experiments. It mentions that the experiments are limited to an extremely lowresource regime, which may not be representative of realworld applications, and that sentence classification is an easier task. The reviewer also suggests that the proposed augmentation method could be applied to more NLP tasks, but this is not demonstrated in the paper. However, the comment does not specify which sections or experiments these issues pertain to, making it weakly grounded. The feedback is specific in detailing the weaknesses and potential improvements, but without explicit references to sections or experiments, the authors may find it challenging to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper\"s experiments are weak due to their focus on an extremely lowresource regime and an easier task (sentence classification). The reviewer suggests that the proposed augmentation method could be applied to more NLP tasks, which was not demonstrated in the paper. However, the comment lacks specific examples or references to support the claim that the experiments are insufficient or that the augmentation method could be applied to other tasks. The reasoning is somewhat vague, making it difficult for the authors to fully understand and address the critique. Therefore, the comment is rated as 2, as it provides some justification but lacks detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies specific weaknesses in the paper, particularly related to the experiments. It points out that the experiments are limited to an extremely lowresource regime, which may not be representative of realworld applications, and that sentence classification is an easier task. The reviewer suggests that the proposed augmentation method could be applied to more NLP tasks, but this is not demonstrated in the paper. While the comment highlights important areas for improvement, it lacks detailed guidance or suggestions on how the authors might address these issues or expand their experiments. The feedback is 3 as it provides insight into the limitations of the current work, but it could be more actionable with specific recommendations or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to provide more information about the traits of the experts and to justify why annotation must be carried out by the experts, rather than focusing solely on commercial values. It also asks specific questions about the expertise of the experts, the nature of the annotation, and potential linguistic challenges. These questions provide clear guidance on what additional information should be included in the paper. The action is explicit and concrete, giving the authors a clear understanding of what needs to be addressed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the first point,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: a more detailed description of the traits of the experts and a justification for why annotation must be carried out by the experts, rather than focusing solely on commercial values. The comment also asks specific questions about the expertise of the experts, the nature of the annotation, and potential linguistic challenges. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with a score of 5.", "verifiability_rationale": "The review point raises a claim about the need for more information regarding the traits of the experts and the justification for using their expertise for annotation. However, it does not provide any specific reasoning or evidence to support this claim. The comment lacks detailed justification or examples that would help the authors understand why this information is necessary or how it would improve the paper. As a result, the claim is 1, as it does not provide sufficient evidence or reasoning to support the need for additional information. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by identifying a gap in the paper regarding the description of the experts\" traits and the justification for using their expertise for annotation. It asks questions about the expertise of the experts, the nature of the annotation, and potential linguistic challenges, which could help the authors clarify and strengthen their argument. By prompting the authors to address these points, the comment offers a clear path for improvement, making it 5. Therefore, the comment is rated as 5, consistent with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should include examples of their system applied to actual texts rather than focusing solely on other components or models. While the comment implies that the authors should provide such examples, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not specify the type of examples or how they should be presented. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including examples of the system applied to actual texts, rather than focusing on other components or models. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the results or discussion sections, but this inference is not explicit. The comment is specific in suggesting the inclusion of examples, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it would be beneficial to include examples of the system applied to actual texts, rather than focusing solely on other components or models. However, the comment does not provide any specific reasoning, examples, or references to support why this would be valuable or necessary. Without additional context or justification, the authors may find it challenging to understand the importance of this suggestion or how to implement it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the authors should include examples of their system applied to actual texts, rather than focusing solely on other components or models. This feedback is 3 as it provides a specific direction for enhancing the paper by demonstrating the system\"s practical application. However, the comment lacks depth and does not offer detailed guidance on how to present these examples or what specific aspects of the system should be highlighted. While it points out a potential area for improvement, it does not fully support the authors in making those improvements. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the paper raises two hypotheses about multilinguality and country/languagespecific bias but does not test or discuss them further. The reviewer suggests that the hypotheses could be phrased more optimally for testing but acknowledges their value. The comment also expresses a desire for the paper to delve deeper into these topics. While the comment identifies areas for improvement, it does not provide explicit guidance on how to rephrase the hypotheses or how to deepen the discussion. The action is implicit and somewhat vague, as the authors are left to infer what changes are needed without concrete instructions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 078086, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the hypotheses about multilinguality and country/languagespecific bias are not tested or discussed further, which is misleading. The comment further suggests that the paper should delve deeper into these topics. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper raises two hypotheses about multilinguality and country/languagespecific bias but does not test or discuss them further. The reviewer suggests that the hypotheses could be phrased more optimally for testing but acknowledges their value. The comment also expresses a desire for the paper to delve deeper into these topics. While the reviewer provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion that the hypotheses are not tested or discussed. This makes the claim 3, as it requires more detailed evidence or examples to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that it raises two hypotheses about multilinguality and country/languagespecific bias but does not test or discuss them further. This is considered misleading, as the hypotheses are not explored or mentioned again in the paper. The reviewer also suggests that the paper should delve deeper into these topics, which is a valuable suggestion for improvement. However, the comment could be more helpful by providing specific guidance on how to test or discuss these hypotheses, or by suggesting alternative ways to explore them. Despite this, the feedback is 4 as it highlights a critical gap in the paper and offers a direction for improvement. Therefore, it aligns with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the use of the Challenge Set (CS) and its role in the evaluation and training process. It explicitly asks whether the CS is used to augment the training material and requests information about the data split. While the comment does not provide explicit instructions, it does imply that the authors should clarify these aspects. The action is implicit but concrete, as it directs the authors to provide specific information about the use of the CS. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment raises questions about the use of the Challenge Set (CS) in the evaluation and training process, specifically asking if it is used to augment the training material and requesting information about the data split. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its questions about the use of the CS and the data split, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the use of the Challenge Set (CS) in the evaluation and training process. It seeks clarification on whether the CS is used to augment the training material and requests information about the data split. However, the comment does not provide any supporting evidence, reasoning, or references to justify these questions. Without additional context or explanation, the authors may find it challenging to address the concerns effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises important questions about the use of the Challenge Set (CS) in the evaluation and training process. It seeks clarification on whether the CS is used to augment the training material and requests information about the data split. This feedback is valuable as it prompts the authors to provide more detailed information about their methodology, which can help readers better understand the study. However, the comment could be more helpful if it offered suggestions on how to address these questions or provided examples of how similar studies have handled such issues. Overall, the comment is 3 as it identifies a gap in the paper and encourages the authors to clarify their approach, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the relatively poor performance of TWSI on nouns, which is expected due to its nature. It also notes that the oracle GAP for PPDBClus is higher than most clustering approaches, which is disconcerting. The reviewer suggests understanding the gap better and points out a contradiction with the claim that the clustering approach is generalizable to all parts of speech. While the comment identifies areas of concern and suggests further exploration, it does not provide explicit instructions or concrete steps for the authors to take. The action is implicit and somewhat vague, as the authors are left to infer that they should investigate the gap and reconcile the contradictory claims. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the performance of TWSI on nouns, which is expected due to its nature, and the fact that the oracle GAP for PPDBClus is higher than most clustering approaches. It also points out a contradiction with the claim that the clustering approach is generalizable to all parts of speech. However, the comment does not specify which sections of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the concerns about performance and the contradiction with the claim, but without explicit references to sections, it is challenging for the authors to pinpoint the exact parts of the paper that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the relatively poor performance of TWSI on nouns is disconcerting, given the nature of TWSI and the fact that the oracle GAP for PPDBClus is higher than most clustering approaches. The comment also points out a contradiction with the claim that the clustering approach is generalizable to all parts of speech. While the reviewer provides some reasoning by mentioning the oracle GAP and the expected performance of TWSI, the comment lacks specific examples or detailed analysis to fully substantiate the claim. The reasoning is 3, as it highlights a potential issue but requires more detailed evidence or examples to be fully convincing. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific concern about the performance of TWSI on nouns, which is expected due to its nature. It also points out a contradiction with the claim that the clustering approach is generalizable to all parts of speech, as the performance is not uniform. The comment suggests that the authors should investigate the gap between the oracle GAP for PPDBClus and most clustering approaches, which is a clear and actionable suggestion. However, the comment could be more helpful by providing additional guidance on how to address the issue or suggesting specific methods for analysis. Overall, the feedback is 4 as it highlights a critical area for improvement and offers a direction for further exploration, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly requests the authors to provide examples of spurious structures in the discussion of section 5.2, which is a direct and concrete action. The authors know exactly what they need to do to address this feedback, which is to include specific examples to clarify the discussion. This makes the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 5.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the discussion, stating that it is too abstract and lacks examples of spurious structures. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the discussion in section 5.2 is too abstract and lacks examples of spurious structures. However, it does not provide any specific reasoning or evidence to support this claim. Without detailed examples or references to what is considered abstract or lacking, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the discussion in section 5.2, noting that it is too abstract and lacks examples of spurious structures. This feedback is clear and actionable, as it directs the authors to provide concrete examples to clarify the discussion and enhance the paper\"s insights. By addressing this feedback, the authors can improve the clarity and depth of their analysis, making the comment 4. However, it could be more helpful if it included suggestions on how to present these examples or what specific aspects of the discussion need more detail. Therefore, the comment is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests including the hard prompt baseline in Table 1 to demonstrate the increase in performance of each method. This is an explicit action that provides clear guidance on what the authors should do to improve their draft. The comment specifies exactly what needs to be added to the table, making it 5. The authors know exactly how to implement this suggestion, ensuring that they can effectively address the feedback.", "grounding_specificity_rationale": "The comment suggests including the hard prompt baseline in Table 1 to demonstrate the increase in performance of each method. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table. The authors can infer that it relates to the results or discussion sections, but this inference is not explicit. The comment is specific in suggesting the inclusion of the hard prompt baseline, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests including the hard prompt baseline in Table 1 to demonstrate the increase in performance of each method. This is a request for additional information or analysis, rather than a claim or opinion that requires verification. It does not contain subjective judgments, opinions, or suggestions that need to be supported by evidence or reasoning. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment suggests including the hard prompt baseline in Table 1 to demonstrate the increase in performance of each method. This feedback is clear and actionable, providing the authors with a specific suggestion to enhance their results section. By including this baseline, the authors can better illustrate the effectiveness of their methods and provide a more comprehensive comparison. However, the comment could be more helpful if it explained why this comparison is important or how it would impact the overall understanding of the paper. Despite this, the suggestion is valuable and offers a clear path for improvement, making the comment 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the lack of numerical results and expresses curiosity about how the method could be applied to popular algorithms and compared with existing DP algorithms. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should include numerical results and comparisons, but it lacks concrete details on what specific algorithms to consider or how to conduct the comparisons. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment highlights the lack of numerical results and expresses curiosity about applying the method to popular algorithms and comparing its performance with existing DP algorithms. However, it does not specify which part of the paper lacks numerical results or where the authors should include these comparisons. The authors might infer that it relates to the experimental results or methodology sections, but this inference is not explicit. The comment is specific in its request for numerical results and comparisons, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses curiosity about the lack of numerical results and suggests comparing the method with existing DP algorithms. However, it does not provide any specific examples, references, or detailed reasoning to support the claim that such comparisons are necessary or beneficial. The comment lacks evidence or justification for why these comparisons are important, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of numerical results. It expresses curiosity about how the method could be applied to popular algorithms and compared with existing DP algorithms. This feedback is 3 as it highlights an area for improvement and prompts the authors to consider including such comparisons. However, the comment lacks specific guidance or suggestions on how to conduct these comparisons or which algorithms to focus on, leaving the authors with a general direction but not a detailed roadmap for improvement. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the experimental comparisons are insufficient and recommends testing the proposed InvP method with wider backbones like ResNet50 (2\u00d7) and ResNet50 (4\u00d7). This feedback provides a clear and explicit action for the authors to take, which is to conduct additional experiments with these wider backbones. The suggestion is concrete, as it specifies exactly what needs to be done to improve the experimental section. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the experimental comparisons are insufficient and recommends testing the proposed InvP method with wider backbones like ResNet50 (2\u00d7) and ResNet50 (4\u00d7). While it does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the experimental results or methodology sections. The comment is specific in suggesting a particular comparison that could be made to enhance the study. However, since it does not explicitly mention a section, it is weakly grounded but specific. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that the experimental comparisons are insufficient and suggests testing the proposed InvP method with wider backbones like ResNet50 (2\u00d7) and ResNet50 (4\u00d7). The comment provides a specific suggestion for improvement by referencing other methods that have tested results with wider backbones. This reasoning is logical and provides a clear direction for the authors to enhance their experimental comparisons. However, the comment could be strengthened by including references to the specific methods or studies that have used these wider backbones, which would make it 5. Therefore, the comment is 4, as it provides a solid basis for the suggestion but lacks complete references.", "helpfulness_rationale": "The review comment identifies a specific weakness in the experimental comparisons, noting that the proposed method, InvP, has not been tested with wider backbones like ResNet50 (2\u00d7) and ResNet50 (4\u00d7). This feedback is clear and actionable, as it suggests a straightforward way for the authors to enhance their experimental results by including these wider backbones. By following this advice, the authors can provide a more comprehensive evaluation of their method and potentially improve its performance. However, the comment could be more helpful if it provided additional context or reasoning for why these wider backbones are important or how they might impact the results. Overall, the comment is 4 as it offers a concrete suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to correct the callout to table 5, suggesting it should point to table 3 instead. It also mentions a specific page and section where the figure 6 callout is not directing properly. This feedback is clear and provides concrete actions for the authors to take, ensuring they know exactly what needs to be corrected in their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, including \"table 5,\" \"table 3,\" \"page 7, section 5, last par.,\" and \"figure 6.\" This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies the issue with the callouts, indicating that the callout to table 5 should point to table 3 instead and that the callout for figure 6 is not directing properly. This provides clear guidance on what needs to be corrected. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements and does not contain any subjective claims, opinions, or suggestions that require verification. It is purely descriptive, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by pointing out two errors in the paper. It instructs the authors to correct the callout to table 5, suggesting it should point to table 3 instead. Additionally, it highlights an issue with the callout for figure 6, indicating that it is not directing properly. This feedback is clear and direct, giving the authors precise guidance on how to improve the accuracy and clarity of their paper. However, the comment could be more helpful if it explained why these corrections are necessary or how they impact the paper\"s readability. Overall, the comment is 4 as it provides concrete steps for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights concerns about the experiments, specifically noting that the paper only reports selfcomparisons and lacks an explanation for this choice. It suggests that comparisons with SketchRNN could be performed in a generative setting. While the comment identifies a specific issue with the experiments and provides a suggestion for improvement, it does not explicitly instruct the authors to make these comparisons or explain how to implement them. The action is implicit and somewhat vague, as the authors need to infer that they should include comparisons with SketchRNN and provide an explanation for their choice of selfcomparisons. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the experiments, namely the lack of comparisons with other methods like SketchRNN, and the need for an explanation for the choice of selfcomparisons. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper has a \"biggest concern\" with its experiments, specifically noting that it only reports selfcomparisons and lacks an explanation for this choice. The reviewer suggests that comparisons with SketchRNN could be performed in a generative setting. While the comment identifies a specific issue with the experiments, it lacks detailed reasoning or examples to fully substantiate the claim. The suggestion to include comparisons with SketchRNN is a logical one, but the comment could be strengthened by providing more context or evidence to support the need for these comparisons. Therefore, the comment is 3, as it provides a basis for the claim but requires additional information to be fully convincing.", "helpfulness_rationale": "The review comment identifies a significant concern with the paper, specifically the lack of comparisons with other methods, such as SketchRNN, in the experiments. It highlights the issue of only reporting selfcomparisons and the need for an explanation for this choice. This feedback is clear and actionable, as it points out a specific area for improvement and suggests a potential direction for enhancing the paper by including comparisons with relevant methods. However, the comment could be more helpful if it provided additional guidance on how to conduct these comparisons or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with further suggestions or examples."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point acknowledges that the paper is generally easy to follow but identifies specific areas that may cause confusion. However, it does not provide explicit guidance on how to address these potential sources of confusion. The comment lacks actionable details, such as suggesting specific changes or improvements to clarify these areas. As a result, the authors are left without a clear understanding of what steps to take to enhance the clarity of their draft. Since the comment does not offer concrete actions or suggestions, it is 1.", "grounding_specificity_rationale": "The comment acknowledges that the paper is generally easy to follow but identifies specific areas that may cause confusion. However, it does not specify which parts of the paper are confusing or what aspects need clarification. Without explicit references to sections, figures, or specific elements, the authors cannot confidently determine which parts of the paper are being addressed. This lack of grounding and specificity makes it difficult for the authors to understand and address the issues raised. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is generally easy to follow but identifies specific areas that may cause confusion. However, it does not provide any examples or detailed reasoning to support this claim. Without specific references or explanations, the authors may find it challenging to understand and address the potential sources of confusion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment acknowledges that the paper is generally easy to follow but identifies specific areas that may cause confusion. However, it does not provide any details or examples of what these confusing areas are, nor does it offer suggestions on how to address them. Without specific guidance or actionable feedback, the authors are left without a clear understanding of what needs to be improved or clarified. This lack of detail makes the comment 2, as it identifies a potential issue but does not provide the authors with the necessary information to address it effectively."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the claim \"there is no corresponding set of tools for the reinforcement learning setting\" is false, and it provides references to support this assertion. The comment is clear and direct, leaving no ambiguity about the action required. The authors know exactly what needs to be done, which is to address the false claim by providing a corresponding set of tools or references. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the part of the paper where the claim is made, \"there is no corresponding set of tools for the reinforcement learning setting.\" This allows the authors to accurately identify the section being addressed. The comment is also specific because it clearly specifies that the claim is false and provides references to support this assertion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement \"there is no corresponding set of tools for the reinforcement learning setting\" is false. It provides references to support this claim, which is a clear and explicit form of evidence. This makes the claim 5, as the authors can easily access the references to understand the basis of the reviewer\"s assertion. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment directly challenges a claim made in the paper, stating that \"there is no corresponding set of tools for the reinforcement learning setting\" is false. It provides references to support this assertion, which is a valuable contribution to the authors\" understanding of the topic. By correcting a potential misconception, the comment helps the authors refine their work and ensures the accuracy of their claims. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided additional context. Overall, the comment is 4 as it corrects a significant error and guides the authors toward a more accurate representation of their work."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights that the results are based on \"standard\" techniques but are not obvious a priori, requiring a fair degree of technical competency. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue of the results being nonobvious or how to make them more accessible to a broader audience. Without any actionable suggestions or specific instructions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the results section, specifically mentioning that they are based on \"standard\" techniques but are not obvious a priori. However, it does not specify which results or techniques are being referred to, making it weakly grounded. The comment is specific in pointing out the issue of the results being nonobvious and requiring technical competency, but it lacks detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the results are based on \"standard\" techniques but are not obvious a priori, requiring a fair degree of technical competency. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed justification or evidence, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment points out that the results are based on \"standard\" techniques, which are not obvious a priori and require a fair degree of technical competency. This observation highlights a potential limitation in the accessibility of the results, suggesting that they may not be readily understandable to a broader audience. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as by providing additional explanations or examples to make the results more accessible. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy in the amount of data used to train the text disambiguation model compared to the endtoend system. It questions the conclusion that the direct model is clearly superior, given the small difference in performance. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest ways to improve the data usage or analysis. The action is implicit and vague, as the authors are left to infer that they should reconsider their data usage or analysis, but without concrete steps or suggestions, the comment lacks actionability. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the amount of data used to train the text disambiguation model compared to the endtoend system. It questions the conclusion that the direct model is clearly superior, given the small difference in performance. However, the comment does not specify which part of the paper discusses these models or their performance, making it weakly grounded. The comment is specific in detailing the issue with the data usage and the implications for the conclusion, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact parts needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the conclusion that the direct model is clearly superior, given the small difference in performance compared to the endtoend system. The comment highlights a discrepancy in the amount of data used for training, suggesting that this may impact the conclusion. However, the comment lacks specific examples or references to support the claim that the difference in data usage is significant or that it affects the conclusion. The reasoning is somewhat logical but requires more detailed evidence or examples to be 5. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the conclusion that the direct model is clearly superior, given the small difference in performance compared to the endtoend system. It highlights a discrepancy in the amount of data used for training, which could impact the validity of the conclusion. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their analysis. While it points out a relevant concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight but lacks depth and specificity in its feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies two main issues: the lack of motivation for GaRare compared to GaLore and the need for a more detailed algorithmic presentation, particularly regarding the process of recovering updated parameters from projected gradients. The comment provides explicit actions for the authors to take, such as providing evidence or justification for GaRare\"s advantages and clarifying the algorithmic presentation. These suggestions are clear and concrete, giving the authors a direct path to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"GaRare\" and \"GaLore,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the lack of motivation for GaRare and the need for a more detailed algorithmic presentation, particularly regarding the process of recovering updated parameters from projected gradients. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks motivation for GaRare and does not provide evidence or justification for its advantages over GaLore. It also suggests that a more detailed algorithmic presentation is needed, particularly to clarify the process of recovering updated parameters from projected gradients. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the exact issues or how to address them. The lack of detailed reasoning or evidence makes the claim 3, as it requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies two key areas for improvement in the paper. First, it points out the lack of motivation for GaRare, specifically noting the absence of evidence or justification for its advantages over GaLore based on theoretical analysis. This feedback is clear and actionable, as it prompts the authors to provide a more thorough explanation of the benefits and advantages of their approach. Second, the comment highlights the need for a more detailed algorithmic presentation, particularly regarding the process of recovering updated parameters from projected gradients. This suggestion is also actionable, as it directs the authors to enhance the clarity and understanding of their methodology. Overall, the comment provides specific and constructive feedback that can guide the authors in improving their draft, making it 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly requests the authors to conduct an ablation study on the visDial dataset to further validate the proposed visual reference resolution model. It also suggests conducting an experiment to evaluate the performance of ATT(+H) without considering relevant attention retrieval from the attention memory. This feedback provides clear and specific actions for the authors to take, including conducting additional experiments and analyses. The instructions are explicit and concrete, giving the authors a clear understanding of what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 4 left,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, which is the performance of ATT(+H) without considering relevant attention retrieval from the attention memory. This provides clear guidance on what additional experiments or analyses should be conducted to further validate the proposed model. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests conducting an ablation study on the visDial dataset to further validate the proposed visual reference resolution model. It also requests an experiment to evaluate the performance of ATT(+H) without considering relevant attention retrieval from the attention memory. While the comment provides a clear suggestion for additional experiments, it lacks specific reasoning or evidence to support why these experiments are necessary or how they would contribute to the paper\"s validity. The request for an ablation study is 3, as it suggests a logical next step, but the lack of detailed justification or examples makes it difficult for the authors to fully understand the importance of these experiments. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting additional experiments to further validate the proposed visual reference resolution model. It recommends conducting an ablation study on the visDial dataset to assess the model\"s performance in a realworld scenario. Additionally, it highlights an experiment of particular interest, namely the performance of ATT(+H) without considering relevant attention retrieval from the attention memory. This feedback is clear and detailed, offering the authors a concrete direction for enhancing the robustness and validity of their work. By addressing these suggestions, the authors can significantly improve the comprehensiveness and credibility of their draft. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a potential concern about the need for reinforcement learning in a static VQA task, suggesting that it might be a weakness that could make the approach less data efficient and harder to train models using gradient descent. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks specific guidance on how to address this potential weakness or improve the approach. Without actionable suggestions or a clear direction for improvement, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a potential concern about the need for reinforcement learning in a static VQA task, suggesting it might be a weakness that could make the approach less data efficient and harder to train models using gradient descent. However, the comment does not specify which part of the paper this issue pertains to, nor does it provide detailed guidance on how to address this potential weakness. Without explicit references to specific sections or examples, the authors cannot confidently determine where to focus their efforts for improvement. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the need for reinforcement learning in a static VQA task may be a potential weakness, making the approach less data efficient and harder to train models using gradient descent. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without specific examples or detailed justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a potential concern about the need for reinforcement learning in a static VQA task, suggesting that it might be a weakness that could make the approach less data efficient and harder to train models using gradient descent. While the comment identifies a potential issue, it lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this concern. Without detailed feedback or recommendations, the authors are left without a clear path for improvement. Therefore, the comment is 3, as it points out a potential area for consideration but does not fully support the authors in making improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to include a table showing the distribution of video lengths across the dataset and to explain how they ensured a balanced representation of different video lengths across the 11 categories. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what needs to be done to address the issue. The comment is explicit and detailed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"benchmark\" and the \"distribution of videos of different lengths,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the inclusion of a table showing the distribution of video lengths across the dataset and an explanation of how the authors ensured a balanced representation of different video lengths across the 11 categories. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the distribution of videos of different lengths within the benchmark is crucial for assessing reasoning ability and robustness, but the paper does not provide relevant explanations. The reviewer suggests that the authors include a table showing the distribution of video lengths across the dataset and explain how they ensured a balanced representation of different video lengths across the 11 categories. This feedback is 4 as it provides a clear and logical reasoning for the importance of the distribution analysis, and it suggests specific actions for improvement. However, the comment could be strengthened by referencing similar studies or benchmarks that support the need for this analysis. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment is 5 as it identifies a critical aspect of the paper that is not adequately addressed: the distribution of videos of different lengths within the benchmark. It highlights the importance of this distribution for assessing reasoning ability and robustness, and it provides specific suggestions for improvement, such as including a table showing the distribution of video lengths and explaining how the authors ensured a balanced representation across the 11 categories. This feedback is actionable and detailed, offering the authors clear guidance on how to enhance their draft. Therefore, it aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly advises the authors to take a cautious approach regarding their contribution until the promised dataset is made publicly available. This is a clear and direct action for the authors to take, as it specifies the need to wait for the dataset to be accessible before making any claims or contributions based on it. The comment provides a concrete step for the authors to follow, making it 5.", "grounding_specificity_rationale": "The comment addresses the issue of the promised dataset not being publicly available, which is a specific concern regarding the contribution of the paper. However, it does not specify which part of the paper discusses the dataset or where the promise was made, making it weakly grounded. The comment is specific in its request for caution until the dataset is openly accessible, but without explicit references to the paper, the authors may struggle to pinpoint the exact sections needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the promised dataset has not been made publicly available, which is a factual statement. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment highlights a critical issue regarding the promised dataset not being publicly available, which is a significant concern for the contribution of the paper. By pointing out this gap, the comment provides the authors with a clear and actionable area for improvement. It advises the authors to take a cautious approach until the dataset is openly accessible, which is a logical and necessary step to ensure the validity and reproducibility of the research. However, the comment could be more helpful if it suggested ways to address this issue, such as providing a timeline for dataset release or offering alternative approaches to validate the findings. Overall, the comment is 4 as it identifies a critical problem and guides the authors toward a solution, but it could be more comprehensive with additional suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the results presented in Figure 3, specifically regarding the preactivation values of two networks and their output cosine similarity. It suggests that the results of the latter loss term of Equation 13 should be directly illustrated instead. While the comment implies that the authors should provide additional results or explanations, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to present the results or what additional information should be included. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 3 e\" and \"Eqn 13,\" allowing the authors to accurately identify the specific parts of the paper being addressed. It also specifies the issue by questioning the need to directly illustrate the results of the latter loss term of Equation 13, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the need to illustrate the results of the latter loss term of Equation 13, suggesting that the preactivation values of two networks are the same membrane potentials, which would result in a high output cosine similarity. This claim is based on logical reasoning and common knowledge about the similarity of preactivation values and cosine similarity. However, the comment lacks specific examples or references to support the claim fully, making it 3. The authors would need to consider the reasoning and potentially provide additional evidence to fully understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of results in Figure 3, specifically questioning the need to illustrate the results of the latter loss term of Equation 13. It provides a logical reasoning that the preactivation values of two networks are the same membrane potentials, which would result in a high output cosine similarity. This feedback is clear and actionable, as it suggests a potential improvement by directly illustrating the results of the latter loss term. However, the comment could be more helpful if it offered additional guidance on how to present these results or why they are important. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with further suggestions or explanations."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper should include a comparison with testtime adaptation (TTA) methods, such as AB, which also aim to adapt to outofdistribution data when the input data is disturbed by noise. The reviewer questions whether data processing is superior to model parameter adjustment and suggests making a comparison based on experimental results. While the comment implies that the authors should include a comparison with TTA methods, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to conduct the comparison or what metrics to use. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"video action recognition\" and \"testtime adaptation (TTA) methods,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting a comparison with TTA methods and questioning the superiority of data processing over model parameter adjustment. The comment provides a clear direction for improvement by recommending a comparison based on experimental results. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks comparison with testtime adaptation (TTA) methods, suggesting that such a comparison would be beneficial. The reviewer provides a logical reasoning by pointing out that TTA methods aim to adapt to outofdistribution data when the input data is disturbed by noise, and that these methods primarily focus on updating model parameters, while the paper focuses on adjusting input data. The reviewer questions whether data processing is superior to model parameter adjustment and suggests making a comparison based on experimental results. This reasoning is clear and provides a logical basis for the claim, making it 4. However, the comment could be strengthened by referencing specific TTA methods or providing more detailed examples of how such a comparison might be conducted. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a gap in the paper by pointing out the lack of comparison with testtime adaptation (TTA) methods, which are relevant to the topic of robustness in video action recognition. It suggests that such a comparison could be beneficial, as TTA methods also aim to adapt to outofdistribution data when the input data is disturbed by noise. The comment raises a valid point about the superiority of data processing over model parameter adjustment and encourages the authors to make a comparison based on experimental results. This feedback is clear and actionable, providing the authors with a specific direction for improving their draft by including a comparison with TTA methods. However, it could be more helpful if it offered guidance on how to conduct the comparison or what metrics to use. Overall, the comment is 4, as it effectively guides the authors toward enhancing their work by addressing a critical gap in their analysis."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies an error in the first expression for J(\u03b8) in Section 3.2.1, stating that it should be Q(st0, \u03c0\u03b8(st0)). This provides a clear and direct action for the authors to take, which is to correct the expression. The feedback is specific and leaves no ambiguity about what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the error in the first expression for J(\u03b8), stating that it should be Q(st0, \u03c0\u03b8(st0)). This provides clear guidance on what needs to be corrected. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the first expression for J(\u03b8) in Section 3.2.1 is incorrect and provides a correction. This is a factual statement that does not require verification or justification. It is a direct observation about the content of the paper, making it a normal statement and fitting the label \"No\".", "helpfulness_rationale": "The review comment identifies a specific error in the first expression for J(\u03b8) in Section 3.2.1, pointing out that it should be Q(st0, \u03c0\u03b8(st0)). This feedback is clear and actionable, providing the authors with a precise correction that needs to be made in their draft. By addressing this error, the authors can ensure the accuracy and correctness of their work, which is crucial for the integrity of their research. However, the comment could be more helpful if it explained why the correction is necessary or how it impacts the overall analysis. Despite this, the feedback is 4 as it directly guides the authors in improving their draft. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point consists of a series of corrections to be made in the manuscript, including changes to the text and references. These corrections are explicit and provide clear guidance on what needs to be changed, making the actions concrete. The authors know exactly what needs to be done to address the issues identified, ensuring a high level of actionability. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper (e.g., \"p.8\") and references, allowing the authors to accurately identify the parts being addressed. It is also specific because it details the corrections needed, such as capitalizing certain words in the references and correcting errors in the text. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a series of corrections to be made in the manuscript, including changes to the text and references. These corrections are factual and do not contain subjective opinions, judgments, or suggestions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a list of corrections to be made in the manuscript, including changes to the text and references. It specifies the exact words that need to be capitalized, such as \"ai\" in Amodei et al. (2016), \"bayesian\" in many of the papers, and \"Advances in neural information processing systems\" in several of the papers. Additionally, it corrects the publication details for Dusenberry et al. (2020), Osawa et al. (2019), and Swiatkowski et al. (2020). These specific and actionable suggestions are valuable for the authors, as they directly address errors and inconsistencies in the manuscript, helping to improve its accuracy and professionalism. However, the comment could be more helpful if it provided context or explanation for why these corrections are important. Overall, the feedback is 4, as it offers clear guidance for improving the draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly requests information about the model parameters for task 1 and the lambda value chosen for the Boltzmann policy. It also asks how the parameters were chosen, suggesting that maximum likelihood estimates might be used. These questions are clear and direct, providing the authors with specific actions to take to address the reviewer\"s concerns. The feedback is explicit and concrete, giving the authors a clear understanding of what information is needed and how to provide it. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"task 1\" and \"Boltzmann policy,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what information is missing, namely the model parameters for task 1 and the lambda value chosen for the Boltzmann policy. Additionally, it asks how the parameters were chosen, suggesting maximum likelihood estimates as a possibility. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of factual questions seeking clarification on specific parameters and their choices. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific gap in the paper by noting the absence of information about certain model parameters, such as those for task 1 and the lambda value for the Boltzmann policy. It also raises a question about how the parameters were chosen, suggesting maximum likelihood estimates as a possibility. This feedback is clear and actionable, as it directs the authors to provide missing information and clarifies the methodology used in parameter selection. By addressing these points, the authors can enhance the transparency and comprehensiveness of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to present this information effectively. Overall, the comment is 4, as it guides the authors toward improving the clarity and completeness of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the performance of applying Conditional Batch Norm (CBN) to layer 2 in addition to layers 3 and 4, compared to when CBN is applied to layers 4 and 3 only. It explicitly asks the authors to provide an explanation for this observation, suggesting that they should address the potential reasons for the observed performance deterioration. While the comment does not explicitly instruct the authors to include an explanation in the paper, the request for clarification implies that the authors should address this issue. The action is explicit but lacks concrete guidance on how to provide the explanation, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the application of Conditional Batch Norm (CBN) to layer 2, compared to when CBN is applied to layers 4 and 3 only, and asks for an explanation of why this might be happening. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the performance of applying Conditional Batch Norm (CBN) to layer 2 in addition to layers 3 and 4, compared to when CBN is applied to layers 4 and 3 only. The reviewer asks for an explanation of why this might be happening, which is a request for clarification rather than a claim. Therefore, the comment is factual and does not contain a claim, aligning with the label \"No\".", "helpfulness_rationale": "The review comment identifies a specific issue with the application of Conditional Batch Norm (CBN) in Table 2, noting that applying CBN to layer 2 in addition to layers 3 and 4 deteriorates performance for GuessWhat?! compared to when CBN is applied to layers 4 and 3 only. It raises a question about the potential reasons for this observation, prompting the authors to provide an explanation. This feedback is clear and actionable, as it directs the authors to address a specific aspect of their methodology that could impact the paper\"s results. By asking for an explanation, the comment encourages the authors to critically evaluate their findings and potentially improve their understanding of the phenomenon. However, it could be more helpful if it provided some initial thoughts or suggestions on possible explanations, which would make it fully actionable. Overall, the comment is 4, as it effectively guides the authors to enhance their draft by addressing a critical aspect of their methodology."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the proposed method\"s inability to handle headpose, which is deferred to future work. It questions why the method cannot condition headpose parameters similar to a previous work (Gafni et al. ICCV 2021). While the comment implies that the authors should address this issue, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as it lacks concrete guidance on how to incorporate the suggested approach or improve the method\"s capabilities. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed method\"s inability to handle headpose, which is a specific aspect of the paper being addressed. It also references a previous work (Gafni et al. ICCV 2021) that can control both facial expression and headpose, providing a clear basis for comparison. The comment is specific in its questioning of why the proposed method cannot condition headpose parameters similarly to the previous work. This level of detail helps the authors understand what needs to be addressed in their paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a claim about the proposed method\"s inability to handle headpose, which is deferred to future work. The reviewer questions why the method cannot condition headpose parameters similar to a previous work (Gafni et al. ICCV 2021). This claim is 3 as it references a specific previous work that addresses the issue, providing a basis for comparison. However, the comment lacks detailed reasoning or examples from the previous work to fully substantiate the claim. The authors would need to explore the referenced work to fully understand the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant limitation in the proposed method, specifically its inability to handle headpose. It questions why the method cannot condition headpose parameters similar to a previous work (Gafni et al. ICCV 2021), which is already able to control both facial expression and headpose. This feedback is clear and actionable, as it prompts the authors to address this limitation and potentially improve their method by incorporating the approach suggested by the previous work. However, the comment could be more helpful if it provided specific suggestions or examples on how to implement this improvement. Overall, the comment is 4 as it highlights a critical area for improvement and provides a direction for the authors to enhance their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a similarity between the spurious features discussed in Sections 3.1 and 3.2 and backdoor triggers, noting that both are artificial patterns that appear infrequently in the training set. It references specific examples from Chen et al. (2017) and Gu et al. (2019) to illustrate this point. The comment also mentions the wellknown impact of rare spurious examples on trained models. While the comment provides a clear comparison and references external work, it does not explicitly instruct the authors to make any changes or improvements to their draft. The action is implicit and somewhat vague, as the authors can infer that they should consider the implications of these similarities but are not given specific guidance on how to address them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1 and 3.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the similarity between the spurious features discussed in the paper and backdoor triggers, providing examples from external works (Chen et al., 2017, and Gu et al., 2019) to support the comparison. This level of detail helps the authors understand what needs to be addressed in their paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the spurious features in Sections 3.1 and 3.2 are similar to backdoor triggers, citing examples from Chen et al. (2017) and Gu et al. (2019). It also mentions the wellknown impact of rare spurious examples on trained models. The comment provides specific references to external works, which helps substantiate the claim. However, it could be more 5 if it included detailed explanations or examples of how these spurious features affect the model\"s performance. Overall, the comment is 4, as it provides a solid foundation for the claim but lacks some depth in its explanation. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a similarity between the spurious features discussed in Sections 3.1 and 3.2 and backdoor triggers, noting that both are artificial patterns that appear infrequently in the training set. It references specific examples from Chen et al. (2017) and Gu et al. (2019) to illustrate this point, which provides a clear comparison for the authors to consider. Additionally, the comment highlights the wellknown impact of rare spurious examples on trained models, which is a valuable insight for the authors to address. However, the comment could be more helpful if it offered suggestions on how the authors might address this similarity or its implications for their work. Despite this, the feedback is 4 as it provides relevant information and context for the authors to consider in improving their draft. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the structural optimization is a key component of the paper and has been emphasized multiple times. However, it notes that the optimization algorithm appears to be directly taken from previous works, which the reviewer finds confusing and reduces the contribution of the paper. While the comment highlights a potential issue with the originality of the optimization algorithm, it does not provide explicit guidance on how the authors should address this concern. The action is implicit and somewhat vague, as the authors are left to infer that they should either clarify the source of the optimization algorithm or demonstrate its novelty. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"structural optimization,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the optimization algorithm appears to be directly taken from previous works, which the reviewer finds confusing and reduces the contribution of the paper. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the structural optimization is a key component of the paper, but it is unclear whether this is a subjective opinion or a factual observation. The comment further suggests that the optimization algorithm is directly taken from previous works, which the reviewer finds confusing and reduces the contribution of the paper. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the claim remains 3, as it provides some justification but lacks comprehensive support. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the originality of the structural optimization algorithm, noting that it appears to be directly taken from previous works. This observation is relevant and could be a concern for the authors, as it may impact the novelty and contribution of their work. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as recommending alternative optimization algorithms or suggesting ways to differentiate their approach. While it highlights a critical area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the pipeline style method, which includes two models, does not provide better average results for both XVNLI and MaRVL. Additionally, it notes that the baseline models in the experiments are not well introduced. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to improve the introduction of baseline models or how to enhance the pipeline style method to achieve better results. Without specific suggestions or instructions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the performance of the pipeline style method, which includes two models, and the introduction of baseline models in the experiments. However, it does not specify which sections of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact parts that need attention. The comment is specific in its critique of the results and the introduction of baseline models, but it lacks grounding as it does not explicitly mention the sections where these issues are discussed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the pipeline style method, which includes two models, does not provide better average results for both XVNLI and MaRVL. Additionally, it notes that the baseline models in the experiments are not well introduced. However, the comment lacks specific examples, detailed reasoning, or references to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies two main issues with the paper: the performance of the pipeline style method, which includes two models, and the introduction of baseline models in the experiments. It points out that the method does not provide better average results for both XVNLI and MaRVL, which is a critical observation. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might improve the performance or introduce the baseline models more effectively. Without detailed feedback or examples, the authors are left with a general understanding of the issues but without a clear path to address them. Therefore, the comment is 3, as it highlights areas for improvement but does not offer comprehensive guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the authors primarily focus on SSC and do not contrast their method with other subsequent methods, such as TSC and greedy subspace clustering by Park, which are computationally efficient and have similar guarantees. While the comment highlights an area for improvement, it does not provide explicit guidance on how the authors should address this issue or suggest specific methods for comparison. The action is implicit and somewhat vague, as the authors are left to infer that they should include comparisons with these methods but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights a focus on SSC and suggests that the authors should contrast their method with other subsequent methods, such as TSC and greedy subspace clustering by Park, which are computationally efficient and have similar guarantees. However, it does not specify which part of the paper this critique pertains to, making it weakly grounded. The comment is specific in its suggestion to include comparisons with these methods, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors primarily focus on SSC and do not contrast their method with other subsequent methods, such as TSC and greedy subspace clustering by Park, which are computationally efficient and have similar guarantees. The comment provides a logical reasoning by suggesting that the authors should include comparisons with these methods to demonstrate the effectiveness of their approach. However, it lacks specific examples or references to these subsequent methods, which would strengthen the claim. Therefore, the comment is 3, as it provides a logical basis for the suggestion but requires more detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, noting that the authors primarily focus on SSC and do not contrast their method with other subsequent methods, such as TSC and greedy subspace clustering by Park, which are computationally efficient and have similar guarantees. This feedback is clear and actionable, as it suggests that the authors should include comparisons with these methods to demonstrate the effectiveness of their approach. However, the comment could be more helpful if it provided specific guidance on how to conduct these comparisons or what aspects to focus on. Overall, the comment is 4 as it directs the authors to a critical area for enhancement, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights that the contributions of the paper are small compared to previous methods, such as NCNet [6] and Sparse NCNet [21], and that it mostly consists of engineering improvements. It also notes that it is challenging to differentiate the current work from its predecessors due to similar performance. However, the comment does not provide any explicit or implicit actions for the authors to take in response to these observations. It lacks guidance on how to address the concerns or improve the paper, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the paper\"s contributions, suggesting that they are small and mostly engineeringbased, and notes the difficulty in differentiating it from its predecessors. However, it does not specify which parts of the paper are being addressed, such as specific sections, experiments, or results that highlight these contributions. Additionally, while it provides some insight into the perceived lack of differentiation, it does not offer specific guidance on how to address this issue or improve the paper. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the contributions of the paper are small and mostly engineeringbased, and it is difficult to differentiate it from its predecessors due to similar performance. However, the comment does not provide specific examples or references to support this claim, such as comparing the performance of the current work with that of NCNet [6] and Sparse NCNet [21]. Without detailed evidence or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment critiques the paper for its small contributions compared to previous methods, such as NCNet [6] and Sparse NCNet [21], and suggests that it primarily consists of engineering improvements. It also notes that it is challenging to differentiate the current work from its predecessors due to similar performance. However, the comment lacks specificity and does not provide actionable feedback or suggestions for improvement. It does not offer guidance on how the authors might differentiate their work or enhance its originality. As a result, the comment is not particularly helpful, as it identifies a potential issue but does not assist the authors in addressing it effectively. Therefore, it aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to remove statements about semantic segmentation being a lowlevel cue from the paper. This is a clear and direct action that the authors can take to address the comment. The feedback is specific and provides a concrete step for improvement, making it 5.", "grounding_specificity_rationale": "The comment addresses the issue of semantic segmentation being classified as a lowlevel cue, suggesting that this classification is incorrect. However, it does not specify which part of the paper discusses this classification or where the statements about semantic segmentation being a lowlevel cue are located. Without explicit references to sections or specific statements, the authors may find it challenging to pinpoint the exact parts of the paper that need revision. Therefore, the comment is weakly grounded as it does not provide clear guidance on where to make changes. However, it is specific in its suggestion to remove the statements about semantic segmentation being a lowlevel cue. This makes the comment 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that \"semantic\" segmentation is not lowlevel since the categories are specified for each pixel. This claim is based on a logical reasoning that the level of detail in semantic segmentation makes it a higherlevel cue. However, the comment lacks specific examples or references to support this claim, which would help the authors understand the basis of the argument. Without detailed evidence or examples, the claim is 3, as it provides a logical rationale but lacks comprehensive support.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the classification of semantic segmentation as a lowlevel cue. It provides a clear and actionable suggestion to remove statements about semantic segmentation being a lowlevel cue, which is a direct and constructive piece of feedback. By addressing this point, the authors can ensure that their paper accurately reflects the nature of semantic segmentation. However, the comment could be more helpful if it provided additional context or examples to further clarify the distinction between lowlevel and highlevel cues. Overall, the feedback is 4 as it guides the authors toward a specific improvement in their draft."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy in the ablation experiment, noting that the performance without reinforcement learning dropped lower than without dependency tree. It also points out that the tables do not include cases where both dependency tree and reinforcement learning are not used. While the comment identifies a potential issue with the presentation of the results, it does not provide explicit guidance on how to address this issue or suggest specific actions for the authors to take. The feedback is implicit and somewhat vague, as it lacks concrete instructions on how to improve the presentation of the results. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"ablation experiment\" and the \"two tables,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out a discrepancy in the results, noting that the performance without reinforcement learning dropped lower than without dependency tree, and it highlights the absence of cases where both dependency tree and reinforcement learning are not used. This provides clear guidance on what needs to be addressed in the results section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point highlights a discrepancy in the ablation experiment, noting that the performance without reinforcement learning dropped lower than without dependency tree. It also points out that the tables do not include cases where both dependency tree and reinforcement learning are not used. This is a factual observation about the presentation of the results, which does not require verification or justification. The comment does not contain subjective opinions, suggestions, or claims that need to be supported. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of the results in the ablation experiment. It points out that the performance without reinforcement learning dropped lower than without dependency tree, and it notes that the tables do not include cases where both dependency tree and reinforcement learning are not used. This feedback is clear and actionable, as it highlights a potential error or omission in the results that the authors need to address. By pointing out this discrepancy, the comment provides the authors with a clear direction for improving the clarity and accuracy of their results presentation. However, the comment could be more helpful if it suggested ways to address this issue, such as including additional cases or clarifying the methodology. Overall, the comment is 4, as it effectively directs the authors to a specific area needing improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the vulnerability discovery methodology, specifically questioning the ecological validity of considering a single vulnerability at a time. It suggests that previous work has considered multiple CVEs or CWEs simultaneously and questions whether the authors are arguing that identifying one vulnerability at a time is an intended use case. The comment also notes that the results are difficult to interpret or are marginal improvements at best. While the comment implies that the authors should clarify their methodology and its implications, it does not provide explicit guidance on how to address these concerns. The action is implicit and somewhat vague, as the authors need to infer that they should clarify their methodology and its implications. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the vulnerability discovery methodology, specifically questioning the ecological validity of considering a single vulnerability at a time. It references previous work that considers multiple CVEs or CWEs simultaneously and questions the authors\" approach. However, the comment does not explicitly mention which part of the paper discusses this methodology, making it weakly grounded. The comment is specific in detailing the issue with the methodology and suggesting that the results are difficult to interpret. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the vulnerability discovery methodology, specifically questioning the ecological validity of considering a single vulnerability at a time. The reviewer references previous work that considers multiple CVEs or CWEs simultaneously and suggests that the results are difficult to interpret or are marginal improvements at best. This claim is 3 as it provides a logical reasoning based on the comparison with previous work, but it lacks specific references or detailed examples to fully substantiate the critique. The authors would need to explore the referenced literature to fully understand the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a significant concern about the vulnerability discovery methodology used in the paper. It questions the ecological validity of considering a single vulnerability at a time, noting that previous work has considered multiple CVEs or CWEs simultaneously. The comment also points out that the results are difficult to interpret or are marginal improvements at best. This feedback is valuable as it highlights a potential weakness in the study\"s methodology and suggests that the authors should clarify their approach and its implications. However, the comment could be more helpful if it provided specific suggestions on how to address these concerns or offered examples of alternative methodologies. Overall, the comment is 3 as it identifies a critical area for improvement but lacks detailed guidance for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights the need for more explanation regarding how a small degree of bias can be obtained from a clear community structure. It references Theorem 1 and 2, which prove that GCL conforms to a clearer community structure, but notes that the relationship with degree bias is not intuitive enough. While the comment identifies a gap in the explanation, it does not provide explicit guidance on how to address this issue or suggest specific steps for improvement. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide a more detailed explanation of the relationship between community structure and degree bias. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 1 and 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the need for more explanation regarding the relationship between a small degree of bias and a clear community structure, as well as the lack of intuitive understanding of the relationship between GCL and degree bias. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the relationship between a small degree of bias and a clear community structure is not intuitive enough, despite Theorem 1 and 2 proving that GCL conforms to a clearer community structure. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed explanation or references leaves the claim 3, as it requires more information to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by suggesting that the relationship between a small degree of bias and a clear community structure needs more explanation. It references Theorem 1 and 2, which prove that GCL conforms to a clearer community structure, but notes that the relationship with degree bias is not intuitive enough. This feedback is clear and actionable, as it directs the authors to provide a more detailed explanation of the relationship between these concepts. However, the comment could be more helpful if it offered specific suggestions on how to enhance the explanation or provided examples of similar approaches in the literature. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the construction of clean exemplar manifolds for nonstochastic networks, specifically asking how the denominator of Figure 2.c is computed for ResNet50 and ATResNet50 networks. While the comment does not explicitly instruct the authors to clarify or revise their methodology, it implies that the authors should provide additional explanation or clarification regarding this aspect of their work. The action is implicit and somewhat vague, as it does not specify exactly what information should be added or how to address the question. However, the authors can infer that they need to provide more details on the construction of clean exemplar manifolds for nonstochastic networks. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (182183) and figures (2.c) in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies the issue by questioning the construction of clean exemplar manifolds for nonstochastic networks and how the denominator of Figure 2.c is computed for ResNet50 and ATResNet50 networks. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the construction of clean exemplar manifolds for nonstochastic networks, specifically asking how the denominator of Figure 2.c is computed for ResNet50 and ATResNet50 networks. The comment does not contain subjective opinions, suggestions, or judgments that require verification. It is a factual question seeking clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the construction of clean exemplar manifolds for nonstochastic networks, specifically asking how the denominator of Figure 2.c is computed for ResNet50 and ATResNet50 networks. This feedback is 3 as it identifies a potential gap in the explanation or methodology of the paper. However, it lacks specific suggestions or guidance on how the authors might address this issue or clarify their approach. While it prompts the authors to consider this aspect, it does not provide detailed actionable steps or examples, leaving the authors with a general direction but not a comprehensive plan for improvement. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point claims that the originality of the paper is limited because the main idea of variable splitting is not new and the algorithm is not new. However, it does not provide any specific guidance or suggestions on how the authors could address this issue or improve the originality of their work. There is no explicit or implicit action for the authors to take, leaving them without any direction on how to enhance the originality of their paper. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment claims that the originality of the paper is limited because the main idea of variable splitting is not new and the algorithm is not new. However, it does not specify which part of the paper this claim pertains to, such as a specific section or methodology. Without explicit references to sections or elements of the paper, the authors cannot confidently determine which parts need attention. Additionally, the comment lacks specificity regarding what aspects of the originality are lacking or how the authors could address these issues. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the originality of the paper is limited because the main idea of variable splitting is not new and the algorithm is not new. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without specific details or references to existing works that have already explored variable splitting or similar algorithms, the claim remains 1. The authors are left without a clear understanding of why the originality is limited or how to address this issue. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment claims that the originality of the paper is limited because the main idea of variable splitting is not new and the algorithm is not new. However, it does not provide any specific examples or references to existing works that have already explored variable splitting or similar algorithms. Without detailed guidance or suggestions for improvement, the comment lacks actionable feedback that could help the authors enhance the originality or novelty of their work. As a result, the comment is 1, as it does not offer any constructive direction for the authors to address the issue raised."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should discuss and compare their work with the AAAI15 paper by Ghoshdastidar and Dukkipati, which deals with hypergraph data using tensors. This feedback is explicit and provides a clear action for the authors to take, which is to include a discussion and comparison with this related work. The comment also specifies the reason for this action, highlighting the relevance of the AAAI15 paper to the authors\" work. Therefore, the comment is 5, as it gives the authors a direct and concrete step to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the AAAI15 paper by Ghoshdastidar and Dukkipati, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of a discussion and comparison with this related work. This provides clear guidance on how to improve the paper by ensuring it covers relevant stateoftheart work. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the AAAI15 paper by Ghoshdastidar and Dukkipati is a related work that should be discussed and compared against to provide a better understanding of the stateoftheart. The comment provides a specific reference to the AAAI15 paper, which is a clear and explicit source of evidence supporting the claim. This makes the claim 5, as it is based on a concrete reference that the authors can easily verify or address in their work. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a potential gap in the authors\" work by pointing out a related paper, \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications\" by Ghoshdastidar and Dukkipati, which deals with hypergraph data using tensors. The comment suggests that this paper should be discussed and compared against to provide a better understanding of the stateoftheart. This feedback is clear and actionable, as it directs the authors to include a discussion and comparison with this related work, which can enhance the comprehensiveness and relevance of their paper. However, the comment could be more helpful if it provided specific guidance on how to integrate this comparison or discussed potential insights that could be gained from it. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment indicates that the paper is difficult to follow, specifically mentioning issues with understanding the experimental procedures and evaluations. However, it does not provide any explicit or implicit suggestions for improvement. There is no guidance on how the authors might clarify or simplify the experimental procedures or evaluations to make the paper more accessible. Without actionable advice or specific recommendations, the authors are left without a clear path to address the issues raised. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment indicates that the paper is difficult to follow, specifically mentioning issues with understanding the experimental procedures and evaluations. However, it does not specify which part of the paper is particularly challenging to follow, making it weakly grounded. The comment is specific in identifying the issue of clarity in the experimental procedures and evaluations, but without explicit references to sections or figures, the authors cannot pinpoint the exact areas needing improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is difficult to follow, specifically mentioning issues with understanding the experimental procedures and evaluations. However, the comment does not provide any specific examples or detailed reasoning to support this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment indicates that the paper is difficult to follow, specifically mentioning issues with understanding the experimental procedures and evaluations. However, it does not provide any specific suggestions or guidance on how the authors might improve the clarity or organization of their work. Without actionable feedback or detailed advice, the authors are left without a clear path to address the issues raised. Therefore, the comment is 1, as it does not offer any constructive direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states that the claim in section 2 about INRs operating on a perdatainstance basis is true but does not consider it an advantage. The reviewer suggests that a model that can only handle a single time series data is almost useless. While the comment identifies a potential issue with the claim, it does not provide specific guidance on how the authors should address this concern or improve their draft. The action is explicit but lacks concrete details on how to implement the suggested change. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 2\" and a specific claim within that section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim, pointing out that while it is true, it is not considered an advantage due to the limitation of handling only a single time series data. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that a model that can only handle a single time series data is almost useless, but it does not provide any supporting evidence or reasoning to substantiate this claim. The comment lacks specific examples or references to justify why this limitation is problematic or how it affects the model\"s utility. Without additional context or evidence, the claim remains 1, as the authors would need to infer the basis of the critique themselves. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific claim in section 2 of the paper regarding the operation of INRs on a perdatainstance basis. It points out that while the claim is true, it is not considered an advantage because a model that can only handle a single time series data is almost useless. This feedback is 3 as it highlights a potential limitation in the paper\"s claims, prompting the authors to reconsider the significance of their findings. However, the comment could be more helpful if it provided suggestions on how to address this limitation or offered alternative perspectives on the utility of the model. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should introduce specific aspects of the model that are relevant to the example model being discussed. It provides a concrete example of what should be clarified, such as the fact that the model operates in a setting with finite subdivisions for certain parameters and that some parameters are bounded on one side. This feedback is explicit and provides clear guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions line 132, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be introduced, namely the specific aspects of the model that are relevant to the example model being discussed. The comment specifies that certain parameters are bounded on one side and that the model operates in a setting with finite subdivisions. This level of detail provides the authors with a clear understanding of what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors should clarify specific aspects of the model, such as the finite subdivisions for certain parameters and the bounded nature of some parameters. However, the comment does not provide any specific reasoning or evidence to support why these clarifications are necessary or how they would improve the paper. Without additional context or examples, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 2.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors introduce the specific aspects of the model that are relevant to the example model being discussed. It highlights the need to clarify that the model operates in a setting with finite subdivisions for certain parameters and that some parameters are bounded on one side. This feedback is clear and offers a concrete way for the authors to enhance the clarity and comprehensiveness of their draft. By addressing these points, the authors can improve the readability and understanding of their work for both experts and nonexperts. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a limitation in the experiments, specifically noting that most experiments are limited to RoBERTabase and questioning the generalizability of the results to other models. It suggests investigating the generalizability to differences in model size, objective function, and architecture, and explicitly mentions the inclusion of more analysis and discussion for GPT2. The reviewer provides a specific example by requesting the results of Figure 2 for GPT2. This feedback is explicit and provides concrete guidance on what the authors should do to improve their draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.1.1\" and \"Figure 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the experiments, noting the limited scope to RoBERTabase and the need for generalization to other models. The comment further specifies the areas that require more analysis and discussion, such as GPT2, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments are limited to RoBERTabase and questions the generalizability of the results to other models. It suggests investigating the generalizability to differences in model size, objective function, and architecture. The comment provides a specific example by requesting the results of Figure 2 for GPT2, which adds a level of detail to the claim. However, the comment lacks references or detailed reasoning to fully substantiate the claim about the limitations of the experiments. Therefore, the claim is 3, as it provides a basis for the claim but requires more detailed evidence or examples to be fully supported.", "helpfulness_rationale": "The review comment identifies a limitation in the experiments, specifically noting that most experiments are limited to RoBERTabase and questioning the generalizability of the results to other models. It suggests investigating the generalizability to differences in model size, objective function, and architecture, and provides a specific example by requesting the results of Figure 2 for GPT2. This feedback is clear and actionable, as it directs the authors to expand their analysis and discussion to include more models, such as GPT2. By addressing this feedback, the authors can enhance the robustness and applicability of their findings, making the comment 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the applicability of the parameters, model, and experiments to areas beyond image data and ViT. It suggests that the authors should consider applying their principles to other research areas, such as NLP or simpler models in the image domain (CNNs), to demonstrate generalizability. While the comment implies that the authors should explore these areas, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement this exploration. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1\" and \"the model and the experiments,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the applicability of the parameters, model, and experiments to areas beyond image data and ViT, suggesting that the authors should explore other research areas such as NLP or simpler models in the image domain. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a claim about the applicability of the parameters, model, and experiments to areas beyond image data and ViT. It suggests that the authors should explore other research areas, such as NLP or simpler models in the image domain, to demonstrate generalizability. The comment provides a logical reasoning by questioning the focus on stateoftheart performance and suggesting that the method should be tested on different architectures and tasks. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to provide additional evidence or context to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the applicability of the parameters, model, and experiments to areas beyond image data and ViT. It suggests that the authors should explore other research areas, such as NLP or simpler models in the image domain, to demonstrate the generalizability of their method. This feedback is clear and actionable, as it provides a specific direction for the authors to expand their work and improve its relevance. However, the comment could be more helpful if it offered additional guidance on how to approach these other areas or what specific aspects to focus on. Overall, the comment is 4, as it effectively guides the authors toward enhancing the scope and applicability of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the required condition on the learning rate, specifically its scalability and the unrealistic nature of the condition. The reviewer acknowledges the need for a way to characterize the benefit of large learning rates but questions the practicality of the condition. While the comment highlights an issue, it does not provide explicit guidance or suggestions on how the authors might address this concern. The action is implicit and somewhat vague, as the authors are left to infer that they should reconsider the condition or find an alternative approach. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the required condition on the learning rate, specifically its scalability and the unrealistic nature of the condition. However, it does not specify which part of the paper discusses this condition, making it weakly grounded. The comment is specific in detailing the issue with the condition and the need for a more realistic approach, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact part of the paper that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the required condition on the learning rate, which scales with the number of samples, is not scalable and is unrealistic. The reviewer provides a logical reasoning by stating that they have never seen a step size grow with the sample size in practice, which would lead to unreasonably large learning rates for largescale datasets. This reasoning is based on common knowledge and experience in the field, making the claim 3. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the required condition on the learning rate, which scales with the number of samples. It points out that this condition is not scalable and is unrealistic, as step sizes are not typically seen to grow with the sample size in practice. The reviewer acknowledges the need for a way to characterize the benefit of large learning rates but questions the practicality of the condition itself. While the comment highlights a potential weakness in the paper, it does not provide specific suggestions or guidance on how the authors might address this issue or explore alternative approaches. The feedback is 3 as it prompts the authors to reconsider the condition, but it lacks actionable advice, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment acknowledges that the abstract does a good job explaining the proposed idea but points out a lack of description regarding how the idea was evaluated and what the outcome was. It also mentions minor language issues. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues or what specific changes should be made to improve the abstract. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more details about the evaluation and outcome, as well as address the language issues. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of description regarding how the proposed idea was evaluated and what the outcome was, as well as minor language issues. This provides clear guidance on what needs to be addressed in the abstract. Therefore, this comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point claims that the abstract does a good job explaining the proposed idea but lacks description of how the idea was evaluated and what the outcome was. The comment also mentions minor language issues. However, it does not provide specific examples or detailed reasoning to support the claim about the lack of evaluation or outcome description. Additionally, the mention of minor language issues is vague and lacks context. Without detailed justification or examples, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient evidence or explanation to fully substantiate the claims.", "helpfulness_rationale": "The review comment identifies a specific weakness in the abstract, noting that it effectively explains the proposed idea but lacks description of how the idea was evaluated and what the outcome was. This feedback is clear and actionable, as it directs the authors to enhance the abstract by including details about the evaluation and outcomes. However, the comment could be more helpful if it provided specific suggestions on how to present this information or examples of what might be included. Despite this, the comment is 4 as it guides the authors toward improving the clarity and completeness of their abstract."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment expresses skepticism about the experimental results and questions the usefulness of the experiments section. It points out that the paper aims to solve POMDP problems with nonconvex value functions but does not provide experiments on the specific settings mentioned, such as surveillance in museums with thresholded rewards or privacypreserving data collection. The comment implies that the authors should include experiments on these settings to better motivate their solution. However, it does not explicitly instruct the authors to conduct these experiments or provide detailed guidance on how to implement them. The action is implicit and somewhat vague, as the authors can infer that they need to add experiments but are not given specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental results\" and the \"POMDP problem with nonconvex value function,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the lack of experiments on specific settings, such as surveillance in museums with thresholded rewards or privacypreserving data collection. This provides clear guidance on what needs to be addressed in the experiments section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point expresses skepticism about the experimental results, questioning the usefulness of the experiments section. It suggests that the paper should include experiments on specific settings, such as surveillance in museums with thresholded rewards or privacypreserving data collection, to better motivate the solution. However, the comment lacks specific examples or detailed reasoning to support why these experiments are necessary or how they would improve the paper. The lack of concrete evidence or detailed justification makes the claim 3, as the authors would need to infer the importance of these experiments based on the general critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a significant concern about the experimental results, questioning their relevance and usefulness. It points out that the paper aims to solve POMDP problems with nonconvex value functions but does not provide experiments on specific settings mentioned, such as surveillance in museums with thresholded rewards or privacypreserving data collection. This feedback is clear and actionable, as it highlights a gap in the experimental section that the authors need to address to better motivate their solution. However, the comment could be more helpful if it provided specific suggestions on how to incorporate these experiments or what additional data or analysis would be beneficial. Overall, the comment is 4 as it identifies a critical area for improvement and guides the authors toward enhancing the experimental section of their paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that an epochwise analysis, particularly for finite sum settings, could provide insights into the behaviors of optimization algorithms. It proposes investigating the effects of batch size and different sampling strategies on the progress of algorithms after every full pass of data. Additionally, it suggests that this analysis could aid in comparative analysis of deterministic and stochastic methods. While the comment implies that the authors should consider including an epochwise analysis, it does not explicitly instruct them to do so or provide detailed guidance on how to implement this analysis. The action is implicit and somewhat vague, as the authors can infer the need for an epochwise analysis but may not be entirely sure of the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests an analysis of epochwise behavior, particularly for finite sum settings, to gain insights into optimization algorithms. It proposes investigating the effects of batch size and different sampling strategies on the progress of algorithms after every full pass of data. Additionally, it mentions the potential for comparative analysis of deterministic and stochastic methods. However, the comment does not specify which part of the paper this analysis should be included in, making it weakly grounded. The suggestion is specific in terms of the type of analysis and potential insights it could provide, but without explicit references to sections or figures, the authors may find it challenging to pinpoint where to incorporate this feedback. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that an epochwise analysis, particularly for finite sum settings, could provide insights into the behaviors of optimization algorithms. It proposes investigating the effects of batch size and different sampling strategies on the progress of algorithms after every full pass of data. The comment also mentions the potential for comparative analysis of deterministic and stochastic methods. While the suggestion is logical and provides a clear direction for further analysis, it lacks specific examples or references to support the claim. This makes the comment 3, as it provides a reasonable basis for the suggestion but requires more detailed justification or evidence to be fully convincing.", "helpfulness_rationale": "The review comment suggests a potential area for improvement by proposing an epochwise analysis, particularly for finite sum settings, to gain insights into the behaviors of optimization algorithms. It provides a specific example of investigating the effects of batch size and different sampling strategies on the progress of algorithms after every full pass of data. Additionally, it mentions the potential for comparative analysis of deterministic and stochastic methods. This feedback is clear and actionable, offering the authors a concrete direction for enhancing their analysis and understanding of their results. However, it could be more helpful if it included specific suggestions on how to implement this analysis or examples of similar studies that have used epochwise analysis. Overall, the comment is 4 as it provides a valuable insight into improving the paper."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a specific issue with the paper\"s classification of extreme speech, noting that the distinction between derogatory and exclusionary extreme speech is unclear. It provides a concrete example from the sample data file, asking why a particular instance is classified as exclusionary extreme speech but derogatory extreme speech. The comment also raises questions about the role of local regulations in annotations and their impact on zeroshot crosscountry classification. While the comment identifies a clear issue and provides specific examples, it does not explicitly instruct the authors on how to address these concerns. The action is implicit but concrete, as the authors can infer that they need to clarify the classification criteria and potentially address the impact of local regulations. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Paper Summary\" section, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the need for a clear distinction between the three classes of extreme speech and provides a specific example from the sample data file to illustrate the difficulty in differentiating derogatory and exclusionary extreme speech. The comment further questions the role of local regulations in annotations and their impact on zeroshot crosscountry classification. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with a score of 5.", "verifiability_rationale": "The review point raises a concern about the clarity of the distinction between derogatory and exclusionary extreme speech, specifically questioning the classification of an instance in the sample data file. The reviewer provides a detailed example and asks for clarification on the role of local regulations in annotations. This level of specificity and the inclusion of a concrete example make the claim 4. However, the comment could be strengthened by providing more detailed reasoning or references to support the claim about the impact of local regulations on zeroshot crosscountry classification. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment is 5 as it identifies a specific area of concern in the paper\"s classification of extreme speech. It provides a clear example from the sample data file, highlighting the difficulty in differentiating derogatory and exclusionary extreme speech. The comment also raises questions about the role of local regulations in annotations and their impact on zeroshot crosscountry classification. By offering a concrete example and prompting further clarification, the reviewer provides the authors with actionable feedback that can significantly improve the clarity and robustness of their classification system. This level of detail and specificity makes the comment 5, as it empowers the authors to address a critical issue in their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to include a graph showing the plot of T versus the number of images and Expectation(T) over the ImageNet test set. This provides a clear and direct action for the authors to take, as it specifies exactly what needs to be added to the draft. The comment also offers a rationale for why this information is important, which further clarifies the action. Therefore, the comment is 5, as it provides explicit guidance and concrete details on how to implement the suggested change.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for a graph showing the plot of T versus the number of images and Expectation(T) over the ImageNet test set. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be added to the paper, namely, a graph to understand the performance improvement and whether it stems from the network design or the nature of ImageNet. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should include a graph showing the plot of T versus the number of images and Expectation(T) over the ImageNet test set. The reviewer provides a logical reasoning for why this information is important, stating that it would help understand whether the performance improvement stems from the network design or the nature of ImageNet. However, the comment lacks specific references or examples to support the claim that the nature of ImageNet provides an unfair advantage. While the reasoning is clear, the absence of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors include a graph showing the plot of T versus the number of images and Expectation(T) over the ImageNet test set. This request is clear and directly addresses a gap in the paper, offering a concrete way for the authors to enhance their analysis and understanding of the performance improvement. The comment also raises an important question about whether the performance improvement is due to the network design or the nature of ImageNet, which is a valuable consideration for the authors to explore. However, the comment could be more helpful if it provided additional context or examples to further guide the authors in interpreting the results. Overall, the feedback is 4 as it offers clear and actionable suggestions for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors need to change the notation to make it mathematically correct, unless doing so would make other equations messy. It also points out that the notation L_l should be introduced beforehand. While the comment implies that changes are needed, it does not provide explicit instructions on how to make these changes or what specific aspects need to be addressed. The action is implicit and somewhat vague, as the authors can infer that they need to revise the notation but are not given detailed guidance on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig.\" and \"L_l,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear feedback on the need for mathematical correctness and the introduction of notation, specifying what needs to be addressed. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the notation used in the paper, specifically \"L_l\" instead of \"L,\" needs to be changed to be mathematically correct. The reviewer provides a logical reasoning by stating that this change might affect other equations, implying that the current notation is incorrect. However, the comment lacks specific examples or references to support the claim that the current notation is problematic. This makes the claim 3, as the authors would need to investigate the potential issues themselves to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper: the need for mathematical correctness and the introduction of notation. It suggests that the notation \"L_l\" should be changed to \"L\" and that this change should be introduced beforehand. This feedback is clear and actionable, providing the authors with concrete steps to improve the mathematical rigor and clarity of their work. However, the comment could be more helpful if it explained why the current notation is problematic or how it might affect other equations. Despite this, the comment is 4 as it directs the authors to make specific improvements that can enhance the quality of their draft. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the effectiveness of the proposed methods when the training and evaluation timesteps are the same, as shown in Figure 5. It suggests that the proposed method might be more effective under scenarios where the training and evaluation timesteps are different. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to improve the draft. The action is implicit and somewhat vague, as it leaves the authors to infer that they should explore scenarios with different timesteps but does not specify how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the effectiveness of the proposed methods when the training and evaluation timesteps are the same. The comment suggests that the proposed method might be more effective under scenarios where the training and evaluation timesteps are different. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the effectiveness of the proposed methods is questionable when the training and evaluation timesteps are the same, as shown in Figure 5. The reviewer suggests that the proposed method might be more effective under scenarios where the training and evaluation timesteps are different. However, the comment lacks specific examples or detailed reasoning to support this claim. It provides a logical suggestion but does not fully substantiate the claim with evidence or references, making it 3. The authors would need to explore this suggestion further to fully understand and address the issue.", "helpfulness_rationale": "The review comment raises a valid concern about the effectiveness of the proposed methods when the training and evaluation timesteps are the same, as shown in Figure 5. It questions the significance of the proposed methods in achieving good performance when the timesteps are identical. The comment suggests that the proposed method might be more effective under scenarios where the training and evaluation timesteps are different. This feedback is clear and actionable, as it prompts the authors to explore and discuss scenarios where the timesteps differ, potentially leading to a more comprehensive understanding of the method\"s effectiveness. However, the comment could be more helpful if it provided specific examples or suggestions on how to address this issue. Overall, the comment is 4, as it directs the authors to a critical area for improvement in their draft."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a concern about the clarity of how disentanglement is guaranteed in the paper. It suggests that while the \"Broader Impacts and Limitations\" section mentions disentanglement as a limitation, it is still important to highlight how disentanglement is realized and guaranteed without certain bias types. This feedback provides a clear and explicit action for the authors to take, which is to further elaborate on the disentanglement process and its guarantees. The comment is specific and actionable, as it directs the authors to address a particular aspect of their work. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the issue of disentanglement, specifically questioning how it is guaranteed and suggesting that the authors highlight how disentanglement is realized and guaranteed without certain bias types. However, it does not specify which part of the paper discusses disentanglement, making it weakly grounded. The comment is specific in detailing what needs to be addressed regarding disentanglement, such as highlighting how it is realized and guaranteed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the clarity of how disentanglement is guaranteed in the paper. It references the \"Broader Impacts and Limitations\" section, which mentions disentanglement as a limitation, but suggests that further explanation is needed. The comment provides a logical reasoning by pointing out the importance of highlighting how disentanglement is realized and guaranteed without certain bias types. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to provide additional details or evidence to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the clarity of how disentanglement is guaranteed in the paper. It points out that while the \"Broader Impacts and Limitations\" section mentions disentanglement as a limitation, it is still important to highlight how disentanglement is realized and guaranteed without certain bias types. This feedback is clear and actionable, as it directs the authors to provide more detailed information on the disentanglement process and its guarantees. By addressing this feedback, the authors can enhance the clarity and comprehensiveness of their paper. Therefore, the comment is rated as 4, as it provides valuable guidance for improvement but could be more comprehensive with additional suggestions or examples."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests including a learning curve for a model without mean teacher or pi regularization in the left graph of Figure 3. This provides a clear and direct action for the authors to take, as it specifies exactly what needs to be added to the figure for comparison. The suggestion is concrete, as it outlines a specific addition that would help clarify the impact of mean teacher and pi regularization on learning. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be included in the left graph of Figure 3: the learning curve for a model without mean teacher or pi regularization. This provides clear guidance on what the authors should add to their figure for comparison. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests including a learning curve for a model without mean teacher or pi regularization in the left graph of Figure 3 to compare the impact of these techniques on learning. This is a logical suggestion to enhance the clarity and comprehensiveness of the figure, but it does not contain any subjective claims, opinions, or judgments that require verification. It is purely a request for additional information or clarification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the paper. It recommends including a learning curve for a model without mean teacher or pi regularization in the left graph of Figure 3, which would allow for a direct comparison of the impact of these techniques on learning. This feedback is clear and offers a concrete way for the authors to enhance the clarity and comprehensiveness of their results. By addressing this suggestion, the authors can provide a more detailed analysis of the effectiveness of their approach. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the handling of different types of inputs, such as biomedical signals or speech, and suggests that the authors should discuss and present their solutions in the paper. While the comment implies that the authors should address this issue, it does not provide specific guidance on how to do so or what aspects of the solutions should be discussed. The mention of \"citation\" being \"a bit disordered\" is vague and does not offer actionable advice. Therefore, the comment is 3, as it identifies an area for improvement but lacks concrete details on how to implement the suggested changes.", "grounding_specificity_rationale": "The comment raises a concern about the handling of different types of inputs, such as biomedical signals or speech, and suggests discussing and presenting solutions in the paper. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in suggesting that the authors should discuss and present their solutions regarding different types of inputs. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the handling of different types of inputs, such as biomedical signals or speech, and suggests discussing and presenting solutions in the paper. However, the comment does not provide specific examples or detailed reasoning to support why this is an issue or how it could be addressed. The mention of \"citation\" being \"a bit disordered\" is vague and lacks context. Without further explanation or examples, the claim is difficult for the authors to understand and address, making it 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors should discuss and present their solutions for handling different types of inputs, such as biomedical signals or speech. This feedback is clear and actionable, as it directs the authors to address a critical aspect of their work that could enhance its applicability and relevance. However, the comment could be more helpful if it provided specific examples or suggestions on how to approach this discussion or solution. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point consists of two parts. The first part is a question about the implications of Eq. 4, asking if it means that u^l in Eq. 3 tends to be 1. This is a clarification question that does not provide any explicit or implicit action for the authors to take. The second part critiques the improvement of the designed solutions in Table 5, noting that the proposed solution provides only a marginal improvement on the OfficeHome dataset. This feedback is 3 as it points out a potential issue with the effectiveness of the proposed solution, but it lacks specific guidance on how the authors might address this concern. Overall, the comment is 3, as it raises questions and points out a potential issue but does not provide concrete steps for improvement.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq. 4\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the implications of Eq. 4 and critiquing the marginal improvement of the proposed solution on the OfficeHome dataset. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of two parts. The first part is a question about the implications of Eq. 4, asking if it means that u^l in Eq. 3 tends to be 1. This is a logical question that requires no verification, as it is a request for clarification. The second part critiques the improvement of the designed solutions in Table 5, noting that the proposed solution provides only a marginal improvement on the OfficeHome dataset. This is a factual statement without a claim or opinion, as it describes the observed results. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises two points. First, it questions the implications of Eq. 4, asking if it means that u^l in Eq. 3 tends to be 1. This is a logical question that prompts the authors to clarify the relationship between these equations. Second, it critiques the improvement of the designed solutions in Table 5, noting that the proposed solution provides only a marginal improvement on the OfficeHome dataset. This feedback is 3 as it points out a potential issue with the effectiveness of the proposed solution, but it lacks specific suggestions or guidance on how the authors might address this concern. Overall, the comment provides some insight but could be more actionable with additional details or suggestions for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the question answering process, specifically the use of template mapping to transform questions into masked statements. It suggests that this approach might lead to poor generalization for questions that are not \"Whtypes\" or transformable. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the generalization of their model. The action is implicit and vague, as the authors are left to infer that they need to explore alternative methods or improve the template mapping process, but without concrete steps or examples, the action remains unclear. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the question answering process, namely the use of template mapping to transform questions into masked statements. However, it does not specify which part of the paper discusses this process, making it weakly grounded. The comment is specific in identifying the potential issue of poor generalization for questions that are not \"Whtypes\" or transformable, providing a clear direction for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the question answering process might lead to poor generalization due to the use of template mapping to transform questions into masked statements. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks references to similar cases or studies that demonstrate the potential issue with generalization. Without such evidence or examples, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is rated as 3, as it provides some insight but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment identifies a potential issue with the question answering process, specifically the use of template mapping to transform questions into masked statements. It suggests that this approach might lead to poor generalization for questions that are not \"Whtypes\" or transformable. While the comment highlights a critical area for improvement, it lacks specific suggestions or guidance on how the authors might address this issue or improve the generalization of their model. Without actionable advice or detailed feedback, the authors are left with a general understanding of the problem but without a clear path to resolution. Therefore, the comment is 3, as it points out a potential weakness but does not provide comprehensive guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "2", "actionability_rationale": "The review point states that using a volumetric representation in the deformation field is not a novel idea, referencing the work of VolumeDeform [1]. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue of nonnovelty or suggestions for improvement. The comment lacks actionable details, leaving the authors without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of a volumetric representation in the deformation field, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it references the work of VolumeDeform [1], which provides a clear context for the nonnovelty claim. This makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that using a volumetric representation in the deformation field is not a novel idea, referencing the work of VolumeDeform [1]. This claim is supported by the specific mention of VolumeDeform, which provides a clear reference for the authors to verify the claim. The inclusion of a reference to a specific work adds credibility to the claim, making it 4. However, the comment could be strengthened by providing more detailed information about how VolumeDeform\"s approach differs from the current work, which would further enhance the verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment points out that using a volumetric representation in the deformation field is not a novel idea, referencing the work of VolumeDeform [1]. While it provides a reference to support the claim, it does not offer any constructive feedback or suggestions for improvement. The comment lacks depth and does not guide the authors on how to address the issue of nonnovelty or how to differentiate their approach from existing work. As a result, the comment is 2, as it identifies a potential weakness but does not provide actionable advice for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a significant drop in accuracy scores (from 70.4 to 55.6) after implementing the ICLHAR, which is intended to improve consistency and verifiability. The comment suggests that this issue should be discussed or acknowledged in more detail in the main text. While the action is explicit, it lacks specific guidance on how to discuss or acknowledge this issue in detail. The authors are given a clear direction to address the problem but may not be entirely sure of the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"ICLHAR,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting the significant drop in accuracy scores (from 70.4 to 55.6) and the need for more detailed discussion or acknowledgment in the main text. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the implementation of ICLHAR has significantly impacted the accuracy scores, dropping from 70.4 to 55.6 on TRIP. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant drop in accuracy scores (from 70.4 to 55.6) after implementing the ICLHAR, which is intended to improve consistency and verifiability. It suggests that this issue should be discussed or acknowledged in more detail in the main text. This feedback is clear and actionable, as it highlights a potential tradeoff between accuracy and other benefits and encourages the authors to address this point in their paper. However, the comment could be more helpful if it provided specific suggestions on how to discuss or acknowledge this issue in detail. Overall, the comment is 4 as it directs the authors to a critical area that needs further exploration and clarification."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point critiques the limited innovations in network architecture design and constraint embedding, noting that the authors have discussed the performance being limited by the oracle expert. However, it does not provide any explicit or implicit suggestions for improvement or guidance on how the authors might address these limitations. Without actionable advice or specific recommendations, the authors are left without a clear path forward to enhance their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the limited innovations in network architecture design and constraint embedding, noting that the authors have discussed the performance being limited by the oracle expert. However, it does not specify which part of the paper discusses these limitations or how they could be improved. The authors might infer that it relates to the methodology or results sections, but this inference is not explicit. The comment lacks specificity as it does not provide detailed guidance on what aspects of the network architecture or constraint embedding need improvement. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the innovations in network architecture design and constraint embedding are limited, and it references the authors\" discussion about the performance being limited by the oracle expert. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed justification or evidence makes the claim 3, as it requires more information to fully substantiate the critique.", "helpfulness_rationale": "The review comment points out a limitation in the innovations of network architecture design and constraint embedding, noting that the authors have discussed the performance being limited by the oracle expert. However, it does not provide any specific suggestions or guidance on how the authors might address this limitation or improve their work. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should conduct calibration curves to demonstrate the consistency between predicted scores and actual risks, which is a crucial aspect for the clinical scoring system. It also encourages the authors to prove the feasibility of the generated scoring system and discuss the differences between the traditional method and their own approach. While the comment implies specific actions, it does not provide detailed guidance on how to conduct these analyses or what specific aspects to focus on. The authors can infer the actions but may need further clarification on execution. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"model AUC\" and \"calibration curves,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as conducting calibration curves to demonstrate consistency between predicted scores and actual risks, and discussing the differences between the traditional method and the authors\" method. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the model AUC can assess discriminant ability but may not demonstrate consistency between predicted scores and actual risks, which is crucial for clinical scoring systems. The reviewer encourages the authors to conduct calibration curves to show this agreement. The comment provides a logical reasoning for the claim, suggesting that the model\"s discriminant ability alone may not be sufficient for clinical applications. However, it lacks specific references or examples to fully substantiate the claim, making it 3. The authors would need to consider the suggestion to improve their draft, but the lack of detailed evidence or references limits the comprehensiveness of the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by recommending the use of calibration curves to demonstrate the consistency between predicted scores and actual risks. This is particularly relevant for clinical scoring systems, where such consistency is crucial. The comment also encourages the authors to discuss the differences between their method and traditional approaches, which could enhance the paper\"s contribution. While the comment is specific and offers valuable guidance, it could be more helpful if it included examples or further details on how to conduct the calibration curves or discuss the differences. Overall, the feedback is 4 as it directs the authors toward important areas for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that the range of ID and OOD in Figure 4 does not seem to change much with sparsification, and it questions the importance of Lemma 2\"s requirement for an approximately identical mean as the assumption. The reviewer suggests that these conditions are crucial for DICE but are not well discussed, specifically asking how to ensure DICE meets these conditions. While the comment identifies areas that need further discussion, it does not provide explicit guidance on how the authors should address these issues or what specific aspects should be included in the discussion. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps without concrete instructions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4\" and \"Lemma 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the range of ID and OOD does not seem to change much with sparsification, and it questions the importance of Lemma 2\"s requirement for an approximately identical mean as the assumption. The comment further suggests that these conditions are crucial for DICE but are not well discussed, specifically asking how to ensure DICE meets these conditions. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the range of ID and OOD in Figure 4 does not seem to change much with sparsification, and it questions the importance of Lemma 2\"s requirement for an approximately identical mean as the assumption. The comment suggests that these conditions are crucial for DICE but are not well discussed. However, the comment lacks specific examples, detailed reasoning, or references to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered 2, as it provides some insight but requires more detailed justification to be 5.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the range of ID and OOD in Figure 4 does not seem to change much with sparsification, and it questions the importance of Lemma 2\"s requirement for an approximately identical mean as the assumption. The reviewer points out that these conditions are crucial for DICE but are not well discussed, specifically asking how to ensure DICE meets these conditions. This feedback is clear and actionable, as it highlights a critical area that needs further discussion and explanation. By addressing these points, the authors can enhance the clarity and comprehensiveness of their work. However, the comment could be more helpful if it provided specific suggestions on how to discuss or address these conditions. Overall, the comment is 4, as it directs the authors to a specific area that requires attention and improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises several concerns about the experiments, questioning the strength and fairness of the baselines used. It suggests that the authors should use the default settings of these baselines in the literature and include baselines related to BO with discrete and categorical variables. Additionally, it points out the need to discuss limitations and societal impacts of the proposed approach. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to address these issues, such as which baselines to include or how to discuss limitations. The actions are implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment addresses several issues related to the experiments, including the strength and fairness of the baselines, the use of position kernels, and the absence of certain baselines. It also mentions the need to discuss limitations and societal impacts. However, the comment does not specify which sections of the paper these issues pertain to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as using the default settings of baselines and including specific baselines related to BO with discrete and categorical variables. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several claims, including the lack of strength and fairness in the experiments, the absence of certain baselines, and the need to discuss limitations and societal impacts. However, the comment lacks specific examples or detailed reasoning to support these claims. It provides general observations without concrete evidence or references to substantiate the assertions. This makes the claims difficult for the authors to address effectively, as they are not provided with sufficient information to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper. It questions the strength and fairness of the experiments, suggesting that the authors should use the default settings of baselines in the literature and include baselines related to BO with discrete and categorical variables. Additionally, it points out the need to discuss limitations and societal impacts of the proposed approach. While the comment highlights important areas for enhancement, it lacks specific guidance or suggestions on how to address these issues, such as which baselines to include or how to discuss limitations. This limits the comment\"s usefulness, as it provides insight but does not offer actionable steps for improvement. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point observes a drop in correlation after a short period of training, followed by an increase with more training iterations. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this observation, whether it is a concern or a normal part of the training process, or what steps the authors should consider to improve their draft. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions a specific observation regarding a drop in correlation after a short period of training, followed by an increase with more training iterations. However, it does not specify which part of the paper this observation is based on, such as a particular experiment or analysis. Without explicit references to sections, tables, or figures, the authors cannot confidently determine the exact part of the paper being addressed. This lack of grounding makes it difficult for the authors to understand the context of the comment. Additionally, the comment lacks specificity as it does not provide details on what needs to be addressed or improved regarding this observation. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point observes a drop in correlation after a short period of training, followed by an increase with more training iterations. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the observation or how it impacts their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment observes a drop in correlation after a short period of training, followed by an increase with more training iterations. However, it does not provide any context, explanation, or suggestions for how this observation might impact the authors\" work or what steps they could take to address it. Without additional information or guidance, the authors are left without a clear understanding of the significance of this observation or how to improve their draft. Therefore, the comment is 1, as it lacks actionable feedback or insight."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the lack of insight into why all sparsity patterns perform similarly and suggests that this might be a unique aspect of the sparsity detection problem or a general characteristic of GNNs. It also points out a typo in the text, suggesting a correction. While the comment identifies a potential area for further exploration and provides a specific correction, it does not offer explicit guidance on how the authors should address the lack of insight or conduct further analysis. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the reasons behind the similar performance and potentially explore the generalizability of the findings. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.3\" and \"presentation bits,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out a typo in the text (\"presentation bits\" should be \"representation bits\") and raises a concern about the lack of insight into why all sparsity patterns perform similarly. The comment suggests that this might be a unique aspect of the sparsity detection problem or a general characteristic of GNNs. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the lack of insight into why all sparsity patterns perform similarly and suggests that this might be a unique aspect of the sparsity detection problem or a general characteristic of GNNs. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, noting that all sparsity patterns seem to perform similarly without providing insight into why this is the case. It raises a question about whether this is a unique aspect of the sparsity detection problem or a general characteristic of GNNs. This feedback is 3 as it prompts the authors to consider the broader implications of their findings and potentially explore the generalizability of their results. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of how similar observations have been handled in other works. Overall, the comment provides some direction for further exploration but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the derivation from Equation 3 to Equation 4 is missing the temperature \u03c4 and suggests that it should be shown in a rigorous way or mentioned in the paper. This provides a clear and direct action for the authors to take, ensuring that the temperature \u03c4 is included in the derivation or mentioned in the paper. The comment is explicit and provides concrete guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eqn. 3\" and \"Eqn. 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of missing the temperature \u03c4 and suggests that it should be shown in a rigorous way or mentioned in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the derivation from Equation 3 to Equation 4 is missing the temperature \u03c4 and suggests that it should be shown in a rigorous way or mentioned in the paper. However, the comment does not provide any reasoning or evidence to support why the inclusion of \u03c4 is necessary or how it would impact the derivation. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the derivation in the paper, noting that the temperature \u03c4 is missing from the equations. It suggests that the temperature should be included in a rigorous manner or mentioned in the paper. This feedback is clear and actionable, providing the authors with a direct way to improve their draft by ensuring the inclusion of the temperature variable. However, the comment could be more helpful if it explained why the inclusion of \u03c4 is important or how it affects the derivation. Overall, the comment is 4 as it guides the authors toward a specific improvement, but it could be more comprehensive with additional context or explanation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests adding a citation on differential privacy, specifically mentioning a standard work like [2] as an example. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 156,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding a citation on differential privacy, providing a clear direction for improvement. The comment specifies the type of citation (e.g., a standard work like [2]) that would be beneficial. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests adding a citation on differential privacy, specifically mentioning a standard work like [2]. This is a clear and specific recommendation that provides a direct action for the authors to take. The suggestion is 5 as it offers a concrete example of the type of reference that would be beneficial, making it easy for the authors to understand and implement. Therefore, the comment is categorized as 5.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the paper by recommending the addition of a citation on differential privacy, specifically mentioning a standard work like [2]. This feedback is clear and direct, offering the authors a concrete step to enhance the comprehensiveness and credibility of their work. By incorporating this suggestion, the authors can ensure that their readers are provided with a solid foundation for understanding the concepts discussed in the paper. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point consists of two parts. The first part addresses a claim in the paper regarding the methodology requiring significant additional assumptions. The reviewer challenges this claim by pointing out that the only additional assumption is that the test set is drawn from the same distribution as the query set, which is a natural assumption in many machine learning settings. This feedback provides a clear and explicit action for the authors to reconsider their claim and potentially revise it. The second part of the comment points out an inequality with the wrong sign, providing a specific line number for correction. This feedback is explicit and concrete, giving the authors clear guidance on how to address both issues. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2\" and \"line 310,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear feedback on the claim regarding additional assumptions and the inequality with the wrong sign. The comment specifies what needs to be addressed, such as reconsidering the claim about additional assumptions and correcting the inequality. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts: a claim about the methodology requiring significant additional assumptions and a correction regarding an inequality. The first part challenges the claim by providing a logical reasoning that the additional assumption is natural in many machine learning settings, which supports the claim that the assumption is not as extreme as stated. The second part provides a specific correction to an inequality, which is a factual statement requiring no verification. Overall, the comment is 4 for the first part due to the logical reasoning provided, while the second part is verifiable as it corrects a factual error. Therefore, the overall score is 4.", "helpfulness_rationale": "The review comment provides two distinct pieces of feedback. First, it challenges the claim in the paper that the methodology requires significant additional assumptions, pointing out that the only additional assumption is that the test set is drawn from the same distribution as the query set, which is a natural assumption in many machine learning settings. This feedback is helpful as it prompts the authors to reconsider their claim and potentially revise it, providing a more accurate representation of the methodology. Second, the comment corrects an inequality on line 310, specifying that the base alpha should be less than one. This is a clear and actionable suggestion that helps the authors correct a factual error in their work. Both pieces of feedback are specific and constructive, making the comment 4. However, it could be more comprehensive by offering additional suggestions or explanations on how to address the claim about additional assumptions. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide a more robust justification for using Shapely values over other methods, such as CaCE or raw gradients, by comparing them experimentally. It also recommends including a significant discussion on the advantages and disadvantages of each method for transforming highdimensional data to lowdimensional latent space. While the comment implies that the authors should conduct additional experiments and provide a more comprehensive discussion, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Shapely values\" and \"other methods,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the authors should provide a more robust justification for using Shapely values over other methods, such as CaCE or raw gradients, and recommends including a significant discussion on the advantages and disadvantages of each method for transforming highdimensional data to lowdimensional latent space. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with a score of 5.", "verifiability_rationale": "The review point suggests that the authors should provide a more robust justification for using Shapely values over other methods, such as CaCE or raw gradients, by comparing them experimentally. It also recommends including a significant discussion on the advantages and disadvantages of each method for transforming highdimensional data to lowdimensional latent space. While the comment provides a logical reasoning for the need to compare methods and discuss their advantages, it lacks specific examples or references to support the claim. This makes the comment 3, as it provides a clear direction for improvement but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors should provide a more robust justification for using Shapely values over other methods, such as CaCE or raw gradients. It also recommends including a significant discussion on the advantages and disadvantages of each method for transforming highdimensional data to lowdimensional latent space. This feedback is clear and actionable, as it guides the authors to conduct additional comparisons and analyses to strengthen their argument. However, the comment could be more helpful if it provided specific examples or references to support the suggested comparisons. Overall, the comment is 4 as it offers valuable insights for enhancing the paper, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a specific issue with Appendix A.2, noting that it does not clearly illustrate the state space representation of the environment. However, it does not provide any explicit or implicit guidance on how to address this issue or improve the clarity of the representation. The authors are left without any actionable steps to take, such as suggestions for additional explanations, examples, or changes to the representation. Without specific instructions or examples, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix A.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity in illustrating the state space representation of the environment. This provides clear guidance on what needs to be addressed in the appendix. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Appendix A.2 does not illustrate the state space representation of the environment clearly. However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the clarity of the state space representation of the environment in Appendix A.2. This feedback is 3 as it points out a particular area that needs improvement, allowing the authors to focus their attention on enhancing the clarity of their representation. However, the comment lacks depth and does not provide specific suggestions or guidance on how to address the issue, such as what aspects of the representation need clarification or how to improve its presentation. While it highlights an area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point highlights a limitation of the authors\" approach, stating that it is only applicable for small or mediumscale problems and that largescale problems may overwhelm current LPsolvers. However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or improve their approach for largerscale problems. The comment lacks actionable guidance, leaving the authors without a clear understanding of what steps to take to enhance their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a limitation of the authors\" approach, stating that it is only applicable for small or mediumscale problems and that largescale problems may overwhelm current LPsolvers. However, it does not specify which part of the paper this limitation is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the approach need to be addressed or improved to make it applicable for largerscale problems. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the authors\" approach is only applicable for small or mediumscale problems, and that largescale problems may overwhelm current LPsolvers. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation of the authors\" approach, noting that it is only applicable for small or mediumscale problems and may struggle with largescale problems. However, it does not provide any suggestions or guidance on how the authors might address this limitation or improve their approach for largerscale problems. Without actionable feedback or constructive advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the motivation behind using characteristic function regularization is unclear. However, it does not provide any explicit or implicit suggestions on how the authors might clarify this motivation or improve the clarity of their explanation. Without guidance on what specific aspects of the motivation are unclear or how to address them, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the overall motivation for using characteristic function regularization, but it does not specify which part of the paper this issue pertains to, such as a specific section or subsection. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being discussed. Additionally, the comment lacks specificity regarding what aspects of the motivation are unclear or how they could be clarified. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the overall motivation for using characteristic function regularization is unclear. However, the comment does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a critical issue with the paper, noting that the overall motivation for using characteristic function regularization is unclear. This is an important observation that could impact the paper\"s clarity and impact. However, the comment lacks specificity and does not provide any suggestions or guidance on how the authors might clarify this motivation or improve the explanation. Without actionable feedback or examples, the authors are left without a clear path to address the issue. Therefore, the comment is 2, as it highlights a significant weakness but does not offer meaningful guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the paper for being limited to a combination of existing techniques, suggesting that the contribution is incremental. However, it does not provide any explicit or implicit actions for the authors to take to improve their draft. There is no guidance on how to enhance the originality or novelty of the work, nor are there suggestions for potential areas of improvement or additional contributions. As a result, the comment lacks any actionable advice, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment critiques the paper for being limited to a combination of existing techniques, specifically mentioning the adaptation to an unknown level of corruption (Lykouris et al., 2018), varying variances treated with a weighted version of OFUL (Zhou et al., 2021), and variable decision sets (standard in contextual linear bandits). However, it does not specify which part of the paper these techniques are discussed in, making it weakly grounded. The comment is specific in detailing the existing techniques used and the perceived lack of originality, but it does not provide guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is limited to a combination of existing techniques, citing specific references (Lykouris et al., 2018; Zhou et al., 2021) for context. This provides a clear basis for the claim, as it references specific works that the paper builds upon. However, the comment lacks detailed reasoning or examples to fully substantiate the claim that the contribution is incremental. While the references provide some support, the comment could be strengthened by elaborating on how the combination of these techniques is not novel or innovative. Therefore, the claim is 4, as it requires additional context to fully substantiate the critique.", "helpfulness_rationale": "The review comment critiques the paper for being limited to a combination of existing techniques, suggesting that the contribution is incremental. It references specific works (Lykouris et al., 2018; Zhou et al., 2021) to support this claim, which provides some context for the authors to understand the basis of the critique. However, the comment lacks actionable suggestions or guidance on how the authors might enhance the originality or novelty of their work. While it identifies a potential weakness, it does not offer specific advice on how to address it, leaving the authors with limited insight into how to improve their draft. Therefore, the comment is 3, as it points out a limitation but does not provide comprehensive feedback for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights several writing issues, such as grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not provide specific examples or guidance on how to address these issues. The comment lacks explicit instructions or suggestions for improvement, leaving the authors uncertain about what actions to take. Without concrete details or examples, the authors may struggle to identify and correct the issues effectively. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights writing issues such as grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not specify which parts of the paper these issues are found in, making it difficult for the authors to pinpoint the exact sections that need attention. Additionally, the comment lacks specificity regarding which grammatical errors, mathematical symbols, or unclear sentences are problematic. Without detailed guidance, the authors cannot effectively address the issues. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper contains severe writing issues, such as grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not provide specific examples or detailed evidence to support these claims. Without concrete examples or references to particular sections of the paper, the authors may find it challenging to understand and address the issues effectively. The lack of specific details makes the claim difficult to verify, resulting in a score of 1.", "helpfulness_rationale": "The review comment identifies several writing issues, such as grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not provide specific examples or detailed guidance on how to address these issues. Without concrete suggestions or actionable feedback, the authors are left with a general understanding of the problems but without a clear path to improvement. This lack of specificity and actionable advice makes the comment 2, as it does not effectively guide the authors in enhancing their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point provides explicit instructions for the authors to run additional experiments and add the results to the figures and Table 1. It also requests clarification on specific aspects of the figures, such as whether the network was trained on random data or evaluated with random data. The comment is clear and actionable, as it specifies exactly what the authors need to do to address the reviewer\"s concerns. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific figures (Fig 3c and Fig 3) and requests clarification on certain aspects of the data. It also provides clear and specific suggestions for additional experiments and the inclusion of results in figures and Table 1. This level of detail allows the authors to accurately identify the parts of the paper being addressed and what needs to be clarified or improved. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a series of requests for clarification and suggestions for additional experiments. It does not contain subjective opinions, judgments, or claims that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by requesting additional experiments and clarifications on the figures. It explicitly asks for the inclusion of results for untrained networks in the figures and Table 1, which is a clear and direct suggestion for improvement. Additionally, it seeks clarification on the nature of the random data used in the experiments, which is important for understanding the methodology. The comment is detailed and provides clear guidance on how the authors can enhance their draft, making it 5 for improving the paper. Therefore, it aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should repeat the experiments and conduct statistical significance analysis on the numbers to determine whether the improvement over previous methods is statistically significant. This provides a clear and direct action for the authors to take. The comment also specifies that the results in Table 1 and Fig. 5 do not report the mean and standard deviation, which is another actionable point. Overall, the comment is explicit and provides concrete guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1\" and \"Fig. 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of reporting of mean and standard deviation, and the difficulty in determining statistical significance. The suggestion to repeat the experiments and conduct statistical significance analysis is clear and actionable. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the improvement over previous methods is small, about 0.2%1%, and suggests that the results in Table 1 and Fig. 5 do not report the mean and standard deviation, making it difficult to determine statistical significance. The reviewer provides a clear and logical reasoning for the claim, noting the limited novelty and marginal improvement. However, the comment could be strengthened by providing specific examples or references to support the claim about the small improvement. Despite this, the reasoning is 4, as it provides a logical basis for the suggestion to repeat the experiments and conduct statistical significance analysis. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the improvement over previous methods is small, about 0.2%1%. It also points out that the results in Table 1 and Fig. 5 do not report the mean and standard deviation, making it difficult to determine statistical significance. The reviewer provides a clear and actionable suggestion to repeat the experiments and conduct statistical significance analysis, which would help clarify the results and their significance. This feedback is valuable as it highlights a critical area for improvement and offers a concrete step for the authors to take. However, the comment could be more helpful by providing additional context or examples of how to conduct the statistical analysis. Overall, the comment is 4, as it effectively guides the authors toward improving the draft but could be more comprehensive with further guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the \"approach section\" is missing from the main paper and suggests that the supplementary material should be used more like additional information rather than an extension. The reviewer provides a specific reference to the work by Timothy Nguyen, Zhourong Chen, and Jaehoon Lee, which can guide the authors in understanding the expected format for the approach section. This feedback is clear and provides concrete guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"approach section\" in the main paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the supplementary material should be used more like additional information and not as an extension to the paper. The comment provides a specific reference to the work by Timothy Nguyen, Zhourong Chen, and Jaehoon Lee, which further clarifies the expectation for the approach section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the \"approach section\" is missing from the main paper and suggests that the supplementary material should be used more like additional information rather than an extension. The reviewer provides a specific reference to the work by Timothy Nguyen, Zhourong Chen, and Jaehoon Lee, which supports the claim that the supplementary material should be used appropriately. This provides a clear and specific reference, making the claim 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how the approach section should be structured. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant omission in the main paper, specifically the absence of an approach section. It provides a specific reference to the work by Timothy Nguyen, Zhourong Chen, and Jaehoon Lee, which the reviewer used as a basis for their evaluation. This feedback is clear and actionable, as it directs the authors to include an approach section in the main paper and clarifies the expectations for the supplementary material. By referencing a similar work, the comment offers a concrete example of how the authors can improve their draft. However, the comment could be more helpful if it provided additional guidance on how to structure the approach section or what specific elements should be included. Overall, the comment is 4, as it effectively guides the authors toward a significant improvement in their draft."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the statement regarding the biological plausibility of backpropagation in the introduction is too weak and suggests that it is widely accepted that backpropagation is biologically implausible. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to strengthen the statement or address the issue, leaving the authors without a clear understanding of what changes are needed. Without specific suggestions or instructions, the authors are unable to make meaningful improvements to their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific statement in the introduction regarding the biological plausibility of backpropagation, which is mentioned explicitly. This allows the authors to accurately identify the part of the paper being addressed, making it fully grounded. The comment is also specific because it points out that the statement is too weak and provides a counterargument that backpropagation is widely accepted as biologically implausible. This level of detail helps the authors understand what needs to be addressed in the introduction. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement regarding the biological plausibility of backpropagation in the introduction is too weak, as it is widely accepted that backpropagation is biologically implausible. The reviewer provides a logical reasoning by stating that the statement is too weak and that the biological plausibility of backpropagation is a subject of debate. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened by providing specific references or examples to support the claim, which would align it with a score of 5. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the statement in the introduction regarding the biological plausibility of backpropagation. It points out that the statement is too weak and suggests that it is widely accepted that backpropagation is biologically implausible. This feedback is clear and actionable, as it highlights a potential weakness in the introduction and provides a direction for improvement by suggesting a stronger statement or additional evidence to support the claim. However, the comment could be more helpful if it offered specific suggestions on how to strengthen the statement or provided examples of how to address the issue. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper provides valuable insights for contrastive learning in code search tasks but does not thoroughly explore the implications of the proposed method for other NLP tasks. This limitation is noted as it somewhat restricts the generalizability of the results. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this limitation or explore the implications for other NLP tasks. Without specific suggestions or instructions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a limitation in the paper, noting that while it provides valuable insights for contrastive learning in code search tasks, it does not thoroughly explore the implications of the proposed method for other NLP tasks. However, it does not specify which part of the paper this limitation pertains to, such as specific sections or experiments that could be expanded. Additionally, the comment lacks specificity in terms of what aspects of other NLP tasks should be explored or how the generalizability could be improved. As a result, the authors cannot confidently determine which part of the paper needs attention, making the comment 2. Therefore, this comment aligns with a score of 2.", "verifiability_rationale": "The review point claims that the paper provides valuable insights for contrastive learning in code search tasks but does not thoroughly explore the implications of the proposed method for other NLP tasks. This limits the generalizability of the results. However, the comment lacks specific examples or references to other NLP tasks that could be explored, making it difficult for the authors to understand the exact scope of the limitation. The claim is 3 as it highlights a potential gap in the paper, but it requires more detailed justification or examples to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, noting that while it provides valuable insights for contrastive learning in code search tasks, it does not thoroughly explore the implications of the proposed method for other NLP tasks. This observation highlights a potential area for improvement, as it suggests that the paper could be more comprehensive by exploring the generalizability of the results to other NLP tasks. However, the comment lacks specific suggestions or guidance on how the authors might address this limitation or expand their exploration to other NLP tasks. While it points out a weakness, it does not provide actionable feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the experiments are limited to toy data and recommends including realworld data to demonstrate the method\"s performance. While the comment implies that the authors should expand their experiments to include realworld data, it does not provide specific guidance on which realworld problems to focus on or how to conduct these experiments. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experiments are limited to toy data and recommends including realworld data to demonstrate the method\"s performance. However, it does not specify which part of the paper discusses the experiments or where the authors should include realworld data. The authors might infer that it relates to the experimental section, but this inference is not explicit. The comment is specific in suggesting the inclusion of realworld data, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments are limited to toy data and suggests that the method should be tested on realworld data. However, the comment lacks specific examples or references to realworld problems where barycenters could be used, making it difficult for the authors to understand the scope of the suggestion. The lack of detailed reasoning or examples makes the claim 3, as the authors would need to infer the potential benefits of testing on realworld data. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the experiments, noting that they are restricted to toy data. It suggests that the method should be tested on realworld data to demonstrate its applicability and performance in practical settings. This feedback is clear and actionable, as it provides a specific direction for the authors to expand their experiments and improve the relevance and impact of their work. However, the comment could be more helpful if it offered examples of realworld problems or suggested specific datasets to consider. Overall, the comment is 4, as it guides the authors toward a meaningful enhancement of their study."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests conducting more experiments on deeper networks, such as ResNet50, and other network structures, like MobileNet, to strengthen the paper. It provides specific examples of references that could guide the authors in their experiments. This feedback is clear and actionable, as it directly instructs the authors on what additional experiments to perform and where to find relevant references. The authors know exactly what actions to take to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for more experiments on deeper networks, such as ResNet50, and other network structures, like MobileNet. This allows the authors to accurately identify the part of the paper being addressed, which is the experimental section. The comment is also specific because it provides clear guidance on what additional experiments are needed to strengthen the paper, including references to relevant works. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests conducting more experiments on deeper networks, such as ResNet50, and other network structures, like MobileNet, to strengthen the paper. This suggestion is supported by references to specific works that have explored similar approaches, providing a basis for the claim. However, the comment could be strengthened by including more detailed reasoning or examples of how these additional experiments would contribute to the paper\"s strength. Overall, the claim is 4, as it provides a solid foundation but lacks comprehensive justification, aligning with a score of 4.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by recommending additional experiments on deeper networks, such as ResNet50, and other network structures, like MobileNet. This feedback is specific and offers concrete guidance on how the authors can enhance the robustness and applicability of their work. The inclusion of references to relevant literature further supports the suggestion, making it 5 for the authors to consider and implement. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the clarity of why the proposed sample selection mechanism helps preserve the label distribution. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve the clarity of their explanation. The comment lacks actionable guidance, leaving the authors uncertain about what steps to take to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the clarity of why the proposed sample selection mechanism helps preserve the label distribution. However, it does not specify which part of the paper discusses this mechanism or where the issue of clarity arises. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the explanation are unclear or how the authors might clarify the issue. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point questions the clarity of why the proposed sample selection mechanism helps preserve the label distribution. However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific area of concern regarding the clarity of why the proposed sample selection mechanism helps preserve the label distribution. This is a relevant observation that could help the authors improve their explanation or justification of their method. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue. Without actionable feedback or detailed advice, the authors may find it challenging to know exactly what steps to take to enhance their draft. Therefore, the comment is 3, as it points out a potential area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the results and analysis are detailed and comprehensive, but it notes that only two relatively old and small models are evaluated. However, it does not provide any explicit or implicit suggestions for improvement. There is no guidance on whether the authors should evaluate additional models, what types of models should be considered, or how to address the issue of evaluating only a limited number of models. Without any actionable advice, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the evaluation of results and analysis, noting that only two relatively old and small models are evaluated. However, it does not specify which part of the paper this critique pertains to, such as the results section or the discussion of model evaluation. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper being addressed. Additionally, while the comment highlights a specific issue with the models evaluated, it does not provide detailed guidance on how to address this issue or what alternative models should be considered. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the results and analysis are detailed and comprehensive, but it notes that only two relatively old and small models are evaluated. This claim is 3 as it highlights a potential limitation in the evaluation process. However, the comment lacks specific examples or references to support the claim about the models being old and small, which would strengthen the justification. The authors might need to provide additional context or evidence to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment points out a limitation in the evaluation of results and analysis, noting that only two relatively old and small models are evaluated. While this observation highlights a potential weakness in the study, the comment lacks specificity and actionable guidance. It does not suggest alternative models to consider, nor does it provide insights into how the authors might address this limitation. Without detailed feedback or suggestions for improvement, the authors are left without a clear path forward. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges that KD and LS are not identical but suggests that KD can be viewed as a special form of LS under specific conditions. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this observation or how it might impact the paper. The comment lacks actionable details, leaving the authors without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment discusses the relationship between KD (Knowledge Distillation) and LS (Label Smoothing), suggesting that KD can be viewed as a special form of LS under specific conditions. However, it does not specify which part of the paper this discussion is based on, making it difficult for the authors to identify the exact section being addressed. The comment is specific in its claim about the equivalence of KD and LS under certain conditions, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that KD (Knowledge Distillation) can be viewed as a special form of LS (Label Smoothing) under specific conditions. The reviewer provides a logical reasoning by stating that when the teacher network is uniformly distributed and the temperature is set at 1, KD and LS are equivalent. This reasoning is based on a clear understanding of the concepts and their relationship, which provides a logical basis for the claim. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is 4, as it provides a logical basis but lacks detailed evidence or references.", "helpfulness_rationale": "The comment acknowledges that KD (Knowledge Distillation) and LS (Label Smoothing) are not identical but suggests that KD can be viewed as a special form of LS under specific conditions. It provides a logical reasoning by stating that when the teacher network is uniformly distributed and the temperature is set at 1, KD and LS are equivalent. This observation could be valuable for the authors, as it offers a deeper understanding of the relationship between these two methods. However, the comment does not provide any actionable suggestions or guidance on how this insight might impact the paper or its presentation. While it offers a theoretical insight, it lacks practical application or specific advice for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks the authors to provide an explanation for the observed performance degradation when using additional information about missing, wrong, or redundant data in the FBN results. This request is clear and direct, giving the authors a specific action to take. The comment provides a concrete direction for the authors to follow, ensuring they know exactly what is expected of them. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by asking for an explanation of the performance degradation when using additional information about missing, wrong, or redundant data. This provides clear guidance on what the authors need to address in their paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification, asking the authors to explain the observed performance degradation when using additional information about missing, wrong, or redundant data in the FBN results. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area of concern regarding the performance degradation in the FBN results when using additional information about missing, wrong, or redundant data. By asking for an explanation, the comment prompts the authors to address a potential issue in their methodology or results. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might investigate or resolve this issue. To be more helpful, the comment could include questions or suggestions for further analysis or experimentation. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a gap in the analysis regarding the flatness of the minima found by the proposed method. It explicitly states that the authors need to provide an analysis on the losses of the noiseinjected models after training to support their claim that the minima found are flat. This feedback is clear and provides a specific action for the authors to take, ensuring they know exactly what needs to be done to address the issue. The comment is explicit and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq (3),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing in the analysis regarding the flatness of the minima and provides a detailed explanation of what is required to support the claim. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of flatness is missing, despite the paper arguing that the proposed method finds flat minima. The reviewer provides a logical reasoning by pointing out that minimizing the averaged loss across noiseinjected models does not ensure the flatness of the minima. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened by referencing specific examples or studies that support the claim about the relationship between averaged loss and flatness. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a critical gap in the analysis of the paper, specifically regarding the flatness of the minima found by the proposed method. It highlights that while the paper argues that the method finds flat minima, the analysis on flatness is missing. The comment provides a clear and actionable suggestion by pointing out that the authors need to analyze the losses of the noiseinjected models after training to support their claim. This feedback is valuable as it directs the authors to a specific area that requires further investigation and clarification, which can significantly enhance the robustness of their findings. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the text inside the figure and the labels are too small to read without zooming, and it suggests that this text should be roughly the same size as the manuscript text. This feedback provides a clear and direct action for the authors to take, ensuring that the text is legible and consistent with the rest of the manuscript. The comment is explicit and concrete, giving the authors precise guidance on how to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"text inside the figure and the labels,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the text being too small and suggests that it should be the same size as the manuscript text. This provides clear guidance on what needs to be addressed to improve the readability of the figures. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the text inside the figure and the labels are too small to read without zooming, and suggests that they should be the same size as the manuscript text. This is a factual observation about the readability of the figures, which does not require any subjective judgment or opinion. It is purely descriptive and does not contain a claim that needs verification. Therefore, the label \"No\" is appropriate.", "helpfulness_rationale": "The review comment identifies a specific issue with the readability of the figures in the paper, noting that the text inside the figures and labels are too small to read without zooming. It provides a clear and actionable suggestion to improve the figures by recommending that the text should be roughly the same size as the manuscript text. This feedback is valuable as it directly addresses a visual aspect of the paper that could impact its accessibility and clarity. By suggesting a straightforward adjustment, the comment empowers the authors to enhance the readability of their figures, which is crucial for effective communication of their results. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges that including multiple local prompts can be intuitive but notes that the features and their positions may not be the same for different categories. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting ways to ensure consistency across categories or proposing alternative methods. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the issue of including multiple local prompts, noting that the features and their positions may not be the same for different categories. However, it does not specify which part of the paper this observation pertains to, such as a specific section or experiment. This lack of explicit reference makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being discussed. The comment is specific in its observation about the features and positions, but without grounding, it is difficult for the authors to address the issue effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point makes a claim about the effectiveness of including multiple local prompts, stating that it is intuitive but noting that the features and their positions may not be the same for different categories. However, the comment lacks specific examples, reasoning, or references to support this claim. Without detailed evidence or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 2, as it provides some insight but requires more detailed justification to be 5.", "helpfulness_rationale": "The review comment acknowledges the intuitive nature of including multiple local prompts but points out a potential issue: the features and their positions may not be the same for different categories. This observation highlights a potential weakness in the paper\"s methodology or results, suggesting that the authors should consider this aspect when designing or interpreting their experiments. However, the comment does not provide specific guidance or suggestions on how to address this issue, such as proposing alternative methods or analyses to ensure consistency across categories. While it identifies a relevant area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight but lacks depth and specificity."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the presentation of the model in Section 4 is somewhat complicated and requires careful reading, possibly with reference to the supplement. It provides a specific action for improvement by recommending the use of notation and breakout diagrams to illustrate the attention mechanisms. While the comment explicitly states the need for improvement, it does not provide detailed guidance on how to implement these suggestions, such as which parts of the presentation should be rewritten or which diagrams should be included. The authors are given a clear direction but lack concrete steps on how to execute the changes. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear suggestions for improving the presentation, such as replacing natural language descriptions with notation and adding breakout diagrams to illustrate attention mechanisms. This level of detail guides the authors on what changes to make to enhance the clarity of the presentation. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the presentation of the model in Section 4 is somewhat complicated and requires careful reading, possibly with reference to the supplement. It provides a specific recommendation to improve the presentation by replacing natural language descriptions with notation and adding breakout diagrams to illustrate attention mechanisms. However, the comment does not provide detailed reasoning or examples to support why these changes would be beneficial or how they would improve the clarity of the presentation. While the suggestion is logical, the lack of detailed justification or examples makes the claim 3. The authors would need to infer the benefits of these changes themselves, which is why the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of the model in Section 4, noting that it is somewhat complicated and requires careful reading. It provides a constructive suggestion for improvement by recommending the use of notation and breakout diagrams to illustrate the attention mechanisms. This feedback is clear and actionable, offering a concrete way for the authors to enhance the clarity and accessibility of their presentation. However, the comment could be more helpful if it included specific examples of how to implement these suggestions or which parts of the presentation should be revised. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the paper, noting that it only conducts experiments on a limited number of molecules and provides indistribution testing for these samples. The reviewer suggests that the method\"s value would be limited if it requires training for each molecule individually. However, the comment does not provide explicit guidance or suggestions on how the authors might address this limitation or improve the generalizability of their method. The action is implicit and vague, as the authors are left to infer that they should expand their experiments to a broader range of molecules or improve the generalizability of their method. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment highlights a limitation in the paper, noting that it only conducts experiments on a limited number of molecules and provides indistribution testing for these samples. However, it does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The comment is specific in identifying the issue of limited generalizability and the need for broader testing, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper\"s value is limited due to its focus on a limited number of molecules and indistribution testing. However, the comment lacks specific examples or references to support this claim. It does not provide detailed reasoning or evidence to substantiate why the method\"s value would be limited or how it could be improved. Without additional context or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, noting that it only conducts experiments on a limited number of molecules and provides indistribution testing for these samples. The reviewer suggests that the method\"s value would be limited if it requires training for each molecule individually. While the comment highlights a potential weakness, it lacks specific suggestions or guidance on how the authors might address this limitation or improve the generalizability of their method. The feedback is 3 as it points out an area for improvement, but it could be more actionable with additional details or recommendations. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment states that the symbols are complicated and take time to understand, but it does not provide any explicit or implicit actions for the authors to take. It lacks specific suggestions or guidance on how to simplify or clarify the symbols, leaving the authors without a clear understanding of what changes are needed. Without actionable advice or concrete steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions that symbols are complicated and take time to understand, but it does not specify which symbols or parts of the paper are being referred to. This lack of explicit reference makes it difficult for the authors to identify the exact sections that need attention. Additionally, the comment does not provide specific details on what aspects of the symbols are confusing or how they could be simplified. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the symbols are complicated and take time to understand. However, it does not provide any specific examples, reasoning, or references to support this claim. Without detailed explanation or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment indicates that the symbols used in the paper are complicated and take time to understand. However, it lacks specificity and does not provide any actionable feedback or suggestions on how to simplify or clarify the symbols. Without detailed guidance or examples, the authors are left without a clear understanding of what changes are needed to improve the clarity of their symbols. This lack of actionable feedback makes the comment unhelpful, as it does not offer a path for the authors to enhance their draft. Therefore, it aligns with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly questions the understanding of the red line in Figure 3, asking where the test data comes from and whether there is a ground truth. This provides a clear and direct action for the authors to take, which is to clarify these points in their draft. The comment is explicit and provides concrete guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by questioning the understanding of the red line and asking about the source of the test data and the presence of a ground truth. This provides clear guidance on what needs to be clarified or addressed in the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the red line in Figure 3, specifically asking where the test data comes from and whether there is a ground truth. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 5 as it identifies a specific area of confusion in the paper, namely the red line in Figure 3. By asking where the test data comes from and whether there is a ground truth, the reviewer provides clear and actionable feedback that prompts the authors to clarify these aspects. This feedback is valuable as it directs the authors to address a potential misunderstanding in their work, which can lead to improved clarity and understanding for readers. However, the comment could be more helpful if it suggested ways to address the confusion or provided additional context. Overall, the comment is 4, as it effectively guides the authors toward improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It suggests that adding periodicity to the spectral kernel might be enough to allow it to capture all of the results at a similar level to the explicitly compositional model. While the comment implies that the authors should consider this aspect, it does not explicitly instruct them to conduct additional experiments or analyses to address the question. The action is implicit and somewhat vague, as it lacks specific guidance on how to proceed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It specifically mentions the comparison model, which cannot capture periodic relationships, and questions whether adding periodicity to the spectral kernel would allow it to capture all of the results at a similar level to the explicitly compositional model. However, the comment does not explicitly mention which part of the paper this question pertains to, such as specific sections or experiments. While the authors might infer that it relates to the results or methodology sections, the lack of explicit grounding makes it difficult to pinpoint the exact part of the paper being addressed. The comment is specific in its questioning of the results, but without full grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point raises a question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It suggests that the comparison model cannot capture periodic relationships, and questions whether adding periodicity to the spectral kernel would allow it to capture all of the results at a similar level to the explicitly compositional model. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. The reasoning is 3, as it provides a logical basis for questioning the results, but it requires more detailed evidence or examples to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises an interesting question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It points out that the comparison model cannot capture periodic relationships, and questions whether adding periodicity to the spectral kernel would allow it to capture all of the results at a similar level to the explicitly compositional model. This feedback prompts the authors to consider the role of periodicity in their results and encourages them to explore whether the spectral kernel could be enhanced to capture these periodic relationships. While the comment does not provide specific guidance on how to address this question, it does highlight an important area for further investigation. Therefore, the comment is 3, as it provides a direction for the authors to consider but lacks detailed suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the alignment of results in Table 6 with those in Table 1 (MCTpair) and asks about the ablation studies of MCT without adaptive metrics. While the questions imply that the authors should address these discrepancies or provide explanations, they do not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors need to infer that they should investigate and clarify these issues. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the alignment of results in Table 6 with those in Table 1 (MCTpair) and asks about the ablation studies of MCT without adaptive metrics. However, it does not specify which part of the paper these tables or studies are located in, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its questions but lacks grounding, as it does not provide clear references to the parts of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions seeking clarification about the alignment of results in Table 6 with those in Table 1 (MCTpair) and the ablation studies of MCT without adaptive metrics. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises questions about the alignment of results in Table 6 with those in Table 1 (MCTpair) and asks about the ablation studies of MCT without adaptive metrics. While it identifies potential inconsistencies or gaps in the presentation of results, it does not provide specific suggestions or guidance on how the authors might address these issues. The comment highlights areas that need clarification but lacks actionable feedback, making it 3. The authors are given a direction to explore but are not fully supported in making improvements to their draft. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the 10 subtasks are too simplistic for bAbi and that the authors could solve all the subtasks with their final model. It implies that the authors should provide more discussions on this aspect. However, the comment does not specify what kind of discussions are needed or how to address this issue. The action is implicit and somewhat vague, as the authors are left to infer what specific discussions are required. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the 10 subtasks are too simplistic for bAbi and that the authors could solve all the subtasks with their final model. However, it does not specify which part of the paper this critique is based on, such as a particular section or experiment. Without explicit references, the authors may find it challenging to pinpoint the exact part of the paper that needs revision. Additionally, the comment lacks specificity regarding what kind of discussions are required or how the authors should address the issue. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the 10 subtasks are too simplistic for bAbi and that the authors could solve all the subtasks with their final model. However, the comment lacks specific examples, detailed reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the simplicity of the 10 subtasks used in the bAbi dataset, suggesting that the authors could solve all the subtasks with their final model. This feedback highlights a possible weakness in the experimental setup and encourages the authors to provide more discussions on this aspect. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or what additional discussions could be included. While it points out a relevant area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the limitation of using triplets (or a sliding window of length 3) and asks whether this is a fundamental limitation of the approach or if extending to longer subsequences without a sliding window is straightforward. While the comment implies that the authors should consider extending their approach to longer subsequences, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the issue or what specific changes to make. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the limitation of using triplets (or a sliding window of length 3) and asks whether this is a fundamental limitation of the approach or if extending to longer subsequences without a sliding window is straightforward. However, it does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The comment is specific in its questioning of the approach\"s limitations and potential extensions, but without clear grounding, the authors may struggle to identify the exact section being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the limitation of using triplets (or a sliding window of length 3) and asks whether this is a fundamental limitation of the approach or if extending to longer subsequences without a sliding window is straightforward. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this limitation is problematic or how it could be addressed. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to respond to it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the limitation of using triplets (or a sliding window of length 3) and asks whether this is a fundamental limitation of the approach or if extending to longer subsequences without a sliding window is straightforward. This is a relevant question that prompts the authors to consider the potential limitations of their approach and whether it can be extended to address longer subsequences. However, the comment does not provide specific guidance or suggestions on how to address this limitation or extend the approach. While it identifies an area for potential improvement, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises two issues: the definition of \"sqeuence of episodes\" and the lack of related work. The first issue is addressed explicitly, as the reviewer asks for clarification on the term \"sqeuence of episodes.\" This provides a clear action for the authors to take, which is to clarify the term in their draft. The second issue is also explicit, as the reviewer suggests that related work is missing and that it seems related but does not negate the novelty of the work. This feedback is actionable because it directs the authors to include relevant related work to support their claims. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L167,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the definition of \"sqeuence of episodes\" and suggesting that practice and evaluation might be the two types of this sequence. Additionally, the comment points out the absence of related work, which is relevant to the context. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises two claims: the first is about the definition of \"sqeuence of episodes,\" and the second is about the lack of related work. The comment does not provide any supporting evidence or reasoning for either claim, such as explaining why the definition is unclear or how the absence of related work affects the novelty of the work. Without additional context or justification, the claims remain 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises two important points. First, it questions the definition of \"sqeuence of episodes,\" which is unclear and needs clarification. This feedback is actionable as it prompts the authors to clarify a critical term in their work. Second, the comment points out the absence of related work, suggesting that it is related but does not negate the novelty of the work. This is a valuable observation that could help the authors strengthen their paper by including relevant references. However, the comment could be more helpful if it provided specific examples of related work or suggested how to integrate it into the paper. Overall, the feedback is 4 as it identifies clear areas for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point questions whether the study on different subdomain sizes can be considered an \"ablation\" study, as it does not involve removing a component of the method. However, it does not provide any explicit or implicit guidance on how the authors should address this issue or what changes, if any, should be made to their draft. The comment lacks actionable advice, leaving the authors without a clear understanding of how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment questions whether the study on different subdomain sizes can be considered an \"ablation\" study, as it does not involve removing a component of the method. However, it does not specify which part of the paper this discussion is based on, making it difficult for the authors to pinpoint the exact section being addressed. The comment lacks specificity regarding what aspect of the study is being questioned or how it should be addressed. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point questions whether the study on different subdomain sizes can be considered an \"ablation\" study, as it does not involve removing a component of the method. The comment provides a logical reasoning by explaining that an ablation study typically involves removing a component to assess its impact. However, it does not provide specific examples or references to support this claim, which would help the authors understand the basis of the critique. Therefore, the comment is 3, as it provides a logical argument but lacks detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment questions whether the study on different subdomain sizes can be considered an \"ablation\" study, as it does not involve removing a component of the method. While the comment raises a valid point about the terminology used, it does not provide any actionable feedback or suggestions for improvement. It lacks depth and does not offer guidance on how the authors might address this issue or clarify their methodology. As a result, the comment is 2, as it identifies a potential misunderstanding but does not assist the authors in resolving it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about whether it would make sense to include and learn AccNet as part of a larger predictor, such as for semantic segmentation, that uses similar operators. While the comment implies that the authors should consider this possibility, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to incorporate AccNet into a larger predictor or what specific steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 126,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether it would make sense to include and learn AccNet as part of a larger predictor, such as for semantic segmentation, that uses similar operators. This provides clear guidance on what the authors should consider, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a question about whether it would make sense to include and learn AccNet as part of a larger predictor, such as for semantic segmentation, that uses similar operators. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification or an inquiry, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the potential inclusion of AccNet as part of a larger predictor, such as for semantic segmentation, that uses similar operators. This is a thoughtful suggestion that could lead to a broader application of the model and potentially enhance its utility. However, the comment lacks depth and does not provide specific guidance or examples on how to implement this idea or what benefits it might offer. While it prompts the authors to consider an expansion of their work, it does not offer detailed actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights that the new proposed metric is only tested on a single dataset, which is a limitation. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue. There is no guidance on whether the authors should test the metric on additional datasets, how they might do so, or what specific datasets would be appropriate. Without any actionable advice or concrete steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a limitation in the paper, noting that the new proposed metric is only tested on a single dataset. However, it does not specify which part of the paper this limitation is discussed in, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the metric or dataset testing are problematic. Without detailed guidance or references to specific sections, the authors cannot effectively address the issue. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the new proposed metric is only tested on a single dataset, which is a limitation. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a limitation in the paper, noting that the new proposed metric is only tested on a single dataset. This is a relevant observation that could impact the generalizability and applicability of the metric. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this limitation, such as recommending additional datasets for testing or discussing potential implications of this limitation. Without actionable feedback or specific advice, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point criticizes the evaluation as weak and notes that the baselines used in the paper are not designed for fair classification. However, it does not provide any explicit or implicit suggestions for how the authors might improve the evaluation or select more appropriate baselines. Without guidance on what specific changes should be made or what alternative baselines could be considered, the authors are left without a clear path forward. The comment lacks actionable details, leaving the authors without a clear understanding of how to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the evaluation as weak and mentions that the baselines used in the paper are not designed for fair classification. However, it does not specify which part of the paper this critique pertains to, such as a particular section or experiment. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing revision. Additionally, the comment does not provide specific details on what aspects of the evaluation are weak or how the baselines could be improved. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the evaluation is weak and that the baselines used in the paper are not designed for fair classification. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate these claims. Without specific details or references to justify the critique, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, specifically the evaluation, by pointing out that the baselines used are not designed for fair classification. This is a critical observation that highlights a fundamental issue with the methodology and results presented. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this issue or select more appropriate baselines. Without detailed feedback or examples, the authors are left with a general understanding of the problem but without a clear path to improvement. Therefore, the comment is 3, as it points out a significant issue but does not fully support the authors in resolving it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the first three paragraphs of Section 2 need to be clarified to spell out the setting more clearly. It implies that the authors may be claiming credit for a more general approach than what is actually presented, which muddles the exposition. However, the comment does not provide specific guidance on how to clarify the setting or what aspects need to be addressed. The action is implicit and somewhat vague, as the authors are left to infer what changes are needed without concrete instructions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first three paragraphs of Section 2, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of needing to spell out the setting more clearly, suggesting that the authors may be claiming credit for a more general approach than what is actually presented, which muddles the exposition. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point claims that the first three paragraphs of Section 2 need to be clarified to spell out the setting more clearly. It suggests that the authors may be claiming credit for a more general approach than what is actually presented, which muddles the exposition. However, the comment lacks specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the exact issue or how to address it. The lack of detailed justification or references makes the claim 3, as it provides a general direction but requires more detailed explanation to be fully actionable.", "helpfulness_rationale": "The review comment identifies a specific issue with the first three paragraphs of Section 2, suggesting that the setting needs to be clarified more clearly. It implies that the authors may be claiming credit for a more general approach than what is actually presented, which muddles the exposition. This feedback is clear and actionable, as it directs the authors to clarify the setting to avoid confusion and ensure that their claims are accurately represented. However, the comment could be more helpful if it provided specific suggestions on how to clarify the setting or what aspects need further elaboration. Overall, the comment is 4 as it points out a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the experiments, specifically questioning the choice of the old baseline and suggesting that the proposed method should be tested on newer 3D CNNs like X3D and SlowFast. The reviewer also asks for a comparison with these approaches to highlight the advantages of the proposed method. While the comment implies that the authors should test their method on these newer approaches and provide a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional experiments and comparisons. However, the comment provides a clear direction for improvement, making it 4.", "grounding_specificity_rationale": "The comment addresses the experiments, specifically questioning the choice of the old baseline and suggesting that the authors should test their method on newer 3D CNNs like X3D and SlowFast. It also asks for a comparison with these approaches to highlight the advantages of the proposed method. However, the comment does not explicitly mention which part of the paper discusses the experiments, making it weakly grounded. The authors can infer that it relates to the experimental section, but this inference is not as direct as it could be. The comment is specific in detailing what needs to be addressed, such as testing on newer 3D CNNs and comparing with existing approaches. Therefore, the comment is 3, aligning with the label 3.", "verifiability_rationale": "The review point questions the validity of the experiments by suggesting that the choice of the old baseline, such as R3D and C3D, may not be sufficient. It proposes that newer 3D CNNs like X3D and SlowFast should be considered for comparison. The comment raises a valid point about the need for a more comprehensive evaluation, but it lacks specific examples or references to support the claim that these newer approaches are superior or more relevant. The lack of detailed justification or evidence makes the claim 3, as the authors would need to conduct additional research to fully address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the experiments, specifically questioning the choice of the old baseline and suggesting that newer 3D CNNs like X3D and SlowFast should be considered for comparison. It also asks for clarification on whether the proposed method works on these newer approaches and what advantages it offers compared to them. This feedback is clear and actionable, as it prompts the authors to expand their experimental evaluation to include more relevant baselines and to highlight the unique contributions of their method. By addressing these points, the authors can enhance the comprehensiveness and impact of their work. Therefore, the comment is rated as 4, as it provides valuable guidance for improving the draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly requests clarification on how the attention module is attached to the backbone ResNet20 architecture during the search process. It asks specific questions about the number of attention modules used and their placement, such as whether they are used after each block or stage. This provides clear and direct guidance on what the authors need to clarify in their draft. The comment is explicit and concrete, giving the authors precise steps to take to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"attention module\" and the \"backbone ResNet20 architecture,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for clarification on how the attention module is attached to the architecture, including questions about the number and placement of attention modules. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the clarity of the paper regarding the attachment of the attention module to the backbone ResNet20 architecture. It asks specific questions about the number and placement of attention modules, which are factual inquiries seeking clarification. However, the comment does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, making it a normal statement. Therefore, the label \"No\" is appropriate.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the attachment of the attention module to the backbone ResNet20 architecture during the search process. It asks clear and direct questions about the number and placement of attention modules, which is a critical aspect of the methodology. By requesting clarification on these details, the comment provides the authors with actionable feedback that can help them improve the clarity and comprehensiveness of their draft. However, the comment could be more helpful if it offered suggestions on how to present this information more clearly or provided examples of similar approaches. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises two specific concerns: the performance of the proposed method at different bitrates and the suggestion to discuss or compare with a related work. The reviewer explicitly asks for the precise bitrate range used for BDrate comparison and suggests discussing or comparing with a specific related work. These requests are clear and provide concrete actions for the authors to take, such as specifying the bitrate range and considering the suggested work for discussion or comparison. The feedback is explicit and provides detailed guidance, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed method and the comparison with baselines at different bitrates, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the need for a precise bitrate range for BDrate comparison and suggests discussing or comparing with a related work by Guo Lu et al. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of two parts: a claim about the performance of the proposed method at different bitrates and a suggestion to discuss or compare with a related work. The first part is a factual statement without an opinion or claim, as it describes the performance of the method at different bitrates. The second part is a suggestion for further discussion or comparison, which does not require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides two specific pieces of feedback. First, it points out that the proposed method performs better at high bitrates but is close to the baselines at low bitrates, prompting the authors to clarify the precise bitrate range used for BDrate comparison. This is a clear and actionable suggestion that can help the authors refine their results presentation. Second, the comment suggests discussing or comparing with a related work by Guo Lu et al. on content adaptive algorithms in learned video compression. This recommendation is valuable as it could enhance the paper\"s context and relevance. Both pieces of feedback are clear and actionable, making the comment 4. However, it could be more comprehensive by providing additional context or suggestions for how to incorporate the related work. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should distinguish the \"allornothing\" or \"cutoff\" phenomenon from the usual statistical bounds that the machine learning and NeurIPS community is familiar with. While the comment implies that the authors should clarify this distinction, it does not provide specific guidance on how to make this distinction or what aspects of the paper need to be revised to achieve this. The action is implicit and somewhat vague, as the authors are left to infer the necessary changes without detailed instructions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should distinguish the \"allornothing\" or \"cutoff\" phenomenon from the usual statistical bounds that the machine learning and NeurIPS community is familiar with. However, it does not specify which part of the paper this distinction should be made in, nor does it provide details on how to make this distinction. Without explicit references to sections or examples, the authors cannot confidently determine where to address this feedback. The comment is weakly grounded as it does not specify the part of the paper being addressed, and it is also not specific because it lacks detailed guidance on how to implement the suggested distinction. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the authors should distinguish the \"allornothing\" or \"cutoff\" phenomenon from the usual statistical bounds that the machine learning and NeurIPS community is familiar with. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this distinction is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains vague and 1, leaving the authors without a clear understanding of the issue or how to address it. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the authors should distinguish the \"allornothing\" or \"cutoff\" phenomenon from the usual statistical bounds that the machine learning and NeurIPS community is familiar with. While the comment identifies a potential area for clarification, it lacks specific guidance or examples on how to make this distinction or what aspects of the paper need to be revised to achieve this. The feedback is 3 as it points out a potential area for improvement, but it could be more actionable with additional details or suggestions. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point critiques the marginal improvements on three tasks over previous works and selfimplemented baselines, suggesting that further analysis beyond the main experiments is insufficient. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or what specific analyses should be conducted. The comment lacks actionable details, leaving the authors uncertain about how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the marginal improvements on three tasks over previous works and selfimplemented baselines, suggesting that further analysis beyond the main experiments is insufficient. However, it does not specify which parts of the paper these tasks or baselines are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. Additionally, the comment lacks specificity regarding what kind of further analysis is needed or how the authors could improve their analysis. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the improvements on three tasks over previous works and selfimplemented baselines are marginal, and further analysis beyond the main experiments is insufficient. However, the comment does not provide specific examples, detailed comparisons, or references to support this claim. Without concrete evidence or detailed reasoning, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that the improvements on three tasks over previous works and selfimplemented baselines are marginal, suggesting that further analysis beyond the main experiments is necessary. However, the comment lacks specificity and does not provide actionable guidance on what additional analysis should be conducted or how the authors might improve their results. Without detailed suggestions or examples, the authors are left with a general idea of what needs to be addressed but without a clear path forward. Therefore, the comment is 2, as it identifies an area for improvement but does not offer sufficient guidance to be fully actionable."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the linear convergence rates rely on Theorem 8, which is buried at the end of the appendix and has a proof that is not clear enough. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to improve the clarity of the proof or where it should be moved within the main text. Without specific suggestions or instructions, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 8,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is the lack of clarity in the proof of Theorem 8 and its location at the end of the appendix. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the linear convergence rates rely on Theorem 8, which is buried at the end of the appendix and has a proof that is not clear enough. However, the comment does not provide any specific reasoning or examples to support why the proof is unclear or how it affects the linear convergence rates. Without detailed justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the linear convergence rates rely on Theorem 8, which is buried at the end of the appendix and has a proof that is not clear enough. This feedback is valuable as it points out a potential weakness in the paper\"s presentation and clarity. However, the comment lacks actionable suggestions or guidance on how the authors might improve the clarity of the proof or its placement within the main text. While it highlights an area for improvement, the lack of detailed feedback limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that the authors should present the average results on the test set with clearly defined error bars under different random seeds. This is a direct and concrete action that the authors can take to improve the credibility of their results. The comment provides specific guidance on what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Tables 1 and 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: presenting average results on the test set with clearly defined error bars under different random seeds. This provides clear guidance on how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the reported results on the dev set are insufficient for convincing the reader. The reviewer suggests presenting average results on the test set with clearly defined error bars under different random seeds. This claim is 3 as it provides a logical reasoning for why the current presentation of results is not sufficient. However, the comment lacks specific examples or references to support the claim, such as comparisons with similar studies or detailed explanations of why the current approach is insufficient. Providing more detailed justification or examples would strengthen the verifiability of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the presentation of results in Tables 1 and 2, where the authors report the best results on the dev set with hyperparameter search and model selection on the dev set. The reviewer suggests that this is not sufficient for convincing the reader and strongly recommends presenting average results on the test set with clearly defined error bars under different random seeds. This feedback is clear and actionable, providing the authors with a specific direction to improve the credibility and robustness of their results. By addressing this suggestion, the authors can enhance the transparency and reliability of their findings, making the comment 5."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises several questions about the methodology and dataset used in the paper. It asks for specific details regarding the number of topics used, the method for obtaining topicword parameters for the \"real\" dataset, the size of the AG news dataset, and the number of documents in the training and testing sets, as well as the vocabulary size. These questions are explicit and provide clear guidance on what information the authors need to include in their paper. The feedback is concrete, as it specifies exactly what details should be addressed, making it 5. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment raises several questions about the methodology and dataset used in the paper, specifically asking for details on the number of topics used, the method for obtaining topicword parameters, the size of the AG news dataset, and the number of documents in the training and testing sets, as well as the vocabulary size. While the comment does not explicitly mention specific sections of the paper, the authors can infer that these questions pertain to the methodology and dataset sections. The questions are specific, as they request detailed information about the dataset and its parameters. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point consists of a series of questions seeking clarification on specific aspects of the methodology and dataset used in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and seek information that would help the authors clarify their work. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises several important questions about the methodology and dataset used in the paper. It asks for specific details regarding the number of topics used, the method for obtaining topicword parameters for the \"real\" dataset, the size of the AG news dataset, and the number of documents in the training and testing sets, as well as the vocabulary size. These questions are relevant and provide clear guidance on what information the authors need to include in their paper to enhance its clarity and transparency. By addressing these questions, the authors can improve the comprehensiveness and rigor of their work. However, the comment could be more helpful if it provided suggestions on how to present this information or why it is important. Overall, the feedback is 4 as it identifies specific areas for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the analysis on BRPNAS is somewhat barebones, as it only compares against three basic alternatives and ignores other NAS approaches like supernet or oneshot approaches. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should consider including more NAS approaches in their analysis, but it lacks concrete details on which specific approaches to include or how to integrate them into the analysis. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the analysis on BRPNAS, specifically noting that it is somewhat barebones due to only comparing against three basic alternatives and ignoring other NAS approaches like supernet or oneshot approaches. However, it does not specify which part of the paper this analysis is presented in, such as a specific section or table. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being discussed. The comment is specific in detailing what is missing from the analysis, namely the inclusion of other NAS approaches. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the analysis on BRPNAS is somewhat barebones, as it only compares against three basic alternatives and ignores other NAS approaches like supernet or oneshot approaches. However, the comment does not provide specific examples or references to support this claim, nor does it explain why these other approaches should be included. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment identifies a specific weakness in the analysis of BRPNAS, noting that it only compares against three basic alternatives and ignores other NAS approaches like supernet or oneshot approaches. This feedback is 3 as it points out a gap in the analysis that could be addressed to provide a more comprehensive evaluation. However, the comment lacks specific suggestions or guidance on how the authors might expand their analysis to include these other approaches, which would make it more actionable. The authors are left with a general understanding of what needs to be improved but without detailed instructions on how to do so. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment expresses a personal preference regarding the focus of the paper, suggesting that the zeroshot version and the connection to density estimation are distracting from the main point. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this perceived distraction or how to better align the paper with the reviewer\"s preference. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses a personal preference regarding the focus of the paper, suggesting that the zeroshot version and the connection to density estimation are distracting from the main point. However, it does not specify which part of the paper these elements are discussed in, making it difficult for the authors to identify the exact sections that need attention. Additionally, the comment lacks specificity in terms of what aspects of these elements are distracting or how they could be better integrated into the main focus. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses a personal preference regarding the focus of the paper, suggesting that the zeroshot version and the connection to density estimation are distracting from the main point. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why these aspects are distracting or how they could be better integrated. Without specific details or references, the claim lacks verifiability, making it difficult for the authors to understand and address the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses a personal preference regarding the focus of the paper, suggesting that the zeroshot version and the connection to density estimation are distracting from the main point. However, the comment does not provide any actionable feedback or suggestions for improvement. It lacks specificity and does not offer guidance on how the authors might better align their work with the reviewer\"s preference. Without actionable advice or constructive criticism, the comment does not help the authors in improving their draft. Therefore, it is rated as 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the experiment results could be enriched by including attacks with different strengths and by exploring how different thresholds influence detection performance. While the comment implies that the authors should expand their experiments to include these aspects, it does not provide specific guidance on how to implement these changes or what specific attacks or thresholds should be considered. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experiment results could be enriched by including attacks with different strengths and by exploring how different thresholds influence detection performance. However, it does not specify which part of the paper this feedback pertains to, such as a specific section or experiment. This lack of explicit reference makes it difficult for the authors to pinpoint the exact areas needing improvement. The comment is specific in suggesting what could be added to enhance the results, but it is 1 because it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the experiment results could be enriched by including attacks with different strengths and exploring how different thresholds influence detection performance. However, the comment lacks specific examples or references to support the claim that these aspects are lacking or how they could enhance the results. Without detailed justification or evidence, the claim remains somewhat vague, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is classified as 3, as it provides some insight but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the experimental results, suggesting that the inclusion of attacks with different strengths and an exploration of how different thresholds influence detection performance could enrich the study. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their experimental analysis. However, the comment could be more helpful if it offered specific examples of attacks or thresholds to consider, which would provide even more detailed guidance. Overall, the comment is 4 as it directs the authors to expand their experimental scope, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that to evaluate the claim of reducing exposure bias, the authors should train a discriminator on generations from the learned model, similar to Figure 1. It also notes that this is different from Figure 4, as the discriminator is coadapting with the generator during training. While the comment implies an action, it does not provide explicit instructions on how to implement this evaluation or what specific steps to take. The authors can infer that they need to conduct this evaluation, but the lack of concrete guidance makes the action somewhat vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"Figure 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that training a discriminator on generations from the learned model is needed to evaluate the claim of reducing exposure bias. The comment provides a clear direction for the authors to address the evaluation aspect of their work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that to evaluate the claim of reducing exposure bias, the authors should train a discriminator on generations from the learned model, similar to Figure 1. It notes that this is different from Figure 4, as the discriminator is coadapting with the generator during training. The comment provides a logical reasoning for the evaluation method, which is based on a common practice in generative models. However, it lacks specific references or examples to fully substantiate the claim, making it 3. The authors would need to infer the exact methodology from the suggestion, which could be clearer with additional details. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for evaluating the claim of reducing exposure bias. It recommends training a discriminator on generations from the learned model, similar to Figure 1, to confirm the claim. This feedback is specific and offers a concrete step for the authors to take to strengthen their evaluation process. However, the comment could be more helpful if it included additional guidance on how to implement this evaluation or what specific metrics to consider. Overall, the comment is 4 as it directs the authors toward a critical aspect of their evaluation, but it could be more comprehensive with further elaboration."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide information on how much performance difference using different image sizes and different variations of ResNets can lead to. This is an explicit request for additional data or analysis, but it does not specify how the authors should go about obtaining this information or what specific metrics or methods to use. While the action is clear, the lack of detailed guidance makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions line number 170, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing: information on how much performance difference using different image sizes and different variations of ResNets can lead to. This provides clear guidance on what the authors need to address in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification, asking for more information on how much performance difference using different image sizes and different variations of ResNets can lead to. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment suggests that the authors provide information on how much performance difference using different image sizes and different variations of ResNets can lead to. This is a clear and actionable suggestion that could help the authors improve their draft by addressing a specific gap in their analysis. However, the comment could be more helpful if it provided additional context or examples of how this information might be presented or analyzed. Overall, the feedback is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with further guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that it would be interesting to see a runtime comparison at test time, given the mention of using Chebyshev polynomials for speedup. While the comment implies that the authors should include a runtime comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to conduct the comparison or what aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that it would be interesting to see a runtime comparison at test time, given the mention of using Chebyshev polynomials for speedup. However, it does not specify which part of the paper discusses this possibility, making it weakly grounded. The comment is specific in suggesting a particular type of comparison that could be included, but without explicit references to sections or parts of the paper, the authors may find it challenging to pinpoint the exact area needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it would be interesting to see a runtime comparison at test time, given the mention of using Chebyshev polynomials for speedup. This is a request for additional information or analysis, rather than a claim or opinion that requires verification. It does not present subjective judgments, suggestions, or deductions that need to be supported by evidence or reasoning. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment suggests that it would be interesting to see a runtime comparison at test time, given the mention of using Chebyshev polynomials for speedup. This feedback is 3 as it points out a potential area for improvement in the paper, specifically suggesting a comparison that could enhance the understanding of the method\"s performance. However, the comment lacks specific guidance on how to conduct the comparison or what aspects to focus on, which limits its usefulness. To be more helpful, the comment could include suggestions on the methodology or metrics to use for the comparison. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the applicability of the proposed method to natural images, such as CIFAR10, which are more relevant to realworld applications. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should test the method on CIFAR10, modify the method to accommodate natural images, or address the issue in the paper. The comment lacks actionable details, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the applicability of the proposed method to natural images, such as CIFAR10, which are more relevant to realworld applications. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its inquiry about the method\"s applicability to natural images, but it lacks grounding as it does not reference a particular section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the applicability of the proposed method to natural images, such as CIFAR10, which are more relevant to realworld applications. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the method might not work on natural images. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the applicability of the proposed method to natural images, such as CIFAR10, which are more relevant to realworld applications. This is a valuable observation that prompts the authors to consider expanding the scope of their method to include natural images, which could enhance the practicality and relevance of their work. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as testing the method on CIFAR10 or discussing potential modifications. While it identifies a critical area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the figures are not clear, specifically mentioning that the relationship between the subfigures in Figure 2 is confusing and that some modules, such as CMAF, L_BT, and VoLTA, are not labeled. This provides clear and direct actions for the authors to take, which is to clarify the relationships between the subfigures and label the missing modules. The feedback is specific and actionable, giving the authors concrete steps to improve the clarity of their figures. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the relationship between the subfigures is confusing and that some modules, such as CMAF, L_BT, and VoLTA, are not labeled. This provides clear guidance on what needs to be addressed to improve the clarity of the figures. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the figures are not clear, specifically mentioning that the relationship between subfigures in Figure 2 is confusing and that some modules are not labeled. This is a subjective claim that requires justification or examples to support the assertion. The comment lacks specific details or references to explain why the figures are unclear or how they could be improved. Without additional context or examples, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies specific issues with the clarity of the figures, particularly in Figure 2, where the relationship between subfigures is confusing and some modules are not labeled. This feedback is clear and actionable, as it provides the authors with a direct way to improve the clarity and readability of their figures. By addressing these issues, the authors can enhance the comprehensibility of their work for readers. However, the comment could be more helpful if it offered suggestions on how to clarify the relationships or label the missing modules. Overall, the comment is 4 as it effectively guides the authors toward improving the visual presentation of their results."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about questionable design choices related to the use of perplexity as a measure of semantic information retention after finetuning. It questions whether this measure adequately addresses aspects of domain drift and catastrophic forgetting. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their design choices. The action is implicit, as the authors need to infer that they should consider alternative measures or methods to account for domain drift and catastrophic forgetting. Additionally, the comment lacks concrete details on how to implement these changes, making it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises concerns about questionable design choices related to the use of perplexity as a measure of semantic information retention after finetuning. It questions whether this measure adequately addresses aspects of domain drift and catastrophic forgetting. However, the comment does not specify which part of the paper discusses these design choices or where the authors should address these concerns. Without explicit references to sections, tables, or figures, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, while the comment highlights specific issues, it does not provide detailed guidance on how to address them. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a concern about the use of perplexity as a measure of semantic information retention after finetuning, questioning whether it adequately addresses aspects of domain drift and catastrophic forgetting. The comment provides a logical reasoning by suggesting that there are separate factors to consider, such as domain drift, which are not fully addressed by perplexity. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to further explore the issue to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the design choices in the paper, specifically questioning the use of perplexity as a measure of semantic information retention after finetuning. It highlights the need to consider aspects of domain drift and catastrophic forgetting, which are separate from the original task. However, the comment does not provide specific suggestions or guidance on how the authors might address these concerns or improve their design choices. While it points out a relevant area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight into a potential weakness but lacks depth and specificity in its feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the impact of the number of images on model performance and the need to explain BYOL in the abstract. While it implies that the authors should address these issues, the comment does not provide explicit instructions on how to do so. The questions are clear, but the lack of guidance on how to address them makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the impact of the number of images on model performance and the need to explain BYOL in the abstract. However, it does not specify which part of the paper these questions pertain to, making it weakly grounded. The comment is specific in its request for clarification on the impact of image number and the explanation of BYOL, but without clear grounding, the authors may struggle to identify the exact sections needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions seeking clarification and additional information, such as the impact of the number of images on model performance and the need to explain BYOL in the abstract. These are requests for clarification or elaboration, not claims or opinions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the impact of the number of images on model performance and the need to explain BYOL in the abstract. These are relevant points that could help the authors clarify and improve their draft. However, the comment lacks specific guidance or suggestions on how to address these questions or what additional information should be included. While it identifies areas for improvement, the feedback is somewhat vague, making it 3. The authors are given a direction to explore but without detailed instructions, which limits the comment\"s usefulness. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the sufficiency of the training data, specifically questioning whether 44k dialogues can capture a wide range of user traits and personalities across different content topics. The reviewer suggests that LLMs are typically trained on trillions of tokens, implying that the dataset size is insufficient. However, the comment does not provide explicit guidance on how the authors should address this concern or suggest ways to improve the dataset. The action is implicit and vague, as the authors are left to infer that they need to increase the dataset size but without specific instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the sufficiency of the training data, specifically questioning whether 44k dialogues are sufficient to capture a wide range of user traits and personalities across different content topics. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the dataset size and its implications for capturing user traits and personalities, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the sufficiency of the training data, specifically questioning whether 44k dialogues are sufficient to capture a wide range of user traits and personalities across different content topics. The reviewer compares this dataset size to the typical training data for LLMs, which are often trained on trillions of tokens. However, the comment lacks specific examples or references to support the claim that 44k dialogues are insufficient. The reasoning is logical but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is 3, as it provides a logical basis but lacks comprehensive support.", "helpfulness_rationale": "The review comment raises a concern about the sufficiency of the training data, specifically questioning whether 44k dialogues are sufficient to capture a wide range of user traits and personalities across different content topics. The reviewer compares this dataset size to the typical training data for LLMs, which are often trained on trillions of tokens, suggesting that the dataset may not be comprehensive enough. This feedback is 3 as it highlights a potential limitation in the dataset and prompts the authors to consider the impact of dataset size on the model\"s performance. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending additional data sources or methods to enhance the dataset. Therefore, it is 3, as it identifies a weakness but does not provide detailed actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should use other metrics, specifically BERTScore, to evaluate their results. This is an explicit suggestion that provides a clear action for the authors to take. The comment is also concrete, as it specifies the exact metric that should be used, giving the authors a direct and specific direction for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests using other metrics, specifically BERTScore, to evaluate the results. However, it does not specify which part of the paper this suggestion pertains to, such as the Results section or a specific table or figure. Without explicit references, the authors may find it challenging to determine where to incorporate this suggestion. The comment is specific in recommending the use of BERTScore, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests using other metrics, specifically BERTScore, to evaluate the results. However, it does not provide any reasoning or evidence to support why BERTScore is a better or more appropriate metric compared to the ones already used. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests using other metrics, specifically BERTScore, to evaluate the results. While it identifies a potential area for improvement, it lacks specificity and does not provide a rationale or explanation for why BERTScore might be a better choice over the current metrics. The comment does not offer guidance on how to implement BERTScore or how it might enhance the evaluation process. As a result, the feedback is 3, as it points out a possible improvement but does not provide enough detail or context to be fully actionable. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should compare their SynTextBench metric to other metrics proposed in the literature, such as MMLU or Big Bench, to understand under what conditions one should use SynTextBench. While the comment implies that the authors should conduct this comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to conduct the comparison or what aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"SynTextBench metric,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests comparing the SynTextBench metric to other metrics proposed in the literature, such as MMLU or Big Bench, to understand under what conditions one should use SynTextBench. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that there has been a significant amount of work on LLM evaluation, with some metrics not satisfying the proposed desiderata. It recommends comparing the SynTextBench metric to other metrics in the literature to understand its applicability. The comment provides a logical reasoning by referencing existing work and suggesting a specific comparison, which is a clear and actionable suggestion. However, it does not provide specific references to the existing metrics or studies, which would strengthen the verifiability of the claim. Therefore, the comment is 4, as it provides a solid basis for the suggestion but lacks detailed references.", "helpfulness_rationale": "The review comment provides a constructive suggestion for the authors to compare their SynTextBench metric with other metrics proposed in the literature, such as MMLU or Big Bench, to understand under what conditions one should use SynTextBench. This feedback is clear and actionable, as it identifies a specific area for improvement and offers a concrete comparison to consider. By suggesting this comparison, the comment empowers the authors to enhance the comprehensiveness and applicability of their work. However, the comment could be more helpful if it included specific examples or references to guide the authors in conducting the comparison. Overall, the comment is 4, as it provides valuable guidance for improving the draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point highlights a general issue with the writing and annotations, noting that they are \"a little hard to follow.\" However, it does not provide any specific guidance or suggestions on how the authors might improve the clarity or readability of their draft. The comment lacks actionable details, such as identifying particular sections or aspects that need improvement or suggesting specific changes to enhance clarity. As a result, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions \"poor writing and annotations,\" but it does not specify which parts of the paper are affected or provide details on what aspects of the writing or annotations are problematic. This lack of specificity and grounding makes it difficult for the authors to identify the exact areas that need improvement. The comment is 1 as it does not refer to any specific sections, figures, or tables, and it is not specific because it does not detail what needs to be addressed. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the writing and annotations are \"a little hard to follow,\" but it does not provide any specific examples or detailed reasoning to support this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. The comment lacks verifiability as it does not offer sufficient evidence or justification for the claim, making it difficult for the authors to improve their draft based on this feedback. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The comment points out a general issue with the writing and annotations, noting that they are \"a little hard to follow.\" However, it lacks specificity and does not provide any actionable feedback or suggestions on how the authors might improve the clarity or readability of their draft. Without detailed guidance or examples, the authors are left without a clear understanding of what changes are needed to address the issue. Therefore, the comment is 1, as it does not offer any actionable insights or direction for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the performance of the proposed method in Table 2, specifically regarding the evaluation metrics and the \"Twitter2017 $\rightarrow$ Twitter2015\" setting. It highlights a discrepancy between the overall F1 score and the F1 scores for individual types. While the comment identifies an area of concern, it does not provide explicit guidance or suggestions on how the authors should address this issue. The authors are left to infer that they should investigate and explain this discrepancy, but without concrete steps or suggestions, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the proposed method\"s performance in terms of achieving SOTA performances and the discrepancy in F1 scores between the overall and individual types. The comment raises a question about the performance in a specific setting, which provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the performance of the proposed method in Table 2, specifically regarding the evaluation metrics and the \"Twitter2017 $\rightarrow$ Twitter2015\" setting. It highlights a discrepancy between the overall F1 score and the F1 scores for individual types. While the comment identifies a potential issue, it does not provide any supporting evidence, reasoning, or references to substantiate the claim. The lack of detailed explanation or references makes it difficult for the authors to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the performance of the proposed method in Table 2, noting that only 8 of the 14 evaluation metrics achieve stateoftheart (SOTA) performances. It also questions the discrepancy between the overall F1 score and the F1 scores for individual types in a particular setting. This feedback is clear and actionable, as it prompts the authors to investigate and explain this discrepancy, which could be a critical aspect of their methodology. By addressing these points, the authors can enhance the clarity and robustness of their results. However, the comment could be more helpful if it provided suggestions on how to address the issue or offered additional context. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the rationale behind considering only ECG segments with one label assigned, suggesting that including all reports would be more beneficial. While the comment implies that the authors should reconsider their approach, it does not explicitly instruct them to do so or provide specific guidance on how to address this issue. The action is implicit and somewhat vague, as the authors can infer that they need to reconsider their methodology but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions the rationale behind considering only ECG segments with one label assigned, suggesting that including all reports would be more beneficial. However, it does not specify which part of the paper discusses this methodology, making it weakly grounded. The comment is specific in its critique of the approach, questioning the rationale behind the chosen methodology. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the rationale behind considering only ECG segments with one label assigned, suggesting that including all reports would be more beneficial. The comment provides a logical reasoning by implying that considering all reports would lead to a more comprehensive analysis. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to consider the implications of including all reports to fully understand the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the rationale behind considering only ECG segments with one label assigned, suggesting that including all reports would be more beneficial. This feedback highlights a potential limitation in the methodology and prompts the authors to reconsider their approach. However, the comment does not provide specific suggestions or examples on how to address this issue or improve the methodology. While it identifies a potential area for improvement, it lacks depth and actionable guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the results presentation can be improved, specifically mentioning that the yaxis in Figures 2 and 3 is labeled as \"performance,\" which is ambiguous, and that the runtime is not represented. It provides a concrete suggestion to present the results as a scatter plot with the x/y axes being runtime/performance, which would help readers better understand and interpret the results. Additionally, it recommends highlighting the best results in tables. While the comment is explicit in its suggestions, it does not provide detailed guidance on how to implement these changes, such as specific formatting or presentation guidelines. Therefore, the comment is 4, as it provides clear directions but lacks detailed execution steps.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2 and 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details what needs to be improved, such as the labeling of the yaxis as \"performance\" and the absence of runtime representation in those figures. Additionally, it provides a concrete suggestion to present the results as a scatter plot with x/y axes being runtime/performance, which would help readers better understand and interpret the results. The comment also suggests highlighting the best results in tables. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the results presentation can be improved by providing a scatter plot with x/y axes being runtime/performance, which would help readers better understand and interpret the results. The comment also mentions that the yaxis in Figures 2 and 3 is labeled as \"performance,\" which is ambiguous, and that the runtime is not represented. This feedback is 4 as it provides a logical reasoning for improving the clarity of the results presentation, but it lacks specific examples or references to support the claim. The authors would need to infer the exact improvements needed based on the suggestion. Therefore, the comment is categorized as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on how to improve the presentation of results in the paper. It identifies a lack of clarity in the labeling of the yaxis in Figures 2 and 3, which is labeled as \"performance,\" and suggests that the runtime should also be represented. The comment offers a concrete suggestion to present the results as a scatter plot with x/y axes being runtime/performance, which would help readers better understand and interpret the results. Additionally, it recommends highlighting the best results in tables. This feedback is clear and actionable, providing the authors with a direct path to enhance the clarity and effectiveness of their results presentation. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the meaning of the statement \"NodeSort differentially sorts nodes depending on the base node.\" It asks whether the base node affects the ordering, the key nodes for attention, and the model performance. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this question or clarify the statement in their draft. As a result, the authors are left without a clear understanding of what steps to take to improve their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the meaning of a statement in the paper, specifically regarding the impact of the base node on the ordering, key nodes for attention, and model performance. However, it does not specify which part of the paper this statement is from, making it difficult for the authors to pinpoint the exact section that needs clarification. The comment is specific in its inquiry about the implications of the base node, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question seeking clarification about the statement \"NodeSort differentially sorts nodes depending on the base node.\" It does not express an opinion, judgment, or suggestion that requires verification. It is a request for clarification, which is factual and does not contain a claim. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the meaning of a statement in the paper, specifically regarding the impact of the base node on the ordering, key nodes for attention, and model performance. While it identifies a potential area of confusion, it does not provide any suggestions or guidance on how the authors might clarify or address this issue in their draft. The comment lacks depth and actionable feedback, leaving the authors with only a vague understanding of what needs to be improved. Therefore, it is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the direction of the arrow in Figure 2, asking why it is from a Gaussian space into the latent space rather than from the latent space to n^(i). The reviewer suggests that the main purpose might be to influence n^(i). While the comment raises a specific question about the arrow direction, it does not provide explicit guidance on how the authors should address this issue or what changes, if any, are needed. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the arrow direction but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the direction of the arrow in the figure and provides a rationale for why it might be unexpected, suggesting that the main purpose might be to influence n^(i). This level of detail helps the authors understand what aspect of the figure needs clarification or revision. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the direction of the arrow in Figure 2, suggesting that it should be from the latent space to n^(i) rather than from a Gaussian space. The reviewer provides a logical reasoning by stating that the main purpose might be to influence n^(i). However, the comment lacks specific references or detailed explanations to fully substantiate the claim. While the reasoning is clear, the lack of additional evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a specific question about the direction of the arrow in Figure 2, questioning why it is from a Gaussian space into the latent space rather than from the latent space to n^(i). This feedback is 3 as it prompts the authors to clarify the purpose and direction of the arrow, which could be important for understanding the methodology. However, the comment does not provide any suggestions or guidance on how to address this issue or improve the figure\"s clarity. To be more helpful, the comment could include suggestions on how to better explain the arrow\"s direction or its significance in the context of the paper. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with abbreviations in Table 5, noting that \"AR\" stands for domain adaptation tasks and algorithms. This feedback is explicit and provides a clear action for the authors to take, which is to define the abbreviations used in the table. The comment is concrete because it specifies exactly what needs to be done to improve the clarity of the table. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular issue with abbreviations, namely that \"AR\" stands for domain adaptation tasks and algorithms. This provides clear guidance on what needs to be addressed to improve the clarity of the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that many abbreviations lack definition and cause confusion, specifically mentioning that \"AR\" in Table 5 stands for domain adaptation tasks and algorithms. This claim is 3 as it provides a specific example of an abbreviation that is unclear, but it lacks broader context or justification for why other abbreviations might also be problematic. The comment could be strengthened by providing more examples or explaining how these abbreviations impact the clarity of the paper. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with abbreviations in the paper, noting that many of them lack definition and cause confusion. It provides a concrete example by pointing out that \"AR\" in Table 5 stands for domain adaptation tasks and algorithms. This feedback is clear and actionable, as it directs the authors to define abbreviations used in the paper to improve clarity and prevent confusion among readers. However, the comment could be more helpful if it suggested specific ways to define these abbreviations or provided examples of how to do so. Overall, the comment is 4 as it highlights a critical area for improvement and provides a clear direction for the authors to enhance the clarity of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the choice of using advantage instead of q value for conducting the analysis. While it implies that the authors should consider other technical considerations for this choice, it does not explicitly instruct them to do so or provide specific guidance on what those considerations might be. The action is implicit and somewhat vague, as the authors can infer that they should explore other technical reasons but are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the choice of using advantage instead of q value for conducting the analysis, suggesting that there might be other technical considerations. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the technical considerations, but without clear grounding, the authors may struggle to determine where to address this issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the choice of using advantage instead of q value for conducting the analysis, suggesting that there might be other technical considerations. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this choice is more common in practice or what specific technical considerations might exist. Without additional context or explanation, the claim remains vague and 1, leaving the authors without a clear understanding of the basis for the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the choice of using advantage instead of q value for conducting the analysis, suggesting that there might be other technical considerations. While it identifies a potential area for exploration, it lacks depth and does not provide specific guidance or suggestions on how the authors might address this question or what other technical considerations might be relevant. The comment is 3 as it prompts the authors to consider an alternative approach, but it does not offer actionable steps or detailed feedback to enhance the draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the setting of Unsupervised Online Adaptation, suggesting that it is not truly unsupervised because the training set requires annotations. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or clarify the setting. Without specific suggestions or instructions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec 3.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the setting of Unsupervised Online Adaptation is strange because it requires a training set with documents, queries, and labels, which contradicts the notion of unsupervised adaptation. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the setting of Unsupervised Online Adaptation is strange because it requires a training set with documents, queries, and labels, contradicting the notion of unsupervised adaptation. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the setting of Unsupervised Online Adaptation, pointing out that it requires a training set with documents, queries, and labels, which contradicts the notion of unsupervised adaptation. This feedback is 3 as it highlights a possible inconsistency in the paper, prompting the authors to reconsider their approach or clarify the setting. However, the comment lacks specific suggestions or guidance on how to address this issue, such as proposing alternative methods or explaining the rationale behind the current setup. To be more helpful, the comment could provide more detailed feedback or actionable advice. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the fairness of the performance comparison in Table 1, specifically mentioning that VINS sets different sample weights W u i in the training process, while most compared baselines like DNS, AOBPR, SA, and PRIS set all sample weights as 1. This comment implies that the authors should address the issue of fairness in the performance comparison, but it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should investigate and potentially adjust the sample weights to ensure fairness. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the unfairness in the performance comparison due to different sample weights used by VINS compared to other baselines like DNS, AOBPR, SA, and PRIS. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the performance comparison in Table 1 is unfair due to different sample weights used by VINS compared to other baselines. This claim is 3 as it provides a specific reason for the perceived unfairness, namely the use of different sample weights. However, the comment lacks detailed examples or references to support the claim fully, such as comparing the performance with and without these sample weights. This makes the claim 3, as it provides a basis for the critique but requires more detailed evidence to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific issue with the performance comparison in Table 1, noting that the fairness of the comparison is compromised due to different sample weights used by VINS compared to other baselines. This feedback is clear and actionable, as it highlights a potential bias in the evaluation process that could impact the interpretation of results. By pointing out this issue, the comment provides the authors with a clear direction for improvement, such as adjusting the sample weights or providing additional context to ensure a fair comparison. However, the comment could be more helpful if it suggested specific ways to address the issue or provided examples of how to ensure fairness in the comparison. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a potential issue with the time complexity if the reply buffer is too large. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting ways to optimize the buffer size or alternative methods to reduce complexity. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions the time complexity issue related to the reply buffer being too large, but it does not specify which part of the paper this issue is discussed in. Without explicit references to sections, tables, or figures, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what needs to be addressed or how to improve the time complexity issue. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the time complexity will be too high if the reply buffer is too large, and it references PRMRL as a source. However, the comment does not provide detailed reasoning or examples to support this claim, such as how the time complexity is calculated or how the buffer size affects it. The reference to PRMRL is a general reference to a related work, but it does not directly address the specific issue raised in the comment. Therefore, the claim is 3, as it provides some support but lacks detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the time complexity of the reply buffer being too large, which could impact the overall performance of the system. However, it does not provide any specific suggestions or guidance on how to address this issue, such as recommending ways to optimize the buffer size or suggesting alternative methods to reduce complexity. Without actionable advice or detailed feedback, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, as it highlights a concern but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should display the performance of accelerating SGMs by involving other baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. However, it does not provide specific guidance on which baselines to include or how to implement these suggestions. The action is implicit and somewhat vague, as the authors are left to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should display the performance of accelerating SGMs by involving other baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting alternative perspectives and baselines to consider, but without clear grounding, the authors may struggle to identify where these suggestions should be implemented. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should display the performance of accelerating SGMs by involving other baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. However, the comment does not provide specific examples or references to support the claim that these alternative perspectives are necessary or beneficial. Without detailed justification or evidence, the authors may find it challenging to understand the rationale behind this suggestion. Therefore, the comment is considered 2, as it lacks sufficient support to fully substantiate the claim.", "helpfulness_rationale": "The review comment suggests that the authors should display the performance of accelerating SGMs by involving other baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. This feedback is 3 as it identifies a potential area for improvement by suggesting alternative perspectives that could enhance the paper\"s contribution. However, the comment lacks specific guidance on which baselines to consider or how to implement these suggestions, leaving the authors with a general direction but not a detailed plan for improvement. Therefore, the comment is rated as 3, as it provides some insight but could be more actionable with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to provide a brief conclusion and a summary of their contributions. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific task that the authors need to address, making it 5. The authors know exactly what needs to be done to enhance their paper, ensuring a score of 5.", "grounding_specificity_rationale": "The comment explicitly mentions the need for a brief conclusion and a summary of the paper\"s contributions, providing clear guidance on what needs to be addressed. However, it does not specify which part of the paper currently lacks these elements, making it weakly grounded. The authors can infer that it pertains to the conclusion or abstract sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point is a request for a brief conclusion and a summary of the paper\"s contributions, which is a factual statement requiring no verification. It does not contain any subjective claims, opinions, or suggestions that would necessitate verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the paper lacks a brief conclusion and a summary of its contributions. This feedback is clear and actionable, as it provides the authors with a direct task to enhance their draft. By addressing this feedback, the authors can better communicate the significance and impact of their work to the readers. However, the comment could be more helpful if it offered suggestions on how to structure the conclusion or what aspects to highlight in the summary. Overall, the comment is 4, as it directs the authors to a critical area for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should compare their framework with a method designed to defend against multiple attacks, as the current comparison with APEGAN may not be comprehensive. While the comment implies that this comparison would enhance the paper\"s results, it does not explicitly instruct the authors to make this comparison or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should compare with a method that defends against multiple attacks and determine how to implement this comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should compare their framework with a method designed to defend against multiple attacks, rather than just APEGAN. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where comparisons are made. The authors can infer that it relates to the results or discussion sections, but this inference is not explicit. The comment is specific in suggesting a comparison with a method that defends against multiple attacks, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should compare their framework with a method designed to defend against multiple attacks, as the current comparison with APEGAN may not be comprehensive. The comment provides a logical reasoning for the suggestion, noting that such a comparison would enhance the paper\"s results. However, it lacks specific references or examples of methods that defend against multiple attacks, which would strengthen the claim. Therefore, the comment is 3, as it provides a logical basis but requires more detailed evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment suggests that the authors should expand their comparison by including a method designed to defend against multiple attacks, rather than just APEGAN. This feedback is 3 as it identifies a potential area for improvement in the paper\"s results and suggests a way to enhance the comprehensiveness of the study. However, the comment could be more helpful if it provided specific examples of methods to consider or detailed guidance on how to incorporate this comparison. Overall, the feedback is actionable but incomplete, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to define the bounds for \tau_i^l, which is crucial for understanding the timewarp function. This is a clear and direct action for the authors to take, providing them with a specific task to complete. The comment is concrete because it specifies exactly what needs to be defined, making it 5. Therefore, this comment aligns with a score of 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"l111,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be defined, which is the bounds for \tau_i^l, and why it is important for understanding the timewarp function. This provides clear guidance on what the authors need to address in their draft. Therefore, this comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point is a request for clarification, specifically asking the authors to define the bounds for \tau_i^l. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for additional information, making it a factual statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment is 5 as it provides clear and actionable feedback by explicitly requesting the authors to define the bounds for \tau_i^l. This is an important detail that can help readers better understand the timewarp function. By addressing this request, the authors can enhance the clarity and comprehensibility of their work, making it more accessible to readers. The comment is specific and actionable, offering a direct path for improvement. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights specific writing errors, such as \"informative informative\" and \"performance,\" and notes that the latter lacks a title. While the comment identifies these issues, it does not provide explicit guidance on how to correct them or suggest ways to improve the writing. The authors can infer that they need to proofread their manuscript for such errors, but the comment lacks concrete details on how to address these issues. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific pages (5 and 1) where writing errors are found, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the exact errors, such as \"informative informative\" and \"performance,\" and notes that the latter lacks a title. This level of detail provides clear guidance on what needs to be corrected, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point highlights specific writing errors, such as \"informative informative\" and \"performance,\" and notes that the latter lacks a title. However, the comment does not provide any reasoning or examples to support why these errors are problematic or how they impact the paper\"s clarity or readability. Without additional context or explanation, the authors may find it challenging to understand the significance of these errors and how to address them. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies specific writing errors in the paper, such as \"informative informative\" and \"performance,\" which lack a title. This feedback is valuable as it points out areas where the authors can improve the clarity and professionalism of their manuscript. However, the comment does not provide suggestions on how to correct these errors or offer broader guidance on improving the overall writing quality. While it highlights a specific issue, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to rewrite the first sentence of the abstract. This is a clear and direct action, leaving no ambiguity about what needs to be done. The comment provides a specific and concrete instruction, making it 5. The authors know exactly what step to take to improve their draft, which aligns with a score of 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first sentence of the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the rewriting of the first sentence of the abstract. Therefore, this comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point is a request for a change, specifically asking for the first sentence of the abstract to be rewritten. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely a request for modification, making it a normal statement and fitting the label \"No\".", "helpfulness_rationale": "The comment provides a clear and direct suggestion for improvement by instructing the authors to rewrite the first sentence of the abstract. This feedback is actionable and specific, offering a concrete step the authors can take to enhance the clarity and impact of their abstract. However, the comment does not elaborate on why the current sentence is problematic or what specific changes would improve it. While it provides a clear direction, it lacks depth and detailed guidance, making it 4. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the method is more complex than necessary and implies that there might be a simpler underlying principle driving the quality gains. However, it does not provide explicit guidance or suggestions on how to simplify the method or identify the underlying principle. The action is implicit and vague, as the authors are left to infer what changes might be needed without concrete instructions. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the method is more complex than necessary and implies that there might be a simpler underlying principle driving the quality gains. However, it does not specify which part of the paper this critique pertains to, such as a specific section, figure, or table. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the method are considered overly complex or how to simplify it. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the method is more complex than necessary and implies that there might be a simpler underlying principle driving the quality gains. However, the comment lacks specific examples, detailed reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the method is more complex than necessary and implies that there might be a simpler underlying principle driving the quality gains. While it identifies a potential issue with the complexity of the method, it lacks specificity and does not provide actionable guidance or suggestions on how to simplify the method or identify the underlying principle. The comment points out a possible area for improvement but does not offer detailed advice or examples, leaving the authors with limited insight into how to address the issue. Therefore, the comment is 2, as it provides some insight but lacks depth and actionable feedback."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the hGRU architecture appears adhoc and lacks motivation, but it does not provide any explicit or implicit suggestions for improvement. It does not offer guidance on how the authors might address this issue or provide specific details on what aspects of the architecture need to be improved or motivated. Without actionable advice or concrete steps, the authors are left without a clear understanding of how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the hGRU architecture as \"adhoc\" and lacking motivation, but it does not specify which part of the paper discusses this architecture. Without explicit references to sections, tables, or figures, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the architecture are considered adhoc or how it could be better motivated. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the hGRU architecture is \"adhoc\" and lacks motivation. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why the architecture is considered adhoc or how it could be improved. Without specific details or references, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The comment points out a potential issue with the hGRU architecture, suggesting that it appears adhoc and lacks motivation. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve the architecture. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the use of \"s_n\" instead of \"s_t\" in Algorithm 1, Line 8. It also expresses curiosity about the asymptotic performance of the proposed method and requests average return results with more environment steps. The comment provides a specific suggestion for improvement by recommending the use of \"s_n\" instead of \"s_t\" and requests additional data to support the claim. While the comment is explicit in its request for clarification and additional data, it does not provide detailed guidance on how to implement these changes or what specific data to include. Therefore, the comment is 4, as it clearly identifies the areas for improvement but lacks detailed instructions on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"algorithm 1 Line 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the use of \"s_n\" instead of \"s_t\" and expresses curiosity about the asymptotic performance of the proposed method. The comment further requests additional data, such as average return results with more environment steps, and provides a reference to a relevant GitHub repository. This level of detail and specificity helps the authors understand what needs to be addressed and how to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the use of \"s_n\" instead of \"s_t\" in Algorithm 1, Line 8, and expresses curiosity about the asymptotic performance of the proposed method. It also requests additional data, such as average return results with more environment steps. The comment provides a reference to a GitHub repository, which could be considered a form of external reference. However, the claim itself is more of a request for clarification or additional data, rather than a statement that requires verification. Therefore, the comment is 4, as it provides some support through the reference but lacks detailed reasoning or evidence to fully substantiate the claim. The authors would need to provide the requested data to address the concern. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises a specific question about the use of \"s_n\" instead of \"s_t\" in Algorithm 1, Line 8, which is a clear and actionable suggestion for improvement. It also expresses curiosity about the asymptotic performance of the proposed method and requests additional data, such as average return results with more environment steps. This feedback is valuable as it directs the authors to a potential error in their algorithm and encourages them to provide additional data to support their claims. However, the comment could be more helpful if it provided more detailed guidance on how to address the issue with the algorithm or what specific data to include. Overall, the comment is 4 as it identifies a specific area for improvement and provides a clear direction for additional analysis, but it could be more comprehensive with further guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the challenges when analyzing Adam under the (L0, L1)smoothness condition, suggesting that standard analysis could be applied. It implies that the authors should explain the challenges and differentiate their approach from that of Zhang et al. While the comment identifies a need for clarification, it does not provide explicit instructions on how to address the issue or what specific aspects should be highlighted. The action is implicit and somewhat vague, as the authors can infer that they need to provide additional explanation but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper, namely the challenges when analyzing Adam under the (L0, L1)smoothness condition. It implies that the authors should explain the challenges and differentiate their approach from that of Zhang et al. However, the comment does not explicitly mention which section or part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the challenges and differences with existing work. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the clarity of the challenges when analyzing Adam under the (L0, L1)smoothness condition, suggesting that standard analysis could be applied. The comment implies that the authors should explain the challenges and differentiate their approach from that of Zhang et al. However, the comment lacks specific examples or detailed reasoning to support the claim that standard analysis could be applied. This makes the claim 3, as it provides a basis for questioning but requires more detailed justification or evidence to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the challenges when analyzing Adam under the (L0, L1)smoothness condition. It suggests that standard analysis could be applied and recommends that the authors explain the challenges and differentiate their approach from that of Zhang et al. This feedback is clear and actionable, as it directs the authors to clarify their analysis and highlight the unique aspects of their work. However, the comment could be more helpful if it provided specific examples or detailed guidance on how to differentiate the approach. Overall, the comment is 4 as it guides the authors toward improving the clarity and differentiation of their work."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point highlights that most person reID methods are based on pedestrian detectors (twostep methods) and mentions the existence of endtoend methods that combine detection and reID. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this information or how it relates to their work. Without any actionable suggestions or questions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions \"most of person reID methods\" and \"pedestrian detector\" without specifying which part of the paper these methods are discussed in. This makes it difficult for the authors to pinpoint the exact section being addressed. Additionally, the comment provides a general observation about the existence of endtoend methods but does not specify what needs to be addressed or improved regarding this observation. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point makes a factual statement about the basis of person reidentification methods, mentioning that most are based on pedestrian detectors (twostep methods) and that there are also endtoend methods that combine detection and reID. This statement is based on common knowledge in the field and does not require additional evidence or references to be considered factual. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a general observation about the basis of person reidentification methods, noting that most are based on pedestrian detectors (twostep methods) and that there are also endtoend methods that combine detection and reID. While this information is factual and may be of interest to the authors, it does not offer any specific feedback or suggestions for improvement. The comment lacks depth and does not provide actionable guidance for the authors to enhance their draft. As a result, it is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point suggests adding a first sentence to introduce the content of Section 3.2. While it explicitly states an action, it lacks specific guidance on what should be included in the introduction sentence. The authors are aware of the need to introduce the section but may struggle to determine the exact content of the introduction. Therefore, the comment is 3, as it provides a clear direction but lacks detailed instructions on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding a first sentence to introduce the section, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests adding a first sentence to introduce Section 3.2. However, it does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification or improvement, fitting the classification of \"No.\"", "helpfulness_rationale": "The comment suggests adding a first sentence to introduce Section 3.2, which is a straightforward and actionable piece of feedback. By doing so, the authors can ensure that readers are immediately aware of the content and purpose of the section, enhancing the clarity and accessibility of the paper. However, the comment lacks depth and does not provide specific guidance on what should be included in the introduction sentence. While it offers a clear direction for improvement, it could be more helpful if it provided more detailed suggestions or examples. Therefore, the comment is rated as 3, as it provides a clear action but lacks comprehensive guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the meaning of the phrase \"initial rationale selector is perfect\" and suggests that if it were perfect, no additional work would be needed. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to clarify or address this point in the draft, nor are there suggestions for improvement or correction. As a result, the comment lacks any actionable advice, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 44,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the meaning of the phrase \"initial rationale selector is perfect\" and provides a logical reasoning for why this might be problematic. The comment clearly specifies what needs to be addressed, which is the clarification of the phrase \"initial rationale selector is perfect.\" Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the phrase \"initial rationale selector is perfect\" and suggests that if it were perfect, no additional work would be needed. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this assumption is problematic or how it affects the paper. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment questions the phrase \"initial rationale selector is perfect\" and suggests that if it were perfect, no additional work would be needed. This raises a valid point about the clarity and logic of the paper, prompting the authors to reconsider their wording and ensure that their claims are wellsupported. However, the comment does not provide specific suggestions or guidance on how to address this issue or improve the clarity of the text. While it identifies a potential area for improvement, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about whether the authors experimented with the use of domain ontologies to avoid placeholder generation in the evaluated responses. It also asks for specific details regarding the number of questions created for the zeroshot intent classifier and its accuracy. While the comment implies that the authors should provide this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks detailed guidance on how to address the questions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 211,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the use of domain ontologies and asks for details regarding the number of questions created for the zeroshot intent classifier and its accuracy. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the use of domain ontologies to avoid placeholder generation in the evaluated responses. It does not contain a claim or opinion but rather seeks clarification on a specific aspect of the methodology. The comment is factual and descriptive, fitting the \"No\" label.", "helpfulness_rationale": "The review comment raises a specific question about the use of domain ontologies to avoid placeholder generation in the evaluated responses. It also asks for detailed information regarding the number of questions created for the zeroshot intent classifier and its accuracy. This feedback is clear and actionable, as it prompts the authors to provide additional information that could enhance the comprehensiveness and clarity of their paper. However, the comment could be more helpful if it offered suggestions on how to address the issue or why this information is important. Overall, the comment is 4 as it directs the authors to specific areas needing clarification, providing a clear path for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should compare their work with other selfsupervised learning methods that are not based on contrastive learning. This is an explicit action that provides a clear direction for the authors to follow. However, it does not specify which specific methods should be compared or how to conduct the comparison, leaving some room for ambiguity. While the action is explicit, it lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment suggests comparing the work with other selfsupervised learning methods that are not based on contrastive learning. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology, results, or discussion sections. Without explicit references to specific sections or elements of the paper, the authors cannot confidently determine where to incorporate this comparison. Additionally, the comment lacks specificity regarding which specific methods should be considered or how the comparison should be conducted. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that it would be beneficial to compare the work with other selfsupervised learning methods that are not based on contrastive learning. However, the comment does not provide any specific reasoning, examples, or references to support why this comparison is necessary or how it would enhance the paper. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should compare their work with other selfsupervised learning methods that are not based on contrastive learning. This feedback is 3 as it points out a potential gap in the paper\"s comparison and suggests a direction for further exploration. However, the comment lacks specificity regarding which specific methods should be considered or how the comparison should be conducted, leaving the authors with a general idea but without detailed guidance on implementation. To be more helpful, the comment could provide examples of alternative methods or suggest specific aspects to focus on in the comparison. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the abstention process, specifically whether it is based on a prediction probability threshold or a decision threshold used by the models. It requests clarification from the authors on this matter. While the comment does not explicitly instruct the authors to provide clarification, it implies that they should address the question by clarifying the difference between the two thresholds. The action is implicit but concrete, as the authors know exactly what information is needed to clarify the issue. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the abstention process,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the basis of the abstention process, whether it is based on a prediction probability threshold or a decision threshold, and requests clarification on the difference between the two. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the basis of the abstention process, suggesting that it might be based on a prediction probability threshold. It asks for clarification on how this differs from a decision threshold used by the models. This is a request for clarification rather than a claim, as it does not express an opinion or judgment about the paper. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the abstention process used in the paper, specifically whether it is based on a prediction probability threshold or a decision threshold used by the models. It requests clarification on this point, which is a relevant and important aspect of the methodology that could impact the interpretation of results. However, the comment does not provide any suggestions or guidance on how the authors might clarify this aspect or improve their explanation. While it identifies a potential area for improvement, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a lack of meaningful baselines in the paper, specifically noting that the authors limit their comparisons to simple naive baselines. It suggests that the authors could compare with a chainofthought prompting approach, providing a concrete example of a more meaningful baseline. This feedback is clear and actionable, as it directly instructs the authors on how to enhance their comparisons by including a specific alternative. The authors know exactly what needs to be done to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of lacking meaningful baselines and suggests a comparison with a chainofthought prompting approach. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks meaningful baselines, specifically noting that the authors limit their comparisons to simple naive baselines. The reviewer suggests that the authors could compare with a chainofthought prompting approach, providing a specific example of a more meaningful baseline. This suggestion is supported by logical reasoning, as it highlights the need for more comprehensive comparisons to enhance the paper\"s evaluation. However, the comment could be strengthened by providing additional references or examples of similar comparisons in the literature. Overall, the claim is 4, as it provides a clear direction for improvement but lacks detailed evidence or references.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, specifically the lack of meaningful baselines in the comparisons. It points out that the authors limit their comparisons to simple naive baselines, suggesting that this limits the paper\"s evaluation and impact. The comment provides a specific suggestion for improvement by recommending a comparison with a chainofthought prompting approach, which could offer a more meaningful baseline. This feedback is clear and actionable, offering the authors a concrete way to enhance the rigor and depth of their evaluation. However, it could be more helpful if it included additional suggestions or examples of other potential baselines to consider. Overall, the comment is 4 as it provides valuable guidance for improving the draft."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the pretraining process for the cardiac signal representation learning model. It asks whether the model is pretrained on the entire dataset or just the training set, and if the latter, how well it generalizes to settings without associated labels. While the comment does not explicitly instruct the authors to provide this information, it implies that the authors should clarify this aspect in their paper. The action is implicit but concrete, as the authors know exactly what information is needed to address the question. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment raises a question about the pretraining process for the cardiac signal representation learning model, specifically asking whether it is trained on the entire dataset or just the training set. It also inquires about the generalization of the model to settings without associated labels. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The authors can infer that it relates to the methodology or experimental setup sections, but this inference is not direct. The comment is specific in its inquiry about the pretraining process and generalization, but without explicit grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point is a question seeking clarification about the pretraining process for the cardiac signal representation learning model. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises an important question about the pretraining process for the cardiac signal representation learning model. It asks whether the model is pretrained on the entire dataset or just the training set, and if the latter, how well it generalizes to settings without associated labels. This question is relevant and could help the authors clarify their methodology, potentially leading to improvements in the robustness and generalizability of their model. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as recommending a particular approach or methodology. While it identifies a critical area for clarification, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the accuracy of the ground truth and the differences in the results reported in the ablation study. However, it does not provide explicit instructions or suggestions for the authors to address these questions or improve their draft. The authors are left to infer that they might need to provide additional information or analysis to clarify these points, but the comment lacks concrete guidance on how to do so. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment raises questions about the accuracy of the ground truth and the differences in the results reported in the ablation study. However, it does not specify which part of the paper these questions pertain to, such as which sections or tables discuss the ground truth or the ablation study. Without explicit references, the authors cannot confidently determine the exact parts of the paper being addressed. Additionally, the comment lacks specificity in detailing what needs to be addressed or improved regarding the accuracy or differences in the results. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point consists of two questions: one about the accuracy of the ground truth and the other about the differences in the results reported in the ablation study. Neither question contains a claim or opinion that requires verification. They are factual inquiries seeking clarification or additional information. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the accuracy of the ground truth and the differences in the results reported in the ablation study. It prompts the authors to consider whether the observed differences are due to noise or randomness in the training process, which is a valid concern for the robustness and reliability of the results. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address these questions or improve their analysis. While it identifies potential areas for improvement, the feedback is incomplete and does not offer detailed advice, making it 3 but not fully comprehensive. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that no new evaluation metrics are proposed and that only existing metrics are linearly combined. It also suggests that the experimental analysis section should include an indepth exploration of the reasons for the experimental results. While the comment implies that the authors should provide more detailed analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to conduct the indepth exploration. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of new evaluation metrics and the linear combination of existing metrics in the experimental analysis section. It suggests that there should be an indepth exploration of the reasons for the experimental results. However, it does not specify which part of the experimental analysis section needs this exploration, making it weakly grounded. The comment is specific in its request for an indepth exploration, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that no new evaluation metrics are proposed and that only existing metrics are linearly combined. It further suggests that the experimental analysis section lacks an indepth exploration of the reasons for the results. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of detailed justification or evidence makes the claim 3, as the authors would need to infer the specific issues from the general statement. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, noting that no new evaluation metrics are proposed and that only existing metrics are linearly combined. It also suggests that the experimental analysis section lacks an indepth exploration of the reasons for the results. This feedback is clear and actionable, as it highlights an area where the authors could enhance their work by proposing new evaluation metrics or providing a more detailed analysis of the experimental results. However, the comment could be more helpful if it offered specific suggestions on how to introduce new metrics or conduct the indepth exploration. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the notation \"K,\" which is used for both a known kernel function and the number of layers. This feedback is explicit and provides clear guidance on what needs to be addressed: the authors should clarify the usage of \"K\" to avoid confusion. The comment is concrete, as it specifies the exact issue and suggests a straightforward action for the authors to take. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (L166 and L176) where the notation \"K\" is used, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of the notation \"K\" being used for both a known kernel function and the number of layers, which can lead to confusion. This provides clear guidance on what needs to be addressed to improve the clarity of the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the notation \"K\" is being abused, as it is used for both a known kernel function and the number of layers. This claim is 3 as it highlights a potential issue with notation clarity, but it lacks specific examples or references to support the assertion. The authors would need to investigate the context of \"K\" in the paper to fully understand the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the notation \"K,\" which is used for both a known kernel function and the number of layers. This feedback is clear and actionable, as it highlights a potential source of confusion for readers and suggests that the authors should clarify the usage of \"K\" to avoid ambiguity. By addressing this issue, the authors can improve the clarity and readability of their paper. However, the comment could be more helpful if it provided suggestions on how to resolve the notation issue or offered examples of alternative notations. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a potential limitation of the weak recovery problem studied in the paper, suggesting that the AMP algorithm may not be useful for nonGaussian problems. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how to address the issue or improve the practical impact of the AMP algorithm. As a result, the authors are left without a clear understanding of what steps to take to enhance their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the practical impact of the weak recovery problem studied in the paper, suggesting that the AMP algorithm may not be useful for nonGaussian problems. However, it does not specify which part of the paper discusses the weak recovery problem or the AMP algorithm, making it difficult for the authors to pinpoint the exact sections that need attention. The comment lacks specificity as it does not provide detailed guidance on how to address the issue or improve the practical impact. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the weak recovery problem studied in the paper is primarily of theoretical interest and questions the practical impact of the AMP algorithm for nonGaussian problems. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation of the weak recovery problem studied in the paper, suggesting that it may not have significant practical impact due to the AMP algorithm\"s limited usefulness for nonGaussian problems. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this issue or enhance the practical relevance of their work. Without detailed feedback or constructive advice, the authors are left without a clear path for improvement. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the relevance of bringing connections to human cognition into the study, given that the problem is reductionist and does not allow for mechanisms like bargaining and negotiation. The reviewer questions the authors\" statement about the interaction between cognitively basic adaptation mechanisms and the structure of the CPR, suggesting that it would be surprising for a behavioral economist to ignore these aspects. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or clarify their statement. The action is implicit and vague, as the authors are left to infer that they need to provide more context or references to support their claim. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific concern about the relevance of bringing connections to human cognition into the study, given that the problem is reductionist and does not allow for mechanisms like bargaining and negotiation. It questions the authors\" statement about the interaction between cognitively basic adaptation mechanisms and the structure of the CPR, suggesting that it would be surprising for a behavioral economist to ignore these aspects. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concern about the relevance of human cognition and the need for more citation for comparison. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the relevance of bringing connections to human cognition into the study, given that the problem is reductionist and does not allow for mechanisms like bargaining and negotiation. The reviewer challenges the authors\" statement about the interaction between cognitively basic adaptation mechanisms and the structure of the CPR, suggesting that it would be surprising for a behavioral economist to ignore these aspects. The comment provides a logical reasoning by contrasting the reductionist nature of the problem with the need for humanlike mechanisms, but it lacks specific references or examples to fully substantiate the claim. This makes the comment 3, as it provides a logical basis but requires more detailed evidence or references to be fully convincing.", "helpfulness_rationale": "The review comment raises a concern about the relevance of bringing connections to human cognition into the study, given that the problem is reductionist and does not allow for mechanisms like bargaining and negotiation. It questions the authors\" statement about the interaction between cognitively basic adaptation mechanisms and the structure of the CPR, suggesting that it would be surprising for a behavioral economist to ignore these aspects. The comment also points out the need for more citation for comparison against \"previously appreciated.\" While the comment identifies a potential issue and suggests a need for clarification or additional references, it lacks specific guidance on how the authors might address this concern or improve their draft. The feedback is 3 as it highlights an area for improvement but could be more actionable with additional details or suggestions. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the wording in the conclusion is overly exaggerated and that the word choice is \"flamboyant\" in multiple places. However, it does not provide specific suggestions or guidance on how to revise the wording or tone. The action is implicit, as the authors can infer that they need to tone down the language, but it lacks concrete details on how to achieve this. Therefore, the comment is 3, as it identifies an issue but does not provide clear steps for resolution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the conclusion, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue with the wording being overly exaggerated and the use of flamboyant language, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the wording in the conclusion is overly exaggerated and that the word choice is \"flamboyant\" in multiple places. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact issues and how to address them. The lack of detailed justification or evidence makes the claim 3, as the authors would need to invest effort to identify and correct the issues themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the wording in the conclusion, noting that it is overly exaggerated and uses flamboyant language. This feedback is clear and actionable, as it points out a potential weakness in the paper\"s presentation and suggests a need for more modest language. However, the comment could be more helpful if it provided specific examples or suggestions for alternative wording that would better align with the paper\"s content. Despite this, the comment still offers valuable guidance for the authors to improve the clarity and professionalism of their writing. Therefore, it is rated as 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to perform ablation experiments to compare their proposed method with other methods, specifically mentioning TubeR, in terms of the number of learnable parameters and GFLOPs. This provides a clear and direct action for the authors to take, specifying exactly what needs to be done to improve their draft. The comment is concrete and actionable, as it outlines a specific analysis that can be conducted to enhance the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests performing ablation experiments to compare the proposed method with other methods, specifically mentioning TubeR, in terms of the number of learnable parameters and GFLOPs. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. This lack of explicit grounding makes it difficult for the authors to identify the exact part of the paper that needs revision. The comment is specific in its request for ablation experiments and comparison with TubeR, but without clear grounding, it aligns with a score of 1. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests performing ablation experiments to compare the proposed method with other methods, specifically mentioning TubeR, in terms of the number of learnable parameters and GFLOPs. This is a request for additional analysis and comparison, rather than a claim or opinion. It does not contain subjective judgments, suggestions, or deductions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to improve their draft. It recommends performing ablation experiments to compare the proposed method with other methods, specifically mentioning TubeR, in terms of the number of learnable parameters and GFLOPs. This feedback is valuable as it directs the authors to conduct a specific analysis that can enhance the comprehensiveness and rigor of their study. By suggesting a comparison with TubeR, the comment offers a concrete benchmark for evaluation. However, the comment could be more helpful if it provided additional context or rationale for why this comparison is important or how it might impact the results. Overall, the comment is 4 as it offers a clear path for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a significant weakness in the paper, namely the lack of comparison to simple feature acquisition baselines like expected utility or similar measures. This feedback implies that the authors should include such comparisons to demonstrate the effectiveness of their proposed approach. However, the comment does not provide specific guidance on which baselines to consider or how to conduct the comparison. While the action is clear\u2014adding comparisons to demonstrate effectiveness\u2014the lack of concrete details on how to implement this makes the comment 3. The authors know they need to compare to baselines but may struggle with the specifics of which ones to choose and how to conduct the comparison.", "grounding_specificity_rationale": "The comment identifies a significant weakness in the paper, namely the lack of comparison to simple feature acquisition baselines like expected utility or similar measures. However, it does not specify which part of the paper this issue pertains to, such as the methodology or results sections. Additionally, while it mentions \"writing style and other issues,\" it does not elaborate on what these issues are or how they could be addressed. As a result, the comment is 1, as the authors cannot confidently determine which part of the paper is being addressed, and it is not specific, as it lacks detailed guidance on what needs to be improved. Therefore, this comment is categorized as 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper lacks a comparison to simple feature acquisition baselines, such as expected utility, to demonstrate the effectiveness of the proposed approach. This claim is 3 as it highlights a potential gap in the paper\"s methodology. However, the comment does not provide specific examples of these baselines or detailed reasoning on why they are relevant, which would strengthen the justification. The authors may need to infer the importance of these comparisons themselves, making the claim 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, noting that it lacks a comparison to simple feature acquisition baselines like expected utility or similar measures. This feedback is important as it highlights a gap in the paper\"s methodology, which could impact the evaluation and demonstration of the proposed approach\"s effectiveness. However, the comment does not provide specific suggestions on which baselines to consider or how to conduct the comparison, leaving the authors with a general direction but without detailed guidance. While the feedback is clear about the need for comparison, it could be more helpful with additional details on how to implement this suggestion. Therefore, the comment is 3, as it points out a critical area for improvement but lacks depth and specificity."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point provides a mix of explicit and implicit actions. It explicitly asks for more explanations regarding Figure 5a and how the authors dealt with DVS input when the input is in aer format. However, the suggestion to analyze energy consumption as reference [15] did is implicit, as it does not specify how to implement this analysis. The comment is 4 because it clearly identifies areas that need further explanation and provides a concrete suggestion for improvement, but the action regarding energy consumption analysis is less explicit. Therefore, the comment aligns with a score of 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 5a,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with \"Fig. 5a\" by asking for more explanations. Additionally, the comment provides a specific suggestion to analyze energy consumption as reference [15] did, which is clear and actionable. Therefore, this comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point consists of multiple claims and suggestions. The first claim about \"11\" being wonderful is not verifiable as it lacks supporting evidence or context. The second claim about Figure 5a being strange is not supported by any reasoning or examples, making it difficult for the authors to understand the basis of the critique. The suggestion to analyze energy consumption as reference [15] did is also not verifiable without specific details or examples. Overall, the comment lacks sufficient justification or evidence for its claims and suggestions, making it 1.", "helpfulness_rationale": "The review comment provides some helpful feedback by acknowledging the quality of \"11\" and suggesting that the authors consider other bit operations. It also points out a potential issue with Figure 5a, asking for more explanations. Additionally, it raises a question about how the authors dealt with DVS input when the input is in aer format. However, the comment could be more helpful if it offered specific suggestions or examples on how to address these issues. The reference to analyzing energy consumption as done in reference [15] is a valuable suggestion but lacks detailed guidance on how to implement it. Overall, the comment provides some direction but could be more comprehensive and actionable, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the potential oversmoothing of GNNbased encoders due to similarityaware positive sample selection and the impact on generalization performance. It suggests conducting additional experiments on different downstream tasks and across different domains to address these concerns. While the comment identifies specific areas for improvement, it does not provide explicit instructions or concrete steps on how to conduct these experiments or what specific aspects to focus on. The authors can infer that they need to conduct additional experiments, but the lack of detailed guidance makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises concerns about the potential oversmoothing of GNNbased encoders due to similarityaware positive sample selection and the impact on generalization performance. It suggests conducting additional experiments on different downstream tasks and across different domains to address these concerns. However, the comment does not specify which part of the paper discusses the similarityaware positive sample selection or the experiments on transfer performance, making it difficult for the authors to pinpoint the exact sections that need attention. While the authors might have an idea of where these issues are discussed, the lack of explicit references makes the comment weakly grounded. The comment is specific in suggesting additional experiments, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point raises concerns about the potential oversmoothing of GNNbased encoders due to similarityaware positive sample selection and the impact on generalization performance. The reviewer suggests conducting additional experiments on different downstream tasks and across different domains to address these concerns. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that similarityaware positive sample selection could lead to oversmoothing or lower generalization performance. The suggestion for additional experiments is logical but requires more detailed justification or evidence to be 5. Therefore, the comment is classified as 2.", "helpfulness_rationale": "The review comment raises concerns about the potential oversmoothing of GNNbased encoders due to similarityaware positive sample selection and its impact on generalization performance. It suggests conducting additional experiments on different downstream tasks and across different domains to address these concerns. While the comment identifies a potential issue and provides a direction for further exploration, it lacks specific guidance or detailed suggestions on how to conduct these experiments or what aspects to focus on. The feedback is 3 as it points out a critical area for improvement, but it could be more actionable with additional details or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the expressiveness of fast SMP compared to SMP and expresses a desire for more discussion on the power of different architectures. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the question or what specific aspects of the discussion should be expanded upon. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the expressiveness of fast SMP compared to SMP and expresses a desire for more discussion on the power of different architectures. However, it does not specify which part of the paper this discussion should be included in, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, while it suggests a topic for further discussion, it lacks specificity in terms of what aspects of the power of different architectures should be explored. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point consists of a question and a request for more discussion on the power of different architectures. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification or additional information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the expressiveness of fast SMP compared to SMP and expresses a desire for more discussion on the power of different architectures. While it identifies a potential area for further exploration, it lacks specificity and actionable guidance. The authors are left without clear instructions on how to address this issue or what specific aspects of the power of different architectures should be discussed. Without detailed suggestions or examples, the comment provides limited value in helping the authors improve their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of clarity regarding the types of situations or social norms discussed in the main paper, specifically mentioning physical and psychological safety. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific changes to improve clarity. The action is implicit, as the authors can infer that they need to clarify these aspects, but it lacks concrete details on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment highlights a lack of clarity regarding the types of situations or social norms discussed in the main paper, specifically mentioning physical and psychological safety. However, it does not specify which part of the paper this issue pertains to, such as a particular section or subsection. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in identifying the issue of clarity regarding social norms, but without grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the types of situations or social norms (e.g., physical and psychological safety) are not clear in the main paper. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed explanation or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment identifies a specific area of concern regarding the clarity of the types of situations or social norms discussed in the main paper, particularly mentioning physical and psychological safety. This feedback is 3 as it points out a potential gap in the paper that needs clarification. However, it lacks detailed guidance or suggestions on how the authors might address this issue, such as recommending specific sections to revise or examples to include. While it provides some direction, the comment could be more actionable and comprehensive to be fully helpful. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to define the dashed lines in specific figures, providing a clear and direct action for the authors to take. The comment is specific and leaves no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions specific figures (2AB and 4B), allowing the authors to accurately identify the parts of the paper being addressed. It clearly specifies what needs to be defined, which are the dashed lines in these figures. This provides full grounding and specificity, making this comment 5.", "verifiability_rationale": "The review point is a request for clarification, asking the authors to define the dashed lines in specific figures. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is clear and specific, requesting the authors to define the dashed lines in specific figures. This feedback is actionable and provides a direct way for the authors to improve their draft by clarifying an aspect that may be unclear to readers. However, the comment could be more helpful if it provided context or explained why these definitions are important. Despite this, the feedback is 4 as it guides the authors toward a specific improvement that can enhance the clarity of their work."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the results of the proposed methods are not comparable to existing methods, implying that there is limited significance in the proposed methods. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to make the results comparable or what specific changes should be made to enhance the significance of the proposed methods. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment suggests that the results of the proposed methods are not comparable to existing methods, implying that there is limited significance in the proposed methods. However, it does not specify which results or methods are being compared, nor does it provide details on why the results are not comparable. This lack of specificity and grounding makes it difficult for the authors to identify the exact parts of the paper that need attention or improvement. The comment is 1 as it does not refer to any specific section, table, or figure, and it is not specific because it lacks detailed guidance on what needs to be addressed. Therefore, this comment is rated as 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the results are not comparable to existing methods, implying a lack of significance in the proposed methods. However, the comment does not provide any supporting evidence, reasoning, or examples to justify this claim. Without specific comparisons or references to existing methods, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the results of the proposed methods are not comparable to existing methods, implying a lack of significance in the proposed methods. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve the comparability of their results. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the obtained results, specifically the assumption that the spectrum of a kernel is subgaussian. It notes that while this assumption is acceptable for Gaussian kernels, it excludes other popular classes like Matern kernels, which have a polynomial decay in their spectrum. However, the comment does not provide explicit guidance on how the authors should address this limitation or suggest ways to include Matern kernels in their analysis. The action is implicit and somewhat vague, as the authors are left to infer that they should consider expanding their analysis to include other kernel types. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a limitation in the obtained results, specifically the assumption that the spectrum of a kernel is subgaussian. It mentions that while this assumption is acceptable for Gaussian kernels, it excludes other popular classes like Matern kernels, which have a polynomial decay in their spectrum. However, the comment does not specify which part of the paper discusses these assumptions or results, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but the lack of explicit references makes it challenging to pinpoint the exact part of the paper being addressed. The comment is specific in detailing the limitation and the need to consider other kernel types, but the lack of grounding limits its effectiveness. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the results of the paper could be restrictive due to the assumption that the spectrum of a kernel is subgaussian. It provides a logical reasoning by explaining that while Gaussian kernels are included in this class, other popular classes like Matern kernels are not, as their spectrum only decays polynomially. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a limitation in the paper\"s results, specifically the assumption that the spectrum of a kernel is subgaussian. It acknowledges that this assumption is acceptable for Gaussian kernels but points out that it excludes other popular classes like Matern kernels, which have a polynomial decay in their spectrum. This feedback is valuable as it highlights a potential restriction in the paper\"s scope and suggests that the authors should consider expanding their analysis to include other kernel types. However, the comment could be more helpful if it provided specific suggestions on how to incorporate these other kernels or addressed the implications of this exclusion. Overall, the comment is 3 as it directs the authors\" attention to a limitation in their results but lacks detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy between the data in Table 4, which indicates the importance of unsupervised pretraining, and the lack of detailed discussion on this topic in the main paper. The reviewer suggests focusing more on the pretraining method in the main paper, implying that the authors should provide a more indepth analysis of this aspect. While the comment explicitly states the need for more focus on pretraining, it does not provide specific guidance on how to achieve this or what aspects of the pretraining method should be emphasized. The action is explicit but somewhat vague, as the authors know they need to address the pretraining method but may not be entirely clear on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4\" and \"the main paper,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of detailed discussion on unsupervised pretraining, which is a key factor in the performance gain, and suggests focusing more on this aspect. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the unsupervised pretraining is a key factor in performance gain, as indicated by the data in Table 4. However, it notes that there is no detailed discussion on this in the main paper, which is a problem. The reviewer further suggests focusing more on the pretraining method in the main paper, based on the comparison with the ablation study in Table 5. While the comment provides some reasoning and references to specific tables, it lacks detailed evidence or examples to fully substantiate the claim about the importance of pretraining. The suggestion to focus more on pretraining is logical but could be strengthened with additional evidence or examples. Therefore, the comment is 3.", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the detailed discussion of unsupervised pretraining, which is a key factor in the performance gain, as indicated by the data in Table 4. The reviewer suggests that the authors should focus more on the pretraining method in the main paper, providing a clear and actionable suggestion for improvement. This feedback is valuable as it highlights an important aspect of the paper that needs further elaboration, offering the authors a specific direction for enhancing their draft. However, the comment could be more helpful if it included specific suggestions on how to present or discuss the pretraining method in greater detail. Overall, the comment is 4, as it effectively guides the authors toward improving their paper by addressing a critical area of interest."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the choice of ELM (male/female) and whether it requires knowledge of the speaker\"s gender beforehand. It also suggests that the accuracy should be calculated after using a gender detection model in the pipeline. While the comment implies that the authors should address these issues, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the choice of ELM and its implications for accuracy. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the choice of ELM (male/female) and its implications for accuracy, suggesting that the accuracy should be calculated after using a gender detection model in the pipeline. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concern about the choice of ELM and its implications for accuracy. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the choice of ELM (male/female) and its implications for accuracy, suggesting that the accuracy should be calculated after using a gender detection model in the pipeline. The comment provides a logical reasoning by questioning the need for prior knowledge of the speaker\"s gender and highlighting a potential drawback in the methodology. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to further explore and substantiate the claim themselves to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a pertinent question about the choice of ELM (male/female) and its implications for accuracy. It suggests that the accuracy should be calculated after using a gender detection model in the pipeline, which could be a drawback if the speaker\"s gender is required for inference. This feedback is clear and actionable, as it prompts the authors to consider the implications of their choice of ELM and how it might affect the accuracy of their model. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or offered examples of how other researchers have handled similar challenges. Overall, the comment is 4 as it directs the authors\" attention to a critical aspect of their methodology that requires further consideration."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment states that the paper is incremental and lacks technical substance, merely adding a new loss to a previous work. However, it does not provide any explicit or implicit actions for the authors to take to improve their draft. There is no guidance on how to enhance the technical content or what specific changes could be made to add more value. As a result, the authors are left without any actionable steps to address the feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the paper for being incremental and lacking technical substance, specifically mentioning that it adds a new loss to a previous work ([31]). However, it does not specify which part of the paper this critique pertains to, such as a particular section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its critique of the paper\"s lack of technical substance, but without clear grounding, it remains difficult for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is incremental and lacks technical substance, stating that it merely adds a new loss to a previous work. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment critiques the paper for being incremental and lacking technical substance, specifically mentioning that it adds a new loss to a previous work. However, it does not provide any specific suggestions or guidance on how the authors could enhance the technical content or originality of their work. Without actionable feedback or constructive criticism, the authors are left without a clear path for improvement. Therefore, the comment is 1, as it does not offer any value to the authors in terms of enhancing their draft."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the inconsistency in the use of variables in equations (7) and (10), specifically questioning why one uses \"X\" and the other \"H^(1).\" While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this inconsistency. The authors are left to infer that they need to clarify or justify the choice of variables, but without concrete instructions, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eqs. (7) and (10),\" allowing the authors to accurately identify the specific parts of the paper being addressed. It is also specific because it clearly questions the inconsistency in the use of variables, specifically \"X\" and \"H^(1),\" and asks for an explanation. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the inconsistency in the use of variables in equations (7) and (10), specifically noting that one uses \"X\" and the other \"H^(1).\" This is a factual observation that does not contain an opinion, judgment, or suggestion requiring verification. It is a request for clarification, which is a normal statement and should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the inconsistency in the use of variables in equations (7) and (10), noting that one uses \"X\" and the other \"H^(1).\" This is a clear and actionable feedback that prompts the authors to clarify or justify the choice of variables, which could be a critical aspect of their methodology. By addressing this inconsistency, the authors can enhance the clarity and rigor of their work. However, the comment could be more helpful if it provided additional context or suggested potential reasons for the inconsistency. Overall, the feedback is 3 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with further guidance. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the applicability of the model to realworld diffusion processes. It suggests that the authors provide empirical evidence to demonstrate that the proposed model captures the diffusion phenomena in realworld scenarios. While the comment implies that the authors should conduct empirical studies to validate the model\"s applicability, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to conduct the empirical studies or what aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the applicability of the model to realworld diffusion processes. It suggests that the authors provide empirical evidence to demonstrate the model\"s ability to capture diffusion phenomena in realworld scenarios. However, the comment does not specify which part of the paper this concern pertains to, such as a specific section or experiment. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing revision. While the comment is specific in its request for empirical evidence, it is 1 because it does not identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the applicability of the model to realworld diffusion processes. It suggests that the authors provide empirical evidence to demonstrate the model\"s ability to capture diffusion phenomena in realworld scenarios. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the model is not applicable. Without such evidence or justification, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered 2, as it provides a general suggestion but lacks the necessary details to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a critical concern regarding the applicability of the model to realworld diffusion processes. It acknowledges the novelty and elegance of the proposed solutions but suggests that the authors provide empirical evidence to validate the model\"s ability to capture diffusion phenomena in realworld scenarios. This feedback is clear and actionable, as it directs the authors to conduct empirical studies to strengthen the applicability and relevance of their work. However, the comment could be more helpful if it provided specific suggestions on how to conduct these empirical studies or what aspects to focus on. Overall, the comment is 4 as it guides the authors toward a significant improvement in their draft by addressing a crucial gap in the paper\"s applicability."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the authors should test their method on more datasets to get a better understanding of its performance. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not specify which datasets should be used or how the results should be analyzed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the method should be tested on more datasets to better understand its performance. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. Without explicit references to specific sections or elements of the paper, the authors cannot confidently determine where to address this feedback. Additionally, the comment lacks specificity regarding which datasets should be considered or how the results should be analyzed. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the method should be tested on more datasets to better understand its performance. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why testing on additional datasets is necessary or how it would improve the understanding of the method\"s performance. Without such support, the claim remains 1, as the authors are left without a clear understanding of the basis for the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the authors should test their method on more datasets to better understand its performance. While this feedback identifies a potential area for improvement, it lacks specificity and actionable guidance. The comment does not provide suggestions on which additional datasets to consider, how to analyze the results, or how the findings might impact the overall conclusions. Without detailed advice, the authors are left with a general idea of what to do but without a clear path forward. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "1", "actionability_rationale": "The review point states that the main contribution of combining attention with other linear mechanisms is not novel and that alternatives exist, as noted in the paper. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue of nonnovelty or what specific alternatives should be considered. The comment lacks actionable advice, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the main contribution of combining attention with other linear mechanisms, noting that it is not novel and that alternatives exist. However, it does not specify which part of the paper discusses this contribution, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the contribution are not novel or which alternatives are being referred to. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the main contribution of combining attention with other linear mechanisms is not novel, and it references the paper itself, noting that \"a lot of alternatives exist.\" However, the comment does not provide specific examples or detailed reasoning to support the claim of nonnovelty. The reference to \"a lot of alternatives\" is vague and lacks concrete evidence or references to substantiate the claim. This makes the comment 3, as it provides a general direction but lacks the necessary details for full verification.", "helpfulness_rationale": "The review comment points out that the main contribution of combining attention with other linear mechanisms is not novel, as noted in the paper itself. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve their contribution. The comment lacks actionable feedback or constructive advice, leaving the authors without a clear path for improvement. As a result, the comment is 1, as it does not offer any value to the authors in terms of enhancing their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to provide a plot of how different weights of the model move after unlearning, specifically to see which layers are affected the most. This is a clear and direct action that the authors can follow to improve their draft. The comment provides a specific and concrete suggestion, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the method,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, which is the need for a plot showing how different weights of the model move after unlearning, particularly to see which layers are affected the most. This provides clear guidance on what the authors should include in their draft. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide a plot showing how different weights of the model move after unlearning, specifically to see which layers are affected the most. This is a request for additional information or analysis, rather than a claim or opinion that requires verification. Therefore, the comment is factual and does not contain a claim, aligning with the label \"No\".", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the paper. It recommends that the authors include a plot showing how different weights of the model move after unlearning, particularly to see which layers are affected the most. This feedback is clear and offers a concrete way for the authors to enhance their analysis and presentation of results. By following this suggestion, the authors can provide a more comprehensive understanding of the model\"s behavior and potentially identify areas for further exploration. However, the comment could be more helpful if it explained why this analysis is important or how it might impact the interpretation of the results. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the domain of the inputs, suggesting that they might be lying in the same sphere but are not mentioned in the paper. While the comment implies that the authors should clarify this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide clarification on the domain of the inputs. However, the comment does not specify how to address this issue, such as by adding a section or revising the text. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the domain of the inputs, suggesting that they might be lying in the same sphere but are not mentioned in the paper. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in its inquiry about the domain of the inputs, but without clear grounding, the authors may struggle to determine where to address this concern. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the domain of the inputs, suggesting that they might be lying in the same sphere but are not mentioned in the paper. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the domain of the inputs, suggesting that they might be lying in the same sphere but are not mentioned in the paper. While this question identifies a potential gap in the paper, it lacks specificity and does not provide actionable guidance on how the authors might address this issue. The comment does not offer suggestions for clarifying the domain of the inputs or how this information could be integrated into the paper. As a result, the feedback is 3, as it points out a potential area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point identifies a potential conflict between the second rule in Lemma 2, specifically Eq. (7), and the definition of minimal conditional dependence. It suggests that taking Z\" in the definition to be the empty set should result in x and y being independent given W, but Eq. (7) contradicts this. This feedback is explicit and provides a clear action for the authors to take: investigate and resolve the apparent contradiction between the second rule and the definition of minimal conditional dependence. The comment is 5 as it specifies the exact issue and guides the authors on how to address it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Second rule in Lemma 2, i.e., Eq (7) and the definition of minimal conditional dependence,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out a potential conflict between the second rule and the definition of minimal conditional dependence. The comment provides a specific example by suggesting that taking Z\" in the definition to be the empty set should result in x and y being independent given W, but Eq. (7) contradicts this. This level of detail makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a conflict between the second rule in Lemma 2, specifically Eq. (7), and the definition of minimal conditional dependence. The reviewer provides a logical reasoning by suggesting that taking Z\" in the definition to be the empty set should result in x and y being independent given W, but Eq. (7) contradicts this. This reasoning is clear and provides a specific example to support the claim, making it 4. However, the comment could be strengthened by referencing relevant literature or providing more detailed explanations of the conflict. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential conflict between the second rule in Lemma 2, specifically Eq. (7), and the definition of minimal conditional dependence. It provides a specific example by suggesting that taking Z\" in the definition to be the empty set should result in x and y being independent given W, but Eq. (7) contradicts this. This feedback is clear and actionable, as it directs the authors to investigate and resolve the apparent contradiction. By pointing out this specific issue, the comment offers a concrete way for the authors to improve their draft, making it 5. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the visual presentation of data in Figure 3 could be improved for better readability and aesthetic appeal, specifically mentioning the subscripts. However, it does not provide explicit guidance on how to enhance the visual presentation or what specific changes should be made. The action is implicit and somewhat vague, as the authors can infer that they need to improve the visual presentation but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular aspect of the visual presentation, namely the subscripts, and suggests that they could be improved for better readability and aesthetic appeal. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point claims that the visual presentation of data in Figure 3 could be improved for better readability and aesthetic appeal, specifically mentioning the subscripts. However, the comment does not provide any specific examples or detailed reasoning to support why the current presentation is inadequate or how it could be improved. Without additional context or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2, as it lacks sufficient evidence or explanation to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the visual presentation of data in Figure 3, noting that the subscripts could be improved for better readability and aesthetic appeal. This feedback is 3 as it points out a potential area for enhancement, which could improve the overall clarity and impact of the figure. However, the comment lacks detailed guidance or suggestions on how to enhance the visual presentation, such as proposing specific changes to the subscripts or offering examples of better practices. While it highlights an area for improvement, the feedback could be more actionable and comprehensive to be fully helpful. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the process of updating archetype positions after initialisation in Algorithm 2. It explicitly requests the authors to provide a comment on this aspect, which is a clear and direct action. The comment provides a specific area for clarification, making it easy for the authors to understand what needs to be addressed. Therefore, this comment is 5, as it gives the authors a clear direction on how to improve their draft by providing additional information.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of the unclear process of updating archetype positions after initialisation. The comment requests clarification on this aspect, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the process of updating archetype positions after initialisation in Algorithm 2. It does not contain any subjective claims, opinions, or suggestions that require verification. It is a factual inquiry seeking clarification, which is consistent with the \"No\" label.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the process of updating archetype positions after initialisation in Algorithm 2. It requests clarification from the authors, which is a clear and actionable suggestion that can help improve the clarity and comprehensibility of the paper. By addressing this point, the authors can enhance the transparency and understanding of their methodology, making the comment 4. However, the comment could be more helpful if it provided additional context or suggestions on how to clarify the process, which would align with a score of 4 or 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the timeconsuming nature of the shape model training, which is trained in pixel level despite sparsity by landmarks, and the independent training on all font images and characters. It also mentions the highorder factor graph of the parsing model with four types of factors. The comment suggests that the processing efficiency of training and testing should be described and compared with existing work. While the comment identifies areas for improvement, it does not provide explicit instructions on how to implement these suggestions, such as specific methods or benchmarks to use for comparison. The action is implicit and somewhat vague, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"shape model\" and \"parsing model,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the timeconsuming nature of the training process due to the pixellevel training of the shape model and the independent training on all font images and characters. Additionally, it suggests that the processing efficiency of training and testing should be described and compared with existing work. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the shape model is timeconsuming due to its pixellevel training and independent training on all font images and characters. It also mentions the highorder factor graph of the parsing model with four types of factors. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment identifies several areas that could be improved in the paper. It points out the timeconsuming nature of the shape model training, which is trained in pixel level despite sparsity by landmarks, and the independent training on all font images and characters. It also mentions the highorder factor graph of the parsing model with four types of factors, suggesting that the processing efficiency of training and testing should be described and compared with existing work. This feedback is clear and actionable, as it highlights specific aspects of the methodology that could be improved and provides a direction for further analysis. However, the comment could be more helpful if it included suggestions on how to optimize the training process or specific benchmarks to use for comparison. Overall, the comment is 4, as it provides valuable insights for the authors to enhance their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment expresses difficulty in understanding the motivation of the paper and labels it as an \"incremental engineering paper.\" However, it does not provide any specific guidance or suggestions on how the authors might improve the clarity of their motivation or the content of the paper. The comment lacks actionable details, such as what aspects of the motivation are unclear or how the authors might address the perceived incremental nature of the work. As a result, the authors are left without a clear understanding of what changes are needed to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses difficulty in understanding the motivation of the paper and labels it as an \"incremental engineering paper.\" However, it does not specify which part of the paper is unclear or what aspects of the motivation are challenging to follow. Without explicit references to sections, figures, or specific elements, the authors cannot confidently determine which parts of the paper need revision. The comment is 1 as it does not identify a specific area for improvement, and it is also not specific because it lacks detailed guidance on what needs to be addressed. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that it is difficult to follow the motivation of the paper and labels it as an \"incremental engineering paper.\" However, the comment lacks specific examples, reasoning, or references to support these claims. Without detailed justification or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses difficulty in understanding the motivation of the paper and labels it as an \"incremental engineering paper.\" However, it does not provide specific feedback or suggestions on how the authors might improve the clarity of their motivation or the content of the paper. Without actionable guidance or detailed critique, the authors are left without a clear understanding of what changes are needed to address the perceived issues. As a result, the comment is 1, as it does not offer any constructive feedback or direction for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a critical weakness in the paper, namely the lack of novelty and incremental nature of the work. It points out that the paper addresses a particular problem of column operations in designing semantic parsers for TexttoSQL and that it involves a new dataset, which is a different train/test split of an existing dataset SQUALL. The comment also mentions another synthetic benchmark paper that is based on a single question template. However, the comment does not provide any explicit or implicit actions for the authors to take to address these issues. It lacks guidance on how the authors might enhance the novelty or incremental nature of their work, or how they could improve the dataset or benchmark. Without specific suggestions or actionable steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a critical weakness in the paper, specifically the lack of novelty and incremental nature of the work. It provides specific details about the paper\"s focus on column operations in designing semantic parsers for TexttoSQL and mentions the use of a new dataset, which is a different train/test split of an existing dataset SQUALL. Additionally, it references another synthetic benchmark paper based on a single question template. However, the comment does not explicitly mention which part of the paper these issues are discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. The comment is specific in detailing the issues with novelty and incremental nature, providing a clear understanding of what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks novelty and is incremental in nature, specifically mentioning the use of a new dataset that is a different train/test split of an existing dataset SQUALL. It also references another synthetic benchmark paper based on a single question template. However, the comment does not provide specific examples or detailed reasoning to support the claim of lack of novelty, making it difficult for the authors to understand the basis of the critique. The lack of detailed evidence or references makes the claim 3, as the authors would need to invest effort to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical weakness in the paper, specifically the lack of novelty and incremental nature of the work. It points out that the paper addresses a particular problem of column operations in designing semantic parsers for TexttoSQL and that it involves a new dataset, which is a different train/test split of an existing dataset SQUALL. The comment also mentions another synthetic benchmark paper that is based on a single question template. While the comment highlights an important issue, it lacks specific suggestions or guidance on how the authors might address these concerns or enhance the novelty of their work. Without actionable feedback, the authors are left with a general understanding of the problem but without a clear path to improvement. Therefore, the comment is 3, as it provides insight into a critical area but lacks depth and specificity in its guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point consists of two parts. The first part explicitly instructs the authors to add a few more sentences explaining the experimental setting for continual learning. This is a clear and direct action that the authors can follow to improve their draft. The second part of the comment is more complex, as it consists of a series of questions about the experimental results in Figure 3. While these questions are not explicitly stated as actions, they imply that the authors should provide additional explanations or clarifications in the text. The questions are specific and provide a clear direction for the authors to address, making the comment 4. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear questions and requests for additional explanations, such as the correspondence between learning curves and MPHATE, the relationship between performance and structural collapse, and the accuracy numbers for the last task or average. This level of detail guides the authors on what specific information is missing or unclear in the figure, making the comment 5.", "verifiability_rationale": "The review point consists of a series of questions and requests for clarification, such as \"explain the correspondence between the learning curves and MPHATE\" and \"why do you want to want me to look at the learning curves?\" These questions are not claims but rather requests for additional information or clarification. They do not express opinions, judgments, or suggestions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by requesting additional explanations in the experimental setting for continual learning and in Figure 3. It asks for clarification on the correspondence between learning curves and MPHATE, the relationship between performance and structural collapse, and the accuracy numbers for the last task or average. These questions are clear and direct, offering the authors a structured approach to enhance the clarity and comprehensiveness of their experimental results. By addressing these points, the authors can improve the transparency and accessibility of their work. Therefore, the comment is rated as 5, as it effectively guides the authors in making significant improvements to their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection. It suggests that labeled data could provide effective information for consistency training, but it does not explicitly instruct the authors to conduct this experiment or provide specific guidance on how to implement it. The comment implies an action by questioning the current approach and suggesting a potential improvement, but it lacks concrete details on how to execute this suggestion. Therefore, the comment is 3, as the authors can infer a possible direction for improvement but need more guidance to fully implement it.", "grounding_specificity_rationale": "The comment raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection. It suggests that labeled data could provide effective information for consistency training, but it does not specify which part of the paper this suggestion pertains to. The authors might infer that it relates to the methodology or experimental sections, but without explicit grounding, it is difficult to pinpoint the exact part of the paper being addressed. The comment is specific in suggesting a potential improvement, but it lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection. It suggests that labeled data could provide effective information for consistency training, but this claim is not fully supported by the provided references. The references are relevant to graph contrastive learning, but they do not directly address the specific question of using labeled data for consistency training. The comment lacks detailed reasoning or examples to fully substantiate the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection. It suggests that labeled data could provide effective information for consistency training, which might enhance the model\"s ability to deal with the task of graph anomaly detection. This feedback is 3 as it prompts the authors to consider an alternative approach that could improve their methodology. However, the comment lacks specific guidance or suggestions on how to implement this idea or what specific aspects of labeled data might be beneficial. To be more helpful, the comment could include examples or detailed instructions on how to incorporate labeled data into the consistency training process. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the experimental section needs to be reorganized and improved to better highlight the superiority of the method. It implies that the authors should restructure the experimental content in the main text to better showcase the advantages of their approach. However, the comment does not provide specific guidance on how to reorganize the content or what changes should be made to improve the experimental section. While the action is implicit, it lacks concrete details on how to implement the suggested changes, making it 3.", "grounding_specificity_rationale": "The comment suggests that the experimental section needs to be reorganized and improved to better highlight the superiority of the method. It mentions that the current content does not effectively showcase the method\"s advantages, implying that the organization of the experimental content is a problem. However, the comment does not specify which part of the experimental section is problematic or how it should be improved. While it provides a general direction for improvement, it lacks specific guidance or references to particular sections or elements that need attention. This makes the comment 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the experimental section needs to be reorganized and improved to better highlight the superiority of the method. However, it does not provide specific examples or detailed reasoning to support this claim. The suggestion to include specific experimental suggestions in the main text is vague and lacks concrete evidence or references to justify the need for reorganization. Without detailed justification or examples, the claim remains 1, as the authors may struggle to understand the basis of the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental section, noting that it lacks clarity in highlighting the superiority of the method. It suggests that the experimental content should be reorganized to better showcase the advantages of the approach. However, the comment does not provide detailed guidance or examples on how to reorganize the content or what specific aspects should be emphasized. While it points out a potential area for improvement, the feedback lacks depth and actionable suggestions, making it 3. The authors are given a general direction but need to develop the feedback themselves to fully address the issue. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors include a plot with sparsity on the xaxis and performance on the yaxis to directly compare the flexibility of SGC with LoRA. This suggestion is explicit and provides a clear action for the authors to take, as it specifies the type of visualization needed to demonstrate the practical benefits of SGC\"s finegrained control. The comment is also concrete, as it outlines the exact data to be plotted and the comparison to be made. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"SGC\" and \"LoRA,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting the inclusion of a plot with sparsity on the xaxis and performance on the yaxis to directly compare the flexibility of SGC with LoRA. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that SGC offers a more flexible, finegrained tradeoff but notes that PEFT methods typically target computeconstrained scenarios, where such granular control may require extra tuning that reduces practicality. The reviewer suggests including a plot with sparsity on the xaxis and performance on the yaxis to directly compare the flexibility of SGC with LoRA. This suggestion is based on logical reasoning, as it proposes a visual representation to demonstrate the practical benefits of SGC\"s finegrained control. However, the comment could be strengthened by providing specific examples or references to support the claim about the extra tuning required for practicality. Therefore, the comment is 4, as it provides a clear rationale but lacks detailed evidence or examples.", "helpfulness_rationale": "The review comment identifies a potential limitation in the applicability of the proposed method, specifically questioning the practicality of the finegrained control offered by SGC in computeconstrained scenarios. It suggests including a plot with sparsity on the xaxis and performance on the yaxis to directly compare the flexibility of SGC with LoRA, which could provide a more intuitive demonstration of the practical benefits of SGC\"s finegrained control. This feedback is clear and actionable, offering a specific suggestion for improving the paper\"s presentation and clarity. By addressing this point, the authors can enhance the comprehensiveness and practicality of their work. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the reasonableness of the German and Law school dataset having shorter training time in Gerrymandering compared to Independent. It also suggests that since the performance of ERM and plugin is similar to Kearns et al. in Experiment 2, the main advantage is computation time, it would be good to have the code published. While the comment implies that the authors should provide a justification for the observed training time differences and consider publishing the code, it does not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the issue or what aspects of the code should be published. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiments\" and the \"German and Law school dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the reasonableness of the training time differences and suggests that the code should be published, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the reasonableness of the German and Law school dataset having shorter training time in Gerrymandering compared to Independent. It suggests that since the performance of ERM and plugin is similar to Kearns et al. in Experiment 2, the main advantage is computation time, it would be good to have the code published. The comment provides a logical reasoning by comparing the performance and computation time, which is a valid point. However, it lacks specific references or detailed evidence to fully substantiate the claim, making it 3. The authors would need to provide additional context or data to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the reasonableness of the German and Law school dataset having shorter training time in Gerrymandering compared to Independent. It suggests that since the performance of ERM and plugin is similar to Kearns et al. in Experiment 2, the main advantage is computation time, it would be good to have the code published. This feedback is 3 as it points out a potential inconsistency in the experimental results and suggests a possible explanation. However, the comment lacks specific guidance on how to address the issue or improve the draft, such as suggesting ways to clarify the results or provide additional context. While it identifies a potential area for improvement, it does not offer detailed actionable steps, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy between the human baseline and the model baseline, noting that the human baseline is weaker due to only following a little more than 1 hour of speech recordings compared to the full 15 hours. The comment also points out that the abstract mentions beating the human baseline, which is misleading given the limited data the human baseline was exposed to. However, the comment does not provide explicit guidance on how the authors should address this issue or improve their draft. The action is implicit and somewhat vague, as it identifies a problem but does not offer specific steps for resolution. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.1\" and \"the abstract,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the discrepancy between the human baseline and the model baseline, noting that the human baseline is weaker due to only following a little more than 1 hour of speech recordings compared to the full 15 hours. Additionally, it highlights the misleading claim in the abstract regarding the human baseline. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the human baseline is weaker due to only following a little more than 1 hour of speech recordings compared to the full 15 hours, which is a significant factor in the comparison. The comment also points out that the abstract mentions beating the human baseline, which is misleading given the limited data the human baseline was exposed to. However, the comment does not provide specific examples or references to support the claim about the human baseline being weaker, nor does it offer detailed reasoning or evidence to substantiate the claim. This lack of detailed justification makes the claim 3, as the authors would need to further investigate and substantiate the claim themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the human baseline, noting that it is weaker than the model baseline due to only following a little more than 1 hour of speech recordings compared to the full 15 hours. This observation is important as it highlights a potential flaw in the comparison between the human and model baselines. The comment also points out that the abstract\"s claim of beating the human baseline is misleading, given the limited data the human baseline was exposed to. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their draft. While it highlights a critical weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the related work discusses other methods for training NMT models beyond MLE, such as RL methods, but none of these methods is used as a baseline. However, the comment does not provide any explicit or implicit action for the authors to take. It does not suggest whether the authors should include these methods as baselines, compare their performance, or discuss their advantages and disadvantages. Without guidance on how to address this observation, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"related work\" and \"other methods for training NMT models beyond MLE,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that none of the discussed methods is used as a baseline, providing a clear direction for improvement. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the related work discusses other methods for training NMT models beyond MLE, such as RL methods, but none of these methods is used as a baseline. However, the comment does not provide specific examples or references to these other methods, making it difficult for the authors to verify the claim. Without detailed information or references, the authors may struggle to understand the basis of the claim or how to address it. Therefore, the comment is considered 2, as it lacks sufficient evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment points out a gap in the related work section, noting that while it discusses other methods for training NMT models beyond MLE, none of these methods is used as a baseline. This observation highlights a potential area for improvement in the paper, as it suggests that the authors could enhance their work by comparing their method to these alternative approaches. However, the comment lacks specific suggestions on how to incorporate these methods or what aspects to focus on in the comparison. While it identifies a relevant area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential ambiguity in the paper regarding the use of the term \"Efficient Proxy.\" The reviewer suggests that the authors clarify whether they are referring to a specific proxy or a family of proxies. While the comment identifies a specific issue with the terminology, it does not provide explicit guidance on how to address this ambiguity. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the terminology and potentially provide examples or definitions to avoid confusion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the clarity of the term \"Efficient Proxy\" in the paper. It suggests that the authors need to clarify whether they are referring to a particular proxy or a family of proxies. However, it does not specify which part of the paper this ambiguity occurs in, making it weakly grounded. The comment is specific in identifying the issue with the terminology but lacks grounding, as the authors cannot confidently determine the exact section or context where this ambiguity arises. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the clarity of the term \"Efficient Proxy\" in the paper. The reviewer suggests that the use of \"is\" implies a specific proxy, but the absence of a proxy named \"Efficient Proxy\" suggests it refers to a family of proxies. This comment highlights a potential ambiguity in the paper, but it does not provide specific examples or references to support the claim. The reasoning is logical but lacks detailed evidence or examples, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential ambiguity in the paper regarding the term \"Efficient Proxy.\" It points out that the use of \"is\" suggests a specific proxy, but the absence of a proxy named \"Efficient Proxy\" implies a family of proxies. This feedback highlights a specific area where the authors need to clarify their terminology to avoid confusion. While the comment effectively identifies a problem, it does not provide detailed guidance on how to resolve the ambiguity or suggest alternative phrasing. Therefore, the comment is 3, as it directs the authors to a specific area for improvement but lacks comprehensive guidance. This aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point describes the methods used in the paper, specifically mentioning the stacking of methods from Mirzasoleiman et al., 2020 and the Grouplearning setting, followed by the use of a classical method DBSCAN for clustering. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether this stacking is appropriate, if it should be modified, or if additional methods should be considered. Without any actionable advice or suggestions, the authors are left without a clear understanding of how to improve their draft based on this comment. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the stacking of methods from Mirzasoleiman et al., 2020 and the Grouplearning setting, followed by the use of a classical method DBSCAN for clustering. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it details the methods being used and the specific issue of stacking them, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point describes the methods used in the paper, specifically mentioning the stacking of methods from Mirzasoleiman et al., 2020 and the Grouplearning setting, followed by the use of a classical method DBSCAN for clustering. However, it does not express an opinion, judgment, or suggestion that requires verification. It is purely descriptive, making it a factual statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment provides a factual description of the methods used in the paper, specifically mentioning the stacking of methods from Mirzasoleiman et al., 2020 and the Grouplearning setting, followed by the use of a classical method DBSCAN for clustering. However, it does not offer any critique, suggestion, or feedback on the effectiveness or appropriateness of these methods. Without any actionable advice or analysis, the comment lacks helpfulness and does not guide the authors in improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the variability in the results with the chosen random projection matrix and suggests that pathological projection matrices could skew the MFTMA capacity and width scores. The reviewer acknowledges that this is unlikely with random projections but still recommends investigating the resilience of the metric to the choice of random projection. While the comment implies that the authors should explore this aspect, it does not provide explicit instructions on how to conduct this investigation or what specific steps to take. The action is implicit and somewhat vague, as the authors need to infer that they should explore the resilience of the metric and potentially include additional analyses. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"3.a),\" indicating the specific part of the paper being addressed, allowing the authors to accurately identify the section. It is also specific because it raises a concern about the variability in results with the chosen random projection matrix and suggests that pathological projection matrices could skew the MFTMA capacity and width scores. The reviewer acknowledges that this is unlikely with random projections but still recommends investigating the resilience of the metric to the choice of random projection. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the variability in results with the chosen random projection matrix and suggests that pathological projection matrices could skew the MFTMA capacity and width scores. The reviewer acknowledges that this is unlikely with random projections but still recommends investigating the resilience of the metric to the choice of random projection. The comment provides a logical reasoning for the concern, suggesting that the authors should explore this aspect to ensure the robustness of their results. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to further develop the reasoning to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the variability in results with the chosen random projection matrix and suggests that pathological projection matrices could skew the MFTMA capacity and width scores. The reviewer acknowledges that this is unlikely with random projections but still recommends investigating the resilience of the metric to the choice of random projection. This feedback is 3 as it identifies a potential issue with the robustness of the results and suggests a direction for further exploration. However, the comment could be more helpful if it provided specific guidance on how to conduct this investigation or what aspects to focus on. Overall, the comment offers a valuable insight but lacks depth and actionable suggestions, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point raises several questions and requests for clarification regarding the use of synthetic data. It asks for an example of what kind of data could look like synthetic data, clarifies the meaning of \"support data\" and \"predicted training count data\" in Figure 1, and requests the explicit inclusion of the model used in the appendix. These requests are explicit and provide clear guidance on what the authors need to do to improve their draft. The actions are concrete, as they specify what information should be added or clarified. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"synthetic data\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it asks for examples of what kind of data could look like synthetic data, clarifies the meaning of \"support data\" and \"predicted training count data\" in Figure 1, and requests the explicit inclusion of the model used in the appendix. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with a score of 5.", "verifiability_rationale": "The review point consists of questions and requests for clarification, such as asking for examples of synthetic data and seeking clarification on the terms \"support data\" and \"predicted training count data\" in Figure 1. It also requests the explicit inclusion of the model used in the appendix. These are factual requests for information or clarification, not subjective claims or opinions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment is 5 as it provides specific and actionable feedback that can guide the authors in improving their draft. It asks for examples of what kind of data could look like synthetic data, clarifies the meaning of \"support data\" and \"predicted training count data\" in Figure 1, and requests the explicit inclusion of the model used in the appendix. These requests are clear and concrete, offering the authors a direct path to enhance the clarity and comprehensiveness of their work. By addressing these points, the authors can provide more detailed and transparent information, which is crucial for the understanding and reproducibility of their research. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the model is overly simple, which is both a feature and a bug. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to make the model more complex or what specific aspects need improvement. Without actionable suggestions or concrete steps, the authors are left without a clear understanding of how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the model is overly simple, which is both a feature and a bug. However, it does not specify which part of the paper this assessment is based on, such as a particular model description or section. Without explicit references to specific sections or models, the authors cannot confidently determine which part of the paper the comment addresses. Additionally, the comment lacks specificity regarding what aspects of the model are considered overly simple or how this simplicity could be a bug. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the model is overly simple, which is both a feature and a bug. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why the model is considered overly simple. Without specific details or references, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment suggests that the model is overly simple, which is both a feature and a bug. However, it lacks specificity and does not provide any actionable feedback or suggestions for improvement. Without detailed guidance on how to address the simplicity or what aspects of the model need to be enhanced, the authors are left without a clear understanding of how to improve their draft. This makes the comment 2, as it identifies a potential issue but does not offer meaningful guidance for resolution."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a potential limitation of the work, noting that its focus on a narrow task and a specific language may restrict its broader impact. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how the authors might broaden the scope of their work or address the issue of limited impact. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment highlights a potential limitation of the work, noting that its focus on a narrow task (climate change QA) and a specific language (Arabic) may restrict its broader impact. However, it does not specify which part of the paper this observation is based on, making it difficult for the authors to identify the exact section that needs attention. Additionally, while the comment points out a limitation, it does not provide specific guidance on how to address this issue or improve the broader impact of the work. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the work\"s focus on a narrow task (climate change QA) and a specific language (Arabic) may limit its broader impact. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a potential limitation of the work, noting that its focus on a narrow task (climate change QA) and a specific language (Arabic) may restrict its broader impact. While this observation is relevant, the comment lacks specificity and actionable guidance on how the authors might address this limitation or expand the scope of their work. Without detailed suggestions or examples, the feedback provides limited value to the authors in terms of improving their draft. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the winnertakeall property has been widely used in previous works and questions the novelty of the paper\"s contribution in understanding this behavior with its simplified settings. It also mentions that most of the findings have been reported in previous works. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve the novelty of their work. The action is implicit and vague, as the authors are left without clear direction on how to enhance the originality or novelty of their paper. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the originality of the paper, specifically questioning the novelty of the paper\"s contribution to the understanding of the winnertakeall property in its simplified settings. It mentions previous works that have used this property and suggests that most of the findings have been reported in previous works. However, the comment does not specify which part of the paper this critique is based on, such as a particular section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing the issue of novelty and referencing previous works, but without explicit grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point claims that the paper\"s contribution to understanding the winnertakeall property is not novel, given its simplified settings and the fact that most findings have been reported in previous works. However, the comment does not provide specific references or detailed examples of these previous works, making it difficult for the authors to fully understand and address the critique. The lack of explicit evidence or references makes the claim 3, as the authors would need to invest effort to identify the relevant literature themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the originality of the paper, specifically questioning the novelty of the paper\"s contribution to the understanding of the winnertakeall property in its simplified settings. It points out that most of the findings have been reported in previous works, which suggests that the paper may not offer significant new insights. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or enhance the originality of their work. While it identifies a potential weakness, it lacks actionable feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should briefly mention the negligible computational cost of CHR, which is currently only in the appendix, in the main paper to help motivate the method. It also recommends providing a rough example of runtimes in the experiments to assist readers who might want to apply the method. While the comment implies that the authors should include this information, it does not explicitly instruct them to do so. The action is concrete in terms of what needs to be done, but it is implicit in the phrasing. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment suggests that the authors should mention the negligible computational cost of CHR, which is currently only in the appendix, in the main paper to help motivate the method. It also recommends providing a rough example of runtimes in the experiments to assist readers who might want to apply the method. While the comment does not explicitly mention a specific section or part of the paper, it is clear that the authors should consider including this information in the main text. The suggestion is specific in terms of what needs to be addressed, such as mentioning computational cost and providing runtime examples. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that mentioning the negligible computational cost of CHR in the main paper would help motivate the method. It also recommends providing a rough example of runtimes in the experiments to assist readers. However, the comment does not provide any specific reasoning or evidence to support why this information is crucial or how it would benefit the paper. Without detailed justification or examples, the claim remains vague and lacks verifiability. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment suggests that the authors should briefly mention the negligible computational cost of CHR, which is currently only in the appendix, in the main paper to help motivate the method. It also recommends providing a rough example of runtimes in the experiments to assist readers who might want to apply the method. This feedback is clear and actionable, as it identifies a specific area for improvement and provides a concrete suggestion for enhancing the paper. By addressing these points, the authors can better motivate their method and make it more accessible to readers. However, the comment could be more helpful if it included additional details or examples on how to present the computational cost or runtimes. Overall, the comment is 4, as it provides valuable guidance for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide more detailed explanation of the EEG topography plots in Figure 3, specifically addressing whether the spatial arrangement of the EEG sensors played a role in the EEG token quantization process. While the comment explicitly states the need for additional explanation, it does not provide specific guidance on how to present this information or what aspects to focus on. The action is explicit but somewhat vague, as the authors know they need to provide more detail but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, namely the ambiguity in interpretation and the need for greater detail in elucidating the EEG token quantization process. The comment further suggests a specific area of interest, namely whether the spatial arrangement of the EEG sensors played a role in this process. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that Figure 3 presents EEG topography plots for both the input and output during the EEG token quantization process, leading to ambiguity in interpretation. The reviewer recommends that the authors provide more detailed explanation of this procedure, specifically addressing whether the spatial arrangement of the EEG sensors played a role. This claim is 3 as it highlights a potential issue with the figure and suggests a specific area for improvement. However, it lacks detailed reasoning or examples to fully substantiate the claim, making it difficult for the authors to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 3, which presents EEG topography plots for both the input and output during the EEG token quantization process. It points out that this setup leads to ambiguity in interpretation and suggests that the authors should provide a more detailed explanation of the procedure. Additionally, the comment recommends exploring whether the spatial arrangement of the EEG sensors played a role in this process. This feedback is clear and actionable, as it directs the authors to enhance the clarity and depth of their explanation, which could significantly improve the understanding of the methodology. However, the comment could be more helpful if it provided specific suggestions on how to present this information or what aspects to focus on. Overall, the comment is 4, as it effectively guides the authors toward improving the clarity and depth of their explanation."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the authors use the complexity of checking on the Witness oracle, which is polynomial time in the tabular case, as a way to address the problem. However, it suggests that this approach is not direct enough. While the comment implies that the authors should find a more direct way to address the problem, it does not provide specific guidance or suggestions on how to achieve this. The action is implicit and somewhat vague, as the authors are left to infer that they need to find a more direct solution but without concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the complexity of checking on the Witness oracle, which is described as \"polynomial time\" in the tabular case. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out that the approach taken is not direct enough, but it lacks detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors use the complexity of checking on the Witness oracle as a way to address the problem, suggesting that this approach is not direct enough. However, the comment lacks specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a potential issue with the authors\" approach, noting that using the complexity of checking on the Witness oracle as a way to address the problem may not be direct enough. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this issue or improve their approach. Without detailed feedback or examples, the authors are left without a clear understanding of what changes or improvements are needed. Therefore, the comment is 2, as it identifies a potential weakness but does not offer meaningful direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should include additional baselines for code completion tasks. It recommends comparing with existing code completion commercial applications, such as Copilot, and testing them on a smaller subset of RepoEval. This feedback provides a clear and concrete action for the authors to take, specifying both the type of baselines to include and how to test them. The explicit nature of the suggestion and the detailed guidance on implementation make this comment 5.", "grounding_specificity_rationale": "The comment suggests including additional baselines for code completion tasks, specifically mentioning Copilot as a commercial application to compare with. It also recommends testing these baselines on a smaller subset of RepoEval. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the experimental setup or results section. The suggestion is specific in terms of what baselines to include and how to test them, providing clear guidance for improvement. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests including additional baselines for code completion tasks, specifically mentioning Copilot as a commercial application to compare with. The reviewer provides a logical reasoning for the suggestion, stating that it is essential to compare with stateoftheart code completion systems. However, the comment lacks specific examples or references to support the claim that Copilot is a relevant baseline or how it compares to other existing systems. This makes the claim 3, as it provides a general direction but lacks detailed evidence or examples to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting the inclusion of additional baselines for code completion tasks. It recommends comparing with existing code completion commercial applications, such as Copilot, and testing them on a smaller subset of RepoEval. This feedback is clear and actionable, providing the authors with a concrete suggestion to enhance the comprehensiveness and validity of their experimental evaluation. By including these baselines, the authors can better position their work in relation to stateoftheart systems, which is crucial for the credibility and impact of their research. However, the comment could be more helpful if it provided specific guidance on how to implement the comparison or what metrics to use. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the generalizability of the evaluation on a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that the authors should clarify the criteria behind this selection and whether other tasks or datasets might yield different insights. While the comment implies that the authors should provide more information on the selection process and its implications, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the issue of generalizability by providing additional information. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the choice to evaluate on only a subset of the Massive Text Embedding Benchmark (MTEB), questioning the generalizability of the results. It suggests that the authors should clarify the criteria behind this selection and whether other tasks or datasets might yield different insights. However, the comment does not specify which part of the paper discusses this evaluation, making it weakly grounded. The authors can infer that it relates to the experimental section, but the lack of explicit reference makes it challenging to pinpoint the exact location. The comment is specific in its request for clarification on the selection criteria and potential implications for generalizability. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the choice to evaluate on only a subset of the Massive Text Embedding Benchmark (MTEB), questioning the generalizability of the results. The comment suggests that the authors should clarify the criteria behind this selection and whether other tasks or datasets might yield different insights. While the comment highlights a potential issue, it does not provide specific examples or references to support the claim that other tasks or datasets might yield different insights. The reasoning is logical but lacks detailed evidence or examples, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the generalizability of the evaluation by questioning the choice to evaluate on only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that the authors should clarify the criteria behind this selection and whether other tasks or datasets might yield different insights. This feedback is clear and actionable, as it prompts the authors to consider the broader applicability of their findings and potentially expand their evaluation to include additional tasks or datasets. However, the comment could be more helpful if it provided specific examples or suggestions on how to address this issue. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the performance of the shiftedMNIST dataset, specifically why shift=0 performs better than shift~N(0,\u03c32). It also suggests showing the performance of the model and baselines on test samples from the observational (in) distribution. While the comment implies that the authors should provide additional analysis or results to address this question, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional analysis to clarify the performance differences. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"shiftedMNIST,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the performance difference between shift=0 and shift~N(0,\u03c32) and suggesting the inclusion of performance analysis on test samples from the observational (in) distribution. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the performance of the shiftedMNIST dataset, specifically why shift=0 performs better than shift~N(0,\u03c32). It suggests that the authors should show the performance of the model and baselines on test samples from the observational (in) distribution. While the comment questions the reasoning behind the performance difference, it does not provide specific evidence or references to support the claim. The suggestion to include additional analysis is logical but lacks detailed justification or examples. Therefore, the comment is 3, as it provides a reasonable basis for further exploration but requires more detailed evidence or reasoning to be fully substantiated.", "helpfulness_rationale": "The review comment raises a question about the performance of the shiftedMNIST dataset, specifically why shift=0 performs better than shift~N(0,\u03c32). It suggests that the authors should provide additional analysis by showing the performance of the model and baselines on test samples from the observational (in) distribution. This feedback is clear and actionable, as it identifies a specific area for improvement and provides a concrete suggestion for further analysis. By addressing this point, the authors can enhance the comprehensiveness and robustness of their results. However, the comment could be more helpful if it included additional context or explanation about the significance of this analysis. Overall, the comment is 4, as it provides valuable guidance for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper should analyze the quality of local minima found by Algorithm 1, specifically mentioning the approximation ratio under certain assumptions. While the comment implies that the authors should expand their analysis to include this aspect, it does not provide explicit instructions on how to conduct this analysis or what specific assumptions should be considered. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take and may not be entirely sure of the scope of the analysis. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the analysis of the quality of local minima found by Algorithm 1, particularly the approximation ratio under certain assumptions. This provides clear guidance on what the authors need to focus on to improve their work. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper should analyze the quality of local minima found by Algorithm 1, specifically mentioning the approximation ratio under certain assumptions. This claim is 3 as it provides a logical suggestion for further analysis, but it lacks specific examples or references to support the need for such an analysis. The comment suggests a direction for improvement but does not fully substantiate the claim with detailed reasoning or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the analysis of the paper, specifically noting that it only examines the conditions under which Algorithm 1 converges to permutations as local minima. It suggests that the quality of these local minima should also be analyzed, such as the approximation ratio under certain assumptions. This feedback is clear and actionable, providing the authors with a specific direction for enhancing their analysis and potentially improving the comprehensiveness of their results. However, the comment could be more helpful if it offered examples or specific assumptions to consider in the analysis. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their work."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about how information redundancy is built into the Fill, Propagate, Decode algorithms. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on what specific aspects of the algorithms need clarification or improvement, leaving the authors without a clear understanding of how to address the issue. Without actionable suggestions or concrete steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Fill, Propagate, Decode\" algorithms and the sentence \"Finally, by comparing the performance of the secret model with or without fusion, we conclude that the robustness of Cans largely comes from the information redundancy implemented in our design of the weight pool.\" This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it questions how information redundancy is built into the algorithms and provides a reference to the sentence where this claim is made. This level of detail helps the authors understand what needs to be clarified or improved. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the implementation of information redundancy in the Fill, Propagate, Decode algorithms. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim. The comment lacks specific details or examples that would help the authors understand the issue or provide a basis for addressing it. As a result, the claim is 1, as it does not offer sufficient information for the authors to make improvements based on the feedback. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the implementation of information redundancy in the Fill, Propagate, Decode algorithms. It references a specific sentence in the paper where the authors claim that the robustness of Cans largely comes from the information redundancy implemented in the weight pool design. However, the comment does not provide any further explanation, analysis, or suggestions on how the authors might clarify or improve this aspect of their work. Without additional guidance or context, the authors are left without a clear understanding of what specific aspects of the implementation need to be addressed or how to enhance their explanation. Therefore, the comment is 2, as it identifies a potential area of concern but lacks depth and actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the importance of the model\"s novel feature, which involves using multiple INs at different speeds in the dynamics predictor. It suggests that the design choice should be ablated to determine its significance. The comment explicitly asks whether one IN would suffice, providing a clear action for the authors to take. However, it does not specify how the authors should conduct the ablation study or what specific aspects to focus on. While the action is explicit, the lack of detailed guidance on implementation makes the comment 3.", "grounding_specificity_rationale": "The comment raises a question about the importance of a novel feature in the model, specifically the use of multiple INs at different speeds in the dynamics predictor. However, it does not specify which part of the paper discusses this feature, making it weakly grounded. The comment is specific in questioning the necessity of this design choice and suggesting an ablation study to determine its significance. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the importance of a novel feature in the model, specifically the use of multiple INs at different speeds in the dynamics predictor. It suggests that this design choice should be ablated to determine its significance. However, the comment lacks specific reasoning or evidence to support why this feature is important or how its ablation would impact the model\"s performance. Without detailed justification or examples, the claim remains 3, as the authors would need to infer the importance of this feature themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a pertinent question about the importance of a novel feature in the model, specifically the use of multiple INs at different speeds in the dynamics predictor. It suggests that this design choice should be ablated to determine its significance and asks whether one IN would suffice. This feedback is clear and actionable, as it prompts the authors to conduct an ablation study to evaluate the impact of this feature on the model\"s performance. By addressing this point, the authors can gain a better understanding of the model\"s effectiveness and potentially make improvements. However, the comment could be more helpful if it provided additional guidance on how to conduct the ablation study or what specific aspects to focus on. Overall, the comment is 4, as it directs the authors to a critical area for improvement with actionable suggestions."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should include experimental results that exclude the mixup technique from the proposed method. This is a clear and direct action for the authors to take, as it specifies exactly what needs to be done to demonstrate the pure contribution of the proposed method. The comment provides concrete guidance on how to improve the draft by adding additional experiments. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 4.2\" and \"the mixup technique in LUMP,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the inclusion of experimental results that exclude the mixup technique to demonstrate the pure contribution of the proposed method. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should include experimental results that exclude the mixup technique from the proposed method to demonstrate its pure contribution. This claim is based on the observation that the mixup technique is also used in the experiments on SplitCIFAR100 and SplitTinyImageNet. The comment provides a logical reasoning for the suggestion, as it highlights the need to isolate the contribution of the proposed method from other techniques. However, it lacks specific references or detailed examples of how the mixup technique might affect the results, which would strengthen the justification. Therefore, the comment is 3, as it provides a logical basis but could be more robust with additional evidence or examples.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the experimental setup by suggesting that the authors should include experimental results that exclude the mixup technique from the proposed method. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the paper\"s contribution by isolating the effects of the proposed method from other techniques. By following this advice, the authors can better demonstrate the pure contribution of their method, which is crucial for evaluating its effectiveness. However, the comment could be more helpful if it provided additional context or rationale for why this exclusion is important. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks for clarification regarding the object detection based attention, specifically whether it is performed on the image or on a convolutional feature map. It also suggests that the authors should clarify if any rescaling is done based on the receptive field to determine which image regions correspond to which spatial locations in the feature map. This feedback provides clear and explicit actions for the authors to take, ensuring they know exactly what needs to be clarified and how to address it. The comment is 5 as it offers concrete guidance on how to improve the draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"object detection based attention,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified: whether the attention is performed on the image or on a convolutional feature map, and whether rescaling is done based on the receptive field. This provides clear guidance on what the authors need to address, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a request for clarification regarding the object detection based attention, specifically whether it is performed on the image or on a convolutional feature map. It also asks about the potential use of rescaling based on the receptive field. This is a factual request for clarification and does not contain any subjective claims or opinions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area of confusion regarding the object detection based attention. It asks for clarification on whether the attention is performed on the image or on a convolutional feature map, and whether rescaling is done based on the receptive field. This feedback prompts the authors to clarify these aspects, which could help improve the clarity and understanding of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to address these questions. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a lack of details regarding how the network is made to fit the residual instead of directly learning the inputoutput mapping. However, it does not provide explicit guidance or suggestions on what the authors should do to address this issue. The comment implies that the authors should include more details on this aspect, but it lacks concrete instructions on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of fitting the network to the residual rather than directly learning the inputoutput mapping. This allows the authors to accurately identify the part of the paper being addressed. However, the comment is not specific because it does not provide detailed guidance on what aspects of the network fitting process need clarification or improvement. Therefore, this comment is 4, aligning with category 4.", "verifiability_rationale": "The review point questions the lack of details on how the network is made to fit the residual instead of directly learning the inputoutput mapping. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the network architecture, specifically the lack of details on how it fits the residual instead of directly learning the inputoutput mapping. This feedback is 3 as it points out a potential gap in the explanation of the network\"s design, prompting the authors to clarify this aspect. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as recommending additional explanations or examples. While it highlights an area for improvement, the lack of detailed feedback limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks for details about the experiment setup in Section 3.3, specifically mentioning data augmentation methods, learning rate, etc. This request is clear and direct, providing the authors with a specific action to take. The inclusion of a reference to a relevant paper further supports the action by providing a source for the authors to consider. Therefore, this comment is 5, as it clearly instructs the authors on what information to include and where to find additional resources.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the details about the experiment setup, such as data augmentation methods and learning rate. The inclusion of a reference to a relevant paper further supports the specificity of the comment. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a factual question about the experiment setup in Section 3.3, specifically asking for details on data augmentation methods and learning rate. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area for improvement by asking for details about the experiment setup in Section 3.3. It requests information on data augmentation methods and learning rate, which are important aspects of the experimental design. However, the comment could be more helpful if it provided guidance on how to present this information or suggested specific ways to improve the clarity of the experimental setup. By offering more detailed feedback, the comment could empower the authors to make more significant improvements to their draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the possibility of an error in the initial calibration steps (steps 1 & 2) that might explain the speed disparities observed between the RSPs and FDs. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should investigate this possibility, correct the calibration steps, or address the speed disparities in their analysis. The comment lacks actionable advice, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions Section III of the \"Recognition and Velocity Computation of Large Moving Objects in Images\" paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether an error in the initial calibration steps (steps 1 & 2) might explain the speed disparities observed between the RSPs and FDs. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the possibility of an error in the initial calibration steps (steps 1 & 2) that might explain the speed disparities observed between the RSPs and FDs. However, it does not provide any specific evidence, examples, or references to support this claim. The comment lacks detailed reasoning or justification, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is 1, as it does not provide sufficient evidence or reasoning to substantiate the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the possibility of an error in the initial calibration steps (steps 1 & 2) that might explain the speed disparities observed between the RSPs and FDs. While it identifies a potential issue, it lacks specific guidance or suggestions on how the authors might investigate or address this concern. The comment does not provide actionable steps or detailed feedback on how to improve the draft, leaving the authors with only a vague direction to explore. Therefore, the comment is 2, as it identifies a potential area for improvement but does not offer sufficient guidance to be actionable."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point acknowledges that the artificial networks trained using ASAP (and similar methods) may not necessarily resemble biological networks, except for the weight transport problem, which is of arguable importance. The reviewer clarifies that this observation does not affect the review given and does not hold the authors accountable. However, the comment does not provide any actionable advice or suggestions for the authors to address this issue or improve their draft. It lacks specific guidance on how the authors might enhance their work to better align with biological networks or address the weight transport problem. As a result, the authors are left without any clear direction on how to proceed, making the comment 1.", "grounding_specificity_rationale": "The comment addresses the issue of whether artificial networks trained using ASAP (and similar methods) resemble biological networks, specifically questioning the importance of the weight transport problem. However, it does not specify which part of the paper this discussion is based on, making it weakly grounded. The comment is specific in its critique of the resemblance between artificial and biological networks, but it lacks grounding as it does not reference a particular section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions whether artificial networks trained using ASAP (and similar methods) resemble biological networks, specifically addressing the weight transport problem. The reviewer acknowledges that this issue does not affect the review given and does not hold the authors accountable. However, the comment lacks specific evidence or references to support the claim that these networks do not resemble biological networks. Without detailed reasoning or examples, the claim remains 3, as it provides a basis for questioning but lacks comprehensive justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges that artificial networks trained using ASAP (and similar methods) may not necessarily resemble biological networks, except for the weight transport problem, which is of arguable importance. However, the reviewer clarifies that this observation does not affect the review given and does not hold the authors accountable. While the comment provides some insight into the limitations of the approach, it lacks actionable feedback or suggestions for improvement. The authors are left without guidance on how to address this issue or enhance their work. Therefore, the comment is 2, as it identifies a potential weakness but does not offer constructive advice for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the authors performed a statistical significance test when comparing the proposed method with baselines. While it implies that the authors should consider conducting such a test, the comment does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to conduct the test or what parameters to consider. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the statistical significance of the numbers presented in the paper, specifically in the comparison between the proposed method and baselines. However, it does not specify which part of the paper this comparison is discussed in, making it weakly grounded. The comment is specific in its request for a statistical significance test, but without clear grounding, the authors may struggle to identify the exact section needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the statistical significance of the numbers presented in the paper, specifically in the comparison between the proposed method and baselines. However, it does not provide any evidence, reasoning, or references to support the claim that the numbers are close or to suggest that a statistical significance test is necessary. Without additional context or justification, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the statistical significance of the numbers presented in the paper, specifically in the comparison between the proposed method and baselines. This is a critical point that could impact the interpretation and validity of the results. However, the comment lacks depth and does not provide specific guidance on how to address this issue or what statistical tests might be appropriate. While it identifies a potential area for improvement, the feedback is somewhat vague and incomplete, making it 3. The authors are given a direction to consider but are not fully equipped with actionable steps to enhance their draft. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the impact of nonparametric emission distributions on inference tasks in a discrete HMM. It explicitly asks which of the common inference tasks (filtering, smoothing, and marginal observation likelihood) can be computed exactly or approximately with an NPSPECHMM. This question provides a clear and direct action for the authors to take, as it prompts them to clarify the relationship between the emission distributions and inference tasks. The comment is explicit and provides concrete guidance on what the authors need to address, making it 5.", "grounding_specificity_rationale": "The comment raises a question about the impact of nonparametric emission distributions on inference tasks in a discrete HMM, specifically asking which of the common inference tasks (filtering, smoothing, and marginal observation likelihood) can be computed exactly or approximately with an NPSPECHMM. However, it does not specify which part of the paper this question pertains to, leaving the authors to infer that it relates to the sections discussing inference or modeling. While the comment is specific in its inquiry, it lacks grounding as it does not explicitly mention a particular section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the impact of nonparametric emission distributions on inference tasks in a discrete HMM. It does not present a claim or opinion but rather seeks clarification through a question. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a critical question about the impact of nonparametric emission distributions on inference tasks in a discrete HMM. It specifically asks which of the common inference tasks (filtering, smoothing, and marginal observation likelihood) can be computed exactly or approximately with an NPSPECHMM. This question prompts the authors to clarify an important aspect of their work, which could lead to a more comprehensive understanding of the model\"s capabilities and limitations. However, the comment could be more helpful if it provided additional context or suggestions on how to address this issue. Overall, the feedback is 3 as it identifies a gap in the paper and encourages the authors to clarify a critical aspect of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the analysis of experimental results is insufficient, specifically mentioning that the authors only mention the poor performance of the scope prompting method on GPT3.5turbo without providing any analysis of the underlying reasons. This feedback implies that the authors should include an analysis of the reasons behind this outcome, which is an implicit action. However, the comment does not provide specific guidance on how to conduct this analysis or what aspects to focus on. While the action is clear, it lacks concrete details on how to implement it, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"analysis of experimental results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular issue with the analysis, namely the lack of explanation for the poor performance of the scope prompting method on GPT3.5turbo. The comment provides a clear direction for improvement by suggesting that the authors should analyze the underlying reasons for this outcome. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of experimental results is insufficient, specifically mentioning that the authors only mention the poor performance of the scope prompting method on GPT3.5turbo without providing any analysis of the underlying reasons. This claim is 3 as it highlights a gap in the analysis, but it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to provide additional context or analysis to understand the basis of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the analysis of experimental results, noting that the authors only mention the poor performance of the scope prompting method on GPT3.5turbo without providing any analysis of the underlying reasons. This feedback is clear and actionable, as it highlights a gap in the paper that the authors can address by conducting a more thorough analysis of the experimental results. By suggesting that the authors should explore the reasons behind the poor performance, the comment provides a concrete direction for improvement. However, it could be more helpful if it offered specific suggestions on how to conduct this analysis or what aspects to focus on. Overall, the comment is 4 as it directs the authors to enhance the depth and clarity of their analysis, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about why the authors did not compare batch and greedy methods in the remaining 110 datasets, given that only 10 out of 120 datasets were considered in [7,12]. While the comment implies that the authors should consider comparing these methods in the other datasets, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand their analysis to include more datasets. However, the comment provides a clear rationale for why this comparison might be beneficial, which could guide the authors in making a decision. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the authors\" choice to only consider 10 out of 120 datasets in [7,12] and suggests comparing batch and greedy methods in the remaining 110 datasets. However, it does not specify which part of the paper this issue pertains to, such as a specific section or table where the datasets are discussed. This lack of explicit grounding makes it difficult for the authors to pinpoint the exact part of the paper that needs attention. The comment is specific in its suggestion to compare batch and greedy methods in the remaining datasets, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the authors\" decision to only consider 10 out of 120 datasets in [7,12] and suggests comparing batch and greedy methods in the remaining 110 datasets. However, the comment does not provide any reasoning or evidence to support why this comparison is necessary or beneficial. It lacks specific examples or references to justify the claim, making it difficult for the authors to understand the basis of the suggestion. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the authors\" choice to only consider 10 out of 120 datasets in [7,12] and suggests comparing batch and greedy methods in the remaining 110 datasets. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue. It does not provide actionable steps or detailed feedback on why this comparison is important or how it could impact the results or conclusions of the paper. As a result, the comment is 3, as it points out a potential area for expansion but does not fully support the authors in making improvements to their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the motivation for the lowrank factorization in the introduction is unnecessary, given that the main result is about polytopes. If the result has implications for lowrank matrix factorization, the reviewer requests that these implications be explicitly discussed. While the comment implies that the authors should address the implications of their result for lowrank matrix factorization, it does not provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should discuss the implications and determine how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"motivation in the introduction with the lowrank factorization,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the implications of the main result for lowrank matrix factorization should be explicitly discussed. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the motivation for lowrank factorization in the introduction is unnecessary, given that the main result is about polytopes. The reviewer requests that if the result has implications for lowrank matrix factorization, these implications should be explicitly discussed. However, the comment does not provide specific examples or references to support the claim that the motivation is unnecessary or that the implications should be discussed. This lack of detailed justification or evidence makes the claim 3, as the authors may need to infer the reasoning behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential disconnect between the motivation for lowrank factorization in the introduction and the main result, which is about polytopes. It suggests that if the result has implications for lowrank matrix factorization, these implications should be explicitly discussed. This feedback is clear and actionable, as it points out a specific area where the authors could enhance the clarity and relevance of their work. By addressing this feedback, the authors can improve the coherence and impact of their paper. However, the comment could be more helpful if it provided specific examples or suggestions on how to discuss the implications of the result for lowrank matrix factorization. Overall, the comment is 4, as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks for clarification on the labels for each dataset in Section 4.1, specifically questioning whether they are derived from the dataset itself or from other sources. This request is clear and direct, providing the authors with a specific action to take to improve their draft. The comment also suggests that the labels for generated datasets may be straightforward, but it raises a question about the labels for caspealr1 and mugshot. This additional inquiry adds depth to the comment, making it 5. The authors know exactly what information to provide to address the reviewer\"s concerns, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the labels for each dataset and their origin. The comment asks for clarification on whether the labels are derived from the dataset itself or from other sources, and it raises a question about the labels for specific datasets like caspealr1 and mugshot. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with a score of 5.", "verifiability_rationale": "The review point is a request for clarification regarding the labels for each dataset in Section 4.1, specifically asking where the labels are coming from. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area of confusion regarding the labels for each dataset in Section 4.1. It raises a question about the origin of the labels, whether they are derived from the dataset itself or from other sources. This feedback prompts the authors to clarify this aspect of their work, which can help improve the transparency and comprehensiveness of their methodology. However, the comment could be more helpful if it provided additional context or suggestions on how to address this issue, such as recommending specific ways to clarify the labeling process. Overall, the comment provides some direction but lacks depth, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point notes that the paper is incremental compared to a specific reference, [31], and describes the adaptation of the existing architecture for the multiperson case. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address the perceived incremental nature of the work or improve upon it. Without actionable suggestions or specific feedback, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the paper as being incremental compared to a specific reference, [31], and describes the adaptation of the existing architecture for the multiperson case. However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to identify the exact sections that need attention. Additionally, the comment lacks specificity regarding what aspects of the paper are considered incremental or how the adaptation could be improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is incremental compared to reference [31], and it describes the adaptation of the existing architecture for the multiperson case. However, the comment does not provide any specific details or examples to support this claim, such as how the paper is incremental or what aspects of the existing architecture are adapted. Without these details, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that the paper is incremental compared to a specific reference, [31], and describes the adaptation of the existing architecture for the multiperson case. However, it does not provide any specific feedback or suggestions on how the authors might address this perceived incremental nature or improve their work. Without actionable guidance or constructive criticism, the comment lacks depth and does not offer much value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises several questions and observations about the sensitivity of performance and sample efficiency to the \u03bb parameters, as well as the process of calculating \u03bb. It also mentions a lack of understanding regarding the explanation of why ELLA does not increase sample efficiency in a COMBO environment. The comment provides references to relevant literature, which could help the authors better understand the context. However, it does not explicitly instruct the authors to address these issues or provide specific guidance on how to improve the clarity or explanation. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the calculation process and the explanation of ELLA\"s impact on sample efficiency. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific pages and lines where the issues are discussed, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the concerns about the sensitivity of performance and sample efficiency to the \u03bb parameters, the process of calculating \u03bb, and the explanation of why ELLA does not increase sample efficiency in a COMBO environment. The comment further provides references to relevant literature, which adds to the specificity of the feedback. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises several claims and questions, making it a combination of factual statements and claims. The first claim about the sensitivity of performance and sample efficiency to the \u03bb parameters is supported by references to specific lines in the paper, providing a clear basis for the claim. The second claim regarding the process of calculating \u03bb is also supported by references to specific lines in the paper, offering a logical basis for the inquiry. The third claim about the explanation of ELLA\"s impact on sample efficiency is supported by references to relevant literature, which helps contextualize the issue. Overall, the comment is 4 as it provides sufficient evidence and references to support the claims and questions, making it clear to the authors what needs clarification or further explanation. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises several important points and questions that could help the authors improve their draft. It highlights the sensitivity of performance and sample efficiency to the \u03bb parameters, which is an important observation that the authors should address. The comment also questions the process of calculating \u03bb and the explanation of why ELLA does not increase sample efficiency in a COMBO environment, which could lead to confusion among readers. The inclusion of references to relevant literature provides context and direction for the authors to further explore these issues. However, the comment could be more helpful if it offered specific suggestions or guidance on how to clarify or address these points. Overall, the feedback is 4 as it identifies key areas for improvement and provides some direction, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the specific method used to solve the minmin problem, but it does not provide any explicit or implicit action for the authors to take. It lacks guidance on whether the authors should clarify the method, provide more details, or address the question in any way. Without any actionable steps or suggestions, the authors are left without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the specific method used to solve the minmin problem, but it does not specify which part of the paper this question pertains to. The authors cannot confidently determine the exact section or context where this method is mentioned, making the comment weakly grounded. However, the comment is specific in its inquiry about the method used, which provides some guidance on what needs to be clarified. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point is a question seeking clarification about the specific method used to solve the minmin problem. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the specific method used to solve the minmin problem, which is briefly mentioned in the paper. While it identifies a potential area for clarification, it lacks depth and does not provide any suggestions or guidance on how the authors might address this issue. The comment is 3 as it points out a gap in the paper, but it does not offer actionable advice or detailed feedback on how to improve the draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the experiments should be more comprehensive and general, specifically mentioning that the model size is limited and the baselines are restrictive. However, it does not provide explicit guidance on how to achieve this or what specific changes should be made to improve the comprehensiveness and generality of the experiments. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand the model size and include more diverse baselines. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experiments should be more comprehensive and general, specifically mentioning the limited model size and restrictive baselines for both the language modeling task and image classification task. However, it does not specify which sections of the paper these experiments are discussed in, making it difficult for the authors to pinpoint the exact parts that need improvement. The comment is specific in identifying the issue with the experiments but lacks grounding, as it does not explicitly mention the sections or parts of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments should be more comprehensive and general, specifically mentioning the limited model size and restrictive baselines for both the language modeling task and image classification task. However, the comment lacks specific examples or references to support this claim, such as comparing the model size to industry standards or discussing alternative baselines that could be included. Without detailed justification or evidence, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the experiments, noting that they should be more comprehensive and general. It points out that the model size is limited and the baselines are restrictive, suggesting that these factors limit the scope and applicability of the experiments. However, the comment lacks detailed guidance or suggestions on how to address these limitations, such as recommending specific model sizes or baselines to include. While it highlights an important area for improvement, the feedback could be more actionable and helpful by providing concrete steps for the authors to take. Therefore, the comment is 3, as it provides some direction but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to elaborate on a specific aspect of their paper, namely the Hoeffding\"s bound and its applicability to stochastic algorithms. It provides a clear action for the authors to take, which is to expand on the explanation in the paper. However, the comment does not specify how the authors should elaborate on this topic, leaving some room for interpretation. While the action is explicit, the lack of detailed guidance makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 124125, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what needs to be elaborated on, namely the applicability of Hoeffding\"s bound to stochastic algorithms. The comment provides a clear direction for the authors to improve their explanation, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of factual statements and questions, making it a normal statement. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area of the paper where the authors could provide more elaboration, specifically regarding the applicability of Hoeffding\"s bound to stochastic algorithms. It points out that the authors should explain how the conditioning on the previous iterate further guarantees the validity of the Hoeffding inequality. This feedback is clear and actionable, as it directs the authors to enhance the clarity and depth of their explanation in the paper. However, the comment could be more helpful if it included suggestions on how to present this information or examples to illustrate the point. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests adding an optimizationbased metalearning approach to Table1, specifically mentioning MAML or implicitMAML. This is an explicit suggestion that provides a clear action for the authors to take, namely, to incorporate these approaches into their table. The comment is concrete because it specifies the type of approach to consider, making it 5.", "grounding_specificity_rationale": "The comment suggests adding an optimizationbased metalearning approach to Table1, specifically mentioning MAML or implicitMAML. However, it does not specify which part of Table1 this suggestion pertains to, nor does it provide details on how these approaches might be integrated or what specific improvements they could bring. While the authors might infer that it relates to the experimental results or methodology sections, the comment lacks full grounding as it does not explicitly mention these sections. The suggestion is specific in terms of the type of approach to consider, but the lack of detailed guidance makes it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests adding an optimizationbased metalearning approach to Table1, specifically mentioning MAML or implicitMAML. However, the comment does not provide any reasoning, examples, or references to support why this addition would be beneficial or how it could improve the paper. Without additional context or justification, the authors may find it challenging to understand the significance of this suggestion or how to implement it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests adding an optimizationbased metalearning approach to Table1, specifically mentioning MAML or implicitMAML. This feedback is 3 as it provides a specific suggestion for enhancing the paper by incorporating a particular type of approach. However, the comment lacks detailed guidance on how to implement this suggestion or why it would be beneficial, which limits its usefulness. The authors are given a direction to explore but are not provided with a clear roadmap for integration or the potential benefits of this addition. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to use the terms \"causal mechanisms\" and \"causality\" carefully, as they are different from the term \"temporal relationship.\" This feedback provides a clear and direct action for the authors to take, ensuring they use the terms correctly throughout the paper. The comment is explicit and concrete, leaving no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Page 1\" and the specific term \"causal mechanisms,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of the term \"causal mechanisms,\" pointing out that it should be differentiated from \"temporal relationship.\" Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the use of the term \"causal mechanisms\" on page 1. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the use of terminology on page 1, where the term \"causal mechanisms\" is used interchangeably with \"temporal relationship.\" It provides a clear and actionable suggestion to use the terms carefully, ensuring clarity and accuracy in the paper. This feedback is valuable as it helps the authors correct a potential misunderstanding in their work, improving the precision and clarity of their writing. However, the comment could be more helpful if it provided examples or further explanation of how to differentiate between these terms. Overall, the comment is 4, as it directs the authors to a specific area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point states that the results in Section 4 only apply to shallow fullyconnected ReLU networks. However, it does not provide any explicit or implicit action for the authors to take. There is no guidance on how to address this limitation, whether it should be clarified, or if it affects the generalizability of the results. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the results, stating that they only apply to shallow fullyconnected ReLU networks. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, corresponding to label 5.", "verifiability_rationale": "The review point claims that the results in Section 4 only apply to shallow fullyconnected ReLU networks. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how it affects the validity of their results. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a specific limitation in the results presented in Section 4, stating that they only apply to shallow fullyconnected ReLU networks. While this is a relevant observation, the comment does not provide any suggestions or guidance on how the authors might address this limitation or expand the applicability of their results. Without actionable feedback or suggestions for improvement, the comment offers limited value to the authors in terms of enhancing their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly requests the authors to provide results regarding the discussion of using sequential MCB vs a single MCT layers for the decision head. This request is clear and direct, leaving no ambiguity about what the authors need to do to address the feedback. The comment provides a concrete action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the discussion of using sequential MCB vs a single MCT layers for the decision head, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests the authors to speak about what was observed regarding this discussion, providing a clear direction for improvement. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for additional information, specifically asking the authors to provide results regarding the discussion of using sequential MCB vs a single MCT layers for the decision head. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a gap in the paper by noting that the discussion of using sequential MCB vs a single MCT layers for the decision head is interesting but lacks results. It provides a clear and actionable suggestion for the authors to address by asking them to speak about what was observed in this context. This feedback is specific and offers a direct path for the authors to enhance their draft by providing additional results or analysis. However, it could be more helpful if it included suggestions on how to present or interpret these results. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their paper."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point consists of two parts: a request for sensitivity analysis regarding other hyperparameters and a list of minor language issues. The first part is explicit and actionable, as it clearly instructs the authors to conduct a sensitivity analysis on other hyperparameters. The second part is also explicit, as it provides specific examples of language issues that need to be corrected. However, the second part lacks concrete guidance on how to address the language issues, such as suggesting alternative phrasing or providing examples of correct usage. Overall, the comment is 4, as it provides clear instructions for both parts, but the lack of detailed guidance on language issues limits its full actionability.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper, such as \"above of (7),\" \"Theorem 1,\" and \"above of (14),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear examples of language issues that need to be corrected, such as \"we typically considers,\" \"two permutation,\" and \"until converge.\" This level of detail guides the authors on what specific changes are needed to improve the language clarity. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts: a request for sensitivity analysis regarding other hyperparameters and a list of minor language issues. The first part is a suggestion for additional analysis, which is not a claim and does not require verification. The second part is a request for proofreading and correction of language issues, which is a factual statement and does not contain a claim. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a mix of feedback. It suggests conducting a sensitivity analysis on other hyperparameters, which is a clear and actionable suggestion for improving the paper. This part of the comment is 5 as it guides the authors to explore additional aspects of their work. However, the second part of the comment consists of minor language issues, which are listed without specific guidance on how to address them. While the authors are instructed to proofread and fix these issues, the lack of detailed feedback on language usage limits the comment\"s overall helpfulness. Therefore, the comment is 4, as it provides actionable guidance on one aspect but lacks depth in another, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the choice of 20 distribution sets and whether the number of distribution sets for each class can be controlled. It also asks what would happen if only a few distribution sets were selected. While the comment implies that the authors should clarify these points, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the questions or what information should be included. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the choice of 20 distribution sets and whether the number of distribution sets for each class can be controlled. However, it does not specify which part of the paper discusses this choice, making it weakly grounded. The comment is specific in its questions about the choice of distribution sets and the potential impact of selecting fewer sets. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the choice of 20 distribution sets and whether the number of distribution sets for each class can be controlled. It also asks what would happen if only a few distribution sets were selected. However, the comment does not provide any supporting evidence, reasoning, or references to justify these questions. Without additional context or explanation, the authors may find it challenging to address the concerns effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises questions about the choice of 20 distribution sets and whether the number of distribution sets for each class can be controlled. It also asks what would happen if only a few distribution sets were selected. While the comment identifies a potential area of concern, it lacks specific guidance or suggestions on how the authors might address these questions or improve their methodology. The feedback is 3 as it prompts the authors to consider these aspects, but it does not provide actionable advice or detailed insights into how to resolve the issues. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should showcase their approach using transformerbased (masked) language models instead of obsolete language models like ngram HMM and RNN, which are no longer commonly used. This comment explicitly states an action for the authors to take, which is to update their experiments to align with current NLP trends. The suggestion is clear and provides a concrete direction for the authors to follow, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"perplexity experiments\" and the use of \"obsolete language models\" like ngram HMM and RNN, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the language models used and suggests an alternative approach using transformerbased (masked) language models to better align with current NLP trends. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the perplexity experiments are conducted on obsolete language models, such as ngram HMM and RNN, which are no longer commonly used. The reviewer suggests that the authors should showcase their approach using transformerbased (masked) language models to better align with current NLP trends. While the claim is based on the observation that these models are outdated, it lacks specific references or detailed reasoning to support why the use of these models is problematic or how the suggested approach would be more relevant. The comment provides a logical suggestion but lacks sufficient evidence or examples to fully substantiate the claim, making it 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the perplexity experiments, noting that they are conducted on obsolete language models (ngram HMM and RNN) that are no longer commonly used. It suggests that the authors should showcase their approach using transformerbased (masked) language models to better align with current NLP trends. This feedback is clear and actionable, providing the authors with a concrete suggestion to improve the relevance and impact of their work. By addressing this feedback, the authors can enhance the applicability and significance of their paper. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the experiments are insufficient and suggests that more empirical experiments or toy experiments should be conducted to validate the model relaxations and the consistency of the theoretical analysis with empirical results. It also mentions the need to cite the results from Kaplan et al. 2020. This feedback provides clear and concrete actions for the authors to take, such as conducting additional experiments and referencing relevant literature. The explicit nature of the suggestions and the concrete details on what needs to be done make this comment 5.", "grounding_specificity_rationale": "The comment addresses the sufficiency of the experiments, specifically mentioning the need for more empirical experiments or toy experiments to validate the model relaxations and the consistency of the theoretical analysis with empirical results. It also suggests citing the results from Kaplan et al. 2020. However, the comment does not specify which part of the paper these experiments should be conducted in, making it weakly grounded. The authors can infer that it relates to the experimental sections, but the lack of explicit references makes it challenging to pinpoint the exact areas needing attention. The comment is specific in suggesting additional experiments and referencing external work, but the lack of grounding limits its effectiveness. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments are insufficient and suggests conducting more empirical experiments or toy experiments to validate the model relaxations and the consistency of the theoretical analysis with empirical results. The comment also mentions the need to cite the results from Kaplan et al. 2020. While the suggestion to conduct additional experiments is logical, the comment lacks specific examples or detailed reasoning to support why the current experiments are insufficient. This makes the claim 3, as it provides a general direction but lacks the depth needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, specifically the insufficiency of the experiments. It suggests that more empirical experiments or toy experiments are needed to validate the model relaxations and the consistency of the theoretical analysis with empirical results. Additionally, it mentions the need to cite the results from Kaplan et al. 2020. This feedback is clear and actionable, providing the authors with specific directions to enhance the robustness and validity of their work. However, it could be more helpful if it offered guidance on how to design these additional experiments or what specific aspects of the theoretical analysis should be tested empirically. Overall, the comment is 4 as it effectively directs the authors to address a critical area for improvement in their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a lack of clarity regarding the estimation of mu, which is the proportion of missing observations. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or improve the clarity of their discussion. The comment lacks actionable guidance, leaving the authors without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the estimation of mu, which is discussed in the paper. However, it does not specify which part of the paper this discussion is located in, making it weakly grounded. The comment is specific in pointing out the lack of clarity regarding the estimation of mu, but it does not provide detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the discussion on the misestimation of mu is unclear because mu is the proportion of missing observations, and it is not clear how it can be estimated. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this estimation is unclear or how it could be clarified. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the discussion on the misestimation of mu is unclear because mu is the proportion of missing observations. However, it does not provide any suggestions or guidance on how the authors might clarify this aspect or improve their explanation. The comment highlights a potential area for improvement but lacks actionable feedback, making it 3. The authors are given a direction to explore but without detailed guidance on how to address the issue, limiting the comment\"s usefulness. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point suggests a specific way to present the performance of the algorithm by considering the sensitivity to initialization. It provides a clear and concrete action for the authors to take, which is to present the performance as a function of the distance of initialization to the groundtruth. The comment also specifies how to implement this suggestion by providing a range of distances (c) and a method for sampling matrices. This level of detail ensures that the authors know exactly what to do to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests presenting the performance as a function of the distance of initialization to the groundtruth, which provides a clear and specific direction for improvement. However, it does not explicitly mention which part of the paper this suggestion pertains to, such as a specific section or figure. The authors can infer that it relates to the experimental results or methodology sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests presenting the performance as a function of the distance of initialization to the groundtruth, which is a logical and reasonable suggestion. The reviewer provides a clear explanation of how this could be done, including a specific method for sampling matrices and reporting performance. This level of detail and reasoning makes the claim 5, as it provides a concrete and actionable suggestion for improving the paper. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the presentation of the paper. It recommends presenting the performance as a function of the distance of initialization to the groundtruth, which is a novel and insightful approach. The comment also provides a clear methodology for implementing this suggestion, including a range of distances and a method for sampling matrices. This level of detail and guidance empowers the authors to make a significant improvement to their draft, making the comment 5. Therefore, it deserves a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the absolute value operation in the definition of the Frobenius norm in line 77 is unnecessary because tensor entries are real numbers. This provides a clear and direct action for the authors to take, which is to remove the absolute value operation. The comment is explicit and concrete, leaving no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 77,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the absolute value operation in the definition of the Frobenius norm, providing a clear direction for the authors to revise their work. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the absolute value operation in the definition of the Frobenius norm is unnecessary because tensor entries are real numbers. This claim is based on a logical reasoning that the absolute value is not needed for real numbers, which is a common knowledge in mathematics. However, the comment could be strengthened by providing a reference or further explanation to support the claim. Therefore, the comment is 4, as it provides a logical basis but lacks specific references or detailed reasoning.", "helpfulness_rationale": "The review comment identifies a minor issue with the definition of the Frobenius norm, specifically pointing out that the absolute value operation is unnecessary because tensor entries are real numbers. This feedback is clear and actionable, as it provides the authors with a specific correction to make in their draft. By addressing this minor detail, the authors can ensure the accuracy and clarity of their mathematical definitions. However, the comment could be more helpful if it provided additional context or explained why this correction is important. Overall, the comment is 4 as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that only bounds in expectation are provided and asks for highprobability bounds. It also recommends using ensemble methods as performed in the experiments and suggests adding measures of robustness, such as error bars or standard deviation, to the experiments. While the comment implies that the authors should provide highprobability bounds and consider adding measures of robustness, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that only bounds in expectation are provided and asks for highprobability bounds. It also recommends using ensemble methods as performed in the experiments and suggests adding measures of robustness, such as error bars or standard deviation, to the experiments. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the experimental results or methodology sections. The comment is specific in detailing what needs to be addressed, such as providing highprobability bounds and adding measures of robustness. However, it lacks full grounding as it does not explicitly mention the sections, making it weakly grounded but specific. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that only bounds in expectation are provided and suggests that highprobability bounds would be beneficial. It also recommends using ensemble methods as performed in the experiments and suggests adding measures of robustness, such as error bars or standard deviation, to the experiments. The comment provides a logical reasoning for the suggestion, as ensemble methods are known to provide highprobability bounds, and the addition of measures like error bars or standard deviation would enhance the robustness analysis. However, the comment could be strengthened by providing specific examples or references to support the claim about ensemble methods and highprobability bounds. Overall, the claim is 4, as it provides a clear rationale but lacks detailed evidence or references. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a specific limitation in the paper, noting that only bounds in expectation are provided and suggests that highprobability bounds would be beneficial. It provides a concrete suggestion by recommending the use of ensemble methods as performed in the experiments, which could help achieve these highprobability bounds. Additionally, the comment suggests adding measures of robustness, such as error bars or standard deviation, to the experiments. This feedback is clear and actionable, offering the authors specific ways to enhance their work by addressing the identified weaknesses. However, the comment could be more helpful if it provided additional context or examples on how to implement these suggestions effectively. Overall, the comment is 4 as it provides valuable guidance for improving the draft."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point expresses concern about the lack of explicit enforcement of diversity in the model, despite the extensive motivation for diversity in the paper. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to incorporate diversity into the model or suggestions for improvements. As a result, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the title, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the discrepancy between the extensive motivation for diversity and the lack of explicit enforcement of diversity in the model. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper extensively motivates \"diversity\" but does not enforce it explicitly in the model. The reviewer expresses disappointment at the lack of diversity enforcement, suggesting that the authors\" efforts to incorporate diversity were not realized. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. Without detailed evidence or reasoning, the claim remains 3, as it provides a general critique but lacks the necessary depth to fully substantiate the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the lack of explicit enforcement of diversity in the model, despite the extensive motivation for diversity in the paper. This feedback is valuable as it highlights a potential gap between the theoretical framework and its practical implementation. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or incorporate diversity into their model. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 3, as it provides insight but lacks depth and actionable steps."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that some experiments are missing, specifically mentioning contrastive learning and adversarial learning. This provides a clear and direct action for the authors to take, which is to include these experiments in their study. The comment is explicit and concrete, as it specifies exactly what needs to be added to the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment mentions that \"some experiments are missing,\" specifically mentioning contrastive learning and adversarial learning. However, it does not specify which part of the paper these experiments should be included in, making it weakly grounded. The comment is specific in identifying the missing experiments, but without clear grounding, the authors may struggle to determine where these experiments should be integrated. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that \"some experiments are missing,\" specifically mentioning contrastive learning and adversarial learning. However, it does not provide any reasoning, examples, or references to support this claim. Without further explanation or evidence, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out that some experiments are missing, specifically mentioning contrastive learning and adversarial learning. This feedback is clear and actionable, as it provides the authors with a direct suggestion to enhance their study by including these experiments. However, the comment could be more helpful if it explained why these experiments are important or how they would contribute to the overall understanding of the research. Despite this, the feedback is 4 as it guides the authors toward a clear enhancement of their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to use DinoV2 Frechet Distances for comparisons, in addition to the widely used FID metric. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"FIDs\" and \"DinoV2 Frechet Distances,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the use of FIDs and suggests using DinoV2 Frechet Distances for comparisons, in addition to the widely used FID metric. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that FIDs have clear flaws and suggests using DinoV2 Frechet Distances for comparisons. However, it does not provide specific examples or detailed reasoning to support the claim about the flaws in FIDs. The reference to [C] is not sufficient to fully substantiate the claim, making it 3. The authors would need to investigate the referenced work to fully understand the basis of the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to consider using DinoV2 Frechet Distances for comparisons, in addition to the widely used FID metric. This feedback is specific and offers a concrete way to improve the evaluation methodology, which is particularly important in the context of image generation. By suggesting an alternative metric, the comment empowers the authors to enhance the rigor and relevance of their comparisons. However, the comment could be more helpful if it included a brief explanation of why DinoV2 Frechet Distances might be a better choice or how it addresses the flaws in FIDs. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests conducting an experiment where the image is occluded, simulating irregularities in neural/behavioral data. It provides a clear rationale for why this experiment is important, highlighting its ability to test the model\"s longrange inference capacity. The reviewer also indicates that these experiments should be included in the final version, unless the authors can provide a convincing reason otherwise. This feedback is explicit and provides concrete guidance on what the authors should do to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests conducting an experiment where the image is occluded, simulating irregularities in neural/behavioral data. It provides a clear rationale for why this experiment is important, specifically to test the model\"s longrange inference capacity. However, the comment does not explicitly mention which part of the paper this suggestion pertains to, such as a specific section or experiment. While the authors might infer that it relates to the experimental setup or results, the lack of explicit grounding makes it weakly grounded. The comment is specific in detailing what the authors should do to improve their draft, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests conducting an experiment where the image is occluded to simulate irregularities in neural/behavioral data. The reviewer provides a clear rationale for why this experiment is important, specifically to test the model\"s longrange inference capacity. However, the comment lacks specific examples or references to support the claim that this type of experiment is necessary or beneficial. While the reasoning is logical, the absence of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the paper by recommending an experiment where the image is occluded to simulate irregularities in neural/behavioral data. This suggestion is based on a logical rationale, as it would allow the authors to test the model\"s longrange inference capacity, which is an important aspect of the study. The comment also emphasizes the importance of including these experiments in the final version, unless the authors can provide a convincing reason otherwise. This feedback is clear and provides the authors with a concrete direction for enhancing their draft, making it 5. Therefore, the comment deserves a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that a statement in the abstract is unclear and suggests that it should be more highlevel, avoiding technicalities. However, it does not provide specific guidance on how to rephrase the statement or what aspects should be clarified. The action is implicit and somewhat vague, as the authors are left to infer that they need to simplify the language without detailed instructions on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the statement in the abstract, pointing out that it is unclear and suggesting that it should be more highlevel and avoid technicalities. This provides clear guidance on what needs to be addressed. Therefore, this comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point claims that a statement in the abstract is unclear and suggests that it should be more highlevel. However, the comment does not provide any specific reasoning or examples to support why the statement is unclear or how it could be improved. Without detailed explanation or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of a statement in the abstract, noting that it is unclear and should be more highlevel. It provides a clear suggestion to avoid technicalities in the abstract, which is a valuable piece of feedback for the authors. However, the comment could be more helpful if it offered specific guidance on how to rephrase the statement or what aspects to focus on for clarity. Despite this, the feedback is 4 as it directs the authors to improve the clarity and accessibility of their abstract."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests adding results in other modalities, specifically mentioning languagerelated tasks. It also implies that expected test loss might not be as meaningful for languagerelated tasks. While the comment provides a general direction for expanding the results, it lacks specific guidance on which modalities to include or how to present the results. The authors can infer that they need to expand their results to other modalities, but the comment does not provide concrete steps or details on how to implement this suggestion. Therefore, the comment is 3, as it identifies an area for improvement but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment suggests adding results in other modalities, specifically mentioning languagerelated tasks. It also implies that expected test loss might not be as meaningful for languagerelated tasks. However, the comment does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The authors can infer that it relates to the results or discussion sections, but without explicit references, it is challenging to pinpoint the exact location. The comment is specific in suggesting the inclusion of results in other modalities, particularly languagerelated tasks, and provides a rationale for why expected test loss might not be as relevant. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests adding results in other modalities, specifically mentioning languagerelated tasks. It also implies that expected test loss might not be as meaningful for languagerelated tasks. However, the comment lacks specific reasoning or references to support why these suggestions are necessary or beneficial. Without detailed justification or examples, the authors may find it challenging to understand the basis of the suggestion or how to implement it effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient evidence or explanation.", "helpfulness_rationale": "The review comment suggests expanding the results to include other modalities, particularly languagerelated tasks. It also implies that expected test loss might not be as meaningful for languagerelated tasks, suggesting that other metrics or evaluations might be more relevant. While the comment provides a direction for improvement, it lacks specific guidance on which languagerelated tasks to consider or how to present the results. Additionally, it does not offer detailed suggestions on how to incorporate these changes into the paper. Despite this, the comment identifies a potential area for expansion and improvement, making it 3 for the authors. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the motivation of the work should be further justified, specifically addressing the use of \"fewshot\" in graph link prediction. It highlights the need to explain how the proposed method effectively uses \"fewshot\" and guarantees generalizability to new tasks with 0/few training steps. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues or specific steps to take. The action is implicit and somewhat vague, as the authors are left to infer what changes are needed without detailed instructions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the motivation of the work, specifically questioning how the proposed method effectively uses \"fewshot\" and guarantees generalizability to new tasks. However, it does not specify which part of the paper discusses the motivation or where the proposed method is described, making it weakly grounded. The comment is specific in detailing what aspects of the motivation need further justification, such as the effective use of \"fewshot\" and generalizability. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the motivation of the work should be further justified, specifically regarding the use of \"fewshot\" in graph link prediction. The reviewer provides a logical reasoning by explaining that in fewshot learning, the goal is to leverage a few instances to learn a generalizable model, and the proposed method does not address how to effectively use \"fewshot\" or guarantee generalizability. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a critical area for improvement in the paper, specifically the motivation and justification of the work. It highlights the need to explain how the proposed method effectively uses \"fewshot\" and guarantees generalizability to new tasks with 0/few training steps. This feedback is clear and actionable, as it directs the authors to clarify the rationale behind their approach and its applicability to the field. However, the comment could be more helpful if it provided specific suggestions or examples on how to address these issues. Overall, the comment is 4 as it guides the authors toward enhancing the clarity and relevance of their work."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that some ablations mentioned in previous sections are hard to locate in the following contents, suggesting that the writing could be improved in this part. However, it does not provide specific guidance on how to improve the writing or which ablations are particularly difficult to locate. The action is implicit and vague, as the authors are left to infer what changes are needed without concrete instructions. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment mentions \"some ablations\" and suggests that they are hard to locate in the following contents, indicating that the author should improve the writing in this part. However, it does not specify which ablations are being referred to or where they are mentioned in the previous sections, making it difficult for the authors to pinpoint the exact areas needing improvement. The comment is weakly grounded as it does not explicitly mention a specific section or part of the paper, and it is not specific because it lacks detailed guidance on what needs to be addressed. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that some ablations mentioned in previous sections are hard to locate in the following contents. However, it does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the exact issue or how to address it. The lack of detailed explanation or references makes the claim 1, as the authors are left without clear guidance on how to improve the paper. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that some ablations mentioned in previous sections are hard to locate in the following contents. This feedback is 3 as it points out a potential problem with the organization or presentation of the ablation results. However, the comment lacks specificity and does not provide detailed guidance on how to improve the writing or where the ablations should be located. Without actionable suggestions or examples, the authors may find it challenging to address the issue effectively. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the differential privacy application is \"halfbaked\" and encourages the authors to think through it more clearly. It also recommends moving the experimental results from the appendix to the main paper. While the comment implies that the authors should improve their work, it does not provide specific guidance on how to enhance the differential privacy application or what aspects need more clarity. The action is implicit and somewhat vague, as the authors are left to infer the exact changes needed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"given2)5)\" and \"the differential privacy application,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the differential privacy application is \"halfbaked\" and encourages the authors to think through it more clearly. Additionally, it provides a suggestion to move the experimental results from the appendix to the main paper. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the differential privacy application is \"halfbaked\" and suggests that the authors should think through it more clearly. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide references to similar works or explain why the application is considered incomplete. Without such evidence or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides some helpful feedback by identifying a potential weakness in the differential privacy application, suggesting that it is \"halfbaked\" and encouraging the authors to think through it more clearly. It also highlights the novelty and interest of the online algorithm and robustness, which is a positive observation. However, the comment could be more helpful if it offered specific suggestions or examples of what aspects need further clarification or improvement in the differential privacy application. Additionally, the suggestion to move the experimental results from the appendix to the main paper is a logical one but lacks detailed guidance on how to present the results effectively. Overall, the comment provides some direction but lacks depth and specificity, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point claims that the contribution of multilingual chainofthought is incremental compared to the villa chainofthought. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how the authors might address this perceived lack of contribution or improve their work based on this feedback. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, it is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment claims that the contribution of multilingual chainofthought is incremental compared to the villa chainofthought. However, it does not specify which part of the paper this observation is based on, nor does it provide details on what aspects of the contribution are considered incremental. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the contribution are considered incremental, leaving the authors without clear guidance on how to address the issue. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the contribution of multilingual chainofthought is incremental compared to the villa chainofthought. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment claims that the contribution of multilingual chainofthought is incremental compared to the villa chainofthought. However, it does not provide any specific details or examples to support this claim, nor does it offer suggestions for improvement or alternative approaches. Without actionable feedback or constructive criticism, the authors are left without a clear understanding of how to address this perceived issue or enhance their work. Therefore, the comment is 1, as it does not provide any value to the authors in terms of improving their draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the specificity of the proposed methodology, questioning whether it is limited to bimanual manipulation or could be applied more broadly to robotic manipulation. However, it does not provide explicit guidance or suggestions on how the authors should address this concern. The comment implies that the authors should clarify the applicability of their methodology, but it lacks concrete details on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the specificity of the proposed methodology, questioning whether it is limited to bimanual manipulation or could be more broadly applicable to robotic manipulation. However, it does not specify which part of the paper this issue pertains to, such as a specific section or methodology description. Without explicit references, the authors may find it challenging to pinpoint the exact part of the paper that needs revision. The comment is specific in its critique but lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point questions the specificity of the proposed methodology, suggesting that it may not be limited to bimanual manipulation and could be more broadly applicable to robotic manipulation. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 2, as it provides some insight but requires more detailed justification to be 5.", "helpfulness_rationale": "The review comment raises a concern about the specificity of the proposed methodology, questioning whether it is limited to bimanual manipulation or could be more broadly applicable to robotic manipulation. This is a relevant point that could help the authors clarify the scope and applicability of their work. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as recommending additional experiments or modifications to the methodology to demonstrate broader applicability. While it identifies a potential area for improvement, the feedback is somewhat vague and incomplete, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential inconsistency in the advantage of the UNIFORM procedure compared to other methods, particularly in the 1shot setting. It questions the authors\" theory for why the method is not as effective in this setting. While the comment implies that the authors should provide an explanation for this inconsistency, it does not explicitly instruct them to do so. The feedback is 3 as it identifies an area for further exploration, but it lacks concrete guidance on how to address the issue. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment addresses the inconsistency in the advantage of the UNIFORM procedure compared to other methods, specifically in the 1shot setting. It mentions the tables showing this inconsistency and questions the authors\" theory for why the method is not as effective in this setting. However, the comment does not specify which tables or sections of the paper are being referred to, making it weakly grounded. The comment is specific in detailing the issue of inconsistency and the need for a theory to explain it. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the advantage of UNIFORM over other procedures is not consistent, particularly in the 1shot setting. It supports this claim by referencing the tables, which show that UNIFORM does not always offer a clear advantage. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. While it provides some evidence, the lack of detailed analysis or references makes the claim 3. The authors would need to further explore the issue to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential inconsistency in the advantage of the UNIFORM procedure compared to other methods, particularly in the 1shot setting. It questions the authors\" theory for why the method is not as effective in this setting, which is a relevant and important point for the authors to address. The comment also acknowledges that the experiments and results are welldesigned, providing a balanced feedback. However, the comment could be more helpful if it offered suggestions on how the authors might explore or address this inconsistency, such as proposing potential explanations or additional experiments. Overall, the comment is 4 as it highlights a critical area for improvement and provides some guidance, but it could be more comprehensive with additional suggestions. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the reason why information value is a stronger predictor for dialogue, referencing specific pages in the paper. It suggests that including an explanation from an existing linguistic theory would strengthen the paper. While the comment implies that the authors should explore this further, it does not explicitly instruct them to do so or provide specific guidance on how to incorporate an existing theory. The action is implicit and somewhat vague, as the authors need to infer that they should investigate existing theories and integrate them into their paper. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific pages (7 and 8) where the issue is discussed, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a question about the reason for information value being a stronger predictor for dialogue and suggests that including an explanation from an existing linguistic theory would strengthen the paper. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the reason why information value is a stronger predictor for dialogue, referencing specific pages in the paper. It suggests that including an explanation from an existing linguistic theory would strengthen the paper. However, the comment does not provide any specific references or detailed reasoning to support the claim that an existing linguistic theory could explain this phenomenon. The suggestion is 3, as it points to a potential area for improvement, but lacks the necessary evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a pertinent question about the reason for information value being a stronger predictor for dialogue, referencing specific pages in the paper. It suggests that including an explanation from an existing linguistic theory would enhance the paper\"s strength. This feedback is clear and actionable, as it directs the authors to explore existing theories that could provide a deeper understanding of the phenomenon. However, the comment could be more helpful if it offered specific examples of theories or suggested how to integrate them into the paper. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a missed opportunity in the paper to discuss the potential benefits of using AutoML approaches beyond improving raw performances. It suggests that the authors should comment on the \"hints\" that can be extracted from the found architecture and what the \"biggest takeaways\" might be. While the comment implies that the authors should address these aspects, it does not provide explicit instructions or concrete steps on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should discuss the potential benefits and takeaways of AutoML approaches. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of discussion on the potential benefits of using AutoML approaches beyond improving raw performances, specifically mentioning the extraction of \"hints\" that could be used in designing new network architectures. However, it does not specify which part of the paper this critique pertains to, such as a particular section or discussion where this aspect should be addressed. The authors can infer that it relates to the methodology or results sections, but the comment lacks explicit grounding. It is specific in detailing what the authors should discuss, namely the \"biggest takeaways\" from the found architecture, but the lack of explicit grounding makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors should discuss the potential benefits of using AutoML approaches beyond improving raw performances, specifically mentioning the extraction of \"hints\" that could be used in designing new network architectures. However, the comment lacks specific examples or references to support this claim, such as discussing existing literature or studies that have successfully applied AutoML approaches in this manner. Without detailed evidence or examples, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is classified as 2.", "helpfulness_rationale": "The review comment identifies a gap in the paper by pointing out that the authors have not discussed the potential benefits of using AutoML approaches beyond improving raw performances. It suggests that the authors should comment on the \"hints\" that can be extracted from the found architecture and what the \"biggest takeaways\" might be. This feedback is clear and actionable, as it directs the authors to expand their discussion to include the potential applications and insights gained from using AutoML approaches. However, the comment could be more helpful if it provided specific examples or suggestions on how to structure this discussion. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy in the definition of T_a(t), noting that it is used in Section 3.1 but is only defined in Section 4. This feedback is explicit and provides a clear action for the authors to take: they should define T_a(t) in Section 3.1 to ensure consistency and clarity. The comment is concrete because it specifies exactly what needs to be done to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1\" and \"Section 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out a discrepancy in the definition of T_a(t), which is used in one section but defined in another. This provides clear guidance on what needs to be addressed to ensure consistency and clarity in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about the usage and definition of T_a(t) in different sections of the paper. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that T_a(t) is used in Section 3.1 but is only defined in Section 4. This feedback is clear and actionable, as it points out a potential inconsistency in the paper that could lead to confusion for readers. By highlighting this issue, the comment provides the authors with a direct suggestion to address the problem by defining T_a(t) in the appropriate section. This feedback is valuable as it helps the authors improve the clarity and consistency of their work. However, it could be more helpful if it provided additional context or suggested how the definition might impact the paper\"s overall structure or logic. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the empirical analysis in Figure 3, specifically questioning the adjustments to the amplitudes of the input series and forecasting target based on the Frequency Stability score and their impact on model prediction accuracy. The reviewer also notes the large spacing between Equations (9) and (10) and the preceding text. While the comment identifies specific areas needing clarification, it does not provide explicit instructions on how the authors should address these issues. The authors are left to infer that they need to provide additional explanations and potentially revise the formatting of the equations. However, the lack of concrete guidance on how to improve the clarity or formatting makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3\" and \"Equations (9) and (10),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the confusion regarding the empirical analysis and the adjustments to the amplitudes, as well as the large spacing between equations. The comment provides clear guidance on what needs to be clarified or improved, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises concerns about the empirical analysis in Figure 3, specifically questioning the adjustments to the amplitudes of the input series and forecasting target based on the Frequency Stability score. The reviewer also notes the large spacing between Equations (9) and (10) and the preceding text. While the comment identifies areas of confusion, it lacks specific examples or detailed reasoning to support the claim that the adjustments are confusing or ineffective. This makes the claim 3, as the authors would need to provide additional context or explanation to fully understand and address the concerns. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies specific issues with the empirical analysis in Figure 3, questioning the adjustments to the amplitudes of the input series and forecasting target based on the Frequency Stability score. It also points out the large spacing between Equations (9) and (10) and the preceding text. While the comment highlights areas that need clarification, it does not provide detailed guidance or suggestions on how the authors might address these issues. The feedback is 3 as it directs the authors to specific areas that require further explanation, but it lacks actionable advice or examples to improve the draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the recent related work CoCoOp should be compared in the experiments, even though it is a CVPR\"22 work that was published after the NeurIPS deadline. The reviewer provides a clear and direct action for the authors to take, which is to include a comparison with CoCoOp in their experiments. This feedback is specific and provides a concrete step for the authors to follow, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the recent related work \"CoCoOp\" and the need to compare it in the experiments. This allows the authors to accurately identify the part of the paper being addressed, specifically the experimental section. The comment is also specific because it clearly specifies what needs to be addressed, which is the inclusion of a comparison with CoCoOp in the experiments. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the recent related work CoCoOp should be compared in the experiments, even though it is a CVPR\"22 work that was published after the NeurIPS deadline. The reviewer provides a logical reasoning by stating that CoCoOp is an extended version of CoOp, which is relevant to the paper. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened by providing specific details or references about the similarities or differences between CoCoOp and the work being evaluated, which would further support the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific omission in the paper\"s experimental comparison, noting that the recent related work CoCoOp should be included despite being published after the NeurIPS deadline. This feedback is clear and actionable, as it provides a direct suggestion for the authors to enhance the comprehensiveness of their experimental evaluation. By addressing this point, the authors can ensure their work is more robust and complete, aligning with best practices in the field. However, the comment could be more helpful if it provided additional context or rationale for why CoCoOp is relevant or how its inclusion would impact the paper\"s conclusions. Overall, the comment is 4, as it directs the authors to a specific area for improvement, but it could be more comprehensive with further elaboration."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that Figure 1 could be improved by showing the processing pipeline, including prompt generation and manual check, demonstration selection with ground truth scores, and automatic scoring. It also mentions the use of model training to optimize the selection modules. While the comment implies that the authors should make these changes to improve the figure, it does not provide explicit instructions on how to implement these suggestions. The action is implicit and somewhat vague, as the authors need to infer the specific changes needed and how to execute them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be improved, suggesting that the figure could be drawn better to show the processing pipeline, including prompt generation and manual check, demonstration selection with ground truth scores, and automatic scoring, along with showing where model training is being used to optimize the selection modules. This level of detail provides clear guidance on what needs to be addressed in the figure. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Figure 1 could be improved by showing the processing pipeline, including prompt generation and manual check, demonstration selection with ground truth scores, and automatic scoring. However, the comment does not provide any specific reasoning or evidence to support why these changes would improve the figure or the paper. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion or how to implement it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that Figure 1 could be improved by showing the processing pipeline, including prompt generation and manual check, demonstration selection with ground truth scores, and automatic scoring. It also mentions the use of model training to optimize the selection modules. While the comment identifies specific areas for improvement in the figure, it lacks detailed guidance on how to implement these suggestions or what specific changes should be made. The feedback is 3 as it points out a potential enhancement, but it could be more actionable with additional details or examples. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that abbreviations like \"MoCo\" should not appear in the section header, as a reader might not know what they mean. This provides a clear and direct action for the authors to take, which is to avoid using abbreviations in section headers. The comment is explicit and provides concrete guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section number (136), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with abbreviations like \"MoCo\" appearing in the section header, explaining that a reader might not know what they mean. This provides clear guidance on what needs to be addressed to improve the draft. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual statement about the use of abbreviations in section headers, suggesting that they should not be used because a reader might not know what they mean. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the use of abbreviations like \"MoCo\" in the section header, suggesting that it might not be clear to readers who are unfamiliar with the abbreviations. This feedback is clear and actionable, as it provides a direct suggestion to avoid using abbreviations in section headers to improve clarity for readers. However, the comment could be more helpful if it offered alternative ways to introduce these abbreviations or provided examples of how to present them in a more readerfriendly manner. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point critiques the novelty and incremental nature of the paper, suggesting that the improvements on different datasets are trivial and that the topic has been extensively explored in previous works. However, it does not provide any explicit or implicit actions for the authors to take to address these concerns. There is no guidance on how to enhance the novelty or originality of the work, nor are there suggestions for how to differentiate it from existing literature. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the novelty and incremental nature of the paper, specifically mentioning that the improvements on different datasets are trivial and that the topic has been extensively explored in previous works. However, it does not specify which parts of the paper are being addressed, such as which datasets are discussed or which previous works are being referenced. This lack of explicit references makes it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its critique of the novelty and incremental nature of the work but lacks grounding, as it does not clearly identify the parts of the paper being discussed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the improvements on different datasets are trivial and that the novelty of the paper is limited, suggesting that the topic has been extensively explored in previous works. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or references to previous works, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment critiques the novelty and incremental nature of the paper, suggesting that the improvements on different datasets are trivial and that the topic has been extensively explored in previous works. While it identifies a potential weakness in the paper, it lacks specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. Without actionable feedback or detailed advice, the comment provides limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the improvements over baselines are marginal and within the error bar range, questioning the significance of the performance differences. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue of marginal improvements or how to improve the method\"s performance. Without actionable suggestions or a clear direction for improvement, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the performance of the method compared to baselines, specifically mentioning the error range and the claim of better performance. However, it does not specify which part of the paper discusses these results, making it weakly grounded. The comment is specific in detailing the issue with the marginal improvements and the high error range, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the improvements over baselines are marginal and within the error bar range, questioning the significance of the performance differences. However, the comment does not provide specific examples or detailed analysis to support this claim, such as comparing the error ranges or providing data to substantiate the assertion. Without such evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2, as it lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment points out a potential issue with the paper\"s claims regarding the performance of the method compared to baselines. It highlights that the improvements are marginal and within the error bar range, questioning the significance of the performance differences. This feedback is 3 as it prompts the authors to reconsider their claims and potentially provide more detailed analysis or evidence to support their assertions. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as recommending additional experiments or analyses to clarify the performance differences. Therefore, while it identifies a potential weakness, it does not provide comprehensive or actionable feedback, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of clarity regarding how to make the new proposed evaluation set more diverse and representative compared to the previous method. It also questions the selection of representative images. While the comment identifies a specific area needing clarification, it does not provide explicit guidance or suggestions on how the authors should address these issues. The action is implicit and somewhat vague, as the authors are left to infer what steps to take to improve the clarity and diversity of the evaluation set. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the clarity of how the new proposed evaluation set is more diverse and representative compared to the previous method. It also questions the selection of representative images. However, it does not specify which part of the paper discusses the evaluation set or the selection of representative images, making it weakly grounded. The comment is specific in detailing what is unclear, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact parts needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the clarity of how the new proposed evaluation set is more diverse and representative compared to the previous method, and how representative images are selected. However, the comment does not provide any specific reasoning, examples, or references to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the diversity and representativeness of the new proposed evaluation set compared to the previous method. It questions how the new set is more diverse and representative and how representative images are selected. This feedback is clear and actionable, as it prompts the authors to clarify and justify the selection process for the evaluation set. However, the comment could be more helpful if it provided suggestions on how to enhance the diversity or offered examples of how to select representative images. Overall, the comment is 4 as it directs the authors to a critical area needing clarification and improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to include a background section on the basic RL framework, specifically mentioning elements like the MDP, trajectories, and policy. It also suggests providing a brief overview of the original DPO algorithm to clarify the modifications proposed in the methods section. These instructions are clear and concrete, giving the authors specific actions to take to improve their draft. The feedback is 5 as it provides detailed guidance on what needs to be added to enhance the clarity and comprehensiveness of the paper.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for a background section on the basic RL framework, including elements like the MDP, trajectories, and policy, to clarify the RL context. It also specifies the need for a brief overview of the original DPO algorithm to distinguish modifications in the methods section. This provides clear guidance on what needs to be addressed, making it easy for the authors to identify the parts of the paper that require revision. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper lacks a background section on the basic RL framework, including elements like the MDP, trajectories, and policy, which would help clarify the RL context. It also recommends providing a brief overview of the original DPO algorithm to distinguish modifications in the methods section. This feedback is logical and provides a clear rationale for why these additions would improve the paper\"s clarity. However, it does not include specific references or examples to fully substantiate the claim. Therefore, the comment is 4, as it provides a strong basis for the suggestion but lacks detailed evidence or references to fully support the claim.", "helpfulness_rationale": "The review comment is 5 as it identifies specific areas where the paper lacks clarity and provides actionable suggestions for improvement. By recommending the inclusion of a background section on the basic RL framework, the reviewer highlights the importance of setting the context for the subsequent sections. Additionally, the comment suggests providing a brief overview of the original DPO algorithm to distinguish the modifications proposed in the methods section. This feedback is clear and constructive, offering the authors a direct path to enhance the comprehensibility and coherence of their draft. Therefore, the comment is rated as 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the relevance of the term \"interpretable\" in the context of the work described by DoshiVelez and Kim. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on whether the authors should address this question, clarify the relevance, or make any changes to their draft. Without actionable suggestions or instructions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 54,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the relevance of the term \"interpretable\" in the context of the work of DoshiVelez and Kim. This provides clear guidance on what aspect of the paper needs clarification or further discussion. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the relevance of the term \"interpretable\" in the context of the work described by DoshiVelez and Kim. It does not contain an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the relevance of the term \"interpretable\" in the context of the work described by DoshiVelez and Kim. While it points out a potential area for clarification, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve their draft. The comment lacks depth and actionable feedback, leaving the authors with only a vague indication of a potential area for improvement. Therefore, it is 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a limitation in the experiments, noting that they are restricted to MNIST and a single realworld dataset. However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or expand their experimental scope. Without guidance on potential additional datasets to include or alternative approaches to consider, the authors are left without a clear path for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a limitation in the experiments, noting that they are restricted to MNIST and a single realworld dataset. However, it does not specify which part of the paper this limitation is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the experiments are limited or how this limitation affects the paper\"s conclusions. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the experiments are limited to MNIST and a single realworld dataset. However, it does not provide any supporting evidence, reasoning, or examples to justify why this limitation is significant or how it affects the paper\"s conclusions. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment points out a limitation in the experiments, noting that they are restricted to MNIST and a single realworld dataset. While this observation is relevant, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this limitation or expand their experimental scope. Without actionable feedback or specific recommendations, the authors are left without a clear path for improvement. Therefore, the comment is 2, as it identifies a potential issue but does not offer meaningful guidance for addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the S2D structure, specifically why the number of parameters does not change despite an increase in depth. The reviewer acknowledges that the efficiency could be improved but suggests that more details are needed regarding the parameters. While the comment implies that the authors should provide additional information on the parameters, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"S2D structure,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue regarding the number of parameters not changing despite an increase in depth, and it suggests that more details are needed on the parameters. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the S2D structure, specifically why the number of parameters does not change despite an increase in depth. The reviewer acknowledges that the efficiency could be improved but suggests that more details are needed regarding the parameters. While the comment provides a logical reasoning for the question, it lacks specific examples or references to support the claim about the parameters. This makes the claim 3, as it provides a basis for the question but requires further elaboration or evidence to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific issue with the S2D structure, questioning why the number of parameters does not change despite an increase in depth. It acknowledges that the efficiency could be improved but suggests that more details are needed regarding the parameters. This feedback is 3 as it points out a potential area for clarification or improvement in the paper. However, it lacks specific suggestions or guidance on how the authors might address this issue, such as proposing alternative approaches or providing examples of how to present the parameter details. Therefore, while it highlights an area for improvement, it does not fully support the authors in making those improvements, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the similarity between the proposed method and the approach in reference [10], suggesting that the method in [10] could also be equipped with scoring causal predictions and interventional data. The comment implies that the authors should clarify why [10] cannot use these side information, but it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the similarity between the proposed method and the approach in reference [10], suggesting that the method in [10] could also be equipped with scoring causal predictions and interventional data. However, it does not specify which part of the paper this comparison is based on, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its questioning of why [10] cannot use these side information, but it lacks grounding as it does not explicitly mention a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the similarity between the proposed method and the approach in reference [10], suggesting that the method in [10] could also be equipped with scoring causal predictions and interventional data. The comment implies that the authors should clarify why [10] cannot use these side information, but it does not provide specific evidence or reasoning to support this claim. The lack of detailed justification or references makes it difficult for the authors to understand the basis of the comparison or the need for clarification. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment raises a question about the similarity between the proposed method and the approach in reference [10], suggesting that the method in [10] could also be equipped with scoring causal predictions and interventional data. It implies that the authors should clarify why [10] cannot use these side information, which is a relevant point for consideration. However, the comment lacks specificity and does not provide detailed guidance or suggestions on how the authors might address this issue or improve their work. While it identifies a potential area for clarification, it does not offer actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the proposed method, noting that it lacks a sparsity constraint in the number of factors used by subsequent tasks. This could lead to an increase in the number of factors and computation with more tasks. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or implement a sparsity constraint. The action is implicit and somewhat vague, as the authors are left to infer that they should consider adding a sparsity constraint but are not given specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the proposed method, namely the lack of a sparsity constraint in the number of factors used by subsequent tasks. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the model\"s lack of sparsity constraint and its potential impact on computation with more tasks. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method lacks a sparsity constraint in the number of factors used by subsequent tasks, which could lead to an increase in the number of factors and computation with more tasks. This claim is 3 as it provides a logical reasoning for the potential issue, but it lacks specific examples or references to support the assertion. The authors would need to consider the implications of this lack of sparsity constraint and potentially address it in their work. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific weakness in the proposed method, namely the lack of a sparsity constraint in the number of factors used by subsequent tasks. This observation is relevant and could impact the model\"s efficiency and computational requirements. However, the comment does not provide actionable suggestions or guidance on how the authors might address this issue or implement a sparsity constraint. While it highlights an important area for improvement, the lack of detailed feedback limits its usefulness to the authors. Therefore, the comment is 3, as it provides insight but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide a more detailed explanation of why the GPC (benchmark) is performing better than BPC (their method). It implies that the authors should reiterate that the better performance of GPC is due to the bandit feedback and not using information about the form of the cost function. While the comment explicitly states the need for additional explanation, it does not provide specific guidance on how to present this information or what aspects to focus on. The action is explicit but somewhat vague, as the authors know they need to provide more context but may not be entirely sure of the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"presentation of the simulation study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the presentation, namely the lack of commentary on why the GPC (benchmark) is performing better than BPC (the authors\" method). The comment provides a suggestion for improvement by recommending that the authors reiterate the reason for the better performance, which is due to the bandit feedback and not using information about the form of the cost function. This level of detail provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the presentation of the simulation study does not provide sufficient explanation for why the GPC (benchmark) is performing better than BPC (the authors\" method). The reviewer suggests that the authors should reiterate that the better performance is due to the bandit feedback and not using information about the form of the cost function. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion. This makes the claim 3, as the authors would need to provide additional evidence or explanation to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of the simulation study, noting that the authors do not provide sufficient explanation for why the GPC (benchmark) is performing better than BPC (their method). It suggests that the authors should reiterate that the better performance is due to the bandit feedback and not using information about the form of the cost function. This feedback is clear and actionable, as it directs the authors to clarify an important aspect of their results. By addressing this point, the authors can enhance the transparency and comprehensibility of their work. However, the comment could be more helpful if it provided additional guidance on how to present this information or suggested specific ways to reiterate the reasoning. Overall, the comment is 4, as it effectively points out a weakness and offers a clear path for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should quantify and clarify the claim about ReLU not working well in deep or convolutional networks. It provides a specific example, the AlexNet paper, which used ReLUs and was considered deep and convolutional at the time. This feedback is explicit and provides a concrete suggestion for how the authors can address the issue, making it 5. The authors know exactly what needs to be done to improve their draft, which is to quantify and clarify the claim by referencing the AlexNet paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests quantifying and clarifying the claim about ReLU not working well in deep or convolutional networks. It provides a specific example, the AlexNet paper, which used ReLUs and was considered deep and convolutional at the time. This provides a clear direction for the authors to address the issue by referencing the AlexNet paper. However, the comment does not specify which part of the paper this claim is made in, making it weakly grounded. The suggestion is specific, as it provides a concrete example and a direction for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the claim about ReLU not working well in deep or convolutional networks should be quantified and clarified. The reviewer provides a specific example, the AlexNet paper, which used ReLUs and was considered deep and convolutional at the time. This example supports the claim by demonstrating that ReLUs were used in a deep and convolutional network, contradicting the initial claim. The reference to the AlexNet paper provides a clear and logical basis for the suggestion, making the claim 4. However, the comment could be strengthened by providing more detailed reasoning or additional examples to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment suggests that the claim about ReLU not working well in deep or convolutional networks should be quantified and clarified. It provides a specific example, the AlexNet paper, which used ReLUs and was considered deep and convolutional at the time. This feedback is actionable as it directs the authors to provide evidence or examples to support their claim, which could enhance the clarity and credibility of their argument. However, the comment could be more helpful if it offered additional suggestions on how to quantify or clarify the claim, such as specific metrics or analyses to consider. Overall, the comment is 4 as it provides a clear direction for improvement but could be more comprehensive with further guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the evaluation needs experiments on distributed deployment and a larger model. This provides clear and direct guidance on what the authors need to do to improve their draft. The action is explicit and concrete, as it specifies exactly what needs to be added to the evaluation. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the evaluation needs experiments on distributed deployment and a larger model. However, it does not specify which part of the paper this feedback pertains to, such as the methodology or results sections. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing improvement. While the comment is specific in suggesting the need for additional experiments, it is 1 because it does not indicate where these suggestions should be implemented. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the evaluation needs experiments on distributed deployment and a larger model. However, it does not provide any supporting evidence, reasoning, or references to justify why these experiments are necessary or how they would improve the evaluation. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the evaluation section of the paper. It suggests that the evaluation should include experiments on distributed deployment and a larger model. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their evaluation by considering additional scenarios and model sizes. However, the comment could be more helpful if it explained why these experiments are important or how they might impact the paper\"s conclusions. Overall, the feedback is 4 as it guides the authors toward a specific improvement, but it could be more comprehensive with additional context or rationale."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should provide a brief discussion on why rooted patterns are important and how they choose the roots. It also implies that if nonrooted patterns are sufficient, the discussion should be moved to the supplementary material. This feedback is clear and provides a direct action for the authors to take, making it 5. The authors know exactly what needs to be done to address the reviewer\"s concern, which is to either include a discussion on the importance of rooted patterns or move the discussion to the supplementary material if nonrooted patterns are sufficient. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"rooted patterns,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of elaboration on why rooted patterns are important and how they choose the roots. Additionally, it suggests that a brief discussion is expected or that the discussion should be moved to the supplementary material if nonrooted patterns are sufficient. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide a brief discussion on the importance of rooted patterns and how they choose the roots. It implies that this discussion is necessary for the sake of exposition. However, the comment does not provide specific reasoning or evidence to support why this discussion is crucial or how it would benefit the paper. Without additional context or examples, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 2.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks clarity and provides a clear suggestion for improvement. It points out that the authors define rooted patterns but do not explain why they are important or how they choose the roots. The comment suggests that a brief discussion on these points is expected or that the discussion could be moved to the supplementary material if nonrooted patterns are sufficient. This feedback is actionable and provides a clear direction for the authors to enhance the clarity and comprehensiveness of their work. However, it could be more helpful if it included specific examples or further guidance on how to structure the discussion. Overall, the comment is 4, as it effectively guides the authors toward improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors provide more explanations regarding the consistency between training and inference, which is implied by the smoothness of neural models. While the comment explicitly states that more explanations are needed, it does not specify what aspects of the explanation should be expanded upon or how to present them. The action is explicit but somewhat vague, as the authors know they need to provide more explanations but may not be entirely sure of the specific details or format of those explanations. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (9597 and 308310) where the paper addresses the consistency between training and inference, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that more explanations are needed on this topic. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper addresses the consistency between training and inference, stating that it can be easily satisfied due to the smoothness of neural models. The reviewer suggests that more explanations are needed on this topic. However, the comment does not provide specific examples or detailed reasoning to support the claim that the explanations are insufficient. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion for more explanations. Therefore, the claim is 3, as it lacks detailed justification or examples to fully substantiate the need for additional explanations.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by suggesting that more explanations are needed regarding the consistency between training and inference, which is attributed to the smoothness of neural models. This feedback is clear and actionable, as it directs the authors to provide additional details or explanations to enhance the clarity and comprehensiveness of their work. However, the comment could be more helpful if it offered specific suggestions on what aspects of the explanation should be expanded or how to present them. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the introduction of two hyperparameters, k and \u03b7, which require finetuning. It suggests that this finetuning depends on the availability of the environment or a good OPE method. However, the comment does not provide any explicit guidance or suggestions on how the authors should address this issue. It lacks concrete details on what actions the authors should take to resolve the problem or improve the draft. As a result, the authors are left without a clear understanding of how to proceed, making the comment 1.", "grounding_specificity_rationale": "The comment addresses the introduction of two hyperparameters, k and \u03b7, and their dependence on finetuning, which is contingent on the availability of the environment or a good OPE method. However, it does not specify which part of the paper discusses these hyperparameters or where the issue of finetuning is mentioned. This lack of explicit reference to a specific section or part of the paper makes it weakly grounded. The comment is specific in detailing the issue with the hyperparameters and their dependence on finetuning, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point claims that the introduction of two hyperparameters, k and \u03b7, requires finetuning, which depends on the availability of the environment or a good OPE method. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the introduction of two hyperparameters, k and \u03b7, which require finetuning. It highlights the dependency on the availability of the environment or a good OPE method, suggesting that this could be a limitation. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or mitigate its impact. Without actionable advice or further elaboration, the feedback is 3, as it points out a potential concern but does not offer a clear path for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the necessity of the base layer GNN encoding in the proposed method and suggests conducting an ablation study to determine its importance. While the comment implies that the authors should conduct an ablation study, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to conduct the ablation study or what aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the necessity of the base layer GNN encoding in the proposed method and suggests conducting an ablation study to determine its importance. However, it does not specify which part of the paper discusses this encoding, making it weakly grounded. The comment is specific in suggesting an ablation study to address the issue, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the necessity of the base layer GNN encoding in the proposed method and suggests conducting an ablation study to determine its importance. However, the comment does not provide any specific reasoning, examples, or references to support why the encoding is unclear or how an ablation study would be beneficial. Without additional context or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the necessity of the base layer GNN encoding in the proposed method, suggesting that an ablation study would be helpful to determine its importance. This feedback is 3 as it identifies a potential area for improvement and provides a specific suggestion for further analysis. However, the comment lacks depth and does not offer detailed guidance on how to conduct the ablation study or what specific aspects to focus on. While it points the authors in the right direction, it could be more helpful with additional details or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should add an explicit discussion on the upper bounds of counting and potentially elaborate on empirical runtimes related to the computational complexity of counting homomorphisms. This feedback provides a clear and concrete action for the authors to take, ensuring they know exactly what needs to be addressed in their draft. The comment is explicit and provides specific guidance on how to improve the paper, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L 145\" and the specific topic of \"computational complexity of counting homomorphisms,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the need for an explicit discussion on upper bounds of counting and potential elaboration on empirical runtimes. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors do not adequately discuss the computational complexity of counting homomorphisms and suggests that they should add an explicit discussion on upper bounds and potentially elaborate on empirical runtimes. The comment provides a specific example from the paper (\"L 145\") to support the claim, which helps justify the need for additional discussion. However, it lacks detailed reasoning or references to specific methods or studies that could further substantiate the claim. While the comment provides a clear direction for improvement, it could be strengthened with more detailed evidence or examples. Therefore, the comment is 4, as it provides a solid basis for the claim but could benefit from additional support.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks depth, namely the discussion on the computational complexity of counting homomorphisms. It points out that the authors make only brief statements about this topic and suggests that the paper would benefit from explicitly adding upper bounds and potentially elaborating on empirical runtimes. This feedback is clear and actionable, providing the authors with a specific direction for improvement that could enhance the comprehensiveness and depth of their work. However, the comment could be more helpful if it offered examples or references to guide the authors in elaborating on the topic. Overall, the comment is 4 as it effectively directs the authors to a critical area for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point consists of three parts: a correction of a typographical error, a correction of a punctuation error, and a question about the convergence of the baseline MCL with deep learning. The first two parts are explicit and provide clear actions for the authors to take, making them 5. The third part is a question that seeks clarification, which is also explicit and actionable. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (108 and 115) where corrections are needed, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the corrections required, such as changing \"f\" to \"g\" and removing an extra period. Additionally, it raises a question about the convergence of the baseline MCL with deep learning, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of three parts: a correction of a typographical error, a correction of a punctuation error, and a question about the convergence of the baseline MCL with deep learning. The first two parts are factual corrections that do not require verification. The third part is a question seeking clarification, which is not a claim and does not require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by identifying typographical errors and punctuation mistakes in the manuscript. It also raises a question about the convergence of the baseline MCL with deep learning, which is a relevant concern for the authors to address. This feedback is clear and direct, offering the authors concrete steps to improve the accuracy and clarity of their draft. However, the comment could be more helpful if it included suggestions on how to ensure convergence or provided examples of how to address this issue. Overall, the comment is 4 as it effectively guides the authors in improving their draft, but it could be more comprehensive with additional guidance or examples."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should include a study of inference time, particularly comparing it to previous topdown and bottomup pose estimation methods. While the comment implies that this is an important aspect to consider, it does not explicitly instruct the authors to conduct this study or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to include a study of inference time but are not given detailed instructions on how to implement it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should include a study of inference time, particularly comparing it to previous topdown and bottomup pose estimation methods. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in suggesting a comparison with previous methods, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should include a study of inference time, particularly comparing it to previous topdown and bottomup pose estimation methods. The claim is based on the premise that the method is direct and does not require detection or keypoint grouping, implying that it should be faster. However, the comment lacks specific examples or references to previous methods, making it difficult for the authors to fully understand the basis of the suggestion. The lack of detailed justification or evidence makes the claim 3, as it provides a general direction but requires more detailed support to be fully actionable.", "helpfulness_rationale": "The review comment suggests that the paper should include a study of inference time, particularly comparing it to previous topdown and bottomup pose estimation methods. This feedback is 3 as it identifies a potential area for improvement by highlighting the importance of evaluating inference speed. However, the comment lacks specific guidance on how to conduct this study or what metrics to use, which would make it more actionable. Additionally, it does not provide any context or explanation for why this comparison is relevant or how it might impact the paper\"s contribution. Therefore, while the comment points out a relevant area for improvement, it could be more helpful with additional details and guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment raises two specific questions about the proof of Theorem A.3. First, it questions how the input x has two indices, given that it is a vector and not a matrix. Second, it points out that the summation should be over k, not d, and that the expression should be \u2211 k ( W k ( 2 ) ) 2 = 1 / d , not d. These questions are explicit and provide clear guidance on what needs to be clarified or corrected in the proof. The authors know exactly what aspects of the proof need attention, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem A.3 proof,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the input x having two indices, which is not consistent with it being a vector, and it corrects the summation expression. This provides clear guidance on what needs to be clarified or corrected in the proof. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions and clarifications about the proof of Theorem A.3, specifically questioning the indexing of the input x and the summation expression. It does not contain subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises specific questions about the proof of Theorem A.3, questioning the indexing of the input x and the summation expression. This feedback is clear and actionable, as it directs the authors to clarify these aspects of their proof. By addressing these questions, the authors can improve the clarity and accuracy of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to resolve these issues. Overall, the comment is 4, as it effectively guides the authors toward improving their draft, but it could be more comprehensive with further explanation or examples."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the use of words like \"somewhat\" and \"good generative ability\" in the description, particularly in relation to the results in sections 4.3 and 4.4. It questions the effectiveness of beam search, given that only 77% of the result lists contain the ground truth logical forms. The reviewer also asks how the pluggedin entities/relationships would be verified if no ground truth is available. While the comment highlights potential issues and raises questions, it does not provide explicit or concrete actions for the authors to take. The authors can infer that they need to address these concerns, but the comment lacks specific guidance on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions sections 4.3 and 4.4, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the concerns about the use of words like \"somewhat\" and \"good generative ability\" in the description, and it questions the effectiveness of beam search and the verification of entities/relationships when no ground truth is available. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises concerns about the use of words like \"somewhat\" and \"good generative ability\" in the description, particularly in relation to the results in sections 4.3 and 4.4. It questions the effectiveness of beam search, given that only 77% of the result lists contain the ground truth logical forms. The reviewer also asks how the pluggedin entities/relationships would be verified if no ground truth is available. While the comment raises valid questions and points out potential issues, it lacks specific evidence or references to support the claim. The authors would need to conduct further analysis to address these concerns, making the comment 3. Therefore, the comment is classified as 3.", "helpfulness_rationale": "The review comment raises a concern about the use of words like \"somewhat\" and \"good generative ability\" in the description, particularly in relation to the results in sections 4.3 and 4.4. It questions the effectiveness of beam search, given that only 77% of the result lists contain the ground truth logical forms. The reviewer also asks how the pluggedin entities/relationships would be verified if no ground truth is available. This feedback is 3 as it identifies a potential issue with the description of the results and prompts the authors to consider the reliability of their findings. However, the comment lacks specific suggestions or guidance on how to address these concerns, such as recommending alternative methods or analyses. Therefore, it is rated as 3, as it provides some insight but does not fully support the authors in improving their draft."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges that the performance of FedPCL is sensitive to the selection of pretrained models, limiting its applicability to wider areas. It notes that the authors have addressed this limitation by developing a lightweight federated learning framework and integrating pretrained models to extract prototypes for federated aggregation. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might further improve the framework or address the sensitivity to pretrained models. Without actionable suggestions or specific directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of performance sensitivity to pretrained models, which is a critical aspect of the paper. The comment acknowledges the authors\" efforts to address this limitation by developing a lightweight framework and integrating pretrained models for federated aggregation. Overall, the comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point acknowledges that the performance of FedPCL is sensitive to the selection of pretrained models, limiting its applicability to wider areas. It supports this claim by referencing Table 4, which shows the model accuracy for different pretrained models. The comment also notes that the authors have addressed this limitation by developing a lightweight federated learning framework and integrating pretrained models to extract prototypes for federated aggregation. This provides a logical and factual basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed analysis or examples of how the sensitivity affects the framework\"s applicability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment acknowledges the sensitivity of the FedPCL performance to the selection of pretrained models, which limits its applicability to wider areas. It recognizes the authors\" efforts to address this limitation by developing a lightweight federated learning framework and integrating pretrained models to extract prototypes for federated aggregation. The comment provides a clear understanding of the paper\"s strengths and limitations, offering a constructive perspective on the work. However, it lacks specific suggestions or guidance on how the authors might further improve the framework or address the sensitivity issue. While it highlights an important aspect of the paper, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that it would be interesting to include not only the retrieved and final attentions but also the tentative attention maps in the qualitative figures. While the comment implies that the authors should include these additional attention maps, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to add these maps but are not given specific guidance on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including additional attention maps in the qualitative figures, specifically mentioning \"the retrieved and final attentions\" and \"the tentative attention maps.\" However, it does not specify which figures or sections of the paper these maps should be included in, making it weakly grounded. The comment is specific in detailing what additional information should be included, such as the tentative attention maps. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it would be interesting to include not only the retrieved and final attentions but also the tentative attention maps in the qualitative figures. However, the comment does not provide any reasoning or evidence to support why this would be beneficial or how it would enhance the paper. Without additional context or justification, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that it would be interesting to include not only the retrieved and final attentions but also the tentative attention maps in the qualitative figures. This feedback provides a specific and actionable suggestion for enhancing the paper by offering additional visualizations that could provide valuable insights into the model\"s attention mechanisms. However, the comment could be more helpful if it explained why these additional maps would be beneficial or how they might contribute to the understanding of the model\"s behavior. Despite this, the suggestion is clear and actionable, making the comment 4. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point provides several suggestions for improving the organization and clarity of the paper. It recommends separating the description of the main contributions into a dedicated section, which would help readers understand the significance of the two types of attention introduced for deep VAEs. Additionally, it suggests referencing normalization and feature scaling techniques in a separate section, which could provide more context and clarity. However, the comment does not specify how these suggestions should be implemented or provide concrete steps for the authors to follow. While the actions are explicit, they are somewhat vague in terms of execution, making the comment 3.", "grounding_specificity_rationale": "The comment provides specific suggestions for improving the organization and clarity of the paper. It recommends separating the description of the main contributions into a dedicated section and suggests referencing normalization and feature scaling techniques in a separate section. However, it does not explicitly mention which sections these suggestions pertain to, making it weakly grounded. The authors can infer that it relates to sections 2.3 and 2.4, but this inference is not as direct as it could be. The comment is specific in detailing what needs to be addressed, such as the scattering of the layerwise attention mechanism description and the need for a separate section on normalization and feature scaling. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of minor suggestions for improving the organization and clarity of the paper. It does not contain any subjective claims, opinions, or judgments that require verification. It is purely descriptive and does not present any claims that need to be substantiated. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides several specific suggestions for improving the organization and clarity of the paper. It recommends separating the description of the main contributions into a dedicated section, which would help readers understand the significance of the two types of attention introduced for deep VAEs. Additionally, it suggests referencing normalization and feature scaling techniques in a separate section, which could provide more context and clarity. These suggestions are clear and actionable, offering the authors concrete steps to enhance the structure and readability of their draft. However, the comment could be more helpful if it included additional details or examples on how to implement these suggestions effectively. Overall, the feedback is 4 as it guides the authors toward improving the organization and clarity of their paper."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review comment indicates a potential issue with Figure 5, either suggesting that the reviewer does not understand it or that the labels are incorrect. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue, such as clarifying the labels or explaining the figure\"s content. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions \"Figure 5,\" which provides full grounding as it allows the authors to accurately identify the part of the paper being addressed. However, the comment lacks specificity because it does not explain what is unclear or what is wrong with the labels. It does not provide any guidance on how to address the issue or what needs to be clarified. Therefore, the comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point consists of a statement questioning the understanding of Figure 5 or the accuracy of its labels. It does not express an opinion, judgment, or suggestion that requires verification. It is purely descriptive and factual, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a concern about either the understanding of Figure 5 or the accuracy of its labels. However, it lacks specificity and does not provide any guidance or suggestions on how to address the issue. Without actionable feedback or detailed explanation, the authors are left without a clear understanding of what needs to be clarified or corrected. This makes the comment 2, as it identifies a potential problem but does not offer any direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should include supervised baselines in their experiments, particularly for datasets with a scale of ~100k images. It provides a rationale for why this is important, noting that full annotation is likely available for such datasets and that including supervised baselines can provide an informative comparison. The comment is clear and provides concrete guidance on what the authors should do to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the paper should include supervised baselines, particularly for datasets with a scale of ~100k images. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. This lack of explicit reference makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the inclusion of supervised baselines, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the paper should include supervised baselines, particularly for datasets with a scale of ~100k images. The reviewer provides a logical reasoning by stating that full annotation is likely available for such datasets and that including supervised baselines would provide an informative comparison. This reasoning is clear and provides a solid basis for the claim, making it 4. However, the comment could be strengthened by referencing specific examples or studies that support the need for supervised baselines in this context. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of supervised baselines, particularly for datasets with a scale of ~100k images. It provides a rationale for why this is important, noting that full annotation is likely available for such datasets and that including supervised baselines would offer an informative comparison to selfsupervised methods. This feedback is clear and actionable, as it directly suggests a specific improvement that the authors can make to enhance the comprehensiveness and validity of their experiments. However, the comment could be more helpful if it provided examples of relevant supervised baselines or suggested how to incorporate them into the study. Overall, the comment is 4, as it effectively guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and observations about the method\"s applicability and benefits. It questions why the method helps on Hopper, which has deterministic dynamics, and suggests evaluating it on domains with nondeterministic dynamics to assess its empirical efficacy. The comment also points out the absence of BEAR from the baselines and questions the method\"s benefits. While the comment raises important points for consideration, it does not provide explicit instructions or concrete suggestions for the authors to address these issues. The actions are implicit and somewhat vague, as the authors need to infer what steps to take to address the questions and concerns. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises several questions and observations about the method\"s applicability and benefits. It questions why the method helps on Hopper, which has deterministic dynamics, and suggests evaluating it on domains with nondeterministic dynamics to assess its empirical efficacy. The comment also points out the absence of BEAR from the baselines and questions the method\"s benefits. However, the comment does not specify which part of the paper these questions or observations are based on, making it difficult for the authors to pinpoint the exact sections that need attention. While the authors might have an idea of where these issues are discussed, the lack of explicit references makes the comment weakly grounded. The comment is specific in its questions and observations, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point consists of a series of questions and observations, each of which requires verification or further explanation. The first question about the method\"s applicability on Hopper, which has deterministic dynamics, is not supported by any evidence or reasoning. The second question about evaluating the method on domains with nondeterministic dynamics is a request for clarification, not a claim. The third question about the absence of BEAR from the baselines is a request for information, not a claim. Overall, the comment lacks verifiable claims or evidence, making it difficult for the authors to address the points effectively. Therefore, it is rated as 1.", "helpfulness_rationale": "The review comment raises several important questions and observations about the method\"s applicability and benefits. It questions why the method helps on Hopper, which has deterministic dynamics, and suggests evaluating it on domains with nondeterministic dynamics to assess its empirical efficacy. This is a valuable suggestion that could help the authors better understand and demonstrate the method\"s effectiveness. Additionally, the comment points out the absence of BEAR from the baselines, which could be a relevant comparison for the authors to consider. However, the comment lacks specific guidance or suggestions on how to address these questions or incorporate BEAR into the analysis. While it identifies areas for improvement, it does not provide detailed actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential limitation of the proposed method, specifically its difficulty in detecting hallucinations in openended responses. It provides an example scenario where the prompt \"introduce a sports celebrity to me\" could lead to responses about different individuals, making it challenging to identify shared information for consistency checking. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their method. The action is implicit and somewhat vague, as the authors are left to infer that they should consider ways to enhance the method\"s ability to detect hallucinations in openended responses. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed method and provides a specific example scenario where the method might struggle to detect hallucinations in openended responses. It also specifies the issue by discussing the challenge of identifying shared information for consistency checking in responses to the prompt \"introduce a sports celebrity to me.\" This level of detail allows the authors to accurately identify the part of the paper being addressed and understand the specific concern, making the comment 5. Therefore, this comment aligns with a score of 5.", "verifiability_rationale": "The review point claims that the proposed method might struggle to detect hallucinations in openended responses, specifically in the context of a prompt like \"introduce a sports celebrity to me.\" The reviewer provides a specific example scenario to illustrate the challenge, which is a clear and logical reasoning to support the claim. However, the comment could be strengthened by providing additional examples or references to similar cases where this issue has been observed. Overall, the claim is 4, as it provides a logical basis but lacks comprehensive evidence or references. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a potential limitation of the proposed method, specifically its difficulty in detecting hallucinations in openended responses. It provides a specific example scenario involving a prompt about introducing a sports celebrity, which could lead to responses about different individuals, making it challenging to identify shared information for consistency checking. This feedback is valuable as it highlights a specific area where the method might struggle, prompting the authors to consider ways to address this issue. However, the comment could be more helpful if it offered suggestions or potential solutions for improving the method\"s ability to detect hallucinations in such scenarios. Overall, the comment is 3 as it provides insight into a potential weakness but lacks detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the relevance of theoretical findings to realworld deep learning models, specifically mentioning the need to verify the conclusion about label noise and model size on MNIST and CNN. While the comment implies that the authors should conduct additional experiments to validate their findings, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to conduct these experiments or what specific aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the relevance of theoretical findings to realworld deep learning models, specifically mentioning the need to verify the conclusion about label noise and model size on MNIST and CNN. However, it does not specify which part of the paper discusses these theoretical findings or where the conclusion about label noise and model size is presented. This makes it difficult for the authors to pinpoint the exact sections that need attention. While the comment is specific in suggesting a verification of the conclusions, it lacks grounding as it does not explicitly mention the sections being addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the relevance of theoretical findings to realworld deep learning models, specifically mentioning the need to verify the conclusion about label noise and model size on MNIST and CNN. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these specific experiments are necessary or how they would address the concern. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the relevance of theoretical findings to realworld deep learning models. It suggests that the authors should verify their conclusions about label noise and model size on MNIST and CNN, which is a clear and actionable piece of feedback. By recommending specific experiments, the comment provides the authors with a concrete step to take to improve the validity and applicability of their findings. However, the comment could be more helpful if it explained why these specific experiments are necessary or how they might address the concern. Overall, the feedback is 4 as it directs the authors toward a specific area for improvement, but it could be more comprehensive with additional context or reasoning."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point provides a mix of positive and constructive feedback. It acknowledges the paper\"s organization and writing quality but suggests specific improvements. It explicitly recommends drawing a table to compare different CoT prompting methods across different dimensions, which is a concrete action. It also raises questions about the assumptions made in the paper, such as why questions of all wrong demonstrations fall into the same frequenterror cluster and whether the selection criteria in section 4.2 are reasonable. These questions imply that the authors should provide more detailed explanations or justification for these assumptions. While the comment is 4, it could be more detailed in explaining how to improve the writing or how to address the questions about assumptions. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment provides a mix of positive and constructive feedback. It acknowledges the paper\"s organization and writing quality but suggests specific improvements. It explicitly recommends drawing a table to compare different CoT prompting methods across different dimensions, which provides clear guidance on how to enhance the paper. Additionally, it raises questions about the assumptions made in the paper, such as why questions of all wrong demonstrations fall into the same frequenterror cluster and whether the selection criteria in section 4.2 are reasonable. These questions imply that the authors should provide more detailed explanations or justification for these assumptions. The comment is fully grounded as it explicitly mentions the writing and content, and it is specific in suggesting improvements and raising questions about the assumptions. Therefore, this comment is labeled as 5.", "verifiability_rationale": "The review point consists of a combination of factual statements and suggestions. It acknowledges the paper\"s organization and writing quality but provides specific feedback on areas that could be improved. The suggestion to draw a table for comparison is a logical recommendation to enhance clarity. The questions about assumptions and selection criteria are factual and do not require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a mix of positive and constructive feedback. It acknowledges the paper\"s organization and writing quality, which is a positive observation. However, it also identifies specific areas for improvement, such as suggesting the inclusion of a table to compare different CoT prompting methods across different dimensions. This is a clear and actionable suggestion that could enhance the clarity and comprehensiveness of the paper. Additionally, the comment raises questions about the assumptions and selection criteria used in the paper, which encourages the authors to provide more detailed explanations or justifications. This feedback is 4 as it offers specific guidance on how to improve the paper, but it could be more comprehensive by addressing additional areas for enhancement. Therefore, the comment is rated as 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the application of weight decay to all layers, suggesting that this could lead to suboptimal training loss and cosine similarities for large weight decay parameters. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their analysis. It lacks concrete details on what specific changes or additions should be made to the draft. As a result, the authors are left without a clear understanding of how to apply the feedback to enhance their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"weight decay\" and \"cosine similarities,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a potential issue with the application of weight decay to all layers, suggesting that this could lead to suboptimal training loss and cosine similarities for large weight decay parameters. The comment further notes that the plots end at a weight decay strength where cosine similarities are still close to optimal, indicating a gap in the analysis. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point claims that weight decay applied to all layers would lead to suboptimal training loss and cosine similarities for large weight decay parameters. It further notes that the plots end at a weight decay strength where cosine similarities are still close to optimal. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that weight decay applied to all layers is suboptimal. Without additional evidence or explanation, the claim remains 3, as it provides a logical inference but lacks comprehensive support. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the application of weight decay to all layers, suggesting that this could lead to suboptimal training loss and cosine similarities for large weight decay parameters. It points out that the plots end at a weight decay strength where cosine similarities are still close to optimal, indicating a gap in the analysis. This feedback is 3 as it highlights a specific area for improvement in the paper, prompting the authors to consider the impact of weight decay on their results. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered guidance on how to extend the analysis to larger weight decay strengths. Overall, the comment provides some direction but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that systematically studying the impact of the cost of incentivization on performance would be beneficial. It provides an example of how this could be done, such as analyzing the reward incentives for various values of alpha and the collective return. The comment also offers a hypothesis about the roles of \"winners\" and \"cooperators\" and how lowering the cost of incentivization might affect the collective return. While the comment implies an action, it does not explicitly instruct the authors to conduct this analysis or provide detailed guidance on how to implement it. The action is somewhat vague, as the authors need to infer the specific steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests a specific analysis that could be conducted to study the impact of the cost of incentivization on performance. It provides examples of what could be analyzed, such as the reward incentives for various values of alpha and the collective return. However, the comment does not explicitly mention which part of the paper this analysis should be included in, making it weakly grounded. The suggestion is specific in terms of what needs to be addressed, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact location for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that systematically studying the impact of the cost of incentivization on performance would be beneficial. It provides a hypothetical scenario where the cost to reward the other agent becomes high for cooperators, leading to the emergence of roles between \"winners\" and \"cooperators.\" The comment further suggests that lowering this cost might affect the collective return. While the comment offers a logical reasoning and a hypothetical scenario, it lacks specific examples or references to support the claim. This makes the claim 3, as it provides a basis for the suggestion but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests a valuable analysis that could be conducted to study the impact of the cost of incentivization on performance. It provides specific examples of what could be analyzed, such as the reward incentives for various values of alpha and the collective return. The comment also offers a hypothesis about the roles of \"winners\" and \"cooperators\" and how lowering the cost of incentivization might affect the collective return. This feedback is clear and actionable, as it directs the authors to a specific area for further exploration and analysis. However, it could be more helpful if it included suggestions on how to implement this analysis or what specific metrics to focus on. Overall, the comment is 4, as it provides a clear direction for enhancing the paper with additional analysis."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies two areas for improvement in the experiments section. First, it suggests that the discussion lacks interpretive insights that would explain why the proposed gyrostructures outperform existing methods. Second, it points out the lack of comparison with other stateoftheart methods that do not rely on gyrostructures, which could provide a clearer understanding of the proposed approach\"s performance. While the comment highlights specific areas for improvement, it does not provide explicit guidance on how to address these issues or what specific comparisons or insights should be included. The actions are implicit and somewhat vague, as the authors need to infer the exact steps to take to improve the discussion and comparisons. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiments part,\" allowing the authors to accurately identify the section being addressed. It is also specific because it details what is missing in the discussion, namely interpretive insights that would explain the superiority of the proposed gyrostructures over existing methods. Additionally, it points out the lack of comparison with other stateoftheart methods that do not rely on gyrostructures, which could provide a clearer understanding of the proposed approach\"s performance. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the related discussion lacks interpretive insights and that the paper does not compare its methods with other stateoftheart methods that might not rely on gyrostructures. This claim is 3 as it highlights a gap in the paper\"s analysis and suggests a potential area for improvement. However, the comment does not provide specific examples of alternative methods or detailed reasoning on why these comparisons are necessary. The lack of concrete evidence or references makes it challenging for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific areas for improvement in the experiments section. First, it points out the lack of interpretive insights in the discussion, which would help explain why the proposed gyrostructures outperform existing methods. Second, it notes the absence of comparisons with other stateoftheart methods that do not rely on gyrostructures, which could provide a clearer understanding of the proposed approach\"s performance. These observations are clear and actionable, as they guide the authors to enhance the interpretability and comprehensiveness of their experimental analysis. However, the comment could be more helpful if it provided specific suggestions on how to incorporate these comparisons or insights. Overall, the feedback is 4, as it directs the authors to important areas for improvement in their experimental discussion."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a difficulty in comprehending Figure 5 and suggests that more details about the two baselines presented in the figure are needed. It also points out that the authors only study CATER for Englishcentric datasets, which is a limitation, and suggests that the authors could extend CATER to other languages in the future. While the comment implies that the authors should provide more details about the baselines and consider extending CATER to other languages, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details and consider expanding the study to other languages. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what is missing in the figure, namely more details about the two baselines presented. Additionally, the comment points out a limitation in the study, noting that the authors only study CATER for Englishcentric datasets, and suggests that the authors could extend CATER to other languages in the future. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 5 is hard to comprehend and suggests that more details about the two baselines presented in the figure are needed. It also points out a limitation in the study, noting that the authors only study CATER for Englishcentric datasets, and suggests that the authors could extend CATER to other languages in the future. The comment provides a logical reasoning for the claim by highlighting the lack of clarity in the figure and the need for more detailed information. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to infer the exact details that are missing and how to address the limitation. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 5, stating that it is hard to comprehend. It provides a clear suggestion for improvement by requesting more details about the two baselines presented in the figure. Additionally, the comment points out a limitation in the study, noting that the authors only study CATER for Englishcentric datasets, and suggests that the authors could extend CATER to other languages in the future. This feedback is actionable and provides a clear direction for the authors to enhance their draft by providing more detailed information and considering the applicability of their work to other languages. However, the comment could be more helpful if it included specific suggestions on how to improve the clarity of Figure 5 or examples of additional details that could be included. Overall, the comment is 4 as it effectively guides the authors toward improving their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the literature review needs improvement, specifically highlighting the lack of clarity regarding the main contribution and distinction from existing work, particularly in relation to GFlowNet for sequence generation. It suggests that the paper should provide a more explicit and comparative analysis of related work. This feedback is clear and provides a direct action for the authors to take, which is to enhance the literature review by clearly articulating the main contribution and distinguishing it from existing work. The comment is explicit and concrete, giving the authors a clear understanding of what needs to be addressed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"literature review\" section of the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it details what needs to be improved, namely the clarity of the main contribution and the distinction from existing work, particularly in relation to the utilization of GFlowNet for sequence generation. The comment provides a clear direction for the authors to enhance their literature review by providing a more explicit and comparative analysis of related work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the literature review is unclear regarding the main contribution and distinction from existing work, particularly in relation to the utilization of GFlowNet for sequence generation. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact issues or how to address them. The lack of detailed justification or examples makes the claim 3, as the authors would need to infer the specific areas needing improvement. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the literature review, noting that it lacks clarity regarding the main contribution and distinction from existing work, particularly in relation to the utilization of GFlowNet for sequence generation. It provides a clear and actionable suggestion to enhance the literature review by offering a more explicit and comparative analysis of related work. This feedback is valuable as it guides the authors on how to improve the clarity and depth of their literature review, which is crucial for establishing the novelty and significance of their work. However, the comment could be more helpful if it included specific examples or references to existing work that the authors should consider for comparison. Overall, the comment is 4, as it provides clear guidance for improvement but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that section 3.2 can be eliminated because readers are presumed to know about the GumbelSoftmax/Concrete distribution. However, it does not provide any specific guidance on how to address this suggestion or what alternative content could be included in its place. The action is explicit but lacks concrete details on how to implement the change, making it 3.", "grounding_specificity_rationale": "The comment suggests that section 3.2 can be eliminated because readers are presumed to know about the GumbelSoftmax/Concrete distribution. However, it does not specify which part of section 3.2 is being addressed or what specific content could be removed. The authors can infer that it relates to the discussion of the GumbelSoftmax/Concrete distribution, but the comment lacks detailed guidance on what needs to be addressed or improved. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that section 3.2 can be eliminated because readers are presumed to know about the GumbelSoftmax/Concrete distribution. However, the comment lacks specific reasoning or evidence to support this claim. It does not provide examples or references to justify why this section is unnecessary or how it could be improved. Without detailed justification or examples, the claim remains 1, as the authors are left without a clear understanding of why this section should be removed. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that section 3.2 can be eliminated because readers are presumed to know about the GumbelSoftmax/Concrete distribution. While this feedback identifies a potential area for improvement, it lacks specificity and does not provide any guidance on how to address this suggestion or what content could be included instead. The comment does not offer actionable advice or detailed reasoning, leaving the authors with limited insight into how to improve their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point provides two explicit suggestions for improving the experiments. First, it recommends adding performance on word similarity and sentence translation tasks, as done in the MUSE paper, to enhance the credibility of the framework\"s robustness and effectiveness. Second, it suggests including morphologically rich languages like Finnish and Hebrew, as well as lowresource languages, in the experiments. These suggestions are clear and provide concrete actions for the authors to take, ensuring they know exactly what improvements to make. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides two distinct suggestions for improvement: (i) the addition of performance on word similarity and sentence translation tasks, as in the MUSE paper, to enhance credibility, and (ii) the inclusion of morphologically rich languages like Finnish and Hebrew, as well as lowresource languages, in the experiments. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests adding performance on word similarity and sentence translation tasks, as done in the MUSE paper, to enhance the credibility of the framework. It also recommends including morphologically rich languages like Finnish and Hebrew, as well as lowresource languages, in the experiments. These suggestions are supported by logical reasoning, as they provide specific examples of tasks and languages that could enhance the robustness and effectiveness of the framework. However, the comment could be strengthened by referencing the MUSE paper or providing more detailed reasoning for why these additions are important. Overall, the claim is 4, as it provides a clear direction for improvement but lacks comprehensive evidence or references.", "helpfulness_rationale": "The review comment provides two specific suggestions for improving the experiments in the paper. First, it recommends adding performance on word similarity and sentence translation tasks, as done in the MUSE paper, to enhance the credibility of the framework\"s robustness and effectiveness. This is a clear and actionable suggestion that could significantly strengthen the paper\"s claims. Second, it suggests including morphologically rich languages like Finnish and Hebrew, as well as lowresource languages, in the experiments. This addition would broaden the applicability and relevance of the framework, making it more robust and useful. The feedback is detailed and provides concrete steps for the authors to take, making it 5 for improving the draft. Therefore, the comment deserves a score of 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper lacks insights into why selfsupervised learning is needed on 360 video data with spatial audio. However, it does not provide explicit guidance or concrete suggestions on how the authors might address this issue. The comment implies that the authors should provide more justification or explanation, but it does not specify what kind of insights or reasoning should be included. As a result, the action is implicit and vague, leaving the authors uncertain about how to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the lack of insights into why selfsupervised learning is needed on 360 video data with spatial audio. However, it does not specify which part of the paper this issue pertains to, such as a specific section or discussion where this insight could be provided. The authors can infer that it relates to the experimental results or the discussion of the proposed approach, but this inference is not explicit. The comment is specific in identifying the need for more insight into the rationale for selfsupervised learning on this type of data, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks insights into why selfsupervised learning is needed on 360 video data with spatial audio. However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. The comment lacks specific details or references that would help the authors understand the basis of the critique or how to address it. As a result, the claim is 1, as it does not provide sufficient information for the authors to make improvements based on the feedback. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the need for selfsupervised learning on 360 video data with spatial audio. It points out that while the experimental results suggest the value of the proposed approach, the paper lacks insights into why this type of data requires selfsupervised learning. This feedback is 3 as it highlights an area where the authors could provide more context and justification for their work. However, the comment does not offer specific suggestions or guidance on how to address this issue, such as what additional insights or explanations could be included. To be more helpful, the comment could provide examples or questions to guide the authors in enhancing their discussion. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to average their results over multiple runs to determine statistical significance. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific and concrete step for the authors to follow, ensuring they know exactly what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests averaging results over multiple runs to determine statistical significance. However, it does not specify which part of the paper this suggestion pertains to, such as the results section or a specific experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its suggestion to average results, but without clear grounding, it is difficult for the authors to know where to implement this change. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests averaging results over multiple runs to determine statistical significance. This is a logical suggestion based on common practices in statistical analysis, as averaging can help reduce variability and improve the robustness of results. However, the comment does not provide specific examples or references to support why this is necessary or how it would impact the paper\"s conclusions. While the suggestion is logical, it lacks detailed justification or evidence, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by recommending that the authors average their results over multiple runs to determine statistical significance. This feedback is valuable as it addresses a critical aspect of experimental design and analysis, which can significantly impact the robustness and credibility of the results. By following this advice, the authors can enhance the rigor and reliability of their findings, making the comment 5. However, the comment could be more helpful if it explained why averaging is important or provided examples of how this practice might affect the results. Therefore, the comment is rated as 5."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises two questions: how the capacity of the SR model affects the FID and whether there are unexpected artifacts due to the proposed method being pipelined. However, it does not provide explicit instructions or suggestions on how the authors should address these questions or investigate the potential issues. The authors are left to infer that they need to explore these aspects further, but without concrete guidance on how to do so, the comment lacks actionability. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises two questions: how the capacity of the SR model affects the FID and whether there are unexpected artifacts due to the proposed method being pipelined. However, it does not specify which part of the paper these questions pertain to, making it difficult for the authors to identify the exact sections that need attention. The comment lacks specificity as it does not provide details on what aspects of the SR model capacity or the pipelining method are causing the unexpected artifacts. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point consists of two questions: \"How the capacity of the SR model affects the FID\" and \"whether there are unexpected artifacts due to the proposed method being pipelined.\" These are requests for clarification or additional information, not claims or opinions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises two questions: how the capacity of the SR model affects the FID and whether there are unexpected artifacts due to the proposed method being pipelined. While these questions are relevant and could lead to further exploration and clarification in the paper, the comment lacks specificity and actionable guidance. It does not provide suggestions on how to address these questions or improve the paper, leaving the authors with a general direction but no clear steps to take. Therefore, the comment is 2, as it identifies areas for improvement but does not offer detailed feedback or actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that Appendix A is left blank and that the purpose of Proposition B.1 in Appendix B is unclear. It suggests that the proposition might be meant to illustrate the classic partitioning principle of Kmeans, which is a wellknown concept in machine learning. The comment also notes that the authors\" socalled \"proof\" is missing. While the comment identifies specific issues and provides some context, it does not explicitly instruct the authors on how to address these issues or what specific actions to take. The feedback is 3 as it highlights areas that need clarification or improvement, but it lacks concrete guidance on how to implement these changes. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix A\" and \"Proposition B.1 in Appendix B,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issues with these sections, such as the blank appendix and the unclear purpose of the proposition. The comment provides a suggestion that the proposition might be meant to illustrate a wellknown concept in machine learning, which adds further clarity. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Appendix A is left blank and that the purpose of Proposition B.1 in Appendix B is unclear, suggesting it might be meant to illustrate a wellknown concept in machine learning. The reviewer also notes that the authors\" socalled \"proof\" is missing. While the comment raises valid concerns about the clarity and completeness of the appendices, it lacks specific examples or references to support the claim that the concept is wellknown or that the proof is missing. This makes the claim 3, as it provides a basis for the critique but requires more detailed evidence or explanation to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several issues with the appendices, specifically noting that Appendix A is left blank and that the purpose of Proposition B.1 in Appendix B is unclear. It suggests that the proposition might be meant to illustrate a wellknown concept in machine learning, such as the classic partitioning principle of Kmeans. Additionally, the comment points out that the authors\" socalled \"proof\" is missing. While the comment highlights important areas for improvement, it lacks specific suggestions or guidance on how to address these issues, such as what content should be included in Appendix A or how to clarify the purpose of Proposition B.1. The feedback is 3 as it directs the authors\" attention to specific areas needing attention, but it could be more actionable with additional guidance. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the paper lacks additional necessary experiments, including comparison experiments, ablation studies, and hyperparameter analysis. This provides a clear and direct action for the authors to take, which is to conduct these additional experiments to enhance the paper. The comment is specific and provides concrete guidance on what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of additional necessary experiments, including comparison experiments, ablation studies, and hyperparameter analysis. This allows the authors to accurately identify the part of the paper being addressed, which is the experimental section. The comment is also specific because it clearly specifies what is missing in the experiments, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks additional necessary experiments, including comparison experiments, ablation studies, and hyperparameter analysis. However, it does not provide any specific examples, reasoning, or references to support this claim. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. This feedback is clear and actionable, as it provides specific areas where the authors can enhance their work by conducting additional experiments. However, the comment could be more helpful if it offered suggestions on which specific comparisons or ablations should be conducted or how to analyze hyperparameters. Despite this, the comment is 4 as it directs the authors to a critical area for improvement, providing a clear path for enhancing the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the proposed model demonstrates impressive performance on various benchmarks, setting new stateoftheart (SOTA) scores. However, it implies that a more careful analysis is needed, particularly for \"old\" benchmarks where the data might have been indirectly seen by the model through the \"data curation\" process. The comment also recommends providing more details about the evaluation procedures. While the comment implies that the authors should conduct a more thorough analysis and provide additional details, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to conduct the analysis or what details to include. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the proposed model demonstrates impressive performance on various benchmarks, setting new stateoftheart (SOTA) scores. It implies that a more careful analysis is needed, particularly for \"old\" benchmarks where the data might have been indirectly seen by the model through the \"data curation\" process. The comment also recommends providing more details about the evaluation procedures. However, it does not specify which part of the paper discusses these benchmarks or evaluation procedures, making it weakly grounded. The comment is specific in suggesting the need for a more thorough analysis and additional details, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed model demonstrates impressive performance on various benchmarks, setting new stateoftheart (SOTA) scores. It suggests that a more careful analysis is needed, particularly for \"old\" benchmarks where the data might have been indirectly seen by the model through the \"data curation\" process. The comment also recommends providing more details about the evaluation procedures. While the claim about the model\"s performance is based on the observation of SOTA scores, the suggestion for a more careful analysis and additional details is not fully supported by specific examples or references. The comment lacks detailed reasoning or evidence to substantiate the need for a more thorough analysis, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the impressive performance of the proposed model on various benchmarks, setting new stateoftheart (SOTA) scores. However, it suggests that a more careful analysis is needed, particularly for \"old\" benchmarks where the data might have been indirectly seen by the model through the \"data curation\" process. This implies that the authors should be cautious about the generalizability of their results and provide more details about the evaluation procedures. While the comment identifies a potential issue and suggests a direction for improvement, it lacks specific guidance on how to conduct this analysis or what additional details should be included. Therefore, the feedback is 3, as it provides insight but could be more actionable with further elaboration."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy in the experimental part, specifically noting that the different metrics used for different OPE methods are not consistent across Figure 4 and Figure 5. The reviewer suggests that the authors provide comments on the differences between the two sets of evaluation methods. While the comment implies that the authors should address this inconsistency, it does not explicitly instruct them to do so or provide specific guidance on how to make these comments. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the differences but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4 and Figure 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out a discrepancy in the experimental part, noting that the different methods in the two sets of benchmarks proposed in the article are different for different OPE methods. The comment suggests that the authors provide comments on the differences between these evaluation methods. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper verifies different metrics for different OPE methods but notes a discrepancy in the evaluation methods used in Figures 4 and 5. The reviewer suggests that the authors provide comments on the differences between the two sets of evaluation methods. However, the comment lacks specific examples or detailed reasoning to support the claim of inconsistency, making it difficult for the authors to understand the exact nature of the issue. The lack of detailed justification or references makes the claim 3, as the authors would need to invest effort to identify and address the problem. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental part of the paper, noting that different metrics are used for different OPE methods in Figures 4 and 5. It suggests that the authors provide comments on the differences between the two sets of evaluation methods, which is a clear and actionable piece of feedback. By addressing this inconsistency, the authors can improve the clarity and consistency of their experimental results, making the comment 4. However, the comment could be more helpful if it provided specific suggestions on how to present or discuss these differences, which would enhance its utility for the authors. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the experimental results, noting that the proposed method does not show an advantage over the stateoftheart (SOTA) without prior information. It suggests that the comparison is unfair because the proposed method requires two representation models, VAE/GAN and CL, which adds complexity and cost. While the comment identifies a potential issue with the experimental setup, it does not provide explicit guidance on how the authors should address this concern or improve their draft. The action is implicit and somewhat vague, as it lacks specific suggestions on how to adjust the experiments or present the results. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental results\" and the \"proposed method,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the comparison, noting that the proposed method does not show an advantage without prior information and that the comparison is unfair due to the additional complexity and cost of using two representation models. The comment provides a clear basis for the authors to understand what needs to be addressed in their draft. Therefore, this comment is labeled as 5.", "verifiability_rationale": "The review point claims that the proposed method does not show an advantage over the stateoftheart (SOTA) without prior information, and that the advantage only appears when using prior knowledge. The reviewer provides a logical reasoning by pointing out that the proposed method requires two representation models, VAE/GAN and CL, which adds complexity and cost. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the experimental setup, noting that the proposed method does not show an advantage over the stateoftheart (SOTA) without prior information. It points out that the comparison is unfair because the proposed method requires two representation models, VAE/GAN and CL, which adds complexity and cost. This feedback is clear and actionable, as it highlights a critical aspect of the experimental design that could be improved to better demonstrate the method\"s advantages. However, the comment could be more helpful if it provided specific suggestions on how to address this issue, such as proposing alternative experimental setups or analyses. Overall, the comment is 4 as it directs the authors\" attention to a significant area for improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the experiments should include collaborative games to evaluate the methods in both collaborative and competitive settings. While the comment implies that the authors should add collaborative games to their experiments, it does not provide specific guidance on which games to choose or how to implement them. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests adding collaborative games to the experiments to evaluate the methods in both collaborative and competitive settings. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. Without explicit references to specific sections or experiments, the authors cannot confidently determine where to incorporate this suggestion. The comment is specific in its request for collaborative games but lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the experiments should include collaborative games to evaluate the methods in both collaborative and competitive settings. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this would be interesting or beneficial. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the experiments should include collaborative games to evaluate the methods in both collaborative and competitive settings. This feedback is 3 as it identifies a potential area for improvement in the experimental design. However, the comment lacks specificity and does not provide guidance on how to implement collaborative games or what specific benefits might be gained from doing so. While it points out a direction for enhancement, it does not offer detailed actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the absence of experimental settings for Figures 1 to 9, which makes the results less convincing. However, it does not provide explicit guidance on what specific information should be included or how the authors should present it. The action is implicit, as the authors can infer that they need to provide experimental settings, but it lacks concrete details on how to do so. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment highlights the absence of experimental settings for Figures 1 to 9, which makes the results less convincing. However, it does not specify which part of the paper discusses these figures, making it difficult for the authors to pinpoint the exact sections that need revision. The comment is specific in identifying the issue of missing experimental settings, but it lacks grounding as it does not mention specific sections or figures. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experimental settings for Figures 1 to 9 are missing, which makes the results less convincing. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a significant issue with the paper, noting the absence of experimental settings for Figures 1 to 9, which makes the results less convincing. This is a critical observation that highlights a gap in the presentation of the experimental results, which is essential for the paper\"s credibility. However, the comment lacks specific guidance on how the authors might address this issue, such as suggesting what information should be included or how to present it. While it points out a significant weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight but does not fully support the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises concerns about the adhoc nature of the regularization term and suggests that the authors provide theoretical support for it. It also implies that other statistics, such as the median, could be used to replace the mean and standard deviation in the regularization. While the comment identifies areas for improvement, it does not explicitly instruct the authors to make specific changes or provide detailed guidance on how to address the issues. The action is implicit and somewhat vague, as the authors can infer that they need to provide theoretical justification and consider alternative statistics, but they are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"regularization term,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear critique of the adhoc nature of the regularization term and suggests alternative statistics, such as the median, that could be used instead of the mean and standard deviation. The comment also raises a question about why these alternatives were not considered, which further specifies the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the regularization term is adhoc and lacks theoretical support, suggesting that other statistics, such as the median, could be used instead of the mean and standard deviation. The comment provides a logical reasoning by pointing out the potential sensitivity of the mean to outliers, which could affect the regularization. However, it lacks specific examples or references to other statistics that could be used, making the claim 3. The authors would need to explore these alternatives themselves to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the regularization term, noting that it appears adhoc and lacks theoretical support. It suggests that other statistics, such as the median, could be used to replace the mean and standard deviation in the regularization. The comment also raises a question about why these alternatives were not considered, which prompts the authors to reflect on their choice of regularization and potentially explore alternative approaches. This feedback is clear and actionable, as it provides a specific suggestion for improvement and encourages the authors to consider alternative statistical methods. However, it could be more helpful if it included examples or references to support the use of the median or other statistics. Overall, the comment is 4, as it guides the authors toward enhancing the theoretical foundation and robustness of their regularization approach."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point provides several explicit actions for the authors to take. It suggests reporting the average over multiple runs to address the issue of results being close together, which would help in favoring one method. It also recommends discussing the decision boundaries in the toydataset, which would be interesting given its nature. Additionally, it asks for clarification on what information is in Figure 9, specifically the middle and right panels. Each of these actions is clear and concrete, giving the authors specific steps to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Experimental section,\" \"Sec. 3.1,\" and \"Sec. 3.3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear and actionable feedback, such as suggesting the reporting of averages over multiple runs to address the closeness of results, discussing the decision boundaries in the toydataset, and asking for clarification on the information in Figure 9. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements and requests for clarification, such as suggesting the reporting of averages over multiple runs and asking for a discussion on the decision boundaries in the toydataset. It does not contain subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback that can help the authors improve their draft. It suggests reporting the average over multiple runs to address the issue of results being close together, which would aid in favoring one method. Additionally, it recommends discussing the decision boundaries in the toydataset, as this would be interesting given its nature. The comment also asks for clarification on what information is in Figure 9, specifically the middle and right panels. This level of detail and guidance is valuable for the authors, as it directly addresses areas that could be improved and provides clear steps for enhancement. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the authors\" use of the center correlation metric, noting that it was deemed uninformative for discriminating model defenses but is used in Figure 4 A&B. The reviewer wonders why this metric was found useful in this context and not elsewhere, or what the authors meant by their statement on lines 8082. While the comment highlights a potential inconsistency or confusion, it does not provide explicit guidance or suggestions for the authors to address this issue. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify their reasoning or provide additional context. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (8082) and figures (4 A&B) in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies the issue by questioning the authors\" use of the center correlation metric, which was previously deemed uninformative, and asking for clarification on why it was found useful in this context. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the authors\" use of the center correlation metric, noting that it was deemed uninformative for discriminating model defenses but is used in Figure 4 A&B. The reviewer wonders why this metric was found useful in this context and not elsewhere, or what the authors meant by their statement on lines 8082. This comment raises a valid point about the inconsistency in the authors\" reasoning, but it does not provide any additional evidence, references, or detailed reasoning to support the claim. The authors are left to infer the issue and address it themselves. Therefore, the comment is considered 2, as it highlights a potential issue but lacks sufficient support or explanation to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential inconsistency in the authors\" use of the center correlation metric, noting that it was deemed uninformative for discriminating model defenses but is used in Figure 4 A&B. The reviewer questions the authors\" reasoning and asks for clarification on why this metric was found useful in this context. This feedback is 3 as it points out a specific area of confusion or inconsistency in the paper, prompting the authors to clarify their rationale. However, the comment could be more helpful if it provided suggestions on how to address this inconsistency or offered guidance on how to improve the clarity of the explanation. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the phrase \"above/below diagonal\" is easier to interpret than \"above/below 45 degree,\" which is perceived as a local property. However, it does not provide any explicit or implicit action for the authors to take. There is no guidance on how to address this issue or improve the clarity of the text. Without any actionable steps or suggestions, the authors are left without a clear understanding of what changes, if any, are needed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the phrase \"above/below diagonal\" and \"above/below 45 degree,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for improvement, recommending the use of \"above/below diagonal\" instead of \"above/below 45 degree\" to enhance interpretability. This specificity helps the authors understand what needs to be addressed in their draft. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the phrase \"above/below diagonal\" is easier to interpret than \"above/below 45 degree,\" which is perceived as a local property. The reviewer provides a logical reasoning by explaining that the diagonal reference is more general and not limited to specific angles, such as when the red line saturates. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened by providing examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the language used in the paper, specifically the phrase \"above/below 45 degree.\" The reviewer suggests that this phrase might be interpreted as a local property, which could be misleading. The comment provides a clear and actionable suggestion to replace \"above/below 45 degree\" with \"above/below diagonal,\" which is perceived as more general and easier to interpret. This feedback is valuable as it helps the authors improve the clarity and precision of their language, enhancing the readability and understanding of their work. However, the comment could be more helpful if it included examples or further explanation of why the suggested change is beneficial. Overall, the comment is 4, as it provides a specific and actionable suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a specific issue with the wording in lines 240 and 428, suggesting that the phrase \"is sufficient\" needs clarification. It provides a potential correction, indicating that the authors might want to write that the sum of the \"optimistic\" hopedfor rewards is close to the expected actual rewards. This feedback is explicit and provides a clear direction for the authors to improve their draft by clarifying the intended meaning. The action is concrete, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (L240 and L428), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified: the phrase \"is sufficient\" should be clarified by writing that the sum of the \"optimistic\" hopedfor rewards is close to the expected actual rewards. This provides clear guidance on how to improve the draft. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the phrase \"is sufficient\" in lines 240 and 428, suggesting that it should be clarified. The reviewer provides a potential correction, stating that the sum of the \"optimistic\" hopedfor rewards should be close to the expected actual rewards. However, the comment does not offer any further justification or evidence to support why this clarification is necessary or how it would improve the paper. The suggestion is logical but lacks detailed reasoning or references, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the wording in lines 240 and 428, where the phrase \"is sufficient\" is used without clear context. It suggests that the authors might want to clarify that the sum of the \"optimistic\" hopedfor rewards is close to the expected actual rewards. This feedback is clear and actionable, providing the authors with a specific direction to improve the clarity and precision of their writing. However, the comment could be more helpful if it explained why this clarification is important or how it might impact the reader\"s understanding. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the lack of scientific insight provided by the model and formalism compared to prior taskoptimized approaches. It specifically questions whether the model is a prototype approximation to nonlinear RNN models and whether it provides an explanation for their emergent behavior. While the comment identifies a gap in the paper\"s explanation, it does not provide explicit guidance or suggestions on how the authors might address this issue. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide a clearer explanation of the model\"s contribution. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of scientific insight provided by the model and formalism compared to prior taskoptimized approaches. The comment questions whether the model is a prototype approximation to nonlinear RNN models and whether it provides an explanation for their emergent behavior. This level of detail provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the scientific insight provided by the model and formalism compared to prior taskoptimized approaches. It specifically challenges the claim that the model is a prototype approximation to nonlinear RNN models and questions whether it provides an explanation for their emergent behavior. The comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the basis of the critique. This results in a 2 rating, as the claim is not fully substantiated but provides some basis for questioning the paper\"s contributions.", "helpfulness_rationale": "The review comment raises a critical question about the scientific insight provided by the model and formalism compared to prior taskoptimized approaches. It specifically questions whether the model is a prototype approximation to nonlinear RNN models and whether it provides an explanation for their emergent behavior. This feedback is valuable as it prompts the authors to clarify the novelty and contribution of their work, which is essential for improving the draft. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address this issue. Overall, the comment is 3 as it identifies a key area for improvement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point provides explicit and concrete actions for the authors to take. It specifies that the texts in legends and axis labels should be larger, corrects the notation for Proposition 1, and suggests increasing the font size for captions and legends in Figures 2 and 3. These instructions are clear and direct, giving the authors a precise understanding of what changes need to be made to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"page 6\" and \"Fig. 2 and 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear instructions on what needs to be addressed, such as increasing the font size for legends and axis labels and correcting the notation for Proposition 1. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements and suggestions for improvement, such as increasing the font size for legends and axis labels. It does not contain subjective opinions, claims, or suggestions that require verification or justification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting improvements to the font size of texts in legends and axis labels, as well as correcting the notation for Proposition 1. It also points out a potential confusion between Proposition 1 and Equation 1. These suggestions are clear and direct, offering the authors concrete steps to enhance the readability and clarity of their paper. By addressing these issues, the authors can improve the overall presentation and understanding of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should include a comparison against Journey TRAK [1] at a particular step of the sampling trajectory for their counterfactual experiments. It provides specific guidance by referencing Figure 2 from [1], which shows a larger effect of removing highscoring images according to Journey TRAK compared to CLIP cosine similarity. This feedback is explicit and provides concrete details on how to implement the suggested comparison, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"counterfactual experiments\" and \"Journey TRAK [1],\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what is missing, namely a comparison against Journey TRAK at a particular step of the sampling trajectory, and provides a specific reference to Figure 2 in [1] to support the suggestion. This level of detail makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the counterfactual experiments should include a comparison against Journey TRAK [1] at a particular step of the sampling trajectory. It provides a specific reference to Figure 2 in [1], which shows a larger effect of removing highscoring images according to Journey TRAK compared to CLIP cosine similarity. This reference supports the claim by providing a concrete example and evidence, making the comment 5. The reviewer has provided a clear and specific justification for the suggestion, ensuring that the authors can understand and address the feedback effectively.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the counterfactual experiments in the paper. It recommends including a comparison against Journey TRAK [1] at a particular step of the sampling trajectory, referencing Figure 2 in [1] to illustrate the potential benefits of this comparison. This feedback is clear and offers a concrete way for the authors to enhance the robustness and comprehensiveness of their experiments. By suggesting a specific comparison and referencing relevant literature, the comment empowers the authors to make a meaningful improvement to their draft. Therefore, it is 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the theoretical discussions could be improved by providing sample complexitytype results for not returning NSF, given confidence levels. While the comment implies that the authors should include such results, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to implement these results or what specific aspects of the theoretical discussions need improvement. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"theoretical discussions,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting improvements, such as providing sample complexitytype results for not returning NSF. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the theoretical discussions could be improved by providing sample complexitytype results for not returning NSF, given confidence levels. The reviewer expects some results beyond the current theorems, which are directly related to the algorithm design and mutual information. However, the comment lacks specific examples or references to support the claim that such results are necessary or beneficial. The reasoning is somewhat vague, making it difficult for the authors to fully understand and address the suggestion. Therefore, the comment is classified as 2.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the theoretical discussions, suggesting that the authors should provide sample complexitytype results for not returning NSF, given confidence levels. This feedback is clear and actionable, as it offers a concrete suggestion for enhancing the theoretical section of the paper. By addressing this point, the authors can strengthen their theoretical foundation and provide more comprehensive insights into the algorithm\"s performance. However, the comment could be more helpful if it included additional guidance or examples on how to approach these sample complexity results. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with further elaboration."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly states that the VAD description is puzzling and suggests that it is not a true VAD because it discards TF bins with a magnitude less than epsilon, which results in a division by zero. The reviewer provides a clear explanation of what a VAD should do and why the current approach is not accurate. This feedback is direct and provides concrete guidance on how to improve the description of the VAD, making it 5. The authors know exactly what needs to be changed to align with the expectations of a VAD, and they are given a clear understanding of what a VAD should do. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Your VAD description,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is puzzling about the VAD description and provides a detailed explanation of what a VAD should do. The comment explains that the current approach discards TF bins with a magnitude less than epsilon, which is not consistent with the definition of a VAD. It also clarifies that a VAD should look for the presence of speech and is usually defined over time, not frequency. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the VAD description is puzzling and suggests that it is not a true VAD because it discards TF bins with a magnitude less than epsilon, which results in a division by zero. The reviewer provides a clear explanation of what a VAD should do and why the current approach is not accurate. This reasoning is logical and based on common knowledge about the function of a VAD, making the claim 4. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a clear and actionable critique of the VAD description in the paper. It points out that the current approach, which discards TF bins with a magnitude less than epsilon, is not consistent with the definition of a VAD. The reviewer explains that a VAD should look for the presence of speech and is usually defined over time, not frequency. This feedback is valuable as it identifies a specific issue with the VAD description and offers a clear understanding of what a VAD should do. By highlighting this discrepancy, the comment empowers the authors to make necessary adjustments to their VAD description, ensuring it aligns with the expectations of a VAD. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors include a brief discussion on the empirical motivation for timevarying Q^t and S_t, as opposed to a fixed one as in Section 4.2. It provides a specific example of what could be discussed, such as the effect on the volatility of \u03b1_t and the average lengths of predictive intervals when Q^t and S_t vary with time. This feedback is explicit and provides concrete guidance on what the authors should discuss, making it 5.", "grounding_specificity_rationale": "The comment suggests including a brief discussion on the empirical motivation for timevarying Q^t and S_t, as opposed to a fixed one as in Section 4.2. It provides a specific example of what could be discussed, such as the effect on the volatility of \u03b1_t and the average lengths of predictive intervals when Q^t and S_t vary with time. While the comment does not explicitly mention a specific section, the authors can infer that it relates to the discussion section, where such a discussion could be included. The suggestion is specific, as it provides a clear direction for the authors to consider. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests including a discussion on the empirical motivation for timevarying Q^t and S_t, as opposed to a fixed one as in Section 4.2. It provides a specific example of what could be discussed, such as the effect on the volatility of \u03b1_t and the average lengths of predictive intervals when Q^t and S_t vary with time. This suggestion is based on logical reasoning and provides a clear direction for the authors to explore, making it 4. However, the comment could be strengthened by referencing similar studies or empirical evidence to support the suggestion, which would align it with a score of 5.", "helpfulness_rationale": "The review comment suggests that the authors include a brief discussion on the empirical motivation for timevarying Q^t and S_t, as opposed to a fixed one as in Section 4.2. It provides a specific example of what could be discussed, such as the effect on the volatility of \u03b1_t and the average lengths of predictive intervals when Q^t and S_t vary with time. This feedback is clear and actionable, offering a concrete suggestion for enhancing the discussion section of the paper. By addressing this point, the authors can provide a more comprehensive understanding of the methodology and its implications. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment states that the paper is not easy to follow and lacks a clear intuition for how the pieces fit together, resulting in experiments that are difficult to understand. However, it does not provide specific guidance or suggestions on how the authors might improve the clarity or structure of the paper. The comment lacks actionable details, such as recommending specific changes to the presentation or experiments to enhance clarity. As a result, the authors are left without a clear understanding of what steps to take to address the issues raised. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment provides a general observation about the paper\"s lack of clarity and difficulty in understanding the pieces that fit together. However, it does not specify which parts of the paper are particularly challenging or what specific aspects need improvement. The authors might infer that the experiments are difficult to follow, but the comment lacks detailed guidance on how to address these issues. Therefore, the comment is weakly grounded as it does not identify a specific part of the paper, and it is not specific in detailing what needs to be addressed. This aligns with a score of 2.", "verifiability_rationale": "The review point claims that the paper is not easy to follow and lacks a clear intuition for how the pieces fit together. However, it does not provide specific examples or detailed reasoning to support this claim. The comment lacks evidence or references to substantiate why the experiments are difficult to understand or how the presentation could be improved. Without specific examples or detailed justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that it is not easy to follow and lacks a clear intuition for how the pieces fit together. This observation is important as it highlights a fundamental weakness in the paper\"s presentation and structure. However, the comment does not provide specific suggestions or guidance on how the authors might improve the clarity or organization of their work. Without actionable feedback, the authors are left without a clear path to address the issues raised. Therefore, the comment is 3, as it points out a critical area for improvement but lacks depth and specificity in its guidance."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the fairness of training the student and refinement networks simultaneously, suggesting that this might improve the performance of the teacher network. It also requests the inclusion of KID/FID metrics for the teacher network. While the comment implies that the authors should provide these metrics, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement the suggested comparison or what specific metrics to use. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the fairness of training the student and refinement networks simultaneously, suggesting that this might improve the performance of the teacher network. It also requests the inclusion of KID/FID metrics for the teacher network. However, the comment does not specify which part of the paper discusses this training method or where the KID/FID metrics should be included. While the authors might infer that it relates to the methodology or results sections, the lack of explicit references makes it weakly grounded. The comment is specific in its request for metrics, but without clear grounding, it aligns with a score of 2.", "verifiability_rationale": "The review point raises a question about the fairness of training the student and refinement networks simultaneously, suggesting that this might improve the performance of the teacher network. It also requests the inclusion of KID/FID metrics for the teacher network. However, the comment lacks specific reasoning or evidence to support the claim that this training method might improve performance. It does not provide references or examples to substantiate the suggestion, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the fairness of training the student and refinement networks simultaneously, suggesting that this might improve the performance of the teacher network. It also requests the inclusion of KID/FID metrics for the teacher network, which could provide valuable insights into the performance of the teacher network. While the comment identifies a potential issue and provides a specific request for additional metrics, it lacks depth and does not offer detailed guidance on how to address the fairness concern or interpret the KID/FID metrics. The feedback is 3 as it points out an area for improvement but could be more comprehensive with additional suggestions or explanations. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the scaling of the refined region vector, suggesting that it might only scale the most important regions by a factor of two before global pooling. It also asks whether having a scaling variable before the attention weight would help. While the comment implies that the authors should consider this scaling factor, it does not explicitly instruct them to do so or provide specific guidance on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should consider the scaling factor and determine how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 157,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the refined region vector, questioning the scaling factor and suggesting a potential improvement by introducing a scaling variable before the attention weight. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the scaling of the refined region vector, suggesting that it might only scale the most important regions by a factor of two before global pooling. The reviewer provides a logical reasoning by explaining the relationship between the attention weight and the scaling factor. However, the comment lacks specific references or examples to fully substantiate the claim, making it 3. The authors would need to consider the reasoning and potentially conduct further analysis to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a specific concern about the scaling of the refined region vector, suggesting that it might only scale the most important regions by a factor of two before global pooling. It questions whether having a scaling variable before the attention weight would help. This feedback is 3 as it identifies a potential issue with the scaling of the vector and prompts the authors to consider an alternative approach. However, the comment lacks depth and does not provide detailed guidance on how to address this issue or what specific changes might be beneficial. While it points out a potential area for improvement, it does not offer comprehensive or actionable suggestions, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the LLM\"s performance on the ALFRED benchmark, attributing failures to goal misspecification. It explains that the LLM struggles to accurately recover the formal goal predicate, particularly when faced with ambiguities in human language. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to improve the LLM\"s performance or what specific changes should be made to enhance the recovery of formal goal predicates. Without actionable suggestions or concrete steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific issue with the LLM\"s performance on the ALFRED benchmark, particularly regarding goal misspecification. However, it does not specify which part of the paper discusses the LLM\"s performance or where the issue of goal misspecification is detailed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing the issue of goal misspecification and its impact on the LLM\"s performance, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that failures on the ALFRED benchmark are often due to goal misspecification, where the LLM does not accurately recover the formal goal predicate. The comment provides a logical explanation by mentioning the challenges posed by ambiguities in human language. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to further investigate the issue to fully understand and address the problem. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the LLM\"s performance on the ALFRED benchmark, attributing failures to goal misspecification. It explains that the LLM struggles to accurately recover the formal goal predicate, particularly when faced with ambiguities in human language. This feedback is valuable as it highlights a potential weakness in the LLM\"s performance and suggests a specific area for improvement. However, the comment does not provide actionable suggestions or guidance on how the authors might address this issue, such as proposing methods to enhance the LLM\"s ability to interpret and recover formal goal predicates. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point raises concerns about the improvement of the method over SOTA methods like IGEV and suggests that the authors analyze the distribution of disparities produced by IGEV compared to other baselines to determine why the effect is not significantly improved. It also questions whether it is difficult for SamplingGaussian to significantly improve iterative frameworks similar to IGEV. While the comment implies that the authors should conduct additional analysis and provide comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific analyses required and how to conduct them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"this method\" and \"SOTA methods such as IGEV,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the improvement of the method over SOTA methods and suggesting an analysis of the distribution of disparities produced by IGEV compared to other baselines. Additionally, it raises a concern about the difficulty of improving iterative frameworks similar to IGEV. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a claim about the small improvement of the method over SOTA methods like IGEV and questions whether this implies a lack of multipeak distribution problems in iterative optimization schemes similar to IGEV. The reviewer suggests analyzing the distribution of disparities produced by IGEV compared to other baselines to determine why the effect is not significantly improved. Additionally, the reviewer questions the difficulty of improving iterative frameworks similar to IGEV. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion about the small improvement or the need for further analysis. This makes the claim 3, as it requires additional evidence or examples to fully substantiate the claims. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the small improvement of the method over SOTA methods like IGEV and suggests that the authors analyze the distribution of disparities produced by IGEV compared to other baselines to determine why the effect is not significantly improved. This feedback is clear and actionable, as it provides a specific direction for the authors to explore and potentially address a critical issue in their work. Additionally, the comment raises a question about the difficulty of improving iterative frameworks similar to IGEV, which prompts the authors to consider the broader context of their findings. Overall, the comment is 5 as it offers constructive suggestions for improving the draft and provides a clear path for the authors to enhance their work."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper should include a deeper investigation into how specific models, such as GPT4o and InternVL2, behave differently when ReGuide is applied. It specifically mentions the need to present differences in false positive rates (FPR) between models with and without ReGuide for a better comparison. This feedback provides a clear and explicit action for the authors to take, as it specifies what additional analysis should be conducted and what specific data should be presented. The guidance is concrete, making it 5.", "grounding_specificity_rationale": "The comment suggests that the paper should include a deeper investigation into how specific models, such as GPT4o and InternVL2, behave differently when ReGuide is applied. It specifically mentions the need to present differences in false positive rates (FPR) between models with and without ReGuide for a better comparison. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the sections discussing the models and their performance. The suggestion is specific in detailing what additional analysis should be included, making the comment weakly grounded but specific. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the paper should include a deeper investigation into how specific models, such as GPT4o and InternVL2, behave differently when ReGuide is applied. It specifically mentions the need to present differences in false positive rates (FPR) between models with and without ReGuide for a better comparison. This claim is 3 as it provides a specific suggestion for enhancing the paper\"s analysis, but it lacks detailed reasoning or examples to fully substantiate the need for this additional investigation. The authors would need to infer the potential benefits of this analysis themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the paper should delve deeper into how specific models, such as GPT4o and InternVL2, behave differently when ReGuide is applied. It provides a concrete example of how this could be achieved by presenting differences in false positive rates (FPR) between models with and without ReGuide. This feedback is actionable and offers a clear direction for the authors to enhance their analysis, providing valuable guidance for improving the depth and nuance of their conclusions. However, the comment could be more helpful if it included additional suggestions or examples of how to present these differences effectively. Overall, the comment is 4, as it provides a clear path for improvement but could be more comprehensive with further guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the paper is missing ablations and suggests that the authors include results using the GCPG model without pretrained initializations. This provides a clear and concrete action for the authors to take, as it specifies exactly what needs to be added to the draft. The comment is explicit and provides detailed guidance on how to improve the paper, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the missing ablations in the results, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely, the performance gain due to the task formulation and the contribution of pretrained language models. The comment provides a clear and actionable suggestion for the authors to include results using the GCPG model without pretrained initializations. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results are unclear regarding the contribution of the task formulation and pretrained language models. It suggests including results using the GCPG model without pretrained initializations to clarify this. The comment provides a logical reasoning for the claim, suggesting that the current results do not adequately distinguish between the contributions of the task formulation and the pretrained models. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to infer the exact nature of the missing information and how it could be addressed. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, specifically the lack of ablation studies to distinguish between the contributions of the task formulation and the use of pretrained language models. It provides a clear and actionable suggestion by recommending that the authors include results using the GCPG model without pretrained initializations. This feedback is valuable as it guides the authors to address a critical aspect of their work, helping them improve the clarity and robustness of their findings. However, the comment could be more helpful if it offered additional context or examples on how to conduct these ablations effectively. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with further guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that including results on ImageNet could make the proposed method more convincing. However, it does not provide explicit instructions on how to incorporate these results or what specific aspects of the proposed method should be tested on ImageNet. The action is implicit and somewhat vague, as the authors are left to infer that they should include ImageNet results but without detailed guidance on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that including results on ImageNet could make the proposed method more convincing. However, it does not specify which part of the paper should include these results or how they would enhance the method\"s credibility. Without explicit references to sections, figures, or specific aspects of the paper, the authors cannot confidently determine where to incorporate these suggestions. The comment is 1 and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1.", "verifiability_rationale": "The review point suggests that including results on ImageNet could make the proposed method more convincing. However, it does not provide any reasoning, examples, or references to support why ImageNet results would be more convincing or how they would enhance the method\"s credibility. The comment lacks specific details or evidence to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that including results on ImageNet could make the proposed method more convincing. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on how to incorporate ImageNet results or what specific aspects of the method should be tested on ImageNet. The feedback is 3 as it points out a direction for enhancement, but it does not offer detailed or actionable advice, leaving the authors with limited guidance on how to address the suggestion. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the insufficient contribution of the paper, specifically noting that while the authors studied the connection between complementary and model robustness, they did not explore how to leverage this connection to improve robustness. The reviewer suggests that the paper should include more insightful findings or possible solutions beyond the analysis of the connection. While the comment implies that the authors should expand their work to provide more insights, it does not explicitly instruct them on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to add more depth to their findings. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the contribution of the paper, specifically critiquing the lack of further studies on how to leverage the connection between complementary and model robustness to improve robustness. However, it does not specify which part of the paper this critique pertains to, such as a particular section or analysis. The authors can infer that it relates to the conclusion or discussion sections, but this inference is not explicit. The comment is specific in detailing what is missing, namely more insightful findings or possible solutions, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the contribution of the paper is insufficient, specifically noting that the authors studied the connection between complementary and model robustness but did not explore how to leverage this connection to improve robustness. The reviewer suggests that the paper should include more insightful findings or possible solutions beyond the analysis of the connection. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion that the conclusion could be easily obtained. This makes the claim 3, as it requires further elaboration or evidence to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, specifically noting that the contribution is insufficient. It points out that while the authors studied the connection between complementary and model robustness, they did not explore how to leverage this connection to improve robustness. The reviewer suggests that the paper should include more insightful findings or possible solutions beyond the analysis of the connection. This feedback is clear and actionable, as it provides a specific area for improvement and encourages the authors to expand their work to offer more valuable insights. However, the comment could be more helpful if it offered specific suggestions or examples of how the authors might address this issue. Overall, the comment is 4, as it effectively guides the authors toward enhancing the depth and impact of their work."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the choice of focusing on which clusters are \"best\" rather than exploring the differences in representation between them, given the paper\"s motivation. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should reconsider their approach, but it lacks concrete details on how to make this change or what specific aspects of the representation should be explored. As a result, the action is implicit and vague, leaving the authors uncertain about how to apply the feedback. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment questions the focus on identifying the \"best\" clusters rather than exploring the differences in representation between them, given the paper\"s motivation. However, it does not specify which part of the paper this critique pertains to, such as a specific section or analysis, making it difficult for the authors to pinpoint the exact area needing revision. The comment is specific in its critique of the focus on \"best\" clusters, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the focus on identifying the \"best\" clusters rather than exploring the differences in representation between them, given the paper\"s motivation. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this choice is odd or how it deviates from the paper\"s motivation. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment questions the focus of the paper on identifying the \"best\" clusters rather than exploring the differences in representation between them, given the paper\"s motivation. This feedback highlights a potential mismatch between the paper\"s objectives and the approach taken, which could be a significant issue. However, the comment does not provide specific suggestions or guidance on how the authors might address this concern or what alternative approaches could be considered. While it identifies a potential weakness, it lacks actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to correct the caption for Figure 7, specifying that it should be changed from \"Node Dynamics\" to \"Edge Dynamics.\" This is a clear and direct action that the authors can take to improve their draft. The comment provides concrete guidance on what needs to be changed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the caption, indicating that it should be corrected from \"Node Dynamics\" to \"Edge Dynamics.\" This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a factual statement about the incorrect caption for Figure 7 and suggests a correction. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is highly specific and actionable, as it identifies a clear error in the caption for Figure 7. By pointing out the incorrect label (\"Node Dynamics\" instead of \"Edge Dynamics\"), the comment provides the authors with a precise and straightforward correction to make. This feedback is valuable as it directly addresses a specific issue in the paper, allowing the authors to make a simple but important improvement. However, the comment could be more helpful if it provided context or explained why the correction is necessary. Overall, the comment is 4, as it guides the authors toward a specific improvement that can enhance the clarity and accuracy of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the traditional DCI framework, suggesting that explicitness (E) and size (S) may already be considered in the evaluation. It provides an example of how the disentanglement (D) of different representation methods might be evaluated using a fixed capacity of probing (f) and a fixed latent size. The reviewer also points out that DCI and ES may be entangled, as changing the capacity of probing or the latent size would affect the DCI evaluation. However, the comment does not provide explicit guidance on how the authors should address these concerns or suggest specific actions to improve the evaluation. The feedback is 3 as it highlights an area for clarification, but it lacks concrete steps for the authors to follow. Therefore, it aligns with a score of 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"traditional DCI framework,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with evaluating disentanglement (D) using a fixed capacity of probing (f) and a fixed latent size, as well as the potential entanglement between DCI and ES. The comment provides specific examples and reasoning, making it clear what needs to be addressed. Therefore, this comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point raises a concern about the traditional DCI framework, suggesting that explicitness (E) and size (S) may already be considered in the evaluation. It provides an example of how the disentanglement (D) of different representation methods might be evaluated using a fixed capacity of probing (f) and a fixed latent size. The reviewer also points out that DCI and ES may be entangled, as changing the capacity of probing or the latent size would affect the DCI evaluation. However, the comment lacks specific references or detailed reasoning to fully substantiate the claim about the entanglement between DCI and ES. While it provides some logical reasoning, it is not 5 due to the lack of detailed evidence or examples. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment raises a concern about the traditional DCI framework, suggesting that explicitness (E) and size (S) may already be considered in the evaluation. It provides an example of how the disentanglement (D) of different representation methods might be evaluated using a fixed capacity of probing (f) and a fixed latent size. The comment also points out that DCI and ES may be entangled, as changing the capacity of probing or the latent size would affect the DCI evaluation. However, the comment lacks specific suggestions or guidance on how the authors might address these concerns or improve their evaluation methodology. While it identifies potential issues, it does not provide actionable feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to clarify which effects are within the range of standard deviation fluctuations and which are improvements brought by the SoRA method. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be addressed in their draft. The comment is specific and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental section\" of the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it clearly specifies the issue of missing standard deviation after multiple experiments and the need to clarify whether the improvements are due to random fluctuations or the SoRA method. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the standard deviation after multiple experiments is not provided, which may lead to the conclusion that the improvement brought by SoRA is limited due to random fluctuations. However, the comment does not provide specific examples or detailed reasoning to support this claim. The suggestion to clarify which effects are within the range of standard deviation fluctuations and which are improvements brought by SoRA is logical but lacks concrete evidence or references. Therefore, the claim is 3, as it provides a logical basis but requires more detailed justification or examples to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific issue in the experimental section, where the standard deviation after multiple experiments is not provided. It suggests that this lack of information may lead to the conclusion that the improvement brought by SoRA is limited due to random fluctuations. The comment provides a clear and actionable suggestion for the authors to clarify which effects are within the range of standard deviation fluctuations and which are improvements brought by the SoRA method. This feedback is valuable as it directs the authors to a critical area for improvement in their experimental analysis, offering a concrete step to enhance the clarity and robustness of their results. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out several issues with the organization and layout of the paper, including the font size of annotations in figures, the placement of figures and tables, and formatting errors. While the comment identifies specific problems, it does not provide explicit guidance on how to address these issues or suggest specific actions for improvement. The authors can infer that they need to improve the organization and layout of their paper, but the comment lacks concrete details on how to achieve this. Therefore, the comment is 3, as it highlights areas for improvement but does not provide detailed instructions on how to implement those changes.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific issues with the organization and layout of the paper, including the font size of annotations in figures, the placement of figures and tables, and formatting errors. The authors can accurately identify the parts of the paper being addressed, such as Figure 1, Figure 2, and Table 2. Additionally, the comment is specific because it details what is wrong with each of these elements, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is not well organized and provides specific examples of issues with the layout, such as font size, figure placement, and table insertion. However, it lacks detailed reasoning or references to support these claims, such as comparisons to other wellorganized papers or guidelines for proper layout. The comment provides some evidence through specific examples, but it does not fully substantiate the claim with comprehensive reasoning or references. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed justification to be fully convincing.", "helpfulness_rationale": "The review comment identifies several specific issues with the organization and layout of the paper, such as font size, figure placement, and table insertion. It provides clear and actionable feedback by pointing out these specific problems, which can help the authors improve the readability and presentation of their work. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided guidance on improving the overall organization of the paper. Despite this, the feedback is 4 as it directs the authors to specific areas that need attention, allowing them to make targeted improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the practicality and safety of the interventions discussed in the paper, suggesting that the authors should consider these aspects when thinking about querying in the real world. However, it does not provide explicit guidance on how to address this concern or what specific steps the authors should take to evaluate the practicality and safety of their interventions. The action is implicit and somewhat vague, as the authors are left to infer that they need to assess the practicality and safety of their interventions but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the practicality and safety of the interventions discussed in the paper, suggesting that the authors should consider these aspects when thinking about querying in the real world. However, it does not specify which part of the paper discusses these interventions, making it weakly grounded. The comment is specific in its suggestion to consider practicality and safety, but without clear references to specific sections or examples, the authors may find it challenging to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the practicality and safety of the interventions discussed in the paper, suggesting that the authors should consider these aspects when thinking about querying in the real world. However, the comment does not provide specific examples, reasoning, or references to support why these interventions might be impractical or unsafe. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises an important consideration regarding the practicality and safety of the interventions discussed in the paper. It suggests that the authors should think about whether these interventions are feasible and safe for querying in the real world. This feedback is relevant and provides a valuable perspective for the authors to consider when refining their work. However, the comment could be more helpful if it offered specific examples or suggestions on how to assess the practicality and safety of the interventions. Despite this, the comment is 4 as it prompts the authors to address an important aspect of their work that could impact its applicability and realworld relevance. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point expresses a lack of conviction regarding the idea that images and their augmentations should be treated separately, suggesting that they can be interchangeable. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or what changes, if any, should be made to the draft. The comment lacks actionable details, leaving the authors without a clear understanding of how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses a lack of conviction regarding the idea that images and their augmentations should be treated separately, suggesting that they can be interchangeable. However, it does not specify which part of the paper this idea is discussed in, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the treatment or interchangeability are unclear or problematic. Without clear grounding and specificity, the authors cannot effectively address the feedback. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses a lack of conviction regarding the idea that images and their augmentations should be treated separately, suggesting that they can be interchangeable. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the reviewer\"s skepticism or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses a lack of conviction regarding the idea that images and their augmentations should be treated separately, suggesting that they can be interchangeable. However, it does not provide any specific reasoning or examples to support this claim, nor does it offer suggestions for how the authors might address this concern. Without actionable feedback or detailed guidance, the authors are left without a clear understanding of what needs to be improved or how to proceed. Therefore, the comment is 1, as it does not provide any meaningful direction for the authors to enhance their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the authors should evaluate the proposed method\"s performance gain by comparing it to baseline detection or parsing techniques separately. This feedback is explicit and provides a clear action for the authors to take, which is to conduct additional evaluations to support their claims. The comment is also concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed method\" and its two major components, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the contribution of each component to the performance gain and suggests evaluating the proposed approach separately against baseline detection or parsing techniques. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the contribution of each component in the proposed method and suggests evaluating it separately against baseline detection or parsing techniques. This claim is 3 as it highlights a potential gap in the paper\"s evaluation, but it lacks specific examples or references to support the suggestion. The authors would need to consider the reviewer\"s point and potentially conduct additional experiments to address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the evaluation of the proposed method. It points out that the contribution of each component to the performance gain is unclear and suggests evaluating the proposed approach separately against baseline detection or parsing techniques. This feedback is clear and actionable, providing the authors with a concrete step to take to better support their claims. By addressing this feedback, the authors can enhance the clarity and robustness of their evaluation, which is crucial for the credibility of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a concern about the clarity of how the method behaves without the Lipschitz Hessian assumption. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion of what additional information or analysis should be included to clarify this point. Without actionable advice or concrete steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the clarity of how the method behaves without the Lipschitz Hessian assumption. However, it does not specify which part of the paper this issue pertains to, such as a specific section or analysis where this assumption is discussed. Without explicit references or context, the authors cannot confidently determine which part of the paper needs revision. Additionally, the comment lacks specificity regarding what needs to be clarified or improved. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point questions the clarity of how the method behaves without the Lipschitz Hessian assumption. However, it does not provide any supporting evidence, reasoning, or examples to justify why this assumption is important or how its absence affects the method. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the clarity of how the method behaves without the Lipschitz Hessian assumption. This is a relevant observation that could impact the understanding and applicability of the method. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or clarify the behavior of the method. Without actionable feedback or specific recommendations, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that some of the pieces are using existing methods, such as equation (12), and that the presentation of these methods is vague. However, it does not provide explicit guidance on how the authors should address this issue or improve the clarity of the presentation. The comment implies that the authors should clarify the methods used, but it lacks concrete suggestions on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment mentions specific elements, such as \"equation (12)\" and the \"presentation of these methods,\" which allows the authors to identify the parts of the paper being addressed. However, it does not specify what aspects of the presentation are vague or how they could be improved. The comment lacks detailed guidance on what needs to be clarified or how to enhance the clarity. Therefore, the comment is fully grounded but underspecific, aligning with a score of 4.", "verifiability_rationale": "The review point claims that some of the pieces are using existing methods, such as equation (12), and that the presentation of these methods is vague. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact issues or how to address them. The lack of detailed justification or evidence makes the claim 2, as it requires more information to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that some of the pieces are using existing methods and that the presentation of these methods is vague. This feedback is 3 as it points out a potential area for improvement, specifically the clarity of the presentation. However, the comment lacks detailed guidance or suggestions on how the authors might clarify or enhance the presentation of these methods. Without specific advice or examples, the authors may find it challenging to address the issue effectively. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to include the results for all four datasets in Table 4. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific and concrete step, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the results for all four datasets. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Table 4 is incomplete because it lacks results for all four datasets. However, it does not provide any supporting evidence, reasoning, or references to justify why this is a significant issue or how it affects the paper\"s contribution. Without additional context or explanation, the claim remains 1, as the authors may not understand the importance of including all datasets in the table. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 4, noting that it is incomplete because it lacks results for all four datasets. This feedback is clear and actionable, as it provides a direct suggestion for improvement by instructing the authors to include the missing results. By addressing this point, the authors can enhance the completeness and comprehensiveness of their results, which is a valuable contribution to the paper. However, the comment could be more helpful if it explained why including all datasets is important or how it impacts the paper\"s conclusions. Overall, the comment is 4 as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point claims that the contribution of the work is incremental and that the proposed pipeline is not impressive or novel, but rather a collection of tricks to improve defense evaluation. However, it does not provide any specific guidance or suggestions on how the authors could improve their work or address these concerns. The comment lacks actionable details, such as recommending specific changes or improvements that could be made to enhance the novelty or impact of the work. As a result, the authors are left without a clear understanding of what steps to take to address the feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the technical contribution of the paper, stating that the proposed pipeline is not impressive or novel but rather a collection of tricks to improve defense evaluation. However, it does not specify which part of the paper this critique is based on, such as a particular section, figure, or experiment. Without explicit references, the authors cannot confidently determine which aspects of the paper are being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity as it does not provide detailed feedback on what aspects of the pipeline are considered tricks or how they could be improved. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the contribution of the work is incremental and that the proposed pipeline is not impressive or novel, but rather a collection of tricks to improve defense evaluation. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without concrete evidence or detailed justification, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment critiques the technical contribution of the paper, stating that the proposed pipeline is not impressive or novel but rather a collection of tricks to improve defense evaluation. However, it does not provide specific examples or detailed feedback on what aspects of the pipeline are considered tricks or how they could be improved. Without actionable suggestions or guidance, the authors are left without a clear understanding of how to address the critique or enhance the novelty of their work. Therefore, the comment is 1, as it lacks depth and specificity, leaving the authors without a clear path for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the triples denoted as $(e_1, r, e_2)$ should be presented in a tuplelike structure rather than as sets. This is a clear and direct action for the authors to take, as it specifies exactly what needs to be changed in the draft. The comment provides concrete guidance on how to improve the presentation of the data, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 122,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the presentation of triples, suggesting that they should be shown in a tuplelike structure rather than as sets. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the presentation of triples as $(e_1, r, e_2)$ should be changed to a tuplelike structure instead of sets. However, the comment does not provide any reasoning or evidence to support why this change is necessary or how it would improve the clarity or understanding of the data. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the presentation of data in the paper. By recommending that the triples denoted as $(e_1, r, e_2)$ should be presented in a tuplelike structure rather than as sets, the reviewer offers a clear and concrete way for the authors to enhance the clarity and readability of their work. This feedback is valuable as it directly addresses a potential confusion in the data representation, which could help the authors improve the overall quality of their draft. However, the comment could be more helpful if it explained why this change is important or how it might impact the understanding of the data. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional context."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the scalability of optimal quantization, noting that it is mentioned in the paper and is a bottleneck for achieving fast convergence in big data/big model settings. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the scalability of their method. The feedback lacks actionable details, such as recommending specific techniques or approaches to enhance scalability. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the scalability issue of optimal quantization, which is mentioned in the paper. It also mentions the paper\"s aim to speed up VI by fast convergence, which is a bottleneck for big data/big model settings. However, the comment does not specify which part of the paper discusses these issues, making it weakly grounded. The comment is specific in detailing the scalability problem and its impact on the paper\"s objectives, but without explicit references to sections or parts of the paper, the authors may struggle to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that optimal quantization is not scalable, which is mentioned in the paper, and that it is a bottleneck for achieving fast convergence in big data/big model settings. The comment provides a logical reasoning by stating that even with clustering before, the quantization process is costly in terms of both the number of data points and the dimensionality. However, the comment lacks specific examples or references to support the claim about the scalability issue or the bottleneck nature of quantization. This makes the claim 3, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the scalability of optimal quantization, which is mentioned in the paper as a bottleneck for achieving fast convergence in big data/big model settings. It highlights the potential loss of the method\"s point due to this scalability issue. However, the comment lacks specific suggestions or guidance on how the authors might address this scalability problem or improve the method\"s scalability. Without actionable advice or detailed feedback, the authors are left with a general understanding of the issue but without a clear path to improvement. Therefore, the comment is 3, as it points out a critical weakness but does not provide sufficient guidance for the authors to address it effectively."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point raises a concern about the assumption that the Pearson correlation coefficient (PCC) is a more relaxed constraint compared to the KL divergence due to its invariance to scale and shift. It suggests that the authors should provide a gradient comparison between KL and PCC to support this claim. While the comment implies that the authors should include this comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide the gradient comparison. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"matching metric,\" specifically the Pearson correlation coefficient (PCC), which allows the authors to accurately identify the part of the paper being addressed. It also provides specific feedback by questioning the assumption that PCC is a more relaxed constraint compared to KL divergence and suggesting that the authors should provide a gradient comparison between KL and PCC. This level of detail and specificity helps the authors understand what needs to be addressed in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the assumption that the Pearson correlation coefficient (PCC) is a more relaxed constraint compared to KL divergence is not convincing. It provides a logical reasoning by comparing the gradient distributions of KL divergence and MSE loss, suggesting that the gradient distribution defines the constraint strength of a loss function. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened by including specific examples or references to support the comparison between PCC and KL divergence. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a detailed critique of the assumption that the Pearson correlation coefficient (PCC) is a more relaxed constraint compared to KL divergence. It offers a logical explanation by comparing the gradient distributions of KL divergence and MSE loss, suggesting that the gradient distribution defines the constraint strength of a loss function. The comment is 5 as it not only identifies a potential weakness in the paper but also offers a clear and actionable suggestion for improvement by recommending a gradient comparison between KL and PCC. This feedback empowers the authors to address a specific issue and enhance the rigor of their analysis, making it highly valuable for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises questions about the possibility of Generalized Pattern Inference (GPI) with noise added reproducing the data similarly well as the original GPI model. It also suggests considering other measures, such as behavioral trajectories or time to goal, to demonstrate that GPI cannot have as good a fit with behavioral data. Additionally, the comment suggests discussing the suitability of the approach for modeling pattern separation tasks, for which behavioral data is available. While the comment implies that the authors should consider these questions and discussions, it does not explicitly instruct them to do so. The actions are implicit and somewhat vague, as the authors need to infer that they should address these points. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the possibility of GPI with noise added reproducing the data similarly well and suggests considering other measures, such as behavioral trajectories or time to goal, to demonstrate the limitations of GPI. Additionally, it suggests discussing the suitability of the approach for modeling pattern separation tasks, for which behavioral data is available. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the effectiveness of Generalized Pattern Inference (GPI) with noise added, suggesting that it might not reproduce the data as well as the original GPI model. It also proposes considering other measures, such as behavioral trajectories or time to goal, to demonstrate the limitations of GPI. The comment provides a logical reasoning by questioning the robustness of GPI with noise added and suggesting alternative measures to evaluate its performance. However, it lacks specific references or detailed examples to fully substantiate the claim. Therefore, the comment is 3, as it provides a logical basis for the claim but requires more detailed evidence or examples to be 5.", "helpfulness_rationale": "The review comment raises several important questions and suggestions that could enhance the paper. It questions the possibility of Generalized Pattern Inference (GPI) with noise added reproducing the data similarly well as the original GPI model, suggesting that other measures, such as behavioral trajectories or time to goal, could be considered to demonstrate the limitations of GPI. Additionally, it highlights the suitability of the approach for modeling pattern separation tasks, for which behavioral data is available, and suggests discussing this aspect further. These points provide clear and actionable feedback that could help the authors improve their draft by addressing specific concerns and expanding the discussion. However, the comment could be more helpful if it offered more detailed guidance on how to incorporate these suggestions or addressed potential challenges in implementing them. Overall, the comment is 4, as it effectively guides the authors toward enhancing their work."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should conduct a comparison between the \"small learning rate for attention parameters\" benchmark and the proposed approach, if they have the resources to do so. While the comment implies an action\u2014conducting a comparison\u2014it does not explicitly instruct the authors to perform this analysis. Additionally, it lacks concrete guidance on how to conduct the comparison or what specific aspects to focus on. The action is implicit and somewhat vague, making it barely actionable.", "grounding_specificity_rationale": "The comment suggests a comparison between the \"small learning rate for attention parameters\" benchmark and the proposed approach. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. This lack of explicit grounding makes it difficult for the authors to identify the exact part of the paper being addressed. The comment is specific in suggesting a comparison, but without clear grounding, it is 3. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point suggests a comparison between the \"small learning rate for attention parameters\" benchmark and the proposed approach. However, it does not provide any reasoning, evidence, or references to support why this comparison is important or how it might impact the paper. The suggestion is based on the reviewer\"s personal interest, but it lacks the necessary justification or context to be considered verifiable. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The comment suggests a comparison between the \"small learning rate for attention parameters\" benchmark and the proposed approach, which could provide valuable insights into the effectiveness of the proposed method. However, the comment lacks specificity and does not provide detailed guidance on how to conduct this comparison or what aspects to focus on. While it identifies a potential area for exploration, the feedback is somewhat vague and does not offer actionable steps for the authors to improve their draft. Therefore, the comment is 3, as it provides a direction for further analysis but lacks depth and detail."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that the authors should reproduce the results of the methods they are comparing using the same setting as the original paper, specifically using AdamW with cosine lr instead of Adam with fixed lr. This is a clear and direct action for the authors to take, as it provides a specific method for improving the fairness of the comparison. The comment also explains why this is necessary, highlighting that most recent methods have their code released. Therefore, the comment is 5, as it provides a concrete and explicit action for the authors to follow.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed method\"s use of AdamW with cosine lr for training, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the unfairness of comparing methods using Adam with fixed lr, suggesting that the authors should reproduce the results using the same setting as the original paper. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method\"s comparison with other methods is unfair due to the use of AdamW with cosine lr for training, while the other methods use Adam with fixed lr. The reviewer suggests that the authors should reproduce the results using the same setting as the original paper, as most recent methods have their code released. This claim is 3 as it provides a logical reasoning for the unfairness of the comparison and suggests a specific action for improvement. However, it lacks detailed examples or references to specific methods or studies that support the claim, which would strengthen the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the fairness of the comparison between the proposed method and other methods, specifically noting that the proposed method uses AdamW with cosine lr for training, while the other methods use Adam with fixed lr. The reviewer suggests that the authors should reproduce the results using the same setting as the original paper, as most recent methods have their code released. This feedback is clear and actionable, providing the authors with a specific direction to improve the fairness and validity of their comparisons. By addressing this issue, the authors can enhance the credibility and robustness of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point expresses curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. However, it does not provide any explicit or implicit action for the authors to take. There is no guidance on whether the authors should investigate this combination, include it in their analysis, or address it in any way. The comment lacks actionable details, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. However, it does not specify which part of the paper this curiosity pertains to, such as a specific section or analysis where this combination could be discussed. Without explicit references to sections or figures, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the performance or combination are of interest. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. However, it does not contain any claims, opinions, or suggestions that require verification. It is a factual statement expressing interest in a specific combination, which does not necessitate justification or evidence. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment expresses curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. While it acknowledges that this is not necessary, it prompts the authors to consider this combination, which could potentially lead to a more comprehensive analysis or comparison. However, the comment lacks specificity and does not provide any guidance on how the authors might explore this combination or what aspects to focus on. Without actionable suggestions or detailed feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the plots are terrible and provides specific reasons for this assessment, such as their small size, hardtodistinguish colors, poorly labeled axes, and visually similar labels. The reviewer emphasizes that these plots are the main presentation of the experimental results and should be much clearer. This feedback is direct and provides concrete guidance on what needs to be improved, such as increasing plot size, distinguishing colors, labeling axes, and ensuring label clarity. The authors know exactly what changes to make to enhance the clarity of their plots, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the plots, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the plots, such as their small size, hardtodistinguish colors, poorly labeled axes, and visually similar labels. The reviewer provides clear guidance on what needs to be improved, making this comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the plots are \"terrible\" due to their small size, hardtodistinguish colors, poorly labeled axes, and visually similar labels. The reviewer provides specific examples of these issues, such as the difficulty in distinguishing between pink and red colors, and the confusion between \"sdropout(tr)\" and \"edropout(tr)\" labels. This level of detail supports the claim, making it 4. However, the comment could be strengthened by providing suggestions on how to improve the plots, which would further enhance its verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the quality of the plots presented in the paper. It identifies several issues, such as the small size of the plots, difficulty in distinguishing colors, poorly labeled axes, and visually similar labels. By pointing out these specific problems, the comment offers clear guidance on how to improve the clarity and presentation of the experimental results, which are crucial for the paper\"s impact. This feedback is 5 as it empowers the authors to make significant improvements to their draft, enhancing its readability and effectiveness. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point notes that the performance gains are not very high, with most metrics showing a difference of less than 1% between the baseline and the best approach. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how to address the issue of low performance gains or suggestions for improvement. As a result, the authors are left without any actionable steps to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the performance gains of the paper, specifically noting that the differences between the baseline and the best approach are less than 1% for most metrics. However, it does not specify which part of the paper this observation is based on, such as a particular section or table that discusses performance metrics. Without explicit references, the authors cannot confidently determine which part of the paper the comment pertains to. Additionally, the comment lacks specificity regarding what needs to be addressed or improved in terms of performance gains. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the performance gains are not very high, with most metrics showing a difference of less than 1% between the baseline and the best approach. This is a factual statement based on the observed data, as it describes the numerical differences in performance. However, it does not provide any additional context, reasoning, or examples to support or explain why these differences are significant or not. Therefore, the claim is 3, as it presents a numerical observation but lacks detailed justification or analysis to fully substantiate the claim. Authors would need to infer the significance of these differences themselves, making the comment 3.", "helpfulness_rationale": "The review comment points out that the performance gains are not very high, with most metrics showing a difference of less than 1% between the baseline and the best approach. While this observation highlights a potential limitation in the paper, it does not provide any actionable feedback or suggestions for improvement. The comment lacks depth and does not offer guidance on how the authors might address this issue or enhance the performance gains. As a result, the comment is not particularly helpful for the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the utility of specific information provided in the feedback network, such as the incorrect phrase and corrected phrase, and the type of mistake. It asks for performance metrics with and without these types of information, as well as with just natural language feedback. While the questions imply that the authors should consider these aspects, they do not explicitly instruct the authors to conduct specific analyses or make changes to their draft. The action is implicit and somewhat vague, as the authors can infer that they need to explore these aspects but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the utility of specific information provided in the feedback network, such as the incorrect phrase and corrected phrase, and the type of mistake. It also asks for performance metrics with and without these types of information, as well as with just natural language feedback. However, the comment does not specify which part of the paper these questions pertain to, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but without explicit references, it is challenging to pinpoint the exact location. The comment is specific in its questions about the performance metrics, but without grounding, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions seeking clarification and additional information about the feedback network. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the utility of specific information provided in the feedback network, such as the incorrect phrase and corrected phrase, and the type of mistake. It asks for performance metrics with and without these types of information, as well as with just natural language feedback. This feedback is 3 as it prompts the authors to consider the impact of different types of information on the performance of their feedback network. However, it lacks specific suggestions or guidance on how to address these questions or improve the draft. While it identifies an area for exploration, it does not provide actionable steps for the authors to take. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that Table 1 should include standard deviations and that the experiments should be more extensive to strengthen the submission. However, it does not provide specific guidance on how to make the experiments more extensive or what additional data or analyses should be included. The comment implies an action but lacks concrete details on how to implement it, making it 3. The authors can infer that they need to add standard deviations to Table 1 and potentially expand their experiments, but the lack of specific guidance limits the actionability of the comment.", "grounding_specificity_rationale": "The comment mentions \"Table 1\" and suggests that it should include standard deviations, indicating a specific part of the paper that needs attention. However, it does not specify what aspects of the experiments should be more extensive or provide detailed guidance on how to achieve this. While the comment is fully grounded as it explicitly mentions \"Table 1,\" it lacks specificity regarding the improvements needed in the experiments. Therefore, this comment is fully grounded but underspecific, aligning with a score of 4.", "verifiability_rationale": "The review point suggests that Table 1 should include standard deviations and that the experiments should be more extensive. However, it does not provide any specific reasoning, examples, or references to support why the experiments are insufficient or how including standard deviations would strengthen the submission. The comment lacks detailed justification or evidence, making it difficult for the authors to understand and address the feedback. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 1, noting that it does not include standard deviations. It also suggests that the experiments could be more extensive, providing a clear and actionable suggestion for improvement. However, the comment lacks further details or examples on how to make the experiments more extensive, which would be beneficial for the authors to fully understand and address the feedback. While it points out a relevant area for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the experiments should be extended to include other architectures and classification tasks beyond neural networks and image classification. While the comment implies that the authors should expand their experiments, it does not provide specific guidance on which architectures or classification tasks to consider or how to implement these changes. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experiments should be extended to include other architectures and classification tasks beyond neural networks and image classification. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing revision. The comment is specific in suggesting the need for broader experimentation, but it is 1 because it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the experiments should be extended to include other architectures and classification tasks beyond neural networks and image classification. This is a request for additional experiments, which is not a claim but rather a suggestion for improvement. The comment does not contain any subjective opinions, judgments, or claims that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment suggests that the experiments should be extended to include other architectures and classification tasks beyond neural networks and image classification. This feedback is 3 as it points out a limitation in the current scope of the experiments and encourages the authors to broaden their evaluation. However, the comment lacks specific guidance on which other architectures or classification tasks should be considered, leaving the authors with a general direction but no detailed steps to take. To be more helpful, the comment could include suggestions or examples of alternative architectures or tasks that might be relevant. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the impact of mitigation strategies on the overall performance of the model, suggesting that there might be a tradeoff between reducing a particular behavior and maintaining high performance. However, it does not provide explicit guidance or suggestions on how the authors should address this concern or evaluate the impact of these strategies. The comment implies that the authors should consider the potential effects of these strategies on the model\"s utility, but it lacks concrete steps or actions for the authors to take. As a result, the comment is vague and does not offer actionable advice, making it barely actionable.", "grounding_specificity_rationale": "The comment addresses the impact of mitigation strategies on the overall performance of the model, specifically questioning whether these strategies might significantly impair the model\"s utility. However, it does not specify which part of the paper discusses these mitigation strategies or where the authors should consider their impact. The authors can infer that it relates to the sections discussing model performance or mitigation strategies, but the comment lacks full grounding as it does not explicitly mention these sections. The comment is specific in detailing the concern about the tradeoff between reducing a particular behavior and maintaining high performance, but it does not provide detailed guidance on how to address this issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the impact of mitigation strategies on the overall performance of the model, suggesting that there might be a tradeoff between reducing a particular behavior and maintaining high performance. The comment provides a logical reasoning by pointing out that if these mitigation strategies significantly impair the model\"s utility, it might deter their adoption. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to further explore and substantiate the potential tradeoffs themselves to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the mitigation strategies used in the paper, specifically questioning their impact on the overall performance of the model. It highlights a common tradeoff between reducing a particular behavior and maintaining high performance, suggesting that if the mitigation strategies significantly impair the model\"s utility, it might deter their adoption. This feedback is 3 as it points out a critical area for consideration and potential consequences, prompting the authors to evaluate the effectiveness of their mitigation strategies. However, the comment lacks specific suggestions or guidance on how to address this concern, such as recommending alternative strategies or providing examples of similar tradeoffs in other works. Therefore, while it identifies an important issue, it does not fully support the authors in improving their draft, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the results presented in Table 2 are insufficient to prove the benefits of the proposed methods. It suggests that additional experiments or more indepth analysis are necessary to better justify the claims in the paper. The comment provides a clear and direct action for the authors to take, which is to conduct further experiments or analysis to strengthen their claims. The feedback is explicit and concrete, giving the authors a clear understanding of what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the results, noting that the proposed approaches only outperform the baselines in one setup out of three and that there is no consistent trend in the results. The comment further suggests that additional experiments or more indepth analysis are needed to better justify the claims. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point claims that the results presented in Table 2 are insufficient to prove the benefits of the proposed methods. It supports this claim by pointing out that the proposed approaches only outperform the baselines in one setup out of three and that there is no consistent trend in the results. This provides a logical reasoning for the claim, as it highlights the lack of robustness and consistency in the results. However, the comment could be strengthened by providing specific examples or references to support the claim further. Overall, the claim is 4, as it provides a clear rationale but lacks detailed evidence or references. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the results presented in Table 2, noting that the proposed approaches only outperform the baselines in one setup out of three and that there is no consistent trend in the results. This feedback is valuable as it highlights a potential weakness in the paper\"s claims about the effectiveness of the proposed methods. The comment suggests that additional experiments or more indepth analysis are necessary to better justify the claims, providing clear and actionable guidance for the authors to improve their draft. However, the comment could be more helpful if it offered specific suggestions on what additional experiments or analyses might be beneficial. Overall, the comment is 4 as it effectively points out a critical area for improvement and provides a direction for further work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper would benefit from a more detailed comparison with related work, specifically focusing on the time complexity and competitiveness of prior art. While the comment implies that the authors should include a more detailed comparison, it does not provide specific guidance on how to conduct this comparison or what aspects to focus on. The action is implicit and somewhat vague, as the authors are left to infer the details of the comparison themselves. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper would benefit from a more detailed comparison with related work, specifically focusing on the time complexity and competitiveness of prior art. However, it does not specify which part of the paper this comparison should be included in, such as a specific section or table. The authors can infer that it relates to the discussion of related work, but the lack of explicit grounding makes it difficult to pinpoint the exact part of the paper being addressed. The comment is specific in suggesting a detailed comparison, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper would benefit from a more detailed comparison with related work, specifically focusing on time complexity and competitiveness. However, the comment does not provide specific examples or references to prior art that could be used for comparison, nor does it explain why this comparison is necessary or how it would enhance the paper. Without detailed justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the paper would benefit from a more detailed comparison with related work, particularly focusing on time complexity and competitiveness. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their draft by including a more comprehensive analysis of their work in relation to existing literature. However, the comment could be more helpful if it offered examples of how to conduct this comparison or suggested specific aspects to consider. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the method, ODA, has learned a policy to imitate problemsolving but does not clearly explain how it improves performance and computation speed compared to just using ODA. While the comment identifies a gap in the explanation, it does not provide explicit guidance on how the authors should address this issue. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide a clearer explanation of the method\"s advantages. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ODA,\" one of the methods for solving the MOIP problem, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the method has learned a policy to imitate problemsolving but does not clearly explain how it improves performance and computation speed compared to just using ODA. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the method, ODA, has learned a policy to imitate problemsolving but does not clearly explain how it improves performance and computation speed compared to just using ODA. However, the comment lacks specific examples, detailed reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the method, ODA, has learned a policy to imitate problemsolving but does not clearly explain how it improves performance and computation speed compared to just using ODA. This feedback is 3 as it points out a gap in the explanation of the method\"s advantages, prompting the authors to clarify their claims. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered examples of how other methods have improved performance. Overall, the comment is 3 as it directs the authors\" attention to an area needing clarification but lacks depth and actionable guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the logic behind the comparison of the proposed method with specific references, such as [9] and [16]. It questions the rationale for the order of comparison and the focus on computational cost. The reviewer also expresses confusion about the significance of computational cost in the context of the paper. While the comment highlights areas of confusion, it does not provide explicit instructions or suggestions for the authors to address these issues. The action is implicit and somewhat vague, as the authors are left to infer what changes might be necessary to clarify the logic and discussion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the logic behind the comparison of the proposed method with specific references, such as [9] and [16], and the focus on computational cost. It also expresses confusion about the significance of computational cost in the context of the paper. However, the comment does not specify which part of the paper these comparisons are made in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but the lack of explicit references makes it challenging to pinpoint the exact location. The comment is specific in detailing the issues with the comparison and the focus on computational cost, but the lack of grounding limits its effectiveness. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the logic and rationale behind the comparisons made in the paper, specifically questioning the order of comparisons and the focus on computational cost. However, it does not provide any specific evidence, reasoning, or references to support these questions. The comment lacks detailed justification or examples that would help the authors understand the basis of the reviewer\"s concerns. As a result, the claim is 1, as it does not provide sufficient information for the authors to address the issues raised. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises several questions about the logic and rationale behind the comparisons made in the paper, specifically questioning the order of comparisons and the focus on computational cost. It also expresses confusion about the significance of computational cost in the context of the paper. While the comment identifies areas of potential confusion, it lacks specific suggestions or guidance on how the authors might address these issues. The feedback is 3 as it prompts the authors to clarify their reasoning and provide more detailed explanations, but it does not offer actionable steps or detailed advice for improvement. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about how the PL condition used in the paper compares to the PL conditions proposed in a specific reference, \"Global Convergence of ArbitraryBlock Gradient Methods for Generalized Polyak\u00c5\u0081ojasiewicz Functions\". However, it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on whether the authors should address this comparison, how they should do so, or what implications it might have for their work. Without any actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the comparison of the PL condition used in the paper with those proposed in a specific reference, \"Global Convergence of ArbitraryBlock Gradient Methods for Generalized Polyak\u00c5\u0081ojasiewicz Functions.\" However, it does not specify which part of the paper this comparison should be made in, nor does it provide details on what aspects of the PL conditions should be compared. This lack of explicit reference to a specific section or element of the paper makes it difficult for the authors to pinpoint the exact area needing attention. The comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification on the comparison of the PL condition used in the paper with those proposed in a specific reference. It does not contain a claim or opinion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the comparison of the PL condition used in the paper with those proposed in a specific reference. While it identifies a potential area for further exploration or clarification, it lacks depth and does not provide specific guidance or suggestions on how the authors might address this comparison or its implications for their work. The comment highlights a gap in the paper but does not offer actionable feedback or insights to help the authors improve their draft. Therefore, it is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the need for the authors to discuss the impact of adding additional parameters and additional computational effort due to the multistage training and multiple discriminators. It suggests that this analysis is necessary for a fair comparison with the baseline [31, 33]. While the comment implies that the authors should include this analysis, it does not provide specific guidance on how to conduct this analysis or what aspects to focus on. The action is implicit and somewhat vague, as the authors can infer the need for additional analysis but may not be entirely sure of the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"idea of jointly discovering, hallucinating, and adapting,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of discussion on the impact of adding additional parameters and computational effort due to the multistage training and multiple discriminators. Additionally, it suggests that the authors should provide this analysis for a fair comparison with the baseline [31, 33]. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper lacks discussion on the impact of adding additional parameters and computational effort due to the multistage training and multiple discriminators. It suggests that this analysis is necessary for a fair comparison with the baseline [31, 33]. However, the comment does not provide specific examples or detailed reasoning to support why this analysis is crucial or how it would impact the comparison. The lack of detailed justification or references makes the claim 3, as the authors would need to infer the importance of this analysis themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of discussion on the impact of adding additional parameters and computational effort due to the multistage training and multiple discriminators. It suggests that this analysis is necessary for a fair comparison with the baseline [31, 33]. This feedback is clear and actionable, as it provides a specific area for improvement that the authors can address to enhance the comprehensiveness and validity of their work. However, the comment could be more helpful if it offered suggestions on how to conduct this analysis or what specific aspects to focus on. Overall, the comment is 4, as it directs the authors to a critical area that requires attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the analysis of the correlation between dataset size and the Frobenius norm and singular values is underwhelming. It highlights the lack of clarity regarding whether this trend holds across different model architectures and the absence of theoretical evidence for the correlation. While the comment identifies areas for improvement, it does not provide explicit guidance on how the authors should address these issues or what specific steps they should take to enhance their analysis. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more detailed analysis and theoretical evidence. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the analysis of the correlation between dataset size and the Frobenius norm and singular values, which is specific. However, it does not specify which part of the paper this analysis is presented in, making it weakly grounded. The comment provides a clear critique of the analysis, noting the lack of clarity regarding whether the trend holds across different model architectures and the absence of theoretical evidence. This specificity helps the authors understand what needs to be addressed, but the lack of explicit grounding makes it challenging for them to pinpoint the exact section needing revision. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the analysis of the correlation between dataset size and the Frobenius norm and singular values is underwhelming. It questions the generalizability of the trend across different model architectures and the lack of theoretical evidence for the correlation. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence or detailed explanation makes it difficult for the authors to understand and address the critique effectively. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that is underwhelming, namely the analysis of the correlation between dataset size and the Frobenius norm and singular values. It points out the lack of clarity regarding whether this trend holds across different model architectures and the absence of theoretical evidence for the correlation. This feedback is clear and actionable, as it highlights a gap in the analysis that the authors need to address. However, the comment could be more helpful if it provided suggestions on how to enhance the analysis or what theoretical evidence might be relevant. Overall, the comment is 4 as it directs the authors to a critical area needing improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the use of AutoAugment as a stronger augmentation strategy, suggesting that information leakage is likely due to its policy being obtained by supervised training on ImageNet. It also questions the authors\" conclusion in Section 4.2 regarding the need for pretraining datasets to match the target dataset in terms of being object or scenecentric, and whether this is a setback for SSL algorithms that aim to learn more generic representations. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their draft. The questions posed are more like clarifications, and the comment lacks actionable advice or concrete steps for the authors to follow. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.2\" and \"L114,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the authors\" conclusion regarding the need for pretraining datasets to match the target dataset in terms of being object or scenecentric, and whether this is a setback for SSL algorithms. Additionally, it raises concerns about the use of AutoAugment as a stronger augmentation strategy, suggesting potential information leakage due to its policy being obtained by supervised training on ImageNet. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the use of AutoAugment as a stronger augmentation strategy, suggesting that information leakage is likely due to its policy being obtained by supervised training on ImageNet. The comment also questions the authors\" conclusion regarding the need for pretraining datasets to match the target dataset in terms of being object or scenecentric, and whether this is a setback for SSL algorithms. However, the comment lacks specific examples, references, or detailed reasoning to support these claims, making it difficult for the authors to fully understand and address the concerns. The lack of detailed justification or evidence makes the claims 3, as the authors would need to invest additional effort to fully understand and address the issues raised. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the use of AutoAugment as a stronger augmentation strategy, suggesting that information leakage is likely due to its policy being obtained by supervised training on ImageNet. It also questions the authors\" conclusion regarding the need for pretraining datasets to match the target dataset in terms of being object or scenecentric, and whether this is a setback for SSL algorithms that aim to learn more generic representations. While the comment identifies potential issues and raises thoughtprovoking questions, it lacks specific suggestions or guidance on how the authors might address these concerns or improve their draft. The feedback is 3 as it prompts the authors to consider these issues, but it could be more beneficial with additional actionable advice or detailed suggestions for improvement. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper lacks analysis on the alignment of entity representations, particularly in the context of multilingual alignment. It explicitly recommends adding more analysis and suggests including visualizations or case studies for different language types, such as language families. Additionally, the reviewer expresses interest in whether entities from lowresourced languages are well aligned with highresourced ones. This feedback provides clear and concrete actions for the authors to take, including specific suggestions for additional analysis and visualizations. The explicit nature of the recommendations and the detailed guidance on what to include make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the languageagnostic characters of entity representations,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of analysis on the alignment of entity representations, particularly in the context of multilingual alignment. The comment suggests adding more analysis and provides specific examples, such as visualizations or case studies for different language types, which adds to the specificity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks analysis on the alignment of entity representations, particularly in the context of multilingual alignment. It suggests adding more analysis and provides specific examples, such as visualizations or case studies for different language types. The comment is 4 as it provides a clear suggestion for improvement and offers specific examples of what could be included. However, it lacks detailed reasoning or references to existing work that could further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks analysis, namely the alignment of entity representations across different languages. It suggests that the authors could enhance their analysis by including more discussion on multilingual alignment and providing visualizations or case studies for different language types, such as language families. Additionally, the reviewer expresses interest in whether entities from lowresourced languages are well aligned with highresourced ones, which could be a valuable addition to the paper. This feedback is clear and actionable, providing the authors with specific directions for improving their analysis and presentation. However, it could be more helpful if it included examples or references to existing work on multilingual alignment, which would further guide the authors in their enhancements. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors provide more details on using attention, possibly as an extra appendix. While it implies that the authors should include additional information, it does not specify what specific details should be added or how they should be presented. The action is implicit and somewhat vague, as the authors need to infer that they should add more details on attention and where to include them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests adding more details on using attention, possibly as an extra appendix. However, it does not specify which part of the paper currently lacks these details or where the authors should include them. The authors might infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in suggesting the addition of more details on attention, but it lacks grounding as it does not pinpoint a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more details on using attention would be useful, possibly as an extra appendix. However, it does not provide any specific reasoning, examples, or references to support why this additional information is necessary or how it would enhance the paper. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment suggests that the authors provide more details on using attention, possibly as an extra appendix. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on what additional details should be included or how they might enhance the paper. The feedback is 3 as it points out a gap in the paper, but it could be more actionable with more detailed suggestions. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a specific issue with the references list, noting that it contains duplicates and lacks publication venues and/or years for many papers. This feedback provides clear and explicit guidance on what needs to be corrected in the references section. The authors know exactly what needs to be done to address these issues, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"references list,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of duplicates and the missing publication venues and/or years for many papers. This provides clear guidance on what needs to be addressed in the references section. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the references list contains duplicates and lacks publication venues and/or years for many papers. This is a factual observation that can be verified by checking the references list. The comment does not include subjective opinions, suggestions, or judgments that require additional justification or evidence. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the references list, noting that it contains duplicates and lacks publication venues and/or years for many papers. This feedback is clear and actionable, as it provides the authors with a direct and concrete step to improve their draft by ensuring the references are accurate and complete. By addressing these issues, the authors can enhance the credibility and professionalism of their work. However, the comment could be more helpful if it suggested ways to check for duplicates or provided examples of how to format the references correctly. Overall, the comment is 4, as it directs the authors to a critical area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point questions the authors about the reason for only showing results on images corrupted using Gaussian noise, despite claiming that their model can work well for a variety of image noise. This comment implies that the authors should provide an explanation or justification for this choice. However, it does not explicitly instruct the authors to do so, nor does it provide guidance on how to address the issue. The action is implicit and somewhat vague, as the authors can infer that they need to provide an explanation but are not given specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions the authors about the reason for only showing results on images corrupted using Gaussian noise, despite claiming that their model can work well for a variety of image noise. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its inquiry about the reason for the limited results, but it lacks grounding as it does not explicitly mention a specific section or figure. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the authors about the reason for only showing results on images corrupted using Gaussian noise, despite claiming that their model can work well for a variety of image noise. This is a factual observation that does not contain a subjective claim or opinion. It is a request for clarification, which is not a claim requiring verification. Therefore, the label \"No\" is appropriate.", "helpfulness_rationale": "The review comment questions the authors about the reason for only showing results on images corrupted using Gaussian noise, despite claiming that their model can work well for a variety of image noise. This is a valid point that prompts the authors to provide a justification or explanation for their choice of experimental setup. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue or improve their experimental design. While it highlights a potential weakness, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point identifies specific issues with the convoluted nature of the results description, providing examples of unnecessarily complex language. It also suggests that the authors should consider related work, such as speakerlistener communication from a teachability perspective, and check that useful communication is actually happening in light of existing literature. The comment includes specific references to [1] and [2], which provide concrete guidance on how to address the issues. However, it does not explicitly instruct the authors to make these changes, leaving the action somewhat implied. Overall, the comment is 4 as it provides clear suggestions and references, but the authors need to infer the specific actions to take.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific examples of convoluted language in the results description, allowing the authors to accurately identify the parts of the paper being addressed. It also provides specific suggestions for improvement, such as considering related work on speakerlistener communication and checking for useful communication in light of existing literature. The references to [1] and [2] further specify the areas that need attention. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results description is unnecessarily convoluted, providing an example of complex language. It suggests considering related work on speakerlistener communication and checking for useful communication in light of existing literature. The comment includes specific references to [1] and [2], which provide a basis for the claim and offer a clear direction for the authors to explore. However, the comment could be strengthened by providing more detailed reasoning or examples of how the convoluted language affects the clarity of the results. Overall, the claim is 4 due to the specific references and suggestions for improvement, but it could be more robust with additional explanation. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the convoluted nature of the results description, providing an example of unnecessarily complex language. It offers actionable suggestions for improvement by recommending related work on speakerlistener communication and suggesting that the authors check for useful communication in light of existing literature. The inclusion of specific references, such as [1] and [2], provides concrete guidance for the authors to consider. This feedback is clear and actionable, offering a direct path for the authors to enhance the clarity and relevance of their results. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to add details about the division of the dataset into training and test sets, including the numbers and the method used for division (e.g., random or with other considerations). This feedback provides a clear and concrete action for the authors to take, ensuring they know exactly what information to include in their draft. The comment is explicit and provides specific guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment explicitly mentions the need for details about the division of the dataset into training and test sets, including the numbers and the method used for division. This provides full grounding as it clearly identifies the specific aspect of the paper being addressed, allowing the authors to accurately pinpoint the part of the paper that needs revision. The comment is also specific because it details what is missing and what needs to be added, such as the numbers and the method used for division. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point requests additional details about the division of the dataset into training and test sets, including the numbers and the method used for division. This is a factual request for clarification, as it does not contain subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks details, namely the division of the dataset into training and test sets. It requests information on the numbers and the method used for division, such as whether it was random or involved other considerations. This feedback is clear and actionable, as it provides the authors with a specific area to address and details on what information is missing. By including this information, the authors can enhance the transparency and rigor of their experimental setup, which is crucial for reproducibility and credibility. However, the comment could be more helpful if it suggested alternative methods for division or provided examples of how this information could be presented. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises concerns about the need for human labor in building text descriptions for each task and questions the optimal textual format for policy learning, noting that it varies across tasks and models. It also mentions the potential scalability issue with longtext input. However, the comment does not provide explicit or implicit actions for the authors to take. It lacks specific guidance on how to address these concerns or improve the draft. Without actionable suggestions or concrete steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises concerns about the need for human labor in building text descriptions for each task and questions the optimal textual format for policy learning, noting that it varies across tasks and models. It also mentions the potential scalability issue with longtext input. However, the comment does not specify which part of the paper these concerns relate to, making it difficult for the authors to identify the exact sections that need attention. Additionally, while it provides some specific issues, it lacks detailed guidance on how to address them. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises concerns about the need for human labor in building text descriptions for each task and questions the optimal textual format for policy learning, noting that it varies across tasks and models. It also mentions the potential scalability issue with longtext input. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. The lack of evidence or detailed justification makes it difficult for the authors to understand and address the concerns effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises concerns about the need for human labor in building text descriptions for each task and questions the optimal textual format for policy learning, noting that it varies across tasks and models. It also mentions the potential scalability issue with longtext input. However, the comment does not provide specific suggestions or actionable feedback on how the authors might address these concerns or improve their draft. Without detailed guidance or constructive advice, the authors are left without a clear understanding of what steps to take to enhance their work. Therefore, the comment is rated as 2, as it identifies areas for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises several issues with the experimental validation, including the lack of consideration for deeper networks and the absence of a description of the optimization strategy, particularly the grid search for hyperparameter selection. It also mentions a minor issue with the positioning of the work with respect to related works, specifically the consideration of layer redundancy in network pruning. The comment provides a specific reference to a related work that addresses layer redundancy, which could help the authors better position their work. While the comment identifies several areas for improvement, it does not explicitly instruct the authors on how to address these issues, such as suggesting specific experiments or changes to the optimization strategy. The action is implicit and somewhat vague, as the authors need to infer the specific actions needed to improve their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses several issues with the experimental validation, including the lack of consideration for deeper networks and the absence of a description of the optimization strategy, particularly the grid search for hyperparameter selection. It also mentions a minor issue with the positioning of the work with respect to related works, specifically the consideration of layer redundancy in network pruning. The comment provides a specific reference to a related work that addresses layer redundancy, which helps ground the comment by suggesting a relevant context for the authors to consider. However, the comment does not explicitly mention which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the consideration of deeper networks and the optimization strategy. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experimental validation is not convincing due to the lack of consideration for deeper networks and the absence of a description of the optimization strategy, including the grid search for hyperparameter selection. It also mentions a minor issue with the positioning of the work with respect to related works, specifically the consideration of layer redundancy in network pruning. The comment provides a specific reference to a related work that addresses layer redundancy, which supports the claim about the positioning of the work. However, the comment lacks detailed reasoning or examples to fully substantiate the claim about the experimental validation, making it 3. The authors would need to provide additional context or evidence to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the experimental validation and positioning of the work. It points out that only shallow networks (2 or 3 layers) are considered, which limits the generalizability of the results. Additionally, it notes the absence of a description of the optimization strategy, including the grid search for hyperparameter selection. This feedback is clear and actionable, as it highlights specific aspects that need to be addressed to strengthen the experimental validation and the paper\"s contribution. The comment also provides a specific reference to a related work on layer redundancy in network pruning, which could help the authors better position their work within the literature. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided more detailed guidance on improving the experimental setup. Overall, the comment is 4 as it directs the authors to important areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the use of a specific type of loss in a particular setting might be novel, but it does not provide any evidence or reasoning to support this claim. The comment lacks explicit guidance or suggestions for the authors to address this issue, such as proposing new theoretical results or providing a rationale for the novelty of the loss function. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. The comment is 1.", "grounding_specificity_rationale": "The comment suggests that the use of a specific type of loss in a particular setting might be novel, but it does not provide any evidence or reasoning to support this claim. It does not specify which part of the paper this claim pertains to, nor does it detail what theoretical results are lacking or how they could be improved. Without specific references or guidance, the authors cannot effectively address the feedback. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the use of a specific type of loss in a particular setting might be novel, but it does not provide any evidence or reasoning to support this claim. The comment lacks specific examples, references, or detailed justification to substantiate the claim that no new theoretical results are proven. Without such evidence, the claim remains 1, as it does not provide the authors with a clear understanding of what needs to be addressed or improved. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the use of a specific type of loss in a particular setting might be novel, but it does not provide any evidence or reasoning to support this claim. It also states that the work does not prove any new theoretical results, which could be a valid concern. However, the comment lacks specificity and actionable feedback, such as suggesting how the authors might demonstrate the novelty of their approach or what theoretical results could be explored. Without detailed guidance or examples, the authors are left without a clear understanding of how to address the feedback. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests a straightforward hypothesis about the trivial and impossible parts of the dataset, proposing that the trivial part consists of images with highly consistent labels or typical object poses, while the impossible part includes images with ambiguous labels or atypical poses. The reviewer expresses interest in whether the human test results support this hypothesis and asks for more evidence to either prove or disprove it. While the comment implies that the authors should provide additional evidence, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to provide this evidence. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests a hypothesis about the trivial and impossible parts of the dataset, proposing that the trivial part consists of images with highly consistent labels or typical object poses, while the impossible part includes images with ambiguous labels or atypical poses. The reviewer expresses interest in whether the human test results support this hypothesis and asks for more evidence to either prove or disprove it. However, the comment does not explicitly mention which part of the paper this hypothesis is based on, making it weakly grounded. The authors can infer that it relates to the dataset or experimental setup, but the lack of explicit references makes it challenging to pinpoint the exact section. The comment is specific in detailing the hypothesis and the requested evidence, but the lack of grounding limits its effectiveness. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests a hypothesis about the trivial and impossible parts of the dataset, proposing that the trivial part consists of images with highly consistent labels or typical object poses, while the impossible part includes images with ambiguous labels or atypical poses. The reviewer expresses interest in whether the human test results support this hypothesis and asks for more evidence to either prove or disprove it. However, the comment lacks specific examples or references to support the hypothesis, making it 3. The authors would need to provide additional evidence or analysis to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests a straightforward hypothesis about the trivial and impossible parts of the dataset, proposing that the trivial part consists of images with highly consistent labels or typical object poses, while the impossible part includes images with ambiguous labels or atypical poses. The reviewer expresses interest in whether the human test results support this hypothesis and asks for more evidence to either prove or disprove it. This feedback is 3 as it provides a clear direction for the authors to explore and potentially strengthen their analysis. However, it lacks specific guidance on how to conduct this exploration or what additional evidence might be needed. To be more helpful, the comment could include suggestions on how to test the hypothesis or what specific data or analyses could be used to support or refute it. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the testing of the model on the bAbI dataset, specifically asking if it was only tested on the single supporting fact dataset (Task 1). However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on what the authors should do in response to this question, such as suggesting additional testing or analysis. Without any actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the testing of the model on the bAbI dataset, specifically asking if it was only tested on the single supporting fact dataset (Task 1). However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment. The authors can infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in its question about the testing on other tasks, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the testing of the model on the bAbI dataset, specifically asking if it was only tested on the single supporting fact dataset (Task 1). This is a factual question seeking clarification, as it does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the testing of the model on the bAbI dataset, specifically asking if it was only tested on the single supporting fact dataset (Task 1). While this question highlights a potential limitation in the evaluation of the model, it does not provide any actionable feedback or suggestions for improvement. The comment lacks depth and does not offer guidance on how the authors might address this issue or expand their evaluation to include other tasks. As a result, the comment is 2, as it identifies a potential area for improvement but does not provide sufficient direction for the authors to act upon."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the time complexity of the proposed algorithm, specifically regarding the calculation of the hypervolume in each step of LaMOO. It suggests that this computation could be timeconsuming for problems with many objectives, potentially making LaMOO impractical for such problems. While the comment implies that the authors should address this issue, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to analyze and address the time complexity issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Time Complexity\" and \"LaMOO,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a concern about the time complexity of the proposed algorithm, particularly in relation to the calculation of hypervolume for problems with many objectives. The comment provides a clear question about the practicality of the algorithm for such problems, which gives the authors a clear direction for addressing the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the time complexity of the proposed algorithm, specifically regarding the calculation of the hypervolume in each step of LaMOO. It suggests that this computation could be timeconsuming for problems with many objectives, potentially making LaMOO impractical for such problems. The comment provides a logical reasoning by pointing out the potential issue with the algorithm\"s scalability, which is a valid concern. However, it does not provide specific examples or references to support the claim, making it 3. The authors would need to further explore and substantiate the claim themselves to fully address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical concern about the time complexity of the proposed algorithm, specifically in relation to the calculation of the hypervolume in each step of LaMOO. It highlights a potential issue with the algorithm\"s scalability, particularly for problems with many objectives, which could make it impractical for certain applications. This feedback is valuable as it prompts the authors to consider and address a significant limitation of their approach. However, the comment could be more helpful if it provided suggestions on how to mitigate this issue or offered examples of alternative approaches. Overall, the comment is 4 as it identifies a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should delve deeper into the limitations of evolutionary methods, specifically focusing on leveraging state, reactiveness, and learning during an episode. It also advises being honest and direct in their critique, suggesting that the title is too generic and vague. The comment implies that the authors should clarify what \"brittle convergence properties\" mean and mentions that DeepRL methods are widely adopted. While the comment provides some direction, it lacks specific guidance on how to address these points, such as suggesting particular aspects to explore or examples to include. The action is implicit and somewhat vague, making it barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the limitations of evolutionary methods and the need for deeper discussion on leveraging state, reactiveness, and learning during an episode. It also addresses the title, suggesting it is too generic and vague, and questions the meaning of \"brittle convergence properties.\" The comment provides specific guidance on what aspects need further exploration and clarification, making it clear and actionable. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should delve deeper into the limitations of evolutionary methods, specifically focusing on leveraging state, reactiveness, and learning during an episode. The comment also critiques the title as being too generic and vague, suggesting that the authors should be more precise in their critique. However, the claim lacks specific examples or references to support the assertion that the current discussion on limitations is insufficient. Additionally, the comment questions the meaning of \"brittle convergence properties\" without providing context or explanation. This makes the claim 3, as it provides some reasoning but lacks detailed evidence or examples to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas for improvement, including the need for a deeper discussion on the limitations of evolutionary methods, specifically regarding state, reactiveness, and learning during an episode. It also suggests that the authors should be more precise in their critique, as the title is too generic and vague. The comment provides a clear direction for the authors to enhance their work by offering specific areas to explore and improve upon. However, it could be more helpful if it included suggestions on how to address these issues or provided examples of what a more detailed discussion might entail. Overall, the comment is 4 as it offers actionable feedback that can guide the authors in improving their draft."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about the synthesis of the focal stack, the forward model for using a defocus map and an image to synthesize a defocused image, and how edges with depth discontinuities are handled. These questions imply that the authors need to provide more detailed explanations or methods in these areas. While the comment does not explicitly instruct the authors to address these points, it does suggest that additional information is needed. The action is implicit but concrete, as the authors can infer that they need to provide more detailed explanations in these areas. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment raises questions about the synthesis of the focal stack, the forward model for using a defocus map and an image to synthesize a defocused image, and how edges with depth discontinuities are handled. While it does not explicitly mention specific sections or figures, the authors can infer that these questions pertain to the methodology or results sections. The comment is specific in detailing what aspects need clarification, such as the synthesis process and handling of depth discontinuities. However, it lacks full grounding as it does not explicitly reference specific sections, making it weakly grounded but specific. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point consists of questions seeking clarification on specific aspects of the methodology, such as the synthesis of the focal stack, the forward model, and the handling of edges with depth discontinuities. These questions are factual and do not contain subjective claims or opinions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises several important questions about the methodology and implementation of the focal stack synthesis, specifically asking for clarification on the forward model and how edges with depth discontinuities are handled. These questions are relevant and could help the authors improve the clarity and comprehensiveness of their paper. However, the comment does not provide specific suggestions or guidance on how to address these questions, leaving the authors with a clear understanding of what needs to be clarified but without detailed instructions on how to do so. While the feedback is 3 in identifying areas for improvement, it could be more actionable with additional guidance. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors provide empirical justification for their claim that the proposed algorithm does not require as many points or prior knowledge about subspace dimensions, as compared to existing algorithms. While the comment implies that the authors should include empirical evidence to support this claim, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not specify the exact type of empirical evidence needed or how to present it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the first claimed contribution of the paper, specifically questioning the empirical justification for the claim that the proposed algorithm does not require as many points or prior knowledge about subspace dimensions, as compared to existing algorithms. However, it does not specify which part of the paper discusses this contribution, making it weakly grounded. The comment is specific in its request for empirical justification, which provides some guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the empirical justification for the claim that the proposed algorithm does not require as many points or prior knowledge about subspace dimensions, as compared to existing algorithms. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. The lack of evidence or detailed justification makes it difficult for the authors to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper\"s first claimed contribution, which is that the proposed algorithm does not require as many points or prior knowledge about subspace dimensions, as compared to existing algorithms. It suggests that the authors provide empirical justification for this claim, which is a clear and actionable piece of feedback. However, the comment could be more helpful if it offered specific suggestions on how to conduct the empirical evaluation or what aspects to focus on. Despite this, the feedback provides a valuable direction for the authors to improve their draft, making it 4. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of comprehensive discussion of previous work on the topic, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on what specific aspects of previous work should be discussed or how the authors might improve their discussion. Without any actionable suggestions or concrete steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a lack of comprehensive discussion of previous work on the topic, but it does not specify which part of the paper this issue pertains to, nor does it provide details on what aspects of previous work are missing or how they could be incorporated. Without specific guidance or references to particular sections or examples, the authors cannot effectively address the feedback. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the authors do not provide a comprehensive discussion of previous work on the topic. However, it lacks specific examples or references to previous work that should be discussed, making it difficult for the authors to understand which aspects are missing or how to address the issue. The comment is vague and does not provide sufficient evidence or reasoning to support the claim, making it 1.", "helpfulness_rationale": "The comment identifies a significant weakness in the paper, noting that the authors have not provided a comprehensive discussion of previous work on the topic. This is an important area for improvement, as it can help establish the novelty and contribution of the current work. However, the comment lacks specificity and does not provide guidance on what aspects of previous work should be discussed or how the authors might address this gap. Without actionable suggestions or examples, the feedback is 3, as it highlights an area for improvement but does not fully support the authors in making those improvements. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point raises several questions about the OT sample selection process in Section 2.4.3, specifically whether it runs once or iteratively, and whether the optimization of the loss and solving the OT problem are conducted by turns. It also requests additional details and a flow chart to clarify the process and asks for the runtime of solving the entropic regularized discrete OT problem and the OT sample selection. These questions and requests are explicit and provide clear guidance on what the authors need to address to improve the clarity and comprehensiveness of their draft. The feedback is actionable as it specifies what information is missing and how to provide it, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"2.4.3\" and \"equation (10),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as the process of OT sample selection, the iterative nature of the EP module, and the runtime for solving the entropic regularized discrete OT problem. The request for additional details and a flow chart further clarifies the need for more information. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the OT sample selection process and the iterative nature of the EP module, seeking clarification on whether the optimization and OT problem solving are conducted by turns. It also requests additional details and a flow chart to better understand the process. While the comment identifies areas of uncertainty and suggests improvements, it does not provide specific evidence or references to support the claim. The lack of detailed reasoning or examples makes the claim 3, as the authors would need to provide additional information to fully address the concerns. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises important questions about the OT sample selection process in Section 2.4.3, specifically whether it runs once or iteratively as the EP module is updated during training. It also seeks clarification on whether the optimization of the loss and solving the OT problem are conducted by turns, and requests additional details and a flow chart to better understand the process. Furthermore, the comment asks for the runtime of solving the entropic regularized discrete OT problem and the OT sample selection. These questions and requests are clear and actionable, providing the authors with specific areas to address and improve the clarity and comprehensiveness of their draft. By answering these questions, the authors can enhance the reader\"s understanding of their methodology and its implications. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions: why there are no experiments with continuous tasks despite discussing them, and how the empirical performance of entropy methods for conditional optimization compares to ConBO. These questions imply that the authors should include experiments with continuous tasks and provide a comparison of the empirical performance of these methods. While the questions are explicit, they lack concrete guidance on how to conduct these experiments or comparisons. The authors know they need to address these points, but the feedback does not provide detailed instructions on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 7 in the appendix,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the absence of experiments with continuous tasks and the inclusion of entropy methods for conditional optimization in the experiments. The comment clearly specifies what needs to be addressed, such as including experiments with continuous tasks and comparing the empirical performance of entropy methods to ConBO. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a claim about the absence of experiments with continuous tasks despite discussing them and questions the inclusion of entropy methods for conditional optimization in the experiments. However, the comment does not provide any supporting evidence, reasoning, or references to justify these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper by noting that while the authors discuss how Knowledge Graphs (KG) handle continuous tasks, there are no experiments with continuous tasks included. It also questions the absence of experiments with entropy methods for conditional optimization, despite their derivation in the appendix. The comment raises important points about the lack of empirical evidence and comparison with ConBO, which could be addressed to strengthen the paper. However, it does not provide specific suggestions or guidance on how to incorporate these experiments or comparisons, leaving the authors with a clear understanding of the issues but without detailed instructions on how to address them. Therefore, the comment is 3, as it highlights areas for improvement but lacks depth and actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the difference between similarity and exit times in the context of unsupervised feature selection from a diffusion perspective. It explicitly requests a more detailed explanation from the authors to understand the difference. This feedback is clear and direct, providing a specific action for the authors to take to improve their draft. The request for a detailed explanation leaves no ambiguity about what the authors need to do, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"unsupervised feature selection from a diffusion perspective,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by questioning the difference between similarity and exit times in nature. The comment requests a more detailed explanation, which provides clear guidance on what the authors need to address. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the difference between similarity and exit times in the context of unsupervised feature selection from a diffusion perspective. The reviewer expresses a lack of understanding and requests a more detailed explanation. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that the difference is unclear. Without additional context or explanation, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the difference between similarity and exit times in the context of unsupervised feature selection from a diffusion perspective. It highlights a potential gap in the explanation provided by the authors, which could be addressed by offering a more detailed explanation. This feedback is clear and actionable, as it directs the authors to clarify a critical aspect of their work. However, the comment could be more helpful if it provided suggestions on how to present the explanation or examples to illustrate the difference. Overall, the comment is 4 as it guides the authors to improve their draft by addressing a specific area of confusion."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the limitations of the unified framework, specifically asking if it can handle general POMDP formulations with continuous or infinite spaces. While the comment implies that the authors should address this limitation, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to explore the framework\"s applicability to various POMDP formulations. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the limitations of the unified framework, specifically asking if it can handle general POMDP formulations with continuous or infinite spaces. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the framework\"s applicability to different POMDP formulations, but without clear grounding, the authors may struggle to determine where this question fits within the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question seeking clarification on the limitations of the unified framework. It does not express an opinion, judgment, or suggestion that requires verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the limitations of the unified framework, specifically asking if it can handle general POMDP formulations with continuous or infinite spaces. This is a relevant inquiry that could help the authors clarify the scope and applicability of their framework. However, the comment does not provide any suggestions or guidance on how the authors might address this limitation or expand their framework to accommodate such scenarios. While it prompts the authors to consider a potential area for improvement, it lacks actionable feedback or detailed advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should conduct experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE. This feedback provides a clear and direct action for the authors to take, specifying the types of tasks they should consider. The comment is explicit and concrete, giving the authors a specific direction for expanding their experiments. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiments, specifically noting the limitation of conducting evaluations only on sentence similarity tasks and open domain QA tasks. It also provides a clear suggestion to conduct experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE. This specificity guides the authors on what additional tasks to consider for their experiments. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments are limited because they only evaluate on sentence similarity tasks and open domain QA tasks, suggesting that there are many other tasks involving sentence pairs. The reviewer provides a specific example of sentence inference tasks like MNLI and RTE, which are common in the NLP field. This example supports the claim by offering a concrete alternative for the authors to consider. The reasoning is clear and provides a logical basis for the suggestion, making the claim 4. However, the comment could be strengthened by referencing additional tasks or studies to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a limitation in the experiments, noting that they are restricted to sentence similarity tasks and open domain QA tasks. It suggests that the authors should consider conducting experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE, which are common in the NLP field. This feedback is clear and actionable, providing the authors with a specific direction for expanding their experimental scope. By suggesting additional tasks, the comment offers a concrete way for the authors to enhance the comprehensiveness and relevance of their experiments. However, it could be more helpful if it included specific guidance on how to implement these additional tasks or why they are important. Overall, the comment is 4 as it effectively guides the authors toward improving the breadth and depth of their experiments."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a problem with setting the parameter \"S,\" but it does not provide any explicit or implicit guidance on how to address this issue. It lacks specific suggestions or actions for the authors to take, such as recommending alternative methods or providing examples of how to set the parameter. Without any actionable advice, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a problem with setting the parameter \"S,\" but it does not specify which part of the paper this issue is discussed in, nor does it provide details on what aspect of setting \"S\" is problematic. Without explicit references to sections, figures, or specific discussions, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what needs to be addressed or improved regarding the parameter \"S.\" Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that \"How to set the parameter S remains a problem.\" However, it does not provide any supporting evidence, reasoning, or examples to justify why this is a problem or how it affects the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the problem of setting the parameter \"S.\" However, it does not provide any further details, suggestions, or guidance on how to address this problem. Without additional context or actionable advice, the authors are left without a clear understanding of what needs to be improved or how to proceed. This lack of specificity and direction makes the comment 2, as it does not offer meaningful insights or actionable steps for the authors to take. Therefore, it aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic evaluation metrics, which can be misleading. However, it does not provide explicit guidance on how to conduct this human evaluation or what specific aspects should be evaluated. The action is implicit and somewhat vague, as the authors are left to infer that they should conduct a human evaluation but without detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic evaluation metrics, which are considered misleading. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections where caption generation is discussed. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine where to address this feedback. Additionally, the comment lacks specificity regarding what aspects of the human evaluation would be more convincing or how it should be conducted. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic evaluation metrics, which are considered misleading. However, the comment does not provide any supporting evidence, examples, or references to substantiate why human evaluation would be more reliable or how it could be conducted. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic evaluation metrics, which are considered misleading. This feedback highlights a potential weakness in the current evaluation approach and provides a clear suggestion for improvement. However, the comment lacks specific guidance on how to conduct a human evaluation or what aspects to focus on, which limits its helpfulness. While it identifies a critical area for improvement, it does not offer detailed actionable steps, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the convergence proof as trivial, suggesting that it lacks substantial novelty and rigor. It points out that Assumption 4.1 indicates that $X$ is i.i.d., which leads to a clear covariance matrix for $Z$ as $A^\top A / np$. The reviewer implies that the proof can be adapted with straightforward modifications, as indicated by Modification 1 in Appendix C. While the comment highlights a potential issue with the proof, it does not provide explicit guidance on how to address it or suggest specific modifications that could enhance the proof\"s rigor. The action is implicit and somewhat vague, as the authors are left to infer what changes might be necessary to improve the proof\"s novelty and rigor. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the theoretical proof for convergence,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the proof, pointing out that the assumption of $X$ being i.i.d. leads to a clear covariance matrix for $Z$, which makes the proof appear trivial. The comment further suggests that previous theorems can be adapted with straightforward modifications, indicating a lack of novelty and rigor in the convergence proof. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point claims that the theoretical proof for convergence appears trivial due to the assumption that $X$ is i.i.d., which leads to a clear covariance matrix for $Z$. The reviewer supports this claim by referencing Modification 1 in Appendix C, suggesting that previous theorems can be adapted with straightforward modifications. This provides a logical reasoning and specific reference to support the claim, making it 4. However, the comment could be strengthened by providing more detailed examples or references to specific theorems or proofs that are considered trivial, which would further enhance its verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the theoretical proof for convergence, suggesting that it appears trivial due to the assumption that $X$ is i.i.d., which leads to a clear covariance matrix for $Z$. The reviewer points out that previous theorems can be adapted with straightforward modifications, as indicated by Modification 1 in Appendix C. This feedback highlights a potential weakness in the proof\"s novelty and rigor, providing the authors with a clear direction for improvement. However, the comment could be more helpful if it offered specific suggestions on how to enhance the proof\"s rigor or provided examples of modifications that could be made. Overall, the comment is 4 as it directs the authors to a critical area needing attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the experimental setup borrowed from a previous study is only semireal, as multinode seed cascades are artificially created by merging singlenode seed cascades. It suggests that this should be clearly mentioned in the paper. This feedback provides a direct and concrete action for the authors to take, which is to clarify the experimental setup in the paper. The comment is explicit and provides clear guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental setup borrowed from [2],\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the experimental setup, noting that it is only semireal due to the artificial creation of multinode seed cascades by merging singlenode seed cascades. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the experimental setup is only semireal because multinode seed cascades are artificially created by merging singlenode seed cascades. This claim is 3 as it provides a logical explanation for why the setup might not be fully realistic. However, the comment lacks specific examples or references to support the claim, which would strengthen the justification. Providing more detailed evidence or examples would enhance the verifiability of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental setup, noting that it is only semireal because multinode seed cascades are artificially created by merging singlenode seed cascades. This feedback is clear and actionable, as it directs the authors to clarify this aspect of their experimental setup in the paper. By addressing this point, the authors can enhance the transparency and realism of their experimental design, which is crucial for the credibility of their findings. However, the comment could be more helpful if it provided suggestions on how to improve the realism of the experimental setup or offered examples of how to present this information more clearly. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two main issues: the limited datasets and models used, and the lack of assessment on stateoftheart generative models like GPT. It also notes that the bias benchmarks only assess gender, race, and religion, suggesting that other important biases and datasets are not measured. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues or what specific datasets or models should be considered. The action is implicit and somewhat vague, as the authors need to infer that they should expand their dataset and model selection to include more diverse biases and stateoftheart generative models. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the limited datasets and models used in the paper, specifically mentioning the bias benchmarks that only assess gender, race, and religion. It also points out the absence of assessments on stateoftheart generative models like GPT. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the methodology or results sections, where datasets and models are typically discussed. The comment is specific in detailing what is missing, such as assessments on other important biases and datasets, as well as stateoftheart generative models. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the datasets and models used are limited, specifically mentioning that the bias benchmarks only assess gender, race, and religion, and that other important biases and datasets are not measured. Additionally, it notes the absence of assessments on stateoftheart generative models like GPT. While the comment highlights specific areas where the paper could be improved, it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to infer the specific biases or datasets that should be included and how they relate to the current assessment. Therefore, the comment is 3, as it provides a general direction for improvement but lacks detailed justification or evidence.", "helpfulness_rationale": "The review comment identifies two key areas for improvement: the limited datasets and models used, and the lack of assessment on stateoftheart generative models like GPT. It also points out that the bias benchmarks only assess gender, race, and religion, suggesting that other important biases are not measured. This feedback is clear and actionable, as it highlights specific areas where the authors can expand their analysis to include more diverse datasets and models, as well as address additional biases. However, the comment could be more helpful if it provided specific suggestions on which datasets or models to consider or how to incorporate assessments on stateoftheart generative models. Overall, the comment is 4 as it directs the authors to enhance the scope and depth of their analysis, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the description of the metrics used in the paper is limited and recommends providing an explanation or citing the metrics. While the comment implies that the authors should either explain the metrics or cite them, it does not specify which metrics need clarification or how to present this information. The action is implicit and somewhat vague, as the authors are left to infer which metrics require attention and how to address the issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the description of metrics used in the paper, suggesting that it is limited and recommending either an explanation of the metrics or a citation. However, it does not specify which part of the paper discusses the metrics, making it weakly grounded. The comment is specific in suggesting what needs to be addressed, such as providing an explanation or citation for the metrics. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the description of the metrics used in the paper is limited and suggests that an explanation or citation would be beneficial. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. The lack of detailed reasoning or evidence makes the claim 2, as it provides some insight but requires more information to be fully actionable.", "helpfulness_rationale": "The review comment identifies a limitation in the description of the metrics used in the paper, suggesting that an explanation or citation would be beneficial. This feedback is 3 as it points out an area for improvement, but it lacks specificity and actionable guidance on which metrics need clarification or how to present them. The comment could be more helpful if it provided examples of metrics that require explanation or suggested ways to enhance the description. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of motivation for the problem considered in the paper, specifically the need for fast label aggregation algorithms in a streaming setting. It suggests that the paper should spend more time motivating the applications where such algorithms are needed. However, the comment does not provide explicit guidance on how to address this issue or what specific aspects should be included to motivate the problem. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more context and motivation for the problem. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the paper\"s objective of designing fast label aggregation algorithms for a streaming setting and questions the lack of motivation for such algorithms. It also points out that the datasets used in the empirical analysis are static, which contradicts the paper\"s objective. However, the comment does not specify which part of the paper lacks motivation or where the datasets are discussed, making it weakly grounded. The comment is specific in its critique of the lack of motivation and the use of static datasets, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks motivation for the problem considered, specifically the need for fast label aggregation algorithms in a streaming setting. It points out that the datasets used in the empirical analysis are static, which contradicts the paper\"s objective. However, the comment does not provide specific examples or references to support the claim that the problem is not wellmotivated or that the datasets are inappropriate. The lack of detailed justification or evidence makes it difficult for the authors to understand and address the critique effectively. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting that while it aims to design fast label aggregation algorithms for a streaming setting, it lacks motivation for the problem and does not provide examples of applications where such algorithms are needed. This is a critical issue that the authors need to address to make their work more relevant and impactful. The comment highlights the importance of motivating the problem and suggests that the paper should include examples of realworld scenarios where fast label aggregation is necessary. However, it does not provide specific guidance on how to achieve this or what types of examples would be most relevant. While the feedback is clear in its critique, it could be more helpful with actionable suggestions or examples. Therefore, the comment is rated as 3, as it provides insight but lacks detailed guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the connection between the mentioned fact in the introduction and recent findings regarding the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this question or what steps they should take to clarify the connection. As a result, the authors are left without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction section, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the connection between the mentioned fact and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the connection between a statement in the introduction and recent findings regarding the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. However, it does not provide any supporting evidence, references, or detailed reasoning to substantiate the claim. The lack of specific examples or references makes it difficult for the authors to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the connection between a statement in the introduction and recent findings regarding the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. While it identifies a potential gap in the paper, it does not provide specific guidance or suggestions on how the authors might address this issue or clarify the connection. The comment lacks actionable feedback, leaving the authors with a vague understanding of what needs to be improved. Therefore, it is rated as 2, as it points out a potential area for improvement but does not offer detailed guidance for the authors to follow."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly encourages the authors to conduct error analysis in their paper and provide detailed explanations of the model\"s performance under different scenarios. This suggestion is clear and direct, giving the authors a specific action to take. The comment also explains the importance of error analysis in guiding subsequent improvements and expansions of the ERC research. The feedback is concrete and actionable, as it provides a clear direction for the authors to enhance their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"error analysis,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: conducting error analysis and providing detailed explanations of the model\"s performance under different scenarios. This feedback provides clear guidance on how to improve the paper, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point encourages the authors to conduct error analysis and provide detailed explanations of the model\"s performance under different scenarios. It highlights the importance of error analysis in evaluating model performance and guiding subsequent improvements. However, the comment does not provide specific examples or references to support why error analysis is crucial or how it could be conducted effectively. While the claim is logical and aligns with common practices in model evaluation, the lack of detailed justification or examples makes it 3. The authors would need to infer the importance of error analysis based on the general reasoning provided, which is why the comment is rated as 3.", "helpfulness_rationale": "The review comment highlights the importance of error analysis in evaluating model performance and identifying potential issues. It provides a clear and actionable suggestion for the authors to conduct error analysis and offer detailed explanations of the model\"s performance under different scenarios. This feedback is valuable as it guides the authors on how to enhance their draft by providing a structured approach to evaluating and improving their model. However, the comment could be more helpful if it offered specific examples or methods for conducting error analysis, which would further empower the authors in implementing this suggestion. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the scalability of the model, specifically noting that performance worsens with an increase in the maximum number of identities. It suggests that the capacity should be preset to a small number, such as 10, and questions how the authors might scale up without compromising performance. While the comment identifies an issue and provides a potential solution, it does not explicitly instruct the authors to address this concern or offer detailed guidance on how to implement the suggested solution. The action is implicit and somewhat vague, as the authors need to infer that they should address the scalability issue and consider the suggested approach. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3 (a),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with scalability, noting that performance worsens with an increase in the maximum number of identities. The comment further suggests that the capacity should be preset to a small number and questions how the authors might scale up without compromising performance. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance worsens with an increase in the maximum number of identities, as shown in Table 3 (a). It suggests that the capacity should be preset to a small number, such as 10, to maintain performance. The comment raises a valid concern about scalability and provides a logical reasoning for the suggestion. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to further explore the issue and provide evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the scalability of the model, noting that performance worsens with an increase in the maximum number of identities. It suggests that the capacity should be preset to a small number, such as 10, to maintain performance. The comment also raises a practical concern about realworld scenarios where the number of objects can vary, questioning how the authors might scale up without compromising performance. This feedback is clear and actionable, providing the authors with a specific area for improvement and a potential solution to consider. However, it could be more helpful if it offered additional suggestions or examples on how to address the scalability issue. Overall, the comment is 4 as it directs the authors to a critical area that needs attention and provides a starting point for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the complexity of the proposed method and its relationship to the baselines. It questions whether the performance gain is due to a specific module or simply from having more parameters. The comment suggests that the current ablation study does not provide definitive answers to these questions. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address it. The action is implicit and somewhat vague, as it lacks specific instructions on how to conduct the ablation study or which modules to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the complexity of the proposed method and its relationship to the baselines, specifically questioning whether the performance gain is due to a particular module or simply from having more parameters. However, it does not explicitly mention which part of the paper discusses the ablation study or the modules, making it weakly grounded. The comment is specific in detailing the issue with the ablation study and the need for clearer answers regarding the performance gain. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the complexity of the proposed method and its relationship to the baselines, questioning whether the performance gain is due to a specific module or simply from having more parameters. The comment highlights a lack of clarity in the ablation study, which does not provide definitive answers to these questions. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to infer the exact nature of the problem and how to address it. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed justification or evidence to be 5.", "helpfulness_rationale": "The review comment identifies a critical issue with the proposed method, specifically its complexity and the lack of clarity regarding the source of performance gains. It questions whether the performance improvement is due to a particular module or simply from having more parameters. This feedback is valuable as it highlights a potential weakness in the paper that needs to be addressed. However, the comment could be more helpful if it provided suggestions on how to conduct the ablation study or which modules to focus on for analysis. Despite this, the comment is 4 as it directs the authors\" attention to an important area for improvement, prompting them to clarify the source of their method\"s performance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper\"s reliance on MIA testing as a metric for unlearning effectiveness is not robust enough for privacy guarantees. It recommends using ULiRA as an alternative. While the comment implies that the authors should consider using ULiRA instead of MIA testing, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide detailed guidance on how to implement the suggested change. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"MIA (Membership Inference Attack) Testing via Ulira,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the robustness of MIA testing for privacy guarantees and recommending the use of ULiRA as an alternative. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper\"s reliance on MIA testing as a metric for unlearning effectiveness is not robust for privacy guarantees. It supports this claim by suggesting that the use of ULiRA is recommended as an alternative. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim about the robustness of MIA testing. While it provides a suggestion for improvement, the lack of detailed justification or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper\"s reliance on MIA testing as a metric for unlearning effectiveness, questioning its robustness for privacy guarantees. It provides a specific suggestion by recommending the use of ULiRA as an alternative, which could be a valuable addition to the paper. However, the comment could be more helpful if it explained why ULiRA is a better choice or provided more detailed guidance on how to incorporate it into the paper. Overall, the comment is 4 as it points out a critical area for improvement and offers a concrete suggestion, but it could be more comprehensive with additional context or explanation."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights several issues with the explanations and presentation of the paper, including the lack of detailed procedures and confusing figures. It suggests adding more details to the paper and/or supplementary information to improve clarity. Additionally, it recommends including error bars and pvalues for statistical inferences. While the comment provides explicit actions, such as adding more details and including specific elements like error bars, it does not specify how to implement these changes or provide detailed guidance on what specific information should be added. The authors know the general direction but may need more detailed instructions to fully understand and execute the suggested improvements. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig. 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the explanations, noting that they are qualitative and lack detailed procedures, and that some figures are confusing. The comment provides clear guidance on how to improve the paper by suggesting the addition of more details and statistical elements like error bars and pvalues. This level of specificity and explicit mention of the figures make the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the explanations are qualitative and lacks detailed procedures, which is supported by the observation that some figures are confusing. The reviewer provides specific examples, such as questioning the meaning of \"sample count\" in Figure 2, which helps substantiate the claim. Additionally, the suggestion to include error bars and pvalues for statistical inferences is a logical and common practice in scientific reporting. However, the comment could be strengthened by providing more detailed examples or references to support the claim about the lack of detailed procedures. Overall, the claim is 4, as it provides a clear basis for improvement but lacks comprehensive evidence or references. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper, including the lack of detailed explanations and procedures, confusing figures, and the absence of statistical elements like error bars and pvalues. It provides specific examples, such as questioning the meaning of \"sample count\" in Figure 2, which helps the authors understand the issues more clearly. The comment also suggests actionable steps, such as adding more details to the paper and/or supplementary information, which can significantly enhance the clarity and comprehensiveness of the work. By addressing these points, the authors can improve the quality and impact of their draft. Therefore, the comment is 4, as it offers clear and actionable feedback that can guide the authors in enhancing their manuscript."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of clarity regarding the generalizability of specific examples presented in the paper, such as biases of target statistics and prediction shift of gradient values. However, it does not provide explicit guidance or suggestions on how the authors might address this issue. The comment implies that the authors should clarify the generalizability of these examples, but it lacks concrete steps or actions for the authors to take. As a result, the comment is vague and does not offer actionable advice, making it barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 3.2\" and \"Theorem 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of clarity regarding the generalizability of specific examples presented in the paper, such as biases of target statistics and prediction shift of gradient values. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper presents specific examples of biases and prediction shift, but it does not specify how these examples are unclear or how they affect the generalizability of the results. The comment lacks detailed reasoning or examples to support the claim, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the clarity of the paper, particularly in relation to the generalizability of specific examples presented in the paper. It points out that while the paper provides examples of biases and prediction shift, it does not clarify how general these situations are. This feedback is 3 as it highlights a potential weakness in the paper and prompts the authors to address this issue. However, the comment could be more helpful if it provided suggestions on how to improve the clarity or offered examples of how to better explain the generalizability of the examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that including \"a few more datasets\" would be appreciated, particularly for evaluating crosstask transferability. However, it does not specify which datasets should be included or how they would contribute to the evaluation of crosstask transferability. The action is implicit and lacks concrete details, making it somewhat vague. The authors can infer that they need to add more datasets, but without specific guidance, it may be challenging to determine which ones to include and how to integrate them into the evaluation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that including \"a few more datasets\" would be appreciated, particularly for evaluating crosstask transferability. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. Additionally, it does not provide specific examples of datasets that could be included or how they would contribute to the evaluation. This lack of specificity and grounding makes it difficult for the authors to identify the exact area needing improvement. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that including \"a few more datasets\" would be beneficial, particularly for evaluating crosstask transferability. However, the comment lacks specific examples or references to support why these additional datasets are necessary or how they would enhance the evaluation. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that including \"a few more datasets\" would be beneficial, particularly for evaluating crosstask transferability. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on which datasets should be included or how they would contribute to the evaluation. The feedback is somewhat vague and does not offer actionable steps for the authors to take, making it 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly requests the authors to clarify whether there is any additional novel effort in Section 3.1 for 3D Gaussian generation, given that it appears to follow the previous work, Luciddreamer. This is a clear and direct action for the authors to take, as it specifies what needs to be addressed in the draft. The comment provides a concrete step for the authors to follow, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 3.1 for 3D Gaussians generation,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests clarification on whether there is any additional novel effort in this section, given that it appears to follow the previous work, Luciddreamer. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions whether the section on 3D Gaussian generation in Section 3.1 adds any novel effort beyond following the previous work, Luciddreamer. However, it does not provide any specific reasoning or evidence to support this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the section on 3D Gaussian generation in Section 3.1, suggesting that it may not include any novel effort beyond following the previous work, Luciddreamer. This feedback is 3 as it prompts the authors to clarify whether their contribution is original or if it builds upon existing work. However, the comment lacks specific guidance or suggestions on how the authors might address this concern or enhance their contribution. To be more helpful, the comment could include suggestions for potential novel contributions or ways to differentiate the work from the previous study. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights several issues with the MMD DRO method, including the lack of a tractable exact equivalent reformulation, the crudeness of the upper bound provided in Theorem 3.1, and the need for further approximation even for a simple kernel ridge regression problem. Additionally, it points out the restriction of assuming the loss function belongs to the RKHS, as already noted by the authors. While the comment identifies several areas of concern, it does not provide explicit guidance or suggestions on how the authors might address these issues or improve their draft. The actions are implicit and somewhat vague, as the authors are left to infer what changes might be necessary without concrete steps or examples. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"MMD DRO,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the method, such as the lack of a tractable exact equivalent reformulation, the crudeness of the upper bound provided in Theorem 3.1, and the need for further approximation even for a simple kernel ridge regression problem. Additionally, it points out the restriction of assuming the loss function belongs to the RKHS, as already noted by the authors. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point claims that MMD DRO lacks a tractable exact equivalent reformulation, which is a severe drawback. It further critiques the upper bound provided in Theorem 3.1, noting its crudeness due to the dropped nonnegative constraint on the distribution and the need for further approximation even for a simple kernel ridge regression problem. Additionally, it points out the restriction of assuming the loss function belongs to the RKHS, as already noted by the authors. While the comment provides some reasoning and references the authors\" own observations, it lacks specific examples or detailed explanations of how the issues impact the method\"s effectiveness. This makes the claim 3, as it provides a basis for the critique but requires more detailed evidence or examples to fully substantiate the claims.", "helpfulness_rationale": "The review comment identifies several critical issues with the MMD DRO method, specifically highlighting the lack of a tractable exact equivalent reformulation, the crudeness of the upper bound provided in Theorem 3.1, and the need for further approximation even for a simple kernel ridge regression problem. It also points out the restriction of assuming the loss function belongs to the RKHS, as already noted by the authors. While the comment effectively identifies these weaknesses, it does not provide specific suggestions or guidance on how the authors might address these issues or improve their draft. The feedback is 3 as it highlights areas for improvement, but it lacks actionable advice, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the relevance of the framework in relation to nonconvex losses and nonnorm type defenses. It asks whether the nonvanishing duality gap and the difficulty of maximization over nonnorm type constraints make the algorithm irrelevant or if it could still provide insights into the risk upperbound. Additionally, it poses a question about using the covariance or other statistics to design a better defense if the true mean is known through an oracle. While the comment raises important questions, it does not provide explicit instructions or concrete suggestions for the authors to address these concerns. The actions are implicit and somewhat vague, as the authors need to infer what steps to take to address the questions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the relevance of the framework in relation to nonconvex losses and nonnorm type defenses, specifically mentioning the nonvanishing duality gap and the difficulty of maximization over nonnorm type constraints. It also asks about the potential use of covariance or other statistics to design a better defense if the true mean is known through an oracle. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the discussion of the framework and its applicability. The questions are specific, as they address the relevance and potential limitations of the framework. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point consists of a series of questions and requests for clarification, such as the relevance of the framework to nonconvex losses and nonnorm type defenses, and whether the nonvanishing duality gap and difficulty of maximization over nonnorm type constraints make the algorithm irrelevant. It also asks about the potential use of covariance or other statistics to design a better defense if the true mean is known through an oracle. These questions are not claims or opinions but rather requests for clarification or additional information. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises several questions and points of clarification regarding the relevance of the framework in relation to nonconvex losses and nonnorm type defenses. It asks whether the nonvanishing duality gap and the difficulty of maximization over nonnorm type constraints make the algorithm irrelevant or if it could still provide insights into the risk upperbound. Additionally, it poses a question about using the covariance or other statistics to design a better defense if the true mean is known through an oracle. While the comment identifies important areas for clarification, it lacks specific suggestions or guidance on how the authors might address these questions or improve their draft. The feedback is 3 as it prompts the authors to consider these aspects, but it could be more actionable with additional detail or direction. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the baselines in Figure 3, suggesting that the trained models could be sparsified to reduce the number of selected features and compare accuracy to the proposed model. While the comment implies that the authors should consider this approach, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement the suggestion or what specific features to consider. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a particular experiment to conduct, which is to sparsify the trained models and compare accuracy to the proposed model. This provides clear guidance on what the authors could do to improve their draft. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the baselines in Figure 3. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the baselines in Figure 3, suggesting that the trained models could be sparsified to reduce the number of selected features and compare accuracy to the proposed model. This feedback is 3 as it provides a potential direction for further exploration and analysis. However, it lacks depth and does not offer specific guidance on how to implement this suggestion or what specific features to consider. While it prompts the authors to consider an additional experiment, it does not fully support them in making these improvements. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the paper is not written to be reproduced, even with the pseudocode provided in the supplementary material. It suggests that more details are needed, such as those related to the RNN implementation (e.g., number of units) and other technical details. While the comment identifies the issue and provides a general direction for improvement, it does not specify which specific details are missing or how the authors should address these gaps. The action is explicit but somewhat vague, as it lacks concrete guidance on how to implement the suggested improvements. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of the paper not being written to be reproduced, even with the pseudocode provided in the supplementary material. It suggests that more details are needed, such as those related to the RNN implementation and other technical details. However, the comment does not specify which part of the paper this issue pertains to, making it weakly grounded. The authors can infer that it relates to the methodology or experimental sections, but without explicit references, it is challenging to pinpoint the exact location. The comment is specific in detailing what is missing, such as details about the RNN implementation, but lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is not written to be reproduced, even with the pseudocode provided in the supplementary material. The reviewer suggests that more details are needed, such as those related to the RNN implementation and other technical details. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact areas that need improvement. The lack of detailed justification or evidence makes the claim 3, as it provides a general direction but requires more specific guidance to be fully actionable. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that it is not written to be reproduced, even with the pseudocode provided in the supplementary material. It points out that the paper is written to provide an intuitive understanding of the work but lacks the necessary details for actual reproduction. The comment specifies areas that need more detail, such as the RNN implementation and other technical details. This feedback is clear and actionable, as it provides the authors with a specific direction for improvement by highlighting what is missing in the paper. However, it could be more helpful if it offered suggestions on how to address these gaps or provided examples of what additional details might be needed. Overall, the comment is 4, as it effectively guides the authors toward improving the reproducibility and clarity of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that Figure 1 would be strengthened by including error bars and more random trials to reduce random fluctuations in the results. While the comment implies that these additions would improve the figure, it does not explicitly instruct the authors to make these changes. The action is implicit and somewhat vague, as the authors need to infer that they should add error bars and more random trials. However, the suggestion is concrete, as it provides a clear idea of what could be done to enhance the figure. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of error bars and more random trials to reduce random fluctuations in the results. This provides clear guidance on how to improve the figure. Therefore, the comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point suggests that Figure 1 would be strengthened by including error bars and more random trials to reduce random fluctuations. This claim is 3 as it provides a logical reasoning for why these additions could improve the figure\"s strength. However, the comment lacks specific examples or references to support the claim that more random trials would significantly reduce fluctuations. Providing such examples or references would strengthen the justification, making the claim more verifiable. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that Figure 1 would be strengthened by including error bars and more random trials. This feedback is clear and offers a concrete way for the authors to enhance the visual representation of their results, which could improve the clarity and robustness of their findings. However, the comment could be more helpful if it explained why error bars and more random trials are important or how they would address potential issues with the current figure. Despite this, the comment is 4 as it guides the authors toward a specific improvement that could enhance the quality of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide a brief introduction to energy models in the related work section. It also points out that Figure 1 lacks information about which points correspond to different learning rates in the left graph and different steps in the right graph. The comment provides specific actions for the authors to take, such as introducing energy models and clarifying the figure. However, it does not specify how to introduce energy models or which points in the figure need clarification. While the actions are explicit, the lack of detailed guidance makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"related work section\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the introduction of energy models in the related work section and the clarification of which points in Figure 1 correspond to different learning rates and steps. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide a brief introduction to energy models in the related work section. It also points out that Figure 1 lacks information about which points correspond to different learning rates in the left graph and different steps in the right graph. The comment provides specific suggestions for improvement, which are 4. However, it does not include detailed reasoning or references to support the claim about the need for an introduction to energy models or the importance of clarifying Figure 1. Therefore, the comment is categorized as 4, as it provides a clear direction for improvement but lacks comprehensive justification.", "helpfulness_rationale": "The review comment provides two distinct pieces of feedback. First, it suggests that the authors should include a brief introduction to energy models in the related work section, which is a clear and actionable suggestion that can help readers better understand the context of the paper. Second, it points out a lack of clarity in Figure 1, specifically regarding which points correspond to different learning rates in the left graph and different steps in the right graph. This feedback is helpful as it directs the authors to clarify an important aspect of their figure, which can enhance the paper\"s readability and understanding. However, the comment could be more helpful if it provided specific guidance on how to introduce energy models or how to clarify the figure. Overall, the feedback is 4, as it identifies areas for improvement and offers actionable suggestions, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment raises a question about the model\"s ability to generate novel knowledge or testable hypotheses regarding neuron data. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or what specific steps should be taken to clarify the model\"s capabilities. Without actionable suggestions or a clear direction for improvement, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the model\"s ability to generate novel knowledge or testable hypotheses regarding neuron data. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the model or methodology are unclear or need further elaboration. Without clear grounding and specificity, the authors cannot effectively address the issue. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the model\"s ability to generate novel knowledge or testable hypotheses regarding neuron data. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the model\"s ability to generate novel knowledge or testable hypotheses regarding neuron data. While it identifies a potential area of concern, it lacks specificity and does not provide any actionable suggestions or guidance for the authors to address this issue. Without clear direction on how to improve the model\"s capabilities or what specific aspects need further elaboration, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors present a simplified version of Theorem 2 for the general audience, similar to how Theorem 1 is presented. This is an explicit request for the authors to simplify the presentation of Theorem 2, which is a concrete action. The comment provides clear guidance on what needs to be done to improve the accessibility of the paper, making it 5.", "grounding_specificity_rationale": "The comment suggests simplifying the presentation of Theorem 2 for the general audience, similar to how Theorem 1 is presented. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or subsection. The authors can infer that it relates to the presentation of Theorem 2, but this inference is not as direct as it could be. The comment is specific in suggesting a simplification for the general audience, but it lacks grounding because it does not explicitly mention the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that Theorem 2 is difficult to understand without a simplified version, similar to Theorem 1. However, the comment does not provide specific examples or detailed reasoning to support why Theorem 2 is challenging for the general audience. Without additional context or explanation, the claim lacks sufficient evidence or justification, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the accessibility of Theorem 2, suggesting that it may be difficult for the general audience to understand without a simplified version. This feedback is 3 as it points out a specific area where the paper could be improved, such as by providing a more accessible explanation or a simplified version of the theorem. However, the comment lacks detailed guidance or suggestions on how to achieve this simplification, leaving the authors with a general direction but not a clear path to improvement. Therefore, the comment is rated as 3, as it provides some insight but could be more actionable with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the keypoint mask averaged feature vector and whether it is obtained by multiplying each feature map elementwise by H_psi. This comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the question or improve the clarity of the section. As a result, the authors are left without any actionable steps to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"KeyQN section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the method used to obtain the keypoint mask averaged feature vector, asking whether it is obtained by multiplying each feature map elementwise by H_psi. This provides clear guidance on what needs to be clarified or explained in the section. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the method used to obtain the keypoint mask averaged feature vector. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the method used to obtain the keypoint mask averaged feature vector, specifically asking whether it is obtained by multiplying each feature map elementwise by H_psi. While this question identifies a potential area of confusion or lack of clarity in the paper, it does not provide any actionable feedback or suggestions for improvement. The comment lacks depth and does not offer guidance on how the authors might clarify or address this issue in their draft. As a result, the comment is 2, as it points out a potential problem but does not assist the authors in resolving it. Therefore, it aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that it is difficult to distinguish between the different curves in Figure 2 and recommends using styles (e.g., dashed lines) or adding color to improve this. While the comment explicitly states an action, it does not provide specific guidance on which curves should be differentiated or how to implement the suggested changes. The authors know they need to make the curves more distinguishable, but the lack of detailed instructions makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2 right,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion to improve the figure by recommending the use of styles (e.g., dashed lines) or adding color to distinguish between the different curves. This level of detail guides the authors on what changes to make to enhance the figure\"s clarity. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that it is difficult to distinguish between the different curves in Figure 2 and recommends using styles (e.g., dashed lines) or adding color to improve this. However, the comment does not provide any specific examples or detailed reasoning to support why these changes would be beneficial or how they would improve the figure\"s clarity. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to implement it effectively. Therefore, the comment is considered 2, as it provides a suggestion but lacks sufficient justification or examples to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 2, noting that it is difficult to distinguish between the different curves. It provides a clear and actionable suggestion to improve the figure by recommending the use of styles (e.g., dashed lines) or adding color to enhance clarity. This feedback is valuable as it directly addresses a visual aspect of the paper that could impact its readability and understanding. However, the comment could be more helpful if it included specific examples of how to implement these suggestions or if it provided additional context on why these changes would be beneficial. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with further guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should tone down the claims made in the introduction, as they are not consistent with the tasks and models evaluated. The reviewer recommends that the authors not call the task \"language learning\" but rather a feedbackdriven questionanswering task in the form of a dialog. This feedback is explicit and provides a clear action for the authors to take, along with a concrete suggestion on how to reframe the task. The authors know exactly what needs to be changed and how to implement it, making this comment 5.", "grounding_specificity_rationale": "The comment addresses the claims made in the introduction, specifically questioning the use of the term \"language learning\" when the task is more accurately described as a feedbackdriven questionanswering task in the form of a dialog. However, it does not specify which part of the introduction is being referred to, making it weakly grounded. The comment is specific in its critique of the terminology used and suggests a more accurate description of the task. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the claims made in the introduction are not consistent with the tasks and models evaluated, specifically questioning the use of the term \"language learning\" when the task is more accurately described as a feedbackdriven questionanswering task in the form of a dialog. The reviewer provides a logical reasoning by contrasting the claims with the actual nature of the task, suggesting that the authors should tone down their claims. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to further explore the reasoning to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the claims made in the introduction, specifically questioning the use of the term \"language learning\" when the task is more accurately described as a feedbackdriven questionanswering task in the form of a dialog. This feedback is valuable as it points out a potential misalignment between the claims and the actual nature of the task, which could lead to confusion or misinterpretation among readers. The comment provides a clear and actionable suggestion to tone down the claims and reframe the task more accurately. However, it could be more helpful if it offered specific examples or references to support the recommendation. Overall, the comment is 4 as it guides the authors toward a more accurate and precise description of their work, but it could be further enhanced with additional details or examples."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point highlights that proving lower bounds for round complexity is a significant part of the work involved in proving results for batched ranking problems. It notes that the paper exploits an easy reduction from the problem of collaborative ranking, which makes the lower bound results follow as an easy corollary of the collaborative ranking results. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this observation or improve their draft. Without actionable suggestions or questions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the major chunk of work involved in proving results for batched ranking problems, specifically the lower bounds for round complexity. It mentions that the paper exploits an easy reduction from the problem of collaborative ranking, which makes the lower bound results follow as an easy corollary. However, the comment does not specify which part of the paper discusses these aspects, making it weakly grounded. The authors can infer that it relates to the theoretical analysis or results section, but without explicit references, it is challenging to pinpoint the exact location. The comment is specific in detailing the issue with the lower bounds and their relation to collaborative ranking, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that proving lower bounds for round complexity is a significant part of the work involved in proving results for batched ranking problems. It further states that the paper exploits an easy reduction from the problem of collaborative ranking, which makes the lower bound results follow as an easy corollary of these collaborative ranking results. However, the comment lacks specific examples, references, or detailed reasoning to support the claim about the ease of the reduction or the corollary nature of the lower bound results. Without these details, the authors may find it challenging to fully understand and address the critique. Therefore, the comment is considered 2, as it provides some justification but lacks sufficient evidence or explanation.", "helpfulness_rationale": "The review comment highlights a significant aspect of the paper, namely the major chunk of work involved in proving results for batched ranking problems, which is proving lower bounds for round complexity. It notes that the paper exploits an easy reduction from the problem of collaborative ranking, making the lower bound results follow as an easy corollary. While the comment identifies a key contribution of the paper, it does not provide any suggestions or guidance on how the authors might address this observation or improve their draft. The feedback lacks depth and actionable advice, leaving the authors with limited insight into how to enhance their work. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the prompting technique used in the study is basic and suggests that carefully curated prompts could lead to better results. However, it does not provide specific guidance on how to curate these prompts or what aspects of the current technique need improvement. The action is implicit and somewhat vague, as the authors are left to infer that they should explore more advanced prompting techniques but without concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment critiques the prompting technique used in the study, suggesting that it is basic and does not fully leverage the potential of LLMs. It implies that carefully curated prompts could lead to better results in generating systematic reviews. However, the comment does not specify which part of the paper discusses the prompting technique, making it weakly grounded. Additionally, while it provides a general suggestion for improvement, it lacks specificity in terms of what aspects of the prompting technique need to be addressed or how to curate better prompts. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the prompting technique used in the study is basic and does not fully leverage the potential of LLMs. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. The comment lacks evidence or justification, making it difficult for the authors to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the study by pointing out that the prompting technique used is basic and may not fully leverage the potential of LLMs. It suggests that carefully curated prompts could lead to better results in generating systematic reviews. However, the comment lacks specificity and does not provide detailed guidance or examples on how to curate these prompts or what aspects of the current technique need improvement. While it highlights an area for potential enhancement, the feedback is somewhat vague and incomplete, making it 3 for the authors to consider but not fully actionable. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests conducting additional experiments on larger datasets, acknowledging that compute might be an issue. However, it does not provide specific guidance on how to address the potential issue of maintaining probabilities at large batch sizes. The comment implies that this aspect is not critical, but it does not offer actionable advice on how to handle it. The feedback is somewhat vague, as it suggests an additional experiment but lacks concrete details on how to implement it or address the potential issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests conducting additional experiments on larger datasets, acknowledging that compute might be an issue. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting additional experiments and acknowledging the potential issue of compute, but it lacks detailed guidance on how to address this issue or where to incorporate these experiments. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests conducting additional experiments on larger datasets, acknowledging that compute might be an issue. However, it does not provide any specific reasoning or evidence to support why these additional experiments are necessary or how they would contribute to the paper. The comment also mentions maintaining probabilities at large batch sizes but does not elaborate on why this is an issue or how it relates to the current experiments. Without detailed justification or examples, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests conducting additional experiments on larger datasets, acknowledging that compute might be an issue. While it provides a clear suggestion for improvement, it lacks specific guidance on how to address the potential issue of maintaining probabilities at large batch sizes. The comment also acknowledges that this aspect is not critical, which could be seen as a limitation in terms of actionable feedback. Overall, the comment offers a 3 direction for improvement but could be more detailed and comprehensive to be fully beneficial to the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the performance of Table 4, noting that it is behind more recent models. It provides examples of models, GLaMM and UNINEXT, that have achieved better results on specific metrics. However, the comment does not explicitly instruct the authors to improve their results or suggest ways to address this issue. The action is implicit, as the authors can infer that they need to improve their performance, but it lacks concrete guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the performance of the model, noting that it is behind more recent models and provides examples of models that have achieved better results. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance of Table 4 is behind more recent models, specifically mentioning GLaMM and UNINEXT as examples. It provides specific metrics and results from these models, which helps substantiate the claim. However, the comment could be strengthened by including more detailed comparisons or references to other relevant works. Overall, the claim is 4, as it provides sufficient evidence to support the assertion but lacks comprehensive references or additional context. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the performance of Table 4, noting that it is behind more recent models. It provides examples of models, GLaMM and UNINEXT, that have achieved better results on specific metrics. This feedback is clear and actionable, as it highlights an area where the authors\" model performance could be improved. However, the comment could be more helpful if it suggested ways to address this issue, such as comparing the models\" architectures or suggesting potential improvements. Overall, the comment is 4 as it directs the authors\" attention to a critical area for enhancement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a perceived limitation in the novelty of the proposed video storyboarding approach, specifically noting that the primary method relies on framewise SDSA, which mirrors the approach used in ConsiStory. The only notable difference is the use of CLIPseg and OTSU segmentation as mask sources instead of crossattention. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this limitation or enhance the novelty of their approach. The action is implicit and vague, as the authors are left to infer that they should explore ways to differentiate their method from existing approaches or provide additional justification for the novelty of their work. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the novelty of the proposed video storyboarding approach, specifically mentioning the reliance on framewise SDSA, which mirrors the approach used in ConsiStory. It also notes the use of CLIPseg and OTSU segmentation as mask sources instead of crossattention. However, the comment does not specify which part of the paper discusses these methods or their comparison to ConsiStory, making it weakly grounded. The comment is specific in detailing the limitations of novelty, but without clear grounding, the authors may struggle to identify the exact sections needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the novelty of the proposed video storyboarding approach is limited, specifically noting that the primary method relies on framewise SDSA, which mirrors the approach used in ConsiStory. The only notable difference is the use of CLIPseg and OTSU segmentation as mask sources instead of crossattention. While the comment provides some reasoning by comparing the approach to ConsiStory, it lacks specific examples or detailed analysis to fully substantiate the claim. The authors would need to explore the differences more deeply to understand the basis of the claim. Therefore, the comment is 3, as it provides a starting point for further investigation but requires more detailed justification.", "helpfulness_rationale": "The review comment identifies a potential limitation in the novelty of the proposed video storyboarding approach, specifically noting that the primary method relies on framewise SDSA, which mirrors the approach used in ConsiStory. The comment highlights the use of CLIPseg and OTSU segmentation as mask sources as a minor difference. While the comment points out a weakness, it lacks actionable suggestions or guidance on how the authors might address this issue or enhance the novelty of their approach. The feedback is 3 as it provides insight into the perceived limitations, but it could be more beneficial with additional direction or suggestions for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the method\"s weakness would be more prominent in images with multiple objects or cluttered scenes. It implies that the authors should consider comparing their approach to previous methods on a dataset with such images. However, the comment does not explicitly instruct the authors to conduct this comparison or provide specific guidance on how to implement it. The action is implicit and somewhat vague, as the authors can infer the need for comparison but are not given detailed instructions on how to execute it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the method\"s weakness would be more prominent in images with multiple objects or cluttered scenes. It implies that the authors should consider comparing their approach to previous methods on a dataset with such images. However, the comment does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. Additionally, it lacks specificity regarding what aspects of the method should be compared or how the comparison should be conducted. As a result, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the method\"s weakness would be more prominent in images with multiple objects or cluttered scenes. It proposes a comparison with previous methods on a dataset with such images, which would be interesting. However, the comment lacks specific examples or references to support the claim that the method\"s weakness is more pronounced in such scenarios. Without detailed evidence or examples, the claim remains somewhat speculative, making it difficult for the authors to fully understand and address the suggestion. Therefore, the comment is classified as 2.", "helpfulness_rationale": "The review comment identifies a potential weakness in the method\"s applicability, suggesting that it may be more effective in images with multiple objects or cluttered scenes. It provides a constructive suggestion to compare the approach with previous methods on such datasets, which could help the authors better understand and address the method\"s limitations. However, the comment lacks specific guidance on how to conduct this comparison or what aspects to focus on, which limits its actionable nature. While it offers a valuable insight, it could be more helpful with additional details or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point states that a fullpage explanation of the implementation of kernels using OpenAI\"s Triton instead of CUDA is unnecessary because of wellknown engineering improvements. However, it does not provide any guidance or suggestions on how the authors should address this issue or what specific aspects of the explanation are unnecessary. The comment lacks explicit instructions or concrete details on how to improve the draft, leaving the authors uncertain about what actions to take. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"kernels\" and \"OpenAI\"s Triton,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies that a fullpage explanation of the implementation is unnecessary due to wellknown engineering improvements. This provides clear guidance on what aspect of the paper should be revised or omitted. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that a fullpage explanation of the implementation of kernels using OpenAI\"s Triton instead of CUDA is unnecessary due to wellknown engineering improvements. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that the paper uses OpenAI\"s Triton for kernel implementation instead of CUDA, suggesting that a fullpage explanation is unnecessary due to wellknown engineering improvements. While the comment identifies a potential area for improvement by suggesting that the explanation could be condensed, it lacks depth and does not provide specific guidance on how to address this issue or what aspects of the explanation could be simplified. The feedback is 3 as it highlights a potential area for streamlining, but it could be more actionable with additional details or suggestions. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point raises questions about the zeroshot nature of the study and suggests that the transferability might be limited due to the difficulty of the source and target tasks. It also provides specific examples to support the claim, such as the difference between the \"walkerrun\" and \"walkerwalk\" tasks and the complexity of the manipulation scenario. The comment explicitly states that the authors need to clarify these points in the paper to avoid misleading readers. The feedback is clear and provides concrete guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment raises questions about the zeroshot nature of the study and suggests that the transferability might be limited due to the difficulty of the source and target tasks. It provides specific examples, such as the difference between the \"walkerrun\" and \"walkerwalk\" tasks and the complexity of the manipulation scenario, to support its claims. However, it does not explicitly mention which part of the paper these examples are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be clarified, such as the difficulty of policy transfer and the need for clear explanations. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the zeroshot nature of the study and suggests that the transferability might be limited due to the difficulty of the source and target tasks. The reviewer provides specific examples, such as the difference between the \"walkerrun\" and \"walkerwalk\" tasks and the complexity of the manipulation scenario, to support their claim. This level of detail and reasoning makes the claim 4, as it provides a logical basis for the critique. However, the comment could be strengthened by referencing specific literature or studies that support the idea of limited transferability in similar scenarios. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises a critical question about the zeroshot nature of the study and suggests that the transferability might be limited due to the difficulty of the source and target tasks. It provides specific examples, such as the difference between the \"walkerrun\" and \"walkerwalk\" tasks and the complexity of the manipulation scenario, to support its claim. The comment also highlights the need for the authors to clarify these points in the paper to avoid misleading readers. This feedback is clear and actionable, as it identifies a potential weakness in the study and offers specific suggestions for improvement. By addressing these issues, the authors can enhance the clarity and validity of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the proposed method achieves only a modest improvement over baselines, particularly on a small backbone like ResNet50. It suggests that the method might struggle on larger backbone models like SwinB or SwinL due to the introduction of global pooling. While the comment implies that the authors should test their method on larger models, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the issue or what specific tests to conduct. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the performance of the proposed method on different frameworks and tasks, specifically mentioning the relative gains and the impact on small backbone models like ResNet50. It also raises a concern about the method\"s performance on larger backbone models like SwinB or SwinL. However, the comment does not explicitly mention which part of the paper discusses these aspects, making it weakly grounded. The comment is specific in detailing the concerns about the method\"s performance and potential limitations, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method\"s improvement over baselines is not very strong, particularly on a small backbone like ResNet50. It suggests that the method might struggle on larger backbone models due to the introduction of global pooling. However, the comment lacks specific examples, references, or detailed reasoning to support the claim about the relative gains and the potential issues with larger models. This makes the claim 3, as it provides a general observation but lacks the necessary evidence or explanation to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation in the proposed method\"s performance, specifically noting that the relative gains are not very strong, particularly on small backbone models like ResNet50. It suggests that the method might struggle on larger backbone models due to the introduction of global pooling, which could limit its effectiveness on larger receptive fields. This feedback is 3 as it points out a specific area for improvement and provides a rationale for why the method might not perform as well on larger models. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided guidance on alternative approaches to enhance performance on larger models. Overall, the comment is 3, as it highlights a potential weakness but lacks detailed guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point critiques the analysis of neural networks, suggesting that it contributes less and that the extension from linear models to wide fullyconnected neural networks is trivial. It also claims that the work bypasses the core problem of overparametrized neural networks. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address these critiques or improve their analysis. Without actionable suggestions or a clear direction for revision, the authors are left without a path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions sections 3.2 and 3.3, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the critique that the analysis of neural networks contributes less and that the extension from linear models to wide fullyconnected neural networks is trivial. The comment further specifies that the work bypasses the core problem of overparametrized neural networks by only considering easy wide fullyconnected neural networks. This level of detail provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of neural networks contributes less and that the extension from linear models to wide fullyconnected neural networks is trivial. It also suggests that the work bypasses the core problem of overparametrized neural networks. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment critiques the analysis of neural networks, suggesting that it contributes less and that the extension from linear models to wide fullyconnected neural networks is trivial. It also claims that the work bypasses the core problem of overparametrized neural networks by only considering easy wide fullyconnected neural networks. While the comment identifies a potential weakness in the analysis, it lacks specific suggestions or guidance on how the authors might address these issues or improve their work. Without actionable feedback or detailed advice, the authors are left without a clear path for improvement. Therefore, the comment is rated as 2, as it provides some insight but lacks depth and actionable guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the sufficiency of the datasets for a rigorous evaluation, particularly given the large size of some datasets. It suggests that the authors should consider adding more datasets or providing a repository for reproducing experiments. While the comment implies an action, it does not explicitly instruct the authors to take specific steps, such as identifying additional datasets or creating a repository. The suggestion is somewhat vague, as it lacks concrete guidance on how to address the issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the sufficiency of the datasets for a rigorous evaluation, particularly in relation to the number of datasets available for each task. It mentions that having 5, 6, and 4 datasets for the three tasks, respectively, might not be sufficient. However, the comment does not specify which sections or parts of the paper discuss these datasets, making it weakly grounded. The comment is specific in its critique of the dataset selection and size, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the sufficiency of the datasets for a rigorous evaluation, particularly given the large size of some datasets. The reviewer suggests that having fewer datasets for each task might not provide a comprehensive evaluation. However, the comment lacks specific examples or references to support the claim that the datasets are insufficient. Without detailed justification or evidence, the claim remains somewhat vague, making it difficult for the authors to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the sufficiency of the datasets for a rigorous evaluation, particularly given the large size of some datasets. It suggests that having fewer datasets for each task might not provide a comprehensive evaluation. The comment is 3 as it identifies a potential weakness in the dataset selection and size, prompting the authors to consider whether their evaluation is robust. However, it lacks specific suggestions or guidance on how to address this issue, such as recommending additional datasets or providing a rationale for the current dataset selection. To be more helpful, the comment could include actionable advice or examples of how to improve the dataset selection process. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point provides a specific suggestion to include a reference to a relevant paper, \"Assessing Fire Safety using Complex Numerical Models with a Bayesian Multifidelity Approach (Stroh et al. 2017),\" which could help the authors contextualize their work. However, the comment also points out a potential inconsistency in the abstract and introduction regarding the term \"relatively inexpensive,\" which is not actionable advice. The authors are informed of the issue but not given explicit guidance on how to address it. Therefore, the comment is 3, as it provides a concrete suggestion for inclusion but lacks detailed guidance on the inconsistency.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the multifidelity framework and sequential design for learning quantities (e.g. probabilities of threshold exceedance),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out a potential inconsistency in the abstract and introduction regarding the term \"relatively inexpensive.\" The comment provides a specific reference to a relevant paper, which further grounds the feedback. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests including a reference to a specific paper, \"Assessing Fire Safety using Complex Numerical Models with a Bayesian Multifidelity Approach (Stroh et al. 2017),\" which is a common practice in academic writing to support claims or provide context. This suggestion is 5 as it provides a clear and specific reference that the authors can use to enhance the credibility of their work. However, the second part of the comment regarding the inconsistency in the abstract and introduction is not a claim but rather a factual observation, making it a normal statement. Therefore, the overall comment is verifiable.", "helpfulness_rationale": "The review comment provides a specific suggestion to include a reference to a relevant paper, \"Assessing Fire Safety using Complex Numerical Models with a Bayesian Multifidelity Approach (Stroh et al. 2017),\" which could help the authors contextualize their work within the existing literature. This is a valuable piece of feedback that can guide the authors in enhancing the scholarly context of their paper. Additionally, the comment points out a potential inconsistency in the abstract and introduction regarding the term \"relatively inexpensive,\" which could be confusing for readers. While the comment identifies these issues, it does not offer detailed guidance on how to address the inconsistency or improve the clarity of the text. Therefore, the comment is 4, as it provides actionable suggestions but could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the method\"s ability to address sparse reward problems and compares it to other methods like Qmix. However, it does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their method. The comment lacks concrete actions or details on how to implement changes, leaving the authors uncertain about what steps to take. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises questions about the method\"s ability to address sparse reward problems and compares it to other methods like Qmix. However, it does not specify which part of the paper discusses the method or the experiments, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its questioning of the method\"s effectiveness but lacks grounding, as it does not clearly identify the parts of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the method\"s ability to address sparse reward problems and compares it to other methods like Qmix. However, it does not provide specific evidence or examples to support the claim that the method does not address sparse reward problems effectively. The comment lacks detailed reasoning or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a critical question about the method\"s ability to address sparse reward problems, specifically questioning whether it offers a better solution compared to other methods like Qmix. It also points out a potential issue with the proposed method requiring subtaskspecific rewards, which could be seen as providing a dense reward signal. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address these concerns or improve their method. While it identifies an area for improvement, the feedback is somewhat vague and does not offer actionable advice, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the curated AH36M dataset is used for training and, if so, whether other methods like HMR and SPIN had access to this data during training for a fair comparison. While the comment implies that the authors should clarify this aspect, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the use of the curated AH36M dataset for training and whether other methods like HMR and SPIN had access to this data during training for a fair comparison. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in its inquiry about the use of the dataset and the fairness of comparisons, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the use of the curated AH36M dataset for training and whether other methods had access to it during training for a fair comparison. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is a concern or how it affects the fairness of the comparison. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a critical question about the use of the curated AH36M dataset for training and whether other methods like HMR and SPIN had access to this data during training. This is an important point that could impact the fairness of the comparison and the validity of the results. However, the comment lacks specificity and does not provide guidance on how the authors might address this issue or what steps they should take to ensure a fair comparison. While it identifies a potential weakness, the feedback is somewhat vague and incomplete, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the clarity of the motivation for using an adversarial network in the model and questions the fairness of the experimental results. It also points out that the proposed model is larger than others due to the addition of CAT and GAN, even when compared to pretrained models. However, the comment does not provide explicit guidance on how to address these issues or suggest specific actions for improvement. The authors are left to infer that they need to clarify the motivation and ensure fairness in the experimental results, but without concrete steps or examples, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the motivation for using an adversarial network in the model and questions the fairness of the experimental results. It also mentions the addition of CAT and GAN, which makes the proposed model larger than others. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but without explicit references, it is challenging to pinpoint the exact location. The comment is specific in detailing the concerns about the motivation and fairness of the experimental results, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the clarity of the motivation for using an adversarial network in the model and questions the fairness of the experimental results. It also points out that the proposed model is larger than others due to the addition of CAT and GAN, even when compared to pretrained models. However, the comment lacks specific examples, detailed reasoning, or references to support these claims. The lack of evidence or detailed justification makes it difficult for the authors to understand and address the issues effectively. Therefore, the comment is considered 2, as it provides some basis for the claims but requires more detailed support to be 5.", "helpfulness_rationale": "The review comment identifies two main issues: the lack of clarity in the motivation for using an adversarial network in the model and the perceived unfairness in the experimental results. It also points out that the proposed model is larger than others due to the addition of CAT and GAN, even when compared to pretrained models. While the comment highlights important areas for improvement, it lacks specific suggestions or guidance on how the authors might address these issues. The feedback is 3 as it directs the authors\" attention to critical areas that need clarification or improvement, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the reliability of the experimental results, specifically in Table 1, where the MSE is significantly smaller than the MAE. However, it does not provide any explicit or implicit guidance on how the authors should address this issue or improve the reliability of their results. There is no suggestion for further analysis, correction, or clarification. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the experimental results, namely the concern about the validity of the results due to the significant difference between the MSE and MAE. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental results are unreliable, specifically in Table 1, where the MSE is significantly smaller than the MAE. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this discrepancy raises concerns about the validity of the results. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental results, noting that the MSE is significantly smaller than the MAE in Table 1, which raises concerns about the validity of the results. This is a clear and actionable feedback that highlights a potential problem with the experimental methodology or analysis. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the reliability of their results. While it points out a critical area for improvement, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point claims that the proposed meta algorithm is a direct extension of existing methods, suggesting that there is not much novelty in the methodology. However, it does not provide any explicit or implicit actions for the authors to take in response to this feedback. There is no guidance on how the authors might address this issue, such as suggesting ways to enhance the novelty or differentiate their approach from existing methods. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the novelty of the methodology, specifically mentioning that the proposed meta algorithm is a direct extension of existing methods. However, it does not specify which part of the paper this critique pertains to, such as a particular section or methodology description. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper being addressed. Additionally, the comment does not provide specific details on what aspects of the methodology are considered extensions or how they could be improved to enhance novelty. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the proposed meta algorithm is a direct extension of existing methods, suggesting a lack of novelty in the methodology. However, the comment does not provide specific examples or references to existing methods that the proposed algorithm is based on, making it difficult for the authors to understand the basis of the claim. Without detailed evidence or examples, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment points out a lack of novelty in the methodology, specifically noting that the proposed meta algorithm is a direct extension of existing methods. While this feedback identifies a potential weakness in the paper, it lacks actionable suggestions or guidance on how the authors might address this issue or enhance the novelty of their approach. Without specific advice or examples, the comment provides limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the performance of the proposed method should be compared with more methods and that analysis should be provided for inferior results that violate the motivation. While the comment implies that the authors should expand their comparisons and provide additional analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add more comparisons and analysis. However, the comment does provide a clear direction for improvement, making it 3.", "grounding_specificity_rationale": "The comment addresses the comparison of performance with other methods and the consistency of the proposed method\"s superiority. It suggests that analysis should be provided for inferior results that violate the motivation. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for additional analysis, but without clear grounding, it is difficult for the authors to pinpoint the exact sections that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the performance is only compared with a few methods and that the proposed method is not consistently better than others. It suggests that analysis should be provided for inferior results that violate the motivation. However, the comment lacks specific examples or references to support the claim about the limited comparison or the inconsistency in performance. Without detailed evidence or examples, the authors may find it challenging to understand and address the issue effectively. Therefore, the claim is considered 2, as it provides some basis for the critique but requires more detailed justification.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s performance evaluation, noting that it is only compared with a few methods and that the proposed method is not consistently better than others. It suggests that analysis should be provided for inferior results that violate the motivation. This feedback is clear and actionable, as it directs the authors to expand their comparisons and provide additional analysis to address the inconsistency. However, the comment could be more helpful if it offered specific suggestions on how to conduct this analysis or which methods to include in the comparison. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the authors have not provided sufficient information on the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit, as the authors can infer that they need to include more information on these aspects, but it lacks concrete details on what specific information should be added or how to present it. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment highlights a lack of coverage on the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. However, it does not specify which part of the paper this issue pertains to, such as a specific section or chapter. This makes it difficult for the authors to pinpoint the exact area that needs attention. The comment is specific in identifying the missing information but lacks grounding, as it does not indicate where in the paper this discussion should be included. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors have not covered more on the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. This feedback is 3 as it points out an area where the authors could provide more detailed information or analysis. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as recommending additional data or analysis to include. While it highlights an area for improvement, the lack of actionable advice limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests using different notation for \"D\" to avoid confusion between its use as a dimensionality of points and a dilation factor. While the comment identifies a potential issue and provides a clear action for the authors to take, it does not specify which notation should be used or how to implement this change. The action is explicit but somewhat vague, as the authors know they need to make a change but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests using different notation for \"D\" to avoid confusion between its use as a dimensionality of points and a dilation factor. However, it does not specify which part of the paper this issue pertains to, such as a specific section, table, or figure where \"D\" is used. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs revision. The comment is specific in suggesting a change in notation to avoid confusion, but without clear grounding, it is challenging for the authors to address the issue effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests using different notation for \"D\" to avoid confusion between its use as a dimensionality of points and a dilation factor. However, the comment does not provide any reasoning or examples to support why this confusion exists or how it could be resolved by using different notation. Without specific examples or detailed justification, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential source of confusion in the paper, specifically the use of \"D\" to represent both dimensionality of points and dilation factor. It suggests using different notation to avoid this confusion, which is a clear and actionable piece of feedback. However, the comment could be more helpful if it provided specific suggestions on alternative notations or examples of how to implement them. Despite this, the feedback is 3 as it directs the authors to a specific area for improvement, even if it lacks detailed guidance. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a lack of clarity regarding the concept of \"state\" and suggests that the authors should elaborate on it. It questions whether \"elements\" are equivalent to \"states\" or \"actions\" and requests further elaboration. While the comment explicitly points out the need for clarification, it does not provide specific guidance on how to elaborate or what additional information should be included. The action is explicit but somewhat vague, as the authors know they need to clarify the concept of \"state\" but may not be entirely sure of the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 186line 187,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether \"elements\" are equivalent to \"states\" or \"actions\" and requesting further elaboration. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the clarity of the concept of \"state\" and suggests that it represents the grid status (e.g., agent position) and is obtained after applying an action of the trace. The reviewer also asks whether \"elements\" are equivalent to \"states\" or \"actions\" and requests further elaboration. While the comment raises valid points about the clarity of the paper, it lacks specific examples or references to support the claim. The reasoning is logical but could be strengthened with more detailed evidence or examples. Therefore, the comment is 3, as it provides a basis for the claim but requires additional information for full verification.", "helpfulness_rationale": "The review comment identifies a lack of clarity regarding the concept of \"state\" in the paper. It questions whether \"elements\" are equivalent to \"states\" or \"actions\" and suggests that more elaboration is needed. This feedback is clear and actionable, as it points out a specific area where the authors need to clarify their terminology and provide additional explanation. By addressing this issue, the authors can improve the comprehensibility of their work for readers. However, the comment could be more helpful if it provided specific suggestions on how to clarify the concept or examples of what additional information should be included. Overall, the comment is 4, as it directs the authors to a critical area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a lack of clarity in the theoretical comparisons to adaptive learning of GPRGNN. However, it does not provide any explicit or implicit suggestions on how to address this issue or what specific aspects need clarification. The comment lacks actionable guidance, leaving the authors uncertain about how to improve their draft. Without concrete steps or examples, the authors are unable to make meaningful changes to their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment identifies a specific issue with the theoretical comparisons to adaptive learning of GPRGNN, but it does not specify which part of the paper this issue pertains to. The authors can infer that it might be related to the theoretical sections or discussions, but without explicit references, it is weakly grounded. The comment is specific in pointing out the lack of clarity in the theoretical comparisons, but it does not provide detailed guidance on how to address this issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the theoretical comparisons to adaptive learning of GPRGNN are not clear. However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific area of concern regarding the clarity of theoretical comparisons to adaptive learning of GPRGNN. However, it lacks depth and does not provide any suggestions or guidance on how the authors might improve this aspect of their paper. Without actionable feedback or examples, the authors are left without a clear understanding of what changes are needed to address the issue. Therefore, the comment is 2, as it points out a problem but does not offer any direction for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the sufficiency of measuring object hallucination through only yes/no responses. It suggests that a yes response does not necessarily indicate that the model comprehends the presence of the object, as it may still produce incorrect objects in other tasks. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this concern or improve the measurement methodology. Without specific suggestions or instructions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the sufficiency of measuring object hallucination through only yes/no responses, suggesting that a yes response does not necessarily indicate comprehension. However, it does not specify which part of the paper this issue pertains to, such as a specific section or experiment where this measurement is discussed. The authors can infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in its critique of the measurement approach but lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point raises a question about the sufficiency of measuring object hallucination through only yes/no responses. It suggests that a yes response does not necessarily indicate comprehension, as the model may still produce incorrect objects in other tasks. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. The lack of evidence or detailed explanation makes it difficult for the authors to understand and address the concern fully. Therefore, the comment is considered 2, as it provides some insight but requires more detailed justification to be 5.", "helpfulness_rationale": "The review comment raises a valid concern about the sufficiency of measuring object hallucination through only yes/no responses. It points out that a yes response does not necessarily indicate that the model comprehends the presence of the object, as it may still produce incorrect objects in other tasks. This feedback is 3 as it prompts the authors to reconsider their measurement approach and potentially explore more comprehensive methods to assess object hallucination. However, the comment lacks specific suggestions or guidance on how to address this issue, such as proposing alternative measurement techniques or providing examples of more robust approaches. While it identifies a potential weakness, it does not offer actionable steps for improvement, making it 3 but incomplete."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the verylongterm forecasting task is of limited practical significance and provides a specific action for improvement: conducting experiments on more datasets and training the baseline models with the \"correct\" forecast horizon to put the results in a proper context. This feedback is explicit and provides concrete steps for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment addresses the discussion section, specifically mentioning the need for improvement in the discussion. It suggests conducting experiments on more datasets and training the baseline models with the \"correct\" forecast horizon to put the results in a proper context. However, it does not specify which part of the discussion is lacking or what specific aspects need improvement. While the authors can infer that it relates to the discussion section, the comment lacks full grounding as it does not explicitly mention a specific section or element. The suggestion is specific in terms of what needs to be addressed, but the lack of explicit grounding makes it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that the verylongterm forecasting task is of limited practical significance. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. The suggestion to improve the discussion by conducting experiments on more datasets and training the baseline models with the \"correct\" forecast horizon is a logical next step, but it lacks specific guidance or examples to support the claim. Without detailed justification or evidence, the claim remains 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the practical significance of the verylongterm forecasting task, which is an important observation for the authors to consider. It provides a specific suggestion for improvement by recommending conducting experiments on more datasets and training the baseline models with the \"correct\" forecast horizon to put the results in a proper context. This feedback is actionable and offers a clear direction for the authors to enhance the relevance and applicability of their work. However, the comment could be more helpful if it included additional details or examples on how to implement these suggestions effectively. Overall, the comment is 4 as it provides valuable guidance for improving the draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that there should be experiments and explanations regarding the different queries used in spatiotemporal representation, specifically mentioning spatial, temporal, and summary queries. It also suggests that experiments should be conducted to explore what would happen if only spatial or temporal and summary queries were used. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what experiments to conduct and what aspects to focus on. The comment is explicit and provides detailed guidance, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Experiments  Ablation,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing: experiments and explanations regarding the different queries used in spatiotemporal representation, such as spatial, temporal, and summary queries. The comment also suggests conducting experiments to explore what would happen if only spatial or temporal and summary queries were used. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the experiments should include an ablation study on the different queries used in spatiotemporal representation, such as spatial, temporal, and summary queries. The reviewer highlights the importance of this comparison to differentiate the work from VideoChatGPT and other works. However, the comment does not provide specific examples or references to support why this comparison is necessary or how it would impact the understanding of the results. While the suggestion is logical, the lack of detailed justification or examples makes the claim 3, as the authors may need to infer the significance of the comparison themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the experiments section, namely the need for an ablation study on the different queries used in spatiotemporal representation. It suggests that experiments should be conducted to explore the impact of using only spatial, temporal, or summary queries, which is a key difference from VideoChatGPT and other works. This feedback is clear and actionable, providing the authors with a concrete direction for enhancing their experimental design and analysis. By addressing this suggestion, the authors can better understand the contributions of their work and provide a more comprehensive evaluation of their approach. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the proposed FRM, which is a combination of channel attention and spatial attention, should be described in more detail. However, it does not provide specific guidance on what aspects of the FRM should be elaborated or how the authors should present this information. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more detailed explanations but without concrete instructions on what to include. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the proposed FRM, which is a combination of channel attention and spatial attention, should be described in more detail. However, it does not specify which part of the paper this description should be added to, making it weakly grounded. The comment is specific in its request for more detailed explanation of the innovative aspects of the FRM. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the proposed FRM, a combination of channel attention and spatial attention, should be described in more detail. However, the comment does not provide any specific reasoning or evidence to support why this description is lacking or how it could be improved. Without additional context or examples, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the proposed FRM, a combination of channel attention and spatial attention, should be described in more detail. This feedback is 3 as it points out a potential weakness in the paper and encourages the authors to provide a more comprehensive explanation of their innovative approach. However, the comment lacks specificity and does not offer detailed guidance on what aspects of the FRM should be elaborated or how to present them. To be more helpful, the comment could include suggestions on what specific details should be included or how to better explain the innovation. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors could mention the social impact of increased automation or the risks from the dual use of their method, even though the reviewer does not believe the work has significant negative social impact. While the comment implies that the authors should address these potential impacts, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should discuss these aspects but are not given specific guidance on how to integrate them into their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 379,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the authors could mention the social impact of increased automation or the risks from the dual use of their method, providing clear guidance on what could be added to the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a factual statement about the authors\" claim regarding the lack of negative social impact and a suggestion to address potential social impacts. The reviewer does not express an opinion or make a claim that requires verification. It is a request for clarification or additional discussion, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment acknowledges the authors\" claim that their work has no negative social impact and suggests that they could address potential social impacts, such as increased automation or dualuse risks. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address these concerns. It does not provide actionable steps or detailed feedback on how to integrate this discussion into the paper. As a result, the comment is 3, as it points out an area for consideration but does not fully support the authors in making improvements."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a lack of clarity regarding the connection between \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness.\" However, it does not provide explicit guidance or suggestions on how the authors might clarify this connection or improve the clarity of their work. The comment highlights an issue but lacks actionable advice, leaving the authors uncertain about how to address the identified problem. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment highlights a lack of clarity regarding the connection between \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness.\" However, it does not specify which part of the paper this issue pertains to, making it difficult for the authors to identify the exact sections that need revision. The comment provides some specificity by pointing out the lack of clarity, but it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is 2, aligning with category 2.", "verifiability_rationale": "The review point claims that there is a lack of clarity regarding the connection between \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness.\" However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed explanation or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a lack of clarity regarding the connection between \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness.\" However, it does not provide specific suggestions or guidance on how the authors might clarify this connection or improve the clarity of their work. While it highlights an area for improvement, the comment lacks actionable feedback, making it 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should conduct theoretical analyses or extensive experiments to understand why the simple greedy selection approach outperforms more principled acquisition functions and why deterministic MLP predictors outperform probabilistic predictors like GPs, deep ensembles, or Bayesian neural networks. However, the comment does not provide explicit instructions or concrete steps on how to conduct these analyses or experiments. While the authors can infer that they need to perform additional research, the lack of detailed guidance makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should conduct theoretical analyses or extensive experiments to understand the reasons behind the empirical results. It mentions specific aspects that could be explored, such as the performance of simple greedy selection versus more principled acquisition functions and the superiority of deterministic MLP predictors over probabilistic predictors. However, the comment does not specify which part of the paper these analyses or experiments should be conducted in, making it weakly grounded. The suggestion is specific in terms of what needs to be addressed, but without explicit references to sections or parts of the paper, the authors may find it challenging to pinpoint the exact areas for improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the empirical results of the proposed method are strong and that a more novel contribution would be to explore theoretical analyses or extensive experiments to understand the reasons behind the performance of simple greedy selection and deterministic MLP predictors. The comment highlights the absence of such rigorous analyses in the paper. However, it does not provide specific examples, references, or detailed reasoning to support the claim that these analyses are necessary or would be beneficial. The lack of evidence or detailed justification makes the claim 3, as the authors would need to infer the importance of these analyses based on the general suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting that the authors conduct theoretical analyses or extensive experiments to understand the reasons behind the empirical results. It specifically mentions the superiority of simple greedy selection over more principled acquisition functions and the performance of deterministic MLP predictors over probabilistic predictors. While the comment highlights an interesting direction for further exploration, it lacks specific guidance or detailed suggestions on how to conduct these analyses or experiments. The authors are left with a general idea of what could be explored but without concrete steps to follow. Therefore, the comment is 3, as it provides some direction but lacks depth and actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly instructs the authors to provide a citation for the \"kmax problem\" and to discuss it elsewhere in the paper. This is a clear and direct action, leaving no ambiguity about what needs to be done. The authors know exactly what step to take to address the comment, making it 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"the kmax problem,\" which allows the authors to identify the specific part of the paper being addressed. It also specifies the action required, which is to provide a citation for this problem and discuss it elsewhere in the paper. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification, specifically asking for a citation for the \"kmax problem\" and its discussion elsewhere in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area for improvement by asking for a citation for the \"kmax problem\" and its discussion elsewhere in the paper. This feedback is clear and actionable, prompting the authors to provide additional context and references to enhance the comprehensiveness of their work. However, the comment could be more helpful if it provided guidance on why this information is important or how it relates to the broader context of the paper. Overall, the feedback is 3 as it directs the authors to a specific area for improvement but lacks depth and detailed guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a lack of information regarding the estimation of the function for the optimal sequence length (Equation 1) and the reliability of the model. However, it does not provide explicit guidance on what the authors should do to address this issue. The comment implies that the authors should include this information, but it lacks concrete details on how to estimate the function or what specific aspects of reliability should be addressed. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper, namely the estimation of the function for the optimal sequence length (Equation 1) and the reliability of the model. This provides full grounding as it explicitly mentions a particular equation and a specific concern about reliability. The comment is also specific because it clearly identifies what information is missing and what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the reliability of the model by noting the absence of information on how the function for the optimal sequence length was estimated (Equation 1). This is a claim that requires justification, as it implies a lack of transparency or understanding of the model\"s reliability. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a critical gap in the paper regarding the estimation of the function for the optimal sequence length (Equation 1) and the reliability of the model. This is an important observation that highlights a lack of transparency and clarity in the methodology, which could impact the credibility of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending additional experiments or analyses to validate the model\"s reliability. While it points out a significant weakness, the feedback lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out a specific issue with the use of the word \"thousands\" in line 006, suggesting that it may not be accurate and recommending the addition of \"on the subword level.\" This feedback provides a clear and direct action for the authors to take, specifying exactly what needs to be changed and how to implement it. The comment is explicit and concrete, giving the authors a clear understanding of what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L006,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the use of \"thousands\" is not accurate and suggests adding \"on the subword level.\" This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the use of \"thousands\" in line 006 is not accurate and suggests adding \"on the subword level.\" However, the comment does not provide any supporting evidence, reasoning, or references to justify why \"thousands\" is incorrect or how the addition of \"on the subword level\" would improve the accuracy. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the use of the word \"thousands\" in line 006, suggesting that it may not be accurate and recommending the addition of \"on the subword level.\" This feedback is clear and actionable, providing the authors with a precise suggestion to improve the accuracy and clarity of their draft. By addressing this point, the authors can enhance the precision and correctness of their work. However, the comment could be more helpful if it explained why \"thousands\" is not accurate or how the addition would improve the draft. Overall, the comment is 4 as it offers a specific and actionable suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises several issues. First, it notes that some hyperparameters, such as regularization, are not given. Second, it questions why the y value at x=0 is always 0 in the latent path figures, suggesting that this might be due to normalization. The reviewer also requests clarification in the description and suggests further analysis using the interpolations. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to address these issues. The actions are implicit and somewhat vague, as the authors need to infer what specific changes are needed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises multiple issues, including the lack of information on hyperparameters and the behavior of the y value at x=0 in the latent path figures. It also suggests further analysis using interpolations. While the comment does not explicitly mention specific sections or figures, the authors can infer that it relates to the sections discussing hyperparameters and the latent path figures, such as Figure 3. The comment is specific in detailing what needs to be addressed, namely the lack of hyperparameter information and the behavior of the y value at x=0. However, it lacks full grounding as it does not explicitly mention the sections or figures being addressed. Therefore, this comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises several claims, each of which requires verification. First, it claims that \"a number of hyperparameters are not given,\" which is a subjective opinion that lacks specific examples or references to support the claim. Second, it questions why the y value at x=0 is always 0 in the latent path figures, suggesting that it might be due to normalization. This claim is 3 as it provides a logical reasoning but lacks specific evidence or references. Third, the reviewer suggests further analysis using interpolations, which is a request for additional work rather than a claim. Overall, the comment contains a mix of claims and requests, with some elements being 3 and others requiring more detailed justification. Therefore, the overall score is 3.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper. It points out the lack of information on hyperparameters, such as regularization, which is important for reproducibility and understanding the model\"s behavior. It also questions the behavior of the y value at x=0 in the latent path figures, suggesting that it might be due to normalization and asking for clarification. Additionally, the reviewer suggests further analysis using interpolations, which could provide valuable insights into the model\"s performance. While the comment highlights specific issues and offers suggestions for improvement, it could be more helpful by providing more detailed guidance on how to address these points. Overall, the feedback is 4 as it directs the authors to areas that need clarification and additional analysis, but it could be more comprehensive with specific suggestions or examples."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies two issues: forward referencing and the need for clearer explanations of contributions in the introduction. It also mentions that material supporting the main contributions is in the appendix rather than the main sections. While the comment highlights areas for improvement, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to clarify the contributions in the introduction and ensure that the main contributions are discussed in the main sections, but the comment lacks concrete guidance on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"the Introduction,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the need for clearer explanations of contributions and the placement of material supporting the main contributions in the appendix rather than the main sections. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is forward referencing in the paper, with material being introduced without proper explanation and then explained later. It also mentions that the main contributions are not clearly written in the introduction and that supporting material is in the appendix rather than the main sections. However, the comment lacks specific examples or references to substantiate these claims, making it difficult for the authors to understand the exact issues and address them effectively. The lack of detailed evidence or examples makes the claim 3, as it provides a general direction but requires more detailed justification for the authors to fully understand and address the issues.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper: forward referencing, where material is introduced without proper explanation and is explained later, and the need for clearer explanations of contributions in the introduction. It also points out that material supporting the main contributions is in the appendix rather than the main sections, which could impact the reader\"s understanding. While the comment highlights important areas for improvement, it does not provide detailed guidance on how to address these issues or specific suggestions for reorganizing the content. The feedback is 4 as it directs the authors to clarify their contributions and improve the flow of the paper, but it could be more comprehensive with additional guidance. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the theoretical effect of rounding core tensors to smaller ranks with a given accuracy, specifically asking for an error bound in terms of epsilon. While the comment does not explicitly instruct the authors to provide this information, it implies that the authors should address this gap in their explanation. The action is implicit but concrete, as the authors know exactly what information is missing and how to address it by providing an error bound in terms of epsilon. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the part of the paper where the issue is discussed, specifically the mention of rounding core tensors to smaller ranks with a given accuracy. This allows the authors to accurately identify the section being addressed. The comment is also specific because it clearly specifies the issue of the theoretical effect on the approximation in the full tensor error and asks for an error bound in terms of epsilon. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the theoretical effect of rounding core tensors to smaller ranks with a given accuracy, specifically asking for an error bound in terms of epsilon. The comment does not contain any subjective opinions, judgments, or suggestions that require verification. It is a factual question seeking clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the theoretical effect of rounding core tensors to smaller ranks with a given accuracy, particularly regarding the full tensor error. It asks for an error bound in terms of epsilon, which is a clear and actionable suggestion for the authors to address. By prompting the authors to provide this information, the comment offers a constructive way to enhance the theoretical foundation of their work. However, the comment could be more helpful if it provided additional context or examples to guide the authors in understanding the implications of this question. Overall, the comment is 4 as it identifies a gap in the paper and suggests a specific area for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the results presented in Table 1, specifically noting that it only shows results for the discriminative setting, which is known to not apply to real applications. The reviewer questions the results for the generative setting and requests clarification. While the comment implies that the authors should provide results for the generative setting, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to address the missing results but are not given specific guidance on how to present them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of results for the generative setting in Table 1, and questions the applicability of the discriminative setting to real applications. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the results presented in Table 1, specifically noting that it only shows results for the discriminative setting, which is known to not apply to real applications. The reviewer requests clarification on the results for the generative setting. While the comment highlights a potential gap in the results, it does not provide specific reasoning or evidence to support the claim that the discriminative setting is not applicable to real applications. The lack of detailed justification or references makes the claim 3, as the authors would need to investigate the issue further to address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of results in the paper, noting that Table 1 only shows results for the discriminative setting, which is known to not apply to real applications. The reviewer questions the results for the generative setting and requests clarification. This feedback is clear and actionable, as it highlights a gap in the results presented and prompts the authors to address it by providing results for the generative setting. By doing so, the authors can ensure that their work is more comprehensive and applicable to realworld scenarios. However, the comment could be more helpful if it provided additional context or suggestions on how to present the generative setting results. Overall, the comment is 4, as it directs the authors to a specific area for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the evaluation of the proposed approach for other language families, suggesting that its effectiveness is unknown. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to evaluate the approach for other language families or what specific steps should be taken to determine its effectiveness. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment highlights a gap in the evaluation of the proposed approach for other language families, suggesting that its effectiveness is unknown. However, it does not specify which part of the paper this issue pertains to, such as a specific section or analysis, making it weakly grounded. The comment is specific in identifying the lack of evaluation for other language families, but without clear grounding, the authors may struggle to determine where to address this issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the effectiveness of the proposed approach for other language families remains unknown. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a significant gap in the evaluation of the proposed approach, specifically noting that its effectiveness for other language families remains unknown. This is a critical observation that highlights an important area for further exploration and validation. However, the comment lacks specific suggestions or guidance on how the authors might address this gap or conduct additional evaluations. While it points out a key weakness, it does not provide actionable feedback or detailed advice on how to improve the draft. Therefore, the comment is 3, as it directs the authors\" attention to an important area for improvement but does not fully support them in making those improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the form of p should be described near line 135, as it is currently not explicitly stated. The reviewer assumes that p is a Gaussian distribution but notes that it is not explicitly mentioned. This provides a clear and direct action for the authors to take, which is to clarify the form of p in the manuscript. The comment is explicit and provides concrete guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 135,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the description of the form of p. The reviewer assumes that p is a Gaussian distribution but notes that it is not explicitly stated. This provides clear guidance on what needs to be clarified in the manuscript. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the form of p should be described near line 135, as it is currently not explicitly stated. The reviewer assumes that p is a Gaussian distribution but notes that it is not explicitly mentioned. This is a request for clarification rather than a claim, as it does not express an opinion, judgment, or suggestion that requires verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by suggesting that the form of p should be described near line 135. The reviewer assumes that p is a Gaussian distribution but notes that it is not explicitly stated. This feedback is clear and actionable, as it provides a direct suggestion for enhancing the clarity and completeness of the manuscript. By addressing this point, the authors can improve the readability and comprehensibility of their work. However, the comment could be more helpful if it provided additional context or examples on how to describe the form of p. Overall, the comment is 4, as it guides the authors toward a specific improvement but could be more comprehensive with further guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the related work section could be improved by describing the differences between the works mentioned. However, it does not provide specific guidance on how to achieve this improvement or which works need more detailed descriptions. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more detailed descriptions of the differences between the related works. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the clarity of the related work section, specifically mentioning that some related works are named but their differences are not described enough. However, it does not specify which part of the related work section this issue pertains to, making it weakly grounded. The comment is specific in identifying the need for more detailed descriptions of the differences between related works. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the related work section could be improved by describing the differences between the works mentioned. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand which works are insufficiently described or how they could be improved. The lack of detailed justification or examples makes the claim 3, as the authors would need to invest effort to determine the specific issues and address them. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The comment identifies a specific area for improvement in the related work section, noting that some works are mentioned but their differences are not described in detail. This feedback is 3 as it points out a potential weakness in the paper and suggests a direction for enhancement. However, it lacks specificity and does not provide detailed guidance on how to address the issue, such as which works need more detailed descriptions or what aspects of their differences should be highlighted. To be more helpful, the comment could include examples or suggestions for improvement. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the authors mention the importance of reliable PPP metrics for understanding PPP effects in different tasks but do not provide an explicit explanation or understanding of this concept. The reviewer asks the authors to explicitly explain what type of understanding one reaches by looking at PPP maps. This request is explicit and provides clear guidance on what the authors need to do to improve their draft. The action is concrete, as it specifies the exact information that needs to be added to the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the authors\" statement about the importance of reliable PPP metrics for understanding PPP effects in different tasks. However, it does not specify which part of the paper this statement is made in, making it weakly grounded. The comment is specific in its request for the authors to explicitly explain what type of understanding one reaches by looking at PPP maps. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the authors\" statement about the importance of reliable PPP metrics for understanding PPP effects in different tasks, noting that this explanation or understanding is not explicitly given in the article. The reviewer asks for clarification by requesting an explanation of what type of understanding one reaches by looking at PPP maps. While the comment highlights a gap in the paper, it does not provide specific reasoning or evidence to support the claim that such an explanation is necessary. This makes the comment 3, as it identifies a potential area for improvement but lacks detailed justification or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the explanation of the importance of reliable PPP metrics for understanding PPP effects in different tasks. It points out that while the authors mention this point, they do not provide an explicit understanding or explanation. The reviewer asks for clarification by requesting that the authors explicitly explain what type of understanding one reaches by looking at PPP maps. This feedback is clear and actionable, as it directs the authors to enhance their draft by providing a more detailed explanation of the concept. However, it could be more helpful if it offered specific suggestions on how to present this explanation or what aspects to focus on. Overall, the comment is 4, as it guides the authors toward improving their draft by addressing a critical gap in the paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of comparison with other stateoftheart methods, such as SpanBERT, which could impact the credibility of the paper. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific methods to include in the comparison. The action is implicit and somewhat vague, as the authors are left to infer that they need to conduct additional comparisons but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights a lack of comparison with other stateoftheart methods, specifically mentioning SpanBERT. However, it does not specify which part of the paper this comparison should be included in, such as the methodology or results sections. The authors can infer that it relates to the evaluation or comparison sections, but the comment lacks full grounding as it does not explicitly mention these sections. The comment is specific in identifying the need for comparison with SpanBERT, but it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors lack credibility due to not comparing their methods with other stateoftheart methods, specifically mentioning SpanBERT. However, the comment does not provide any specific examples or detailed reasoning to support why this comparison is necessary or how it would impact the credibility of the paper. The lack of supporting evidence or detailed justification makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by noting the absence of comparisons with other stateoftheart methods, specifically mentioning SpanBERT. This feedback is valuable as it highlights a critical area for improvement that could enhance the credibility and relevance of the paper. However, the comment does not provide specific suggestions on which methods to compare or how to conduct the comparison, leaving the authors with a general direction but without detailed guidance. While the feedback is 3 in pointing out a key area for enhancement, it could be more actionable with additional details. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the training process for RBI, noting that it only considers rewarded actions and ignores rewardless actions that provide useful supervision. The reviewer suggests that this could be a significant factor contributing to the performance of FP + RBI over RBI alone. The comment implies that the authors should provide a stronger baseline than RBI, which is supervised by feedback, to prove the usefulness of FP. However, the comment does not explicitly instruct the authors to do so or provide specific guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors can infer the need for a stronger baseline but are not given concrete steps on how to achieve it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the training process for RBI, specifically noting that it only considers rewarded actions and ignores rewardless actions that provide useful supervision. The reviewer suggests that this could be a significant factor contributing to the performance of FP + RBI over RBI alone. However, the comment does not specify which part of the paper discusses RBI or FP, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, while the comment provides a specific concern about the training process, it lacks detailed guidance on how to address this issue or improve the paper. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a concern about the training process for RBI, specifically noting that it only considers rewarded actions and ignores rewardless actions that provide useful supervision. The reviewer suggests that this could be a significant factor contributing to the performance of FP + RBI over RBI alone. The comment implies that the authors should provide a stronger baseline than RBI, which is supervised by feedback, to prove the usefulness of FP. However, the comment lacks specific examples or references to support the claim that rewardless actions are ignored, making it 3. The authors would need to further explore and substantiate the claim to fully understand its implications. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the training process for RBI, specifically noting that it only considers rewarded actions and ignores rewardless actions that provide useful supervision. The reviewer suggests that this could be a significant factor contributing to the performance of FP + RBI over RBI alone. The comment implies that the authors should provide a stronger baseline than RBI, which is supervised by feedback, to prove the usefulness of FP. While the comment highlights a relevant issue, it lacks specific guidance or suggestions on how the authors might address this concern or improve their draft. The feedback is 3 as it points out a potential area for improvement, but it could be more actionable with additional details or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the use of the term \"multiscale\" in the context of the slow and fast RNNs, suggesting that it is misleading because the RNNs operate on a logical time scale rather than a physical one. The reviewer highlights that the only benefit seems to be the reduction of gradient path by the slow RNN. While the comment identifies a potential issue with the terminology, it does not provide explicit guidance on how to address it or suggest alternative wording. The action is implicit and somewhat vague, as the authors are left to infer that they should clarify the terminology or provide additional context. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the use of the term \"multiscale\" in the context of the slow and fast RNNs, suggesting that it is misleading because the RNNs operate on a logical time scale rather than a physical one. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the terminology and the potential benefit of the slow RNN, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the use of the term \"multiscale\" is misleading because the slow and fast RNNs operate on a logical time scale rather than a physical one. The reviewer provides a logical reasoning by explaining that the RNNs operate on a logical time scale when the stacks are sequentialized in the graph. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the terminology used in the paper, specifically the term \"multiscale,\" which the reviewer suggests is misleading. The reviewer explains that the slow and fast RNNs operate on a logical time scale rather than a physical one, and that the only benefit seems to be the reduction of gradient path by the slow RNN. This feedback is clear and actionable, as it points out a specific area where the authors might need to clarify their terminology or provide additional context to avoid confusion. However, the comment could be more helpful if it offered suggestions on how to rephrase or clarify the terminology. Overall, the comment is 4 as it provides valuable insight into a potential misunderstanding in the paper, prompting the authors to consider revising their terminology for clarity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors clarify the distinction between the decisionmaker\"s interest in the true objective function and the noise, which is currently not represented clearly. It implies that the authors should make this distinction clearer upfront in the paper. While the comment explicitly states the need for clarification, it does not provide specific guidance on how to achieve this clarity. The action is explicit but somewhat vague, as the authors know they need to clarify the distinction but may not be entirely sure of the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"formulation in this paper,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the need to clarify the distinction between the decisionmaker\"s interest in the true objective function and the noise, and how this differs from the current formulation. The comment provides a clear direction for improvement by suggesting that the authors make this distinction clearer upfront. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the expected performance under observation noise is typically used for evaluation because the decisionmaker is interested in the true objective function, while the noise is assumed to be noise. It argues that in the paper\"s formulation, the decisionmaker does care about the noise, and the objective function of interest is the stochastic noisy function. The comment suggests that this distinction should be made clearer upfront. The reasoning is logical and based on common knowledge about evaluation practices, making the claim 4. However, the comment could be strengthened by providing specific examples or references to support the claim, which would align it with a score of 5.", "helpfulness_rationale": "The review comment identifies a potential confusion in the paper regarding the decisionmaker\"s interest in the true objective function versus the noise. It points out that the typical approach is to evaluate expected performance under observation noise, assuming the noise is misleading and not representative. However, the comment notes that in the paper\"s formulation, the decisionmaker does care about the noise, and the objective function of interest is the stochastic noisy function. This feedback is clear and actionable, as it suggests that the authors should clarify this distinction upfront in the paper. By addressing this point, the authors can improve the clarity and accuracy of their work. Therefore, the comment is 4, as it provides a specific area for improvement with actionable guidance, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about running VGAE with a vamp prior to better match the doubly stochastic construction in the work. It suggests that this could help determine whether the benefits are coming from a better generative model or better inference due to doublysemi implicit variational inference. Additionally, it provides a minor point about Figure 3, suggesting that keeping the generative model fixed and optimizing only the inference part of the model could help compare representations. While the comment implies an action by questioning the use of VGAE with a vamp prior, it does not explicitly instruct the authors to do so. The suggestion about Figure 3 is more explicit but lacks detailed guidance on how to implement it. Overall, the comment provides some actionable insights but lacks concrete instructions, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, such as running VGAE with a vamp prior to better match the doubly stochastic construction and comparing representations by keeping the generative model fixed. This provides clear guidance on how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about running VGAE with a vamp prior to better match the doubly stochastic construction in the work. It suggests that this could help determine whether the benefits are coming from a better generative model or better inference due to doublysemi implicit variational inference. The comment also provides a minor point about Figure 3, suggesting that keeping the generative model fixed and optimizing only the inference part of the model could help compare representations. However, the comment lacks specific examples, references, or detailed reasoning to fully substantiate the claim about the benefits of VGAE with a vamp prior. While it provides some logical reasoning, it is not 5 due to the lack of detailed evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by questioning the use of VGAE with a vamp prior to better match the doubly stochastic construction. This suggestion could help the authors determine whether the benefits are coming from a better generative model or better inference due to doublysemi implicit variational inference. Additionally, the comment offers a minor point about Figure 3, suggesting that keeping the generative model fixed and optimizing only the inference part of the model could help compare representations. This feedback is specific and provides a clear direction for the authors to explore, making it 4. However, the comment could be more comprehensive by elaborating on the potential benefits of this approach or providing more detailed guidance on how to implement it. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the demonstration or results related to the model collapsing less than other methods. It also references a specific line in the paper where the reviewer noted that gradients become 0 and collapse. The comment implies that the authors should address whether this issue is commonly encountered and if it was observed in their experiments. While the comment does not explicitly instruct the authors to provide additional information or results, it does suggest a direction for further exploration. The action is implicit but concrete, as the authors know they need to address the issue of model collapse and its implications. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 159,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the demonstration or results related to the model collapsing less than other methods, and it seeks clarification on whether this issue is commonly encountered and observed in the experiments. This provides clear guidance on what the authors need to address or clarify. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question seeking clarification on whether the authors have observed model collapse in their experiments and whether it is a common issue. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises an important question about the demonstration or results related to the model collapsing less than other methods. It references a specific line in the paper where the reviewer noted that gradients become 0 and collapse, which is a good point. The comment seeks clarification on whether this issue is commonly encountered and if it was observed in the authors\" experiments. This feedback is 3 as it prompts the authors to address a potential weakness in their work and provides a specific area for further exploration. However, it could be more helpful if it offered suggestions on how to address this issue or provided examples of how other methods might handle it. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests conducting experiments with different LLM families, such as OPT, BLOOM, or other alternatives, to provide valuable insights into the method\"s applicability and generalizability. This feedback is clear and provides a concrete action for the authors to take, which is to conduct additional experiments. The suggestion is specific and leaves no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests conducting experiments with different LLM families, such as OPT, BLOOM, or other alternatives, to provide insights into the method\"s applicability and generalizability. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its request for additional experiments, but without clear grounding, the authors may struggle to determine where these experiments should be integrated. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests conducting experiments with different LLM families, such as OPT, BLOOM, or other alternatives, to provide insights into the method\"s applicability and generalizability. The comment is based on a logical reasoning that additional experiments could enhance the understanding of the method\"s applicability across various LLM families. However, it lacks specific examples or references to support the claim that these experiments would be valuable or necessary. The suggestion is 3 as it provides a logical rationale but lacks detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the paper lacks experiments on different LLM families, such as OPT, BLOOM, or other alternatives. This feedback is clear and actionable, as it provides a concrete suggestion for expanding the experimental scope to enhance the paper\"s applicability and generalizability. By conducting these additional experiments, the authors can gain valuable insights into the method\"s performance across various LLM families, which could significantly strengthen the paper\"s contribution. However, the comment could be more helpful if it provided guidance on how to design these experiments or what specific aspects to focus on. Overall, the feedback is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a perceived disconnect between the first part of the paper, which involves curve finding, and the second part, which focuses on FGE. The reviewer suggests that the connection between these two parts is weak and that the initial expectation of the first part was not met. However, the comment does not provide explicit guidance or suggestions on how to strengthen the connection or improve the clarity of the paper. The feedback lacks actionable details, leaving the authors uncertain about how to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a perceived disconnect between the first part of the paper, which involves curve finding, and the second part, which focuses on FGE. However, it does not specify which sections or parts of the paper these topics are discussed in, making it difficult for the authors to pinpoint the exact areas needing revision. The comment provides some specific feedback about the expectations and outcomes of the first part, but it lacks detailed guidance on how to address the perceived weakness. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the connection between the curve finding (the first part) and FGE (the second part) is weak. The reviewer provides a specific expectation of what the first part should entail, which is learning curves between weights and finding nice weights to be mixed into the final ensemble. However, the comment does not explain why this expectation was not met or how the current approach differs from the expected one. Additionally, the comment mentions that the approach could work but is computationally demanding, without elaborating on the implications or providing evidence to support this claim. The lack of detailed reasoning or examples makes the claim 3, as it requires more information to fully understand and address the critique.", "helpfulness_rationale": "The review comment identifies a perceived disconnect between the first part of the paper, which involves curve finding, and the second part, which focuses on FGE. It suggests that the initial expectation of the first part was not met, as it did not involve learning curves between weights and finding nice weights to be mixed into the final ensemble. However, the comment acknowledges that this approach could work but is computationally demanding. While the comment highlights a potential issue, it lacks specific guidance or suggestions on how to address the disconnect or improve the clarity of the paper. The feedback is 3 as it points out a potential weakness, but it does not provide actionable steps for improvement, making it incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include the results for linear scalarization with Concorde, a heuristicbased solver, for a better comparison. This is an explicit action with concrete details on how to implement it, as it specifies the exact method and comparison to be included. The authors know exactly what needs to be done to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2\" and \"Concorde,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the experimental results, namely the need to include the results for linear scalarization with Concorde for a better comparison. This provides clear guidance on what needs to be addressed. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the learningbased solvers are better than the heuristicbased solvers, except for the single objective TSP where the SOTA heuristicsolver (Concorde) performs best. The reviewer suggests including the results for linear scalarization with Concorde for a better comparison. This claim is 3 as it is based on the experimental results presented in the paper, but it lacks specific references or detailed reasoning to fully substantiate the claim. The suggestion to include additional results is logical, but the comment could be strengthened with more detailed justification or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental results, noting that the learningbased solvers outperform the heuristicbased solvers except for the single objective TSP, where the SOTA heuristicsolver (Concorde) performs best. The reviewer suggests including the results for linear scalarization with Concorde for a better comparison, which is a clear and actionable piece of feedback. This guidance helps the authors enhance the comprehensiveness and validity of their experimental analysis, making the comment 4. However, the comment could be more helpful if it provided additional context or explanation on why this comparison is important or how it might impact the overall conclusions. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should discuss the proposed method in relation to existing methods that capture similar general ideas, such as the generalized Voronoi graph, semantic maps, and pose graphs in SLAM. While the comment implies that the authors should make these comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to make these comparisons or what aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"grounding of the proposed method in neuroscience\" and the \"general ideas\" that are already present in other methods, such as the generalized Voronoi graph, semantic maps, and pose graphs in SLAM. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely, discussing the proposed method in relation to these existing methods. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some of the general ideas in the proposed method are already present in other methods, specifically mentioning the generalized Voronoi graph, semantic maps, and pose graphs in SLAM. The reviewer provides a detailed explanation of how these existing methods capture similar ideas, such as reasoning topologically and longterm storage through pose graphs. This reasoning is clear and provides a logical basis for the claim, making it 4. However, the comment could be strengthened by including specific references to these existing methods, which would further support the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by pointing out that some of the general ideas proposed are already present in other methods, such as the generalized Voronoi graph, semantic maps, and pose graphs in SLAM. It suggests that the paper should discuss the proposed method in relation to these existing methods, which would provide a more comprehensive context for the work. This feedback is clear and actionable, as it directs the authors to consider how their method fits within the existing literature, potentially leading to a more robust and comparative discussion. However, the comment could be more helpful if it provided specific examples or references to guide the authors in making these comparisons. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the choice of using GRU for the Pyramid and LSTM for the sequential part, inquiring if the combination of two architectures is the reason for the improvements. While it highlights a potential area of interest, it does not provide explicit guidance or suggestions for the authors to address this question or improve their draft. The action is implicit and somewhat vague, as the authors are left to infer that they might need to provide a rationale or justification for their architectural choices. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the choice of using GRU for the Pyramid and LSTM for the sequential part, inquiring if the combination of two architectures is the reason for the improvements. However, it does not specify which part of the paper discusses these architectural choices, making it weakly grounded. The comment is specific in its inquiry about the rationale behind the architectural choices, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point is a question seeking clarification about the choice of using GRU for the Pyramid and LSTM for the sequential part. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the choice of using GRU for the Pyramid and LSTM for the sequential part, inquiring if the combination of two architectures is the reason for the improvements. While it highlights a potential area of interest, it does not provide specific guidance or suggestions on how the authors might address this question or improve their draft. The comment lacks depth and actionable feedback, leaving the authors with only a vague direction for improvement. Therefore, it is 2, aligning with a score of 2."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the definition of \"active vertices\" in the context of line 135. While it does not explicitly instruct the authors to clarify the definition, it implies that they should provide a clear explanation of this term. The action is implicit but concrete, as the authors can infer that they need to clarify the definition of \"active vertices\" in their draft. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 135,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the definition of \"active vertices,\" prompting the authors to clarify this term. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification on the definition of \"active vertices\" in the context of line 135. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the definition of \"active vertices\" in the context of line 135, which is a specific and relevant point that could help clarify the paper\"s content. By asking for clarification, the reviewer prompts the authors to provide a clear definition of this term, which could enhance the understanding of the paper for readers. However, the comment does not offer any suggestions or guidance on how to address this issue or improve the clarity of the paper. While it identifies a potential area for improvement, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two main issues: the lack of mention of the inapplicability of the theory to the used model in the limitations section and the vague nature of the structural assumptions given in the appendix. It also suggests that the authors underestimate the current use of graph neural networks in industry and recommends providing more elaboration on potential negative societal impacts. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to clarify the limitations and provide more detailed information on the structural assumptions, as well as consider the societal impact of graph neural networks. However, the lack of concrete guidance on how to implement these changes makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"limitations\" section of the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of mention of the inapplicability of the theory to the used model, the vagueness of the structural assumptions given in the appendix, and the need for more elaboration on potential negative societal impacts of graph neural networks. This provides clear guidance on what needs to be addressed in the limitations section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not mention the inapplicability of its theory to the used model in the limitations section, which is a subjective opinion. The reviewer also suggests that the structural assumptions are vague and not clearly stated, which could be a valid observation. However, the comment lacks specific examples or references to support these claims, making it 3. The suggestion to provide more elaboration on potential negative societal impacts of graph neural networks is a logical request but again lacks detailed justification or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a detailed critique of the paper, identifying several areas for improvement. It points out that the theory\"s applicability to the used model is not mentioned in the limitations section, which is a significant oversight. The comment also highlights the vagueness of the structural assumptions given in the appendix, making it difficult for readers to understand the limitations. Additionally, the reviewer suggests that the authors underestimate the current use of graph neural networks in industry and recommends providing more elaboration on potential negative societal impacts. This feedback is clear and actionable, offering specific areas for the authors to address and improve their draft. However, it could be more helpful if it included suggestions on how to clarify the structural assumptions or address the societal impact concerns. Overall, the comment is 4, as it provides valuable insights and guidance for enhancing the paper."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a specific observation about the impact of the projection head (CNN layers) and the classification head (FCN layer). However, it does not provide any explicit or implicit action for the authors to take. There is no guidance on how to address this observation or what changes, if any, should be made to improve the draft. Without actionable suggestions or questions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"projection head (CNN layers)\" and the \"classification head (FCN layer),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out a particular observation about the impact of these heads, which provides clear guidance on what needs to be addressed. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about the impact of the projection head (CNN layers) and the classification head (FCN layer). It does not express an opinion, make a claim, or suggest changes. It is purely descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment points out a specific observation regarding the impact of the projection head (CNN layers) and the classification head (FCN layer). However, it does not provide any context, explanation, or suggestions for improvement. Without additional information or guidance, the authors are left without a clear understanding of why this observation is relevant or how it might impact their work. The comment lacks depth and actionable feedback, making it 2 at best. Therefore, it aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the generalizability of the model to focusing distances not present in the training data. It explicitly asks for an explanation of how the model performs on focusing distances other than those in the training data. This provides a clear and direct action for the authors to take, which is to address the generalizability issue by providing additional information or analysis. The comment is explicit and concrete, giving the authors a clear understanding of what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the generalizability of the model to focusing distances not present in the training data, and it asks for an explanation of how the model performs on these distances. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the generalizability of the model to focusing distances not present in the training data. It does not contain any subjective claims, opinions, or suggestions that require verification. It is a factual question seeking clarification, making it a normal statement. Therefore, the label \"No\" is appropriate.", "helpfulness_rationale": "The review comment raises a pertinent question about the generalizability of the model to focusing distances not present in the training data. By asking for an explanation of how the model performs on these distances, the comment prompts the authors to consider and address a potential limitation of their work. This feedback is clear and actionable, as it directs the authors to provide additional information or analysis to enhance the robustness and applicability of their model. However, the comment could be more helpful if it suggested specific methods or approaches for evaluating generalizability. Overall, the comment is 4, as it provides a clear direction for improvement but lacks some depth in terms of detailed guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should consider defining content and style more broadly, particularly as it relates to their specific neural application. It references a specific work by Gabbay & Hosehn (2018) to illustrate how style can be instancespecific and content can include information that can be transferred among groups. The comment also questions what the authors mean by \"style\" representing the \"movement dynamic\" in their model, which is not sequential and does not capture temporal dynamics. While the comment implies that the authors should clarify these concepts, it does not provide explicit instructions on how to define or clarify them. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the feedback. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should consider defining content and style more broadly, particularly as it relates to their specific neural application. It references a specific work by Gabbay & Hosehn (2018) to illustrate how style can be instancespecific and content can include information that can be transferred among groups. The comment also questions what the authors mean by \"style\" representing the \"movement dynamic\" in their model, which is not sequential and does not capture temporal dynamics. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the sections discussing content and style in their neural application. The comment is specific in its request for clarification on the definitions of content and style, as well as the implications for their model. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should consider defining content and style more broadly, particularly as it relates to their specific neural application. It references a specific work by Gabbay & Hosehn (2018) to illustrate how style can be instancespecific and content can include information that can be transferred among groups. The comment also questions what the authors mean by \"style\" representing the \"movement dynamic\" in their model, which is not sequential and does not capture temporal dynamics. While the comment provides a reference to external work, it lacks detailed explanation or examples from the authors\" work to fully substantiate the claim. This makes the comment 3, as it provides a starting point for the authors to consider but requires further elaboration. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should consider defining content and style more broadly, particularly as it relates to their specific neural application. It references a specific work by Gabbay & Hosehn (2018) to illustrate how style can be instancespecific and content can include information that can be transferred among groups. The comment also questions what the authors mean by \"style\" representing the \"movement dynamic\" in their model, which is not sequential and does not capture temporal dynamics. This feedback is 3 as it prompts the authors to clarify their terminology and provides a reference for a broader definition of content and style. However, the comment could be more helpful if it offered specific suggestions on how to define these terms or how to incorporate the referenced work into their own context. Overall, the comment provides some direction but lacks depth and detailed guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point provides a detailed critique of the analysis of vit quantification, specifically addressing the claim that a direct quantization method leads to information distortion and that the proposed approach does not improve this phenomenon. It also points out the large loss of precision introduced by the quantization of MHSA, which has been observed in transformer quantization in NLP. The comment highlights specific examples and references to support its claims, providing concrete evidence for the authors to consider. However, while it identifies issues, it does not explicitly instruct the authors on how to address these concerns or improve their analysis. The action is implicit and somewhat vague, as the authors can infer that they need to provide a more detailed explanation or address the issues raised, but they are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the analysis of vit quantification, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed critiques and examples, such as the comparison of quantization methods in Line 45 and the figures (1(b) and 5(b)) for Block.3, as well as references to transformer quantization in NLP. This level of detail helps the authors understand what needs to be addressed in their analysis. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two main claims: (1) the analysis of vit quantification could be explained in depth, and (2) the quantization of MHSA introduces a large loss of precision, which has been observed in transformer quantization in NLP. The first claim is supported by specific examples and references to figures, providing a clear basis for the critique. The second claim is also supported by references to transformer quantization in NLP, which adds credibility to the assertion. However, the comment could be strengthened by providing more detailed reasoning or examples for the first claim. Overall, the claims are 4, as they are wellsupported but could benefit from additional explanation or references. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a detailed critique of the analysis of vit quantification, specifically addressing the claim that a direct quantization method leads to information distortion and that the proposed approach does not improve this phenomenon. It supports this claim with specific examples from the paper, such as the comparison of quantization results in Figures 1(b) and 5(b) for Block.3. Additionally, the comment highlights the large loss of precision introduced by the quantization of MHSA, which has been observed in transformer quantization in NLP. This feedback is valuable as it identifies specific areas where the analysis could be improved and provides concrete examples for the authors to consider. However, the comment could be more helpful if it offered suggestions on how to address these issues or improve the analysis. Overall, the comment is 4, as it provides clear and actionable feedback that can guide the authors in enhancing their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a main weakness in the work, specifically the lack of technical novelty with respect to spatial transformer networks (STN) and the absence of comparisons to STN. It highlights that the proposed Xtransformation is similar to STN but applied locally, and mentions existing works that apply STN in a local pixel neighborhood. The comment also notes that PointNet uses a variant of STN in their network architecture, suggesting that the technical novelty is limited. Additionally, it points out the lack of empirical or conceptual comparisons to STN, which is considered important. While the comment clearly identifies the issues, it does not provide explicit guidance on how to address them, such as suggesting specific comparisons or improvements to enhance the novelty. The action is implicit and somewhat vague, as the authors can infer that they need to address the lack of novelty and comparisons, but they are not given concrete steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"spatial transformer networks (STN)\" and \"PointNet,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of technical novelty and the absence of comparisons to STN, which are important aspects of the work. The comment provides specific examples of existing works that apply STN in a local pixel neighborhood and mentions PointNet\"s use of a variant of STN. This level of detail helps the authors understand what needs to be addressed in their draft. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the technical novelty of the work is limited due to its similarity to existing work on spatial transformer networks (STN) and the lack of comparisons to STN. The reviewer provides specific examples of existing works, such as PointNet, which uses a variant of STN, and mentions that the proposed Xtransformation is similar to STN but applied locally. This level of detail supports the claim, making it 4. However, the comment could be strengthened by providing more detailed comparisons or references to specific aspects of the work that lack novelty. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant weakness in the work, specifically the lack of technical novelty with respect to spatial transformer networks (STN) and the absence of comparisons to STN. It highlights that the proposed Xtransformation is similar to STN but applied locally, and mentions existing works that apply STN in a local pixel neighborhood. Additionally, it points out that PointNet uses a variant of STN in their network architecture, suggesting that the technical novelty is limited. The comment also notes the absence of empirical or conceptual comparisons to STN, which is considered important. This feedback is clear and actionable, as it directs the authors to address the lack of novelty and comparisons, which are crucial for the work\"s impact. However, it could be more helpful if it provided specific suggestions on how to enhance the novelty or conduct comparisons. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point consists of two parts: a correction of a typographical error and a suggestion to link theorems and corollaries to their corresponding proofs. The first part is explicit and actionable, as it clearly instructs the authors to correct the figure reference. The second part is also explicit and actionable, as it provides a specific action for the authors to take to improve the paper\"s readability. However, the comment does not provide detailed guidance on how to link the theorems and corollaries to their proofs, which could be more concrete. Overall, the comment is 4, as it provides clear actions but could be more detailed in some aspects.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Row 821 in Supp. Page 31,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out a typographical error (\"Fig.7\" should be \"Fig.12\") and suggests linking theorems and corollaries to their corresponding proofs to improve readability. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts: a correction of a typographical error and a suggestion to link theorems and corollaries to their corresponding proofs. The first part is factual and does not contain a claim, while the second part is a suggestion for improvement. The suggestion is logical and straightforward, aiming to enhance the paper\"s readability. However, it lacks specific examples or references to support the claim that this improvement is necessary or beneficial. Therefore, the comment is 4, as it provides a clear suggestion but lacks detailed justification or evidence.", "helpfulness_rationale": "The review comment provides two specific pieces of feedback. First, it corrects a typographical error by pointing out that \"Fig.7\" should be \"Fig.12\" in a specific row of the supplementary material. This is a clear and actionable suggestion that helps the authors improve the accuracy of their paper. Second, it suggests linking theorems and corollaries to their corresponding proofs, which would enhance the paper\"s readability and make it easier for readers to follow the logical flow. This is a constructive and actionable piece of feedback that could significantly improve the paper\"s clarity. However, the comment does not address broader issues or provide suggestions for improving the paper\"s motivation, methodology, or experimental results, which would make it more comprehensive. Overall, the comment is 4 as it offers specific and actionable feedback, but it could be more comprehensive to fully support the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies several issues with the paper, including the absence of a determiner in the definition at line 248 and questions about the selection of action verbs, classes, and action frames. While the comment highlights specific areas that need clarification, it does not provide explicit instructions or suggestions on how the authors should address these issues. The actions are implicit and somewhat vague, as the authors can infer that they need to clarify these points but are not given concrete guidance on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (248 and 306ff) and terms (\"action verbs,\" \"50 classes,\" and \"action frames\") that allow the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as the missing determiner in the definition, the selection of action verbs and classes, and the explanation of \"action frames.\" Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a series of questions and observations, such as the absence of a determiner in the definition at line 248 and inquiries about the selection of action verbs, classes, and action frames. These questions are factual and do not contain subjective claims or opinions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies several specific areas that need clarification or elaboration in the paper. It points out the absence of a determiner in the definition at line 248, questions the selection of action verbs and classes, and seeks clarification on the concept of \"action frames.\" These questions and observations are clear and actionable, as they guide the authors to address specific gaps in their draft. However, the comment could be more helpful if it provided suggestions on how to address these issues or offered examples of how to clarify these concepts. Overall, the feedback is 4 as it directs the authors to improve the clarity and comprehensiveness of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point identifies a minor typographical error, specifically correcting the spelling of \"Empiically\" to \"Empirically\" on line 32 of page 1. This feedback is explicit and provides a clear action for the authors to take, ensuring the accuracy of the manuscript. The comment is concrete because it specifies the exact line and page where the correction is needed, making it 5. Therefore, this comment is rated as a 5 on the actionability scale.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Ln 32 on Page 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear correction for the spelling of \"Empiically\" to \"Empirically.\" This level of detail guides the authors on what needs to be corrected, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a factual correction regarding the spelling of \"Empiically\" on line 32 of page 1. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a minor typographical error, specifically correcting the spelling of \"Empiically\" to \"Empirically\" on line 32 of page 1. While this feedback is accurate and actionable, it does not provide any broader context or suggestions for improvement beyond correcting the spelling. The comment is limited in scope and does not offer insights into how this correction might impact the overall clarity or understanding of the manuscript. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the feature selection presented in Section 4.2 could be improved by considering representation learning. However, it does not provide explicit guidance on how to incorporate representation learning or what specific aspects of the feature selection should be improved. The comment implies an action but lacks concrete details on how to implement it, leaving the authors with a general direction but no clear steps to follow. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper, including \"Sec. 4.2\" and \"Line 167174, Sec. 4,\" allowing the authors to accurately identify the parts being addressed. It also specifies the issue by pointing out that the proposed invariant learning module focuses on mask selection and rawlevel features, while the former framework seems not limited to rawlevel selection. Additionally, the comment suggests that the feature selection could be improved by considering representation learning. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the feature selection presented in Section 4.2 could be improved by considering representation learning. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The mention of the \"former framework\" and \"representation learning in the appendix\" adds some context but lacks sufficient detail to fully substantiate the claim. As a result, the comment is 3, as it provides a general direction but lacks the depth needed for a 5 claim.", "helpfulness_rationale": "The review comment identifies a potential weakness in the proposed invariant learning module, specifically noting that the feature selection presented in Section 4.2 could be improved by considering representation learning. It points out a discrepancy between the focus on mask selection and rawlevel features in Section 4.2 and the broader discussion about representation learning in the appendix. This feedback is 3 as it highlights an area for improvement and suggests a direction for enhancing the feature selection. However, the comment could be more helpful if it provided specific examples or detailed guidance on how to incorporate representation learning into the feature selection process. Overall, the comment offers a valuable insight but lacks depth and actionable suggestions, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that some details are missing, specifically mentioning the design of rewards. However, it does not provide explicit guidance on what details are missing or how the authors should address this issue. The comment lacks concrete suggestions or examples, leaving the authors uncertain about how to improve their draft. As a result, the action is implicit and vague, making it barely actionable.", "grounding_specificity_rationale": "The comment mentions that \"some details are missing,\" specifically regarding the design of rewards. However, it does not specify which part of the paper this pertains to, such as a particular section or subsection. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in identifying the missing detail about the design of rewards, but without clear grounding, it remains 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that \"some details are missing,\" specifically mentioning the design of rewards. However, it does not provide any specific examples or detailed reasoning to support this claim. Without additional context or explanation, the authors may find it challenging to understand which details are missing or how to address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific area where the paper lacks detail, namely the design of rewards. This is a clear and actionable piece of feedback that can guide the authors in improving their draft by providing more information on this critical aspect. However, the comment could be more helpful if it offered suggestions on what specific details should be included or how the authors might approach the design of rewards. Despite this, the feedback is still 3 as it directs the authors to a specific area needing attention. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should discuss the runtime of Prithvi WxC, given its large parameter count, as a potential limitation for applications that require computational cheapness. While the comment implies that the authors should include this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to discuss the runtime or what aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should discuss the runtime of Prithvi WxC, given its large parameter count, as a potential limitation for applications that require computational cheapness. However, it does not specify which part of the paper should include this discussion, making it weakly grounded. The comment is specific in its suggestion to address the runtime as a limitation, but without explicit references to sections or parts of the paper, the authors may find it challenging to pinpoint where this discussion should be included. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the selling point of MLbased emulators is their computational cheapness, and it suggests that the runtime of Prithvi WxC should be discussed due to its large parameter count. The comment provides a logical reasoning for why the runtime is important, as it could be a limitation for applications requiring computational cheapness. However, it lacks specific examples or references to support the claim about the large parameter count or the potential impact on runtime. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the point.", "helpfulness_rationale": "The review comment identifies a potential limitation of the Prithvi WxC model, specifically its large parameter count, which could impact its computational cheapness. It suggests that the authors should discuss the runtime of Prithvi WxC as a limitation for applications that require computational efficiency. This feedback is clear and actionable, as it provides a specific area for improvement and a direction for the authors to address in their draft. However, it could be more helpful if it offered suggestions on how to discuss or mitigate the runtime issue. Overall, the comment is 4, as it effectively guides the authors toward enhancing their draft by addressing a critical aspect of their work."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the paper may be overselling its method, which could make the contribution less clear. However, it does not provide specific guidance on how to address this issue or what changes should be made to improve the clarity of the contribution. The comment lacks explicit instructions or concrete suggestions, leaving the authors uncertain about how to implement the feedback. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment suggests that the paper may be overselling its method, which could make the contribution less clear. However, it does not specify which part of the paper is being referred to, such as a particular section, figure, or table, making it difficult for the authors to pinpoint the exact area needing revision. Additionally, the comment lacks specificity regarding what aspects of the framing are considered overselling or how to address this issue. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper may be overselling its method, which could make the contribution less clear. However, the comment does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed justification or references, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment suggests that the paper may be overselling its method, which could make the contribution less clear. However, it does not provide specific examples or details on how the method is being oversold or what aspects of the contribution are unclear. Without concrete guidance or suggestions for improvement, the authors are left without actionable feedback to address the issue. The comment identifies a potential weakness but lacks depth and specificity, making it 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the quality of paraphrases used in the training data, noting that the difference between the paraphrases and the original sentences is unclear. It suggests that this could impact the subsequent steps, as the model relies on the quality of these paraphrases. The comment implies that the authors should ensure the paraphrases are sufficiently different from the originals to maintain the quality of the training data. However, it does not provide explicit guidance on how to achieve this or what specific steps to take. The action is implicit and somewhat vague, as the authors can infer that they need to address the issue of paraphrase quality but are not given concrete instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific concern about the quality of paraphrases used in the training data, questioning how different they are from the original sentences. It highlights the importance of this issue for subsequent steps, as the model relies on the quality of these paraphrases. However, the comment does not specify which part of the paper discusses the generation of paraphrases, making it weakly grounded. The authors can infer that it relates to the methodology or data preparation sections, but this inference is not explicit. The comment is specific in detailing the impact of the paraphrase quality on the training data and subsequent steps. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the quality of paraphrases used in the training data is unclear, which could impact the subsequent steps of the model. The reviewer provides a logical reasoning by suggesting that if the difference between the paraphrases and the original sentences is not significant, the quality of the training data will be compromised. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to further explore and substantiate the claim themselves to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the quality of paraphrases used in the training data, noting that the difference between the paraphrases and the original sentences is unclear. It highlights the importance of this issue, as it directly impacts the subsequent steps of the model, which relies on the quality of these paraphrases. The comment provides a clear and actionable suggestion by pointing out that if the paraphrases are not sufficiently different, the quality of the training data will be compromised, leading to a limited number of pairs being added to the new training data. This feedback is valuable as it directs the authors to address a specific weakness in their methodology, offering a clear path for improvement. However, the comment could be more helpful if it provided specific guidance on how to ensure the quality of the paraphrases or examples of what constitutes a sufficient difference. Overall, the comment is 4, as it effectively highlights a critical area for improvement and provides a clear direction for the authors to enhance their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment acknowledges that identifying rationales is a complex task, particularly for more complicated NLP tasks like machine translation. It commends the paper for its organization and ease of following, but notes that Figure 2 is cluttered and the \"bold\" text is hard to see. The reviewer suggests using another color or a bigger font to improve the visibility of the humanidentified rationales. While the comment provides a specific suggestion for improving the figure, it does not explicitly instruct the authors to make these changes. The action is implicit and somewhat vague, as the authors need to infer that they should improve the figure\"s clarity. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the figure, noting that it is cluttered and the \"bold\" text is hard to see, suggesting improvements like using another color or a bigger font to enhance the visibility of the humanidentified rationales. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point acknowledges that identifying rationales is a complex task, particularly for more complicated NLP tasks like machine translation. It commends the paper for its organization and ease of following, but notes that Figure 2 is cluttered and the \"bold\" text is hard to see. The suggestion to use another color or a bigger font to improve the visibility of the humanidentified rationales is logical and provides a clear direction for improvement. However, the comment lacks specific examples or references to support the claim about the complexity of identifying rationales in machine translation. Therefore, the claim is 4, as it provides a logical basis but could be strengthened with more detailed evidence or examples.", "helpfulness_rationale": "The review comment acknowledges the complexity of identifying rationales, particularly in more complicated NLP tasks like machine translation. It commends the paper for its organization and ease of following, but points out that Figure 2 is cluttered and the \"bold\" text is hard to see. The reviewer provides a specific suggestion to improve the figure by using another color or a bigger font to enhance the visibility of the humanidentified rationales. This feedback is clear and actionable, offering a concrete way for the authors to improve the clarity and effectiveness of their presentation. However, the comment could be more helpful if it also addressed the complexity of identifying rationales or provided additional suggestions for improving the paper\"s content. Overall, the comment is 4 as it offers constructive feedback on a specific aspect of the paper, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the writing could be improved, noting that it took effort to understand the main idea and theoretical analysis. However, it does not provide specific guidance on how to improve the writing or what aspects need attention. The action is implicit and vague, as the authors are left without clear direction on how to enhance the clarity of their writing. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the writing could be improved, noting that it took effort to understand the main idea and theoretical analysis. However, it does not specify which parts of the paper are particularly challenging or what aspects of the writing need improvement. Without explicit references to sections, figures, or specific issues, the authors cannot confidently determine which parts of the paper need revision. Additionally, the comment lacks specificity regarding what improvements are needed, such as clarity, organization, or coherence. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the writing could be improved, noting that it took effort to understand the main idea and theoretical analysis. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks evidence or references to substantiate why the writing is challenging or how it could be improved. Without additional context or explanation, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the writing could be improved, noting that it took effort to understand the main idea and theoretical analysis. However, it lacks specificity and does not provide actionable feedback or suggestions on how to enhance the clarity or organization of the writing. Without detailed guidance or examples, the authors are left without a clear understanding of what changes are needed to improve their draft. Therefore, the comment is 2, as it identifies a potential issue but does not offer meaningful guidance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the proposed method primarily builds upon existing methods and lacks significant theoretical novelty. The reviewer expresses willingness to improve their score if the authors address these concerns. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or enhance the theoretical novelty of their work. The action is implicit and vague, as the authors are left to infer what steps to take without concrete instructions. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed method and its reliance on existing methods, such as ClopperPearson intervals and Gaussian elimination. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it highlights the lack of theoretical novelty and suggests that the authors address this concern to improve the reviewer\"s score. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method primarily builds upon existing methods and lacks significant theoretical novelty. This claim is supported by the explicit mention of specific existing methods, such as ClopperPearson intervals and Gaussian elimination, which are referenced with citations. This provides a clear basis for the reviewer\"s assertion, making the claim 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how the proposed method relies on these existing methods, which would further enhance its verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, noting that the proposed method primarily builds upon existing methods and lacks significant theoretical novelty. This feedback is 3 as it points out an area where the authors might need to enhance their work to differentiate it from existing approaches. However, the comment does not provide specific suggestions or guidance on how the authors could address this concern or improve the theoretical novelty of their method. Without actionable advice, the authors may struggle to determine how to effectively respond to this feedback. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point poses a question about whether the text input can be concatenated by the four text elements of an object. However, it does not provide any explicit or implicit actions for the authors to take. The question is not phrased as a suggestion or a request for clarification, leaving the authors without any guidance on how to address the issue. As a result, the comment lacks actionability, as the authors are not given any direction on how to improve their draft. Therefore, this comment is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment poses a question about whether the text input can be concatenated by the four text elements of an object. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section being addressed. Additionally, the comment lacks specificity as it does not provide any context or details about the issue being raised. Without clear grounding and specificity, the authors are left without a clear understanding of what needs to be addressed or improved. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification about whether the text input can be concatenated by the four text elements of an object. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment poses a question about whether the text input can be concatenated by the four text elements of an object. While it highlights a potential area of confusion or misunderstanding, it does not provide any actionable feedback or suggestions for improvement. The authors are left without guidance on how to address this issue or clarify the text input process. As a result, the comment is not helpful, as it does not offer any constructive feedback or direction for the authors to enhance their draft. Therefore, it aligns with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a specific issue with the sentence in lines 1217 of the abstract, noting that it is cumbersome and can be made clearer. However, it does not provide explicit guidance on how to improve the clarity or suggest specific changes that could be made. The action is implicit, as the authors can infer that they need to simplify the sentence, but the comment lacks concrete details on how to achieve this. Therefore, the comment is 3, as it points out an area for improvement but does not offer detailed guidance on how to address it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific sentence in lines 1217 of the abstract, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the sentence is cumbersome and can be made clearer. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the sentence in lines 1217 of the abstract is cumbersome and can be made clearer. However, it does not provide any specific reasoning or examples to support why the sentence is cumbersome or how it could be improved. Without detailed justification or suggestions for clarity, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the sentence in lines 1217 of the abstract, noting that it is cumbersome and could be made clearer. This feedback is 3 as it points out a potential area for improvement, suggesting that the authors should consider revising the sentence for clarity. However, the comment lacks detailed guidance or suggestions on how to achieve this clarity, such as proposing alternative phrasing or restructuring the sentence. While it provides some direction, it could be more helpful with additional details or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the domainspecific model is trained on Pix3D and that the experiments are conducted on Pix3D, which is considered unfair for comparisons with zeroshot singleimage 3D reconstruction models. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the issue of unfair comparisons or suggestions for alternative approaches. Without actionable advice or specific instructions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the domainspecific model being trained on Pix3D and the experiments being conducted on Pix3D. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it points out the unfairness of comparing the domainspecific model to zeroshot singleimage 3D reconstruction models, providing a clear indication of what needs to be addressed. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the domainspecific model is trained on Pix3D and the experiments are conducted on Pix3D, which makes comparisons to zeroshot singleimage 3D reconstruction models unfair. However, the comment lacks specific reasoning or evidence to support why these comparisons are unfair or how they impact the validity of the results. Without detailed justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient evidence or explanation to fully substantiate the claim.", "helpfulness_rationale": "The review comment points out a potential issue with the experimental setup, noting that the domainspecific model is trained on Pix3D and the experiments are conducted on Pix3D, which is considered unfair for comparisons with zeroshot singleimage 3D reconstruction models. This feedback highlights a critical flaw in the experimental design that could impact the validity of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their experimental setup. While it identifies a significant weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight but lacks depth and actionable steps for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the evaluation is limited, primarily relying on four OCR QA datasets, and suggests that more scenarios like the LLaVA benchmark should be included, especially in ablation studies. While the comment implies that the authors should expand their evaluation to include additional datasets, it does not provide specific guidance on which datasets to consider or how to incorporate them into the ablation studies. The action is implicit and somewhat vague, as the authors need to infer the need for additional datasets and how to integrate them effectively. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig 4(5),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the limited evaluation, relying on only four OCR QA datasets, and suggests that more scenarios like the LLaVA benchmark should be included, especially in ablation studies. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the evaluation is limited, primarily relying on four OCR QA datasets, and suggests that more scenarios like the LLaVA benchmark should be included. The comment references Figure 4(5), which the authors admit may be unreliable, providing some justification for the claim. However, the comment lacks specific examples or detailed reasoning about why the LLaVA benchmark would be beneficial or how it could improve the evaluation. This makes the claim 3, as it provides a basis for the critique but requires more detailed justification or examples to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the evaluation section, noting that it primarily relies on four OCR QA datasets. It acknowledges the authors\" admission that this evaluation may be unreliable, as seen in Figure 4(5). The comment suggests that more scenarios, such as the LLaVA benchmark, should be included, especially in ablation studies. This feedback is clear and actionable, as it provides a specific suggestion for expanding the evaluation to include additional datasets, which could enhance the robustness and generalizability of the results. However, the comment could be more helpful if it offered guidance on how to incorporate the LLaVA benchmark or other datasets into the evaluation process. Overall, the comment is 4, as it directs the authors toward a meaningful improvement in their evaluation methodology."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the abstract visual reasoning tasks, describing them as unintuitive and overly difficult. It questions the complexity of the tasks, suggesting that simpler ones might be more effective. The reviewer also expresses difficulty in solving the tasks and questions the interpretation of the models\" learning. However, the comment does not provide explicit guidance or suggestions on how to address these concerns or improve the tasks. The authors are left without a clear understanding of what changes, if any, are needed to enhance the draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"abstract visual reasoning tasks,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with these tasks, such as their unintuitiveness, difficulty, and potential for confusion due to multiple rows and changing factors. The comment further questions the necessity of these tasks and suggests simpler alternatives. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point raises concerns about the abstract visual reasoning tasks, describing them as unintuitive and overly difficult. The reviewer expresses difficulty in solving the tasks and questions the interpretation of the models\" learning. However, the comment lacks specific examples or references to support the claim that simpler tasks might be more effective. Without detailed evidence or reasoning, the claim remains 3, as it provides a basis for questioning the complexity of the tasks but lacks comprehensive justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises concerns about the abstract visual reasoning tasks used in the paper, describing them as unintuitive and overly difficult. It questions the complexity of the tasks, suggesting that simpler ones might be more effective. The reviewer also expresses difficulty in solving the tasks and questions the interpretation of the models\" learning. While the comment identifies a potential issue with the complexity of the tasks, it lacks specific suggestions or guidance on how to address these concerns or simplify the tasks. The authors are left with a general understanding of the problem but without actionable steps to improve their draft. Therefore, the comment is 3, as it highlights an area for improvement but does not provide detailed guidance or solutions."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of essential visualizations of intermediate processes and comparisons, suggesting that these are necessary for the paper. However, it does not provide specific guidance on what these visualizations should include or how they should be presented. The action is implicit, as the authors can infer that they need to add visualizations, but it is vague because it lacks concrete details on what exactly should be visualized or compared. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment highlights a lack of essential visualizations of intermediate processes and comparisons, but it does not specify which part of the paper lacks these visualizations or where they should be included. This makes it difficult for the authors to pinpoint the exact sections that need improvement. Additionally, the comment lacks specificity regarding what kind of visualizations or comparisons are needed. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that there is a lack of essential visualization of intermediate processes and comparisons. However, it does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific area for improvement by pointing out the lack of essential visualizations of intermediate processes and comparisons. This feedback is 3 as it directs the authors to enhance their paper by including visual representations that could aid in understanding the intermediate steps and comparisons. However, the comment lacks specificity regarding what kind of visualizations are needed or how they should be presented, which limits its usefulness. To be more helpful, the comment could provide examples or suggestions on how to effectively visualize these processes and comparisons. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to include keypoint detection results in the experiments section. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific and concrete suggestion, leaving no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly instructs the authors to include keypoint detection results in the experiments section, providing clear guidance on what needs to be addressed. This makes the comment fully grounded, as the authors can accurately identify the part of the paper being addressed. Additionally, the comment is specific because it clearly specifies what needs to be included, which is the keypoint detection results. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for additional information, specifically asking for the inclusion of keypoint detection results in the experiments section. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a clear and specific suggestion for improvement by requesting the inclusion of keypoint detection results in the experiments section. This feedback is actionable and directly addresses a gap in the paper, offering a concrete way for the authors to enhance their draft. By including these results, the authors can provide a more comprehensive evaluation of their work, which is beneficial for both the paper and the readers. However, the comment could be more helpful if it explained why these results are important or how they would contribute to the paper\"s findings. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about whether the grid search of the learning rate is done on the validation set. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this question or what steps to take to clarify this aspect of the methodology. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the grid search of the learning rate, specifically asking if it is done on the validation set. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its inquiry about the validation set, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact location of the issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the grid search of the learning rate, specifically asking if it is done on the validation set. This is a factual inquiry that does not contain an opinion, claim, or suggestion requiring verification. It is a request for clarification, which is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the grid search of the learning rate, specifically asking if it is done on the validation set. While this is a relevant inquiry, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve their methodology. Without actionable feedback or additional context, the authors are left without a clear understanding of what steps to take to enhance their work. Therefore, the comment is 2, as it identifies a potential area of concern but does not offer meaningful guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the number of discourse relations in Table A2, suggesting that it might be an artifact of the colloquial language or a misclassification of relations. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue or whether it is a concern that needs to be addressed. Without any actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table A2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the number of discourse relations in the treebank, suggesting that it might be an artifact of the colloquial language or a misclassification of relations. This provides clear guidance on what aspect of the paper needs further clarification or investigation. Therefore, this comment is labeled as 5, corresponding to a score of 5.", "verifiability_rationale": "The review point raises a question about the number of discourse relations in Table A2, suggesting that it might be an artifact of the colloquial language or a misclassification of relations. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the number of discourse relations in Table A2, suggesting that it might be an artifact of the colloquial language or a misclassification of relations. This is a relevant observation that could help the authors understand the nature of their data and potentially improve the accuracy of their analysis. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or investigate the cause of the apparent discrepancy. While it identifies a potential area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the racial and economic diversity of the sample and how well the results might generalize to other groups, particularly marginalized groups. While it implies that the authors should consider these aspects, it does not explicitly instruct them to include this information or provide specific guidance on how to address the issue. The action is implicit and somewhat vague, as the authors can infer that they need to consider these factors but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L393,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the racial and economic diversity of the sample and how well the results might generalize to other groups, particularly marginalized groups. This provides clear guidance on what aspects need to be considered or addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the racial and economic diversity of the sample and how well the results might generalize to other groups, particularly marginalized groups. However, it does not provide any supporting evidence, reasoning, or references to justify why this aspect is important or how it might impact the results. The comment is more of a suggestion for the authors to consider these factors rather than a claim that requires verification. Therefore, it is classified as \"1.\"", "helpfulness_rationale": "The review comment raises an important question about the racial and economic diversity of the sample and how well the results might generalize to other groups, particularly marginalized groups. This is a relevant concern that could impact the validity and applicability of the study. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or improve their analysis to account for these factors. While it identifies a potential weakness, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges that the output quality is reasonable but notes that it is still far from realistic. It references recent GAN works that have achieved amazing quality in synthesized results, suggesting that the bar has risen significantly in recent years. The reviewer implies that there is still room for improvement in result quality, but does not provide specific guidance on how to achieve this improvement. The comment also mentions the limited novelty, low resolution output, and high hardware requirement, which could be considered as reasons for rejection. However, the feedback lacks explicit actions or concrete suggestions for the authors to address these issues. As a result, the comment is vague and does not provide actionable steps for the authors to improve their draft, making it barely actionable.", "grounding_specificity_rationale": "The comment addresses the output quality of the paper, noting that it is reasonable but still far from realistic. It references recent GAN works that have achieved impressive results, suggesting that the bar for output quality has risen significantly. However, the comment does not specify which part of the paper discusses the output quality, making it weakly grounded. The comment is specific in its critique of the output quality and the need for improvement, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the output quality is reasonable but still far from realistic, referencing recent GAN works that have achieved impressive results. The reviewer suggests that the bar for output quality has risen significantly in recent years, implying that the current results are not up to par. However, the comment lacks specific examples or references to these recent GAN works, making it difficult for the authors to fully understand and address the critique. The claim is 3 as it provides a general context but lacks detailed evidence or examples to substantiate the claim fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges that the output quality is reasonable but notes that it is still far from realistic, particularly in comparison to recent GAN works that have achieved impressive results. The reviewer suggests that there is still room for improvement in result quality, which is a valid observation. However, the comment lacks specificity and actionable feedback on how the authors might improve the output quality or what specific aspects need attention. Additionally, the comment mentions the limited novelty, low resolution output, and high hardware requirement as reasons for rejection, but again, does not provide detailed guidance on how to address these issues. As a result, the comment is 3, as it identifies areas for improvement but does not offer comprehensive or actionable suggestions, leaving the authors with limited direction for enhancing their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the traditional experiment for unseen characters is presented as an afterthought and recommends adding more evaluation in this direction, specifically on classifying unseen words. It also suggests adding translations to Figure 6 for readers who do not speak Chinese. While the comment provides explicit actions, it lacks concrete details on how to implement these suggestions, such as specific evaluation metrics or methods to add translations. The authors know what needs to be done but may struggle with the execution, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding translations to Figure 6 for readers who do not speak Chinese, providing a clear direction for improvement. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the traditional experiment for unseen characters is presented as an afterthought and recommends adding more evaluation in this direction. It also suggests adding translations to Figure 6 for readers who do not speak Chinese. However, the comment lacks specific examples or detailed reasoning to support the claim that the experiment is an afterthought or why more evaluation is needed. Without additional context or evidence, the authors may find it challenging to understand and address the feedback effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment acknowledges the idea of a simple/traditional experiment for unseen characters as a nice addition but notes that it is presented as an afterthought. It suggests that more evaluation in this direction, specifically on classifying unseen words, would be beneficial. Additionally, the comment recommends adding translations to Figure 6 for readers who do not speak Chinese, which could enhance the accessibility of the results. While the comment identifies areas for improvement and provides some actionable suggestions, it could be more helpful by offering specific evaluation metrics or methods for classifying unseen words. Overall, the feedback is 4 as it guides the authors toward enhancing their draft, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the authors do not discuss computational aspects in detail, particularly in high dimensions, and questions the practical usefulness of their proposed methods. It highlights a specific issue with the algorithm requiring the solution of several LPs in high dimensions, each involving a parameter that is not easily calculable. The comment also notes that the experiments are performed on smallscale datasets. While the comment identifies a concern about the computational aspects and the scalability of the methods, it does not provide explicit guidance on how the authors should address these issues or improve their discussion. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more detailed discussions and potentially conduct experiments on larger datasets. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of detailed discussion on computational aspects, particularly in high dimensions, and questions the practical usefulness of the proposed methods. It mentions that the algorithm requires solving several LPs in high dimensions, each involving a parameter that is not easily calculable. The comment also notes that the experiments are performed on smallscale datasets. While the comment does not explicitly mention specific sections or figures, the authors can infer that it relates to the discussion of computational aspects and the appendix, where the LPs are mentioned. The comment is specific in detailing the issue with the computational aspects and the scalability of the methods. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors do not discuss computational aspects in detail, particularly in high dimensions, and questions the practical usefulness of their proposed methods. It highlights a specific issue with the algorithm requiring the solution of several LPs in high dimensions, each involving a parameter that is not easily calculable. The comment also notes that the experiments are performed on smallscale datasets. While the claim is based on logical reasoning and observations from the paper, it lacks specific examples or references to support the assertion about the difficulty of calculating parameters in high dimensions. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper regarding the discussion of computational aspects, particularly in high dimensions. It points out that the authors do not provide sufficient detail on the practical usefulness of their proposed methods, especially in terms of scalability. The comment highlights a specific issue with the algorithm requiring the solution of several LPs in high dimensions, each involving a parameter that is not easily calculable. This observation is relevant and important, as it raises concerns about the applicability of the method in realworld scenarios. However, the comment could be more helpful if it offered suggestions on how the authors might address these issues, such as providing more detailed explanations or conducting experiments on larger datasets. Overall, the comment is 3 as it directs the authors\" attention to a critical area that needs further exploration and clarification."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies specific errors in the equations, suggesting corrections to the signs in the equations. It provides clear and concrete instructions on what changes need to be made, such as replacing \"+\" signs with \"\" signs and vice versa. This level of detail ensures that the authors know exactly what corrections to make, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper (Line 502, 503, and 504), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the errors in the equations, including the incorrect signs and the need for corrections. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of factual statements and corrections to specific equations, such as the suggestion to change \"+\" signs to \"\" signs and vice versa. It does not contain subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by identifying errors in the equations, suggesting corrections to the signs in the equations and the summation term. This level of detail is valuable for the authors, as it directly points out where the equations are incorrect and how to correct them. By addressing these minor but important errors, the authors can ensure the accuracy and clarity of their work. However, the comment could be more helpful if it also explained the significance of these corrections or how they might impact the overall understanding of the paper. Overall, the feedback is 4 as it provides clear guidance for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the motivation behind the crossencoder architecture, specifically addressing the claim that it \"ignores crossentity comparison\" and \"attends to all candidates at once.\" The reviewer acknowledges that the architecture may not be as finegrained as claimed. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the issue or improve the motivation, leaving the authors without a clear path forward. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the motivation behind the crossencoder architecture, specifically challenging the claim that it \"ignores crossentity comparison\" and \"attends to all candidates at once.\" However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its critique of the motivation but lacks grounding, as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point critiques the motivation behind the crossencoder architecture, specifically challenging the claim that it \"ignores crossentity comparison\" and \"attends to all candidates at once.\" The reviewer provides a logical reasoning by explaining that the architecture does not ignore crossentity comparison and attends to all candidates simultaneously. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to further explore the architecture to fully understand the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the motivation behind the crossencoder architecture, specifically challenging the claim that it \"ignores crossentity comparison\" and \"attends to all candidates at once.\" The reviewer acknowledges that the architecture may not be as finegrained as claimed. However, the comment lacks actionable suggestions or guidance on how the authors might improve the motivation or clarify the architecture\"s functionality. Without specific feedback or recommendations, the authors are left without a clear path to address the issue. Therefore, the comment is 3, as it identifies a potential weakness but does not provide sufficient direction for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point criticizes the use of an \"antiquated\" GNN model and method, stating that it negatively impacts the performance of the framework. It also mentions that the baseline algorithms/methods are antiquated. However, the comment does not provide any explicit or implicit suggestions for improvement or action. It lacks specific guidance on what the authors should do to address these issues, such as recommending the use of more modern models or methods or suggesting alternative approaches. Without actionable advice, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment criticizes the use of an \"antiquated\" GNN model and method, which it claims negatively impacts the performance of the framework. It also mentions that the baseline algorithms/methods are antiquated. However, the comment does not specify which part of the paper discusses these models or methods, making it difficult for the authors to identify the exact sections that need attention. Additionally, while it highlights the issue of antiquated models, it does not provide specific suggestions or examples of more modern alternatives. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the use of an \"antiquated\" GNN model and method negatively impacts the performance of the framework. However, it does not provide specific examples, references, or detailed reasoning to support this claim. The comment lacks evidence or justification for why the model and method are considered antiquated and how this impacts performance. Without such support, the claim remains 1, as the authors would need to make significant efforts to understand and address the issue. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the use of an \"antiquated\" GNN model and method, which it claims negatively impacts the performance of the framework. It also mentions that the baseline algorithms/methods are antiquated. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or improve their work. Without actionable advice or examples of more modern alternatives, the feedback is limited in its usefulness to the authors. Therefore, it is rated as 2, as it highlights a critical area for improvement but does not provide sufficient guidance for the authors to make meaningful changes."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point identifies a concern about the experiment that estimates the quality of uncertainty estimates, specifically the use of pseudo feature importance due to the lack of true feature importance. It highlights the reliance on Proposition 3.2 and the need for a large perturbation value to ensure the correctness of the pseudo feature importance. The comment suggests that this makes it difficult to judge the trustworthiness of the experiment, as the difference between the tested method and the pseudo feature importance is only the number of perturbations. The reviewer provides two ways to strengthen the experiment: by using true feature importance or by providing a more detailed analysis of the perturbation value. While the comment implies an action, it does not explicitly instruct the authors to take these steps. However, the concrete suggestions on how to improve the experiment make the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiment that estimates the quality of uncertainty estimates, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the experiment, namely the use of pseudo feature importance due to the lack of true feature importance, and the reliance on Proposition 3.2 and a large perturbation value. The comment further suggests ways to strengthen the experiment, such as using true feature importance or providing a more detailed analysis of the perturbation value. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the experiment using pseudo feature importance is difficult to trust because it relies on Proposition 3.2 and a large perturbation value. The reviewer suggests that the difference between the tested method and the pseudo feature importance is only the number of perturbations. This claim is 3 as it provides a logical reasoning for the concern about the experiment\"s trustworthiness. However, the comment lacks specific references or detailed examples to fully substantiate the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the experiment that estimates the quality of uncertainty estimates, specifically the use of pseudo feature importance due to the lack of true feature importance. It highlights the reliance on Proposition 3.2 and the need for a large perturbation value to ensure the correctness of the pseudo feature importance. The comment points out that this makes it difficult to judge the trustworthiness of the experiment, as the difference between the tested method and the pseudo feature importance is only the number of perturbations. The reviewer provides two actionable suggestions for strengthening the experiment: using true feature importance or providing a more detailed analysis of the perturbation value. This feedback is clear and constructive, offering the authors specific ways to improve their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises several issues, including the lack of comparison with other models besides GPT2, confusion in sections of the paper, a missing citation or reference in Line 99, and an unreferenced notation in Line 165. The comment acknowledges the authors\" effort to address limitations but does not provide specific guidance on how to address these issues. The actions are implicit and somewhat vague, as the authors are left to infer what needs to be done without concrete instructions. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines and sections of the paper, allowing the authors to accurately identify the parts being addressed. It specifies the issues with the paper, such as the lack of comparison with other models, confusion in sections, a missing citation or reference, and an unreferenced notation. The comment also acknowledges the authors\" effort to address limitations. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with a score of 5.", "verifiability_rationale": "The review point raises several claims, including the lack of comparison with other models, confusion in sections, a missing citation, and an unreferenced notation. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issues effectively. The mention of \"great effort\" to acknowledge limitations is a positive observation but does not contribute to the verifiability of the other claims. Therefore, the comment is considered 2, as it provides some support but lacks detailed justification for the claims.", "helpfulness_rationale": "The review comment identifies several issues with the paper, including the lack of comparison with other models, confusion in sections, a missing citation or reference, and an unreferenced notation. It also acknowledges the authors\" effort to address limitations. While the comment highlights important areas for improvement, it lacks specific suggestions or guidance on how to address these issues. The authors are left with a general understanding of what needs to be improved but without detailed instructions on how to make those improvements. Therefore, the comment is 3, as it provides some direction but not comprehensive guidance for enhancing the draft."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point suggests that a more comprehensive and dataintensive analysis would enhance the paper, but acknowledges that it is a short paper and therefore not a strong negative point. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to conduct a more comprehensive analysis or what specific aspects of the paper could benefit from such an analysis. Without actionable steps or suggestions, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that a more comprehensive and dataintensive analysis would improve the paper, but it does not specify which part of the paper this analysis should focus on. The authors cannot confidently determine which sections or aspects of the paper are being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity regarding what aspects of the analysis would be beneficial or how it could be implemented. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that a more comprehensive and dataintensive analysis would improve the paper, but it acknowledges that it is a short paper and therefore not a strong negative point. However, the comment does not provide any specific examples, reasoning, or references to support why a more comprehensive analysis would be beneficial. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges that the paper is short and suggests that a more comprehensive and dataintensive analysis would significantly improve it. However, it does not provide specific guidance or suggestions on how to achieve this improvement, nor does it identify any particular areas that could benefit from such an analysis. The comment lacks actionable feedback and does not offer a clear path for the authors to enhance their work. As a result, it is 1, as it does not provide the authors with any actionable insights or direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a gap in the evaluation results, specifically noting the absence of a proper comparison against online learning approaches and RL. It raises questions about the reasons for discarding online learning and the challenges of including it in the evaluation. While the comment identifies areas that need clarification and comparison, it does not provide explicit instructions or concrete suggestions on how to address these issues. The authors are left to infer that they should include a comparison and provide explanations for the decisions made. However, the lack of specific guidance on how to conduct the comparison or what aspects to focus on makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract and other parts of the paper where the authors discuss online learning, allowing the authors to accurately identify the sections being addressed. It is also specific because it clearly specifies what is missing in the evaluation results, namely a proper comparison against online learning approaches and RL. The comment raises questions about the reasons for discarding online learning and the challenges of including it in the evaluation, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the lack of a proper comparison against online learning approaches and RL in the evaluation results, as mentioned in the abstract. It questions the reasons for discarding online learning and suggests that the authors should clarify why it is not considered. The comment provides a logical reasoning by pointing out the absence of a comparison that would help understand the limitations of online learning. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to provide additional context or evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the evaluation of the paper, specifically noting the absence of a proper comparison against online learning approaches and RL. It raises important questions about the reasons for discarding online learning and the challenges of including it in the evaluation. By prompting the authors to clarify these issues, the comment provides actionable feedback that can help the authors improve the comprehensiveness and validity of their evaluation. However, the comment could be more helpful if it offered specific suggestions on how to conduct the comparison or what aspects to focus on. Overall, the comment is 4 as it directs the authors to address a critical area for improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should cite works on metalearning, even though they do not directly target continual learning. It also implies that the authors should distinguish between different approaches to metalearning and link them more heavily to the work on RL for architecture search and/or as optimizers for learning. While the comment provides a clear direction for the authors to expand their citations and make connections between different approaches, it does not specify which specific works should be cited or how the authors should distinguish between different approaches. The action is explicit but somewhat vague, as the authors know they need to expand their citations and make connections but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should cite works on metalearning, even though they do not directly target continual learning. It also implies that the authors should distinguish between different approaches to metalearning and link them more heavily to the work on RL for architecture search and/or as optimizers for learning. While the comment does not explicitly mention specific sections or parts of the paper, it does provide a clear direction for the authors to expand their citations and make connections between different approaches. The authors can infer that this pertains to the sections discussing related work or literature review. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should cite works on metalearning, even though they do not directly target continual learning. It also implies that the work on RL for architecture search and/or as optimizers for learning should be more heavily linked to the current work. However, the comment lacks specific examples or references to support the claim that these works should be cited or linked more heavily. Without detailed evidence or examples, the authors may find it challenging to understand the exact nature of the connection or the specific works that should be cited. Therefore, the comment is considered 2, as it provides some direction but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment identifies a potential gap in the paper by suggesting that the authors should explore a deeper connection with metalearning, even though the works cited do not directly target continual learning. It provides a clear direction for the authors to expand their citations and make connections between different approaches, such as those related to RL for architecture search and/or as optimizers for learning. This feedback is actionable and offers a specific area for improvement, making it 4. However, the comment could be more comprehensive by suggesting how the authors might distinguish between different approaches or provide examples of how these connections could be made. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the lack of lexical and syntactic diversity in the teacher feedback, suggesting that it might be autogenerated. It asks whether the authors intend to use human turkers or generate different types of feedback to make it more realistic. While the comment implies that the authors should consider these options, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement the suggested changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the lack of lexical and syntactic diversity in the teacher feedback, implying that it might be autogenerated. However, it does not explicitly mention which part of the paper this feedback is discussed in, making it weakly grounded. The comment is specific in detailing the issue of diversity and suggesting ways to address it, such as using human turkers or generating different types of feedback. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the lack of lexical and syntactic diversity in the teacher feedback, suggesting that it might be autogenerated. The reviewer asks whether the authors intend to use human turkers or generate different types of feedback to make it more realistic. While the comment identifies a potential issue, it lacks specific examples or references to support the claim that the feedback is autogenerated or how it could be improved. The suggestion for human turkers or diverse feedback is logical but not fully substantiated, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the teacher feedback, noting a lack of lexical and syntactic diversity. It raises a concern about the feedback being autogenerated and suggests that the authors might consider using human turkers or generating different types of feedback to make it more realistic. This feedback is clear and actionable, as it provides a specific area for improvement and offers a potential solution. However, it could be more helpful if it included additional guidance on how to implement these suggestions or examples of diverse feedback types. Overall, the comment is 4, as it directs the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly recommends comparing the performance of the proposed method with two specific works: \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MADX: An AdapterBased Framework for MultiTask CrossLingual Transfer.\" This provides a clear and direct action for the authors to take, as it specifies which works to compare their method with. The suggestion is concrete, as it outlines a specific task and references two relevant studies. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the recommendation to compare the performance with specific works: \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MADX: An AdapterBased Framework for MultiTask CrossLingual Transfer.\" This allows the authors to accurately identify the part of the paper being addressed, which is the performance evaluation section. The comment is also specific because it clearly specifies what needs to be addressed, namely, the comparison with these two works. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests comparing the performance of the proposed method with two specific works: \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MADX: An AdapterBased Framework for MultiTask CrossLingual Transfer.\" This recommendation is based on the premise that these works are relevant and could provide a useful comparison. However, the comment does not provide detailed reasoning or evidence to support why these particular works are important or how they relate to the current study. While the suggestion is logical, it lacks specific justification or references, making it 3. The authors would need to independently investigate the relevance of these works to fully understand the basis of the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the paper by recommending a comparison of the proposed method with two specific works: \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MADX: An AdapterBased Framework for MultiTask CrossLingual Transfer.\" This recommendation is clear and could significantly enhance the paper by providing a more comprehensive evaluation of the proposed method. However, the comment could be more helpful if it included a rationale for why these comparisons are important or how they might impact the results. Overall, the feedback is 4 as it offers a concrete step for the authors to take, but it could be more comprehensive with additional context or explanation. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the applicability of the approach to more general settings, suggesting that the authors consider extending their approach to broader scenarios. While the comment implies that the authors should explore this possibility, it does not provide explicit guidance on how to do so or what specific aspects of the approach might need to be modified. The action is implicit and somewhat vague, as the authors are left to infer that they should consider expanding their approach but without concrete steps or examples. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the applicability of the approach to more general settings, suggesting that the authors consider extending their approach to broader scenarios. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for an extension to more general settings, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the applicability of the approach to more general settings, suggesting that the authors consider extending their approach to broader scenarios. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this extension might be beneficial or how it could be achieved. Without additional context or explanation, the claim remains vague and 1, leaving the authors without a clear understanding of the basis for the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the applicability of the approach to more general settings, suggesting that the authors consider extending their approach to broader scenarios. This feedback is 3 as it prompts the authors to think beyond the specific setting they have explored and encourages them to consider the potential for broader applicability. However, the comment lacks specific guidance or suggestions on how to achieve this extension, such as identifying potential challenges or areas for improvement. While it provides a direction for further exploration, it does not offer detailed actionable steps, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the dimensionality of each region and asks which feature extractor is used. While it identifies a specific line in the paper where this issue is discussed, it does not provide any explicit or implicit guidance on how the authors should address this question or what action they should take. The comment lacks actionable advice, such as suggesting ways to clarify or provide additional information about the feature extractor. As a result, the authors are left without a clear understanding of how to improve their draft in response to this feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 201,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the dimensionality of each region and asks which feature extractor is used. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the dimensionality of each region and the feature extractor used. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the dimensionality of each region and the feature extractor used, which is relevant to the understanding of the methodology. However, it does not provide any suggestions or guidance on how the authors might address this question or improve their draft. The comment lacks actionable feedback or insights that could help the authors enhance their work. As a result, it is 2, as it identifies a potential area of confusion but does not offer any direction for improvement. Therefore, it aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks for clarification regarding the choice of p < 0.4 in Algorithm 1. This is a direct and concrete question that the authors can address by providing an explanation or justification for their selection. The action is clear and specific, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the choice of p < 0.4, which is a clear and direct question. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual question seeking clarification on the choice of p < 0.4 in Algorithm 1. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is highly specific and actionable, as it directly questions the choice of p < 0.4 in Algorithm 1. This prompts the authors to provide an explanation or justification for their selection, which is crucial for the clarity and reproducibility of their work. By addressing this point, the authors can enhance the transparency and credibility of their methodology. However, the comment could be more helpful if it provided context or suggested potential reasons for the choice, which would further guide the authors in improving their draft. Overall, the comment is 4, as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the motivation behind applying CMD (Command and Data Manipulation) in federated learning is unclear and could be improved with a more explicit demonstration or explanation. While the comment implies that the authors should provide a clearer explanation, it does not specify how to achieve this or what aspects of the motivation need further elaboration. The action is implicit and somewhat vague, as the authors are left to infer the specific steps needed to improve the clarity of the motivation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the motivation behind applying CMD in federated learning, suggesting that it is unclear and could benefit from a more explicit demonstration or explanation. However, it does not specify which part of the paper discusses this motivation, making it weakly grounded. The comment is specific in identifying the issue of clarity regarding the motivation, but without explicit references to sections or parts of the paper, the authors may find it challenging to pinpoint the exact areas needing improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the motivation behind applying CMD in federated learning is unclear and suggests that it could benefit from a more explicit demonstration or explanation. However, the comment does not provide any specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the exact nature of the issue or how to address it. Therefore, the claim is considered 2, as it lacks sufficient support to be fully actionable.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, specifically the lack of clarity in the motivation behind applying CMD in federated learning. It suggests that the authors should provide a more explicit demonstration or explanation to enhance the understanding of this motivation. While the comment highlights an area for improvement, it does not offer specific guidance or suggestions on how to achieve this clarity. The feedback is 3 as it points out a critical area for enhancement, but it lacks depth and actionable advice, leaving the authors with a general direction but not a clear path to improvement. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point highlights two areas for improvement: the lack of analysis on the effectiveness of each data augmentation method and the need to compare the approach to other paraphrasing methods, such as EDA or LLMbased paraphrasing. It suggests that references to specific works, such as [1] and [2], could provide additional context. While the comment implies that the authors should conduct a more comprehensive analysis and comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional analysis and comparisons. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of analysis on the effectiveness of each data augmentation method, allowing the authors to identify the specific part of the paper being addressed. It also specifies the need for a comparison with other paraphrasing methods, such as EDA or LLMbased paraphrasing, to clarify the unique advantages of their method. The comment provides specific suggestions for improvement, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that there is insufficient analysis of the effectiveness of each data augmentation method and suggests comparing the approach to other paraphrasing methods, such as EDA or LLMbased paraphrasing, to clarify the unique advantages of the method. The comment supports this claim by referencing specific works, including [1] and [2], which provide additional context and justification for the need for more comprehensive analysis. This provides a solid basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced works to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant gap in the analysis of the paper, specifically the lack of analysis on the effectiveness of each data augmentation method. It suggests that comparing the approach to other paraphrasing methods, such as EDA or LLMbased paraphrasing, would clarify the unique advantages of the method. The comment provides specific references to relevant works, which can guide the authors in enhancing their analysis and understanding of their approach. This feedback is clear and actionable, offering a concrete direction for improvement that can significantly enhance the paper. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the performance of a model that assigns all negative samples to a distractor class. While it implies that the authors should consider this scenario, it does not provide explicit guidance on how to address it or what specific aspects of the model\"s performance should be evaluated. The action is implicit and somewhat vague, as the authors can infer that they should explore this scenario but are not given concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment poses a question about the performance of a model that assigns all negative samples to a distractor class. However, it does not specify which part of the paper this question pertains to, such as a specific section, experiment, or analysis. Without explicit references or context, the authors cannot confidently determine where this question should be addressed in the paper. Additionally, the comment lacks specificity regarding what aspects of performance should be evaluated or how this scenario relates to the overall study. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification on the performance of a specific model scenario. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment poses a question about the performance of a model that assigns all negative samples to a distractor class. While it highlights an interesting scenario that the authors might not have considered, it lacks depth and does not provide any guidance or suggestions on how to address this issue or its implications. The comment does not offer actionable feedback or insights that would help the authors improve their draft. Therefore, it is 2, as it prompts the authors to consider a specific scenario but does not provide meaningful direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies the lack of quantitative analysis on computational gains and suggests that specific measurements or comparisons should be included to substantiate the claims. It provides clear guidance by specifying what kind of quantitative analysis would be beneficial, such as GPU hours, memory usage, or training time. This feedback is direct and concrete, giving the authors a clear understanding of what needs to be added to their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of quantitative analysis on computational gains, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely specific measurements or comparisons to substantiate the claimed computational benefits. The comment provides a clear direction for improvement by suggesting the inclusion of quantitative analysis, such as GPU hours, memory usage, or training time. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks specific measurements or comparisons to substantiate the computational gains from replacing the MAE model with a CNNbased data augmentation strategy. The reviewer suggests that a quantitative analysis, such as GPU hours, memory usage, or training time, would provide stronger evidence of the efficiency improvements in DQ V2. This claim is 4 as it provides a clear suggestion for what kind of evidence would strengthen the paper\"s claims. However, it lacks specific examples or references to existing literature or studies that could further substantiate the need for such quantitative analysis. Therefore, the comment is categorized as 4.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of quantitative analysis on computational gains. It highlights the importance of specific measurements or comparisons to substantiate the claimed benefits of replacing the MAE model with a CNNbased data augmentation strategy. The suggestion to include quantitative analysis, such as GPU hours, memory usage, or training time, provides clear and actionable guidance for the authors to strengthen their claims and improve the credibility of their findings. This feedback is valuable as it directs the authors to a specific area for improvement, making it 4. However, it could be more helpful if it offered examples or references to similar studies that have successfully implemented such analyses. Therefore, the comment is rated as 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises several questions and concerns about the \"filter manifold network\" (FMN), which forms the main part of the technique. It asks whether the authors experimented with other architectures for FMN and how adaptive convolutions scale with the number of filter parameters. Additionally, it questions the scalability of FMN when the number of input and output channels is large. These questions imply that the authors should provide more detailed analysis and discussion on the FMN, potentially including experiments with different architectures and scalability tests. While the comment does not explicitly instruct the authors to conduct these analyses, it provides clear guidance on what aspects need further exploration. The action is implicit but concrete, making this comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"filter manifold network\" (FMN), allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues by questioning the lack of discussion or analysis on FMN, asking about experiments with other architectures, and inquiring about the scalability of adaptive convolutions with varying filter parameters. The comment provides clear guidance on what aspects need further exploration, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises several questions and concerns about the \"filter manifold network\" (FMN), which forms the main part of the technique. It questions the lack of discussion or analysis on FMN, asks about experiments with other architectures, and inquires about the scalability of adaptive convolutions with varying filter parameters. While the comment highlights important areas for further exploration, it does not provide specific evidence or references to support these questions. The lack of detailed justification or examples makes the claim 3, as the authors would need to conduct additional research to address the points raised. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the discussion and analysis of the \"filter manifold network\" (FMN), which forms the main part of the technique. It raises important questions about the scalability of FMN with varying filter parameters and the potential for experimenting with other architectures. By highlighting these areas for further exploration, the comment provides clear and actionable feedback that can guide the authors in enhancing their draft. However, the comment could be more helpful if it offered specific suggestions on how to address these questions or conduct additional experiments. Overall, the feedback is 4 as it directs the authors to important areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the performance boost claimed by the proposed CoNO model, suggesting that it is unclear whether the fractional transform or the UNet operation in the fractional Fourier domain is responsible for the improvement. The reviewer implies that comparisons to UNets are necessary to clarify this point. While the comment identifies a need for additional comparisons, it does not explicitly instruct the authors to conduct these comparisons or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to include comparisons but are not given detailed instructions on how to implement them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"CoNO model\" and the \"UNet part after the fractional transform,\" allowing the authors to accurately identify the specific part of the paper being addressed. It also specifies the issue by questioning the source of the performance boost and suggesting that comparisons to UNets are necessary. The comment provides specific examples of related works, such as Raonic et al and Gupta et al, which further grounds the suggestion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the source of the performance boost claimed by the proposed CoNO model, suggesting that it is unclear whether the fractional transform or the UNet operation in the fractional Fourier domain is responsible. The reviewer provides a logical reasoning by comparing the UNet operation in the fractional Fourier domain to pointwise multiplication, as done in FNOs, and suggests that comparisons to UNets are necessary. Additionally, the comment references specific works by Raonic et al and Gupta et al, which have shown strong performances on regular gridded domains. This provides a basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed comparisons or examples from the referenced works. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises a critical question about the source of the performance boost claimed by the proposed CoNO model. It highlights a lack of clarity regarding whether the fractional transform or the UNet operation in the fractional Fourier domain is responsible for the improvement. The reviewer suggests that comparisons to UNets are necessary to clarify this point, especially since UNets have shown strong performances on regular gridded domains, as evidenced by references to Raonic et al and Gupta et al. This feedback is 4 as it identifies a specific area of confusion and provides a clear suggestion for improvement by recommending comparisons to UNets. However, the comment could be more helpful if it offered specific guidance on how to conduct these comparisons or what aspects to focus on. Overall, the comment provides valuable insight and direction for the authors to enhance their draft, aligning with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises questions about how the authors handle concepts (multiple entity mentions referring to the same entity) in the DocRED dataset. It explicitly asks whether the documents are considered as an entire sentence and requests clarification on this aspect. While the comment does not provide specific guidance on how to address these questions, it does prompt the authors to consider and clarify these aspects in their manuscript. The action is explicit but somewhat vague, as it lacks detailed instructions on how to address the issues. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises questions about how the authors handle concepts (multiple entity mentions referring to the same entity) in the DocRED dataset. It explicitly mentions \"DocRED,\" providing full grounding as the authors can accurately identify the part of the paper being addressed. The comment is specific in its request for clarification on how the documents are considered and how concepts are handled. However, it does not specify where in the manuscript this information is currently missing, which would make it 5. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions seeking clarification on how the authors handle concepts (multiple entity mentions referring to the same entity) in the DocRED dataset. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises important questions about how the authors handle concepts (multiple entity mentions referring to the same entity) in the DocRED dataset. It specifically asks whether the documents are considered as an entire sentence and requests clarification on this aspect, which is currently missing from the manuscript. This feedback is clear and actionable, as it prompts the authors to address a specific gap in their work. By providing this information, the authors can enhance the clarity and completeness of their manuscript. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of how other datasets handle similar challenges. Overall, the comment is 4 as it directs the authors to a critical area needing clarification, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point expresses a subjective opinion that the contribution is marginal because the methods used are welldesigned and demonstrated. It suggests that adding another stream for lowresolution might not be a significant contribution for a toptier venue like ICLR. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the perceived lack of contribution or how to enhance the paper to meet the expectations of a toptier venue. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses an opinion about the contribution being marginal, suggesting that the methods used are welldesigned and demonstrated. However, it does not specify which part of the paper this assessment is based on, nor does it provide details on what aspects of the contribution are considered marginal. Without explicit references to specific sections, figures, or results, the authors cannot confidently determine which parts of the paper are being addressed. Additionally, the comment lacks specificity regarding what aspects of the contribution are deemed marginal or how they could be improved. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses an opinion that the contribution is marginal because the methods used are welldesigned and demonstrated. It suggests that adding another stream for lowresolution might not be a significant contribution for a toptier venue like ICLR. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the contribution is marginal. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses a subjective opinion that the contribution is marginal, suggesting that the methods used are welldesigned and demonstrated. It implies that adding another stream for lowresolution might not be a significant contribution for a toptier venue like ICLR. However, the comment lacks specificity and does not provide actionable feedback or suggestions for improvement. It does not offer guidance on how the authors might enhance their contribution or address the perceived lack of significance. Without detailed feedback or constructive advice, the authors are left without a clear path to improve their draft. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the tester for the spread parameter immediately yields an (\u03f5,\u03b4)identity tester as well. It specifically mentions a scenario where the distance between two distributions is large, suggesting that the tester might not handle this case. While the comment implies that the authors should clarify this aspect, it does not provide explicit instructions on how to address the issue or what specific steps to take. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional clarification on the tester\"s capabilities. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether the tester for the spread parameter immediately yields an (\u03f5,\u03b4)identity tester and provides a specific example of how it might not handle (\u03c0,\u03d5) pairs where \u03d5=\u03d50 but dK(\u03c00,\u03c0) is large. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the tester for the spread parameter, specifically asking if it immediately yields an (\u03f5,\u03b4)identity tester. It provides a specific example of a scenario where the distance between two distributions is large, suggesting that the tester might not handle this case. While the comment raises a valid point, it lacks detailed reasoning or references to support the claim. The authors would need to infer the potential issue and address it themselves. Therefore, the comment is 3, as it provides a basis for the claim but requires further elaboration or evidence to be fully substantiated.", "helpfulness_rationale": "The review comment raises a question about the tester for the spread parameter, specifically asking whether it immediately yields an (\u03f5,\u03b4)identity tester. It provides a specific example of a scenario where the distance between two distributions is large, suggesting that the tester might not handle this case. This feedback is 3 as it identifies a potential gap in the paper\"s explanation or testing methodology. However, it lacks detailed guidance or suggestions on how the authors might address this issue or improve their testing framework. To be more helpful, the comment could include specific recommendations or examples of how to handle such scenarios. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a lack of clarity regarding the detailed distribution of the proposed dataset. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on what specific information should be included or how the authors might clarify the distribution. Without actionable suggestions or concrete steps, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a lack of clarity regarding the detailed distribution of the proposed dataset. However, it does not specify which part of the paper this issue pertains to, such as a specific section or table where the distribution is discussed. Without explicit references or context, the authors cannot confidently determine which part of the paper needs revision. Additionally, the comment lacks specificity regarding what aspects of the distribution are unclear or what additional information is needed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the detailed distribution of the proposed dataset is unclear. However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific area of concern regarding the detailed distribution of the proposed dataset, which is an important aspect of the paper. However, it lacks depth and does not provide any suggestions or guidance on how the authors might clarify or improve this aspect of their work. Without actionable feedback or specific recommendations, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, the comment is 2, as it points out a problem but does not offer a path to resolution."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the proposed method is limited to supervised training due to the need for annotated labels for learning semantic tokens. It implies that a selfsupervised pretraining approach without annotations could be more appealing. While the comment highlights a potential limitation and suggests an alternative approach, it does not provide explicit guidance on how to implement this suggestion or what specific changes should be made to the draft. The action is implicit and somewhat vague, as the authors are left to infer the need for a selfsupervised approach and how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the proposed method is limited to supervised training due to the need for annotated labels for learning semantic tokens. It implies that a selfsupervised pretraining approach without annotations could be more appealing. However, the comment does not specify which part of the paper discusses the proposed method or where the limitation is mentioned. This makes it difficult for the authors to pinpoint the exact section that needs attention. Additionally, while the comment provides a suggestion for improvement, it lacks specificity in detailing how the authors might implement a selfsupervised approach. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the proposed method is limited to supervised training due to the need for annotated labels for learning semantic tokens. It suggests that a selfsupervised pretraining approach without annotations could be more appealing. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that a selfsupervised approach would be more appealing. The lack of evidence or detailed justification makes it difficult for the authors to understand and address the critique effectively. Therefore, the comment is considered 2, as it provides a general suggestion but lacks the necessary details to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a limitation of the proposed method, which requires annotated labels for learning semantic tokens, thereby limiting its application to supervised training. It suggests that a selfsupervised pretraining approach without annotations could be more appealing. While the comment highlights a potential area for improvement, it lacks specific guidance or suggestions on how the authors might implement a selfsupervised approach or address the limitation. The feedback is 3 as it points out a critical issue, but it could be more actionable with additional details or examples. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should demonstrate the scalability of their method, LFF, by showing its effectiveness on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. This is an explicit suggestion that provides a clear direction for the authors to expand their experiments. However, the comment does not specify how the authors should implement this suggestion, such as which specific tasks to consider or how to measure scalability. While the action is explicit, the lack of concrete guidance makes it 3.", "grounding_specificity_rationale": "The comment suggests that the authors should demonstrate the scalability of their method, LFF, by showing its effectiveness on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting the types of tasks that could be used to demonstrate scalability, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area needing improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that continuous control experiments are typically performed on simple and lowdimensional tasks, such as cartpole or mountain car, and recommends demonstrating the scalability of LFF by solving more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. This claim is 3 as it provides a logical reasoning for the suggestion, noting the current limitations of the experiments and proposing a way to address them. However, the comment lacks specific examples or references to support the claim about the challenges of higher input dimensionality tasks, which would strengthen the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation in the current experiments, noting that most continuous control experiments are performed on simple and lowdimensional tasks. It suggests that to fully demonstrate the scalability of the proposed method, LFF, the authors should show its effectiveness on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. This feedback is clear and actionable, providing a specific direction for the authors to expand their experiments and enhance the credibility of their results. However, the comment could be more helpful if it offered guidance on how to select or design these more challenging tasks or provided examples of similar experiments in the literature. Overall, the comment is 4 as it effectively guides the authors toward improving the scope and applicability of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests two specific changes: first, to include a statement about the change in linear regions in output space after a citation in the abstract, and second, to provide learning curves for all experiments in an appendix. Both suggestions are explicit and provide clear guidance on what the authors need to do to improve their draft. The concrete nature of the actions makes this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for improving the abstract by including a statement about the change in linear regions in output space after a citation. Additionally, it suggests including learning curves for all experiments in an appendix. This level of detail and specificity helps the authors understand exactly what needs to be addressed, making this comment 5.", "verifiability_rationale": "The review point suggests a specific change to the abstract, recommending the inclusion of a statement about the change in linear regions in output space after a citation. This suggestion is based on a logical reasoning that the current statement is too vague and could be improved by providing more specific details. However, the comment does not provide any references or examples to support the claim that this change would be beneficial or necessary. While the suggestion is logical, it lacks detailed justification or evidence, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting a change to the abstract to include a statement about the change in linear regions in output space after a citation. This recommendation would enhance the clarity and specificity of the abstract, making it more informative for readers. Additionally, the comment suggests including learning curves for all experiments in an appendix, which would provide a more comprehensive view of the results. This feedback is clear and actionable, offering the authors concrete steps to improve their draft. However, it could be more helpful if it explained why these changes are important or how they would benefit the paper. Overall, the comment is 4, as it provides valuable guidance for enhancing the clarity and depth of the paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises concerns about the paper\"s motivation and application, questioning the need for the proposed method and its potential usefulness. It suggests that the paper would be more impactful if it demonstrated the methodology\"s application to actual tasks involving domain adaptation, such as adapting a model trained on a synthetic dataset to a real dataset. While the comment implies that the authors should provide more context and examples to clarify the motivation and application, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional context and examples. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the paper\"s motivation and application, specifically questioning the need for the proposed method and its potential usefulness. It mentions the results showing mapping of one RGB image to another RGB image with a different style, and suggests that the paper would be more impactful if it demonstrated the methodology\"s application to actual tasks involving domain adaptation. However, the comment does not explicitly mention which part of the paper it is referring to, such as a specific section or figure, making it weakly grounded. The comment is specific in detailing what the authors could do to improve the paper, such as demonstrating the methodology\"s application to actual tasks. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the motivation and application of the proposed method, specifically noting the lack of clarity regarding the need for domain adaptation and the potential usefulness of the method. The reviewer suggests that demonstrating the methodology\"s application to actual tasks involving domain adaptation, such as adapting a model trained on a synthetic dataset to a real dataset, would be more impactful. While the comment raises valid concerns, it lacks specific examples or references to support the claim that the current application is insufficient. This makes the claim 3, as it provides a logical reasoning but requires more detailed evidence or examples to fully substantiate the critique.", "helpfulness_rationale": "The review comment raises a critical issue regarding the paper\"s motivation and application, questioning the need for the proposed method and its potential usefulness. It points out that the paper demonstrates results mapping one RGB image to another RGB image with a different style, but does not provide a clear application or context for when this domain adaptation would be necessary or beneficial. The comment suggests that the paper would be more impactful if it demonstrated the methodology\"s application to actual tasks involving domain adaptation, such as adapting a model trained on a synthetic dataset to a real dataset. This feedback is clear and actionable, as it identifies a specific area for improvement and provides a concrete suggestion for enhancing the paper\"s relevance and impact. However, it could be more helpful if it offered additional guidance on how to implement this suggestion or provided specific examples of tasks that could benefit from the proposed method. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the paper considers MULT as the only deep learningbased baseline that considers crosssensory interaction, despite MULT being proposed in 2019 and thus being \"out of fashion.\" However, the comment does not provide any explicit or implicit actions for the authors to take. It does not suggest whether the authors should update their baseline selection, include additional baselines, or address the issue of outdated baselines in their discussion. Without actionable guidance, the authors are left without a clear understanding of how to improve their draft based on this feedback. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the paper \"MISA: ModalityInvariant and Specific Representations for Multimodal Sentiment Analysis, ACM MM 2020,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the paper considers MULT as the only deep learningbased baseline that considers crosssensory interaction, despite MULT being proposed in 2019 and thus being \"out of fashion.\" This provides clear guidance on what needs to be addressed in the paper, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper considers MULT as the only deep learningbased baseline that considers crosssensory interaction, despite MULT being proposed in 2019 and thus being \"out of fashion.\" The comment provides a reference to MULT, which supports the claim that it is an outdated baseline. However, the comment lacks specific reasoning or evidence to fully substantiate why MULT is no longer relevant or how it impacts the paper\"s analysis. This makes the claim 3, as it provides some context but requires more detailed justification to be fully convincing.", "helpfulness_rationale": "The review comment points out that the paper considers MULT as the only deep learningbased baseline that considers crosssensory interaction, despite MULT being proposed in 2019 and thus being \"out of fashion.\" This feedback highlights a potential weakness in the paper\"s analysis, as it suggests that the authors may be overlooking more recent and relevant baselines. However, the comment does not provide specific suggestions on how the authors might address this issue or improve their analysis by considering newer baselines. While it identifies a gap in the paper, it lacks actionable guidance, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the comparison against other models in the experiments is unclear due to the omission of the value of the used ranks for all the models. It provides a clear action for the authors to take, which is to compare the tensor completion results for all the models with the same number of model parameters. The reviewer suggests a method for computing the number of model parameters, which is a concrete step for the authors to follow. This feedback is explicit and provides detailed guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiments\" and \"tensor completion results,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the comparison against other models, namely the omission of the value of the used ranks and the need to compare results with the same number of model parameters. The comment provides a clear direction for improvement by suggesting how to compute the number of model parameters. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the comparison against other models in the experiments is unclear due to the omission of the value of the used ranks for all the models. The reviewer suggests that to show the superiority of TW over TT and TR, the authors must compare the tensor completion results for all the models with the same number of model parameters. This claim is 3 as it provides a logical reasoning for the need to include the value of the used ranks and suggests a specific way to improve the comparison. However, the comment lacks specific examples or references to support the claim fully, making it difficult for the authors to fully understand the issue and address it effectively. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the experimental comparison, specifically the omission of the value of the used ranks for all the models, which makes it difficult to conduct a fair comparison. It provides a clear and actionable suggestion for improvement by recommending that the authors compare the tensor completion results for all the models with the same number of model parameters. This feedback is valuable as it guides the authors on how to enhance the clarity and rigor of their experimental analysis. However, the comment could be more helpful if it included specific examples or references to similar studies that have successfully implemented this approach. Overall, the comment is 4 as it provides actionable feedback that can significantly improve the draft."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the author\"s claim regarding the proposed algorithm\"s ability to remove subdivision splines and its potential impact on computation cost. However, it does not provide explicit guidance or suggestions on how the authors should address this concern or improve their draft. The comment implies that the authors should provide more detailed information about the algorithm\"s operation and its potential computational costs, but it does not specify what specific details are missing or how to present them. As a result, the action is implicit and vague, leaving the authors without clear direction on how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the author\"s claim about the observation of subdivision splines and the goal of pruning, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the lack of detailed explanation of the proposed algorithm and its potential impact on computation cost. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the author\"s claim about the proposed algorithm\"s ability to remove subdivision splines and its potential impact on computation cost. It challenges the claim by pointing out that the theoretical part of the paper lacks detailed explanation of the algorithm\"s operation. This raises a valid concern about the verifiability of the claim, as it highlights a gap in the paper\"s explanation. However, the comment does not provide specific examples or references to support the claim, making it 3. The authors would need to address this gap themselves to fully understand and respond to the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the authors\" claim regarding the proposed algorithm\"s ability to remove subdivision splines and its impact on computation cost. It points out that the theoretical part of the paper lacks detailed explanation of the algorithm\"s operation, which is crucial for understanding its effectiveness and efficiency. This feedback is clear and actionable, as it highlights a specific area where the authors need to provide more detailed information to support their claims. However, the comment could be more helpful if it offered suggestions on how to present this information or what specific details should be included. Overall, the comment is 4 as it directs the authors to a critical area for improvement in their draft."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that certain terms, such as W1, W2, W, and V, are not defined in the paper. It suggests that these terms might refer to the Encoder and Decoder networks, but this inference is not explicitly stated. The comment provides a clear indication of what needs to be addressed, which is the definition of these terms. However, it lacks specific guidance on how to define them or where to include the definitions in the paper. While the action is implicit, it is concrete once the authors understand the issue. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper where terms are not defined, such as \"p.3, A4, eq.3.\" This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what is missing, namely the definitions of W1, W2, W, and V. This provides clear guidance on what needs to be addressed to improve the clarity of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements about the absence of definitions for certain terms (W1, W2, W, and V) in the paper. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a significant issue by pointing out that certain terms, such as W1, W2, W, and V, are not defined in the paper. This lack of definition can lead to confusion for readers and hinder understanding of the paper. The comment is specific in its identification of the terms and provides clear guidance by suggesting that these terms might refer to the Encoder and Decoder networks. However, it could be more helpful if it included suggestions on where to define these terms or how to clarify their meaning within the context of the paper. Despite this, the comment is 4 as it directs the authors to a critical area that needs attention and improvement. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the comparison with certain baselines is unfair because they lack the prior knowledge of users or any language embedding computation. It implies that a better comparison should be considered. However, the comment does not specify which baselines are being referred to or how to make a better comparison. The action is implicit and lacks concrete details, making it 3. The authors can infer that they need to reconsider their comparison methodology, but they are not provided with specific guidance on how to do so.", "grounding_specificity_rationale": "The comment suggests that the comparison with certain baselines is unfair because they lack prior knowledge of users or language embedding computation. However, it does not specify which baselines are being referred to or where in the paper these comparisons are made. This lack of explicit reference to specific sections or baselines makes it difficult for the authors to pinpoint the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what a \"better comparison\" might entail, leaving the authors without clear guidance on how to address the issue. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the comparison with certain baselines is unfair because they lack prior knowledge of users or any language embedding computation. However, the comment does not provide specific examples of these baselines or detailed reasoning to support why they are considered unfair. Without this information, the authors may find it challenging to understand and address the issue. The lack of detailed justification or examples makes the claim 3, as it requires more context and evidence to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison of the proposed method with certain baselines, suggesting that the baselines lack prior knowledge of users or any language embedding computation. This feedback highlights a possible unfairness in the comparison, which could impact the validity of the results. However, the comment does not provide specific suggestions or examples of how to address this issue or what alternative baselines might be more appropriate. While it points out a relevant concern, the lack of actionable guidance limits its helpfulness. Therefore, the comment is 3, as it provides insight into a potential weakness but lacks depth and specificity in suggesting improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and observations about the paper, including why the outputside layers do not benefit from a specific method, the clarity of Figure 4, the presentation of Pixelshuffle details, and the use of pixelshuffle in superresolution. It also points out the lack of discussion on limitations and potential negative societal impact. While the comment identifies areas that need clarification or improvement, it does not provide explicit instructions or concrete suggestions on how the authors should address these issues. The actions are implicit and somewhat vague, as the authors need to infer what specific changes are needed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises several questions and observations about the paper, including the lack of clarity in Figure 4, the presentation of Pixelshuffle details, and the use of pixelshuffle in superresolution. It also points out the absence of a discussion on limitations and potential negative societal impact. However, the comment does not specify which part of the paper these issues are related to, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but the lack of explicit references makes it challenging to pinpoint the exact parts. The comment is specific in detailing what needs to be addressed, such as the clarity of Figure 4 and the presentation of Pixelshuffle details. Therefore, the comment is weakly grounded but specific, aligning with the label 3.", "verifiability_rationale": "The review point raises several questions and observations about the paper, including the lack of clarity in Figure 4, the presentation of Pixelshuffle details, and the use of pixelshuffle in superresolution. It also points out the absence of a discussion on limitations and potential negative societal impact. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. The lack of detailed justification or examples makes it difficult for the authors to understand and address the issues raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises several important points that could help the authors improve their draft. It questions the lack of clarity in Figure 4 and the presentation of Pixelshuffle details, suggesting that these aspects need further explanation. Additionally, it points out the absence of a discussion on limitations and potential negative societal impact, which is a critical aspect of any research work. However, the comment does not provide specific suggestions or guidance on how to address these issues, such as recommending additional explanations or examples. While it identifies areas for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is 3, as it provides some direction but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the process of generating negative chips from a lightweight RPN and whether they are fixed or updated during training. It also asks if alternating between generating negative chips and training the network would improve performance. While the comment highlights an area of uncertainty, it does not provide explicit instructions or suggestions for the authors to address this issue. The authors can infer that they need to clarify the process and potentially conduct experiments to test the impact of alternating between these steps, but the comment lacks concrete guidance on how to proceed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the process of generating negative chips from a lightweight RPN, specifically asking if they are fixed or updated during training. It also inquires about the potential impact of alternating between generating negative chips and training the network on performance. However, the comment does not specify which part of the paper this process is discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or experimental setup, but the lack of explicit reference makes it challenging to pinpoint the exact section. The comment is specific in its inquiry about the process and its potential impact, but the lack of grounding limits its effectiveness. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions seeking clarification about the process of generating negative chips from a lightweight RPN and whether they are fixed or updated during training. It also asks if alternating between these steps would improve performance. These are factual questions that do not contain subjective opinions, judgments, or suggestions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises an important question about the process of generating negative chips from a lightweight RPN, specifically asking whether they are fixed or updated during training. It also inquires about the potential impact of alternating between these steps on performance. This feedback is 3 as it prompts the authors to clarify a critical aspect of their methodology and potentially explore a new approach to improve performance. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending a particular approach or experiment to test the impact. While it identifies a potential area for improvement, it does not provide detailed actionable steps, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the applicability of the proposed approach to patients who are firsttime visitors without historical reports. It suggests that the authors should evaluate the approach on both new and old patients. While the comment implies that the authors should conduct additional experiments or analyses, it does not provide explicit instructions on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional experiments and determine how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the applicability of the proposed approach to patients who are firsttime visitors without historical reports. It suggests that the authors should evaluate the approach on both new and old patients. However, the comment does not specify which part of the paper this issue pertains to, such as a specific section or experiment. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. The comment is specific in suggesting a particular evaluation, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the applicability of the proposed approach to patients who are firsttime visitors without historical reports. It suggests that the authors should evaluate the approach on both new and old patients. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this evaluation is necessary or how it would impact the study. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a valid concern about the applicability of the proposed approach to patients who are firsttime visitors without historical reports. It suggests that the authors should evaluate the approach on both new and old patients to ensure its effectiveness in different scenarios. This feedback is 3 as it identifies a potential limitation in the study and provides a direction for further evaluation. However, the comment lacks specific guidance on how to conduct these evaluations or what metrics to use, which could be beneficial for the authors. Therefore, the comment is rated as 3, as it provides a clear direction for improvement but lacks detailed actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point suggests that some techniques used in the algorithm, such as computation offloading and gradient augmentation, may not be particularly novel. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue or improve the novelty of their techniques. The comment lacks actionable details, leaving the authors uncertain about what steps to take to enhance the novelty of their work. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment suggests that some techniques used in the algorithm, such as computation offloading and gradient augmentation, may not be particularly novel. However, it does not specify which part of the paper discusses these techniques, making it difficult for the authors to identify the exact sections that need attention. The comment is vague and lacks specificity, as it does not provide details on why these techniques might not be novel or how they could be improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that some techniques used in the algorithm, such as computation offloading and gradient augmentation, may not be particularly novel. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without specific examples or detailed justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that some techniques used in the algorithm, such as computation offloading and gradient augmentation, may not be particularly novel. However, it does not provide any specific examples or detailed reasoning to support this claim, nor does it offer suggestions on how the authors might address this issue or improve the novelty of their techniques. Without actionable feedback or guidance, the comment lacks utility for the authors in terms of improving their draft. Therefore, it is rated as 1."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the formulation of Equation (1), suggesting that the observations might be aggregated by methods other than averaging over the support $v$. It also mentions that disease incident data are often available in counts or rates per number of residents. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific changes to their formulation. The action is implicit and somewhat vague, as the authors are left to infer that they should consider alternative aggregation methods but are not given concrete steps on how to implement these changes. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equation (1),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the formulation assumes observations are obtained by averaging over the support $v$, but this might not be the only aggregation method used. The comment further suggests that disease incident data are often available in counts or rates per number of residents, implying that other aggregation methods could be considered. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the formulation in Equation (1) assumes observations are obtained by averaging over the support $v$, but this might not be the only aggregation method used. The reviewer supports this claim by referencing external works, specifically [Law et al., NeurIPS\"18] and [4], which discuss alternative aggregation methods. This provides a clear basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed examples or references to specific instances where other aggregation methods are used. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the formulation of Equation (1), suggesting that the observations might be aggregated by methods other than averaging over the support $v$. It also points out that disease incident data are often available in counts or rates per number of residents, implying that other aggregation methods could be considered. This feedback is 3 as it highlights a specific area for improvement in the paper\"s formulation. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or examples of alternative aggregation methods that could be considered. Overall, the comment offers some direction for the authors to enhance their work, but it lacks depth and actionable guidance, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper lacks an indepth analysis of why inverse scaling occurs over compute. It explicitly states that providing such an analysis would strengthen the paper. However, it does not specify what aspects of the analysis should be included or how the authors should approach it. The action is explicit but vague, as it lacks concrete guidance on how to conduct the analysis. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper lacks an indepth analysis of why inverse scaling occurs over compute. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for an analysis explaining the training dynamics, which would enhance the paper\"s solidity. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks an indepth analysis of why inverse scaling occurs over compute. However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. The comment suggests that such an analysis would strengthen the paper, but it lacks specific guidance or references to support the need for this analysis. As a result, the claim is 1, as it lacks sufficient justification or evidence to substantiate the need for an indepth analysis.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the lack of an indepth analysis to explain why inverse scaling occurs over compute. It suggests that providing such an analysis would strengthen the paper\"s solidity. While the comment highlights an important area for improvement, it does not offer specific guidance or suggestions on how the authors might conduct this analysis or what aspects to focus on. The feedback is 3 as it points out a critical area for enhancement, but it could be more actionable with additional details or examples. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a potential issue with the proposed algorithm, suggesting that it requires an additional assumption that each individual\"s data is iid drawn from the same distribution. The reviewer questions the validity of this assumption, noting that in practice, users\" preferred sets of emojis are likely to be different. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern or suggest alternative approaches. The action is implicit and somewhat vague, as the authors are left to infer that they need to justify or revise the assumption, but without concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 5.1\" and \"Theorem 6 and Theorem 7,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the proposed algorithm, namely the assumption that each individual\"s data is iid drawn from the same distribution, and questions the validity of this assumption. The comment provides a detailed critique of the theoretical foundation of the algorithm, which helps the authors understand the specific areas that need attention. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the validity of an assumption made in the paper regarding the iid nature of individual data. The reviewer provides a logical reasoning by questioning how Theorem 6 can be applied to prove Theorem 7 without this assumption. Additionally, the comment highlights a potential issue with the assumption by noting that in practice, users\" preferred sets of emojis are likely to be different. This provides a clear and logical basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed algorithm, specifically questioning the assumption that each individual\"s data is iid drawn from the same distribution. It points out that this assumption may not be justifiable in practice, as users\" preferred sets of emojis are likely to be different. This feedback is clear and actionable, as it prompts the authors to reconsider and justify this assumption or explore alternative approaches. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered examples of how to make the assumption more realistic. Overall, the comment is 4 as it directs the authors\" attention to a critical area that requires further clarification or revision."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should consider making the policy nonfixed to allow for more complex tasks, which would enable a comparison with reinforcement learning algorithms. While the comment implies an action, it does not provide explicit guidance on how to implement this suggestion or what specific tasks or algorithms should be considered. The authors can infer that they need to explore more complex tasks and compare their results with reinforcement learning algorithms, but the comment lacks concrete details on how to execute this action. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the current setting with a fixed policy is a subset of reinforcement learning and proposes a way to make the tasks more complex. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting a way to make the tasks more complex and compare with reinforcement learning algorithms, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the current setting with a fixed policy is a subset of reinforcement learning and proposes a way to make the tasks more complex. However, the comment lacks specific examples or references to support the claim that the tasks can become more complex or how this would impact the comparison with reinforcement learning algorithms. Without detailed justification or evidence, the claim remains somewhat vague, making it difficult for the authors to fully understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the current setting with a fixed policy is a subset of reinforcement learning and proposes a way to make the tasks more complex. It provides a specific suggestion to compare with a reinforcement learning algorithm baseline, which could be a valuable addition to the paper. However, the comment lacks detailed guidance on how to implement this suggestion or what specific tasks or algorithms should be considered. While it identifies a potential area for improvement, the feedback could be more actionable and comprehensive to be fully helpful. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the paper primarily focuses on explaining multitask models, which limits its applicability. However, it does not provide any explicit or implicit actions for the authors to take to address this limitation. There is no guidance on how to broaden the applicability or what specific changes should be made to improve the paper. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment suggests that the paper primarily focuses on explaining multitask models, which limits its applicability. However, it does not specify which part of the paper this focus is discussed in, nor does it provide details on how the applicability could be broadened. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention. Additionally, the comment lacks specificity regarding what aspects of applicability are limited or how they could be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper primarily focuses on explaining multitask models, which limits its applicability. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references to what aspects of applicability are limited or how the focus on multitask models affects it, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment points out that the paper primarily focuses on explaining multitask models, which limits its applicability. However, it does not provide any specific suggestions or guidance on how the authors might broaden the applicability or address this limitation. Without actionable feedback or detailed advice, the comment lacks depth and does not offer much value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the literature review, noting that it ignores several papers that are relevant to the topic. It suggests that the authors should consider including papers like VRMARINA and DASHAMVR, which satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. While the comment implies that the authors should expand their literature review to include these papers, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add these references to their literature review. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"next section\" and the \"literature review,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the literature review, namely the omission of relevant papers like VRMARINA and DASHAMVR, which satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the literature review ignores several papers that are relevant to the topic, specifically mentioning VRMARINA and DASHAMVR. The reviewer provides a rationale by stating that these papers satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. This reasoning is 3 as it provides a logical basis for the claim, but it lacks specific references or detailed comparisons to fully substantiate the claim. The authors would need to investigate these papers to fully understand the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the literature review, noting that it overlooks several relevant papers, including VRMARINA and DASHAMVR. It provides a clear rationale for why these papers are important, as they satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. This feedback is actionable, as it directs the authors to expand their literature review to include these papers, which could enhance the comprehensiveness and relevance of their work. However, the comment could be more helpful if it suggested how to integrate these papers into the literature review or provided specific guidance on how to address this omission. Overall, the comment is 4, as it highlights a significant gap in the literature review and offers a clear direction for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point consists of two questions: the first asks for additional insights into modest performance gains on Clothing1M, and the second inquires about the algorithm\"s performance on other realworld datasets like WebVision, evaluated by DivideMix. These questions are explicit and seek specific information from the authors. However, they do not provide any guidance or suggestions on how the authors should address these questions or improve their draft. The lack of actionable advice makes it difficult for the authors to know what steps to take in response to the questions. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment consists of two questions, each of which seeks additional information or clarification. The first question asks for insights into modest performance gains on Clothing1M, while the second inquires about the algorithm\"s performance on other realworld datasets like WebVision, evaluated by DivideMix. However, the comment does not specify which part of the paper these questions pertain to, making it difficult for the authors to identify the exact sections that need attention. Additionally, the questions lack specificity regarding what kind of insights or performance details are being sought. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point consists of two questions seeking additional insights or information. It does not contain any claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the \"No\" label.", "helpfulness_rationale": "The review comment consists of two questions seeking additional insights or information. The first question asks for additional insights into modest performance gains on Clothing1M, while the second inquires about the algorithm\"s performance on other realworld datasets like WebVision, evaluated by DivideMix. These questions are relevant and could provide valuable context for the authors to enhance their understanding of the algorithm\"s performance. However, the comment lacks actionable feedback or suggestions for improvement, leaving the authors with only a need for clarification. While it prompts the authors to consider these aspects, it does not offer guidance on how to address them or improve the draft. Therefore, the comment is 3, as it provides some direction but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors provide a more detailed presentation of the compared models, specifically mentioning the differences between KVAE and DMM and DVBF. It also asks for a comment on the computation requirements of the three methods compared in Table 1. While the comment implies that the authors should provide more detailed information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not specify exactly what details should be included or how to present them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests a more detailed presentation of the compared models, specifically mentioning the differences between KVAE and DMM and DVBF. Additionally, it asks for a comment on the computation requirements of the three methods compared in Table 1. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point expresses a request for more detailed information about the compared models, specifically mentioning the differences between KVAE and DMM and DVBF. The reviewer acknowledges understanding the general differences but seeks a more detailed presentation. The comment does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for additional information, making it a factual statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors provide a more detailed presentation of the compared models, particularly the differences between KVAE and DMM and DVBF. It also requests a comment on the computation requirements of the three methods compared in Table 1. This feedback is clear and actionable, as it directs the authors to enhance the clarity and depth of their presentation, which can help readers better understand the models and their differences. However, the comment could be more helpful if it included suggestions on how to present the additional details or examples of what specific information would be beneficial. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the theoretical results\" lack of immediate practical implications, noting that this is understandable given the novelty of the work. It suggests that the paper should include more takeaway points for practitioners, specifically mentioning the observation that querying a cluster proportionally to the square root of its size. However, the comment does not provide explicit guidance on how to incorporate these takeaway points or whether this observation is indeed novel. The action is implicit and somewhat vague, as the authors are left to infer that they should include more practical implications and clarify the novelty of their findings. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the theoretical results and their practical implications, acknowledging the novelty of the work. It suggests that the paper should include more takeaway points for practitioners, specifically mentioning the observation that querying a cluster proportionally to the square root of its size. However, the comment does not specify which part of the paper discusses these theoretical results or where the authors should include more practical implications. While the authors might infer that it relates to the theoretical sections, the comment lacks full grounding as it does not explicitly mention specific sections or figures. The suggestion is specific in terms of what the authors should consider, but the lack of explicit grounding makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point acknowledges the theoretical nature of the results and their lack of immediate practical implications, noting that this is understandable given the novelty of the work. It suggests that the paper should include more takeaway points for practitioners, specifically mentioning the observation that querying a cluster proportionally to the square root of its size. However, the comment does not provide specific examples or references to support the claim that this observation is novel or lacks practical implications. The reasoning is somewhat logical but lacks detailed evidence or references, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the theoretical nature of the results and their lack of immediate practical implications, which is understandable given the novelty of the work. It suggests that the paper should include more takeaway points for practitioners, specifically mentioning the observation that querying a cluster proportionally to the square root of its size. However, the comment does not provide specific guidance on how to incorporate these takeaway points or how to make them more practical. While it identifies a potential area for improvement, the feedback lacks depth and actionable suggestions, making it 3. The authors gain some insight into the need for more practical implications but are left without detailed guidance on how to achieve this. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the necessity of introducing separators in section 4 and asks for clarification on what additional information they convey beyond T/I/O. While the comment implies that the authors should provide a justification for the introduction of separators, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to explain the purpose of the separators but are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the reason for introducing separators and asks for clarification on what additional information they convey beyond T/I/O. This provides clear guidance on what needs to be addressed in the section. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the necessity of introducing separators in section 4 and asks for clarification on what additional information they convey beyond T/I/O. However, the comment does not provide any reasoning, examples, or references to support why the introduction of separators is questionable. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment questions the rationale behind the introduction of separators in section 4, asking for clarification on what additional information they convey beyond T/I/O. This feedback is 3 as it prompts the authors to provide a justification for the inclusion of separators, which could enhance the clarity and comprehensiveness of their work. However, the comment lacks specific suggestions or guidance on how to address this issue, such as proposing alternative explanations or examples. To be more helpful, the comment could include more detailed feedback or suggestions for improvement. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that, in addition to the number of queries, the real search cost (e.g., in terms of GPU days) should be compared in Table 3. This is an explicit suggestion that provides a clear action for the authors to take, namely, to include the real search cost in their analysis. The comment is specific and provides a concrete example of what needs to be added, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests comparing the real search cost (e.g., in terms of GPU days) in addition to the number of queries. This provides clear guidance on what needs to be addressed in the table. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that, in addition to the number of queries, the real search cost (e.g., in terms of GPU days) should be compared in Table 3. This is a suggestion for improvement, not a claim or opinion that requires verification. It is a request for additional information to be included in the table, which is a factual statement. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the paper. It recommends comparing the real search cost (e.g., in terms of GPU days) in addition to the number of queries, which is a relevant and important aspect of the analysis. This feedback is clear and provides a concrete way for the authors to enhance their draft, making it 5. However, it could be more helpful if it explained why this comparison is important or how it would impact the understanding of the results. Overall, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the training details of the VQGAN, specifically whether it is pretrained or only trained on the 88,635 images from the Computer Vision Figures dataset. While the comment implies that the authors should provide these details, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include this information. However, the comment does provide a clear direction on what details are missing, which makes it 3. Therefore, this comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment raises a question about the training details of the VQGAN, specifically whether it is pretrained or only trained on the 88,635 images from the Computer Vision Figures dataset. However, it does not specify which part of the paper this question pertains to, such as the methodology or results sections. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper being addressed. The comment is specific in its request for clarification on the training details, but it is 1 because it does not indicate where this information should be included. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the training details of the VQGAN, specifically whether it is pretrained or only trained on the 88,635 images from the Computer Vision Figures dataset. This is a factual inquiry that does not contain a claim or opinion requiring verification. It is a request for clarification, which is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the training details of the VQGAN, asking whether it is pretrained or only trained on the 88,635 images from the Computer Vision Figures dataset. This is a clear and actionable request for clarification, as it prompts the authors to provide additional information that could be crucial for understanding the methodology and results. By addressing this point, the authors can enhance the transparency and comprehensiveness of their paper. However, the comment could be more helpful if it provided context or explained why this information is important. Overall, the feedback is 4 as it directs the authors to a specific area needing clarification, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the proposed methods, DualIS and DualDIS, noting that they do not perform well on some crossmodel retrieval tasks, particularly in the MSVD dataset (Table 3). However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this issue, such as suggesting ways to improve the methods\" performance or offering alternative approaches. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"DualIS and DualDIS\" and \"MSVD (Table 3),\" allowing the authors to accurately identify the specific parts of the paper being addressed. It also specifies the issue by pointing out that the proposed methods do not perform well on some crossmodel retrieval tasks, particularly in the MSVD dataset. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed methods, DualIS and DualDIS, are not generic on some crossmodel retrieval tasks, specifically citing the performance in the MSVD dataset (Table 3). However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or data to support the assertion, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment points out a specific issue with the proposed methods, DualIS and DualDIS, noting that they do not perform well on some crossmodel retrieval tasks, particularly in the MSVD dataset (Table 3). This feedback is 3 as it identifies a potential weakness in the paper\"s methodology, prompting the authors to consider whether their methods are generic enough for various tasks. However, the comment lacks actionable suggestions or guidance on how to address this issue or improve the methods\" performance. Without specific advice or examples, the authors may find it challenging to make meaningful improvements based on this feedback. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the experimental strengths of the proposed approach, specifically questioning the need for running a descent procedure for 40 different networks from the training phase. The reviewer suggests an alternative method, running vanilla Adam on the final network with 40 random initial points, which could potentially reach the global minimum. While the comment implies that the authors should reconsider their experimental approach, it does not explicitly instruct them to make changes or provide detailed guidance on how to implement the suggested alternative. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their experimental setup and potentially make changes. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the experimental methodology, namely the need to run a descent procedure for 40 different networks from the training phase. However, it does not explicitly mention which section of the paper this methodology is discussed in, making it weakly grounded. The comment is specific in detailing the alternative method suggested by the reviewer, which involves running vanilla Adam on the final network with 40 random initial points. This provides clear guidance on what could be improved in the experimental setup. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point questions the experimental strengths of the proposed approach by suggesting an alternative method that could potentially reach the global minimum. The reviewer provides a logical reasoning by comparing the proposed algorithm to a simpler method involving vanilla Adam and random initial points. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises a concern about the experimental strengths of the proposed approach, specifically questioning the need for running a descent procedure for 40 different networks from the training phase. The reviewer suggests an alternative method, running vanilla Adam on the final network with 40 random initial points, which could potentially reach the global minimum. This feedback is clear and provides a specific suggestion for improvement, offering a different perspective on the experimental design. However, the comment could be more helpful if it included additional details or examples to further guide the authors in implementing the suggested alternative. Overall, the comment is 4 as it identifies a potential area for improvement and provides a concrete suggestion, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point is explicit and provides a clear action for the authors to take: they need to correct the quotation marks in the phrase \"for \"inbetween\" uncertainty\" to ensure they are forward marks rather than backward marks. This feedback is concrete and leaves no ambiguity about what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the phrase \"for \"inbetween\" uncertainty,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the quotation marks, providing a precise correction that needs to be made. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual correction regarding the quotation marks in the phrase \"for \"inbetween\" uncertainty.\" It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely a factual statement about the correct usage of quotation marks, making it a \"No\" label.", "helpfulness_rationale": "The review comment is highly specific and actionable, as it identifies a precise error in the use of quotation marks in the phrase \"for \"inbetween\" uncertainty.\" By pointing out this error, the comment provides clear guidance on how to correct it, which is crucial for maintaining the accuracy and professionalism of the paper. This level of detail and specificity makes the comment 5, as it empowers the authors to make a direct and meaningful improvement to their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment raises several questions and suggestions regarding specific aspects of the paper. It explicitly asks why the authors did not specify what Omega is at line 178 and suggests being more explicit about the OMD algorithm and the link function. Additionally, it inquires about the specific theorem in reference [32] that is being referred to for the regret guarantee. These questions and suggestions provide clear and explicit actions for the authors to take, such as specifying Omega, being more explicit about OMD, and clarifying the link function and theorem reference. The feedback is concrete and direct, giving the authors a clear understanding of what needs to be addressed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions line 178, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the need to specify what Omega is, the explicitness of the OMD algorithm, the link function, and the specific theorem in reference [32] being referred to for the regret guarantee. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of questions and requests for clarification, such as asking for the definition of Omega, the explicitness of the OMD algorithm, the link function, and the specific theorem in reference [32] being referred to. These are factual requests for information or clarification, not subjective claims or opinions. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by questioning the lack of clarity in the paper regarding the definition of Omega, the explicitness of the OMD algorithm, the link function, and the specific theorem in reference [32] being referred to for the regret guarantee. By asking for clarification on these points, the comment directs the authors to enhance the clarity and specificity of their work. This feedback is valuable as it identifies areas where the paper could be improved and provides clear guidance on what needs to be addressed. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of how to improve the clarity. Overall, the comment is 4, as it effectively guides the authors toward improving the clarity and precision of their draft."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point states that the models are learned directly from pixels without a Markovian state, but it does not provide any explicit or implicit actions for the authors to take. It lacks any guidance or suggestions on how the authors might address this observation or improve their work. Without any actionable advice or direction, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions that the models are learned directly from pixels without a Markovian state, but it does not specify which part of the paper this observation is based on. The authors cannot confidently determine which section or aspect of the paper this comment addresses, making it weakly grounded. Additionally, the comment lacks specificity as it does not provide details on why this observation is important or how it affects the paper. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the models are learned directly from pixels without a Markovian state. However, it does not provide any supporting evidence, reasoning, or references to justify why this is a concern or how it affects the paper. Without additional context or explanation, the claim remains 1, as the authors would not know how to address or understand the issue. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment points out that the models are learned directly from pixels without a Markovian state, which is a relevant observation that could impact the paper\"s methodology or results. However, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might address this observation or its implications. Without actionable feedback or detailed insights, the authors are left without a clear understanding of how to improve their draft based on this information. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the usefulness of the sequence example at different steps of the paper but expresses surprise at the mention of a \"common\" practice in Example 2, specifically the use of the Hamming distance as a scoring loss over entire parts of the sequence. The reviewer suggests that this approach is not commonly seen and requests references to support this claim. While the comment implies that the authors should provide references, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors know they need to provide references but may not be entirely sure how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Example 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular practice mentioned in Example 2, namely the use of the Hamming distance as a scoring loss over entire parts of the sequence, which the reviewer claims is not commonly seen. The comment further requests references to support this claim, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point expresses surprise at the mention of a \"common\" practice in Example 2, specifically the use of the Hamming distance as a scoring loss over entire parts of the sequence. The reviewer claims that this approach is not commonly seen and requests references to support this claim. While the comment highlights a potential gap in the literature, it lacks specific examples or references to substantiate the claim. This makes the comment 3, as it points out an area for further exploration but does not provide sufficient evidence or examples to fully support the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the usefulness of the sequence example at different steps of the paper but expresses surprise at the mention of a \"common\" practice in Example 2, specifically the use of the Hamming distance as a scoring loss over entire parts of the sequence. The reviewer points out that this approach is not commonly seen and requests references to support this claim. This feedback is 3 as it identifies a potential gap in the literature and suggests a direction for further exploration or clarification. However, the comment could be more helpful if it provided specific examples or detailed guidance on how to address this issue. Overall, the comment offers a clear direction for improvement but lacks depth, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests changing the name of the \"Evaluation\" element to \"Metrics\" to avoid confusion with the more general term \"evaluation.\" It also implies that the corresponding sections can be removed and the metrics can be mentioned briefly along with the datasets or in the captions of the tables. While the comment provides a clear action to change the name, it lacks specific guidance on how to integrate the metrics into the text or what specific sections should be removed. The authors know they need to make these changes but may struggle with the execution details. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests changing the name of the \"Evaluation\" element to \"Metrics\" and implies that the corresponding sections can be removed. It also mentions that the metrics can be briefly mentioned along with the datasets or in the captions of the tables. However, the comment does not specify which sections are being referred to, making it weakly grounded. The suggestion to change the name and remove sections is specific, but without explicit references to the sections, the authors may find it challenging to pinpoint the exact parts of the paper that need revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests changing the name of the \"Evaluation\" element to \"Metrics\" to avoid confusion with the more general term \"evaluation.\" It also implies that the corresponding sections can be removed and the metrics can be mentioned briefly along with the datasets or in the captions of the tables. The comment provides a logical reasoning for the change, as most metrics are wellknown and used as standard practice. However, it lacks specific examples or references to support the claim that the metrics are wellknown and used as standard practice. This makes the claim 3, as it provides a logical basis but could be strengthened with more detailed evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests a change in the name of the \"Evaluation\" element to \"Metrics,\" which is a clear and actionable piece of feedback. It also implies that the corresponding sections can be removed and the metrics can be mentioned briefly along with the datasets or in the captions of the tables. This suggestion is logical and could help improve the clarity and organization of the paper. However, the comment could be more helpful if it provided specific examples of how the metrics should be integrated into the text or which sections should be removed. Overall, the comment is 4 as it offers a clear direction for improvement but could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the new proposed dataset, DRRI, could have been explored more in the paper. However, it does not provide any explicit or implicit guidance on how the authors should explore this dataset further. There is no indication of what specific aspects of the dataset should be discussed, analyzed, or compared. Without concrete suggestions or examples, the authors are left without a clear understanding of how to address this feedback. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment suggests that the new proposed dataset, DRRI, could have been explored more in the paper. However, it does not specify which part of the paper should have included more exploration of the dataset, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the dataset should have been explored further. Without explicit guidance on where to make improvements, the authors cannot effectively address the feedback. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the new proposed dataset, DRRI, could have been explored more in the paper. However, it does not provide any specific reasoning, examples, or references to support why this exploration is necessary or how it could have been improved. Without additional context or justification, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that the new proposed dataset, DRRI, could have been explored more in the paper. However, it lacks specificity and does not provide any guidance on how the authors might explore the dataset further or what aspects of it could be discussed. Without actionable suggestions or examples, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests using more objective terms instead of \"remarkable\" to describe the accuracy improvement. It provides a specific example of the term \"remarkable\" and offers a suggestion to characterize the improvement more objectively. While the comment explicitly states the action to take, it does not provide detailed guidance on how to achieve this objective, such as suggesting alternative terms or a more detailed analysis of the improvement. Therefore, the comment is 4, as it clearly identifies the issue but lacks concrete steps for execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific line number, \"[218],\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion to use more objective terms instead of \"remarkable\" to describe the accuracy improvement. The comment further specifies the issue by pointing out that the improvement is evident but not necessarily remarkable, given the squished axes. This level of detail provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests using more objective terms instead of \"remarkable\" to describe the accuracy improvement. The reviewer provides a specific example of the term \"remarkable\" and offers a logical reasoning by pointing out that the improvement is evident but not necessarily remarkable, given the squished axes. This reasoning is clear and provides a basis for the suggestion, making the claim 4. However, the comment could be strengthened by providing examples of more objective terms or references to established practices in the field. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a specific suggestion to use more objective terms instead of \"remarkable\" when describing the accuracy improvement. It offers a clear and actionable recommendation by pointing out that the improvement is evident but not necessarily remarkable, given the squished axes. This feedback is valuable as it helps the authors refine their language and presentation of results, making the comment 4. However, the comment could be more helpful if it included suggestions for alternative terms or a more detailed explanation of how to characterize the improvement objectively. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges the paper\"s interesting idea and extensive experiments, noting that the results are not perfect but show improved performance over the previous stateoftheart. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issues with the synthesized results, such as inconsistent motion, changing color, or objects disappearing over time. Without actionable suggestions or specific feedback, the authors are left without a clear path for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"UCF101\" and \"synthesized results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the synthesized results, such as inconsistent motion, changing color, and objects disappearing over time. The reviewer suggests running the LSTM over longer time steps to address these issues. This provides clear guidance on what needs to be improved. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point acknowledges the paper\"s interesting idea and extensive experiments, noting that the results are not perfect but show improved performance over the previous stateoftheart. It provides specific examples of issues with the synthesized results, such as inconsistent motion, changing color, and objects disappearing over time. However, the comment does not offer detailed reasoning or references to support these claims, leaving the authors without a clear understanding of how to address these issues. The suggestion to run the LSTM over longer time steps is a logical next step, but it lacks specific guidance or evidence to fully substantiate the claim. Therefore, the comment is 3, as it provides some justification but lacks detailed evidence or examples.", "helpfulness_rationale": "The review comment acknowledges the paper\"s interesting idea and extensive experiments, noting that the results are not perfect but show improved performance over the previous stateoftheart. It highlights specific issues with the synthesized results, such as inconsistent motion, changing color, and objects disappearing over time. The reviewer suggests running the LSTM over longer time steps to address these issues. While the comment identifies areas for improvement, it lacks depth and does not provide detailed guidance or suggestions on how to address these issues. The feedback is 3 as it points out specific weaknesses but does not offer comprehensive advice for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point states that, like most work on pruning, it is not yet possible to realize efficiency gains on GPU. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or suggestions for potential solutions. The comment lacks actionable details, leaving the authors without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions \"most work on pruning\" without specifying which part of the paper it addresses, making it difficult for the authors to identify the exact section being referred to. Additionally, it does not provide specific details or examples of what needs to be addressed regarding the realization of efficiency gains on GPU. This lack of grounding and specificity makes it challenging for the authors to understand the feedback and take appropriate action. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that \"it is not yet possible to realize efficiency gains on GPU,\" which is a subjective opinion based on the current state of research in pruning. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a potential limitation in the work, noting that, like most work on pruning, it may not yet be possible to realize efficiency gains on GPU. However, the comment lacks specificity and does not provide any actionable advice or suggestions for improvement. It does not offer guidance on how the authors might address this issue or explore alternative approaches to achieve efficiency gains on GPU. Without actionable feedback or constructive suggestions, the comment does not help the authors in improving their draft. Therefore, it is rated as 1."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the numerical evaluation, specifically noting that the method is only evaluated on synthetic data and that the comparison with [5] is not fair due to the different complexity of the problem. However, the comment does not provide explicit guidance on how the authors should address these issues. It lacks concrete suggestions or actions for improving the evaluation or making the comparison more fair. The authors are left to infer that they need to expand the evaluation to realworld data and consider the complexity of the problem, but without specific instructions, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the numerical evaluation and the comparison with a specific reference, [5], which provides some grounding. However, it does not specify which part of the paper discusses the numerical evaluation or the comparison, making it weakly grounded. The comment is specific in pointing out the issue with the evaluation on synthetic data and the unfair comparison with [5], but it lacks detailed guidance on how to address these issues. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the numerical evaluation is not fully convincing because the method is only evaluated on synthetic data, and the comparison with [5] is not fair due to the different complexity of the problem. The comment provides a logical reasoning by pointing out the limitations of the evaluation setup and the unfair comparison with [5]. However, it lacks specific examples or references to support the claim fully, such as detailed comparisons or data that demonstrate the unfairness. This makes the claim 3, as it provides a basis for the critique but requires more detailed evidence to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant limitation in the numerical evaluation of the method, noting that it is only evaluated on synthetic data. It also points out an unfair comparison with [5], as [5] is designed for a more complex problem. This feedback is valuable as it highlights a critical weakness in the evaluation process and suggests that the authors should consider expanding their evaluation to realworld data and addressing the unfair comparison. However, the comment could be more helpful if it provided specific suggestions on how to improve the evaluation or make the comparison more fair. Despite this, the comment is 4 as it directs the authors\" attention to a crucial area for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether studying the number of bits in logits helps against a larger epsilon in the PGD attack. It suggests that having a 32bit logit should improve robustness against a more powerful adversary. While the comment implies that the authors should consider this experiment, it does not explicitly instruct them to conduct it. The action is implicit and somewhat vague, as the authors are left to infer that they should explore this aspect. However, the comment does provide a concrete suggestion about the potential impact of the experiment on strengthening the paper. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the study of the number of bits in logits and their impact on robustness against a larger epsilon in the PGD attack. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment does provide some specificity by suggesting that having a 32bit logit might improve robustness, but it lacks detailed guidance on how to address this question or where to incorporate it into the paper. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a question about the impact of the number of bits in logits on robustness against a larger epsilon in the PGD attack. The comment suggests that having a 32bit logit might improve robustness, but it does not provide any evidence or references to support this claim. The reasoning is based on intuition, which is not sufficient to fully substantiate the claim. Therefore, the comment is considered 2, as it lacks detailed justification or evidence to fully support the claim.", "helpfulness_rationale": "The review comment raises an interesting question about the potential impact of the number of bits in logits on robustness against a larger epsilon in the PGD attack. It suggests that having a 32bit logit might improve robustness, which is a logical inference based on the authors\" work. However, the comment does not provide specific guidance or suggestions on how the authors might explore this question or incorporate it into their study. While it identifies a potential area for further investigation, it lacks actionable advice or detailed feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the impact of the method on insurance costs for men and women. However, it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this question or what specific information should be included in the paper to answer it. Without any actionable steps or suggestions, the authors are left without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the impact of the method on insurance costs for men and women. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the method or results should be considered in relation to insurance costs. Without clear grounding or specificity, the authors cannot effectively address the issue. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification on a specific aspect of the paper, specifically the impact of the method on insurance costs for men and women. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the impact of the method on insurance costs for men and women. While it identifies a potential area of interest, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this question or incorporate it into their paper. The comment does not offer actionable feedback or insights that would help the authors improve their draft. As a result, it is 2, as it points out a potential area of interest but does not provide enough detail or direction for the authors to effectively address it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the paper\"s methodology, specifically the way it categorizes papers based on their publication years on the ACL anthology. The reviewer points out that many papers are available on arXiv much earlier than their publication in the ACL anthology, using the example of the BERT paper. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest alternative categorization methods. The action is implicit and somewhat vague, as the authors can infer that they need to reconsider their categorization approach but are not given specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue with categorizing papers based on their publication years on the ACL anthology, providing a specific example of the BERT paper being available on arXiv earlier. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it points out a potential issue with the categorization method and provides a concrete example of a paper that was available earlier on arXiv. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper\"s categorization of papers based on their publication years on the ACL anthology is problematic because many papers are available on arXiv much earlier. The reviewer provides a specific example of the BERT paper being available on arXiv from October, which supports the claim. However, the comment could be strengthened by providing more examples or a broader analysis of the issue. Overall, the claim is 4 due to the specific example provided, but it could be more robust with additional evidence or reasoning. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s categorization method, specifically the use of publication years on the ACL anthology to categorize papers. It points out that many papers are available on arXiv much earlier than their publication in the ACL anthology, using the example of the BERT paper. This feedback is 3 as it highlights a potential flaw in the categorization approach and prompts the authors to reconsider their methodology. However, the comment could be more helpful if it provided suggestions on alternative categorization methods or how to address this issue. Overall, the comment is 3 as it directs the authors\" attention to a specific area for improvement but lacks detailed guidance on how to resolve the issue."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises two main issues. First, it questions the authors\" choice of using a relaxation of rejection sampling instead of directly using Importance sampling. This implies that the authors should provide a justification for their approach. Second, it points out a lack of understanding regarding the difference between QRS and RS in Algorithm 1, suggesting that the authors should clarify how these methods differ and provide an example where they behave differently. Both comments are explicit in their requests for clarification and justification, and they provide concrete guidance on how the authors can address these issues. Therefore, the comments are 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the reviewer\"s inability to understand the difference between QRS and RS and the need for the authors to provide an example where these methods behave differently. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts. The first part questions the authors\" choice of using a relaxation of rejection sampling instead of directly using Importance sampling, without providing any justification or evidence for why this choice is problematic. The second part raises a question about the difference between QRS and RS in Algorithm 1, suggesting that the authors should provide an example where these methods behave differently. However, the comment lacks specific reasoning or references to support the claim, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises two distinct issues. First, it questions the authors\" choice of using a relaxation of rejection sampling instead of directly using Importance sampling, suggesting that the authors should provide a justification for their approach. This feedback is 3 as it prompts the authors to clarify their reasoning, but it lacks specific guidance on how to improve the explanation. Second, the comment points out a lack of understanding regarding the difference between QRS and RS in Algorithm 1, suggesting that the authors should provide an example where these methods behave differently. This is a clear and actionable suggestion that could help the authors clarify their methodology. Overall, the comment provides some helpful feedback but could be more comprehensive and detailed to fully support the authors in improving their draft. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point notes that the observed performance enhancements are modest, implying that there is room for further refinement in the future. However, it does not provide any explicit or implicit actions for the authors to take to address this observation. There is no guidance on how to refine the work or what specific areas need improvement. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment suggests that the observed performance enhancements are modest, implying that there is room for further refinement in the future. However, it does not specify which part of the paper this observation is based on, nor does it provide details on what aspects of the work could be refined. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention. Additionally, the comment lacks specificity regarding what specific improvements could be made or how the authors might address the modest performance enhancements. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the observed performance enhancements are modest, suggesting that there is room for further refinement. However, the comment lacks specific examples, data, or references to support this claim. Without detailed evidence or reasoning, it is difficult for the authors to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment acknowledges the observed performance enhancements but suggests that they are modest, implying that there is room for further refinement. However, it does not provide specific guidance or suggestions on how the authors might achieve this refinement or what areas could be improved. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to provide references for specific passages in Section 3.2 and to clarify what \"MLP\" stands for in Figure 2. These are clear and direct actions that the authors can take to improve their draft. The feedback is specific and provides concrete guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections (3.2, lines 230234 and 234235) and a figure (Figure 2), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely providing references for the passages mentioned and clarifying what \"MLP\" stands for in Figure 2. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements and requests for clarification, such as asking for references and clarification of terms. It does not contain subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 5 as it provides specific and actionable feedback. It identifies two areas where references are needed, which is crucial for establishing the credibility and context of the paper. By asking for references, the authors are guided to enhance the robustness and transparency of their work. Additionally, the comment clarifies a term (\"MLP\") that is not described in the paper, ensuring that the terminology is consistent and understandable. This level of detail and guidance empowers the authors to make significant improvements to their draft, making the comment 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the experimental results on the last two datasets, suggesting that the performance is similar to IRM and questioning whether this is due to the issues mentioned earlier. However, it does not provide explicit guidance or suggestions on how the authors might address these concerns or improve the experimental validation. The comment lacks actionable details, such as recommending additional experiments, modifications to the methodology, or alternative analyses to validate the proposed method. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the experiments\" and \"the last two datasets,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the experimental results, noting that they are not convincing enough to validate the effectiveness of the proposed method due to similarities with IRM. The comment further questions whether this similarity is caused by the issues mentioned earlier. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with a score of 5.", "verifiability_rationale": "The review point claims that the experimental results on the last two datasets are not convincing enough to validate the effectiveness of the proposed method, as the performance is similar to IRM. The reviewer questions whether this similarity is due to the issues mentioned earlier. However, the comment lacks specific examples or detailed reasoning to support the claim that the performance is not convincing. Without additional context or evidence, the authors may find it challenging to understand and address the critique. Therefore, the claim is considered 2, as it provides some basis for the critique but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental results, noting that the performance on the last two datasets is not convincing enough to validate the effectiveness of the proposed method. It further questions whether this similarity to IRM is due to the issues mentioned earlier. While the comment highlights a potential weakness in the experimental validation, it lacks actionable suggestions or guidance on how the authors might address this issue or improve their experimental setup. Without specific recommendations or detailed feedback, the authors are left with a general understanding of the problem but without a clear path to improvement. Therefore, the comment is 3, as it points out a concern but does not provide sufficient detail or direction for the authors to effectively address it."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the necessity of detecting both entities in Figure 2, suggesting that knowing the long entity might be sufficient. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should address this question, modify their approach, or provide additional explanation. The comment lacks actionable details, leaving the authors uncertain about how to respond. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the necessity of detecting both entities in the example and asks for clarification on the difference between detecting both entities and just knowing the long one. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5.", "verifiability_rationale": "The review point is a question seeking clarification about the necessity of detecting both entities in Figure 2. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the necessity of detecting both entities in Figure 2, suggesting that knowing the long entity might be sufficient. This is a valid point that prompts the authors to reconsider the relevance and importance of their approach. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve their methodology. While it identifies a potential area for improvement, the feedback is somewhat vague and does not offer actionable steps for the authors to take. Therefore, the comment is 3, as it provides some insight but lacks comprehensive guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the paper lacks empirical validation and suggests that experiments should be conducted to validate the bounds. This provides a clear and direct action for the authors to take, which is to include empirical validation through experiments. The comment is explicit and concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the paper lacks empirical validation and requests experiments to validate the bounds. However, it does not specify which part of the paper this lack of validation pertains to, such as specific sections or experiments. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its request for empirical validation but lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks empirical validation and suggests that experiments should be conducted to validate the bounds. However, the comment does not provide any specific examples, references, or detailed reasoning to support why empirical validation is necessary or how it would improve the paper. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by noting the absence of empirical validation. It suggests that the authors should include experiments to validate the bounds, which is a clear and actionable piece of feedback. However, the comment could be more helpful if it provided specific guidance on what types of experiments or validation methods would be most appropriate or how to integrate them into the existing framework. Despite this, the comment effectively points out a critical area for improvement, making it 4. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about Theorem 1, specifically regarding the upper bound when there is a separate node with 0 neighbors. The reviewer acknowledges that the theorem seems correct but points out an exception that is not true. However, the comment does not provide any explicit guidance or suggestions on how the authors should address this issue or clarify the exception. The action is implicit, as the authors need to infer that they should provide an explanation for this exception, but it is vague because it lacks concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the upper bound when there is a separate node with 0 neighbors, and it asks for an explanation of this exception. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about Theorem 1, specifically regarding the upper bound when there is a separate node with 0 neighbors. The reviewer acknowledges that the theorem seems correct but points out an exception that is not true. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that the upper bound is not true. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about Theorem 1, specifically regarding the upper bound when there is a separate node with 0 neighbors. The reviewer acknowledges that the theorem seems correct but points out an exception that is not true. This feedback is 3 as it identifies a potential issue with the theorem and prompts the authors to consider and explain this exception. However, the comment lacks depth and does not provide specific guidance on how to address this exception or improve the theorem. To be more helpful, the comment could include suggestions on how to clarify or refine the theorem to account for this exception. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the statement about the training time reduction on page 5 should be deleted because it is not revisited in the Discussion section. The comment explicitly instructs the authors to delete the word \"Discussion,\" providing a clear and direct action. This makes the comment 5, as the authors know exactly what to do to address the feedback.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Pg.5\" and the specific phrase \"The training time reduction is less drastic than the parameter reduction because most gradients are still computed for early downsampling layers (Discussion).\" This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it points out that the statement about the training time reduction is not revisited in the Discussion section, and it suggests deleting the word \"Discussion\" to correct this. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement about the training time reduction on page 5 is not revisited in the Discussion section, suggesting that the word \"Discussion\" should be deleted. However, the comment does not provide any reasoning or evidence to support why this statement is incorrect or why it should be deleted. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that a statement about the training time reduction on page 5 is not revisited in the Discussion section. It suggests that the word \"Discussion\" should be deleted to correct this inconsistency. While the comment points out a potential error, it does not provide any additional context or explanation as to why this inconsistency matters or how it might impact the overall understanding of the paper. The feedback is 3 as it directs the authors to a specific area for improvement, but it lacks depth and actionable suggestions for enhancing the draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about whether the problem discussed in the paper applies to other downstream tasks or is specific to binding affinity prediction. It also asks for an explanation if the problem is specific to binding affinity prediction. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the question or what additional information should be included in the paper. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the applicability of the problem discussed in the paper to other downstream tasks or if it is specific to binding affinity prediction. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment lacks specificity as it does not provide details on what aspect of the problem needs clarification or why it is relevant. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification on whether the problem discussed in the paper applies to other downstream tasks or is specific to binding affinity prediction. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the applicability of the problem discussed in the paper to other downstream tasks or if it is specific to binding affinity prediction. This is a valid point that could lead to a deeper understanding of the paper\"s scope and relevance. However, the comment lacks specificity and does not provide any suggestions or guidance on how the authors might address this question or improve their draft. Without actionable feedback or additional context, the comment offers limited value to the authors in terms of improving their work. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a gap in the analysis regarding the detection of rumors generated by GPT, suggesting that further analysis or solutions should be proposed. It questions why GPTgenerated rumors are as difficult to detect as natural rumors, given that both are written by humans. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to conduct this analysis or propose solutions. The action is implicit and somewhat vague, as the authors are left to infer what kind of analysis or solutions might be appropriate. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the handling of rumors generated by GPT,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue by questioning the analysis of why GPTgenerated rumors are as difficult to detect as natural rumors, given that both are written by humans. The comment suggests that further analysis or solutions should be proposed to address this gap. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks analysis or solutions regarding the detection of rumors generated by GPT, specifically questioning why GPTgenerated rumors are as difficult to detect as natural rumors. The reviewer provides a logical reasoning by pointing out that both GPTgenerated and natural rumors are written by humans, and therefore, the difficulty in detection should be similar. However, the comment does not provide specific examples or references to support this claim, making it 3. The authors would need to further explore the reasoning and evidence themselves to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks analysis or solutions regarding the detection of rumors generated by GPT. It questions why GPTgenerated rumors are as difficult to detect as natural rumors, given that both are written by humans. This feedback is clear and actionable, as it prompts the authors to further explore and analyze this aspect of their work. By addressing this gap, the authors can enhance the comprehensiveness and depth of their analysis, which is crucial for improving the draft. However, the comment could be more helpful if it provided specific suggestions or examples of how to approach this analysis. Overall, the comment is 4, as it directs the authors to a critical area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "1", "actionability_rationale": "The review point critiques the technical contribution of the paper, specifically noting that Section 4 is more about heuristics than a formal and principled solution. However, it does not provide any explicit or implicit suggestions for improvement or guidance on how the authors might address this issue. The comment lacks actionable details, leaving the authors without a clear understanding of what changes, if any, are needed to enhance the technical contribution. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment critiques the technical contribution of the paper, specifically mentioning that Section 4 is more about heuristics than a formal and principled solution. However, it does not specify which part of Section 4 is being referred to, making it difficult for the authors to pinpoint the exact issue. The comment is specific in its critique of the technical contribution but lacks grounding as it does not identify the specific sections or elements being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the technical contribution is limited, specifically mentioning that Section 4 is more about heuristics than a formal and principled solution. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or references to what constitutes a formal and principled solution, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment critiques the technical contribution of the paper, specifically noting that Section 4 is more about heuristics than a formal and principled solution. While it identifies a potential weakness in the paper, it lacks actionable feedback or suggestions for improvement. The comment does not provide guidance on how the authors might enhance the technical contribution or address the critique, leaving the authors without a clear path for improvement. As a result, the comment is not particularly helpful, as it does not offer actionable insights or constructive feedback to assist the authors in enhancing their draft."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the font size in Figure 6 is a bit small, but it does not provide any explicit or implicit action for the authors to take. It lacks guidance on whether the font size should be increased, how much it should be increased, or if there are any specific considerations for the figure. Without any actionable advice or suggestions, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the font size being too small. This provides clear guidance on what needs to be addressed in the figure. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about the font size in Figure 6 being small. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely descriptive and does not necessitate any justification or evidence beyond the observation itself. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The comment points out a specific issue with the font size in Figure 6, noting that it is a bit small. While this is a factual observation, it does not provide any actionable feedback or suggestions for improvement. The comment lacks depth and does not offer guidance on how the authors might address this issue or why it is important to do so. As a result, the comment is 2, as it identifies a minor issue but does not assist the authors in making meaningful improvements to their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses regret that the probability mass function is not fully exploited in the paper, specifically mentioning the use of a quasiuniform distribution in MixBoost. The reviewer suggests that considering various probability mass functions could add depth to the experimental setting. However, the comment does not provide explicit guidance on how to implement this suggestion or what specific probability mass functions should be considered. The action is implicit and somewhat vague, as the authors are left to infer that they should explore different probability mass functions but without concrete steps or examples. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"probability mass function\" and \"MixBoost,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the probability mass function is not fully exploited and suggests considering various distributions to add depth to the experimental setting. However, the comment lacks specific examples or detailed guidance on how to implement this suggestion, making it somewhat specific. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point expresses regret that the probability mass function is not fully exploited in the paper, specifically mentioning the use of a quasiuniform distribution in MixBoost. The reviewer suggests that considering various probability mass functions could add depth to the experimental setting. However, the comment lacks specific examples or references to support the claim that considering different distributions would be beneficial. The suggestion is based on intuition and logical reasoning, but without detailed evidence or examples, it remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting that the probability mass function is not fully exploited in the paper. It points out that the quasiuniform distribution used in MixBoost is based on a single parameter, which could be expanded upon by considering different probability mass functions. The comment provides a logical rationale for why this exploration could add depth to the experimental setting, and it even hints at a possible reason why the quasiuniform distribution might be suitable. However, the comment could be more helpful if it offered specific examples of alternative probability mass functions or detailed guidance on how to implement this suggestion. Overall, the feedback is 3 as it highlights a potential area for enhancement but lacks comprehensive guidance for execution."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to include references to specific works, particularly [a], which uses supervised learning in QBF solving. It also suggests discussing connections between the paper and [a], which uses QBF to generalize SMT. The comment provides clear and concrete actions for the authors to take, such as discussing the relevance of [a] to their work and potentially incorporating it into their analysis. The explicit nature of the instructions and the concrete suggestions make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the references that are missing, allowing the authors to accurately identify the part of the paper that needs attention. It also specifies what is missing by suggesting the inclusion of references to [a], which uses supervised learning in QBF solving. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that certain references are relevant to the topic and suggests discussing connections with a specific reference, [a]. However, it does not provide detailed reasoning or examples to support why these references are relevant or how they should be integrated into the paper. The mention of [a] and its use of supervised learning in QBF solving is a vague reference that lacks specific details or context. Without further explanation or examples, the claim is difficult for the authors to understand and act upon, making it barely verifiable. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out missing references that are relevant to the topic. It suggests discussing connections with a particular reference, [a], which uses supervised learning in QBF solving. This feedback is clear and actionable, as it provides a concrete step for the authors to take to enhance the comprehensiveness and relevance of their work. However, the comment could be more helpful if it included a brief explanation of why these references are important or how they relate to the paper\"s content. Overall, the comment is 4 as it guides the authors toward a specific improvement, but it could be more comprehensive with additional context or explanation."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the comparison of computation cost or running time, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on whether the authors should include this comparison, how to conduct it, or what specific aspects to focus on. Without any actionable suggestions or details, the authors are left without a clear understanding of what steps to take in response to this comment. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the comparison of computation cost or running time, but it does not specify which part of the paper this comparison should be included in or what specific aspects need to be addressed. The authors cannot confidently determine which section of the paper this comment pertains to, making it weakly grounded. Additionally, the comment lacks specificity as it does not provide detailed guidance on what aspects of computation cost or running time should be compared or how this comparison should be presented. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point is a question seeking clarification on the comparison of computation cost or running time. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the comparison of computation cost or running time, which is a relevant aspect of the paper. However, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue or what specific comparisons should be made. Without actionable feedback or detailed advice, the authors are left without a clear understanding of how to improve their draft in this area. Therefore, the comment is 2, as it identifies a potential area for improvement but does not offer sufficient guidance to be actionable."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should clarify the goal of their paper in the introduction and provide examples that better demonstrate the need for interprocess communication. It also implies that the authors should focus on problems where the loss function does not decompose as the sum of sample losses and other ERMbased distributed algorithms, such as Hogwild. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors to make these changes, leaving some room for interpretation. The action is mostly concrete, as it specifies the types of examples to consider, but it is not fully explicit. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction and the second paragraph, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the examples provided do not convincingly demonstrate the need for interprocess communication, particularly regarding samplingbased Bayesian methods. The reviewer provides a specific suggestion to focus on problems where the loss function does not decompose as the sum of sample losses and other ERMbased distributed algorithms, such as Hogwild. This level of detail and guidance makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the introduction does not provide a clear picture of the paper\"s goal and suggests that the examples used do not convincingly demonstrate the need for interprocess communication. The reviewer provides a specific example of the second paragraph, where samplingbased Bayesian methods are mentioned as an example where the paper\"s results are irrelevant due to their embarrassingly parallel nature. The comment also suggests focusing on problems where the loss function does not decompose as the sum of sample losses and other ERMbased distributed algorithms. While the comment provides some reasoning and examples, it lacks detailed justification or references to support the claim fully. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed evidence or examples to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a lack of clarity in the introduction, specifically regarding the goal of the paper and the need for interprocess communication. It suggests that the examples provided do not convincingly demonstrate the relevance of the paper\"s results, particularly in the context of samplingbased Bayesian methods. The reviewer offers a specific suggestion to focus on problems where the loss function does not decompose as the sum of sample losses, which could provide a more relevant context for the paper. This feedback is clear and actionable, providing the authors with a direction to improve the clarity and relevance of their work. However, it could be more helpful if it included additional guidance on how to present the examples or the introduction more effectively. Overall, the comment is 4, as it effectively guides the authors toward enhancing the clarity and focus of their paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the privacy preservation of the approach compared to other federated learning methods and questions the relevance of using traffic signal control as an example. However, it does not provide explicit guidance or suggestions for the authors to address these concerns. The authors are left to infer that they need to clarify the privacy aspects of their approach and potentially reconsider the choice of example. While the comment implies an action, it lacks concrete details on how to implement these changes, making it 3.", "grounding_specificity_rationale": "The comment raises questions about the privacy preservation of the approach compared to other federated learning methods and questions the relevance of using traffic signal control as an example. However, it does not specify which part of the paper discusses these issues, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its critique but lacks grounding, as it does not clearly identify the parts of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions and critiques, such as questioning the privacy preservation of the approach and the relevance of using traffic signal control as an example. These are not claims that require verification, as they are factual questions or observations. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the privacy preservation of the approach compared to other federated learning methods and questions the relevance of using traffic signal control as an example. It challenges the authors to clarify the privacy aspects of their approach and suggests that the choice of example may not be the most appropriate. However, the comment lacks specific guidance or suggestions on how the authors might address these concerns or improve their draft. While it identifies areas for improvement, it does not provide actionable feedback or detailed advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a specific issue with the hyperlinks for footnotes 3 and 4, indicating that they do not seem to work. This is an explicit statement that clearly directs the authors to check and fix the hyperlinks. The action is concrete, as it specifies exactly what needs to be done to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"footnote 3 and 4,\" allowing the authors to accurately identify the specific parts of the paper being addressed. It is also specific because it clearly specifies the issue of broken hyperlinks, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about the functionality of hyperlinks in the paper, specifically noting that footnotes 3 and 4 do not seem to work. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is straightforward and identifies a specific issue with the hyperlinks for footnotes 3 and 4, indicating that they do not seem to work. This is a clear and actionable piece of feedback that the authors can address by checking and fixing the hyperlinks. However, the comment does not provide any additional context or suggestions on how to troubleshoot or prevent similar issues in the future. While it is a useful observation, it lacks depth and does not offer comprehensive guidance for improvement. Therefore, the comment is 3, as it provides a clear direction for action but lacks depth and comprehensive feedback."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests revising the discussion, particularly in the modeling section, to make it clearer. It provides a specific example of what needs to be improved, such as formalizing the architecture in section 2 and clarifying the role of Label Embeddings. While the comment implies that these changes are necessary, it does not explicitly instruct the authors to make these revisions. However, the concrete suggestions on what needs to be improved provide a clear direction for the authors to follow. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment suggests revising the discussion, particularly in the modeling section, to make it clearer. It provides a specific example of what needs to be improved, such as formalizing the architecture in section 2 and clarifying the role of Label Embeddings. This provides clear guidance on what needs to be addressed. However, the comment does not explicitly mention which part of the modeling section is unclear, making it weakly grounded. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests revising the discussion, particularly in the modeling section, to make it clearer. It provides a specific example of what needs to be improved, such as formalizing the architecture in section 2 and clarifying the role of Label Embeddings. The comment also points out a potential misunderstanding regarding the figure, suggesting that the Label Embeddings are external parameters rather than the output of the encoder. This feedback is 4 as it provides clear and specific suggestions for improvement, but it could be strengthened with additional examples or references to support the claim about the figure. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting revisions to the discussion, particularly in the modeling section. It identifies a lack of clarity in the current form of the discussion and offers a concrete example of what needs to be improved, such as formalizing the architecture in section 2. Additionally, it points out a potential misunderstanding regarding the role of Label Embeddings, suggesting that the figure is misleading. This feedback is clear and actionable, guiding the authors on how to enhance the clarity and accuracy of their work. However, the comment could be more helpful if it included additional suggestions or examples to further clarify the issues. Overall, the comment is 4 as it provides valuable insights for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the limitations of the model, specifically whether it is possible to train it towards attentionbased encoderdecoder training. While the comment implies that the authors should consider this possibility, it does not provide explicit guidance or suggestions on how to implement this change or what specific steps to take. The action is implicit and somewhat vague, as the authors need to infer that they should explore this possibility and determine how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the limitations of the model, specifically whether it is possible to train it towards attentionbased encoderdecoder training. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment where the model is discussed. This lack of grounding makes it difficult for the authors to identify the exact part of the paper being addressed. The comment is specific in its suggestion to explore attentionbased training, but without clear grounding, it is challenging for the authors to determine where to focus their attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the limitations of the model, specifically whether it is possible to train it towards attentionbased encoderdecoder training. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this change would be beneficial or how it might impact the model\"s performance. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the limitations of the model, specifically whether it is possible to train it towards attentionbased encoderdecoder training. While it identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance or suggestions on how the authors might explore this possibility or what specific changes could be made to the model. The comment is 3 as it prompts the authors to consider an alternative approach, but it does not offer actionable steps or detailed feedback to enhance the draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights that the mitigation methods affect the image generation capabilities of diffusion models, potentially leading to lower image quality. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how to address the issue, such as suggesting ways to mitigate the impact or improve the image quality. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions \"mitigation methods\" and their impact on \"image generation capabilities of diffusion models,\" but it does not specify which part of the paper discusses these methods or their effects. This makes it difficult for the authors to identify the exact section being addressed. Additionally, the comment lacks specificity regarding what aspects of image quality are affected or how the authors might address these issues. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that \"mitigation methods affect the image generation capabilities of diffusion models, which can lead to lower image quality.\" However, it does not provide any supporting evidence, examples, or references to substantiate this claim. Without specific details or examples, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the mitigation methods used in the paper, suggesting that they may affect the image generation capabilities of diffusion models, leading to lower image quality. However, the comment lacks specificity and does not provide any actionable advice or suggestions on how the authors might address this issue or improve the image quality. Without detailed guidance or examples, the authors are left without a clear understanding of what steps to take to resolve the problem. Therefore, the comment is 2, as it highlights a potential concern but does not offer meaningful direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that the pretrained visual model and target dataset might leak additional information, potentially skewing results and leading to issues of unfairness. However, the comment does not provide explicit guidance on how the authors should address these concerns or suggest specific actions to mitigate the potential issues. The feedback is implicit and lacks concrete details on how to implement changes, making it 3.", "grounding_specificity_rationale": "The comment raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. However, it does not specify which part of the paper discusses this issue or where the prior knowledge is incorporated, making it weakly grounded. The comment is specific in detailing the potential issue of unfairness due to the leakage of additional information from the pretrained visual model and target dataset. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that the pretrained visual model and target dataset might leak additional information, potentially skewing results and leading to issues of unfairness. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. The lack of concrete evidence or detailed explanation makes it difficult for the authors to understand and address the concern fully. Therefore, the comment is considered 2, as it provides a general concern but lacks sufficient detail for verification.", "helpfulness_rationale": "The review comment raises a valid concern about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It highlights a potential issue of unfairness resulting from the leakage of additional information from the pretrained visual model and target dataset. This feedback is 3 as it identifies a critical area that could impact the validity of the results, prompting the authors to consider potential biases and address them in their analysis. However, the comment lacks specific suggestions or guidance on how to mitigate these concerns, such as proposing alternative methods or controls to ensure fairness. Therefore, while it provides some insight, it could be more helpful with additional actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses surprise at the dominance of function words over content words in a Japanese sentence, but it does not provide any explicit or implicit actions for the authors to take. There is no suggestion for further analysis, clarification, or improvement. The comment lacks actionable guidance, leaving the authors without a clear understanding of what steps, if any, they should take in response to this observation. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by expressing surprise at the dominance of function words over content words in a Japanese sentence. However, the comment does not provide further details or suggestions on how to address this observation, making it specific. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point expresses surprise at the dominance of function words over content words in a Japanese sentence, but it does not provide any supporting evidence, reasoning, or references to justify this observation. The comment lacks specific examples or explanations that would help the authors understand the basis of the surprise or how this observation impacts the paper. As a result, the claim is 1, as it does not provide sufficient information for the authors to address the issue or improve their work.", "helpfulness_rationale": "The comment expresses surprise at the dominance of function words over content words in a Japanese sentence, but it does not provide any further context, analysis, or suggestions for improvement. It lacks depth and actionable feedback, leaving the authors without a clear understanding of the issue or how to address it. Without additional guidance or explanation, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it is rated as 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the FLOT cost matrix in Algorithm 1 is not defined, providing a clear and direct action for the authors to take. The comment specifies exactly what needs to be addressed, which is the definition of the FLOT cost matrix in Algorithm 1. This makes the action 5, as the authors know precisely what step to take to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of definition for the FLOT cost matrix. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual statement that the FLOT cost matrix in Algorithm 1 is not defined. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is clear and direct, pointing out a specific issue with the paper: the FLOT cost matrix in Algorithm 1 is not defined. This feedback is actionable as it identifies a clear gap in the paper that needs to be addressed. By specifying the exact element that is missing, the comment provides the authors with a concrete step to take to improve their draft. However, it could be more helpful if it suggested how the authors might define the FLOT cost matrix or provided examples of similar definitions in related work. Overall, the comment is 4 as it directs the authors to a specific area needing attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point raises a question about the convergence of the bound in Theorem 2, Eq. (30), when T goes to infinity. It compares this bound to a similar bound in [Grunewalder et al, 2010], noting that the latter converges to 0. The reviewer suggests that the first term in Eq. (30) converges to 0, but it is not trivial to derive that the second term also converges to 0. The comment explicitly asks the authors to prove this, providing a clear and concrete action for the authors to take. The reviewer also indicates a willingness to increase their score if the authors address the question satisfactorily. This level of detail and explicit request for proof make the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 2, Eq. (30)\" and \"Eq. (27),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a question about the convergence of the bound in Theorem 2, Eq. (30), and compares it to a similar bound in [Grunewalder et al, 2010]. The comment further specifies the issue by noting that the first term in Eq. (30) converges to 0 but that it is not trivial to derive that the second term also converges to 0. The reviewer explicitly asks the authors to prove this, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the convergence of the bound in Theorem 2, Eq. (30), when T goes to infinity. It compares this bound to a similar bound in [Grunewalder et al, 2010], noting that the latter converges to 0. The reviewer provides a logical reasoning by pointing out that the first term in Eq. (30) converges to 0, but it is not trivial to derive that the second term also converges to 0. The comment suggests that the authors should prove this, which is a clear and logical request. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is 4, as it provides a solid basis for the claim but lacks complete evidence or references.", "helpfulness_rationale": "The review comment raises a specific question about the convergence of the bound in Theorem 2, Eq. (30), when T goes to infinity. It compares this bound to a similar bound in [Grunewalder et al, 2010], noting that the latter converges to 0. The reviewer points out that while the first term in Eq. (30) converges to 0, it is not trivial to derive that the second term also converges to 0. This feedback is clear and actionable, as it prompts the authors to address a potential gap in their proof or analysis. The reviewer\"s willingness to increase their score if the authors can satisfactorily address the question adds a sense of urgency and importance to the feedback. Overall, the comment is 5 as it provides a specific area for improvement and offers a clear path for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises two main concerns: the lack of clarity in the specific definition of the sparsity of the residual term and the need for evidence supporting the sparsity assumption across various noisy cases. It also suggests that the authors should demonstrate the advantages of their assumptions compared to existing methods. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to clarify the definition of sparsity and provide evidence or examples to support the sparsity assumption, but the comment lacks concrete guidance on how to achieve this. Therefore, the comment is 3, as it highlights areas for improvement but does not provide detailed steps for execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"specific definition of the sparsity of the residual term,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of clarity in the definition and suggests that the authors provide evidence to support the sparsity assumption across various noisy cases. Additionally, it requests a comparison of the proposed method\"s assumptions with existing methods. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a claim about the lack of clarity in the specific definition of the sparsity of the residual term and suggests that the authors provide evidence to support the sparsity assumption across various noisy cases. However, the comment does not provide any specific reasoning, examples, or references to support these claims. The lack of detailed justification or evidence makes it difficult for the authors to understand and address the concerns effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the clarity of the definition of the sparsity of the residual term. It questions whether the residual term includes many zero elements and suggests that the authors provide evidence to support the sparsity assumption across various noisy cases. Additionally, the comment highlights the need to demonstrate the advantages of the proposed method\"s assumptions compared to existing methods. This feedback is clear and actionable, as it directs the authors to clarify their definition and provide evidence or examples to support their claims. However, it could be more helpful if it offered specific suggestions on how to present this evidence or comparison. Overall, the comment is 4, as it provides valuable guidance for improving the draft but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states that the term \"connectivity\" is misleading because it does not refer to structural connections between the brain and body. However, it does not provide any guidance on how the authors should address this issue or suggest alternative terminology. The action is explicit but lacks concrete details on how to implement the change, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the term \"connectivity,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the term \"connectivity,\" explaining that it does not refer to structural connections between the brain and body. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the term \"connectivity\" is misleading because it does not refer to structural connections between the brain and body. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is the case. Without additional context or explanation, the claim remains 1, as the authors may not fully understand the basis of the critique. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The comment identifies a specific issue with the term \"connectivity\" used in the paper, pointing out that it does not accurately reflect the structural connections between the brain and body. This feedback is 3 as it highlights a potential misinterpretation or misunderstanding in the paper. However, it lacks actionable suggestions or guidance on how the authors might address this issue or clarify the terminology. To be more helpful, the comment could suggest alternative terminology or provide examples of how to accurately describe the connections. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point indicates that the paper is not polished and lacks details in related work, experiments, and writing. However, it does not provide specific guidance on what details are missing or how the authors should address these issues. The comment refers to another section for more details, but this does not provide actionable advice within the current context. As a result, the authors are left without clear direction on how to improve their draft. Since the comment lacks explicit or implicit actions and is vague, it is 1.", "grounding_specificity_rationale": "The comment indicates that the paper is not polished and lacks details in related work, experiments, and writing. However, it does not specify which parts of the paper are lacking in detail or what specific aspects need improvement. Additionally, it does not provide any references or examples to support the claim, making it difficult for the authors to identify and address the issues. The comment lacks grounding as it does not point to specific sections or elements of the paper, and it is also not specific in detailing what needs to be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is not polished and lacks details in related work, experiments, and writing. However, it does not provide specific examples or evidence to support this claim, such as mentioning which aspects of the related work are missing or how the writing could be improved. The reference to \"Clarity, Quality, Novelty And Reproducibility\" does not provide additional context or details to substantiate the claim. As a result, the comment lacks verifiability, as it does not offer sufficient evidence or reasoning to justify the claim. Therefore, it is rated as 1.", "helpfulness_rationale": "The review comment indicates that the paper is not polished and lacks details in related work, experiments, and writing. However, it does not provide specific examples or guidance on what details are missing or how the authors could improve these areas. The reference to \"Clarity, Quality, Novelty And Reproducibility\" suggests that more detailed feedback can be found in those sections, but this does not help the authors directly within the context of the current comment. As a result, the comment is 3, as it identifies areas for improvement but lacks actionable guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should study the essentialness of using orthogonal matrices rather than just following the form that connects local and beyond local windows. It implies that the authors should investigate the significance of this choice, but it does not provide explicit instructions on how to conduct this study or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors can infer that they need to explore the impact of orthogonal matrices but are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Step 2\" and \"Step 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details what needs to be addressed, namely the study of the essentialness of using orthogonal matrices rather than just following the form that connects local and beyond local windows. This provides clear guidance on what the authors should focus on to improve their draft. Therefore, the comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point claims that \"Step 3 is the vital part that only orthogonal matrix weight can perform,\" suggesting that the essentialness of using orthogonal matrices should be studied. However, the comment lacks specific evidence or references to support this claim. It does not provide detailed reasoning or examples to justify why orthogonal matrices are crucial for Step 3 or how their use differs from other weight matrices. Without this supporting information, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the use of orthogonal matrices in the paper. It highlights that Step 3 is the vital part where only orthogonal matrix weights can perform, suggesting that this aspect should be studied further. The comment also points out that the essentialness of using orthogonal matrices is not presented, which is crucial for validating the significance of this choice. This feedback is clear and actionable, as it directs the authors to focus on a particular aspect of their work that could strengthen their argument. However, it could be more helpful if it provided specific suggestions on how to conduct this study or what aspects to explore. Overall, the comment is 4, as it effectively guides the authors toward a critical area for improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the accuracy drop in Figure 5 after a certain order of around 45, asking whether it is due to overfitting. While the comment implies that the authors should provide an explanation for this observation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to address the issue but are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the accuracy drop after a certain order and asks for an explanation, specifically whether it is due to overfitting. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the accuracy drop in Figure 5 after a certain order. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the accuracy drop in Figure 5 after a certain order, specifically asking whether it is due to overfitting. This is a relevant and important question that could help the authors understand the behavior of their model and potentially identify areas for improvement. However, the comment does not provide any suggestions or guidance on how the authors might investigate or address this issue. While it prompts the authors to consider a potential explanation, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the models and datasets used are too toylike and proposes specific alternatives, such as CIFAR100, ResNet 34 or 50, and ViTtiny or small, to improve the complexity and difficulty of the experiments. It also asks whether there is a foreseeable challenge to experiment on language tasks. While the comment provides explicit suggestions for improvement, it does not specify how the authors should address these suggestions or what specific changes should be made to the experiments. The action is concrete but stated implicitly, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the models and datasets, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear suggestions for improving the complexity and difficulty of the experiments by recommending specific models and datasets, such as CIFAR100, ResNet 34 or 50, and ViTtiny or small. Additionally, it raises a question about the feasibility of experimenting on language tasks, which further specifies the areas needing attention. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the models and datasets are \"too toylike\" and suggests specific alternatives, such as CIFAR100, ResNet 34 or 50, and ViTtiny or small. The reviewer provides a logical reasoning by stating that CIFAR100 is of similar size to CIFAR10 but more difficult, and that ResNet 34 or 50 would provide more compute power while being manageable by the authors\" machines. The suggestion to include ViTtiny or small is also supported by the reasoning that they have similar compute requirements as ResNet 18. However, the comment lacks specific references or examples to fully substantiate the claim, making it 3. The authors would need to consider the suggestions to fully understand the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the models and datasets used are too toylike and proposes alternative, more challenging datasets and models, such as CIFAR100, ResNet 34 or 50, and ViTtiny or small. It also raises a question about the feasibility of experimenting on language tasks, which could be an interesting direction for the authors to explore. By offering concrete suggestions and a clear path for improvement, the comment is 5 as it empowers the authors to enhance the complexity and relevance of their experiments. However, it could be more helpful if it included additional guidance on how to integrate these suggestions into the existing framework or addressed potential challenges in implementing them. Overall, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the absence of Vision Transformer (ViT) in the experiment, noting its importance as a stateoftheart (SOTA) model in image classification. It also questions whether the pruning strategy would be different in selfattention layers for larger datasets like ImageNet. While the comment highlights a potential gap in the experimental setup, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they should consider including ViT in their experiments and potentially explore its impact on larger datasets. However, the comment lacks concrete suggestions on how to implement these changes or what specific aspects of ViT or selfattention layers should be considered. Therefore, the comment is 3, as it identifies an area for improvement but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiment\" and the absence of Vision Transformer (ViT), which is an important stateoftheart (SOTA) model in image classification. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it raises a concern about the absence of ViT and questions whether the pruning strategy would be different in selfattention layers for larger datasets like ImageNet. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point raises a claim about the absence of Vision Transformer (ViT) in the experiment, noting its importance as a stateoftheart model in image classification. It also questions whether the pruning strategy would be different in selfattention layers for larger datasets like ImageNet. However, the comment lacks specific reasoning or evidence to support why the inclusion of ViT is necessary or how it would impact the pruning strategy. Without detailed justification or examples, the claim remains somewhat vague, making it difficult for the authors to fully understand and address the concern. Therefore, the comment is rated as 3, as it provides some basis for the claim but requires more detailed support to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a significant gap in the experimental setup by noting the absence of Vision Transformer (ViT), an important stateoftheart (SOTA) model in image classification. It questions whether the pruning strategy would be different in selfattention layers for larger datasets like ImageNet. This feedback is valuable as it highlights a potential limitation in the paper\"s scope and suggests a direction for future experiments. However, the comment could be more helpful if it provided specific guidance on how to incorporate ViT or what aspects of the pruning strategy might be affected by its inclusion. Despite this, the comment is 4 as it directs the authors\" attention to an important area for improvement in their experimental design."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the paper regarding the lack of reported metrics that demonstrate the efficiency of the proposed method compared to previous work. While the comment identifies a specific area for improvement, it does not provide explicit guidance on what metrics should be included or how to measure efficiency. The action is implicit and somewhat vague, as the authors need to infer that they should include metrics to demonstrate efficiency. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of reported metrics that demonstrate the efficiency of the proposed method compared to previous work. However, it does not specify which part of the paper discusses the advantages over previous work, making it weakly grounded. The comment is specific in pointing out the absence of efficiency metrics, which is a clear indication of what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks metrics to demonstrate the efficiency of the proposed method compared to previous work. However, it does not provide specific examples of what metrics should be included or how the authors could demonstrate efficiency. The comment lacks detailed reasoning or references to support the claim, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting that while the authors discuss the advantages of their method over previous work in terms of efficiency, they do not provide any metrics to substantiate these claims. This feedback is valuable as it highlights a critical area for improvement, specifically the need to include efficiency metrics to support the claims made in the paper. However, the comment could be more helpful if it suggested specific metrics or methods for measuring efficiency, which would provide the authors with more actionable guidance. Overall, the comment is 3 as it points out a key weakness in the paper but lacks depth in terms of actionable suggestions for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly requests more details on the statespace, actions, and the space where theta lies. It suggests that the authors should be precise in their descriptions rather than leaving the reader to guess. This feedback provides a clear and direct action for the authors to take, which is to provide more detailed information in the manuscript. The comment is explicit and concrete, giving the authors a specific task to complete. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L81,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the need for more details about the statespace, actions, and the space where theta lies. The comment provides a clear direction for improvement by suggesting that the authors should be precise in their descriptions. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a series of questions seeking clarification on specific aspects of the paper, such as the nature of the statespace, actions, and the space where theta lies. The reviewer acknowledges that they can guess the answers but suggests that the authors should be precise in their descriptions. This comment does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment is 3 as it identifies specific areas where the paper lacks clarity and suggests that the authors provide more detailed information. It points out the need for precision in describing the statespace, actions, and the space where theta lies. While the comment highlights important areas for improvement, it does not offer specific suggestions or guidance on how to enhance the clarity or what additional details should be included. The feedback is 3, as it prompts the authors to be more precise in their descriptions, but it could be more helpful with additional guidance or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point compares the effectiveness of the method on general reasoning tasks versus mathematic reasoning, suggesting that the method is less effective on general reasoning tasks. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how to improve the method\"s performance on general reasoning tasks or suggestions for further analysis or experimentation. As a result, the authors are left without any actionable steps to address the issue, making the comment 1.", "grounding_specificity_rationale": "The comment compares the effectiveness of the method on general reasoning tasks versus mathematic reasoning, but it does not specify which part of the paper this comparison is based on. The authors cannot confidently determine which sections or results are being referred to, making the comment weakly grounded. Additionally, the comment lacks specificity as it does not provide details on what aspects of the method are ineffective or how they could be improved. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the method is less effective on general reasoning tasks compared to mathematical reasoning. However, it does not provide any supporting evidence, examples, or references to substantiate this claim. Without specific examples or data to illustrate the effectiveness difference, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a potential limitation of the method, noting that it is less effective on general reasoning tasks compared to mathematical reasoning. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve the method\"s performance on general reasoning tasks. Without actionable feedback or detailed insights, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a specific issue with the proof technique in Appendix A, noting that it relies on a special case where a contradiction arises as matrix norms approach infinity. It acknowledges that the authors have already addressed this issue in Section 3, where they mention that normalizing the input makes the results from Theorem 1 inapplicable. However, the comment does not provide any explicit guidance or suggestions on how the authors should address this issue or improve their proof technique. The action is implicit and vague, as the authors are left to infer that they need to clarify or revise their proof technique, but without concrete steps or suggestions, the comment lacks actionability. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix A\" and \"Section 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the proof technique, noting the reliance on a special case where a contradiction arises as matrix norms approach infinity. The comment further specifies that this issue is acknowledged by the authors in Section 3, where they mention that normalizing the input makes the results from Theorem 1 inapplicable. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proof technique in Appendix A relies on a special case where a contradiction arises as matrix norms approach infinity. It acknowledges that the authors have addressed this issue in Section 3, where they mention that normalizing the input makes the results from Theorem 1 inapplicable. The comment provides a logical explanation of the issue and references the authors\" acknowledgment of it, which is a clear and specific justification for the claim. Therefore, the comment is 4, as it provides a logical reasoning and references the authors\" own acknowledgment of the issue, but it could be strengthened with more detailed examples or references to support the claim fully.", "helpfulness_rationale": "The review comment identifies a specific issue with the proof technique in Appendix A, noting that it relies on a special case where a contradiction arises as matrix norms approach infinity. It acknowledges that the authors have already addressed this issue in Section 3, where they mention that normalizing the input makes the results from Theorem 1 inapplicable. While the comment points out a potential weakness in the proof technique, it does not provide any suggestions or guidance on how the authors might address this issue or improve their proof. The feedback is 3 as it highlights a specific area for improvement, but it lacks actionable advice, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests replacing \"t\" with the size of T in the histogram intersection kernel for clarity. It implies that allowing \"t\" to be arbitrary does not provide any added value. While the comment explicitly states the action of replacing \"t\" with the size of T, it does not provide detailed guidance on how to implement this change or why it would improve clarity. The authors know what needs to be done but may not fully understand the rationale behind the suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"histogram intersection kernel,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests replacing \"t\" with the size of T for clarity, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests replacing \"t\" with the size of T in the histogram intersection kernel for clarity. The reviewer provides a logical reasoning by stating that allowing \"t\" to be arbitrary does not add value. However, the comment lacks specific examples or references to support why this change would improve clarity or how it would impact the kernel\"s functionality. This makes the claim 3, as the authors would need to infer the potential benefits of the suggested change based on the reviewer\"s reasoning.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the clarity of the paper by recommending a change in notation. It suggests replacing \"t\" with the size of T in the histogram intersection kernel, which could enhance the readability and understanding of the kernel\"s operation. This feedback is clear and actionable, offering a concrete step the authors can take to improve their draft. However, the comment could be more helpful if it explained why allowing \"t\" to be arbitrary is not beneficial or how the suggested change would enhance clarity. Overall, the comment is 4 as it provides a clear direction for improvement but could be more comprehensive with additional context or rationale."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the adaptation capacity of the proposed visual memory, specifically questioning whether it can accommodate new concepts effectively. The reviewer provides a rationale for this concern, suggesting that while DINO representations may contain rich geometric information, the adaptation capacity might be limited for concepts where class labels correlate more with semantics rather than geometry. However, the comment does not provide explicit guidance or suggestions on how the authors might address this concern or improve the adaptation capacity. The action is implicit and somewhat vague, as the authors are left to infer that they should explore or address the issue of semantic versus geometric concepts in their adaptation capacity. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the adaptation capacity of the proposed visual memory, specifically questioning whether it can accommodate new concepts effectively. It provides a rationale for this concern, suggesting that while DINO representations may contain rich geometric information, the adaptation capacity might be limited for concepts where class labels correlate more with semantics rather than geometry. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the discussion of the visual memory or adaptation capacity, but the exact section is not explicitly mentioned. The comment is specific in detailing the concern about the adaptation capacity and the potential limitations, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the adaptation capacity of the proposed visual memory, specifically questioning whether it can accommodate new concepts effectively. The reviewer provides a logical reasoning by suggesting that while DINO representations may contain rich geometric information, the adaptation capacity might be limited for concepts where class labels correlate more with semantics rather than geometry. This reasoning is based on a logical inference and common knowledge about the nature of DINO representations. However, the comment could be strengthened by providing specific examples or references to support the claim about the limitations of adaptation capacity for semantic concepts. Therefore, the comment is 3, as it provides a logical basis but lacks detailed evidence or examples.", "helpfulness_rationale": "The review comment raises a valid concern about the adaptation capacity of the proposed visual memory, specifically questioning whether it can effectively accommodate new concepts. The reviewer provides a logical reasoning by suggesting that while DINO representations may contain rich geometric information, the adaptation capacity might be limited for concepts where class labels correlate more with semantics rather than geometry. This feedback is 3 as it highlights a potential limitation in the paper and prompts the authors to consider this aspect further. However, the comment could be more helpful if it offered specific suggestions or examples on how to address this concern or improve the adaptation capacity. Overall, the comment provides a valuable insight but lacks actionable guidance, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point provides a list of specific corrections and clarifications that need to be made in the paper. It explicitly mentions the need to give EF and D2 transcription norms, corrects grammatical errors, and points out inconsistencies in the formatting of numbers and links. These actions are clear and concrete, giving the authors precise guidance on how to improve their draft. The comment is 5 as it provides explicit instructions on what needs to be corrected, ensuring that the authors know exactly how to apply the feedback.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines, figures, and tables, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides detailed corrections and clarifications, such as correcting grammatical errors, formatting inconsistencies, and providing missing transcription norms. This level of detail guides the authors on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point consists of factual corrections and clarifications, such as grammatical errors, formatting inconsistencies, and missing transcription norms. It does not contain subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a list of specific corrections and clarifications that need to be made in the paper. It identifies grammatical errors, formatting inconsistencies, and missing information, such as transcription norms. By pointing out these issues, the comment offers clear and actionable feedback that can help the authors improve the accuracy and clarity of their draft. However, while it addresses specific errors, it does not provide broader insights or suggestions for improving the overall content or structure of the paper. Therefore, the comment is 4, as it effectively guides the authors in making precise corrections but lacks depth in terms of comprehensive feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment provides explicit suggestions for improving the clarity of the notation and figures. It specifies that M and N should be defined and suggests spelling out F.L.T.R in Figure 4. Additionally, it recommends improving the legibility of Figure 1 by making the text larger and crossreferencing notation with figures. These actions are concrete and directly guide the authors on how to enhance the clarity and readability of their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"notation,\" \"M and N,\" \"figure 4,\" and \"figure 1.\" This allows the authors to accurately identify the sections being addressed. The comment is also specific because it provides clear suggestions for improvement, such as defining M and N, spelling out F.L.T.R in figure 4, improving the legibility of figure 1, and crossreferencing notation with figures. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements and suggestions for improvement, such as clarifying notation, improving figure legibility, and crossreferencing notation with figures. It does not contain subjective opinions, claims, or suggestions that require verification or justification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback on several aspects of the paper that need improvement. It identifies issues with notation, suggesting that M and N are used without definition, and recommends spelling out F.L.T.R in Figure 4. Additionally, it points out that the text in Figure 1 is too small to be legible and suggests crossreferencing notation with figures. These suggestions are clear and direct, offering the authors concrete steps to enhance the clarity and readability of their draft. However, the comment could be more helpful if it provided additional context or rationale for why these changes are necessary. Overall, the feedback is 4 as it guides the authors toward improving the clarity and presentation of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential source of confusion in Algorithm 1, specifically regarding the use of $p$ to denote the phase mixing probability and the dummy variable in the inner loop in Phase 2. While the comment identifies a specific issue, it does not provide explicit guidance on how to address this confusion or suggest alternative terminology or explanations. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the notation or terminology, but they are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of potential confusion regarding the use of $p$ to denote the phase mixing probability and the dummy variable in the inner loop in Phase 2. This provides clear guidance on what needs to be addressed to improve the clarity of the algorithm description. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about potential confusion in the notation used in Algorithm 1. It does not express an opinion, judgment, or suggestion that requires verification. It is purely descriptive and does not contain any claims or subjective statements. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a potential source of confusion in the notation used in Algorithm 1, specifically regarding the use of $p$ to denote both the phase mixing probability and the dummy variable in the inner loop in Phase 2. This feedback is 3 as it points out a specific area where the authors might need to clarify their notation or terminology to improve the clarity of their algorithm description. However, the comment does not provide specific suggestions or guidance on how to resolve this issue, such as recommending alternative terminology or explaining the rationale behind the current notation. While it highlights a potential problem, it lacks depth and actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides explicit suggestions for improvement, such as including a more detailed (e.g., mathematical) formulation in the appendix and suggesting changes to the figure to better align with the main contribution of the paper. The reviewer offers specific actions, like adding more text labels to the figure, which provides concrete guidance for the authors. This level of detail and explicitness makes the comment 5, as it clearly outlines what the authors need to do to enhance their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the highlevel description and the figure, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides detailed feedback on how to improve the figure, suggesting the addition of more text labels and reworking it to better align with the main contribution of the paper. The comment also suggests including a more detailed (e.g., mathematical) formulation in the appendix. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the highlevel description is helpful for understanding the approach intuitively but lacks a more detailed (e.g., mathematical) formulation. It also critiques the figure, stating that it is too abstract and does not align well with the main contribution of the paper. The reviewer provides specific suggestions for improvement, such as adding more text labels and reworking the figure to better depict the WiC task. While the comment offers constructive feedback, it lacks detailed reasoning or references to support the claim that the figure is confusing or misaligned. Therefore, the comment is 3, as it provides a basis for improvement but requires more detailed justification or examples to fully substantiate the claims.", "helpfulness_rationale": "The review comment provides actionable feedback by suggesting that the paper\"s highlevel description is helpful for understanding the approach intuitively but could benefit from a more detailed (e.g., mathematical) formulation, possibly included in the appendix. It also critiques the figure, noting that it is too abstract and does not align well with the main contribution of the paper. The reviewer offers specific suggestions for improving the figure, such as adding more text labels and reworking it to better depict the WiC task. This feedback is clear and provides concrete steps for the authors to enhance their draft, making it 4. However, it could be more comprehensive by addressing other aspects of the paper, such as the methodology or results. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that including additional benchmarking tasks outside of AitW would be beneficial. However, it does not specify which specific tasks should be included or how they would contribute to the paper. The action is implicit and lacks concrete details, making it somewhat vague. The authors can infer that they should consider adding more benchmarking tasks, but without specific guidance, it may be challenging to determine which tasks to include and how to integrate them into the paper. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including additional benchmarking tasks outside of AitW, but it does not specify which part of the paper this suggestion pertains to. The authors cannot confidently determine whether this suggestion relates to the methodology, results, or discussion sections. Additionally, the comment lacks specificity regarding which additional benchmarking tasks should be included or why they are necessary. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that including additional benchmarking tasks outside of AitW would be beneficial. However, it does not provide any specific reasoning, examples, or references to support why these additional tasks are necessary or how they would enhance the paper. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the suggestion, rendering the claim 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The comment suggests that including additional benchmarking tasks outside of AitW would be beneficial. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on which specific tasks should be included or how they might enhance the paper. The feedback is somewhat vague, as it does not offer actionable steps for the authors to take. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises several questions and requests for additional information regarding the experiments. It explicitly asks for the comparison results of YOSO with linformer on iterationwise convergence and for an explanation of the performance difference between linformer and YOSO in downstream tasks like SST2. These requests are clear and direct, providing the authors with specific actions to take to improve their draft. The comment is 5 as it offers concrete steps for the authors to follow, ensuring they know exactly what information to include or address in their paper.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing in the pretraining experiment part, namely the steps and ppl of linformer with YOSO, and it requests a comparison of YOSO with linformer on iterationwise convergence. Additionally, it asks for an explanation of the performance difference between linformer and YOSO in downstream tasks like SST2. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point raises several questions and requests for additional information regarding the experiments. It asks for the comparison results of YOSO with linformer on iterationwise convergence and for an explanation of the performance difference between linformer and YOSO in downstream tasks like SST2. These requests are logical and reasonable, but they do not provide specific evidence or references to support the need for these comparisons. The comment lacks detailed reasoning or examples to fully substantiate the claims, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies specific gaps in the experimental section of the paper, particularly regarding the comparison between YOSO and linformer. It points out the absence of steps and ppl of linformer with YOSO in Figure 4, which is a critical piece of information for understanding the experiment. Additionally, it requests a comparison of YOSO with linformer on iterationwise convergence and an explanation of the performance difference in downstream tasks like SST2. These requests are clear and actionable, providing the authors with specific areas to address and improve their draft. The comment is 4 as it offers detailed guidance on how to enhance the experimental section, but it could be more comprehensive by suggesting ways to analyze or interpret the results. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises questions about the policy gradient in Equation 6 and its relationship to the optimal solution in Equation 5. It suggests that the authors clarify these points to ensure clarity. Additionally, it points out a minor grammatical error in Line 78 and a potential typo in Line 132. While the comment identifies specific areas for improvement, it does not provide detailed guidance on how to address the questions or correct the errors. The actions are explicit but somewhat vague, as the authors know what needs to be clarified but may not be entirely sure of the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific equations (Eq. 6 and Eq. 5) and lines (78 and 132), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be clarified regarding the policy gradient and its relationship to the optimal solution, as well as a minor grammatical error and a potential typo. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a series of questions and suggestions, such as clarifying the relationship between equations and correcting grammatical errors. These are factual statements or requests for clarification, not claims that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a mix of factual observations and suggestions for improvement. It raises questions about the relationship between the policy gradient in Equation 6 and the optimal solution in Equation 5, suggesting that the authors clarify this point. Additionally, it points out a minor grammatical error and a potential typo, which are factual observations that could be corrected. While the comment identifies specific areas for improvement, it lacks depth and does not offer comprehensive guidance or suggestions for enhancing the clarity or content of the paper. Therefore, it is 3, as it provides some direction but not a complete roadmap for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether it is possible to assume a general Gaussian distribution instead of an isotropic Gaussian in the proposed algorithm. It also asks for clarification on the difference between the two distributions. While the comment implies that the authors should consider this assumption, it does not explicitly instruct them to do so or provide guidance on how to address the question. The action is implicit and somewhat vague, as the authors can infer that they need to consider the assumption but are not given specific instructions on how to proceed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the possibility of assuming a general Gaussian distribution instead of an isotropic Gaussian in the proposed algorithm and asks for clarification on the difference between the two distributions. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for clarification on the difference between the distributions, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question seeking clarification on the use of a general Gaussian distribution instead of an isotropic Gaussian in the proposed algorithm. It does not express an opinion, judgment, or suggestion that requires verification. The comment is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the possibility of assuming a general Gaussian distribution instead of an isotropic Gaussian in the proposed algorithm. It also seeks clarification on the difference between the two distributions. While the comment identifies a potential area for improvement or clarification, it lacks depth and does not provide specific guidance or suggestions on how the authors might address this issue. The feedback is 3 as it prompts the authors to consider an alternative assumption, but it does not offer actionable steps or detailed advice on how to proceed. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should discuss the limitations of freezing the partitioning in the first iteration, which is a risky choice that makes strong assumptions about the coverage of the initial data. This feedback provides a clear and direct action for the authors to take, which is to address the limitations of this approach. The comment is explicit and concrete, as it specifies exactly what the authors need to do to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 192,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with freezing the partitioning in the first iteration, noting that it makes strong assumptions about the coverage of the initial data. The comment further suggests that the authors should discuss the limitations of this approach. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that freezing the partitioning in the first iteration is a risky choice that makes strong assumptions about the coverage of the initial data. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this choice is risky or what specific assumptions are being made. Without additional context or explanation, the authors may find it challenging to understand and address the concern. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the methodology, specifically the choice to freeze the partitioning in the first iteration. It points out that this approach makes strong assumptions about the coverage of the initial data, which could be a risky choice. The comment suggests that the authors should discuss the limitations of this approach, providing a clear and actionable piece of feedback. By addressing this concern, the authors can enhance the robustness and transparency of their methodology. However, the comment could be more helpful if it offered specific suggestions on how to discuss these limitations or alternative approaches to consider. Overall, the feedback is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point questions the intent of Section 5.2, implying that the authors should clarify the purpose of this section. However, it does not provide any guidance on how to address this question or what specific aspects of the section need clarification. The action is implicit and vague, as the authors are left to infer that they need to provide more context or explanation for the section. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment questions the intent of Section 5.2, indicating that the authors should clarify the purpose of this section. However, it does not specify what aspect of the section is unclear or what specific information is missing. This makes it difficult for the authors to pinpoint the exact part of the paper that needs revision. The comment is 1 as it does not identify a specific section, table, or figure, and it is not specific because it lacks detailed guidance on what needs to be addressed. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification about the intent of Section 5.2. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The comment questions the intent of Section 5.2, indicating that the authors should clarify the purpose of this section. While it identifies a potential area of confusion, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue. The feedback is vague and does not offer actionable steps for improvement, leaving the authors without a clear path forward. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the need for clarification on several aspects of the approach, particularly regarding how the approach allows knowledge about objects to interact with knowledge about verbs to overcome reporting bias. However, it does not provide explicit instructions or concrete suggestions on how to address these issues. The comment implies that the authors should clarify the approach, but it lacks specific guidance on what aspects need clarification or how to improve the explanation. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"many aspects of the approach\" that need clarification, allowing the authors to identify the parts of the paper that require attention. It also specifies the concern about understanding how the approach allows knowledge about objects to interact with knowledge about verbs to overcome reporting bias. This provides clear guidance on what needs to be clarified. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \"many aspects of the approach need to be clarified\" and specifically mentions the lack of understanding regarding how the approach allows knowledge about objects to interact with knowledge about verbs to overcome reporting bias. However, the comment does not provide specific examples or detailed reasoning to support this claim. The reference to \"detailed comments below\" suggests that more information might be provided, but without access to those comments, the current claim is not 5. Therefore, the comment is categorized as 2, as it provides some indication of the issue but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that many aspects of the approach need clarification. It specifically highlights the lack of understanding regarding how the approach allows knowledge about objects to interact with knowledge about verbs to overcome reporting bias. This is a critical point that the authors need to address to improve the clarity and comprehensibility of their work. However, the comment does not provide specific suggestions or guidance on how to clarify these aspects, leaving the authors with a general direction but without detailed steps to take. While it points out a significant weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to clarify the threat model by defining the assumed threat model more explicitly, specifying the attacker\"s level of access, capabilities, and the defender\"s available resources. It also suggests including this information in a dedicated section to enhance clarity, particularly regarding the assumed whitebox access to the victim model. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what needs to be done to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"threat model,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the assumed threat model, including the attacker\"s level of access, capabilities, and the defender\"s available resources. Additionally, it suggests including this information in a dedicated section to enhance clarity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the threat model needs further clarification, specifically asking for the authors to define the assumed threat model more explicitly. It provides a clear and logical reasoning for this request, as it highlights the importance of specifying the attacker\"s level of access, capabilities, and the defender\"s available resources. This feedback is wellsupported by the need for clarity in the threat model, making it 4. However, the comment could be strengthened by providing examples or references to similar threat models for comparison, which would make it 5. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the need for further clarification of the threat model. It provides a clear and actionable suggestion by asking the authors to define the assumed threat model more explicitly, specifying the attacker\"s level of access, capabilities, and the defender\"s available resources. This feedback is valuable as it guides the authors on how to enhance the clarity and comprehensiveness of their threat model, which is crucial for understanding the context and limitations of their work. However, the comment could be more helpful if it included examples or references to similar threat models for comparison. Overall, the comment is 4 as it provides clear guidance for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the feasibility of setting a reasonable classimbalanced task in the context of fewshot learning, where there are only a few examples for each class. It explicitly asks the authors to explain this with concrete details. This provides a clear and direct action for the authors to take, ensuring they understand what is expected of them. The comment is explicit and concrete, giving the authors a specific task to address. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the phrase \"sampling classimbalanced tasks,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the feasibility of setting a reasonable classimbalanced task in the context of fewshot learning and asks for concrete details on how to achieve this. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the feasibility of setting a classimbalanced task in the context of fewshot learning, where there are only a few examples for each class. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely a request for clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a pertinent question about the feasibility of setting a classimbalanced task in the context of fewshot learning, where there are only a few examples for each class. It challenges the authors to explain how they would approach this issue with concrete details. This feedback is clear and actionable, as it prompts the authors to address a specific concern that could impact the validity of their work. By asking for clarification, the comment encourages the authors to provide additional information or justification, which could enhance the comprehensiveness and robustness of their draft. However, the comment could be more helpful if it offered suggestions or examples on how to address this issue. Overall, the comment is 4, as it provides a clear direction for improvement but lacks comprehensive guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the authors do not provide sufficient details on how the ground truth of sensitivity is achieved, specifically regarding the process of pruning. While the comment highlights a gap in the explanation, it does not provide explicit guidance on what additional information should be included or how the authors should address this issue. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more detailed explanations about the pruning process. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 238239, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of detailed explanation on how the ground truth of sensitivity is achieved, particularly regarding the process of pruning. The comment provides a clear direction for the authors to improve their draft by detailing the pruning process. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors do not provide sufficient details on how the ground truth of sensitivity is achieved, specifically regarding the process of pruning. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or explanation, the authors may find it challenging to understand the exact nature of the issue or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks detailed explanation, specifically regarding the process of achieving the ground truth of sensitivity. It points out that the authors mention \"pruning\" but do not provide details on how this is done. This feedback is clear and actionable, as it directs the authors to include more detailed information on the methodology used to estimate sensitivity. However, the comment could be more helpful if it suggested specific aspects of the pruning process that need to be explained or provided examples of how other papers have addressed similar issues. Overall, the comment is 4 as it guides the authors toward improving the clarity and comprehensiveness of their draft."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that certain parts of the text could be written more clearly. It provides specific examples by asking for an explicit explanation of what a proper rotation matrix is in line 97 and what is meant by the problem of the matrix being non positive semidefinite in lines 105106. These requests are explicit and provide clear guidance on what the authors need to clarify in their draft. The feedback is actionable because it specifies exactly what needs to be addressed, making it easy for the authors to implement the changes. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that some parts of the text could be written more clearly, and it provides specific examples by asking for an explanation of what a proper rotation matrix is in line 97 and what is meant by the problem of the matrix being non positive semidefinite in lines 105106. While the comment does not explicitly mention which sections of the paper these examples are from, the authors can infer that it relates to the sections where these specific terms are discussed. This provides weak grounding as the authors cannot confidently determine the exact sections without further context. However, the comment is specific in detailing what needs to be clarified, making it weakly grounded but specific. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point consists of factual statements requesting clarification on specific terms or concepts in the text. It does not contain subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies specific areas where the text could be improved by suggesting that certain parts are not clear. It provides examples by asking for an explicit explanation of what a proper rotation matrix is in line 97 and what is meant by the problem of the matrix being non positive semidefinite in lines 105106. This feedback is clear and actionable, as it directs the authors to clarify specific concepts that may be confusing to readers. By addressing these points, the authors can enhance the clarity and comprehensibility of their draft. However, the comment could be more helpful if it offered suggestions on how to improve the clarity or provided additional context for these concepts. Overall, the comment is 4, as it effectively guides the authors toward improving the clarity of their text."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should consider not calling the \"g\" activation function but rather a binary operator, similar to the approach taken by Cohen and Shashua in 2016. The comment provides a specific reference to a similar approach, which could help the authors understand the reasoning behind the suggestion. However, it does not explicitly instruct the authors to make this change or provide detailed guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer that they should consider this change and how to implement it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 111,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a change in terminology, recommending not to call \"g\" an activation function but rather a binary operator, and provides a reference to a similar approach by Cohen and Shashua (2016). This level of detail guides the authors on what specific change to make and why, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests a change in terminology, recommending not to call \"g\" an activation function but rather a binary operator, similar to the approach by Cohen and Shashua (2016). The comment provides a specific reference to external work, which supports the claim and offers a clear rationale for the suggested change. This level of detail and reference makes the claim 4, as it provides a solid basis for the authors to consider the suggestion. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced work to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the terminology used in the paper, recommending that the authors not call \"g\" an activation function but rather a binary operator. It references a similar approach by Cohen and Shashua (2016), which adds context and justification for the suggestion. This feedback is clear and actionable, offering the authors a concrete way to enhance the clarity and precision of their work. However, the comment could be more helpful if it explained why this change is important or how it might impact the paper\"s overall structure or understanding. Despite this, the comment is 4 as it provides a direct and constructive suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors consider shrinking the captions of Fig. 1 and Fig. 2 to leave more space for the methods or related work sections. This is a clear and direct action for the authors to take, providing them with a specific way to improve their draft. The comment is concrete in its guidance, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 1 and Fig. 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the captions, suggesting that they overlap with the content and recommending shrinking them to leave more space for the methods or related work sections. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the captions of Fig. 1 and Fig. 2 have large overlaps with the content, and it recommends shrinking the captions to leave more space for the methods or related work sections. This is a factual observation and a suggestion for improvement, but it does not contain any subjective claims, opinions, or judgments that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the captions of Figures 1 and 2, noting that they have large overlaps with the content. It suggests a potential solution by recommending that the authors consider shrinking the captions to leave more space for the methods or related work sections. This feedback is clear and actionable, providing the authors with a concrete way to improve the presentation of their figures. However, the comment could be more helpful if it included additional suggestions or guidance on how to effectively reduce the overlap without compromising the clarity of the captions. Overall, the comment is 4 as it directs the authors toward a specific improvement, but it could be more comprehensive with further guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the omission of Vidgen et al., 2021 from Table 2, suggesting that it might be similar to the dataset presented in the work. The reviewer questions why this dataset is not used as a potential benchmark for evaluation, particularly in the context of investigating the role of context in hate detection. While the comment implies that the authors should consider including Vidgen et al., 2021 as a benchmark, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should consider adding this dataset as a benchmark. However, the comment provides a clear rationale for why this addition might be beneficial, which makes it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the omission of Vidgen et al., 2021 from the table and suggesting that it might be similar to the dataset presented in the work. The comment further provides a rationale for why this dataset should be considered as a potential benchmark for evaluation, particularly in the context of investigating the role of context in hate detection. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point raises a claim about the omission of Vidgen et al., 2021 from Table 2, suggesting that it might be similar to the dataset presented in the work. The reviewer questions why this dataset is not used as a potential benchmark for evaluation, particularly in the context of investigating the role of context in hate detection. While the comment provides a logical reasoning for the omission, it lacks specific references or detailed comparisons to support the claim that Vidgen et al., 2021 is similar to the dataset presented. This makes the claim 3, as the authors would need to further investigate the similarities and differences between the datasets to fully address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 2, noting the omission of Vidgen et al., 2021, which might be similar to the dataset presented in the work. It questions why this dataset is not used as a potential benchmark for evaluation, particularly in the context of investigating the role of context in hate detection. This feedback is clear and actionable, as it prompts the authors to consider including Vidgen et al., 2021 as a benchmark, providing a specific reason for its relevance. By addressing this point, the authors can enhance the comprehensiveness and robustness of their evaluation. However, the comment could be more helpful if it provided additional context or suggestions on how to integrate this dataset effectively. Overall, the comment is 4, as it directs the authors to a specific area for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the proposed approach, suggesting that it is merely learning a surrogate model for solving linear/linearized systems of equations arising in FEM. It highlights that the approach still requires careful selection of basis functions and meshes and the assembly of stiffness matrices, which are specific to the present work and rely heavily on FEniCS. The comment also notes that current operator learning methods may not achieve the same accuracy as specialized numerical solvers but are more universal and do not need to be adapted to specific PDEs. However, the comment does not provide explicit guidance or suggestions for the authors to address these issues or improve their approach. The feedback lacks actionable details, leaving the authors uncertain about how to respond or make improvements. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment critiques the proposed approach, suggesting that it is merely learning a surrogate model for solving linear/linearized systems of equations arising in FEM. It highlights the need for careful selection of basis functions and meshes and the assembly of stiffness matrices, which are specific to the present work and rely heavily on FEniCS. The comment also compares current operator learning methods to specialized numerical solvers, noting their limitations and advantages. However, the comment does not explicitly mention which part of the paper this critique is based on, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing the critique of the approach, but without explicit grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point critiques the proposed approach, suggesting that it is merely learning a surrogate model for solving linear/linearized systems of equations arising in FEM. It highlights the need for careful selection of basis functions and meshes and the assembly of stiffness matrices, which are specific to the present work and rely heavily on FEniCS. The comment also compares current operator learning methods to specialized numerical solvers, noting their limitations and advantages. While the comment provides a logical critique and comparison, it lacks specific examples or references to support the claim fully. This makes the claim 3, as it requires more detailed evidence or examples to fully substantiate the critique.", "helpfulness_rationale": "The review comment critiques the proposed approach, suggesting that it is merely learning a surrogate model for solving linear/linearized systems of equations arising in FEM. It highlights the need for careful selection of basis functions and meshes and the assembly of stiffness matrices, which are specific to the present work and rely heavily on FEniCS. The comment also compares current operator learning methods to specialized numerical solvers, noting their limitations and advantages. While the comment identifies a potential weakness in the approach, it lacks specific suggestions or guidance on how the authors might address these issues or improve their work. The feedback is 3 as it provides insight into the limitations of the approach, but it could be more beneficial with actionable advice or examples of how to enhance the methodology. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "1", "actionability_rationale": "The review point acknowledges the difficulty of controlling multiple aspects of variation with fully realistic datasets and agrees with the authors\" judgment regarding the lack of immediate societal impact. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue of controlling variation or how to enhance the societal impact of the work. As a result, the comment lacks any actionable advice, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment acknowledges the difficulty of controlling multiple aspects of variation with fully realistic datasets and agrees with the authors\" judgment regarding the lack of immediate societal impact. However, it does not specify which part of the paper this observation is based on, nor does it provide any guidance or suggestions for improvement. Without explicit references to sections, figures, or specific aspects of the paper, the authors cannot confidently determine which parts need attention or how to address the issues raised. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point consists of two separate claims: the first is about the difficulty of controlling multiple aspects of variation with fully realistic datasets, and the second is about the lack of immediate societal impact. The first claim is supported by logical reasoning, as it explains the challenge of controlling variation with fully realistic datasets. The second claim is based on the authors\" judgment, which is not further elaborated or substantiated with evidence or references. Therefore, the comment is 3 for the first claim and 1 for the second, as it lacks specific reasoning or references to support the judgment about societal impact. Overall, the comment is rated as 2.", "helpfulness_rationale": "The review comment acknowledges the difficulty of controlling multiple aspects of variation with fully realistic datasets, which is a valid observation. It also agrees with the authors\" judgment regarding the lack of immediate societal impact. However, the comment does not provide any actionable feedback or suggestions for improvement. It lacks depth and does not offer any guidance on how the authors might address the challenges of controlling variation or enhance the societal impact of their work. As a result, the comment is 1, as it does not provide the authors with any actionable insights or direction for improving their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the evaluation metric should be mentioned in the text to better understand the scale of the improvement and for comparability with the results reported in the paper. It also points out the specific expression used in Fern\u00e1ndezGonz\u00e1lez and G\u00f3mezRodr\u00edguez (2020) to clarify the evaluation metric. This feedback is explicit and provides concrete guidance on what needs to be done, making it 5. The authors know exactly what needs to be added to improve the clarity and comparability of their results. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lines (078079 / Line 08) where the issue is located, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the evaluation metric should be mentioned to better understand the scale of the improvement and for comparability with the results reported in the paper. Additionally, it provides a specific example of the expression used in Fern\u00e1ndezGonz\u00e1lez and G\u00f3mezRodr\u00edguez (2020) to clarify the evaluation metric. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the evaluation metric should be mentioned to better understand the scale of the improvement and for comparability with the results reported in the paper. It references a specific expression used in Fern\u00e1ndezGonz\u00e1lez and G\u00f3mezRodr\u00edguez (2020) to clarify the evaluation metric. This provides a clear and specific reference to support the claim, making the comment 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how the evaluation metric impacts the results. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the evaluation metric should be mentioned in the text to better understand the scale of the improvement and for comparability with the results reported in the paper. It references a specific expression used in Fern\u00e1ndezGonz\u00e1lez and G\u00f3mezRodr\u00edguez (2020) to clarify the evaluation metric, which is a concrete example that can guide the authors in improving the clarity and comprehensibility of their results. This feedback is clear and detailed, offering the authors a direct path to enhance the clarity and comparability of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a discrepancy between the stated standard deviation of the noise in the simulation study and the observations in the plot, suggesting that the noise level is not as high as claimed. It implies that the authors should study the behavior of the model under higher noise levels. While the comment identifies an issue and suggests a potential action, it does not provide specific guidance on how to implement this study or what specific noise levels to consider. The action is explicit but somewhat vague, as the authors know they need to investigate higher noise levels but may not be entirely sure of the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"simulation study\" and the \"plot,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a discrepancy between the stated standard deviation of the noise and the observations in the plot, suggesting that the noise level is not as high as claimed. The comment further suggests studying the behavior of the model under higher noise levels. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the standard deviation of the noise in the simulation study is not as high as stated, based on observations in the plot compared to the true trajectories. This claim is 3 as it provides a logical reasoning by comparing the observations with the stated noise level. However, the comment lacks specific examples or references to support the claim fully, such as detailed comparisons or data points that demonstrate the discrepancy. This makes the claim 3, as it requires additional evidence or explanation to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a discrepancy between the stated standard deviation of the noise in the simulation study and the observations in the plot, suggesting that the noise level is not as high as claimed. It provides a specific observation that the authors can use to improve their draft by suggesting that they study the behavior of the model under higher noise levels. This feedback is clear and actionable, offering a concrete direction for the authors to enhance their analysis and presentation of results. However, it could be more helpful if it included suggestions on how to implement this study or what specific noise levels to consider. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their work."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment raises a concern about the bounds having o(1) terms and improving over previously known results for arbitrarily long inputs. However, it does not provide specific guidance on how the authors should address this issue or what steps they should take to improve the applicability of their approach. The comment lacks explicit instructions or concrete suggestions, leaving the authors uncertain about how to respond to this feedback. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the bounds and their improvement over previously known results for arbitrarily long inputs. However, it does not specify which part of the paper discusses these bounds or where the authors should focus their attention to address this issue. The comment lacks grounding as it does not mention specific sections, figures, or tables, making it difficult for the authors to pinpoint the exact part of the paper being addressed. Additionally, while it raises a concern about the applicability of the approach, it does not provide specific guidance on how to address this limitation. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a concern about the bounds having o(1) terms and improving over previously known results for arbitrarily long inputs. However, it does not provide specific examples or references to support this claim, nor does it offer detailed reasoning or evidence to substantiate the assertion that these improvements would limit the applications of the approach. The lack of supporting information makes it difficult for the authors to understand and address the concern effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the bounds having o(1) terms and improving over previously known results for arbitrarily long inputs. It suggests that this improvement might limit the applications of the approach. However, the comment lacks specificity and does not provide actionable guidance or suggestions on how the authors might address this concern or improve the applicability of their approach. Without detailed feedback or recommendations, the authors are left without a clear path to enhance their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises an interesting question about how DVP performs on videos of different lengths. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should investigate this further, include additional analysis, or address this issue in their paper. The comment lacks actionable details, leaving the authors uncertain about how to proceed. Therefore, it is 1.", "grounding_specificity_rationale": "The comment raises an interesting question about how DVP performs on videos of different lengths. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspect of DVP\"s performance on differentlength videos is being questioned. Without clear grounding or specificity, the authors are left without a clear understanding of what needs to be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification about how DVP performs on videos of different lengths. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises an interesting question about how DVP performs on videos of different lengths. However, it lacks specificity and does not provide any actionable feedback or suggestions for the authors to address this question. Without guidance on how to explore or investigate this aspect further, the comment does not offer much value in terms of helping the authors improve their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses confusion about whether the paper targets singletoken or multitoken cloze queries and notes that a clear clarification is not provided until the conclusion. However, it does not explicitly instruct the authors to clarify this point or suggest how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the target of their study but are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment expresses confusion about whether the paper targets singletoken or multitoken cloze queries and notes that a clear clarification is not provided until the conclusion. However, it does not specify which part of the paper lacks this clarification, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in identifying the issue of clarity regarding the target of the study but lacks grounding as it does not explicitly mention a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses confusion about whether the paper targets singletoken or multitoken cloze queries and notes that a clear clarification is not provided until the conclusion. However, the comment does not provide any specific reasoning, examples, or references to support the claim of confusion or the need for clarification. Without additional context or explanation, the authors may find it challenging to understand the basis of the reviewer\"s confusion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the target of the paper, whether it focuses on singletoken or multitoken cloze queries. It notes that a clear clarification is not provided until the conclusion, which is a relevant observation that could help the authors improve the clarity and readability of their paper. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as recommending a clearer explanation or restructuring the paper to clarify the target. While it highlights an area for improvement, the feedback lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to evaluate the approximation error by calculating the actual KLdivergence and checking whether it approaches zero. This is a clear and direct action that the authors can follow to address the concern. The comment provides a specific method for evaluation, making it 5. Therefore, this comment is rated as a 5 on the actionability scale.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the proposed training objective, namely the omission of the KLdivergence term in equation (3). The comment further suggests evaluating the approximation error by calculating the actual KLdivergence and checking whether it approaches zero. This provides clear guidance on what needs to be addressed. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed training objective has ignored the KLdivergence term in equation (3) and suggests evaluating the approximation error by calculating the actual KLdivergence. This is a logical claim that requires verification through calculations or experiments to determine the accuracy of the approximation. However, the comment does not provide specific examples or references to support the claim, making it 3. The authors would need to conduct additional analysis to fully substantiate the claim, which is a minor gap in the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed training objective, noting that the KLdivergence term in equation (3) has been ignored. It suggests that the authors evaluate the approximation error by calculating the actual KLdivergence and checking whether it approaches zero. This feedback is clear and actionable, providing the authors with a concrete step to take to address the concern. By following this suggestion, the authors can gain a better understanding of the approximation error and potentially improve their methodology. However, the comment could be more helpful if it provided additional context or examples on how to calculate the KLdivergence or interpret the results. Overall, the comment is 4 as it offers a clear path for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that Section 2 lacks a clear connection with the methodology section and that the theoretical analysis is simplistic and closely related to a specific reference, [1]. However, it does not provide explicit guidance on how the authors should address these issues or improve the connection between the sections. The comment implies that the authors should enhance the theoretical analysis and its connection to the methodology, but it lacks concrete steps or suggestions on how to achieve this. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the limited connection with the methodology section and the simplistic nature of the theoretical analysis, which is closely related to a specific reference, [1]. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Section 2 lacks a clear connection with the methodology section and that the theoretical analysis is simplistic and closely related to a specific reference, [1]. However, the comment does not provide any further explanation or examples to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or specific examples makes the claim 1, as the authors are left without a clear understanding of what needs to be addressed or improved. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper: the lack of connection between Section 2 and the methodology section, and the simplistic nature of the theoretical analysis, which is closely related to a specific reference. While the comment highlights areas for improvement, it does not provide detailed guidance or suggestions on how the authors might address these issues. The feedback is 3 as it points out weaknesses, but it lacks actionable advice or examples to help the authors make meaningful improvements. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that it would be interesting to further discuss or specify the situations where the losses are particularly helpful, such as for specular areas. While the comment implies that the authors should provide additional discussion or examples, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that it would be interesting to further discuss or specify the situations where the losses are particularly helpful, such as for specular areas. However, it does not specify which part of the paper this discussion should be added to, making it weakly grounded. The comment is specific in suggesting a particular area of interest, namely the situations where the losses are beneficial. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it would be interesting to further discuss or specify the situations where the losses are particularly helpful, such as for specular areas. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this discussion would be beneficial or how it could enhance the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that it would be interesting to further discuss or specify the situations where the losses are particularly helpful, such as for specular areas. This feedback identifies a potential area for improvement by encouraging the authors to provide more context or examples regarding the applicability of their losses. However, the comment lacks specific guidance or suggestions on how to address this issue, such as recommending additional experiments or analyses. While it points out a relevant area for enhancement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of clarity regarding the major contributions of the paper. It suggests that merely analyzing previous work does not constitute a contribution. However, the comment does not provide specific guidance on how the authors should clarify their contributions or what additional contributions they could make. The action is implicit and vague, as the authors are left to infer that they need to clarify their contributions but are not given concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the lack of clarity regarding the major contributions of the paper, specifically questioning whether analyzing previous work constitutes a contribution. However, it does not specify which part of the paper this issue pertains to, such as a particular section or discussion, making it weakly grounded. The comment is specific in its critique of the contributions, but without clear grounding, the authors may struggle to identify the exact part of the paper that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that \"analyzing previous work does not constitute as a contribution,\" but it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, namely the lack of clarity regarding its major contributions. It points out that merely analyzing previous work does not constitute a contribution, which is a valid critique. However, the comment does not provide specific suggestions or guidance on how the authors might clarify or enhance their contributions. Without actionable advice, the authors are left with a general understanding of the problem but without a clear path to improvement. Therefore, the comment is 3, as it highlights an important area for improvement but lacks depth and specificity in its feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the difficulty in reproducing the results and asks whether the code will be made publicly available. While the comment implies that the authors should make their code publicly available, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should make their code accessible. However, the comment does provide a clear direction on what needs to be done to address the issue of reproducibility. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the difficulty in reproducing the results and asks whether the code will be made publicly available. However, it does not specify which part of the paper this issue pertains to, such as a specific section or experiment where reproducibility is an issue. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. The comment is specific in its request for code availability, but without clear grounding, it is challenging for the authors to address the issue effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the difficulty in reproducing the results and asks whether the code will be made publicly available. This is a factual statement without any subjective claims or opinions, as it does not suggest changes or express judgments about the paper. It is purely a request for information, making it a normal statement. Therefore, the label \"No\" is appropriate.", "helpfulness_rationale": "The review comment raises a concern about the difficulty in reproducing the results, which is an important issue for the authors to address. It also asks whether the code will be made publicly available, which is a relevant question for transparency and reproducibility. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address the issue of reproducibility or make their code available. While it identifies a critical area for improvement, the feedback is somewhat vague and incomplete, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests extending the protected feature \"A\" to a vector form, implying that it currently represents a single attribute. However, it does not provide explicit instructions on how to implement this suggestion or what specific attributes should be included in the vector form. The action is implicit and somewhat vague, as the authors are left to infer the details of the proposed change. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests extending the protected feature \"A\" to a vector form, implying that it currently represents a single attribute. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where the protected feature is discussed. Without explicit references, the authors may find it challenging to determine the exact part of the paper that needs revision. The comment is specific in suggesting a potential enhancement but lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests extending the protected feature \"A\" to a vector form, implying that it currently represents a single attribute. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this extension would be beneficial or how it might improve the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests extending the protected feature \"A\" to a vector form, implying that it currently represents a single attribute. This feedback is 3 as it provides a potential direction for enhancing the paper by expanding the scope of the protected feature. However, the comment lacks specificity and does not offer detailed guidance on how to implement this suggestion or what specific attributes should be included in the vector form. While it points out a possible improvement, it does not fully support the authors in making the necessary changes. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point raises several questions and suggestions regarding the notation and computation details in the paper. It explicitly asks for clarification on how the vectors are represented and suggests denoting this explicitly. Additionally, it inquires about the normalization of vectors and the method used for computing nearest neighbors. These questions and suggestions provide clear and concrete actions for the authors to take, such as clarifying the notation and sharing computation details. The feedback is explicit and provides specific guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 223,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear suggestions for clarification, such as denoting the vector representations of words, asking about normalization, and specifying the method used for computing nearest neighbors. The comment details what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of questions and suggestions for clarification, such as denoting the vector representations of words and specifying the method used for computing nearest neighbors. It does not contain subjective opinions, judgments, or claims that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by questioning the notation and computation details in the paper. It explicitly asks for clarification on how the vectors are represented and suggests denoting this explicitly. Additionally, it inquires about the normalization of vectors and the method used for computing nearest neighbors, which are important details that can impact the understanding and reproducibility of the work. By addressing these questions, the authors can enhance the clarity and comprehensiveness of their draft. The comment is clear and constructive, making it 5 for the authors to improve their manuscript. Therefore, it aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to check Figure 2, Line 433, and Line 468 for inconsistencies in the use of periods and commas at the end of equations. This provides a clear and direct action for the authors to take, ensuring consistency in their draft. The comment is specific and provides concrete guidance on what needs to be corrected, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, including Figure 2, Line 433, and Line 468, allowing the authors to accurately identify the sections being addressed. It is also specific because it clearly specifies the issue of inconsistent punctuation at the end of equations, providing a clear direction for correction. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the consistency of punctuation in equations. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting inconsistencies in the punctuation used at the end of equations. It provides clear and actionable feedback by instructing the authors to check Figure 2, Line 433, and Line 468 for these inconsistencies. This feedback is valuable as it directs the authors to a specific area of the paper that needs attention, ensuring consistency and clarity in the presentation of equations. However, the comment could be more helpful if it explained why consistency in punctuation is important or provided examples of how this inconsistency might affect the reader\"s understanding. Overall, the comment is 4 as it provides clear guidance for improvement, but it could be more comprehensive with additional context or explanation."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point claims that $kNNECD$ is very similar to $kNNMT$, which limits the technical contribution of the paper. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how the authors might address this issue or improve the paper\"s contribution. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, it is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment claims that $kNNECD$ is very similar to $kNNMT$, which limits the technical contribution of the paper. However, it does not specify which part of the paper discusses these methods or how they are similar, making it difficult for the authors to identify the exact sections that need attention. Additionally, the comment lacks specificity regarding what aspects of the paper are considered similar or how this similarity affects the technical contribution. Without explicit references to sections or detailed explanations, the authors cannot effectively address the feedback. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that $kNNECD$ is very similar to $kNNMT$, which limits the technical contribution of the paper. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without specific details or comparisons, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that $kNNECD$ is very similar to $kNNMT$, which limits the technical contribution of the paper. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or differentiate their work. Without actionable feedback or constructive advice, the comment lacks depth and does not offer much value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point raises a question about the origin of the figures in Figure 1, asking whether they are generated from real experiments or artificially. It also suggests that if the figures are artificially generated, the authors should conduct realworld experiments to support the phenomenon observed in the figures. This feedback is explicit in its request for clarification and suggests a specific action for the authors to take, which is to conduct realworld experiments. The comment provides clear guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by questioning the origin of the figures and suggesting that realworld experiments should be conducted to support the phenomenon observed in the figures. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the origin of the figures in Figure 1, asking whether they are generated from real experiments or artificially. It suggests that if the figures are artificially generated, the authors should conduct realworld experiments to support the phenomenon observed in the figures. This is a request for clarification and additional evidence, which does not contain a subjective claim or opinion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a critical question about the origin of the figures in Figure 1, asking whether they are generated from real experiments or artificially. It suggests that if the figures are artificially generated, the authors should conduct realworld experiments to support the phenomenon observed in the figures. This feedback is 5 as it provides a clear direction for the authors to enhance the credibility and validity of their work by conducting realworld experiments. By addressing this feedback, the authors can significantly strengthen their paper\"s empirical foundation. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges that the assumption among classes is not a common practice but notes that the formulation or definition in the manuscript is somewhat trivial. It suggests that the highlight lies in the optimization and theoretical property analysis, from which conclusions or insights can be gained. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to improve the manuscript or what specific aspects of the optimization or theoretical property analysis should be emphasized. Without actionable advice or suggestions, the authors are left without a clear path for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the assumption among classes, which is not a common practice, and mentions the formulation or definition in the manuscript. However, it does not specify which part of the paper discusses this assumption or formulation, making it weakly grounded. The comment is specific in noting that the highlight lies in optimization and theoretical property analysis, suggesting that insights can be gained from these aspects. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the assumption among classes is not a common practice, but it acknowledges that the formulation or definition in the manuscript is somewhat trivial. The comment suggests that the highlight lies in the optimization and theoretical property analysis, from which conclusions or insights can be gained. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the optimization and theoretical property analysis are significant. Without these elements, the claim remains 3, as the authors may need to infer the importance of these aspects based on the general statement. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges that the assumption among classes is not a common practice but notes that the formulation or definition in the manuscript is somewhat trivial. It suggests that the highlight lies in the optimization and theoretical property analysis, from which some conclusions or insights can be gained. While the comment identifies a potential area of interest, it lacks specific guidance or suggestions on how the authors might enhance their analysis or present their findings more effectively. The feedback is 3 as it points out a potential area of interest, but it does not provide actionable advice for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the statistical significance of the evaluation results reported in Table 1, noting that only three trials were conducted for each case. It suggests that this lack of statistical significance may be the reason why the deviations are often reported as zero. The comment also critiques the statement about performance being \"at least two standard deviation better than the next best baseline,\" arguing that this claim is not supported by the data. While the comment identifies a potential issue with the statistical significance of the results and the validity of certain claims, it does not provide explicit guidance on how the authors should address these concerns. The action is implicit and somewhat vague, as the authors are left to infer that they should conduct more trials or provide additional statistical analysis to support their claims. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the evaluation results, noting the lack of statistical significance due to only three trials per case and the resulting zero deviations. The comment further critiques the statement about performance being \"at least two standard deviation better than the next best baseline,\" explaining why this claim is not supported by the data. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point claims that the evaluation results in Table 1 are not statistically significant due to the limited number of trials (three per case). It argues that this lack of statistical significance is the reason why deviations are often reported as zero and why statements about performance being \"at least two standard deviation better than the next best baseline\" are not supported. The comment provides a logical reasoning for the claim, which is based on the understanding of statistical significance and the need for more trials to establish meaningful deviations. However, it could be strengthened by providing specific examples or references to support the claim further. Overall, the comment is 4, as it provides a clear rationale but lacks detailed evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant issue with the statistical significance of the evaluation results reported in Table 1, noting that only three trials were conducted for each case. It explains that this lack of statistical significance is the reason why deviations are often reported as zero, which undermines the validity of claims about performance being \"at least two standard deviation better than the next best baseline.\" The comment provides a clear and actionable insight into the statistical limitations of the evaluation, prompting the authors to reconsider their methodology or analysis. By pointing out this issue, the comment empowers the authors to make necessary improvements to their draft, making it 4. However, it could be more helpful if it offered specific suggestions on how to address the issue, such as recommending additional trials or statistical tests. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a specific issue with the feature comparison in the paper, noting that it is shallow and missing two relevant papers. However, it does not provide explicit guidance on how to address this issue or suggest which specific features should be compared or how to incorporate the missing papers. The action is implicit, as the authors can infer that they need to expand the feature comparison to include these papers, but the comment lacks concrete details on how to implement this change. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment identifies a specific issue with the feature comparison in the paper, noting that it is shallow and missing two relevant papers. However, it does not specify which part of the paper this feature comparison is discussed in, nor does it provide details on which specific features are missing or how they should be incorporated. This makes it difficult for the authors to pinpoint the exact sections that need revision. The comment is weakly grounded as it does not specify the part of the paper being addressed, and it is not specific because it lacks detailed guidance on what needs to be addressed. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the feature comparison in the paper is shallow and missing two relevant papers. However, it does not provide specific details or references to these two papers, making it difficult for the authors to understand which features are missing or how the comparison could be improved. The lack of detailed justification or examples makes the claim 3, as the authors would need to invest effort to identify the missing papers and their relevance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the feature comparison in the paper, noting that it is shallow and missing two relevant papers. This feedback is clear and actionable, as it directs the authors to expand their feature comparison to include these two papers, which could significantly enhance the depth and comprehensiveness of their analysis. However, the comment could be more helpful if it provided specific suggestions on which features to compare or how to incorporate the missing papers into the discussion. Despite this, the feedback is 4 as it guides the authors toward a meaningful improvement in their draft. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the effectiveness of the multiview clustering approach, specifically questioning the usefulness of the other views when the paraphrase similarity view consistently outperforms them. The reviewer suggests that a more detailed analysis of the differences and similarities between these views is needed to draw solid conclusions. While the comment implies that the authors should conduct a more thorough analysis, it does not provide explicit instructions on how to achieve this or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors can infer that they need to conduct a more detailed analysis but are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"multiview clustering approach\" and the \"paraphrase similarity view,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the effectiveness of the other views and suggesting that a more detailed analysis is needed to understand the differences and similarities between these views. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the effectiveness of the multiview clustering approach, specifically the usefulness of the other views when the paraphrase similarity view consistently outperforms them. The reviewer provides a specific example of how the different views help in clustering paraphrases of the word \"slip,\" but notes that there is no further analysis of how these views differ. This suggests that the claim is based on a lack of detailed analysis, which is a valid observation. However, the comment lacks specific references or detailed reasoning to fully substantiate the claim, making it 3. The authors would need to conduct additional analysis to address the concern, but the comment provides a clear direction for improvement. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the effectiveness of the multiview clustering approach, particularly questioning the usefulness of the other views when the paraphrase similarity view consistently outperforms them. It suggests that a more detailed analysis is needed to understand the differences and similarities between these views, which is a clear and actionable piece of feedback. By highlighting the lack of analysis and suggesting a direction for improvement, the comment provides valuable guidance for the authors to enhance their draft. However, it could be more helpful if it offered specific suggestions on how to conduct this analysis or what aspects to focus on. Overall, the comment is 4 as it directs the authors to a critical area needing further exploration."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide more detailed experimental results on Wikipedia regarding the impact of model size on performance. This is an explicit request for additional data, which is clear and actionable. The comment also references a recent paper by Ni et al. that supports the claim that scaling laws apply to dense retrieval models, providing a concrete basis for the suggestion. This level of detail and reference makes the action 5.", "grounding_specificity_rationale": "The comment suggests that the authors should provide more detailed experimental results on Wikipedia regarding the impact of model size on performance. It references a recent paper by Ni et al. that shows the scaling law applies to dense retrieval models. However, the comment does not specify which part of the paper this issue pertains to, such as a specific section or experiment. While the authors might infer that it relates to the experimental results or methodology, the lack of explicit grounding makes it weakly grounded. The comment is specific in its request for more detailed experimental results and references an external work, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that increasing the model size should not hurt performance, as recent work by Ni et al. shows that the scaling law applies to dense retrieval models. The reviewer provides a specific reference to Ni et al., which supports the claim that scaling laws are applicable. This reference provides a logical basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced work to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential contradiction in the paper regarding the impact of model size on performance. It suggests that the authors should provide more detailed experimental results on Wikipedia to support their claim that increasing model size can hurt performance. The comment references a recent paper by Ni et al. that shows the scaling law applies to dense retrieval models, which provides a logical basis for the suggestion. This feedback is clear and actionable, as it directs the authors to address a specific issue in their experimental results and provides a reference to support their argument. However, the comment could be more helpful if it included specific suggestions on how to present the additional results or what aspects to focus on. Overall, the comment is 4, as it guides the authors toward improving their draft with concrete feedback."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point identifies several specific issues with the presentation quality of the paper, such as the use of \"\" in tables, the lack of informative \"Dataset\" columns, and the management of Figure 3 and Table 2. However, it does not provide explicit guidance on how to address these issues or suggest specific actions for improvement. The authors can infer that they need to improve the presentation quality, but the comment lacks concrete details on how to do so. Therefore, the comment is 3, as it identifies areas for improvement but does not provide detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific aspects of the paper, such as Figures 1&2, tables with a \"\" for the method, the \"Dataset\" columns in the tables, the management of Figure 3 and Table 2, and a \"*\" appearing in Table 1 with no indication of meaning. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it details what aspects of the presentation quality are considered weaknesses, providing clear guidance on what needs to be improved. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point identifies specific issues with the presentation quality of the paper, such as the use of \"\" in tables, the lack of informative \"Dataset\" columns, and the management of Figure 3 and Table 2. However, it does not provide detailed reasoning or examples to support why these aspects are considered weaknesses or how they impact the overall quality of the paper. The comment lacks specific references or evidence to substantiate the claim, making it difficult for the authors to understand and address the issues effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail and justification.", "helpfulness_rationale": "The review comment identifies specific issues with the presentation quality of the paper, such as the use of \"\" in tables, the lack of informative \"Dataset\" columns, and the management of Figure 3 and Table 2. It also points out the appearance of a \"*\" in Table 1 without explanation. While the comment highlights areas for improvement, it does not provide detailed guidance or suggestions on how to address these issues. The feedback is 3 as it directs the authors\" attention to specific aspects of the presentation that need attention, but it lacks actionable advice or examples of how to improve these areas. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include related experiments that demonstrate the effectiveness of the \"information axis\" tool. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on what kind of experiments should be conducted or how to implement them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should include related experiments that demonstrate the effectiveness of the \"information axis\" tool. However, it does not specify which part of the paper this suggestion pertains to, such as the conclusion or a specific section where the tool is discussed. This lack of explicit reference makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the inclusion of related experiments, but without clear grounding, it remains 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the paper uses much analysis to justify the effectiveness of the \"information axis\" tool but lacks related experiments demonstrating its utility. The comment is based on the reviewer\"s observation that the conclusion does not include such experiments. However, it does not provide specific examples or references to support the claim that the analysis is insufficient or that related experiments are necessary. The lack of detailed justification or evidence makes the claim 3, as the authors would need to infer the need for additional experiments based on the reviewer\"s suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential gap in the paper by suggesting that the authors should include related experiments to demonstrate the effectiveness of the \"information axis\" tool. This feedback is 3 as it points out an area where the paper could be strengthened by providing empirical evidence to support the claims made about the tool. However, the comment lacks specificity and does not provide detailed guidance on what kind of experiments should be conducted or how they should be designed. To be more helpful, the comment could include suggestions on the types of experiments or data that would be most relevant to the tool\"s application. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a significant issue with the organization and clarity of the proofs, noting that they are difficult to follow and rigorously check for correctness. It specifically mentions Lemma 3 and questions whether the result holds for any polynomial function. This feedback provides a clear and explicit action for the authors to improve the organization and clarity of their proofs, as well as to address the specific concern about Lemma 3. The comment is 5 as it identifies a specific area for improvement and provides a concrete question to consider, giving the authors clear guidance on how to enhance their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lemma 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue of the proof\"s organization and clarity, providing a concrete example with the question about Lemma 3. This level of detail helps the authors understand what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point claims that the proof is not well organized and difficult to follow, providing a specific example with Lemma 3. The reviewer questions whether the result holds for any polynomial function, which is a logical and relevant concern. However, the comment lacks detailed reasoning or examples to fully substantiate the claim about the overall organization and clarity of the proofs. While it provides a specific question, it does not offer a comprehensive analysis or evidence to support the broader claim. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed justification or examples to be 5.", "helpfulness_rationale": "The review comment identifies a significant issue with the organization and clarity of the proofs, noting that they are difficult to follow and rigorously check for correctness. It provides a specific example by questioning whether the result in Lemma 3 holds for any polynomial function, which is a concrete and actionable suggestion for the authors to address. This feedback is clear and provides a clear direction for improvement, making it 4. However, it could be more helpful if it offered additional guidance on how to improve the organization or clarity of the proofs. Therefore, the comment is rated as 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the scope of the study, specifically whether it is limited to considering only one truck and one drone. It suggests that extending the study to multiple trucks and drones might be more interesting and practical. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or extend their work. The action is implicit and somewhat vague, as the authors are left to infer that they should consider a more extensive setting but without concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the scope of the study, specifically whether it is limited to considering only one truck and one drone. However, it does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The comment is specific in suggesting that extending the study to multiple trucks and drones might be more interesting and practical. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the scope of the study, noting that it only considers one truck and one drone. It suggests that extending the study to multiple trucks and drones might be more interesting and practical. However, the comment lacks specific reasoning or evidence to support why this extension would be more interesting or practical. Without additional context or examples, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is classified as 3.", "helpfulness_rationale": "The review comment points out a limitation in the study, noting that it only considers one truck and one drone. It suggests that extending the study to multiple trucks and drones might be more interesting and practical. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address this limitation or expand their study. The feedback is 3 as it highlights a gap in the scope of the study, but it does not provide actionable steps for the authors to take. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point claims that the proposed approach to pretraining has limited novelty because it follows the strategies used in ELECTRA. However, it does not provide any specific guidance or suggestions on how the authors could address this issue or improve the novelty of their approach. The comment lacks actionable details, such as recommending alternative strategies or suggesting ways to differentiate the approach from ELECTRA. As a result, the authors are left without a clear understanding of what steps to take to enhance the novelty of their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the novelty of the proposed approach to pretraining, stating that it \"more or less just follows the strategies used in ELECTRA.\" However, it does not specify which part of the paper this critique pertains to, such as a specific section or methodology discussion. Without explicit references, the authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity regarding what aspects of the approach are similar to ELECTRA or how the authors could differentiate their work. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the proposed approach to pretraining has limited novelty because it \"more or less just follows the strategies used in ELECTRA.\" However, the comment does not provide any specific examples, comparisons, or references to support this claim. Without detailed evidence or reasoning, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment points out that the proposed approach to pretraining has limited novelty because it follows the strategies used in ELECTRA. However, it does not provide any specific examples or details on how the approach is similar to ELECTRA or how it could be improved to enhance novelty. Without actionable suggestions or constructive feedback, the comment lacks depth and does not offer much value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the motivation for using the Newton algorithm in Section 4 is lacking and proposes that a bisecting line search would suffice for a 1dimensional line search on a convex function. It questions the impact of quadratic convergence on the algorithm\"s runtime and suggests conducting experiments to motivate the need for the analysis/algorithm. While the comment implies that the authors should provide more motivation and conduct experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the motivation and conduct experiments. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the motivation for using the Newton algorithm, questioning its necessity and suggesting that a bisecting line search would suffice. The comment further specifies that experiments could help motivate the need for the analysis/algorithm. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the motivation for using the Newton algorithm in Section 4 is lacking and suggests that a bisecting line search would suffice for a 1dimensional line search on a convex function. The reviewer questions the impact of quadratic convergence on the algorithm\"s runtime and suggests conducting experiments to motivate the need for the analysis/algorithm. While the comment provides a logical reasoning for questioning the motivation, it lacks specific examples or references to support the claim. The suggestion for experiments is a reasonable next step, but the current comment does not fully substantiate the claim. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed evidence or examples to be 5.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, specifically the lack of motivation for using the Newton algorithm in Section 4. It points out that a bisecting line search would suffice for a 1dimensional line search on a convex function, questioning the need for the more complex Newton algorithm. The comment suggests that experiments could help motivate the need for the analysis/algorithm, which is a clear and actionable suggestion for improvement. However, the comment could be more helpful if it provided specific examples or detailed guidance on how to conduct these experiments. Overall, the feedback is 4 as it directs the authors to address a critical aspect of their work, but it could be more comprehensive with additional details. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with Equation 8, specifically mentioning that subtracting \"s\" from the dynamic information may result in the loss of some dynamic information. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or improve the equation. The comment lacks actionable guidance, such as recommending alternative methods or suggesting ways to mitigate the loss of dynamic information. As a result, the authors are left without a clear understanding of what steps to take to resolve the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equation 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with subtracting \"s\" from the dynamic information, explaining how it might result in the loss of dynamic information and affect the LSTM module\"s ability to capture complete dynamic changes. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about Equation 8, specifically regarding the potential loss of dynamic information when subtracting \"s\" from the dynamic information. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with Equation 8, specifically noting that subtracting \"s\" from the dynamic information may result in the loss of some dynamic information, which could affect the LSTM module\"s ability to capture complete dynamic changes. This is a relevant observation that could impact the accuracy and effectiveness of the model. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the equation. Without actionable feedback or specific recommendations, the authors are left without a clear path for improvement. Therefore, the comment is 3, as it highlights a potential problem but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises questions about the impact of the number of Monte Carlo (MC) samples on performance and how the network structure affects this. While it implies that the authors should investigate these aspects, it does not provide explicit instructions or concrete steps on how to conduct these investigations. The authors can infer that they need to explore these relationships, but the comment lacks specific guidance on how to do so. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment raises questions about the impact of the number of Monte Carlo (MC) samples and the network structure on performance. However, it does not specify which part of the paper these questions pertain to, such as specific sections, figures, or tables. This lack of grounding makes it difficult for the authors to identify the exact parts of the paper that need attention. The comment is specific in its inquiry about the effects of MC samples and network structure, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions seeking clarification on the impact of the number of Monte Carlo (MC) samples and the network structure on performance. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and seek information that would help the authors improve their draft. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the impact of the number of Monte Carlo (MC) samples and the network structure on performance. By asking for empirical evidence on how these factors affect performance, the comment prompts the authors to consider and address these aspects in their draft. This feedback is clear and actionable, as it directs the authors to provide additional analysis or experimentation to support their claims. However, the comment could be more helpful if it offered specific suggestions on how to investigate these factors or what metrics to consider. Overall, the comment is 4 as it guides the authors toward improving their draft by highlighting areas that need further exploration."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the generalizability of the method to other domains and questions the selection of event types from Freebase. It explicitly asks for clarification on how the event types were selected and what the coverage is on the 33 event types in the ACE data. These questions provide clear and direct actions for the authors to take, such as providing more information on the selection process and coverage. The feedback is explicit and concrete, giving the authors specific steps to address the concerns. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment raises concerns about the generalizability of the method and questions the selection of event types from Freebase. It specifically mentions Section 2, line 262, which provides some grounding by indicating the part of the paper being addressed. However, it does not specify what needs to be addressed in this part, such as how the event types were selected or what the coverage is on the 33 event types in the ACE data. While the authors can infer that these aspects need clarification, the comment lacks specificity in detailing what needs to be addressed. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises concerns about the generalizability of the method and questions the selection of event types from Freebase. It specifically asks for clarification on how the event types were selected and what the coverage is on the 33 event types in the ACE data. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these concerns. Without additional context or justification, the authors may find it challenging to address the issues raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the generalizability of the method to other domains, specifically questioning the selection of event types from Freebase and the coverage on the 33 event types in the ACE data. This feedback is clear and actionable, as it prompts the authors to provide more information on the selection process and coverage, which could enhance the transparency and applicability of their work. However, the comment could be more helpful if it suggested specific ways to address these concerns or provided examples of how to improve generalizability. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that some aspects of the experimental setup are unclear or poorly motivated, specifically regarding corpora and datasets. However, it does not provide explicit guidance on what needs to be clarified or improved. The authors can infer that they need to provide more detailed information about the corpora and datasets used in the experiments, but the comment lacks concrete suggestions on how to achieve this. As a result, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment mentions \"some aspects of the experimental setup\" as being unclear or poorly motivated, specifically regarding corpora and datasets. However, it does not specify which part of the paper these aspects are discussed in, making it weakly grounded. The comment is specific in identifying the issue with corpora and datasets, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing clarification. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that some aspects of the experimental setup are unclear or poorly motivated, specifically regarding corpora and datasets. However, it does not provide any specific examples or detailed reasoning to support this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 2, as it lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The comment identifies a specific issue with the experimental setup, noting that some aspects are unclear or poorly motivated, particularly regarding corpora and datasets. This feedback is 3 as it points out a potential area for improvement, prompting the authors to clarify and motivate their experimental choices. However, the comment lacks detailed guidance or suggestions on how to address these issues, such as specific questions to consider or examples of how to improve the clarity. While it provides some direction, it could be more helpful with additional details or actionable advice. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the size of the model, specifically its depth or number of parameters, in comparison to competing approaches. It also points out that the authors mention the use of 4 hourglass modules but do not specify the size of each module. This feedback implies that the authors should provide more detailed information about the model\"s size and structure, which is an implicit action. However, the comment does not explicitly instruct the authors to include this information, and it lacks concrete guidance on how to present this information. Therefore, the comment is 3, as the authors can infer the need for additional details but are not given explicit instructions on how to implement them.", "grounding_specificity_rationale": "The comment raises a question about the size of the model, specifically its depth or number of parameters, in comparison to competing approaches. It also points out that the authors mention the use of 4 hourglass modules but do not specify the size of each module. This provides a clear indication of what needs to be addressed, namely the size and structure of the model. However, the comment does not explicitly mention which part of the paper this issue pertains to, such as a specific section or table. While the authors can infer that it relates to the methodology or results sections, the lack of explicit grounding makes it weakly grounded. The comment is specific in detailing what is missing, making it 3. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point raises a question about the size of the model, specifically its depth or number of parameters, in comparison to competing approaches. It points out that the authors mention the use of 4 hourglass modules but do not specify the size of each module. This is a request for clarification rather than a claim, as it does not express an opinion, judgment, or suggestion that requires verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a pertinent question about the size of the model, specifically its depth or number of parameters, in comparison to competing approaches. It points out that the authors mention the use of 4 hourglass modules but do not specify the size of each module. This feedback is valuable as it highlights a gap in the paper that could be addressed to provide a more comprehensive understanding of the model\"s architecture and its relationship to other approaches. However, the comment could be more helpful if it suggested ways to present this information or provided examples of how other papers have addressed similar issues. Overall, the comment is 3 as it identifies a specific area for improvement but lacks detailed guidance on how to address it."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a specific issue with the claim that PACE addresses a gap in climate emulation by treating it as a diagnostictype prediction, noting that prior work (e.g., ClimateBench or ClimateSet) already does this. However, the comment does not provide explicit guidance on how the authors should address this issue or clarify the claim. It lacks concrete suggestions on how to revise the claim or what additional information should be included to make it clearer. As a result, the authors are left with an implicit action to clarify the claim but without detailed guidance on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim that \"To address this gap, we propose PACE, which treats climate emulation as a diagnostictype prediction,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that prior work (e.g., ClimateBench or ClimateSet) already addresses this gap, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement \"To address this gap, we propose PACE, which treats climate emulation as a diagnostictype prediction\" is misleading because prior work (e.g., ClimateBench or ClimateSet) already addresses this gap. The comment provides a specific example of prior work that contradicts the claim, which is a clear and logical reasoning supporting the claim. This makes the comment 5, as it provides a direct and specific reference to external work that challenges the claim. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a specific issue with the claim that PACE addresses a gap in climate emulation by treating it as a diagnostictype prediction. It points out that prior work, such as ClimateBench or ClimateSet, already addresses this gap, making the claim misleading. This feedback is clear and actionable, as it prompts the authors to clarify their claim or provide a more nuanced explanation of how PACE differs from existing work. However, the comment could be more helpful if it suggested ways to address this issue or offered examples of how PACE might contribute to the field. Overall, the comment is 4 as it directs the authors to a critical area needing clarification, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point critiques the metric learning theory in the paper, suggesting that it does not provide better results compared to previous theoretical results. However, it does not offer any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this critique or improve their work. The comment lacks actionable advice, leaving the authors without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the metric learning theory in the paper, suggesting that it does not provide better results compared to previous theoretical results. It also mentions that the metric perspective analysis does not seem to work based on the existing content of the paper. However, the comment does not specify which part of the paper this critique is based on, making it difficult for the authors to identify the exact sections that need attention. While the authors might infer that it relates to the theoretical sections, the lack of explicit references or detailed guidance makes the comment weakly grounded. The comment is specific in its critique of the metric learning theory, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point claims that the metric learning theory in the paper does not provide better results compared to previous theoretical results. It also suggests that the metric perspective analysis does not seem to work based on the existing content of the paper. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment critiques the metric learning theory in the paper, suggesting that it does not provide better results compared to previous theoretical results. It also claims that the metric perspective analysis does not seem to work based on the existing content of the paper. However, the comment lacks specificity and does not provide actionable feedback or suggestions for improvement. It does not offer guidance on how the authors might address the critique or enhance their work. Without detailed feedback or constructive advice, the comment is not particularly helpful for the authors in improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests moving some visual results from the supplementary material to the main paper, specifically mentioning the lack of visual results on crowd density estimation, which is the main experiment. It also suggests condensing the figures illustrating the proposed network architecture to make space for visual results. While the comment implies that the authors should include more visual results, it does not explicitly instruct them to do so or provide detailed guidance on which results to include or how to present them. The action is implicit and somewhat vague, as the authors need to infer the specific changes needed and how to implement them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests moving some visual results from the supplementary material to the main paper, specifically mentioning the lack of visual results on crowd density estimation, which is the main experiment. It also suggests condensing the figures illustrating the proposed network architecture to make space for visual results. The comment is fully grounded as it explicitly mentions the lack of visual results in the main paper and suggests specific changes, such as condensing figures to make space for visual results. It is also specific because it clearly identifies the issue and provides a concrete suggestion for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests moving some visual results from the supplementary material to the main paper, specifically mentioning the lack of visual results on crowd density estimation, which is the main experiment. The comment provides a logical reasoning for this suggestion, noting that the current paper lacks visual results despite having figures for the proposed network architecture. However, it does not provide specific examples or references to support the claim that the visual results are necessary or beneficial. While the reasoning is clear, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting the lack of visual results on crowd density estimation, which is the main experiment. It suggests moving some visual results from the supplementary material to the main paper to address this gap. Additionally, it provides a concrete suggestion to condense the figures illustrating the proposed network architecture to make space for these visual results. This feedback is clear and actionable, offering the authors a direct way to enhance the visual presentation of their work. However, it could be more helpful if it included specific examples of what visual results should be included or how they could be presented. Overall, the comment is 4 as it provides valuable guidance for improving the paper\"s visual content."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the potential impact of not knowing that a test example is crucially different, such as the patient in Figure 8 being British. It suggests that using the American corpus to explain this example might be problematic. However, the comment does not provide explicit guidance or suggestions on how to address this issue or what actions the authors should take to improve their draft. The question is posed in a way that requires the authors to infer the need for additional analysis or clarification, but without concrete steps or suggestions, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the potential impact of not knowing that a test example is crucially different, such as the patient in Figure 8 being British. It suggests that using the American corpus to explain this example might be problematic. However, the comment does not specify which part of the paper this issue pertains to, such as a specific section or figure where this discussion is relevant. Additionally, while it raises a concern, it does not provide specific guidance on how to address this issue or what changes might be necessary. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a question about the potential impact of not knowing that a test example is crucially different, such as the patient in Figure 8 being British. It suggests that using the American corpus to explain this example might be problematic. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises an important question about the potential impact of not knowing that a test example is crucially different, such as the patient in Figure 8 being British. It suggests that using the American corpus to explain this example might be problematic. This is a relevant concern that could affect the validity and generalizability of the results. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or improve their methodology to account for such differences. While it highlights a potential weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it prompts the authors to consider a critical aspect of their work but does not fully support them in making improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point questions the choice of the WebQuestionsSP dataset as the testbed and suggests using the more popular WebQuestions benchmark set instead. It provides a rationale for this suggestion, stating that NSM only requires weak supervision and that using WebQuestions would be more intuitive and straightforward, allowing for direct comparison with mainstream QA research. While the comment implies that the authors should consider using a different dataset, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement the suggested change. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the choice of dataset, specifically the WebQuestionsSP dataset, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear rationale for why the authors should consider using the more popular WebQuestions benchmark set instead, explaining that NSM only requires weak supervision and that using WebQuestions would be more intuitive and straightforward, facilitating direct comparison with mainstream QA research. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the choice of the WebQuestionsSP dataset as the testbed and suggests using the more popular WebQuestions benchmark set instead. The reviewer provides a rationale for this suggestion, stating that NSM only requires weak supervision and that using WebQuestions would be more intuitive and straightforward, allowing for direct comparison with mainstream QA research. This reasoning is logical and provides a clear basis for the suggestion, making the claim 4. However, the comment could be strengthened by referencing specific studies or examples that support the claim about the advantages of using WebQuestions. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment questions the choice of the WebQuestionsSP dataset as the testbed and suggests using the more popular WebQuestions benchmark set instead. It provides a rationale for this suggestion, stating that NSM only requires weak supervision and that using WebQuestions would be more intuitive and straightforward, allowing for direct comparison with mainstream QA research. This feedback is clear and actionable, as it offers a specific alternative dataset that could enhance the paper\"s relevance and comparability. However, the comment could be more helpful if it included additional guidance on how to integrate the suggested dataset or addressed potential challenges in doing so. Overall, the comment is 4 as it provides a constructive suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the necessity of making claims about the desirability of sparsity in training and suggests that any potential benefits, such as improved training speed or reduced FLOPs, need to be demonstrated. While the comment implies that the authors should provide evidence for their claims, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to demonstrate the benefits or what evidence is needed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment questions the need for certain claims regarding sparsity in training and suggests that any potential benefits, such as improved training speed or reduced FLOPs, need to be demonstrated. However, it does not specify which part of the paper these claims are made in, making it weakly grounded. The comment is specific in its critique of the claims and suggests that the authors should provide evidence for their assertions. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the necessity of making claims about the desirability of sparsity in training and suggests that any potential benefits, such as improved training speed or reduced FLOPs, need to be demonstrated. The reviewer provides a logical reasoning by pointing out that in the age of parallelized computation, the reduction in FLOPs may not necessarily lead to cost savings unless it can be shown to impact practical implementations. However, the comment lacks specific examples or references to support the claim that sparsity is not desirable or that the benefits are not significant. This makes the claim 3, as it provides a logical argument but lacks detailed evidence or examples to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the necessity of making claims about the desirability of sparsity in training, suggesting that any potential benefits, such as improved training speed or reduced FLOPs, need to be demonstrated. The reviewer points out that in the age of parallelized computation, the reduction in FLOPs may not necessarily lead to cost savings unless it can be shown to impact practical implementations. While the comment identifies a potential weakness in the claims made by the authors, it lacks specific suggestions or guidance on how to address this issue or provide evidence for the benefits of sparsity. The feedback is 3 as it prompts the authors to consider the practical implications of their claims, but it could be more actionable with additional guidance. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point claims that the novelty of the design is limited because attention for motion learning has been widely used in video understanding. However, it does not provide any specific guidance or suggestions on how the authors could address this issue or enhance the novelty of their work. The comment lacks actionable details, such as recommending ways to differentiate the design or suggesting additional features or approaches that could be incorporated to improve novelty. As a result, the authors are left without a clear understanding of what steps to take to address the concern. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the novelty of the design, specifically mentioning that attention for motion learning has been widely used in video understanding. However, it does not specify which part of the paper this critique pertains to, such as a particular section or experiment where the novelty is discussed. This lack of explicit grounding makes it difficult for the authors to pinpoint the exact part of the paper being addressed. Additionally, while the comment highlights a potential issue with novelty, it does not provide specific guidance on how to address it or improve the novelty of the design. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the novelty of the design is limited because attention for motion learning has been widely used in video understanding. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment points out a potential limitation in the novelty of the design, suggesting that attention for motion learning has been widely used in video understanding. However, it does not provide specific examples or detailed feedback on how the authors could address this issue or enhance the novelty of their work. The comment identifies a weakness but lacks actionable guidance or suggestions for improvement, leaving the authors with limited insight into how to enhance the novelty of their design. Therefore, the comment is 3, as it highlights an area for improvement but does not offer comprehensive guidance or actionable steps."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy between how BigFive and MBTI are presented in the abstract, introduction, and experiments sections. It suggests that these models should be consistently referred to as datasets throughout the paper, unless the authors provide an extended explanation for their approach. While the comment implies an action\u2014consistency in terminology\u2014the authors are not explicitly instructed to make this change. Additionally, the suggestion to provide an extended explanation is vague, as it does not specify what aspects of the explanation are necessary. Therefore, the comment is 3, as it identifies an issue but lacks concrete guidance on how to address it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Abstract\" and \"Introduction\" sections, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the inconsistency in how BigFive and MBTI are presented as models in the abstract and introduction but used as datasets in the experiments. The comment provides a clear suggestion to either consistently refer to them as datasets or provide an extended explanation for their approach. This level of detail makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that BigFive and MBTI are presented inconsistently in the paper, being referred to as models in the abstract and introduction but used as datasets in the experiments. The reviewer suggests that the authors should either consistently refer to them as datasets or provide an extended explanation for their approach. However, the comment lacks specific examples or detailed reasoning to support the claim of inconsistency, making it difficult for the authors to understand the exact issue and how to address it. Without clear evidence or examples, the claim is not verifiable, aligning with a score of 1.", "helpfulness_rationale": "The review comment identifies a discrepancy in the paper, noting that BigFive and MBTI are presented as models to be extended in the abstract and introduction sections, while they are used as mere datasets in the experiments. The reviewer suggests that the authors should either consistently refer to them as datasets or provide an extended explanation for their approach. This feedback is clear and actionable, as it highlights a potential inconsistency in the paper and offers a specific suggestion for improvement. By addressing this issue, the authors can enhance the clarity and consistency of their work. However, the comment could be more helpful if it provided additional guidance on how to present these models or datasets effectively. Overall, the comment is 4, as it directs the authors to a specific area for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to include rejection rates in their experiments or to view them as misclassifications in the results. This provides a clear and direct action for the authors to take, ensuring that they know exactly what needs to be done to address the feedback. The comment is specific and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"any experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the inclusion of rejection rates or viewing them as misclassifications in the results. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that rejection rates should be included in the experiments or viewed as misclassifications. The comment provides a logical reasoning by stating that one could view a misclassification as a rejection, which is a valid point. However, it does not provide specific examples or references to support why this is important or how it would impact the results. While the reasoning is clear, the lack of detailed justification or references makes the claim 3, as the authors may need to further explore the implications of including rejection rates. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific gap in the paper by noting that rejection rates are not shown in any experiments. It provides a clear suggestion for improvement by either including rejection rates or viewing them as misclassifications in the results. This feedback is actionable and offers a concrete way for the authors to enhance the comprehensiveness of their results. However, the comment could be more helpful if it explained why rejection rates are important or how they might impact the interpretation of the results. Overall, the comment is 4 as it directs the authors to a meaningful improvement in their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly requests information about the final thresholds used for the results and suggests sharing the full set of hyperparameters for reproducibility purposes. This feedback provides clear and direct actions for the authors to take, ensuring that they know exactly what information to include in their draft. The request for final thresholds and hyperparameters is specific and concrete, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests information about the final thresholds used and suggests sharing the full set of hyperparameters for reproducibility purposes. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point requests information about the final thresholds used for the results and suggests sharing the full set of hyperparameters for reproducibility purposes. These are factual requests for additional information, which do not contain subjective opinions, judgments, or suggestions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment requests specific information about the final thresholds used for the results and suggests sharing the full set of hyperparameters for reproducibility purposes. This feedback is clear and actionable, as it provides the authors with a direct way to enhance the transparency and reproducibility of their work. By addressing these points, the authors can improve the credibility and reliability of their findings, which is crucial for the scientific community. However, the comment could be more helpful if it provided additional context or suggestions on how to present this information effectively. Overall, the feedback is 4, as it guides the authors toward improving the clarity and reproducibility of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the claim that the readability of RC datasets does not directly affect question difficulty. It suggests that this claim depends on the method or features used for answer detection, such as POS/dependency parse features. While the comment identifies a potential limitation in the claim, it does not provide explicit guidance on how the authors should address this issue or suggest specific changes to their analysis. The action is implicit and somewhat vague, as the authors are left to infer that they need to consider the impact of different methods or features on their analysis. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific claim made in the paper regarding the relationship between dataset readability and question difficulty. It suggests that this claim depends on the method or features used for answer detection, such as POS/dependency parse features. However, the comment does not specify which part of the paper this claim is made in, making it weakly grounded. The authors can infer that it relates to the dataset analysis or methodology sections, but this inference is not direct. The comment is specific in detailing the potential dependency on the method or features used, which provides some guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point challenges the claim that the readability of RC datasets does not directly affect question difficulty, suggesting that this depends on the method or features used for answer detection, such as POS/dependency parse features. The comment provides a logical reasoning by pointing out a potential dependency on the method used, which is a valid critique. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to further explore this aspect to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation in the claim that the readability of RC datasets does not directly affect question difficulty. It suggests that this claim may depend on the method or features used for answer detection, such as POS/dependency parse features. This feedback is 3 as it points out a specific area where the authors might need to consider the impact of their methodology on their findings. However, the comment does not provide detailed guidance on how to address this issue or suggest alternative methods or features to explore. While it highlights a potential weakness, it lacks depth and actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that Figure 1 could be optimized to use less whitespace. However, it does not provide any specific guidance on how to achieve this optimization or what aspects of the figure should be adjusted to reduce whitespace. The action is explicit in suggesting an improvement, but it lacks concrete details on how to implement it, leaving the authors uncertain about the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a clear improvement by recommending the optimization of Figure 1 to use less whitespace. This provides the authors with a concrete direction for enhancing their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Figure 1 could be optimized to use less whitespace. However, it does not provide any reasoning, examples, or references to support why this optimization is necessary or how it would improve the figure. Without additional context or justification, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The comment suggests a specific improvement to the figure, recommending that Figure 1 could be optimized to use less whitespace. This feedback is clear and actionable, providing the authors with a concrete way to enhance the visual presentation of their results. By reducing whitespace, the figure might become more compact and easier to interpret, potentially improving the overall clarity and effectiveness of the presentation. However, the comment could be more helpful if it provided additional context or justification for why this optimization is necessary or beneficial. Overall, the suggestion is 4 as it offers a specific and actionable improvement, but it could be more comprehensive with further explanation."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the writing quality of the paper should be improved, specifically mentioning that the authors spend the same space on explaining basic memory networks and then the forward model. It also notes that the related work section lacks coverage of more reinforcement learning tasks in the literature. However, the comment does not provide explicit guidance on how to improve the writing quality or what specific changes should be made to address the issues with the related work section. The action is implicit and somewhat vague, as the authors are left to infer what specific improvements are needed without concrete instructions. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment provides a general observation about the writing quality, specifically mentioning that the authors spend the same space on explaining basic memory networks and then the forward model. It also notes that the related work section lacks coverage of more reinforcement learning tasks in the literature. However, the comment does not specify which sections of the paper these issues pertain to, making it weakly grounded. The authors can infer that it relates to the sections discussing memory networks and the related work, but this inference is not explicit. The comment is specific in identifying areas for improvement, such as the writing quality and related work coverage. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the writing quality of the paper should be improved, specifically mentioning that the authors spend the same space on explaining basic memory networks and then the forward model. It also notes that the related work section lacks coverage of more reinforcement learning tasks in the literature. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the exact issues and how to address them. The lack of detailed justification or references makes the claim 3, as it requires more information to be fully actionable.", "helpfulness_rationale": "The review comment identifies two specific areas for improvement: the writing quality and the related work section. It points out that the authors spend the same space on explaining basic memory networks and then the forward model, suggesting that this could be improved by focusing on more relevant content. Additionally, it notes that the related work section lacks coverage of more reinforcement learning tasks in the literature, which is an important area for the paper to address. However, the comment does not provide detailed suggestions or examples on how to improve the writing quality or what specific tasks should be included in the related work section. While it highlights important areas for improvement, the feedback could be more actionable and comprehensive. Therefore, the comment is 3, as it provides some direction but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that if the authors did not find improvements in FLOPs or inference time, they should consider looking for improvements in accuracy or specific properties. It provides a specific example of how this could be done, such as examining whether the sequential relationship is easier to model with a recurrent model. This feedback is explicit and provides concrete guidance on what the authors should explore, making it 5.", "grounding_specificity_rationale": "The comment suggests that if the authors did not find improvements in FLOPs or inference time, they should consider looking for improvements in accuracy or specific properties. It provides a specific example of examining whether the sequential relationship is easier to model with a recurrent model. However, the comment does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The suggestion is specific in terms of what the authors should explore, but without clear grounding, the authors may struggle to identify the exact section to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that if the authors did not find improvements in FLOPs or inference time, they should consider looking for improvements in accuracy or specific properties. The reviewer provides a specific example of examining whether the sequential relationship is easier to model with a recurrent model. This suggestion is based on logical reasoning and a clear understanding of the paper\"s focus on recurrent models. However, the comment could be strengthened by providing more detailed examples or references to support the claim that accuracy or specific properties might be improved. Therefore, the comment is 4, as it provides a solid basis for the suggestion but lacks comprehensive evidence or references.", "helpfulness_rationale": "The review comment suggests that if the authors did not find improvements in FLOPs or inference time, they should consider looking for improvements in accuracy or specific properties. It provides a specific example of examining whether the sequential relationship is easier to model with a recurrent model. This feedback is actionable and offers a clear direction for the authors to explore, which can help them refine their work. However, the comment could be more helpful if it provided additional guidance on how to measure or evaluate these specific properties or accuracy improvements. Overall, the comment is 4 as it provides a constructive suggestion for further exploration, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the assumption that d_e are good replacements for entity embeddings has been tested. While it implies that the authors should test this assumption, the comment does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to test this assumption or what specific tests should be conducted. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about an assumption made in the paper, specifically whether d_e are good replacements for entity embeddings. However, it does not specify which part of the paper this assumption is discussed in, making it weakly grounded. The comment is specific in its inquiry about the testing of this assumption, but without explicit references to sections or parts of the paper, the authors may find it challenging to pinpoint the exact area needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about an assumption made in the paper, specifically whether d_e are good replacements for entity embeddings. However, it does not provide any supporting evidence, reasoning, or references to justify why this assumption should be tested or what implications it might have. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a critical question about an assumption made in the paper, specifically whether d_e are good replacements for entity embeddings. This is an important point that the authors should address, as it could impact the validity and robustness of their findings. However, the comment lacks specificity and does not provide guidance on how to test this assumption or what specific tests should be conducted. While it identifies a potential area for improvement, the lack of detailed feedback limits its helpfulness. Therefore, the comment is 3, as it prompts the authors to consider a critical aspect of their work but does not fully support them in making improvements."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point poses a question about the number of different kinds of physical interactions that can be present in a simulation. However, it does not provide any explicit or implicit actions for the authors to take. The question is not phrased as a request for clarification or a suggestion for improvement, leaving the authors without any guidance on how to address the issue. As a result, the comment lacks actionability and provides no direction for the authors to improve their draft. Therefore, it is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment poses a question about the number of different kinds of physical interactions that can be present in a simulation. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure where this information might be discussed. Without explicit references or context, the authors cannot confidently determine which part of the paper the comment addresses. Additionally, the comment lacks specificity as it does not provide guidance on what aspects of the simulation are being questioned or how to address the issue. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification about the number of different kinds of physical interactions that can be present in a simulation. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment poses a question about the number of different kinds of physical interactions that can be present in a simulation. While it highlights an area of potential interest or complexity, it does not provide any actionable feedback or suggestions for improvement. The authors are left without guidance on how to address this question or incorporate it into their draft. As a result, the comment is not helpful, as it does not offer any constructive feedback or direction for the authors to enhance their work. Therefore, it aligns with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights specific issues with the model comparison, noting that the chosen datasets are not adequate for a thorough comparison due to the absence of categorical features and the use of onehot encoding. The comment provides a clear and explicit action for the authors to take, which is to expand the dataset selection to include more diverse features and consider using onehot encoding for categorical features. The feedback is concrete and directly guides the authors on how to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the key contribution of the paper, which is the thorough comparison of models on a wide range of datasets. It also specifies the issue with the dataset selection, noting that only one dataset has categorical features, while all others have exclusively numerical features. This is a clear indication of what needs to be addressed. The comment provides specific reasoning about the impact of this omission on the conclusions and suggests a potential issue with onehot encoding for categorical features. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the chosen dataset selection is inadequate for a thorough comparison due to the absence of categorical features and the use of onehot encoding. The reviewer provides a logical reasoning by explaining that categorical features are generally more challenging for deep learning models, which could affect the conclusions. However, the comment lacks specific examples or references to support the claim that the chosen datasets are insufficient. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a significant issue with the model comparison section of the paper, specifically regarding the dataset selection. It points out that the chosen datasets are not adequate for a thorough comparison because they lack categorical features, which are generally more challenging for deep learning models. The comment also highlights the omission of onehot encoding for categorical features, which could negatively impact performance for some models. This feedback is clear and actionable, as it provides specific areas for improvement that the authors can address to enhance the validity and comprehensiveness of their model comparison. However, the comment could be more helpful if it offered suggestions on how to expand the dataset selection or alternative methods for handling categorical features. Overall, the comment is 4, as it effectively guides the authors toward improving their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly states that the choice of IoT datasets, FlatCam Face [26] and Headpose detection [11], is unusual and suggests that better options should have been chosen. It provides specific examples of more popular datasets, such as wearable health or mobile activity recognition data, or even sets from UCI. This feedback is clear and actionable, as it directs the authors to consider alternative datasets that might be more relevant and widely used in the field. The authors know exactly what needs to be done to improve their draft by selecting more appropriate datasets for benchmarking. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the choice of IoT datasets, particularly FlatCam Face [26] and Headpose detection [11], which are described as unpopular and strange choices. The comment provides specific examples of more popular datasets that could have been used, such as wearable health or mobile activity recognition data, or even sets from UCI. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with a score of 5.", "verifiability_rationale": "The review point claims that the choice of IoT datasets, FlatCam Face [26] and Headpose detection [11], is unusual and suggests that better options should have been chosen. The reviewer provides a logical reasoning by stating that the first dataset is relatively recent but not widely followed, while the second is outdated and no longer used. This reasoning is supported by the mention of specific datasets that could have been used, such as wearable health or mobile activity recognition data, or even sets from UCI. However, the comment could be strengthened by providing more detailed reasoning or examples of why these specific datasets are problematic. Overall, the claim is 4, as it provides a logical basis but lacks comprehensive evidence or references. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by questioning the choice of IoT datasets used in the paper. It points out that the datasets, FlatCam Face [26] and Headpose detection [11], are unpopular and strange choices, suggesting that better options should have been selected. The reviewer offers specific examples of more popular datasets, such as wearable health or mobile activity recognition data, or even sets from UCI. This feedback is clear and constructive, as it directs the authors to consider more relevant and widely used datasets for benchmarking purposes. By addressing this feedback, the authors can improve the credibility and relevance of their results. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to further enlarge the annotations in Figure 4 for improved visibility. This is a clear and direct action that the authors can take to enhance their draft. The comment provides a specific and concrete suggestion, leaving no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the annotations in Figure 4 should be enlarged for better visibility. This provides clear guidance on how to improve the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification or improvement regarding the visibility of annotations in Figure 4. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for enhancement, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the draft by recommending that the annotations in Figure 4 be enlarged for better visibility. This feedback is clear and direct, offering a concrete way for the authors to enhance the clarity and readability of their work. By addressing this suggestion, the authors can improve the overall quality of their draft. However, the comment could be more helpful if it explained why the annotations are currently not visible or suggested alternative methods for enhancing visibility. Despite this, the feedback is 4 as it provides a clear direction for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review comment points out that multiple entities exist in both sentences and documents, even in relation classification tasks, which is not limited to documentlevel RE or joint entity and relation extraction. However, it does not provide any explicit or implicit action for the authors to take. There is no suggestion for improvement, clarification, or additional information that the authors should consider. As a result, the comment lacks any actionable guidance, leaving the authors without a clear understanding of how to address the issue. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 2627, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clarifies that multiple entities exist in both sentences and documents, even in relation classification tasks, which is not limited to documentlevel RE or joint entity and relation extraction. This provides clear guidance on what the authors need to address in their paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual statement describing the existence of multiple entities in both sentences and documents, even in relation classification tasks. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment points out a factual observation about the existence of multiple entities in both sentences and documents, even in relation classification tasks. However, it does not provide any actionable feedback or suggestions for improvement. The comment lacks depth and does not offer any guidance on how this observation might impact the paper or how the authors could address it. As a result, the comment is 1, as it does not assist the authors in enhancing their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to modify the label on the color bar in Fig. 4, specifying that one of the labels should say \"worse.\" This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to address the issue. The comment is explicit and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the color bar, indicating that one of the labels should say \"worse.\" This provides clear guidance on what needs to be corrected. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual statement that describes a potential issue with the labeling in Figure 4. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the labeling in Figure 4, suggesting that one of the labels on the color bar should say \"worse.\" This feedback is clear and actionable, providing the authors with a direct way to improve the clarity and accuracy of their figure. By addressing this feedback, the authors can enhance the readability and effectiveness of their visual representation. However, the comment could be more helpful if it explained why this change is necessary or how it would impact the interpretation of the figure. Overall, the comment is 4 as it offers a specific and actionable suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly identifies a specific error in the manuscript, namely the incorrect use of \"training/validation/test\" instead of \"training/validation/test sets.\" This feedback is clear and direct, providing the authors with a precise action to take to correct the error. The comment is 5 as it specifies exactly what needs to be changed, leaving no ambiguity about the necessary correction. Therefore, this comment is rated as a 5 on the actionability scale.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Row 757 in Supp. Page 29,\" allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it clearly specifies the error, which is the incorrect use of \"training/validation/test\" instead of \"training/validation/test sets.\" This provides clear guidance on what needs to be corrected. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual correction of a typographical error in the manuscript, specifically pointing out the incorrect use of \"training/validation/test\" instead of \"training/validation/test sets.\" It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific typographical error in the manuscript, pointing out that \"training/validation/test\" should be corrected to \"training/validation/test sets.\" This feedback is clear and actionable, providing the authors with a precise correction to make in their draft. By addressing this error, the authors can ensure the accuracy and clarity of their work. However, the comment does not provide broader context or suggestions for improving the overall quality of the paper. Therefore, it is 4, as it offers a clear and actionable step but lacks depth in terms of comprehensive feedback. This aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and concerns about the paper, including the impact of inference slowdown, the coefficient in line 307, the lack of hyperparameter details, and the clarity of the writing. While the comment identifies areas that need clarification or improvement, it does not provide explicit instructions or concrete suggestions on how the authors should address these issues. The authors can infer that they need to provide more detailed explanations and potentially conduct additional experiments or analyses, but the comment lacks specific guidance on how to implement these changes. Therefore, the comment is 3, as it highlights areas for improvement but does not provide detailed steps for the authors to follow.", "grounding_specificity_rationale": "The comment raises several questions and concerns about the paper, including the impact of inference slowdown, the coefficient in line 307, the lack of hyperparameter details, and the clarity of the writing. However, it does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its critique, but it lacks grounding as it does not identify the specific sections or parts of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several questions and concerns about the paper, including the impact of inference slowdown, the coefficient in line 307, the lack of hyperparameter details, and the clarity of the writing. While the comment identifies specific areas that need clarification or improvement, it does not provide detailed reasoning or evidence to support these claims. The lack of specific examples or references makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered 2, as it highlights issues but lacks sufficient support for the authors to fully understand and address them.", "helpfulness_rationale": "The review comment raises several important questions and concerns about the paper, including the impact of inference slowdown, the coefficient in line 307, the lack of hyperparameter details, and the clarity of the writing. While it identifies specific areas that need clarification or improvement, it does not provide detailed guidance or suggestions on how the authors might address these issues. The comment highlights potential weaknesses but lacks actionable advice, making it 3. The authors are given some direction but are left to figure out the specifics of how to improve their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests replacing the term \"stateoftheart\" with \"very high performing model\" or a similar phrase in line 152. This is an explicit action that provides a clear direction for the authors to make a specific change in their draft. The comment is concrete because it specifies what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 152,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests replacing the term \"stateoftheart\" with \"very high performing model\" or a similar phrase, providing clear guidance on what needs to be changed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the model by Dozat and Manning (2016) is no longer stateoftheart, and it recommends replacing the term \"stateoftheart\" with \"very high performing model\" or a similar phrase. However, the comment does not provide any supporting evidence or reasoning to justify why the model is no longer stateoftheart. Without additional context or references, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the terminology used in the paper, suggesting that the term \"stateoftheart\" may no longer be accurate for the model mentioned. It provides a clear and actionable suggestion to replace it with a more appropriate term, such as \"very high performing model.\" This feedback is valuable as it helps the authors maintain the accuracy and relevance of their claims, ensuring that their draft remains uptodate and credible. However, the comment could be more helpful if it provided additional context or justification for why the original term is no longer accurate. Overall, the comment is 4, as it offers a specific and actionable suggestion for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific weakness of the proposed method, namely that it performs worse than PQ when a small code length is allowed. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their method. There is no guidance on potential modifications, alternative approaches, or additional experiments that could be conducted to mitigate this weakness. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the proposed compression method, noting that it performs worse than PQ when a small code length is allowed. However, it does not specify which part of the paper discusses this method or where the comparison with PQ is made. Without explicit references to sections, tables, or figures, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what needs to be addressed or improved in this context. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the proposed compression method performs worse than PQ when a small code length is allowed, which is presented as a main weakness of the method. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or data to support the assertion, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific weakness in the proposed method, noting that it performs worse than PQ when a small code length is allowed. This is presented as a main weakness of the method, which is a valuable observation for the authors to consider. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve their method. Without actionable feedback or specific recommendations, the authors are left with a general understanding of the problem but without a clear path to improvement. Therefore, the comment is 3, as it highlights a critical area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies several subjective statements that need to be supported with proofs and references. It also highlights the challenges of seeking an effective architecture and the sensitivity of image recovery performance to neural architecture choices. Additionally, it points out the need for a detailed explanation regarding the use of multiscale features and when to fuse them. While the comment implies that the authors should provide additional evidence and explanations, it does not explicitly instruct them on how to do so. The action is implicit and somewhat vague, as the authors are left to infer the specific steps needed to address the issues. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"some subjective statements\" and \"proofs and references,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, such as providing detailed explanations and references to support subjective statements. Additionally, it provides specific examples of issues related to the choice of neural architecture and multiscale feature fusion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some subjective statements are inappropriate and suggests that proofs and references are needed to support them. It also highlights the challenges of seeking an effective architecture and the sensitivity of image recovery performance to neural architecture choices. The comment further mentions the need for a detailed explanation regarding the use of multiscale features and when to fuse them. While the comment provides some reasoning, it lacks specific examples or references to substantiate the claims fully. The authors would need to infer the exact issues and how to address them, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas where the paper could be improved, specifically regarding subjective statements that lack proof or references, the challenges of seeking an effective architecture, and the sensitivity of image recovery performance to neural architecture choices. It also highlights the need for a detailed explanation regarding the use of multiscale features and when to fuse them. While the comment points out important areas for improvement, it does not provide specific suggestions or examples on how to address these issues, leaving the authors with a general understanding of what needs to be clarified or substantiated. Therefore, the comment is 3, as it identifies key areas for improvement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point asks for a comparison of the proposed method with prior art, but it does not provide any guidance on how to conduct this comparison or what specific aspects should be considered. The action is implicit and vague, as the authors are left to infer that they need to provide a comparison but without concrete details on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the comparison of the proposed method with prior art, but it does not specify which part of the paper this comparison should be included in. The authors cannot confidently determine which section or subsection this comment pertains to, making it weakly grounded. However, the comment is specific in its request for a comparison with prior art, which provides some guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point is a question seeking clarification on how the proposed method compares with prior art. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a critical question about the comparison of the proposed method with prior art. This is an important aspect that the authors need to address to provide context and relevance for their work. However, the comment lacks specificity and does not offer any guidance or suggestions on how to conduct this comparison or what aspects should be considered. While it identifies a key area for improvement, the lack of detailed feedback limits its helpfulness. Therefore, the comment is 3, as it points out a significant gap but does not provide actionable steps for the authors to address it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the analyses could be more detailed, specifically mentioning the \"language/nationality\" data that includes various languages and nationalities. The reviewer expresses curiosity about potential biases and interesting observations that could be made by comparing these different languages/nationalities. While the comment implies that the authors should expand their analysis to include more detailed comparisons, it does not provide explicit instructions on how to achieve this or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should conduct more detailed analyses and comparisons. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the analyses could be more detailed, specifically mentioning the \"language/nationality\" data and the potential for interesting observations by comparing different languages/nationalities. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or analysis. The authors might infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in suggesting a potential area for improvement, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the analyses could be more detailed, specifically mentioning the \"language/nationality\" data and the potential for interesting observations by comparing different languages/nationalities. The reviewer provides a specific example of the data, which includes Japanese, Chinese, English, Arabic, and German, indicating that there are ~20 different types. This provides some context and a basis for the suggestion, but it lacks detailed reasoning or references to support the claim that biases towards different languages/nationalities are different. The comment is 3 as it provides a starting point for the authors to explore further, but it could be strengthened with more detailed justification or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the analyses could be more detailed. It provides a concrete example by mentioning the \"language/nationality\" data, which includes various languages and nationalities, and notes that biases towards different languages/nationalities might be interesting to explore. This feedback is actionable as it prompts the authors to consider expanding their analysis to include more detailed comparisons and observations. However, the comment could be more helpful if it offered specific suggestions on how to conduct these comparisons or what aspects to focus on. Overall, the comment is 4 as it directs the authors to a potential area for enhancement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether there are other properties of features that could be used besides norm. It implies that the authors should consider exploring additional properties to enhance their approach design. However, the comment does not provide explicit guidance on how to identify or evaluate these properties or suggest specific actions to take. The action is implicit and somewhat vague, as the authors need to infer that they should explore other properties and determine how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the use of other properties of features besides norm, suggesting that it is necessary and helpful for the approach design. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for consideration of other properties, but without clear grounding, the authors may struggle to determine where this feedback fits into their manuscript. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the use of other properties of features besides norm, suggesting that it is necessary and helpful for the approach design. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is important or how it would benefit the approach. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the use of other properties of features besides norm, suggesting that it is necessary and helpful for the approach design. This is a relevant point that could prompt the authors to consider expanding their analysis to include other properties, potentially leading to a more comprehensive understanding of their approach. However, the comment lacks specificity and does not provide detailed guidance on how to explore these other properties or what specific aspects to consider. While it identifies a potential area for improvement, the feedback could be more actionable and helpful with additional details. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper should include tasks beyond link prediction where PE (position encoding) is important. However, it does not provide any explicit or implicit guidance on how to identify or implement these additional tasks. The comment lacks concrete details or suggestions on what specific tasks should be included or how to incorporate them into the paper. As a result, the authors are left without a clear understanding of what actions to take to address this feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the paper should include tasks beyond link prediction where position encoding (PE) is important. However, it does not specify which part of the paper this suggestion pertains to, nor does it provide details on what specific tasks should be included or how they would relate to PE. Without explicit references to sections or examples, the authors cannot confidently determine which part of the paper needs revision. The comment is 1 and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that it is expected to see a variety of tasks beyond link prediction where position encoding (PE) is important. However, the comment does not provide any supporting evidence, reasoning, or examples to justify this expectation. Without specific references or detailed explanations, the claim remains vague and difficult for the authors to understand or address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the paper should include tasks beyond link prediction where position encoding (PE) is important. While it identifies a potential area for expansion, it lacks specificity and does not provide any guidance on how to incorporate these additional tasks or why they are relevant. The feedback is somewhat vague and does not offer actionable advice, leaving the authors with a general idea of what could be improved but without a clear path forward. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that a set of fewshot demonstrations should be included, with the help of domain experts, and that a discussion about this would be appreciated. It also questions the inclusion of zeroshot generation results, suggesting that it might satisfy general curiosity but lacks relevance. However, the comment does not provide explicit guidance on how to implement the suggestion for fewshot demonstrations or how to address the issue with zeroshot results. The actions are implicit and somewhat vague, as the authors are left to infer what specific steps to take to improve their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the inclusion of zeroshot generation results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear critique of the inclusion of zeroshot generation results, suggesting that it might satisfy general curiosity but lacks relevance. The comment further suggests that a set of fewshot demonstrations should be included, with the help of domain experts, and that a discussion about this would be appreciated. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with a score of 5.", "verifiability_rationale": "The review point raises a claim about the inclusion of zeroshot generation results, suggesting that it might satisfy general curiosity but lacks relevance. The reviewer provides a logical reasoning by questioning the relevance of zeroshot results in the context of the paper, which is a valid point. However, the comment lacks specific examples or references to support why the inclusion of zeroshot results is unnecessary or how it could be improved. This makes the claim 3, as it provides a logical basis but lacks detailed evidence or examples to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the inclusion of zeroshot generation results, suggesting that it might satisfy general curiosity but lacks relevance. It also suggests that a set of fewshot demonstrations should be included, with the help of domain experts, and that a discussion about this would be appreciated. This feedback is 3 as it points out a specific area for improvement and provides a suggestion for enhancing the paper. However, the comment could be more helpful if it offered more detailed guidance on how to implement the suggestion for fewshot demonstrations or why the inclusion of zeroshot results is problematic. Overall, the comment provides some direction but lacks depth, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a minor issue with Figure 3, noting that \"OAA\" is not referenced in the body text and suggesting that there might be more content in the appendix that is missing or that the caption is out of date. While the comment identifies a potential issue, it does not provide explicit instructions on how to address it. The authors can infer that they need to either update the caption or include a reference to \"OAA\" in the body text, but the comment lacks concrete guidance on which action to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue of \"OAA\" not being referenced in the body text and suggests that there might be more content in the appendix that is missing or that the caption is out of date. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about Figure 3, specifically noting that \"OAA\" is not referenced in the body text. The reviewer suggests that there might be more content in the appendix that is missing or that the caption is out of date. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to investigate the issue themselves to determine its validity. Therefore, the comment is 3, as it provides a basis for further investigation but lacks comprehensive evidence or justification.", "helpfulness_rationale": "The review comment identifies a minor issue with Figure 3, noting that \"OAA\" is not referenced in the body text. It suggests that there might be more content in the appendix that is missing or that the caption is out of date. While the comment points out a specific issue, it lacks depth and does not provide actionable guidance on how to address the problem. The authors are left with a vague understanding of what needs to be corrected, making the feedback 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the effectiveness of the GS module in propagating context information and improving the effective receptive field. It suggests that the authors should compute the effective receptive field from a reference, which is provided in the comment. This feedback is explicit and provides a clear action for the authors to take, which is to compute the effective receptive field and report the results. The comment is also concrete, as it specifies exactly what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"GS module,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the effectiveness of the GS module in improving the effective receptive field, and it suggests that the authors should compute this from a reference provided in the comment. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the effectiveness of the GS module in improving the effective receptive field, suggesting that the authors should compute this from a reference provided in the comment. However, the comment does not provide any specific reasoning or evidence to support why this computation is necessary or how it would impact the paper. The reference to [2] is not elaborated upon, making it difficult for the authors to understand the significance of this suggestion. Therefore, the claim is considered 2, as it lacks sufficient justification or explanation.", "helpfulness_rationale": "The review comment raises a question about the effectiveness of the GS module in improving the effective receptive field, suggesting that the authors should compute this from a reference provided in the comment. This feedback is 3 as it identifies a potential area for improvement and provides a specific suggestion for further analysis. However, the comment could be more helpful if it offered additional context or explanation on why this computation is important or how it might impact the paper. Overall, the comment provides some direction for the authors to consider, but it lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the objective for the LSTM part would be the same for pretraining and finetuning, as it involves computing the probabilities of actions. It also implies that in the finetuning stage, the authors may add another head to the network to compute value functions for states. While the comment provides some guidance on potential changes, it does not explicitly instruct the authors to make these modifications. The action is implicit and somewhat vague, as it lacks specific instructions on how to implement the suggested changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"LSTM part,\" allowing the authors to accurately identify the section being addressed. It is also specific because it details the objective for the LSTM part, which would be the same for pretraining and finetuning, and suggests adding another head to the network for computing value functions in the finetuning stage. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point suggests that the objective for the LSTM part would be the same for pretraining and finetuning, as it involves computing the probabilities of actions. It also implies that in the finetuning stage, the authors may add another head to the network to compute value functions for states. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. The suggestion is based on logical reasoning, but without further elaboration, it remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the paper by clarifying the objective for the LSTM part, which would be the same for pretraining and finetuning. It also suggests adding another head to the network to compute value functions for states in the finetuning stage. This feedback is clear and actionable, offering the authors a concrete way to enhance their draft. However, the comment could be more helpful if it included additional context or explanation about why this change is necessary or how it would impact the overall methodology. Despite this, the comment is 4 as it provides valuable guidance for improving the paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should acknowledge older works in the related works section, specifically mentioning the use of supervised, multilingual systems. While the comment implies that the authors should include these older works, it does not provide specific examples or guidance on which older works to include or how to integrate them into the related works section. The action is implicit and somewhat vague, as the authors need to infer which older works to include and how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"related works\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests acknowledging older works in the context of using supervised, multilingual systems. This provides clear guidance on what needs to be addressed in the related works section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should acknowledge older works in the related works section, specifically mentioning the use of supervised, multilingual systems. However, the comment does not provide specific examples of older works that should be acknowledged or detailed reasoning for why these older works are relevant. Without such examples or detailed justification, the claim remains somewhat vague and lacks sufficient evidence to be 5. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should acknowledge older works in the related works section, specifically mentioning the use of supervised, multilingual systems. This feedback is 3 as it points out a potential gap in the literature review, encouraging the authors to include relevant older works. However, the comment lacks specificity and does not provide examples of specific older works that should be acknowledged or detailed guidance on how to integrate them into the related works section. While it identifies an area for improvement, the feedback could be more actionable and comprehensive to be fully helpful. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the results in Table 2, specifically the comparison between linear/exponentialdecay sampling and uniform sampling. The reviewer suggests that if the predictor is accurate on the good subregion, as argued by the authors, increasing the sampling probability for topperforming predicted architectures should lead to better performance than uniform sampling. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their analysis. The action is implicit and vague, as the authors are left to infer that they need to clarify or further explore the results in Table 2. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the results, questioning the logic behind the comparison between linear/exponentialdecay sampling and uniform sampling. The comment provides a clear rationale for why the results are confusing and suggests a potential explanation for the observed underperformance. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the results in Table 2, specifically the comparison between linear/exponentialdecay sampling and uniform sampling. The reviewer suggests that if the predictor is accurate on the good subregion, as argued by the authors, increasing the sampling probability for topperforming predicted architectures should lead to better performance than uniform sampling. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the results in Table 2, specifically the comparison between linear/exponentialdecay sampling and uniform sampling. It suggests that if the predictor is accurate on the good subregion, as argued by the authors, increasing the sampling probability for topperforming predicted architectures should lead to better performance than uniform sampling. This feedback is 3 as it points out a potential inconsistency or misunderstanding in the results, prompting the authors to reconsider their analysis or provide further explanation. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as recommending additional experiments or analyses. Therefore, while it identifies a potential area for improvement, it does not provide comprehensive or actionable feedback, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights concerns about the time complexity of the method, specifically mentioning the use of an itemoriented autoencoder, the elementwise function, and the large number of hidden units. However, it does not provide explicit guidance or suggestions on how the authors might address these issues or improve the time complexity. The comment lacks actionable details, such as recommending optimizations or alternative approaches, leaving the authors uncertain about how to proceed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the time complexity of the method, specifically mentioning the use of an itemoriented autoencoder, the elementwise function, and the large number of hidden units. However, it does not specify which part of the paper discusses these aspects, making it weakly grounded. The comment is specific in detailing the concerns about time complexity, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the time complexity seems high, providing three reasons: the use of an itemoriented autoencoder, the elementwise function, and the large number of hidden units. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of evidence or detailed explanation makes the claim 3, as the authors would need to infer the potential issues and address them without clear guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the time complexity of the method, specifically mentioning the use of an itemoriented autoencoder, the elementwise function, and the large number of hidden units. This feedback is 3 as it points out a specific area that could be improved, such as optimizing the time complexity. However, the comment lacks detailed suggestions or guidance on how the authors might address these issues, such as recommending specific optimizations or alternative approaches. While it provides some insight into a potential weakness, the feedback could be more actionable and comprehensive to be fully helpful. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the figures would be clearer if they specified \"pretrained solution encoders & solution decoders,\" as there are multiple types of autoencoders. This is an explicit suggestion that provides a clear action for the authors to take, which is to modify the figures to include this information. The comment is specific and provides concrete guidance on how to improve the clarity of the figures, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figures,\" allowing the authors to accurately identify the specific parts of the paper being addressed. It is also specific because it provides a clear suggestion for improvement, recommending that the figures should specify \"pretrained solution encoders & solution decoders\" to clarify the types of autoencoders used. This level of detail guides the authors on what changes to make to enhance the clarity of their figures. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the figures would be clearer if they specified \"pretrained solution encoders & solution decoders,\" as there are multiple types of autoencoders. This is a claim that is 3, as it provides a logical reasoning for the suggestion to improve clarity. However, the comment lacks specific examples or references to support why this change would enhance the figures\" clarity, making it difficult for the authors to fully understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the clarity of the figures by recommending that they specify \"pretrained solution encoders & solution decoders,\" as there are multiple types of autoencoders. This feedback is clear and actionable, offering the authors a concrete way to enhance the clarity and comprehensibility of their figures. By addressing this suggestion, the authors can improve the readability and understanding of their work for both reviewers and readers. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment consists of two parts. The first part suggests that a brief explanation of \"multiaspect\" would be helpful, which is an explicit request for clarification. The second part provides a specific correction regarding the subscripts in Figure 1, which is also explicit. Both parts are clear and provide concrete actions for the authors to take, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (14 and 47) and a figure (Figure 1), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear suggestions for improvement, such as explaining \"multiaspect\" and correcting the subscripts in Figure 1. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts: a request for clarification regarding the term \"multiaspect\" and a suggestion to correct the subscripts in Figure 1. Neither part contains subjective opinions, judgments, or suggestions that require verification. The comment is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback, addressing two distinct issues in the paper. First, it suggests that a brief explanation of the term \"multiaspect\" would be helpful, which is a clear and direct suggestion for improvement. Second, it points out a typographical error in Figure 1, specifically regarding the subscripts s and t, which should be 1 and 2, respectively. This feedback is precise and actionable, guiding the authors on how to enhance the clarity and accuracy of their work. Therefore, the comment is 5, as it offers concrete suggestions that can significantly improve the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the extraction of parts of sentences and documents and the potential impact of extraction rules on the experiment. It explicitly requests a more detailed analysis. While the comment does not provide specific guidance on how to conduct this analysis or what aspects to focus on, it clearly identifies areas that need further exploration. The authors know they need to provide a more detailed analysis, but the comment lacks concrete steps on how to achieve this. Therefore, the comment is 3, as it provides a clear direction but lacks detailed instructions on execution.", "grounding_specificity_rationale": "The comment raises questions about the extraction of parts of sentences and documents and the potential impact of extraction rules on the experiment. However, it does not specify which part of the paper these questions pertain to, making it weakly grounded. The comment is specific in its request for a more detailed analysis, but without clear grounding, the authors may struggle to identify the exact sections that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions seeking clarification about the extraction process and its impact on the experiment. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises questions about the extraction process and its impact on the experiment, specifically asking how parts of sentences and documents are extracted and whether the extraction rules have any effect on the results. It also requests a more detailed analysis. While the comment identifies areas that need clarification and suggests a deeper exploration, it lacks specific guidance or suggestions on how the authors might address these questions or conduct the requested analysis. The feedback is 3 as it points out areas for improvement, but it could be more actionable with additional details or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks for information about the computation required to implement the experiments, including how long they took and on what kind of hardware. This request provides a clear and direct action for the authors to take, as it specifies exactly what information is needed. The authors know exactly what to include in their draft to address this feedback. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly asks for information about the computation required to implement the experiments, including how long they took and on what kind of hardware. This provides clear guidance on what specific information is needed, making the comment fully grounded. It also specifies what needs to be addressed, making it fully specific. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for additional information about the computation required to implement the experiments and the duration of the experiments. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment requests additional information about the computational requirements and duration of the experiments, which is a relevant and important aspect for readers to understand. By asking for this information, the reviewer is prompting the authors to provide more context and detail about their experimental setup, which can help readers better understand the methodology and results. However, the comment could be more helpful if it suggested specific ways to present this information or provided guidance on how to address potential concerns about computational complexity. Despite this, the feedback is 3 as it directs the authors to enhance the transparency and comprehensiveness of their experimental section."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the application of the meta sampler and suggests that the authors provide more discussion on this aspect. It also asks when the meta sampler is applied. While the comment implies that the authors should provide additional discussion and clarify the timing of the meta sampler\"s application, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more discussion and clarify the timing. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the meta sampler\" and \"the linear classifier,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the authors should provide more discussion on the application of the meta sampler and when it is applied (which epoch). This provides clear guidance on what the authors need to address in their paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification on the application of the meta sampler. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the application of the meta sampler, inquiring whether it is used in a decoupled manner and, if so, when it is applied. This feedback is 3 as it prompts the authors to clarify an aspect of their methodology that may not be fully explained in the paper. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered guidance on how to present the information more clearly. Overall, the comment identifies a potential area for improvement but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to rephrase a section of the paper (lines 107114) as a remark, an aside in the Discussion section, or to remove it entirely. This provides clear and direct guidance on what action to take, making the comment 5. The authors know exactly what changes to make to address the issue, ensuring they can effectively implement the feedback. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 107114, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies that the content is speculative or overly opinionated and suggests that it should be rephrased as a remark, an aside in the Discussion section, or removed. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that lines 107114 are speculative or overly opinionated, suggesting that they should be rephrased or removed. However, the comment does not provide any specific examples or reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed justification or evidence, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific section of the paper (lines 107114) as being speculative or overly opinionated. It provides a clear and actionable suggestion to rephrase this section as a remark or an aside in the Discussion section, or to remove it entirely. This feedback is valuable as it guides the authors on how to improve the clarity and focus of their paper by either refining the content or removing it altogether. However, the comment could be more helpful if it included additional context or examples to further clarify the issue. Overall, the comment is 4 as it offers actionable guidance, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests considering additional baselines, specifically Rope and Alibi relative positional embeddings, to verify the performance improvement resulting from the changes proposed in the paper. While the comment implies that the authors should include these baselines for comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide detailed guidance on how to incorporate these baselines or what specific aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests considering additional baselines, specifically Rope and Alibi relative positional embeddings, to verify the performance improvement obtained by the changes proposed in the paper. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the results discussion. This lack of explicit reference makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the inclusion of these baselines, but without clear grounding, it aligns with a score of 2.", "verifiability_rationale": "The review point suggests considering additional baselines, specifically Rope and Alibi relative positional embeddings, to verify the performance improvement obtained by the changes proposed in the paper. However, the comment does not provide any reasoning or evidence to support why these specific baselines are relevant or how they would contribute to the verification process. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests considering additional baselines, specifically Rope and Alibi relative positional embeddings, to verify the performance improvement obtained by the changes proposed in the paper. This feedback is 3 as it provides a specific suggestion for enhancing the experimental validation of the paper. However, the comment could be more helpful if it explained why these particular baselines are relevant or how they would contribute to the verification process. Additionally, it does not offer guidance on how to incorporate these baselines or what specific aspects to focus on. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies two missing elements in the paper: the value of neighborhood size h and an analysis of its influence on the model\"s performance, as well as the use of different hyperparameter sets per dataset. It suggests that the authors provide insights into how performance varies with a constant set of parameters. These actions are clear and concrete, giving the authors specific guidance on what needs to be addressed in their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"value of neighborhood size h\" and the \"analysis of its influence over the model\"s performance,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what is missing, namely an analysis of the influence of h on performance and the use of different hyperparameter sets per dataset. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper lacks an analysis of the value of neighborhood size h and its influence on the model\"s performance, which is considered a key parameter of the proposed strategy. It also notes the use of different hyperparameter sets per dataset, suggesting that this is not ideal. The comment provides a logical reasoning for the importance of analyzing the neighborhood size and its impact on performance, as well as the need for consistency in hyperparameter sets. However, it does not provide specific examples or references to support the claim, making it 3. The authors would need to infer the importance of these elements based on the provided reasoning. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two important areas for improvement in the paper. First, it points out the absence of an analysis of the value of neighborhood size h and its influence on the model\"s performance, which is a key parameter of the proposed strategy. This feedback is actionable as it suggests that the authors should provide insights into how the neighborhood size affects the model\"s performance, offering a clear direction for enhancing the paper. Second, the comment highlights the use of different hyperparameter sets per dataset, which is not ideal, and asks for insights into how performance varies with a constant set of parameters. This feedback is also actionable, as it prompts the authors to consider standardizing their hyperparameter settings. Overall, the comment provides clear and actionable feedback that can help the authors improve their draft, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the impact of imperfect multimodal data on the model, specifically addressing the effects of missing modalities on the construction of polynomial tensors. While it does not explicitly instruct the authors to address this issue, it implies that the authors should consider and discuss this aspect in their paper. The question is somewhat vague, as it does not provide specific guidance on how to address the issue or what kind of analysis or discussion would be most beneficial. However, the authors can infer that they need to explore and report on the effects of missing data on the model. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the impact of imperfect multimodal data on the model, specifically addressing the effects of missing modalities on the construction of polynomial tensors. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its inquiry about the effects of missing data and how the model handles it, providing a clear direction for the authors to consider. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the impact of imperfect multimodal data on the model, specifically addressing the effects of missing modalities on the construction of polynomial tensors. The comment does not present a claim or opinion but rather poses a question seeking clarification. It does not require verification as it is a request for information or clarification. Therefore, the label \"No\" is appropriate.", "helpfulness_rationale": "The review comment raises an important question about the impact of imperfect multimodal data on the model, specifically addressing the effects of missing modalities on the construction of polynomial tensors. It prompts the authors to consider the potential compounding effects of missing data and how the model might handle such situations. This feedback is 3 as it identifies a potential area for further exploration and discussion in the paper. However, it lacks specific guidance or suggestions on how the authors might address this issue, such as proposing methods or analyses to explore the effects of missing data. To be more helpful, the comment could include actionable steps or examples of how to investigate this aspect. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the SST dataset, specifically asking for statistics on the times negation or intensity words take effect. It suggests showing the frequency of words like \"nothing\" and how often they change the polarity of the context. While the comment implies that the authors should provide these statistics, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include these statistics and how to present them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"General Discussion\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the SST dataset and suggests providing statistics on the times negation or intensity words take effect, such as the frequency of words like \"nothing\" and their impact on polarity. This provides clear guidance on what additional information could be included to enhance the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question and a suggestion regarding the SST dataset. It asks for statistics on the times negation or intensity words take effect, such as the frequency of words like \"nothing\" and their impact on polarity. This is a request for additional information or analysis, rather than a claim or opinion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the SST dataset, suggesting that the authors provide statistics on the times negation or intensity words take effect. It specifically mentions the word \"nothing\" and its impact on polarity, which is a clear and actionable suggestion for improving the paper. By addressing this point, the authors can enhance the comprehensiveness and depth of their analysis, providing readers with a more detailed understanding of the dataset. However, the comment could be more helpful if it included additional suggestions or examples of how these statistics might be presented or analyzed. Overall, the feedback is 4 as it provides a clear direction for enhancing the paper, but it could be more comprehensive with further guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors consider alternative methods, such as freezing layers of the model or using parameterefficient methods like LoRA, for experimental comparison. While the comment implies that the authors should explore these options, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide detailed guidance on how to implement these suggestions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests considering alternative methods, such as freezing layers of the model or using parameterefficient methods like LoRA, for experimental comparison. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting alternative methods for comparison, but without clear grounding, the authors may struggle to determine where these suggestions should be implemented. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests considering alternative methods, such as freezing layers of the model or using parameterefficient methods like LoRA, for experimental comparison. The comment provides a logical reasoning by suggesting that these methods are natural to think about and could offer valuable insights for comparison. However, it does not provide specific examples or references to support the claim, which would strengthen the argument. Therefore, the comment is 3, as it offers a logical suggestion but lacks detailed evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment suggests considering alternative methods, such as freezing layers of the model or using parameterefficient methods like LoRA, for experimental comparison. This feedback is 3 as it provides a direction for the authors to explore additional approaches that could enhance their study. However, the comment lacks specific guidance on how to implement these suggestions or why they might be beneficial, which could be more helpful if it included detailed instructions or examples. Overall, the comment offers a valuable suggestion but could be more actionable with additional details, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to expand the related work section by comparing their work to strong baselines that use coordinates. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and concrete, making it 5.", "grounding_specificity_rationale": "The comment explicitly instructs the authors to expand the related work section by comparing their work to strong baselines that use coordinates. This provides clear guidance on what needs to be addressed, making the comment fully grounded. However, it does not specify which part of the related work section requires expansion or which baselines should be compared, leaving some room for ambiguity. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests expanding the related work section by comparing the work to strong baselines that use coordinates. However, it does not provide any specific examples, references, or detailed reasoning to support why this comparison is necessary or how it would enhance the paper. The lack of supporting evidence or detailed justification makes the claim difficult for the authors to understand and address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion to expand the related work section by comparing the work to strong baselines that use coordinates. This feedback is valuable as it directs the authors to enhance the context and relevance of their work by highlighting its relationship to existing strong baselines. However, the comment could be more helpful if it specified which baselines should be considered or provided examples of how to make these comparisons. Despite this, the feedback is 4 as it guides the authors toward a specific improvement that can strengthen their draft. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the experiments in the paper are limited to a single seed, which makes it difficult to assess the significance of performance differences and the impact of the proposed cycle consistency loss on convergence. The reviewer suggests conducting multiple seed experiments to provide a more robust evaluation. This feedback is clear and provides a direct action for the authors to take, which is to conduct additional experiments with multiple seeds. The suggestion is concrete, as it specifies exactly what needs to be done to improve the evaluation. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the issue of singleseed experiments, which limits the assessment of performance differences and the impact of the proposed cycle consistency loss. However, it does not specify which part of the paper discusses these experiments, making it weakly grounded. The comment is specific in suggesting the need for multiple seed experiments to provide a more robust evaluation. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments in the paper are limited to a single seed, which makes it difficult to assess the significance of performance differences and the impact of the proposed cycle consistency loss on convergence. The reviewer suggests conducting multiple seed experiments to provide a more robust evaluation. This claim is 3 as it provides a logical reasoning for the need for multiple seed experiments to ensure the robustness of the results. However, the comment lacks specific examples or references to support the claim that singleseed experiments are insufficient. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant limitation in the paper\"s experimental setup, specifically the use of a single seed for training. It highlights the difficulty in assessing the significance of performance differences and the impact of the proposed cycle consistency loss on convergence due to this limitation. The reviewer suggests conducting multiple seed experiments to provide a more robust evaluation. This feedback is clear and actionable, offering a specific improvement that the authors can implement to enhance the credibility and robustness of their results. However, the comment could be more helpful if it provided guidance on how to conduct these multiple seed experiments or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors toward a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation of the proposed method, noting that it requires an entire multiGPU setup for optimizations, which may limit its accessibility to potential users. However, the comment does not provide any explicit or implicit suggestions for how the authors might address this issue or improve the accessibility of their method. Without guidance on potential solutions or modifications, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a limitation of the proposed method, specifically mentioning that it requires an entire multiGPU setup for optimizations, which may limit its accessibility to potential users. However, it does not specify which part of the paper discusses this requirement or where the authors should address this issue. The authors can infer that it relates to the methodology or experimental setup sections, but the comment lacks full grounding as it does not explicitly mention these sections. Additionally, while it identifies a potential limitation, it does not provide specific guidance on how to address it or improve accessibility. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the proposed method requires an entire multiGPU setup for optimizations, which limits its accessibility to potential users. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without specific details or examples, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation of the proposed method, noting that it requires an entire multiGPU setup for optimizations, which may limit its accessibility to potential users. This is a relevant observation that could impact the practicality and applicability of the method. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the accessibility of their method. Without actionable feedback or specific recommendations, the authors are left without a clear path to enhance their draft. Therefore, the comment is 3, as it highlights a concern but lacks depth and actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly identifies a missing citation for the public skipgram data set in line 425. This provides a clear and direct action for the authors to take, which is to include the missing citation. The comment is specific and leaves no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L425,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of missing a citation for the public skipgram data set. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual statement about a missing citation in the paper. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting the absence of a citation for the public skipgram data set in line 425. This is a clear and actionable piece of feedback that the authors can address by including the missing citation. However, the comment does not provide any context or explanation about why this citation is important or how it relates to the overall content of the paper. While it highlights a specific error, it lacks depth and does not offer guidance on how this omission might impact the paper\"s validity or interpretation. Therefore, the comment is 3, as it provides a clear action but lacks comprehensive guidance for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests comparing the current system, which captures semantics through RNNbased models, with another system that also captures semantics. It implies that the authors should consider Ref[2] as a strong baseline for comparison. While the comment provides a clear action to compare the current system with another system that captures semantics, it does not specify which aspects of the current system should be compared or how to implement the comparison. The suggestion to use Ref[2] as a baseline is also vague, as it does not provide specific guidance on how to incorporate this reference into the comparison. Therefore, the comment is 4, as it identifies a clear action but lacks concrete details on how to execute it.", "grounding_specificity_rationale": "The comment suggests comparing the current system, which captures semantics through RNNbased models, with another system that also captures semantics. It implies that the authors should consider Ref[2] as a strong baseline for comparison. However, the comment does not specify which part of the paper this comparison should be made in, nor does it provide detailed guidance on how to implement the comparison. This lack of specificity and grounding makes it difficult for the authors to identify the exact areas that need attention. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests comparing the current system, which captures semantics through RNNbased models, with another system that also captures semantics. It implies that Ref[2] could be a strong baseline for comparison. However, the comment lacks specific reasoning or evidence to support why Ref[2] is a suitable baseline or how it would provide a meaningful comparison. Without detailed justification or examples, the claim remains 3, as the authors would need to infer the relevance of Ref[2] themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests comparing the current system, which captures semantics through RNNbased models, with another system that also captures semantics. It implies that this comparison could provide valuable insights into the performance of the current system. Additionally, the comment suggests using Ref[2] as a strong baseline for comparison, which could help the authors benchmark their work effectively. While the comment identifies a potential area for improvement and provides a specific suggestion, it lacks detailed guidance on how to implement the comparison or what specific aspects should be focused on. This limits the comment\"s helpfulness, as it provides a general direction but not a comprehensive plan for improvement. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the model\"s inability to fully identify the true sources in the triangle dataset. It questions whether one of the assumptions is not satisfied or if there are learning difficulties. However, it does not provide explicit guidance or suggestions on how the authors might address these issues or improve the model\"s performance. The comment implies that the authors should investigate these possibilities, but it lacks concrete steps or actions for the authors to take. As a result, the comment is vague and does not offer actionable advice, making it barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the model\"s performance in identifying true sources in the triangle dataset, but it does not specify which part of the paper discusses this issue. The authors cannot confidently determine which section or subsection this comment pertains to, making it weakly grounded. However, the comment is specific in questioning whether one of the assumptions is not satisfied or if there are learning difficulties. This provides some guidance on what the authors might need to address. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the model\"s performance in identifying true sources in the triangle dataset, questioning whether one of the assumptions is not satisfied or if there are learning difficulties. However, the comment does not provide any specific examples, reasoning, or references to support these claims. Without detailed justification or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the model\"s performance in identifying true sources in the triangle dataset. It raises questions about whether one of the assumptions is not satisfied or if there are learning difficulties, which is a clear indication of a potential weakness in the model\"s design or implementation. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address these issues or improve the model\"s performance. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to explain why and how their SE framework can help improve, similar to the feedback provided in comment 2. It also suggests that the authors should not just show what they have achieved but should explain the reasoning behind their achievements. The comment provides a clear action for the authors to take, which is to provide a detailed explanation of the benefits and mechanisms of their framework. Additionally, it offers a concrete suggestion to increase the rating based on the authors\" response. This makes the comment 5, as it gives the authors specific guidance on how to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: an explanation of why and how the SE framework can help improve, similar to comment 2. The comment provides a reference to a relevant work, which further enhances its specificity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a request for clarification and a suggestion to improve the paper. It does not contain any subjective claims, opinions, or judgments that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment provides clear and actionable feedback by asking the authors to explain why and how their SE framework can help improve, similar to a previous comment. It emphasizes the importance of not only showing what has been achieved but also explaining the reasoning and methodology behind the achievements. This feedback is specific and constructive, offering the authors a clear direction for enhancing their draft by providing a deeper understanding of their framework. However, the comment could be more helpful if it included suggestions on how to present this explanation or examples of what might be included. Overall, the comment is 4 as it guides the authors toward improving their paper by providing a more comprehensive explanation of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the user decoder at time step t, specifically why it only uses information up to time step t from the agent decoder rather than using information from all time steps. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this concern. The action is implicit and somewhat vague, as the authors are left to infer that they should clarify the rationale behind this choice. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the user decoder at time step t, specifically why it only uses information up to time step t from the agent decoder. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the user decoder\"s information usage, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the user decoder at time step t, specifically why it only uses information up to time step t from the agent decoder. This is a request for clarification rather than a claim, as it does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the user decoder at time step t, specifically why it only uses information up to time step t from the agent decoder. This is a relevant observation that could lead to a potential improvement in the paper, as it highlights a potential limitation or inconsistency in the methodology. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or clarify the rationale behind the choice. While it identifies a potential area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, as it provides some insight but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that a section on synonym identification is missing under similarity measurement, suggesting that the authors should include this section to describe how the multiplechoice task is approached. This feedback provides a clear and direct action for the authors to take, specifying exactly what needs to be added to their draft. The comment is explicit and concrete, giving the authors a clear understanding of what needs to be done to improve their paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions a missing section on synonym identification under similarity measurement, providing full grounding as the authors can accurately identify the part of the paper being addressed. It also specifies what is missing, namely a description of how the multiplechoice task is approached, which provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that a section on synonym identification is missing under similarity measurement, which would describe how the multiplechoice task is approached. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this section is necessary or how it would improve the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the importance of this section or how to address it. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks a section on synonym identification under similarity measurement, which would describe how the multiplechoice task is approached. This feedback is clear and actionable, as it provides a direct suggestion for improving the paper by adding a section that could enhance the understanding of the methodology. However, the comment could be more helpful if it offered additional guidance on what aspects should be included in this section or how it would contribute to the overall understanding of the paper. Despite this, the comment is 4 as it directs the authors to a clear area for improvement, making it a 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that an overview of the workflow and the model would be beneficial for understanding the work as a whole. However, it does not provide explicit instructions on how to create this overview or what specific elements should be included. The action is implicit and somewhat vague, as the authors can infer that they need to provide an overview but are not given concrete guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that an overview of the workflow and the model would be beneficial for understanding the work as a whole. However, it does not specify which part of the paper lacks this overview or where it should be included. The authors can infer that it might be in the introduction or the methodology section, but this inference is not explicit. The comment is specific in suggesting what is needed, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that an overview of the workflow and the model would be beneficial for understanding the work as a whole. However, it does not provide any specific reasoning, examples, or references to support why this overview is necessary or how it would enhance the paper. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment suggests that an overview of the workflow and the model would be beneficial for understanding the work as a whole. This feedback is 3 as it identifies a potential area for improvement by highlighting the need for a more comprehensive introduction. However, the comment lacks specificity and does not provide detailed guidance on how to incorporate this overview or what specific elements should be included. While it points out a general area for enhancement, it does not offer actionable steps or suggestions for improvement, leaving the authors with a vague idea of what needs to be addressed. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the potential bias in the sketch due to the need to compute the statistical dimension d_lambda of the design matrix A. It suggests that this computation requires the same runtime as solving the ridge regression problem, which could defeat the purpose of the approach. The comment implies that the authors should address this issue by discussing it in the paper, but it does not provide explicit instructions on how to do so. While the action is implicit, it is 3 as it points out a potential problem that the authors should consider. However, the lack of concrete guidance on how to address the issue limits its actionability.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the computation of the statistical dimension d_lambda of the design matrix A, which is crucial for debiasing the sketch. It also mentions a similar issue when computing the surrogate sketch. However, the comment does not specify which part of the paper discusses these issues, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but without explicit references, it is challenging to pinpoint the exact location. The comment is specific in detailing the issue with the computation and its potential impact on the approach, but the lack of grounding limits its effectiveness. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the statistical dimension d_lambda of the design matrix A is necessary for debiasing the sketch, but this computation requires the same runtime as solving the ridge regression problem, potentially defeating the purpose of the approach. The reviewer supports this claim by providing logical reasoning about the computational complexity involved. However, the comment lacks specific references or examples to fully substantiate the claim, making it 3. The authors would need to consider the reasoning and potentially seek additional evidence to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the debiasing of the sketch, specifically the need to compute the statistical dimension d_lambda of the design matrix A. It points out that this computation requires the same runtime as solving the ridge regression problem, which could defeat the purpose of the approach. The comment also mentions a similar issue when computing the surrogate sketch. While it highlights a critical concern, it does not provide specific suggestions or guidance on how the authors might address this issue or mitigate the potential bias. The feedback is 3 as it alerts the authors to a potential problem, but it lacks actionable advice, making it difficult for the authors to fully understand and improve their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to redefine Figure 3, specifying that the expected quantities are scalars but are shown as a vector. This provides a clear and direct action for the authors to take, ensuring that the figure accurately represents the data. The comment is specific and concrete, leaving no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the redefinition of the figure to show scalar quantities instead of vectors. This provides clear guidance on how to improve the figure, making the comment 5.", "verifiability_rationale": "The review point suggests that the quantities in Figure 3 should be represented as scalars rather than vectors. However, it does not provide any reasoning or evidence to support why this change is necessary or how it would improve the clarity or accuracy of the figure. Without additional context or explanation, the claim is difficult for the authors to understand and address, making it 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the paper. It identifies a particular issue with Figure 3, where the expected quantities are represented as vectors instead of scalars, and instructs the authors to redefine the figure accordingly. This feedback is clear and direct, offering a concrete step for the authors to take to enhance the clarity and accuracy of their presentation. By addressing this issue, the authors can improve the overall quality and readability of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises concerns about the ablation experiments, suggesting that they deserve a better experiment setup. However, it does not provide specific guidance on how to improve the setup or what questions need to be addressed. The comment lacks explicit instructions or concrete suggestions, leaving the authors uncertain about what changes to make. As a result, the action is implicit and vague, making it barely actionable.", "grounding_specificity_rationale": "The comment raises concerns about the ablation experiments, suggesting that they deserve a better experiment setup. However, it does not specify which part of the paper discusses these ablations or what specific questions arise regarding the setup. Without explicit references to sections or examples, the authors cannot confidently determine which part of the paper is being addressed. The comment is vague and lacks specificity, making it difficult for the authors to pinpoint the exact areas needing improvement. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a concern about the ablation experiments, suggesting that they deserve a better experiment setup. However, it does not provide specific examples or detailed reasoning to support why the current setup is inadequate. The comment lacks concrete evidence or references to justify the claim, making it difficult for the authors to understand and address the issue. As a result, the claim is 1.", "helpfulness_rationale": "The comment identifies a potential issue with the ablation experiments, suggesting that they deserve a better experiment setup. However, it does not provide specific guidance or suggestions on how to improve the setup or what aspects of the experiments need attention. Without actionable feedback or detailed advice, the authors are left with a general observation that does not offer a clear path for improvement. Therefore, the comment is 2, as it highlights an area for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the proposed models are useful for learning representations for lowfrequency words but lacks empirical evidence to support this claim. It suggests that the authors should explore this aspect further by providing empirical evidence. While the comment implies that the authors should conduct additional experiments or analyses to substantiate their claims, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to conduct these experiments or what metrics to use. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the aspect of the paper being addressed, namely the proposed models\" usefulness for learning representations for lowfrequency words. It also specifies the issue by pointing out the lack of empirical evidence to test the hypothesis and the need for deeper exploration. However, it does not provide specific guidance on how to address these issues or what additional evidence or analysis would be beneficial. Therefore, the comment is 4, aligning with category 4.", "verifiability_rationale": "The review point claims that the proposed models are useful for learning representations for lowfrequency words but lacks empirical evidence to support this claim. The reviewer suggests that the authors should explore this aspect further, which is a reasonable request. However, the comment does not provide specific examples or references to substantiate the claim, making it 3. The authors would need to infer the reasoning behind the suggestion and potentially conduct additional experiments to fully understand and address the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks empirical evidence to support its claims about the usefulness of the proposed models for learning representations of lowfrequency words. It suggests that the authors should explore this aspect further by providing empirical evidence, which is a clear and actionable piece of feedback. However, the comment could be more helpful if it offered specific suggestions on how to conduct these empirical tests or what metrics to use. Despite this, the feedback provides a valuable direction for the authors to enhance their draft, making it 4. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the resolution of the 3D voxel and its impact on the network\"s computational and memory costs. It suggests that studying the importance of the global feature in Section 4.2 by comparing with different resolutions of voxel features would be more convincing. The comment also points out that reducing the resolution to 1x1x1 is equivalent to using a single global feature. While the comment implies that the authors should conduct this comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct the suggested comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the resolution of the 3D voxel and its impact on the network\"s computational and memory costs. The comment suggests studying the importance of the global feature by comparing with different resolutions of voxel features, which provides a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the resolution of the 3D voxel and its impact on the network\"s computational and memory costs. It suggests that studying the importance of the global feature by comparing with different resolutions of voxel features would be more convincing. The comment also points out that reducing the resolution to 1x1x1 is equivalent to using a single global feature. While the comment provides a logical reasoning for the suggestion, it lacks specific examples or references to support the claim about the computational and memory costs. This makes the claim 3, as the authors would need to conduct additional analysis to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a pertinent question about the resolution of the 3D voxel and its impact on the network\"s computational and memory costs. It suggests that studying the importance of the global feature by comparing with different resolutions of voxel features would be more convincing. The comment also points out that reducing the resolution to 1x1x1 is equivalent to using a single global feature, which could be a valuable insight for the authors. While the comment identifies a potential area for improvement, it lacks specific guidance on how to conduct the comparison or what specific resolutions to consider. This limits the comment\"s helpfulness, as it provides a direction but not a detailed roadmap for improvement. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the error analysis on the movie dataset is missing, which is a clear action for the authors to take. It also provides a specific suggestion for improvement by indicating that other researchers need to know the cases where the model fails. This feedback is concrete and direct, giving the authors a clear understanding of what needs to be addressed in their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment addresses the absence of an error analysis on the movie dataset, which is a specific aspect of the paper. However, it does not explicitly mention which part of the paper discusses the movie dataset, making it weakly grounded. The comment is specific in its request for an error analysis to help other researchers understand the model\"s failures. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the error analysis on the movie dataset is missing, which is a critical aspect for other researchers to continue working on the task. However, the comment does not provide any specific examples or detailed reasoning to support why this analysis is necessary or how it would benefit the research community. Without such evidence or explanation, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of an error analysis on the movie dataset. This feedback is valuable as it highlights a critical area that needs attention to ensure the paper\"s contribution is fully understood and reproducible. However, the comment could be more helpful if it provided suggestions on how to conduct the error analysis or what specific aspects of the dataset should be analyzed. Despite this, the comment is 4 as it directs the authors to a crucial area for improvement, making it actionable. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that it is difficult to see trends in Table 3, particularly regarding the behavior of PM+CL compared to PM or CL alone. It also suggests that it would be interesting to see development set trends with respect to these hyperparameters. While the comment implies that the authors should provide additional analysis or trends, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to add more analysis but are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a difficulty in seeing trends and suggests that it would be interesting to see development set trends with respect to hyperparameters. This provides clear guidance on what needs to be addressed in the table. Therefore, this comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point suggests that it is difficult to see trends in Table 3, particularly regarding the behavior of PM+CL compared to PM or CL alone. The reviewer also suggests that it would be interesting to see development set trends with respect to these hyperparameters. However, the comment lacks specific examples or detailed reasoning to support why these trends are not apparent or how they could be analyzed further. Without additional context or evidence, the claim remains somewhat vague, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 3, noting that it is difficult to see trends in the behavior of PM+CL compared to PM or CL alone. It suggests that it would be interesting to see development set trends with respect to these hyperparameters. This feedback is clear and actionable, as it points out a potential area for improvement in the analysis and presentation of results. By suggesting a specific aspect to focus on, the comment provides the authors with a clear direction for enhancing their draft. However, it could be more helpful if it included additional guidance on how to present these trends or what specific analyses might be beneficial. Overall, the comment is 4, as it effectively directs the authors to enhance their results presentation, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a difficulty in understanding Figure 5 due to the presence of many lines on top of each other. It suggests that the authors could report flops or model size to make the metrics more concrete. While the comment implies that the authors should include additional information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to report flops or model size. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the figure, namely the difficulty in understanding due to the overlapping lines, and suggests that reporting flops or model size would make the metrics more concrete. This provides clear guidance on what needs to be addressed to improve the figure. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that it is difficult to understand Figure 5 due to the presence of many lines on top of each other. It suggests that the authors could report flops or model size to make the metrics more concrete. However, the comment lacks specific examples or detailed reasoning to support why these metrics would improve understanding or make the figure more concrete. Without additional context or evidence, the claim is 3, as it provides a suggestion but lacks sufficient justification or examples to fully substantiate the need for these additional metrics. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 5, noting that the presence of many lines on top of each other makes it difficult to understand. It suggests that reporting flops or model size would make the metrics more concrete, providing a clear and actionable suggestion for improvement. By addressing this feedback, the authors can enhance the clarity and comprehensibility of their figures, which is crucial for effective communication of their results. However, the comment could be more helpful if it provided additional context or examples of how to report flops or model size effectively. Overall, the feedback is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with further guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point indicates that some details of the proposed method are missing, as noted in the questions section below. However, it does not specify which details are missing or how the authors should address this issue. The comment lacks explicit guidance or concrete suggestions on what needs to be added or clarified, leaving the authors uncertain about how to improve their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment indicates that some details of the proposed method are missing, as noted in the questions section below. However, it does not specify which part of the paper these questions are from, nor does it provide details on what specific details are missing. This lack of explicit reference to a specific section or element of the paper makes it difficult for the authors to pinpoint the exact areas needing attention. Additionally, the comment lacks specificity regarding the missing details, leaving the authors uncertain about what needs to be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that \"some details of the proposed method are missing,\" but it does not provide any specific examples or reasoning to support this claim. Without detailed explanation or references to what details are missing, the authors may find it challenging to understand and address the issue. The comment lacks verifiability as it does not offer sufficient evidence or justification for the claim, making it difficult for the authors to improve their work based on this feedback. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment indicates that some details of the proposed method are missing, as noted in the questions section below. However, it does not specify which details are missing or provide any guidance on how the authors might address this issue. Without specific feedback or suggestions, the authors are left without actionable steps to improve their draft. The comment lacks depth and clarity, making it 2 at best. Therefore, it aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should evaluate the performance of EIGNN with respect to oversmoothing under standard settings on realworld datasets, particularly in comparison with variants that focus on dealing with oversmoothing, such as GCNII. This comment explicitly states an action for the authors to take, which is to conduct additional evaluations and comparisons. However, it does not provide specific guidance on how to implement these evaluations or which datasets to use. While the action is clear, the lack of concrete details on execution makes the comment 3.", "grounding_specificity_rationale": "The comment suggests evaluating the performance of EIGNN with respect to oversmoothing under standard settings on realworld datasets, particularly in comparison with variants focusing on dealing with oversmoothing, such as GCNII. However, it does not specify which part of the paper this evaluation should be included in, making it weakly grounded. The comment is specific in suggesting a particular area of interest and a comparison with existing work, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact location for improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it would be interesting to evaluate the performance of EIGNN with respect to oversmoothing under standard settings on realworld datasets, particularly in comparison with variants focusing on dealing with oversmoothing, such as GCNII. The comment provides a logical reasoning for the suggestion, as it highlights the importance of evaluating the model\"s performance in a standard setting and in comparison with existing work. However, it does not provide specific examples or references to support the claim, which would strengthen the argument. Therefore, the comment is 3, as it provides a clear direction for improvement but lacks detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment suggests an interesting direction for further evaluation of the EIGNN model, specifically in terms of its performance with respect to oversmoothing under standard settings on realworld datasets. It highlights the importance of comparing EIGNN with variants that focus on dealing with oversmoothing, such as GCNII. This feedback is clear and actionable, as it provides a specific area for the authors to explore and potentially improve their work. However, the comment could be more helpful if it included suggestions on how to conduct these evaluations or which datasets to use. Overall, the comment is 4 as it offers a valuable direction for enhancing the paper, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a missing part in the approach method, specifically the lack of a separate section or subsection to introduce the inference strategy. It clearly states that the authors should include a part or subsection to explain how to use multiple prompts in the test stage. This feedback provides a direct and concrete action for the authors to take, ensuring they know exactly what needs to be added to their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"approach method,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of a separate part or subsection to introduce the inference strategy, particularly how to use multiple prompts in the test stage. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the approach method lacks a separate part or subsection to introduce the inference strategy, specifically how to use multiple prompts in the test stage. However, the comment does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks clarity, namely the absence of a separate part or subsection to introduce the inference strategy. It highlights the need to explain how multiple prompts are used in the test stage, which is a critical aspect of the approach method. This feedback is clear and actionable, as it provides a direct suggestion for improvement by specifying what the authors should include in their draft. However, it could be more helpful if it offered additional guidance on how to structure this section or provided examples of similar approaches. Overall, the comment is 4, as it effectively directs the authors to enhance the clarity and completeness of their paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and concerns about the experiment results and the realworld applications of the proposed problem setting. It suggests that the authors should discuss the results of the Streetview experiment and whether MaxGapTop2UCB is better than the other methods. Additionally, it questions the applicability of the new problem setting to sorting/ranking and the computational complexity of the proposed algorithms when applied to ranking problems. While the comment identifies areas that need clarification and discussion, it does not provide explicit instructions or concrete steps for the authors to follow. The feedback is 3 as it highlights important aspects that need further exploration, but it lacks specific guidance on how to address these issues. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the experiment results\" and \"the realworld applications of this new problem setting,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, such as discussing the results of the Streetview experiment and the applicability of the proposed algorithms to sorting/ranking problems. The comment provides specific questions and concerns, making it clear and actionable. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises several claims and questions, making it a combination of factual statements and claims. The first claim about the experiment results suggests that the authors should discuss whether MaxGapTop2UCB is better than the other methods based on the Streetview experiment. This claim is 3 as it highlights a specific aspect of the results that could be discussed further. The second claim questions the realworld applications of the new problem setting, specifically the applicability to sorting/ranking and the computational complexity of the proposed algorithms. This claim is 3 as it raises valid concerns about the practicality of the approach, but it lacks specific examples or references to support the critique. The minor details section provides factual information without claims or suggestions. Overall, the review point contains a mix of verifiable and nonverifiable elements, justifying a score of 3.", "helpfulness_rationale": "The review comment provides a mix of factual observations and suggestions for improvement. It highlights the need for more discussion on the experiment results, specifically questioning whether MaxGapTop2UCB is better than the other methods based on the Streetview experiment. It also raises concerns about the realworld applications of the new problem setting, questioning the applicability to sorting/ranking and the computational complexity of the proposed algorithms. While the comment identifies important areas for clarification and improvement, it lacks specific guidance or detailed suggestions on how the authors might address these issues. The feedback is 3 as it points out areas that need further exploration, but it could be more actionable with additional direction. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the low results obtained using only ML in the ablation experiments, noting that they are even lower than some simple early methods. It suggests that more explanations are needed. While the comment implies that the authors should provide additional explanations, it does not explicitly instruct them to do so or offer specific guidance on what aspects of the results or explanations should be addressed. The action is implicit and somewhat vague, as the authors can infer that they need to provide more explanations but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the low results obtained using only ML in the ablation experiments, noting that they are even lower than some simple early methods. However, it does not specify which part of the paper this observation is based on, making it difficult for the authors to pinpoint the exact section that needs attention. The comment suggests that more explanations are needed, but it does not provide specific guidance on what aspects of the results or explanations should be addressed. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a question about the low results obtained using only ML in the ablation experiments, noting that they are even lower than some simple early methods. The reviewer suggests that more explanations are needed. However, the comment lacks specific examples or references to support the claim that the results are lower than expected, making it difficult for the authors to understand the basis of the comparison. Without detailed evidence or reasoning, the claim remains somewhat vague, making it challenging for the authors to address the issue effectively. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment raises a question about the low results obtained using only ML in the ablation experiments, noting that they are even lower than some simple early methods. It suggests that more explanations are needed to understand this observation. While the comment identifies a potential issue, it lacks specific guidance or suggestions on how the authors might address this concern or provide additional explanations. The feedback is 3 as it points out a potential area for improvement, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the absence of an ablation analysis in the main paper, which makes it challenging to identify the source of a small performance gain. While the comment implies that an ablation analysis should be included, it does not explicitly instruct the authors to conduct one. The action is implicit and somewhat vague, as the authors can infer that they need to add an ablation analysis but are not provided with specific guidance on how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of ablation analysis in the main paper, which makes it difficult to identify the source of a small performance gain. However, it does not specify which part of the paper this issue pertains to, such as a specific section or experiment. The authors can infer that it relates to the results or methodology sections, but this inference is not explicit. The comment is specific in pointing out the need for an ablation analysis, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the lack of ablation analysis makes it difficult to pinpoint the source of a small performance gain. This is a subjective opinion based on the reviewer\"s expectation of what should be included in the paper. However, the comment does not provide specific examples or detailed reasoning to support why an ablation analysis is necessary or how it would improve the paper. Without additional context or evidence, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The comment identifies a significant gap in the paper, specifically the lack of an ablation analysis, which makes it difficult to pinpoint the source of a small performance gain. This feedback is valuable as it highlights a critical area for improvement that could enhance the paper\"s clarity and understanding of the results. However, the comment does not provide specific suggestions or guidance on how to conduct the ablation analysis or what components to focus on. While it points out a clear weakness, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the hypothesis is interesting but not well verified by the designed experiment. It highlights a specific issue with the experimental setup, noting that the base model is trained on the adversarial set only, while models in conventional methods are trained on both the original training set and the generated adversarial examples. The reviewer recommends comparing the model trained on the original dataset with that trained on the mixture to highlight the impact of the augmented adversarial examples. This feedback is explicit and provides a clear action for the authors to take, making it 5. The authors know exactly what needs to be done to improve the experiment and its motivation, which is to make it more convincing. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the experimental setup, suggesting a comparison between models trained on the original dataset and those trained on the mixture to highlight the impact of augmented adversarial examples. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the hypothesis is interesting but not well verified by the designed experiment. It provides a specific critique of the experimental setup, noting that the base model is trained on the adversarial set only, while models in conventional methods are trained on both the original training set and the generated adversarial examples. The reviewer suggests comparing the model trained on the original dataset with that trained on the mixture to highlight the impact of the augmented adversarial examples. This feedback is supported by logical reasoning and a clear explanation of the issue, making it 4. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental setup, noting that the base model is trained on the adversarial set only, while models in conventional methods are trained on both the original training set and the generated adversarial examples. It suggests that a more comprehensive comparison is needed, recommending that the authors compare the model trained on the original dataset with that trained on the mixture to highlight the impact of the augmented adversarial examples. This feedback is clear and actionable, providing the authors with a specific direction to improve the validity and persuasiveness of their experimental results. By addressing this critique, the authors can enhance the credibility and impact of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point states that the CNN experiments are not fully convincing, but it does not provide any specific details or suggestions on how to improve them. There is no explicit or implicit action for the authors to take, nor are there any concrete steps outlined to enhance the credibility of the experiments. As a result, the comment lacks actionability, leaving the authors without guidance on how to address the issue. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment mentions that the CNN experiments are not fully convincing, but it does not specify which part of the paper these experiments are discussed in, nor does it provide details on what aspects of the experiments are not convincing. This lack of specificity and grounding makes it difficult for the authors to identify the exact areas that need attention or improvement. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the CNN experiments are not fully convincing, but it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment indicates that the CNN experiments are not fully convincing, but it does not provide any specific details or examples to support this claim. Without additional context or suggestions for improvement, the authors are left without actionable feedback on how to enhance the credibility of their experiments. The comment lacks depth and specificity, making it 2 at best. Therefore, it aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to mention that the results for model (3) (Chung et al. 2016) for CsEn were computed by themselves, as they are not reported in the papers. This provides a clear and direct action for the authors to take, ensuring that they accurately represent the source of the results. The comment is specific and concrete, leaving no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the results for model (3) (Chung et al. 2016) for CsEn, noting that these results were not taken from the papers and suggesting that the authors should mention if they computed these results themselves. This provides clear guidance on what needs to be addressed. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results for model (3) (Chung et al. 2016) for CsEn were not taken from the papers, as they are not reported. The reviewer suggests that if the authors computed these results themselves, they should mention it. This claim is 3 as it is based on the observation that the results are not reported in the papers. However, the comment lacks specific references or detailed reasoning to fully substantiate the claim. The authors would need to verify the claim themselves by checking the original papers or other sources. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the results presented in Table 1, noting that the results for model (3) (Chung et al. 2016) for CsEn were not taken from the papers, as they are not reported. The comment suggests that if the authors computed these results themselves, they should mention it. This feedback is clear and actionable, providing the authors with a direct way to improve the transparency and accuracy of their results. By addressing this issue, the authors can enhance the credibility and reliability of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should compare their results with stateoftheart (SoTA) approaches, specifically mentioning HateXplain models. This is an explicit action that provides a clear direction for the authors to follow. The suggestion is concrete, as it specifies a particular model to compare with, making it easy for the authors to understand and implement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests comparing the results with stateoftheart approaches, specifically mentioning HateXplain models. However, it does not specify which part of the paper this comparison should be made in, such as the results section or a specific experiment. This lack of explicit reference to a particular section makes it weakly grounded. The comment is specific in suggesting a comparison with HateXplain models, which provides a clear direction for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests comparing the results with stateoftheart approaches, specifically mentioning HateXplain models. However, it does not provide any reasoning or evidence to support why this comparison is necessary or how it would benefit the paper. The suggestion is general and lacks specific justification or examples, making it difficult for the authors to understand the rationale behind the recommendation. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should compare their results with stateoftheart (SoTA) approaches, specifically mentioning HateXplain models. This feedback is 3 as it provides a clear direction for the authors to enhance their work by benchmarking against established models. However, the comment lacks depth and does not explain why this comparison is important or how it might impact the paper\"s contribution. Additionally, it does not offer specific guidance on how to conduct the comparison or what aspects to focus on. While it points the authors in the right direction, the feedback could be more comprehensive and actionable to be fully helpful. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the rationale behind using freezing in the MLS selection process and suggests using an adaptive method instead. While it implies that the authors should provide a clearer explanation for their choice of freezing, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the issue or what additional information should be included. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment questions the rationale behind using freezing in the MLS selection process and suggests using an adaptive method instead. However, it does not specify which part of the paper discusses the freezing method, making it weakly grounded. The comment is specific in its critique of the freezing method and suggests an alternative approach, but it lacks explicit references to the sections where this method is discussed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the rationale behind using freezing in the MLS selection process and suggests using an adaptive method instead. However, the comment does not provide any supporting evidence, reasoning, or references to justify why freezing is not a suitable choice or why an adaptive method would be better. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid question about the rationale behind using freezing in the MLS selection process. It suggests that if an adaptive method is considered good, then it should be used to choose the subset instead of freezing. This feedback is 3 as it prompts the authors to clarify their choice of methodology and provides a potential alternative approach. However, the comment lacks depth and does not offer specific guidance on how to address the issue or what additional information should be included. To be more helpful, the comment could suggest ways to justify the use of freezing or provide examples of how an adaptive method might be applied. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the issue addressed in the existing work is also solved in the proposed knowledgeCLIP model. It suggests that the authors perform a similar analysis, such as adding negation or changing entities in text, to see if the KGaugmented method can robustly handle these changes. While the comment implies that the authors should conduct this analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement the suggested analysis. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about whether the issue addressed in existing work is also solved in the proposed knowledgeCLIP model. It suggests that the authors perform a similar analysis, such as adding negation or changing entities in text, to see if the KGaugmented method can robustly handle these changes. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. It is specific in suggesting a particular analysis that could be conducted, but without explicit references to the paper, the authors may find it challenging to pinpoint the exact section needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about whether the issue addressed in existing work is also solved in the proposed knowledgeCLIP model. It suggests that the authors perform a similar analysis, such as adding negation or changing entities in text, to see if the KGaugmented method can robustly handle these changes. The comment references an external work (https://arxiv.org/abs/2104.06378) that has done closelyrelated analyses, providing some support for the suggestion. However, the comment lacks specific examples or detailed reasoning from the authors\" work, making it 3. The authors would need to further develop the claim with their own analysis to fully substantiate it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises an interesting question about whether the issue addressed in existing work is also solved in the proposed knowledgeCLIP model. It suggests that the authors perform a similar analysis, such as adding negation or changing entities in text, to see if the KGaugmented method can robustly handle these changes. This feedback is 3 as it provides a specific suggestion for further analysis that could enhance the paper. However, the comment could be more helpful if it offered more detailed guidance on how to conduct this analysis or what specific aspects to focus on. Overall, the comment provides a valuable direction for the authors to consider, but it lacks depth and actionable details, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide more explanation about how novel values in the test set are handled. This is an explicit request for additional clarification, which is clear and actionable. The authors know exactly what needs to be done to improve their draft by adding more explanation on this topic. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions line 97, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the authors should provide more explanation about how novel values in the test set are handled. This provides clear guidance on what needs to be addressed to improve the clarity of the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide more explanation about how novel values in the test set are handled. This is a request for clarification rather than a claim or opinion. It does not contain any subjective statements, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment suggests that the authors should provide more explanation about how novel values in the test set are handled. This is a specific and actionable piece of feedback that can help the authors clarify an aspect of their methodology that may be unclear to readers. By addressing this suggestion, the authors can enhance the clarity and comprehensibility of their paper. However, the comment could be more helpful if it provided additional context or examples of what specific information should be included. Overall, the feedback is 4 as it directs the authors to a clear area for improvement, but it could be more comprehensive with further guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the authors can avoid using \"1) and2)\" by using a generic external knowledge base, as demonstrated in Figure 3. However, the comment is vague because it does not specify which parts of the paper should be revised or how to implement the suggestion. The authors are left without clear guidance on how to address the issue of confusion in the writing. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that \"1) and2)\" can be avoided by using a generic external knowledge base, as shown in Figure 3. However, it does not specify which parts of the paper these references are from, making it weakly grounded. The comment also lacks specificity as it does not detail what is confusing or how the writing could be improved. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that \"1) and2)\" can be avoided by using a generic external knowledge base, as shown in Figure 3. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this approach would be beneficial or how it would address the issues mentioned. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the authors can avoid using \"1) and2)\" by using a generic external knowledge base, as shown in Figure 3. However, the comment lacks specificity and does not provide detailed guidance on how to implement this suggestion or what aspects of the paper should be revised. Additionally, the comment mentions that the writing is confusing, but it does not specify which parts are confusing or how they could be clarified. This lack of detail and actionable feedback makes the comment 2, as it provides only a general direction without concrete steps for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the methodology used to select 0.6 for glove embedding similarity and suggests exploring alternative loss functions, such as replacing the min with a mean or NDCG. While the comment implies that the authors should provide more details on their methodology and consider alternative loss functions, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address these points. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the methodology used to select 0.6 for glove embedding similarity and suggests exploring alternative loss functions. However, it does not specify which part of the paper discusses this methodology or where the authors should address these questions. The authors might infer that it relates to the experimental setup or methodology sections, but this inference is not explicit. The comment is specific in suggesting alternative loss functions but lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point consists of questions and suggestions, such as asking about the methodology used to select 0.6 for glove embedding similarity and suggesting alternative loss functions. These are not claims or opinions that require verification. The comment is factual and descriptive, fitting the \"No\" label.", "helpfulness_rationale": "The review comment raises several questions and suggestions that could help the authors improve their draft. It questions the methodology used to select 0.6 for glove embedding similarity and suggests performing kcrossvalidation to validate this choice. Additionally, it encourages the authors to explore alternative loss functions, such as replacing the min with a mean or NDCG, which could potentially impact the results. While the comment provides valuable insights and prompts for further exploration, it lacks specific guidance on how to implement these suggestions or address the questions. Therefore, it is 3, as it offers direction but not comprehensive actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a missing indepth analysis of the experimental results, specifically questioning why the improvements of models are limited on the offense detection dataset and significant on the coarse stereotype set. While the comment identifies a gap in the analysis, it does not provide explicit guidance on how the authors should address this issue or what specific aspects of the analysis should be included. The action is implicit and somewhat vague, as the authors are left to infer that they need to conduct a more detailed analysis but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"experimental results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a missing indepth analysis and provides a concrete example of what is lacking: the analysis of why improvements are limited on the offense detection dataset and significant on the coarse stereotype set. This provides clear guidance on what the authors need to address in their analysis. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a missing indepth analysis of the experimental results, specifically questioning why the improvements of models are limited on the offense detection dataset and significant on the coarse stereotype set. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks depth, namely the analysis of experimental results. It points out a gap in understanding why the improvements of models are limited on the offense detection dataset and significant on the coarse stereotype set. This feedback is clear and actionable, as it prompts the authors to conduct a more indepth analysis to explain these observations. However, the comment could be more helpful if it provided suggestions on how to approach this analysis or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests several specific actions for the authors to take, including training on labeled data, incorporating input mask explanation annotations for a few examples, and using modern backbone baselines for feature extraction. The reviewer also provides a concrete suggestion to increase the number of convolutional layers to ensure robustness. While the comment is explicit in its actions, it does not provide detailed guidance on how to implement these suggestions, such as specific methods or techniques to use for training or feature extraction. Therefore, the comment is 4, as the authors know what needs to be done but may need further guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific aspects of the paper, such as the \"new method of training on the labeled data\" and the suggestion to use modern backbone baselines like Resnet50 or DenseNet121 for feature extraction. It also specifies the issue with the current approach, noting that three convolutional layers are insufficient for nonsynthetic data. However, the comment lacks specificity regarding the input mask explanation annotations and does not provide detailed guidance on how to address the skepticism about the method\"s effectiveness. Therefore, the comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point suggests that the current method of training on labeled data with input mask explanation annotations for a few examples may not be effective, citing the use of \"3 conv layers\" as insufficient for nonsynthetic data. The reviewer acknowledges that this is their opinion and that it is independent of the rest of the review. The comment lacks specific evidence or references to support the claim that \"lots of such robustness/domain invariance interventions have been proposed and have failed,\" making it difficult for the authors to verify or address the concern. Therefore, the comment is considered 2, as it provides some reasoning but lacks detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment provides specific and actionable feedback, suggesting improvements to the methodology and experimental setup. It recommends incorporating input mask explanation annotations for a few examples and using modern backbone baselines for feature extraction, which could enhance the robustness and effectiveness of the approach. The comment also addresses a potential weakness by suggesting an increase in the number of convolutional layers, which is a concrete step to improve the method\"s applicability to nonsynthetic data. However, the comment does not elaborate on why the current approach might not be effective or provide additional context or examples to support the skepticism about the method\"s robustness. While the feedback is 4, it could be more comprehensive with further explanation or examples. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should ensure that the baseline is fully tuned with the same resources as the proposed method to ensure a fair comparison. This is an explicit action, as it directly instructs the authors to address a specific issue related to the hyperparameter tuning of the baseline. However, the comment does not provide detailed guidance on how to implement this action, such as which hyperparameters to focus on or how to conduct the tuning. While the action is clear, the lack of concrete details makes it 3.", "grounding_specificity_rationale": "The comment addresses the introduction of multiple hyperparameters and the extensive hyperparameter search, specifically mentioning \"temperature, penalty, and threshold.\" However, it does not specify which part of the paper discusses these hyperparameters or the hyperparameter search, making it weakly grounded. The comment is specific in suggesting that the baseline should be fully tuned with similar resources as the proposed method for a fair comparison. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper introduces multiple hyperparameters and conducts an extensive hyperparameter search, which could impact the fairness of the comparison with the proposed method. The reviewer recommends ensuring that the baseline is fully tuned with similar resources as the proposed method. However, the comment lacks specific examples or references to support the claim about the impact of hyperparameters on the comparison. Without detailed evidence or examples, the claim is 3, as it provides a logical suggestion but lacks sufficient justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the fairness of the comparison between the proposed method and the baseline due to the extensive hyperparameter search. It suggests that ensuring the baseline is fully tuned with similar resources as the proposed method could improve the fairness of the comparison. This feedback is clear and actionable, as it highlights a specific area for improvement and provides a concrete suggestion for addressing it. However, the comment could be more helpful if it offered guidance on how to conduct the hyperparameter tuning or provided examples of similar resources. Overall, the comment is 4, as it directs the authors to a critical aspect of their work that requires attention, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a mistake in the definition of perplexity and provides a correction. It also points out that the equation presented does not look like perplexity but rather like crossentropy. This feedback is clear and provides direct actions for the authors to take, such as correcting the definition of perplexity and ensuring that the equation accurately represents perplexity. The comment is 5 as it specifies exactly what needs to be corrected and how to do so.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific line number (\"L259\") and the equation (\"Eq1\"), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly points out the incorrect definition of perplexity and provides a correction, as well as noting that the equation does not look like perplexity but rather like crossentropy. This level of detail guides the authors on what needs to be corrected or clarified. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the definition of perplexity at line 259 is incorrect and that the equation (Eq1) does not look like perplexity but rather like crossentropy. This claim is verifiable as it provides a clear and specific correction to the definition of perplexity, which is a wellestablished concept in natural language processing. The comment also points out the discrepancy between the definition and the equation, which helps the authors understand the issue. However, the comment could be strengthened by providing references or examples to further substantiate the claim. Therefore, the comment is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment identifies a specific error in the definition of perplexity, pointing out that the explanation provided in the paper is incorrect. It also notes that the equation presented does not look like perplexity but rather like crossentropy. This feedback is clear and actionable, as it directly points out a mistake in the paper and provides a correction. By addressing this issue, the authors can ensure that their definition and equation are accurate, which is crucial for the understanding and validity of their work. However, the comment could be more helpful if it provided additional context or examples to further clarify the distinction between perplexity and crossentropy. Overall, the comment is 4 as it guides the authors toward a significant improvement in the accuracy of their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should add more baselines for graph classification tasks, specifically mentioning MVGRL[4] and gptgnn[5] as examples. It also requests that these baselines be tested on common datasets. This feedback provides a clear and concrete action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The suggestion is explicit and detailed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"graph classification task,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the baselines MVGRL[4] and gptgnn[5], and requests the addition of more baselines from graph contrastive learning and their testing on common datasets. This provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point claims that the baseline for the graph classification task is insufficient, specifically mentioning the absence of MVGRL[4] and gptgnn[5]. The reviewer suggests adding more baselines from graph contrastive learning and testing them on common datasets. However, the comment lacks specific reasoning or evidence to support why these particular baselines are necessary or how they would improve the study. The suggestion is 3 as it provides a direction for improvement but lacks detailed justification or examples, making it difficult for the authors to fully understand the basis of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific weakness in the paper, namely the insufficient comparison of baselines in the graph classification task. It points out the absence of MVGRL[4] and gptgnn[5] as potential baselines and suggests adding more baselines from graph contrastive learning and testing them on common datasets. This feedback is clear and actionable, providing the authors with a concrete direction for improving their draft by expanding the baseline comparisons. However, the comment could be more helpful if it included specific suggestions on which additional baselines to consider or why these particular ones are relevant. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a concern about the evaluation of the proposed strategies, specifically the consideration that purifying the input image before passing it to the model and using an adaptive attack against the edge map defense strategies could result in structural damage to the edge map. The reviewer suggests evaluating the proposed defense against an adversarial attack that crafts adversarial examples to produce minimal structural alterations to the edge map while misleading model predictions. This feedback provides a clear and explicit action for the authors to take, namely to evaluate their defense against such an adversarial attack. The suggestion is concrete, as it specifies the type of attack to consider and the goal of minimal structural alterations. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the evaluation of the proposed strategies, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the need to evaluate the proposed defense against an adversarial attack that minimizes structural alterations to the edge map while misleading model predictions. This provides clear guidance on what needs to be addressed in the evaluation section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the evaluation of the proposed strategies, specifically the consideration that purifying the input image before passing it to the model and using an adaptive attack against the edge map defense strategies could result in structural damage to the edge map. The reviewer suggests evaluating the proposed defense against an adversarial attack that crafts adversarial examples to produce minimal structural alterations to the edge map while misleading model predictions. This claim is 4 as it provides a logical reasoning for the need to evaluate the defense against such an attack. However, it lacks specific examples or references to support the claim fully, making it 3. Therefore, the comment aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a critical issue with the evaluation of the proposed strategies, specifically the consideration that purifying the input image before passing it to the model and using an adaptive attack against the edge map defense strategies could result in structural damage to the edge map. The reviewer suggests that the authors should evaluate their defense against an adversarial attack that crafts adversarial examples to produce minimal structural alterations to the edge map while misleading model predictions. This feedback is clear and actionable, providing a specific direction for the authors to improve their evaluation methodology. By addressing this concern, the authors can strengthen the robustness and effectiveness of their defense strategies. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a perceived weakness in the analysis, specifically mentioning the lack of evidence for the existence and smoothness of the solution of SDE (2a)(2d) and any guarantees of the discretization. However, it does not provide explicit guidance on how the authors should address these issues or what specific steps they should take to strengthen their analysis. The comment implies that the authors should provide additional evidence or guarantees, but it lacks concrete instructions on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the provided analysis\" and \"SDE (2a)(2d),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of evidence for the existence and smoothness of the solution of SDE (2a)(2d) and any guarantees of the discretization. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the provided analysis is weak in light of theoretical work on sampling and particlebased optimization methods. It specifically mentions the lack of evidence for the existence and smoothness of the solution of SDE (2a)(2d) and any guarantees of the discretization. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence makes the claim 3, as it requires the authors to infer the specific issues and address them accordingly. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of weakness in the paper, namely the lack of evidence for the existence and smoothness of the solution of SDE (2a)(2d) and any guarantees of the discretization. This feedback is clear and actionable, as it points out a critical aspect of the analysis that needs to be addressed to strengthen the paper. However, the comment could be more helpful if it provided suggestions on how to address these issues or offered examples of how similar analyses have been conducted in related works. Despite this, the comment is 4 as it directs the authors to a specific area that requires further elaboration or justification. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the quality of the generated images by the proposed method, noting that while good continuous control is achieved, the realism of the generated results is limited. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks specific suggestions or guidance on how to improve the quality of the generated images or what aspects of the realism need to be enhanced. Without actionable advice, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the quality of the generated images by the proposed method, specifically mentioning the limited realism of the results shown in the paper and supplemental material. However, it does not specify which part of the paper or supplemental material this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the realism of the generated results, but without clear grounding, the authors may struggle to identify the exact sections that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the quality of the generated images by the proposed method is limited, specifically mentioning the lack of realism in the results shown in the paper and supplemental material. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without concrete evidence or detailed justification, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the quality of the generated images by the proposed method, noting that while good continuous control is achieved, the realism of the generated results is limited. This feedback is 3 as it points out a potential weakness in the paper, prompting the authors to consider ways to improve the realism of their generated images. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending techniques or methods to enhance realism. Without actionable advice, the authors may find it challenging to fully understand and implement the necessary improvements. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment provides explicit instructions on what needs to be improved in the paper. It explicitly states that the authors should describe the size and elements of G, as well as the dimensions of G, X, and W to better understand what DGCN is doing. This feedback is clear and actionable, as it guides the authors on specific details to include in their draft. The authors know exactly what changes to make to improve their paper, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the description of how G is built using the human skeleton, the size and elements of G, and the dimensions of G, X, and W. This provides clear guidance on what the authors need to include to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements and requests for clarification, such as asking for the description of how G is built using the human skeleton and the dimensions of G, X, and W. It does not contain subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by identifying a gap in the description of the model architecture in Section 3.3. It explicitly requests clarification on how the model component G is built using the human skeleton and suggests including the size and elements of G, as well as the dimensions of G, X, and W. This feedback is clear and directs the authors to enhance their explanation of the model, which is crucial for understanding its functionality. By addressing these points, the authors can improve the clarity and comprehensiveness of their draft. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the statement in lines 559560 is not entirely true and provides a correction by explaining that in Cycle Consistency loss, iterations can be performed between two phases of reconstructions with separate standard backpropagation processes. This feedback is clear and provides a direct action for the authors to correct the misrepresentation in their draft. The comment is explicit and concrete, giving the authors precise guidance on how to improve their work. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 559560, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it corrects a statement by explaining that in Cycle Consistency loss, iterations can be performed between two phases of reconstructions with separate standard backpropagation processes. This provides clear guidance on what needs to be corrected in the draft. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement in lines 559560 is not entirely true. It provides a specific correction by explaining that in Cycle Consistency loss, iterations can be performed between two phases of reconstructions with separate standard backpropagation processes. This detailed explanation supports the claim, making it 4. However, the comment could be strengthened by referencing specific literature or examples to further substantiate the correction. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific error in the paper, pointing out that the statement in lines 559560 is not entirely true. It provides a clear and actionable correction by explaining that in Cycle Consistency loss, iterations can be performed between two phases of reconstructions with separate standard backpropagation processes. This feedback is valuable as it helps the authors correct a misrepresentation in their draft, ensuring accuracy and clarity in their work. However, the comment could be more helpful if it also suggested how this correction might impact the overall understanding or methodology of the paper. Overall, the comment is 4 as it provides clear guidance for improvement but could be more comprehensive with additional context or suggestions. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the term \"hyperspectral\" is confusing and provides a clear explanation of what hyperspectral imaging is. This feedback is direct and actionable, as it instructs the authors to avoid using the term \"hyperspectral\" and instead use \"hyperspectral imaging,\" which is the correct terminology. The comment provides a concrete action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the term \"hyperspectral,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the term \"hyperspectral\" and provides a correct definition of \"hyperspectral imaging.\" This level of detail guides the authors on what needs to be corrected, making the comment 5.", "verifiability_rationale": "The review point claims that the term \"hyperspectral\" is confusing and provides a definition of hyperspectral imaging. This claim is 5 as it is supported by a clear explanation of what hyperspectral imaging is and why the term \"hyperspectral\" might be confusing. The comment provides a logical reasoning and a precise definition, making it easy for the authors to understand and address the issue. Therefore, the comment is categorized as 5.", "helpfulness_rationale": "The review comment identifies a specific terminology issue, clarifying that the term \"hyperspectral\" is confusing and provides a correct definition of \"hyperspectral imaging.\" This feedback is actionable and helpful as it guides the authors to use the correct terminology, which can improve the clarity and accuracy of their paper. However, the comment could be more helpful if it also suggested alternative ways to describe the imaging technique or provided context on why the terminology is important. Overall, the comment is 4 as it directs the authors to a clear improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide more detailed ablation studies to demonstrate how each component contributes to the final performance improvements. It specifically mentions the need to explain how the performance of combining the Linformer and the window attention in Big Bird is achieved. While the comment implies that the authors should conduct additional analyses, it does not provide explicit instructions on how to implement these analyses or what specific metrics to focus on. The action is implicit and somewhat vague, as the authors can infer the need for more detailed ablation studies but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions sections 3 and 4, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the authors should provide more detailed ablation studies to demonstrate how each component contributes to the final performance improvements. The comment provides a specific example of how the performance of combining the Linformer and the window attention in Big Bird could be analyzed. This level of detail makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the ablation studies in Sections 3 and 4 could be improved by providing more detailed explanations of how each component contributes to the final performance improvements. The reviewer provides a specific example of how the performance of combining the Linformer and the window attention in Big Bird could be analyzed. This level of detail and suggestion makes the claim 4, as it offers a clear direction for improvement. However, the comment could be strengthened by including references or examples from similar works to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors should provide more detailed ablation studies to demonstrate how each component contributes to the final performance improvements. It specifically mentions the need to explain how the performance of combining the Linformer and the window attention in Big Bird is achieved. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the paper\"s methodology and results sections. By addressing this point, the authors can better illustrate the effectiveness of their approach and enhance the comprehensiveness of their analysis. However, the comment could be more helpful if it included additional guidance on which metrics to focus on or how to present the results. Overall, the comment is 4, as it directs the authors toward a specific improvement that can significantly enhance the clarity and depth of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that some details of the models are missing, specifically the grammar over kernels, which is not explained in detail. It also raises questions about the probabilities associated with the grammar and how inference is performed. While the comment identifies areas that need clarification, it does not provide explicit instructions or concrete suggestions on how the authors should address these issues. The authors can infer that they need to provide more detailed explanations, but the comment lacks specific guidance on what aspects to focus on or how to present the information. Therefore, the comment is 3, as it highlights areas for improvement but does not provide detailed steps for execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the grammar over kernels,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what is missing, namely the explanation of how this approach is applied in practice and the probabilities associated with the grammar. The comment also raises questions about inference, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some details of the models are missing, specifically the grammar over kernels, which is not explained in detail. The reviewer questions how inference is performed and whether probabilities are associated with the grammar. While the comment identifies specific areas of concern, it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to infer the exact nature of the missing details and how they impact the understanding of the models. Therefore, the comment is 3, as it provides a basis for the claim but requires further elaboration to be fully supported.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks detail, namely the explanation of the grammar over kernels and the associated probabilities. It highlights the importance of understanding how this approach is applied in practice, which is crucial for the reader to grasp the methodology. The comment also raises questions about inference, prompting the authors to clarify these aspects. While the comment effectively points out a gap in the paper, it could be more helpful by suggesting ways to address these issues or providing examples of how similar approaches have been explained in other papers. Overall, the feedback is 4 as it directs the authors to enhance the clarity and comprehensiveness of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the role of visual information in the paper and questions the effectiveness of the ablation study. It points out that the performance of the model without the perception module is similar to the model with the perception module, and the implementation detail of the model without perception is unknown. Additionally, it suggests that the improvements are not significant given the sample size of 1000 users. The comment provides a clear critique of the experimental results and raises questions about their validity. However, it does not offer specific guidance on how the authors should address these issues or improve their draft. The action is implicit and somewhat vague, as the authors are left to infer what changes are needed to address the concerns. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 10,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the ablation study, questioning the effectiveness of the visual information and the implementation detail of the model without perception. The comment further critiques the experiment results, suggesting that the improvements are not significant given the sample size. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point claims that the role of visual information is unknown and questions the effectiveness of the ablation study. It provides specific examples from Table 10, where the performance of the model without the perception module is similar to the model with the perception module, and the implementation detail of the model without perception is unknown. Additionally, it suggests that the improvements are not significant given the sample size of 1000 users. This reasoning is 4 as it provides specific examples and logical arguments to support the claim. However, the comment could be strengthened by referencing similar studies or providing more detailed analysis of the sample size and its impact on significance. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper, specifically questioning the role of visual information and the effectiveness of the ablation study. It points out that the performance of the model without the perception module is similar to the model with the perception module, and the implementation detail of the model without perception is unknown. Additionally, it raises concerns about the significance of the improvements given the sample size of 1000 users. This feedback is clear and actionable, as it highlights specific areas that need clarification or further investigation. By addressing these points, the authors can enhance the robustness and validity of their experimental results. However, the comment could be more helpful if it provided suggestions on how to address these issues or offered examples of how to improve the ablation study. Overall, the comment is 4, as it effectively guides the authors toward improving their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the paper, noting that the end of Section 4.2 claims that Transfer Lasso shows the best accuracy in feature screening but does not cite or compare it to previous works on Lasso screening, such as the work by Ren et al. The comment provides a concrete suggestion by explicitly mentioning the missing references, which the authors can use to address the issue. This makes the comment 5, as it clearly identifies what needs to be done to improve the draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular claim about Transfer Lasso\"s accuracy in feature screening and notes the absence of citations or comparisons to previous works on Lasso screening, such as the work by Ren et al. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper\"s conclusion about Transfer Lasso\"s accuracy in feature screening is not supported by citations or comparisons to previous works on Lasso screening, such as the work by Ren et al. This claim is 3 as it highlights a specific omission in the paper\"s references, which could be addressed by including relevant literature. However, the comment lacks detailed reasoning or examples of how the omission affects the paper\"s conclusions, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the conclusion about Transfer Lasso\"s accuracy in feature screening is not supported by citations or comparisons to previous works on Lasso screening, such as the work by Ren et al. This feedback is clear and actionable, as it directs the authors to include relevant references to strengthen their claims and improve the credibility of their findings. By addressing this omission, the authors can enhance the rigor and comprehensiveness of their work. Therefore, the comment is rated as 4, as it provides a clear direction for improvement but could be more comprehensive by suggesting specific ways to integrate the missing references."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the model has many components with hyperparameters that are not fully provided, suggesting that someone might need to trace them in the source code. While the comment implies that the authors should provide more detailed information about the hyperparameters, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment mentions that the model has many components with hyperparameters that are not fully provided, suggesting that someone might need to trace them in the source code. However, it does not specify which part of the paper this issue pertains to, such as a specific section or figure where these components are discussed. This lack of explicit reference makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing the issue of missing hyperparameter information, but without grounding, it is difficult for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the model has many components with hyperparameters that are not fully provided, suggesting that someone might need to trace them in the source code. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand which components or hyperparameters are missing. Without detailed information or evidence, the claim is not verifiable, as it does not provide sufficient context or justification for the authors to address the issue effectively. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the model has many components with hyperparameters that are not fully provided. This feedback is 3 as it points out a potential weakness in the presentation of the model, which could impact reproducibility and understanding. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending which hyperparameters should be included or how to present them more clearly. While it highlights an area for improvement, the comment could be more helpful with additional details or actionable advice. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a lack of clarity in the notation for results, specifically questioning the meaning of \"%p\" in the claim of a 3%p improvement for CIFAR10. While the comment identifies a specific issue with the notation, it does not provide explicit guidance on how to address it or suggest alternative ways to present the results. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the notation but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue with the notation for results, specifically the claim of a 3%p improvement for CIFAR10. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue with the notation, which is the lack of clarity regarding what \"%p\" stands for. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the notation for results is unclear, specifically questioning the meaning of \"%p\" in the claim of a 3%p improvement for CIFAR10. This is a factual statement that requires no verification, as it is a direct observation about the clarity of the notation. The comment does not contain subjective opinions, suggestions, or judgments that would require justification or evidence. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the notation used in the results section, specifically questioning the meaning of \"%p\" in the claim of a 3%p improvement for CIFAR10. This feedback is clear and actionable, as it directs the authors to clarify the notation used in their results to ensure that readers understand the reported improvements. However, the comment could be more helpful if it provided suggestions on how to improve the clarity of the notation or offered examples of how to present the results more effectively. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the use of an automatic metric (TSS) instead of a human metric for evaluating style control in the human evaluation. It suggests that this choice weakens the convincingness of the human evaluation. However, the comment does not provide explicit guidance on what the authors should do to address this issue or how they might improve the evaluation process. The action is implicit, as the authors can infer that they should consider using a human metric, but it lacks concrete details on how to implement this change. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment questions the use of an automatic metric (TSS) instead of a human metric for evaluating style control in the human evaluation. However, it does not specify which part of the paper discusses the human evaluation or where the use of TSS is mentioned. This makes it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the evaluation method but lacks grounding, as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the use of an automatic metric (TSS) instead of a human metric for evaluating style control in the human evaluation. The reviewer claims that this choice weakens the convincingness of the human evaluation. However, the comment lacks specific reasoning or examples to support why a human metric would be more appropriate or how the use of TSS affects the evaluation. Without detailed justification or references, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is classified as 2.", "helpfulness_rationale": "The review comment raises a valid concern about the choice of using an automatic metric (TSS) instead of a human metric for evaluating style control in the human evaluation. This is a critical point that could impact the credibility and validity of the human evaluation results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their evaluation methodology. While it identifies a potential weakness, it lacks actionable advice, making it 3. The authors are given some insight into a possible area for improvement but are not fully supported in making those improvements. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that including experiments across more diverse domains would strengthen the paper. While the comment implies that the authors should expand their experiments, it does not provide specific guidance on which domains to consider or how to conduct these experiments. The action is implicit and somewhat vague, as the authors need to infer that they should expand their experiments and determine the specific domains themselves. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that including experiments across more diverse domains would strengthen the paper. However, it does not specify which part of the paper the current experiments are located in, nor does it provide details on which specific domains should be considered. This makes it difficult for the authors to pinpoint the exact sections that need revision. The comment is specific in suggesting the need for more diverse experiments but lacks grounding, as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments \"succinctly prove the point that the authors try to make\" and suggests that including experiments across more diverse domains would strengthen the paper. However, the comment lacks specific examples or references to support the claim that the current experiments are insufficient or that additional domains would provide more robust evidence. Without detailed justification or evidence, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is classified as 2.", "helpfulness_rationale": "The review comment acknowledges that the experiments successfully prove the authors\" point but suggests that including experiments across more diverse domains would strengthen the paper. This feedback is 3 as it provides a direction for potential improvement by suggesting a broader scope of experiments. However, the comment lacks specific guidance on which domains to consider or how to conduct these additional experiments, leaving the authors with a general idea but no detailed steps to follow. To be more helpful, the comment could include examples or suggestions for specific domains to explore. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a missing evaluation of the magnitude of interpretability tax associated with the method. However, it does not provide any explicit or implicit guidance on how the authors should address this issue or what specific aspects of the interpretability tax should be evaluated. The comment lacks actionable details, such as suggesting which metrics or methods could be used to assess the interpretability tax. As a result, the authors are left without a clear understanding of how to proceed with this feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the paper, namely the lack of evaluation of the magnitude of interpretability tax associated with the method. However, it does not specify which part of the paper this evaluation should be included in, making it weakly grounded. The comment is specific in identifying the missing evaluation of the interpretability tax, but without clear grounding, the authors may struggle to determine where this feedback applies. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper does not evaluate the magnitude of interpretability tax associated with the method. However, it does not provide any supporting evidence, reasoning, or examples to justify why this evaluation is necessary or how it would impact the paper. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks evaluation, namely the magnitude of interpretability tax associated with the method. This is a valuable observation that could help the authors enhance their work by providing a more comprehensive analysis of the interpretability aspects of their method. However, the comment does not offer any suggestions or guidance on how to evaluate this aspect or what specific metrics or approaches could be used. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight but lacks depth and specificity in terms of actionable steps."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges that the LUQ is straightforward to design once the goal is clear and that the approaches in Section 5 are standard and explored in previous literature. The reviewer suggests that the main contribution of the paper is demonstrating that a simple combination of existing techniques can achieve surprisingly good accuracy. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to improve the paper or what specific aspects need attention. Without actionable suggestions or feedback, the authors are left without a clear path for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the design of the LUQ and the approaches in Section 5, suggesting that they are straightforward and standard. However, it does not specify which part of the paper discusses the LUQ or the approaches in Section 5, making it weakly grounded. The comment is specific in its critique of the paper\"s contribution, suggesting that the main contribution is showing the effectiveness of existing techniques rather than proposing novel ones. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the LUQ is straightforward to design and that the approaches in Section 5 are standard and explored in previous literature. The reviewer suggests that the main contribution of the paper is demonstrating the effectiveness of existing techniques rather than proposing novel ones. However, the comment lacks specific references or examples to support the claim that the approaches are standard or explored in previous literature. This makes it difficult for the authors to fully understand and address the critique. Therefore, the comment is considered 2, as it provides some justification but lacks detailed evidence or references.", "helpfulness_rationale": "The review comment acknowledges that the LUQ is straightforward to design once the goal is clear and that the approaches in Section 5 are standard and explored in previous literature. It suggests that the main contribution of the paper is demonstrating the effectiveness of existing techniques rather than proposing novel ones. While the comment provides some insight into the paper\"s contribution, it lacks specific suggestions or guidance on how the authors might enhance their work or address the reviewer\"s concerns. The feedback is 3 as it highlights the paper\"s focus on existing techniques, but it does not offer actionable advice for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the stability of training the deep localization network with the differentiable Sinkhorn method. It suggests that the authors should include training losses to provide evidence of stability. While the comment implies that the authors should include training losses, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to present the training losses or what metrics to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the stability of training the deep localization network with the differentiable Sinkhorn method and suggests including training losses. However, it does not specify which part of the paper this issue pertains to, such as a specific section or experiment where this method is discussed. Without explicit references, the authors may find it challenging to pinpoint the exact part of the paper that needs attention. The comment is specific in its request for training losses but lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point raises a question about the stability of training the deep localization network with the differentiable Sinkhorn method. It suggests that the authors should include training losses to provide evidence of stability. However, the comment does not provide any supporting evidence, reasoning, or references to justify why training losses are necessary or how they would demonstrate stability. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the stability of training the deep localization network with the differentiable Sinkhorn method. It suggests that the authors should include training losses to provide evidence of stability. This feedback is 3 as it identifies a potential area for improvement by suggesting a specific metric that could be included to enhance the paper\"s transparency and robustness. However, the comment lacks depth and does not provide detailed guidance on how to present or interpret the training losses, which would make it more actionable. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the relevance of the proposed method to the authors\" motivations, specifically questioning the effectiveness of automatic scores and the affordability of human evaluation scores. It also suggests that the proposed framework, FFAEVAL, and similar frameworks like Chatbot Arena are not suitable for evaluating a single dialogue system, such as providing fluency scores. The comment implies that arenabased evaluation systems may not address the issues with current scorebased evaluation systems. However, it does not provide explicit guidance or suggestions on how the authors might address these concerns or improve their draft. The action is implicit and somewhat vague, as the authors are left to infer what changes might be necessary without concrete steps or examples. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the relevance of the proposed method to the authors\" motivations, specifically questioning the effectiveness of automatic scores and the affordability of human evaluation scores. It also discusses the limitations of the proposed framework, FFAEVAL, and similar frameworks like Chatbot Arena in evaluating a single dialogue system. However, the comment does not explicitly mention which part of the paper these issues are discussed in, making it weakly grounded. The authors can infer that it relates to the abstract or methodology sections, but this inference is not direct. The comment is specific in detailing the limitations of the proposed method and its relevance to the authors\" motivations. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a claim about the relevance of the proposed method to the authors\" motivations, specifically questioning the effectiveness of automatic scores and the affordability of human evaluation scores. It also suggests that the proposed framework, FFAEVAL, and similar frameworks like Chatbot Arena are not suitable for evaluating a single dialogue system. The comment provides a logical reasoning by contrasting the arenabased evaluation systems with the current scorebased evaluation systems, suggesting that the former may not address the issues with the latter. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to further explore the reasoning and evidence to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical point about the relevance of the proposed method to the authors\" motivations, specifically questioning the effectiveness of automatic scores and the affordability of human evaluation scores. It also suggests that the proposed framework, FFAEVAL, and similar frameworks like Chatbot Arena are not suitable for evaluating a single dialogue system, such as providing fluency scores. The comment provides a logical reasoning by contrasting arenabased evaluation systems with current scorebased evaluation systems, suggesting that the former may not address the issues with the latter. However, the comment lacks specific suggestions or guidance on how the authors might address these concerns or improve their draft. While it identifies a potential weakness, it does not offer actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the training of RegMixup, suggesting that it sees 2x samples per iteration, which could lead to unfair comparisons with other methods. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest ways to improve the training process. The action is implicit and somewhat vague, as the authors are left to infer that they need to ensure a fair comparison by adjusting the training process. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"RegMixup,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of RegMixup seeing 2x samples per iteration, which could lead to unfair comparisons with other methods. The comment provides a clear explanation of the problem and suggests a potential solution, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the training of RegMixup sees 2x samples per iteration, which could lead to unfair comparisons with other methods. However, the comment does not provide any supporting evidence, such as specific examples or references to other methods, to substantiate this claim. The lack of detailed reasoning or references makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the training of RegMixup, suggesting that it sees 2x samples per iteration, which could lead to unfair comparisons with other methods. This is a relevant observation that could impact the validity of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or ensure fair comparisons. While it highlights a potential problem, it lacks actionable feedback, making it 3. The authors are left to infer that they need to adjust their training process or provide additional context to ensure fair comparisons. Therefore, the comment is rated as 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should verify whether the improvements of the proposed model over the RL without feedback model are statistically significant, given that the improvements are not as high as expected (as shown in row 3 versus row 4 in Table 6). While the comment implies that the authors should conduct a statistical analysis, it does not provide specific guidance on how to perform this analysis or what metrics to focus on. The action is implicit and somewhat vague, as the authors need to infer the need for a statistical analysis and determine how to conduct it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"row3 vs. row4 in table 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of the proposed model\"s improvements over the RL without feedback model not being statistically significant, as evidenced by the BLEU1 score. The comment provides a clear direction for the authors to verify the statistical significance of the improvements. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the improvements of the proposed model over the RL without feedback model are not significant, as evidenced by the comparison in Table 6. The reviewer suggests that the authors should verify the statistical significance of these improvements. However, the comment lacks specific reasoning or examples to support the claim that the improvements are not significant. Without detailed analysis or references, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment identifies a potential issue with the improvements of the proposed model over the RL without feedback model, as indicated by the comparison in Table 6. It points out that the improvements are not as significant as expected, particularly for BLEU1, and suggests that the authors should verify the statistical significance of these improvements. This feedback is clear and actionable, as it directs the authors to conduct a statistical analysis to substantiate their claims. However, the comment could be more helpful if it provided specific guidance on how to conduct the statistical analysis or what metrics to focus on. Overall, the comment is 4 as it highlights a critical area for improvement and offers a clear direction for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about relaxing the need to visit all ballaction pairs with each iteration. It suggests considering minimal assumptions or exploring what would happen if only some ballaction pairs are covered. While the comment implies that the authors should consider these possibilities, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the above remark,\" allowing the authors to identify the part of the paper being addressed. It also specifies what needs to be addressed, which is the need to relax the requirement of visiting all ballaction pairs with each iteration. The comment suggests considering minimal assumptions or exploring what would happen if only some ballaction pairs are covered. This provides clear guidance on what the authors should consider to improve their draft. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification on how to relax the need to visit all ballaction pairs with each iteration. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information or clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment builds upon the previous remark by asking for clarification on how to relax the need to visit all ballaction pairs with each iteration. It suggests considering minimal assumptions or exploring what would happen if only some ballaction pairs are covered. This feedback is 3 as it prompts the authors to think critically about their approach and potentially explore alternative methods or assumptions. However, the comment lacks specific guidance or suggestions on how to implement these ideas, which would make it more actionable. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about whether improvements could be observed with a different encoder, such as RoBERTabase, instead of BERT. However, it does not provide any explicit or implicit action for the authors to take. There is no guidance on whether the authors should test this hypothesis, make changes to their encoder, or address this point in their discussion. The comment lacks actionable details, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about whether improvements could be observed with a different encoder, such as RoBERTabase, instead of BERT. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment lacks specificity as it does not detail what improvements are expected or how the encoder choice affects the results. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about whether improvements could be observed with a different encoder, such as RoBERTabase, instead of BERT. However, it does not provide any supporting evidence, reasoning, or examples to justify why this change might lead to improvements. The comment lacks specific details or references that would help the authors understand the basis of the suggestion, making it difficult for them to address the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about whether improvements could be observed with a different encoder, such as RoBERTabase, instead of BERT. While it identifies a potential area for exploration, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue or conduct further experiments. The comment does not offer actionable feedback or insights that would help the authors improve their draft. As a result, it is 2, as it points out a possible direction but does not provide enough detail or direction for the authors to act upon."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should include more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of their proposed technique to tasks with different levels of reasoning requirements. While the comment implies that the authors should expand their dataset selection, it does not provide specific guidance on which datasets to include or how to incorporate them into the study. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the suggestion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests including more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of the proposed technique. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. The authors can infer that it relates to the experimental setup or evaluation, but the lack of explicit grounding makes it difficult to pinpoint the exact part of the paper being addressed. The comment is specific in suggesting the inclusion of additional datasets, but without clear grounding, it aligns with a 3 label.", "verifiability_rationale": "The review point suggests that the authors should include more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of their proposed technique. However, the comment does not provide any reasoning, examples, or references to support why these specific datasets are necessary or how they would contribute to the study. Without additional context or justification, the claim remains vague and 1, as the authors may not fully understand the rationale behind the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the authors should include more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of their proposed technique to tasks with different levels of reasoning requirements. This feedback is 3 as it identifies a potential area for improvement by suggesting additional datasets that could strengthen the evaluation of the technique. However, the comment lacks specific guidance on which datasets to include or how to integrate them into the study, which would make it more actionable. The authors are given a direction to expand their dataset selection, but the feedback could be more detailed to fully support their efforts in enhancing the paper. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the choice of baseline methods could be improved, particularly for evaluating the appearance decomposition part. It provides specific examples of baseline methods that could be used, such as RefNeRF and MipNerf, for different scenarios. This feedback is clear and provides concrete guidance on how to enhance the evaluation by including additional baselines. The authors know exactly what needs to be done to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"choice of baseline methods\" and provides specific suggestions for improvement, such as comparing to RefNeRF and MipNerf for different scenarios. This allows the authors to accurately identify the part of the paper being addressed and what needs to be addressed. The comment is also specific because it provides clear examples of baseline methods that could be used for evaluation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the choice of baseline methods could be improved, particularly for evaluating the appearance decomposition part. It provides specific examples of baseline methods, such as RefNeRF and MipNerf, that could be used for different scenarios. This level of detail and the inclusion of references to existing methods provide a clear and logical basis for the claim, making it 5. The authors can easily understand the reasoning behind the suggestion and how it would enhance their evaluation. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting improvements to the choice of baseline methods for evaluating the appearance decomposition part of the paper. It offers concrete examples of baseline methods, such as RefNeRF and MipNerf, that could be used for different scenarios, which is a clear and helpful suggestion for the authors to consider. By including these additional baselines, the authors can enhance the robustness and comprehensiveness of their evaluation, making this feedback 4. However, the comment could be more helpful if it explained why these specific baselines are relevant or how they would contribute to the evaluation. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the biggest concern during reading is the lack of implementation details of the proposed methods. It suggests that these details should have been included in Section 4.1, which provides implementation details. This feedback is clear and provides a direct action for the authors to take, which is to include the missing implementation details in the specified section. The comment is explicit and concrete, giving the authors a clear understanding of what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of implementation details of the proposed methods. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the biggest concern during reading is the lack of implementation details of the proposed methods. It suggests that these details should have been included in Section 4.1, which provides implementation details. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the missing details. The lack of detailed justification or examples makes the claim 3, as it requires the authors to infer the specific aspects that need clarification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the lack of implementation details of the proposed methods. It suggests that these details should have been included in Section 4.1, which provides implementation details. This feedback is clear and actionable, as it directs the authors to a specific section where they can address the issue. By providing a clear direction for improvement, the comment is 4, as it empowers the authors to enhance the clarity and completeness of their draft. However, it could be more helpful if it offered additional guidance on what specific implementation details are missing or how to present them effectively. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the absence of empirical evaluation and comparison with other methods, which is a significant concern. It also notes the lack of practical value and theoretical argumentation for the contribution. While the comment identifies the need for empirical evaluation and comparison, it does not provide specific guidance on how to address these issues or what aspects should be evaluated. The feedback is implicit and somewhat vague, as it does not offer concrete steps for improvement. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the lack of empirical evaluation, comparison with other methods, and the absence of a theoretical argument for the contribution\"s practical value. However, it does not specify which sections of the paper these issues pertain to, making it weakly grounded. The comment is specific in detailing what is missing, such as empirical evaluation and comparison with other methods, as well as the need for a theoretical argument for practical value. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks empirical evaluation, comparison with other methods, and a theoretical argument for the contribution\"s practical value. However, it does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The comment suggests that the theoretical contributions may be significant but does not elaborate on how this could be demonstrated. Without detailed justification or examples, the claim remains 3, as it lacks sufficient evidence to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies several critical weaknesses in the paper, including the lack of empirical evaluation, comparison with other methods, and a theoretical argument for the contribution\"s practical value. It highlights the importance of these elements, especially in the context of a conference like NeurIPS, where practical relevance is often a key consideration. However, the comment does not provide specific suggestions or guidance on how the authors might address these issues, such as recommending particular methods for comparison or suggesting ways to demonstrate the practical value of the contribution. While it points out important areas for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight into the paper\"s weaknesses but lacks depth and specificity in its feedback."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential source of confusion in the manuscript, where the symbol \"P\" is used to represent both a probability and a cumulative distribution function. However, it does not provide explicit guidance on how to address this issue or suggest specific actions for the authors to take. The comment implies that the authors should clarify the usage of \"P\" to avoid confusion, but it lacks concrete details on how to achieve this. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific equations (3) and (4) and a line number (L44) in the appendix, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue, which is the confusion caused by the use of \"P\" to represent both a probability and a cumulative distribution function. This provides clear guidance on what needs to be addressed to avoid confusion. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the symbol \"P\" is used inconsistently in the manuscript, representing both a probability and a cumulative distribution function. This claim is 3 as it highlights a potential source of confusion in the paper. However, the comment does not provide specific examples or detailed explanations of where this inconsistency occurs, which would help the authors understand and address the issue more effectively. The lack of detailed examples or references makes it challenging for the authors to fully grasp and rectify the problem. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the use of the symbol \"P\" in the manuscript, noting that it is used to represent both a probability and a cumulative distribution function. This observation highlights a potential source of confusion for readers, which is important for the authors to address. However, the comment does not provide specific suggestions or guidance on how to resolve this issue, such as recommending a consistent notation or clarifying the context in which \"P\" is used. While it points out a problem, it lacks actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that other baselines, such as those discussed in related work [29, 5, 6], should also be included. It implies that the authors should consider adding these baselines to their study. However, the comment does not provide explicit guidance on which specific baselines to include or how to integrate them into the paper. While the action is implicit, it is somewhat vague as it lacks concrete details on how to implement the suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including other baselines, such as those discussed in related work [29, 5, 6], and implies that this would enhance the paper. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting the inclusion of additional baselines, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that other baselines should be included, referencing specific works from the related work section. The reviewer acknowledges that the authors have addressed their concerns in the response, which is a positive step. However, the comment lacks specific examples or detailed reasoning about why these additional baselines are necessary or how they would enhance the paper. This makes the claim 3, as it provides some justification but lacks depth and detailed evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that including other baselines, such as those discussed in related work, would enhance the paper. It acknowledges that the authors have addressed the reviewer\"s concerns in their response, which is a positive step. However, the comment could be more helpful if it provided specific examples of additional baselines or detailed guidance on how to integrate them into the paper. While it identifies a potential area for improvement, the feedback lacks depth and actionable suggestions, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a discrepancy between the task loss being referred to as \"L_task\" in the text and \"L_class\" in Figure 1. This is a clear and explicit observation that the authors need to address. The comment provides a specific action for the authors to take, which is to ensure consistency in the naming of the task loss across the text and figures. The feedback is direct and provides clear guidance on what needs to be corrected, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a discrepancy in the naming of the task loss, which is clearly identified as \"L_task\" in the text but \"L_class\" in Figure 1. This provides clear guidance on what needs to be corrected, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a factual observation about a discrepancy in the naming of the task loss in the text and in Figure 1. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific inconsistency in the naming of the task loss, pointing out that it is referred to as \"L_task\" in the text but \"L_class\" in Figure 1. This is a clear and actionable observation that the authors can address to ensure consistency and clarity in their paper. By correcting this discrepancy, the authors can improve the readability and accuracy of their work. However, the comment does not provide additional context or suggestions on why this inconsistency matters or how it might impact the understanding of the paper. While it highlights a specific issue, it lacks depth and does not offer comprehensive guidance for improvement. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about other limitations of the method and specifically asks if the network is shallow in the graph case. While it implies that the authors should address these limitations, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to discuss additional limitations and potentially address the depth of the network. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about other limitations of the method and specifically asks if the network is shallow in the graph case. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for additional information on limitations and the depth of the network, but without clear grounding, the authors may struggle to determine where to address these points. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question seeking clarification on other limitations of the method and whether the network is shallow in the graph case. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about other limitations of the method, specifically asking if the network is shallow in the graph case. While it prompts the authors to consider additional limitations, it lacks depth and does not provide specific suggestions or guidance on how to address these limitations or improve the method. The comment is 3 as it prompts the authors to think about potential weaknesses, but it does not offer actionable advice or detailed feedback on how to enhance the draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the work would be more convincing if it included evaluations in machine translation, which is considered a \"close domain\" generation task with lower uncertainties per word compared to answer generation and summarization. While the comment implies that the authors should include machine translation evaluations, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"answer generation and summarization,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the work would be more convincing if it included evaluations in machine translation, which is considered a \"close domain\" generation task with lower uncertainties per word. This provides clear guidance on what the authors need to address to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the work would be more convincing if it included evaluations in machine translation, which is considered a \"close domain\" generation task with lower uncertainties per word. The reviewer provides a logical reasoning by contrasting the tasks of answer generation and summarization with machine translation, suggesting that the latter is a more appropriate evaluation for the proposed method. However, the comment lacks specific references or examples to support the claim that machine translation is a better evaluation, making it 3. The authors would need to consider the reasoning and potentially conduct additional evaluations to fully understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation in the evaluation of the proposed method, noting that it only uses answer generation and summarization tasks, which are closer to \"open domain\" generation rather than \"close domain\" tasks like machine translation. The reviewer suggests that the work would be more convincing if it included evaluations in machine translation, which exhibits lower uncertainties per word. This feedback is clear and actionable, as it provides a specific suggestion for improving the evaluation of the proposed method. However, it could be more helpful if it offered additional guidance on how to conduct the machine translation evaluation or what specific aspects to focus on. Overall, the comment is 4, as it directs the authors toward a meaningful enhancement of their work."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the dropout process, specifically asking for clarification on the dropping rate and the number of masks generated. While the comment does not explicitly instruct the authors to provide this information, it implies that the authors should address these questions by including the requested details in their draft. The action is implicit but concrete, as the authors know exactly what information is needed to improve their draft. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the dropout\" and \"the reading of the response letter,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the dropping rate and the number of masks generated. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the dropout process, specifically asking for the dropping rate and the number of masks generated. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises specific questions about the dropout process, seeking clarification on the dropping rate and the number of masks generated. While it identifies a gap in the explanation of the dropout method, it does not provide any suggestions or guidance on how the authors might address these questions or improve their explanation. The comment is 3 as it points out a lack of clarity in the paper, but it lacks actionable feedback or detailed suggestions for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the effectiveness of the proposed twostage optimization approach needs further justification. It suggests that showing the performance drop on fusion models is not sufficient and that comparisons with other singlestage attacks are needed to demonstrate effectiveness. The comment also highlights the importance of proper benchmarks and comparisons with other stateoftheart (SOTA) algorithms to justify the technical contributions. This feedback provides clear and concrete actions for the authors to take, such as conducting additional comparisons and benchmarks, which makes the comment 5.", "grounding_specificity_rationale": "The comment addresses the effectiveness of the proposed twostage optimization approach, specifically mentioning the need for further justification and comparisons with other singlestage attacks. However, it does not specify which part of the paper discusses the twostage optimization approach, making it weakly grounded. The comment is specific in detailing what is missing, such as comparisons with other SOTA algorithms and benchmarks, which would help justify the effectiveness of the technical contributions. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the effectiveness of the proposed twostage optimization approach needs further justification. It argues that showing the performance drop on fusion models is not sufficient and suggests that comparisons with other singlestage attacks are needed. The comment also highlights the importance of proper benchmarks and comparisons with other stateoftheart (SOTA) algorithms to justify the technical contributions. While the comment provides a logical reasoning for the need for additional comparisons and benchmarks, it lacks specific examples or references to other SOTA algorithms or singlestage attacks, which would strengthen the argument. Therefore, the claim is 3, as it provides a clear direction for improvement but lacks detailed evidence or examples.", "helpfulness_rationale": "The review comment identifies a critical area for improvement in the paper, specifically the need for further justification of the effectiveness of the proposed twostage optimization approach. It points out that merely showing the performance drop on fusion models is insufficient and suggests that comparisons with other singlestage attacks are necessary to demonstrate the approach\"s effectiveness. Additionally, the comment highlights the importance of proper benchmarks and comparisons with other stateoftheart (SOTA) algorithms to justify the technical contributions. This feedback is clear and actionable, providing the authors with specific directions to enhance their draft by conducting additional comparisons and justifications. However, it could be more helpful if it offered suggestions on how to conduct these comparisons or what specific benchmarks to use. Overall, the comment is 4 as it guides the authors toward improving the justification and demonstration of their technical contributions."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the paper lacks information about the type of GPUs used and the inference time during testing. This provides a clear and direct action for the authors to take, which is to include this information in their draft. The comment is explicit and provides concrete guidance on what needs to be added, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of information about the type of GPUs used and the inference time during testing. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what is missing: the type of GPUs and inference time during testing. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks information about the type of GPUs used and the inference time during testing. This is a factual statement that does not require verification or justification. It is a request for additional information to be included in the paper, which is a normal statement and not a claim. Therefore, the label is \"No.\"", "helpfulness_rationale": "The review comment identifies a specific omission in the paper, namely the lack of information about the type of GPUs used and the inference time during testing. This is a clear and actionable piece of feedback that can help the authors improve their draft by providing crucial details that could impact the reproducibility and understanding of their results. However, the comment could be more helpful if it suggested where this information should be included or how it might affect the interpretation of the results. Despite this, the feedback is 4 as it directs the authors to a critical area for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point consists of several separate comments. The first comment suggests that the authors should explore what happens when the lambda value is even smaller, indicating an implicit action to expand the analysis. The second comment points out missing elements in the equation on page 3, line 2, and line 4, which is an explicit request for correction. These comments provide clear actions for the authors to take, but they are not fully actionable as they lack detailed guidance on how to implement the suggested changes. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 1\" and \"page 3, line 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the missing elements in the equation and the curiosity about the performance at smaller lambda values. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of multiple claims and observations. The first claim suggests that the performance of RSD4PG in Table 1 appears to increase monotonically with lambda values, and the reviewer expresses curiosity about what happens when lambda is even smaller. This claim is 3 as it is based on an observation from the data presented in the table, but it lacks specific reasoning or examples to fully substantiate the claim. The second claim points out missing elements in the equation on page 3, line 2, and line 4, which is a factual observation requiring no verification. The third claim is a request for clarification regarding the notation in the equation, which is a normal statement. Therefore, the overall comment is a mix of claims and normal statements, with the first claim being 3 and the others being factual.", "helpfulness_rationale": "The review comment provides several specific points for improvement. It highlights a potential issue with the monotonic increase in performance in Table 1, suggesting that the authors explore what happens when the lambda value is even smaller. This feedback is actionable and could lead to a more comprehensive analysis. Additionally, the comment points out missing elements in the equation on page 3, line 2, and line 4, which is a clear and specific request for correction. These suggestions are valuable for the authors as they directly address areas that need improvement in the draft. However, the comment could be more helpful if it provided additional context or explanation for why these points are important. Overall, the feedback is 4, as it offers actionable guidance for enhancing the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a specific sentence that is confusing and suggests that the authors reread it to understand its meaning. While the comment identifies a potential issue, it does not provide explicit guidance on how to clarify the sentence or improve its clarity. The action is implicit and somewhat vague, as the authors are left to infer that they need to revise the sentence but are not given specific instructions on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific sentence range (9395) that is confusing, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the confusion regarding the sentence and suggesting that it is not immediately clear what is meant. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that a specific sentence is confusing and suggests that the reviewer had to reread it to understand it. However, the comment does not provide any reasoning or explanation as to why the sentence is confusing or how it could be clarified. Without additional context or examples, the claim lacks sufficient support, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific sentence in the paper (lines 9395) that is confusing and suggests that the authors reread it to understand its meaning. While the comment highlights a potential issue, it does not provide specific guidance or suggestions on how to clarify the sentence or improve its clarity. The feedback is 3 as it points out a specific area that needs attention, but it lacks depth and actionable advice, leaving the authors with only a general direction for improvement. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point provides a list of specific issues that need to be addressed, including the need for citations in various parts of the paper. Each issue is clearly stated, providing the authors with explicit actions to take. The comments are concrete, as they specify exactly what needs to be done, such as adding citations. This makes the feedback 5, as the authors know exactly what steps to take to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (7879, 129130, 156158, and 217218) in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies what is missing, namely citations for claims made in the text. This provides clear guidance on what needs to be addressed to improve the draft. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements requesting citations for specific claims made in the paper. It does not contain subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by identifying several instances where citations are needed to support claims made in the paper. It highlights specific lines where citations are required, such as \"diffusion models have been able to outperform generative adversarial networks on image generation benchmarks\" and \"Previous work has tried to tackle... but with limited success.\" Additionally, it points out the need for evidence to support claims about the reliability and efficiency of diffusion models. This feedback is clear and direct, guiding the authors on how to strengthen their draft by providing necessary references. However, the comment could be more helpful if it included suggestions on which specific references to consider. Overall, the feedback is 4 as it provides clear guidance on improving the paper\"s credibility and rigor."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out an inconsistency between Figures 1 and 2, specifically noting that Figure 2 shows one encoderdecoder per auxiliary task, while Figure 1 shows a single shared encoderdecoder for multiple tasks. This feedback is explicit and provides a clear action for the authors to take, which is to ensure consistency between the figures. The comment is also concrete, as it specifies the exact inconsistency and guides the authors on how to address it. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig 1\" and \"Fig 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the inconsistency between the figures, noting that Figure 2 shows one encoderdecoder per auxiliary task, while Figure 1 shows a single shared encoderdecoder for multiple tasks. This provides clear guidance on what needs to be addressed to ensure consistency. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 1 is inconsistent with Figure 2, specifically noting that Figure 2 shows one encoderdecoder per auxiliary task, while Figure 1 shows a single shared encoderdecoder for multiple tasks. This claim is based on a direct observation of the figures, which is a factual statement. However, the comment does not provide any additional reasoning or evidence beyond the visual comparison of the figures. Therefore, while the claim is factual, it lacks detailed justification or references, making it 3. The authors would need to verify the claim themselves by examining the figures, which is a straightforward task but not fully supported by the comment.", "helpfulness_rationale": "The review comment identifies a specific inconsistency between Figures 1 and 2, noting that Figure 2 shows one encoderdecoder per auxiliary task, while Figure 1 shows a single shared encoderdecoder for multiple tasks. This feedback is clear and actionable, as it points out a critical inconsistency that the authors need to address to ensure the figures are consistent and accurate. By highlighting this issue, the comment provides the authors with a clear direction for improvement, making it 4. However, it could be more helpful if it included suggestions on how to resolve the inconsistency or why it is important for the figures to be consistent. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether each node can attend to its own lowerlevel representation, suggesting that it may only attend to neighboring nodes based on the description of N_l^(s) in equation 2. While the comment implies that the authors should clarify this aspect, it does not provide explicit guidance on how to address the issue or what specific information should be added to the draft. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the attention mechanism and its scope. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the attention mechanism in the paper, specifically whether each node can attend to its own lowerlevel representation. It references equation 2 and the description of N_l^(s) to support the question. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the section discussing the attention mechanism, but this inference is not as direct as it could be. The comment is specific in detailing the question about the attention mechanism, but without explicit grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point raises a question about the attention mechanism in the paper, specifically whether each node can attend to its own lowerlevel representation. The comment references equation 2 and the description of N_l^(s) to support the claim that only neighboring nodes are attended to. However, the comment does not provide detailed reasoning or examples to fully substantiate the claim, leaving the authors to infer the issue. This makes the claim 3, as it requires further explanation or evidence to fully support the assertion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the attention mechanism in the paper, specifically whether each node can attend to its own lowerlevel representation. It references equation 2 and the description of N_l^(s) to support the question, which is a clear and specific point of confusion for the authors. However, the comment does not provide any suggestions or guidance on how to address this issue or clarify the attention mechanism. While it identifies a potential area of concern, it lacks actionable feedback, making it 3. The authors are left with a question to explore but without a clear path to improvement. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly requests clarification on how the inequality after line 433 follows from Lemma 7. It suggests that the authors should facilitate the reading by stating how Lemma 7 is used in this context. This feedback provides a clear and direct action for the authors to take, which is to include an explanation of the connection between Lemma 7 and the subsequent inequality. The comment is explicit and provides concrete guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 433\" and \"Lemma 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by questioning the connection between the inequality after line 433 and Lemma 7. The comment suggests that the authors should clarify how Lemma 7 is used to derive the inequality, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the logical connection between an inequality after line 433 and Lemma 7, suggesting that the authors should clarify how Lemma 7 is used to derive the inequality. However, the comment does not provide any specific reasoning or evidence to support why the connection is unclear or how it should be clarified. Without additional context or explanation, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered 2, as it lacks sufficient justification or examples to fully support the request for clarification.", "helpfulness_rationale": "The review comment identifies a specific issue with the logical flow of the paper, questioning how an inequality after line 433 follows from Lemma 7. It suggests that the authors should clarify the connection between these elements, which is a valuable observation that could help improve the clarity and coherence of the paper. However, the comment could be more helpful if it provided additional guidance on how to present the connection or suggested specific ways to clarify the logic. Despite this, the feedback is 3 as it directs the authors to a potential area of improvement, prompting them to enhance the logical structure of their work."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies several issues with the paper, including the lack of clarity in the main contribution and the unclear explanation of how the proposed method copes with dynamic largescale multitasking. It also points out that the automation aspect is unclear. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues. The actions are implicit and somewhat vague, as the authors are left to infer what specific changes are needed to clarify the main contribution and the automation aspect. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the main contribution of the paper, which is unclear, and points out that the proposed method\"s ability or applicability is either overstated or not wellsupported. It also mentions that the main idea of how the proposed method copes with dynamic largescale multitasking is unclear and that the automation aspect is unclear. However, the comment does not specify which sections of the paper these issues pertain to, making it weakly grounded. The comment is specific in detailing what is unclear about the main contribution and the automation aspect. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the main contribution of the paper is unclear and that the proposed method\"s ability or applicability is either overstated or not wellsupported. It also mentions that the main idea of how the proposed method copes with dynamic largescale multitasking is unclear and that the automation aspect is unclear. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of evidence or detailed explanation makes the claim 3, as the authors would need to infer the issues and address them without clear guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several critical issues with the paper, specifically the lack of clarity in the main contribution and the unclear explanation of how the proposed method copes with dynamic largescale multitasking. It also points out that the automation aspect is unclear. These are important areas that the authors need to address to improve the clarity and impact of their work. However, the comment does not provide specific suggestions or guidance on how to clarify these aspects, such as what additional information or examples could be included to enhance the explanation. While it highlights key areas for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the experiment comparison is weak because the authors only compare their method to the BERTbaseline. It suggests that the authors should compare their method to token pruning and token combination baselines. This feedback provides a clear and direct action for the authors to take, specifying exactly what needs to be done to improve the experiment comparison. The comment is explicit and concrete, giving the authors a clear path forward. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the experiment comparison, specifically noting that the authors only compare their method to the BERTbaseline. It suggests that the authors should compare their method to token pruning and token combination baselines. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the experimental results or methodology sections. The suggestion is specific, as it clearly identifies what needs to be addressed: the inclusion of additional baselines for comparison. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the experiment comparison is weak because the authors only compare their method to the BERTbaseline. It suggests that the authors should compare their method to token pruning and token combination baselines. This claim is 3 as it provides a logical reasoning for the need to include additional baselines for comparison. However, the comment lacks specific examples or references to support why these additional baselines are necessary or how they would enhance the comparison. Providing more detailed justification or examples would strengthen the verifiability of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific weakness in the experimental comparison, noting that the authors only compare their method to the BERTbaseline. It suggests that the authors should include additional baselines, such as token pruning and token combination, to provide a more comprehensive comparison. This feedback is clear and actionable, offering a concrete suggestion for improving the experimental section of the paper. By addressing this critique, the authors can enhance the robustness and validity of their results. However, the comment could be more helpful if it provided additional context or rationale for why these specific baselines are important or how they might impact the results. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the experimental section should include a comparison to coordinateaware methods, such as TFN or SchNet, as the current comparison only includes methods that are unaware of point coordinates. This feedback is explicit and provides a clear action for the authors to take, which is to include a comparison to coordinateaware methods. The suggestion is concrete, as it specifies the types of methods to consider, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the current comparison, which only includes methods that are unaware of point coordinates, and suggests a comparison to coordinateaware methods like TFN or SchNet. This provides clear guidance on what needs to be addressed in the experimental section. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the experimental section should include a comparison to coordinateaware methods, such as TFN or SchNet, as the current comparison only includes methods that are unaware of point coordinates. This claim is 3 as it provides a logical reasoning for the suggestion, noting the lack of comparison to coordinateaware methods. However, the comment could be strengthened by providing specific examples or references to coordinateaware methods that could be included in the comparison. This would enhance the verifiability of the claim, making it more actionable for the authors. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific limitation in the experimental section, noting that the current comparison only includes methods that are unaware of point coordinates. It suggests that a comparison to coordinateaware methods, such as TFN or SchNet, would be appropriate. This feedback is clear and actionable, providing the authors with a specific direction for improving their experimental setup by including a comparison to coordinateaware methods. However, the comment could be more helpful if it explained why these comparisons are important or how they might impact the results. Overall, the comment is 4 as it offers a clear and actionable suggestion for enhancing the experimental section of the paper."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should demonstrate the possible weaknesses of their proposed model. However, it does not provide any explicit guidance or concrete suggestions on how to do so. The action is implicit and vague, as the authors are left to infer that they need to address potential limitations or weaknesses but are not given specific instructions on how to identify or present them. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the authors should demonstrate the possible weaknesses of their proposed model. However, it does not specify which part of the paper this critique pertains to, nor does it provide details on what specific weaknesses should be addressed. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine where to focus their efforts. Additionally, the comment lacks specificity regarding the nature of the weaknesses that should be demonstrated. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the authors did not demonstrate the possible weaknesses of the proposed model. However, it lacks any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references to what weaknesses should have been addressed, the comment is difficult for the authors to understand and address. Therefore, it is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by noting that the authors have not demonstrated the possible weaknesses of their proposed model. This is a critical area for improvement, as understanding and addressing potential limitations is essential for the robustness and credibility of the work. However, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might identify or address these weaknesses. Without actionable advice, the authors are left with a general idea of what needs to be improved but without a clear path forward. Therefore, the comment is 3, as it highlights an important area for improvement but does not offer detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises questions about the novelty and originality of the proposed methodology, specifically asking for comparisons with other extractthengenerate methodologies and questioning the lack of a Related Work section. While the comment implies that the authors should address these issues, it does not provide explicit instructions or concrete suggestions on how to do so. The authors can infer that they need to include a Related Work section and compare their methodology with existing ones, but the comment lacks detailed guidance on how to conduct these comparisons or what specific aspects to focus on. Therefore, the comment is 3, as it identifies areas for improvement but lacks detailed instructions on how to implement them.", "grounding_specificity_rationale": "The comment raises questions about the novelty and originality of the proposed methodology, specifically asking for comparisons with other extractthengenerate methodologies and questioning the lack of a Related Work section. However, it does not specify which part of the paper these concerns relate to, such as a particular section or experiment. The authors can infer that it pertains to the methodology or results sections, but this inference is not explicit. The comment is specific in its critique of the lack of related work and comparisons, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the novelty and originality of the proposed methodology, specifically asking for comparisons with other extractthengenerate methodologies and questioning the lack of a Related Work section. The comment suggests that the paper lacks context and comparison with existing work, which is a valid concern. However, it does not provide specific examples or references to existing work that could be used for comparison, making the claim 3. The authors would need to conduct their own research to address these concerns, which adds complexity to the verification process. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises important questions about the novelty and originality of the proposed methodology, specifically asking for comparisons with other extractthengenerate methodologies and questioning the lack of a Related Work section. It also points out the absence of experiments with other extractthengenerate methods using the proposed model, which is a significant gap in the paper. While the comment identifies critical areas for improvement, it does not provide specific suggestions or guidance on how the authors might address these issues. The feedback is 3 as it highlights important gaps in the paper, but it could be more actionable with additional guidance or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the introduction of related work is insufficient and recommends providing more work on GLN to highlight the advantages or differences of the proposed method, specifically mentioning the difference from BGLN. While the comment implies that the authors should expand the related work section, it does not provide specific guidance on how to do so or which aspects of GLN or BGLN should be emphasized. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to improve the related work section. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the introduction of related work, specifically mentioning the need for more work on GLN to highlight the advantages or differences of the proposed method, such as the difference from BGLN. However, it does not specify which part of the introduction is insufficient or where the additional work on GLN should be included. The authors can infer that it relates to the related work section, but the comment lacks full grounding as it does not explicitly mention the section. It is specific in suggesting what needs to be addressed, such as highlighting the differences from BGLN, but the lack of explicit grounding makes it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that the introduction of related work is insufficient and suggests that more work on GLN should be included to highlight the advantages or differences of the proposed method. However, the comment does not provide specific examples or references to support this claim, nor does it explain why the current introduction is insufficient. Without detailed justification or evidence, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the introduction of related work, noting that it is insufficient and suggests that more work on GLN should be included to highlight the advantages or differences of the proposed method. It specifically mentions the difference from BGLN, which provides a clear direction for improvement. However, the comment could be more helpful if it offered examples of how to incorporate this additional work or suggested specific aspects of GLN or BGLN that should be emphasized. Despite this, the feedback is 4 as it directs the authors to enhance the related work section, providing a clear path for improvement. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the use of hyperparameters in Moon\"s approach, specifically questioning why only one dropout rate is used while Variational dropout has multiple parameters. This comment implies that the authors should provide a justification or explanation for this choice. However, it does not explicitly instruct the authors to do so or offer guidance on how to address the issue. The action is implicit and somewhat vague, as the authors can infer that they need to provide an explanation but are not given specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the use of hyperparameters in Moon\"s approach, specifically questioning why only one dropout rate is used while Variational dropout gets multiple parameters. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its inquiry about the hyperparameters, but it lacks grounding as it does not reference a particular section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point is a question seeking clarification about the use of hyperparameters in Moon\"s approach, specifically regarding the choice of a single dropout rate compared to multiple parameters in Variational dropout. It does not contain an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the use of hyperparameters in Moon\"s approach, specifically questioning why only one dropout rate is used while Variational dropout has multiple parameters. This is a relevant observation that could lead to a deeper understanding of the methodology and its implications. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their explanation. While it highlights a potential area for clarification, it lacks actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should include largerscale experiments with nontrivial dynamics, such as gridworlds with walls and other nontrivial tiles. It also implies that the current experiments may not be sufficient to judge the method\"s scalability. The comment provides a specific suggestion by mentioning videogame domains as a potential area for experimentation, noting that simulators for such experiments are publicly available. This feedback is explicit and provides concrete guidance on how to expand the experiments, making it 5.", "grounding_specificity_rationale": "The comment suggests including largerscale experiments with nontrivial dynamics, such as gridworlds with walls and other nontrivial tiles. It also mentions the need for experiments on videogame domains, which are publicly available. However, the comment does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The authors can infer that it relates to the experimental section, but the lack of explicit reference makes it challenging to pinpoint the exact location. The comment is specific in suggesting the types of experiments to include, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with the label 3.", "verifiability_rationale": "The review point suggests that the paper should include largerscale experiments with nontrivial dynamics, such as gridworlds with walls and other nontrivial tiles. The reviewer questions whether the lack of such experiments is due to time constraints or a potential scalability issue with the method. The comment provides a specific suggestion for experiments on videogame domains, noting that simulators for such experiments are publicly available. This reasoning is 3 as it provides a logical argument and a specific suggestion for improvement, but it lacks detailed evidence or references to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the experimental setup by suggesting the inclusion of largerscale experiments with nontrivial dynamics, such as gridworlds with walls and other nontrivial tiles. It questions whether the current experiments are sufficient to judge the method\"s scalability and suggests that experiments on videogame domains would be more convincing. The comment provides specific examples and references to publicly available simulators, offering clear and actionable guidance for the authors to enhance their experimental section. This feedback is valuable as it directs the authors to expand their experiments, which could significantly improve the paper\"s credibility and impact. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of quantitative measurement for occupation bias relative to real distributions in society. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what specific measurements could be used. The comment lacks actionable guidance, leaving the authors uncertain about how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue regarding the lack of quantitative measurement for occupation bias relative to real distributions in society. However, it does not specify which part of the paper this critique pertains to, such as a particular section or analysis. Without explicit references or context, the authors may find it challenging to pinpoint the exact part of the paper that needs revision. The comment is specific in its critique but lacks grounding, making it 2. Therefore, this comment aligns with a score of 2.", "verifiability_rationale": "The review point claims that the authors did not propose any quantitative measurement to assess the extent of occupation bias relative to real distributions in society. This claim is 3 as it highlights a gap in the paper\"s analysis, but it lacks specific examples or references to support the assertion. The authors would need to consider how to address this gap in their work, but the comment itself does not provide detailed guidance or evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks quantitative measurement for occupation bias relative to real distributions in society. This is a relevant observation that could help the authors improve their analysis by suggesting the inclusion of such measurements. However, the comment does not provide specific guidance on how to implement these measurements or what metrics to use, leaving the authors with a general direction but without detailed actionable steps. While the feedback is 3 in pointing out a gap, it could be more beneficial with additional guidance or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the potential impact of using an adaptive gradient method instead of SGD on the findings. It suggests that such a method might amplify updates for weights associated with hard features, which could affect the results. However, the comment does not provide explicit guidance or suggestions on how the authors should address this concern or whether they should consider using an adaptive gradient method. The action is implicit and somewhat vague, as it lacks concrete steps for the authors to take. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the potential impact of using an adaptive gradient method instead of SGD on the findings. It suggests that such a method might amplify updates for weights associated with hard features, which could affect the results. However, the comment does not specify which part of the paper this concern pertains to, such as a specific section or experiment where the adaptive gradient method is discussed. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. Additionally, while the comment provides a specific concern about the potential impact of using an adaptive gradient method, it does not specify what needs to be addressed or how to address it. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a question about the potential impact of using an adaptive gradient method instead of SGD on the findings. It suggests that such a method might amplify updates for weights associated with hard features, which could affect the results. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. The lack of detailed reasoning or specific examples makes it difficult for the authors to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the potential impact of using an adaptive gradient method instead of SGD on the findings. It suggests that such a method might amplify updates for weights associated with hard features, which could affect the results. While the comment identifies a potential area of concern, it lacks specific guidance or suggestions on how the authors might address this issue or whether they should consider using an adaptive gradient method. The feedback is 3 as it prompts the authors to consider a potential impact of their choice of optimization method, but it does not provide actionable steps or detailed advice for improvement. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that no information from 2hop neighbors is included, suggesting that this method is simple but unclear in its effectiveness. While the comment implies that the authors should provide more information on the effectiveness of the method, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to explain the effectiveness of the method. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment mentions that \"no information from 2hop neighbors is included,\" which implies that it is referring to a specific method or section of the paper. However, it does not explicitly mention which part of the paper this information is missing from, making it weakly grounded. The comment is specific in pointing out the lack of information from 2hop neighbors and questioning the effectiveness of the method. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that \"no information from 2hop neighbors is included,\" suggesting that this method is simple but unclear in its effectiveness. However, the comment lacks specific examples, reasoning, or references to support why the inclusion of 2hop neighbor information would improve the method\"s effectiveness. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment points out a specific omission in the paper, noting that no information from 2hop neighbors is included. It also questions the effectiveness of the method, suggesting that it is unclear why the method is effective. While the comment identifies a gap in the paper and raises a valid concern, it lacks specific suggestions or guidance on how the authors might address this issue or improve the clarity of the method\"s effectiveness. The feedback is 3 as it directs the authors\" attention to a critical area needing further explanation, but it could be more actionable with additional details or examples. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that further optimization and validation are needed for the binder design provided by ProtPainter. However, it does not specify what aspects of the design need optimization or how to validate it. The comment lacks concrete guidance on how the authors should proceed with these actions, leaving them with a vague understanding of what needs to be done. As a result, the comment is barely actionable, as the authors are not provided with clear steps to improve their draft.", "grounding_specificity_rationale": "The comment addresses the binder design provided by ProtPainter, suggesting that further optimization and validation are required. However, it does not specify which part of the paper discusses this design, making it weakly grounded. The comment is specific in its request for further optimization and validation, but without clear references to the paper, the authors may struggle to identify the exact sections needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that \"ProtPainter just provides an empirical conformation estimation\" and suggests that further optimization and validation are required. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the current estimation is insufficient. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the binder design provided by ProtPainter, noting that it is limited to an empirical conformation estimation. It suggests that further optimization and validation are necessary, which is a clear and actionable piece of feedback. However, the comment does not provide specific guidance on how to optimize or validate the design, nor does it offer examples or references to support the suggestion. While it highlights an important area for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is 3, as it provides a direction for improvement but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly requests clarification on how the model in Figure 7 was trained. It asks whether the model was trained on full field flicker stimulus changing contrast with a fixed cycle and whether the time scale of adaptation would shorten if the cycle duration changes. This feedback provides clear and specific actions for the authors to take, such as explaining the training process and addressing the potential impact of changing cycle durations. The authors know exactly what information to provide to address the reviewer\"s concerns. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig. 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests clarification on how the model in Figure 7 was trained and asks about the impact of changing the cycle duration on the time scale of adaptation, referencing a specific study (Smirnakis et al., Nature 1997). This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point requests clarification on how the model in Figure 7 was trained and asks about the impact of changing the cycle duration on the time scale of adaptation. The comment references a specific study (Smirnakis et al., Nature 1997) to support the claim that the time scale of adaptation might shorten. This provides a logical basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced study to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment is 5 as it provides specific and actionable feedback by requesting clarification on how the model in Figure 7 was trained. It asks whether the model was trained on full field flicker stimulus changing contrast with a fixed cycle and whether the time scale of adaptation would shorten if the cycle duration changes. This feedback is clear and directs the authors to address a critical aspect of their methodology, which could significantly impact the interpretation of their results. By clarifying these points, the authors can enhance the transparency and robustness of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises questions about the comparability of the results in Table 2, specifically regarding the use of different amounts of data. The reviewer suggests that comparisons should be made between using the same amount of data, pointing out specific examples where this is not the case. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern or suggest specific actions to take. The authors can infer that they need to ensure consistency in the data used for comparisons, but the comment lacks concrete details on how to implement this. Therefore, the comment is 3, as it highlights an issue but does not provide detailed instructions on how to resolve it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the comparability of the results in Table 2, specifically regarding the use of different amounts of data. The comment provides examples of where comparisons should be made using the same amount of data, which helps the authors understand what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the comparability of results in Table 2, specifically questioning whether the comparisons are made using the same amount of data. The reviewer provides specific examples where the data used differs, such as H>N and H>B using less data than H>N+B, and H>N>H and H>N>H using less data than H>N+B>H. This detailed analysis provides a clear basis for the claim, making it 4. However, the comment could be strengthened by further explaining why this inconsistency is problematic or how it affects the interpretation of the results. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises a valid concern about the comparability of results in Table 2, specifically questioning whether the comparisons are made using the same amount of data. It provides specific examples where the data used differs, such as H>N and H>B using less data than H>N+B, and H>N>H and H>N>H using less data than H>N+B>H. This feedback is clear and actionable, as it prompts the authors to ensure consistency in the data used for comparisons, which is crucial for accurate interpretation of the results. However, the comment could be more helpful if it suggested ways to address this issue, such as adjusting the experimental setup or providing additional explanations. Overall, the comment is 4 as it identifies a significant issue and provides a clear direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises several issues, starting with a comment about the placement of a section at the end of the paper, which is considered counterintuitive. It also questions the application of Algorithm 1 with one or two iterations and asks about the behavior for larger T. Additionally, it points out a lack of reference to Laplacian eigenmaps in Line 224 and the absence of a citation in the introduction. While the comment identifies several areas for improvement, it does not provide explicit instructions or concrete suggestions on how to address these issues. The authors can infer that they need to clarify the placement of the section, explain the behavior of Algorithm 1 for larger T, and ensure proper references and citations. However, the lack of specific guidance makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines and figures in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it details the issues with the placement of a section, the application of Algorithm 1, the lack of reference to Laplacian eigenmaps, and the absence of a citation in the introduction. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point raises several claims, each of which requires verification. The first claim about the placement of a section at the end of the paper is not supported by any reasoning or evidence, making it difficult for the authors to understand the basis of the suggestion. The second claim about the application of Algorithm 1 with one or two iterations and the behavior for larger T is also not substantiated with examples or references. The third claim regarding the lack of reference to Laplacian eigenmaps and its absence in the introduction is 3, as it points out a specific omission that could be addressed with a citation. However, the comment lacks detailed reasoning or examples to fully substantiate the claim. Overall, the review point contains multiple claims that are not fully supported, making it 2.", "helpfulness_rationale": "The review comment raises several issues that could be addressed to improve the clarity and completeness of the paper. It points out a potential counterintuitiveness in the placement of a section at the end of the paper, questioning the application of Algorithm 1 with one or two iterations and the behavior for larger T. Additionally, it notes the absence of a reference to Laplacian eigenmaps in Line 224 and the lack of a citation in the introduction. While the comment identifies specific areas for improvement, it does not provide detailed guidance or suggestions on how to address these issues. The authors are left with a general understanding of what needs to be clarified or corrected but without specific instructions on how to do so. Therefore, the comment is 3, as it highlights areas for improvement but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the inclusion of Section 2.1, suggesting that Batch Normalization is a general technique and that the description of the proposed methodology could be better used to provide greater motivation and intuition for the proposed Conditional Batch Normalization (CBN) approach. While the comment implies that the authors should reconsider the structure of their paper, it does not explicitly instruct them to remove or reorganize Section 2.1. The action is implicit and somewhat vague, as the authors are left to infer that the section might be unnecessary or could be better utilized. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the section, questioning the inclusion of Batch Normalization as a general technique and suggesting that the time spent describing the ResNet architecture could be better used to provide greater motivation and intuition for the proposed Conditional Batch Normalization (CBN) approach. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the inclusion of Section 2.1, suggesting that Batch Normalization is a general technique and that the description of the proposed methodology could be better used to provide greater motivation and intuition for the proposed Conditional Batch Normalization (CBN) approach. The comment provides a logical reasoning by pointing out that Batch Normalization is a general technique, which implies that the section might not be necessary. However, it lacks specific examples or references to support the claim that the time spent on describing the ResNet architecture could be better utilized. This makes the claim 3, as it provides a logical basis but requires more detailed justification or evidence to be fully convincing.", "helpfulness_rationale": "The review comment identifies a potential issue with the structure of the paper, specifically questioning the inclusion of Section 2.1, which describes Batch Normalization as a general technique. The reviewer suggests that the time spent on describing the ResNet architecture could be better utilized to provide greater motivation and intuition for the proposed Conditional Batch Normalization (CBN) approach. This feedback is 3 as it points out a possible redundancy in the paper and offers a suggestion for improvement. However, it lacks specific guidance on how to restructure the paper or what additional content should be included to enhance the motivation and intuition for CBN. Therefore, the comment is rated as 3, as it provides some direction but could be more comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential issue with the explanation of equation (1), questioning how a dense projection matrix could result in a sparse matrix. The reviewer suggests that multiplying by a dense matrix would not lead to sparsity, implying that the authors need to clarify their reasoning. While the comment identifies a specific area of confusion, it does not provide explicit guidance on how the authors should address this issue or clarify their explanation. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide additional explanation or justification for the sparsity assumption. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L122\" and \"equation (1),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the logic behind assuming a dense projection matrix would result in a sparse matrix, providing a clear direction for the authors to clarify their explanation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the logic behind assuming a dense projection matrix would result in a sparse matrix, suggesting that multiplying by a dense matrix would not lead to sparsity. The comment provides a logical reasoning by pointing out the contradiction between the assumption and the expected outcome. However, it does not include specific references or examples to fully substantiate the claim, leaving some gaps in the justification. Therefore, the comment is 3, as it provides a logical basis but lacks detailed evidence or references to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the explanation of equation (1), questioning how a dense projection matrix could result in a sparse matrix. It points out a potential contradiction in the authors\" reasoning, which is a valuable observation that could help the authors clarify their assumptions and explanations. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as proposing alternative explanations or suggesting additional experiments to validate the sparsity assumption. While it highlights a critical area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the statement about initialization should be more carefully stated, as initialization plays a role in the context of NGD, which is a discretization of NGF. The reviewer references a specific paper by Kunstner et al. (2019) to support this claim. While the comment implies that the authors should revise their statement on initialization, it does not provide explicit guidance on how to make the statement more accurate or detailed. The reference to the external work is a helpful starting point, but the authors still need to determine how to apply this information to their draft. Therefore, the comment is 3, as it identifies an area for improvement but lacks concrete steps for execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Initialization,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the statement about initialization should be more carefully stated, particularly in the context of NGD being a discretization of NGF and the role of initialization as an initial value problem (IVP). The comment provides a reference to a specific paper by Kunstner et al. (2019) to support the claim, which further enhances its specificity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that initialization plays a role in the context of NGD, which is a discretization of NGF, and that solving NGF is an initial value problem (IVP). The reviewer suggests that the statement about initialization should be more carefully stated, referencing a specific paper by Kunstner et al. (2019). This provides a logical basis for the claim, as the reference supports the assertion that initialization is relevant in this context. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced paper. Overall, the claim is 4, as it is supported by a reference but could benefit from additional explanation or examples.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved, namely the statement about initialization. It provides a logical reasoning by connecting the role of initialization in the context of NGD, which is a discretization of NGF, and the fact that solving NGF is an initial value problem (IVP). The comment suggests that the statement about initialization should be more carefully stated, offering a reference to a relevant paper by Kunstner et al. (2019) to support this claim. This feedback is clear and actionable, as it directs the authors to reconsider their statement on initialization and provides a reference to a potential source of information. However, the comment could be more helpful if it included specific suggestions on how to revise the statement or additional details from the referenced paper. Overall, the comment is 4, as it provides valuable guidance for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment consists of two parts. The first part, \"L200: \"for every arm a\" implies there is a single optimistic parameter, but of course it depends on a,\" is a clarification question that does not provide any explicit or implicit action for the authors to take. The second part, \"L303: Why not choose T_0 = m Sqrt(T)? Then the condition becomes B > Sqrt(m) T^(3/4), which improves slightly on what you give,\" suggests an alternative approach but does not explicitly instruct the authors to make this change. The action is implicit and somewhat vague, as it does not provide detailed guidance on how to implement the suggested improvement. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions line numbers \"L200\" and \"L303,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides a detailed critique of the statement \"for every arm a\" and suggests an alternative approach for choosing T_0. This level of detail helps the authors understand what needs to be addressed and improved in their draft. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts: a clarification question and a suggestion for improvement. The first part, \"L200: \"for every arm a\" implies there is a single optimistic parameter, but of course it depends on a,\" is a factual statement that does not require verification. The second part, \"L303: Why not choose T_0 = m Sqrt(T)? Then the condition becomes B > Sqrt(m) T^(3/4), which improves slightly on what you give,\" is a suggestion for an alternative approach. It does not contain a claim or opinion that requires verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a detailed critique of the paper, specifically addressing the statement \"for every arm a\" and suggesting an alternative approach for choosing T_0. The reviewer questions the assumption of a single optimistic parameter and offers a more complex condition that could improve the analysis. This feedback is clear and actionable, as it points out a potential weakness in the paper and suggests a specific improvement that could enhance the draft. However, the comment could be more helpful if it explained why the suggested improvement is beneficial or how it would impact the overall analysis. Overall, the comment is 4, as it provides valuable insights and guidance for the authors to consider, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment indicates that the experimental section is weak and suggests that more experiments are needed. However, it does not provide any specific guidance on what additional experiments should be conducted or how they should be designed. The action is implicit and vague, as the authors are left to infer what specific experiments are necessary without concrete details or examples. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment indicates that the experimental section is weak and suggests that more experiments are needed. However, it does not specify which part of the experimental section is weak or what specific experiments are required. This lack of detail makes it difficult for the authors to pinpoint the exact areas needing improvement. The comment is 1 as it does not identify a specific section or element of the paper, and it is not specific because it lacks detailed guidance on what additional experiments should be conducted. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the experimental section is weak and suggests that more experiments are required. However, it does not provide any specific reasoning, examples, or references to support this claim. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a weakness in the experimental section, noting that it is \"a little weak\" and suggesting that more experiments are required. However, it lacks specificity and does not provide any guidance on what additional experiments should be conducted or how they might improve the current experimental setup. Without detailed suggestions or examples, the authors are left with a general idea of what needs improvement but without actionable steps to take. This makes the comment 3, as it points out an area for enhancement but does not fully support the authors in making those improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point consists of a series of grammatical corrections and clarifications. Each correction is explicit and provides clear guidance on how to modify the text, making the actions concrete. The authors know exactly what changes to make to improve the clarity and correctness of their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (2, 56, 158, and 265) where corrections are needed. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it provides clear and actionable corrections for grammatical errors and clarifies the meaning of certain phrases. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of grammatical corrections and clarifications, which are factual statements and do not contain subjective opinions, judgments, or suggestions that require verification. It is purely descriptive and does not present any claims or assertions that need to be substantiated. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by identifying grammatical errors and suggesting corrections in the text. This is particularly helpful for the authors as it directly addresses issues with the clarity and correctness of their draft. By pointing out these errors, the comment empowers the authors to make precise improvements to their manuscript, enhancing its readability and professionalism. However, the comment could be more helpful if it also addressed the meaning of the phrase \"Effect of the modelling mixed temporalmodality features,\" as it is not grammatically correct. Overall, the feedback is 4 as it provides clear guidance on how to improve the draft, but it could be more comprehensive with additional suggestions or explanations. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance of the proposed method in pure combinational logic, suggesting that it might be easier to model without staterelated registers. It also suggests a comparison between sequential and combinational designs. While the comment implies that the authors should consider these aspects, it does not explicitly instruct them to conduct the comparison or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore these comparisons. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the performance of the proposed method in pure combinational logic, suggesting that it might be easier to model without staterelated registers. It also suggests a comparison between sequential and combinational designs. However, the comment does not specify which part of the paper this question pertains to, such as a specific section or experiment. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper being addressed. While the comment is specific in suggesting a comparison, it is 1 because it does not clearly identify the part of the paper being discussed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the performance of the proposed method in pure combinational logic, suggesting that it might be easier to model without staterelated registers. It also suggests a comparison between sequential and combinational designs. However, the comment lacks specific evidence, examples, or references to support the claim that the method performs better in combinational logic or that it would be easier to model without staterelated registers. Without such supporting information, the claim remains speculative, making it difficult for the authors to address the suggestion effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment raises an interesting question about the performance of the proposed method in pure combinational logic, suggesting that it might be easier to model without staterelated registers. It also suggests a comparison between sequential and combinational designs, which could provide valuable insights into the method\"s applicability. However, the comment lacks specificity and does not provide detailed guidance on how to conduct this comparison or what aspects to focus on. While it identifies a potential area for exploration, it does not offer actionable steps for the authors to improve their draft. Therefore, the comment is 3, as it provides some direction but lacks depth and detail."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance of the LDA+LSTM baseline in terms of the topic switch percent metric. While it does not explicitly instruct the authors to conduct a specific analysis or provide detailed guidance on how to address this curiosity, it does imply that the authors should consider evaluating the performance of this baseline. The action is implicit and somewhat vague, as it lacks concrete steps for the authors to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiment section\" and the \"baseline\" that combines LDA and LSTM, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the performance of the baseline in terms of the topic switch percent metric, providing a clear direction for the authors to address. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the performance of the LDA+LSTM baseline in terms of the topic switch percent metric. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the performance of the LDA+LSTM baseline in terms of the topic switch percent metric. While it does not provide specific suggestions for improvement or critique the methodology, it does prompt the authors to consider an important aspect of their experiment that may not have been fully explored. This feedback encourages the authors to delve deeper into their analysis and potentially expand their results to include this metric. However, the comment could be more helpful if it offered guidance on how to evaluate this metric or suggested potential improvements to the baseline. Overall, the comment is 3 as it provides a direction for further exploration but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should include experiments with GPT3.5, a more affordable option, to provide a more comprehensive evaluation of their proposed approach. While the suggestion is explicit, it lacks concrete details on how to implement this change, such as specific experimental setups or comparisons to be made. The authors are given a clear direction but may need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including experiments with GPT3.5, a more affordable option, to provide a more comprehensive evaluation of the proposed approach. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the discussion of results. This lack of explicit grounding makes it difficult for the authors to identify the exact part of the paper that needs revision. The comment is specific in suggesting the inclusion of GPT3.5 experiments, but without clear grounding, it is 3. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point suggests including experiments with GPT3.5 to provide a more comprehensive evaluation of the proposed approach. The reviewer acknowledges the expense of GPT4 but does not provide any specific reasoning or evidence to support why GPT3.5 would be a more suitable or beneficial choice. The comment lacks detailed justification or examples, making it difficult for the authors to understand the rationale behind the suggestion. Therefore, the claim is considered 2, as it provides some insight but lacks sufficient support.", "helpfulness_rationale": "The review comment suggests including experiments with GPT3.5, a more affordable option, to provide a more comprehensive evaluation of the proposed approach. While the suggestion is clear and actionable, it could be more helpful if it provided specific guidance on how to integrate GPT3.5 into the existing experiments or what aspects of the evaluation could benefit from this addition. Additionally, the comment does not address any specific weaknesses or improvements in the current draft, which limits its overall helpfulness. Therefore, the comment is 3, as it provides a clear direction for improvement but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to include bold numbers for the baselines of previous work in Table 4. It also specifies that the best result in terms of BLEU for WMT17WIKT is in the baselines, providing clear guidance on what needs to be done. This feedback is direct and concrete, giving the authors a precise action to take. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be included in the table, namely bold numbers for the baselines of previous work and the fact that the best result in terms of BLEU for WMT17WIKT is in the baselines. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that Table 4 should include bold numbers for the baselines of previous work, specifically noting that the best result in terms of BLEU for WMT17WIKT is in the baselines. This is a clear and specific request for improvement, but it does not provide any additional reasoning or evidence to support why this change is necessary or how it would enhance the paper. The comment lacks detailed justification or references, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that Table 4 should include bold numbers for the baselines of previous work. It also points out that the best result in terms of BLEU for WMT17WIKT is in the baselines, which is an important detail that should be highlighted. This feedback is clear and direct, giving the authors a concrete step to improve the presentation of their results. However, the comment could be more helpful if it explained why this information is important or how it would enhance the paper. Overall, the comment is 4 as it provides actionable guidance for improving the draft, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of sufficient evidence to support the claim about the synergies between DQD and PPO. It specifically points out that the main paper does not mention the TD3GA algorithm, which is crucial for understanding these synergies. The comment also suggests that the comparison to TD3GA should be central to the study, as it relates to the central claim about using onpolicy RL better fitting the DQD framework. While the comment identifies a specific issue and suggests a comparison that should be included, it does not provide explicit instructions on how to address the issue or conduct the comparison. The action is implicit and somewhat vague, as the authors know they need to provide more evidence and include a comparison to TD3GA, but they are not given detailed guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the claim about the synergies between DQD and PPO, specifically questioning the lack of evidence and mentioning the TD3GA algorithm. However, it does not explicitly mention which part of the paper discusses these synergies or where the TD3GA algorithm is mentioned, if at all. The authors can infer that it relates to the methodology or results sections, but this inference is not straightforward. The comment is specific in pointing out the lack of evidence and the importance of the TD3GA algorithm, but it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the claim about the synergies between DQD and PPO is insufficiently backed up, specifically noting the absence of mention of the TD3GA algorithm in the main paper. The reviewer suggests that the comparison to TD3GA is crucial to understand these synergies. This claim is 3 as it highlights a gap in the paper\"s discussion and suggests a specific comparison that could strengthen the argument. However, the comment lacks detailed reasoning or references to support the claim fully, making it 3. The authors would need to address the gap themselves to fully understand and improve the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the claim about the synergies between DQD and PPO, noting that the main paper does not mention the TD3GA algorithm, which is crucial for understanding these synergies. It also suggests that the comparison to TD3GA should be central to the study, as it relates to the central claim about using onpolicy RL better fitting the DQD framework. This feedback is clear and actionable, as it highlights a gap in the paper\"s discussion and provides a specific direction for improvement. By addressing this issue, the authors can strengthen their argument and enhance the comprehensiveness of their work. Therefore, the comment is 4, as it offers valuable guidance for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of clarity and confidence in the empirical findings due to issues with figures and empirical results. It mentions specific problems such as missing axis labels, randomly masked out portions of curves, single seed experiments, and the use of only two smallscale datasets and a single architecture type for core findings. While the comment identifies several areas for improvement, it does not provide explicit instructions on how to address these issues or what specific changes should be made. The authors can infer that they need to improve the presentation of their figures and results, but the comment lacks concrete guidance on how to do so. Therefore, the comment is 3, as it points out areas for improvement but does not provide detailed steps for execution.", "grounding_specificity_rationale": "The comment addresses issues related to the clarity and confidence in the empirical findings, specifically mentioning problems with figures and empirical results. It highlights specific issues such as missing axis labels, randomly masked out portions of curves, single seed experiments, and the use of only two smallscale datasets and a single architecture type for core findings. However, the comment does not explicitly mention which sections or figures these issues pertain to, making it weakly grounded. The authors can infer that it relates to the empirical sections, but the lack of explicit references makes it challenging to pinpoint the exact parts of the paper. The comment is specific in detailing what needs to be addressed, such as improving figure clarity and expanding empirical results. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks clarity and confidence in its empirical findings due to issues with figures and empirical results. It provides specific examples, such as missing axis labels, randomly masked out portions of curves, and single seed experiments. These examples are clear and provide a basis for the claim, making it 4. However, the comment could be strengthened by referencing specific sections or figures where these issues occur, which would enhance its verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies several specific issues that affect the clarity and confidence in the empirical findings of the paper. It points out problems with figures, such as missing axis labels and randomly masked out portions of curves, which can hinder understanding. Additionally, it highlights the use of single seed experiments and the reliance on only two smallscale datasets and a single architecture type for core findings, suggesting that these limitations may impact the generalizability of the results. While the comment provides clear and actionable feedback, it could be more helpful by offering suggestions on how to address these issues, such as recommending the use of multiple seeds or larger datasets. Overall, the comment is 4 as it directs the authors to specific areas that need improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point acknowledges the interesting findings presented in the work but notes that the novelty is limited. It provides a rationale for this observation by explaining that tighter CIs with finetuning are expected due to taskspecific finetuning increasing confidence for a specific task while potentially reducing generalizability. However, the comment does not offer any explicit or implicit actions for the authors to take in response to this feedback. It lacks guidance on how the authors might address the perceived lack of novelty or improve their work based on the observation. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment acknowledges the interesting findings presented in the paper but notes that the novelty is limited. It provides a rationale for this observation by explaining that tighter CIs with finetuning are expected due to taskspecific finetuning increasing confidence for a specific task while potentially reducing generalizability. However, the comment does not specify which part of the paper discusses these findings or observations, making it difficult for the authors to pinpoint the exact sections that need attention. Additionally, while it provides a logical explanation for the limited novelty, it lacks specific guidance on how the authors might address this issue or improve their work. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the novelty of the work is limited, citing observations like tighter CIs with finetuning as expected due to taskspecific finetuning. The reviewer provides a logical explanation for this observation, which is based on common knowledge about the effects of finetuning on confidence intervals. However, the comment lacks specific examples or references to support the claim fully, making it 3. The authors would need to consider the reasoning and potentially seek additional evidence to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the interesting findings presented in the work but points out that the novelty is limited. It provides a rationale for this observation by explaining that tighter CIs with finetuning are expected due to taskspecific finetuning increasing confidence for a specific task while potentially reducing generalizability. However, the comment lacks specific suggestions or guidance on how the authors might enhance the novelty or address the perceived limitations. Without actionable feedback or detailed advice, the comment provides limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper should report the numbers observed when the label noise experiment is performed on imagenet with 1000 classes, specifically focusing on the nontail classes. This is an explicit suggestion for additional data to be included in the paper, which would strengthen the case and further test the conjecture. The comment provides a clear and concrete action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment suggests that the paper should report the numbers observed when the label noise experiment is performed on imagenet with 1000 classes, specifically focusing on the nontail classes. This provides a clear and specific suggestion for additional data to be included in the paper. However, the comment does not explicitly mention which part of the paper this suggestion pertains to, such as a specific section or experiment. While the authors can infer that it relates to the label noise experiment, the lack of explicit grounding makes it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that reporting the numbers observed when the label noise experiment is performed on imagenet with 1000 classes would strengthen the case and further test the conjecture. The comment provides a logical reasoning for why this additional data would be valuable, as it would stress test the conjecture and potentially reveal insights about the phenomenon. However, the comment does not provide specific examples or references to support the claim, which would make it more robust. Therefore, the claim is 3, as it lacks detailed evidence but provides a logical basis for the suggestion.", "helpfulness_rationale": "The review comment suggests that the paper would benefit from reporting the numbers observed when the label noise experiment is performed on imagenet with 1000 classes, specifically focusing on the nontail classes. This suggestion is clear and actionable, as it provides a specific direction for the authors to enhance their study by testing the conjecture in a more challenging setting. The comment also acknowledges that even if the phenomenon weakens in this setting, the numbers are still worth reporting. While the comment is focused on a particular aspect of the paper, it offers a concrete way to strengthen the case and improve the draft. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the choice of the number of weight updates as a metric instead of the number of network updates, given that the brain operates in parallel. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or improve their paper. The comment lacks concrete details on what additional feedback or improvements are needed, leaving the authors uncertain about how to proceed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the choice of the number of weight updates as a metric instead of the number of network updates, given that the brain operates in parallel. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, while the comment suggests providing additional feedback to improve the paper, it does not specify what kind of feedback is needed or how it should be provided. This lack of specificity and grounding makes it challenging for the authors to address the feedback effectively. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the choice of the number of weight updates as a metric instead of the number of network updates, given that the brain operates in parallel. However, it does not provide any supporting evidence, reasoning, or references to justify why the number of weight updates is a better metric. The comment lacks specific examples or explanations to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is 1.", "helpfulness_rationale": "The review comment raises a question about the choice of the number of weight updates as a metric instead of the number of network updates, given that the brain operates in parallel. While it identifies a potential area for improvement, it lacks specificity and does not provide actionable guidance or suggestions on how the authors might address this issue. The comment suggests providing additional feedback to improve the paper, but it does not specify what kind of feedback is needed or how it should be structured. This limits the usefulness of the feedback, making it 2. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the real scenarios where the objective given by the adversarial prediction accuracy, as proposed by the authors, differs from classical prediction accuracy. While it highlights an area of potential interest, it does not provide explicit guidance or suggestions for the authors to address this question or improve their draft. The action is implicit and vague, as the authors are left to infer that they should explore or discuss real scenarios where the proposed objective differs from classical prediction accuracy. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the real scenarios where the objective given by the adversarial prediction accuracy, as proposed by the authors, differs from classical prediction accuracy. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its inquiry about the applicability of the proposed objective, but it lacks grounding as it does not reference any particular section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point poses a question about the real scenarios where the objective given by the adversarial prediction accuracy, as proposed by the authors, differs from classical prediction accuracy. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the real scenarios where the objective given by the adversarial prediction accuracy, as proposed by the authors, differs from classical prediction accuracy. This is a relevant inquiry that could help the authors clarify the practical implications and applications of their work. However, the comment does not provide any suggestions or guidance on how the authors might address this question or improve their draft. It lacks actionable feedback, leaving the authors with only a vague idea of what needs to be explored. Therefore, the comment is 2, as it identifies a potential area of interest but does not offer specific guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights several issues with the evaluation in the paper, including the lack of transparency regarding the experiment setup, the absence of information on the number of different sets of incontent examples used, and the reliance on a single dataset. The comment suggests that these issues limit the comprehensiveness and generalizability of the results. While the comment identifies specific areas that need improvement, it does not provide explicit guidance on how to address these issues or what specific actions the authors should take. The feedback is 3 as it points out the problems but lacks concrete steps for resolution. Therefore, the comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the evaluation section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the evaluation, such as the lack of transparency regarding the experiment setup, the absence of information on the number of different sets of incontent examples used, and the reliance on a single dataset. This provides clear guidance on what needs to be addressed to improve the comprehensiveness and generalizability of the evaluation. Therefore, the comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point claims that the evaluation in the paper is not sufficiently comprehensive and lacks transparency regarding the experiment setup. It highlights specific issues, such as the absence of information on the number of different sets of incontent examples used and the reliance on a single dataset, which may limit the generalizability of the results. The comment provides logical reasoning by pointing out specific areas where the evaluation could be improved, making it 4. However, it could be strengthened by providing examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies several weaknesses in the evaluation section of the paper, specifically noting the lack of transparency regarding the experiment setup, the absence of information on the number of different sets of incontent examples used, and the reliance on a single dataset. These points highlight important areas for improvement that could enhance the comprehensiveness and generalizability of the evaluation. However, the comment could be more helpful if it provided specific suggestions on how to address these issues, such as recommending the inclusion of multiple datasets or the use of different sets of incontent examples. Despite this, the feedback is 4 as it directs the authors to areas that need attention and improvement in their evaluation process. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include comparative experiments with other nonlinear blocks, such as bottleneck in ResNet or linear bottleneck in MobileNetV2, to showcase the unique advantages or potential shortcomings of their proposed method. While the comment implies that the authors should conduct these experiments, it does not provide specific guidance on how to implement them or what specific comparisons should be made. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by suggesting the inclusion of comparative experiments with other nonlinear blocks, such as bottleneck in ResNet or linear bottleneck in MobileNetV2, to showcase the unique advantages or potential shortcomings of the proposed method. This provides clear guidance on what needs to be addressed in the section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper lacks comparative experiments with other nonlinear blocks, such as bottleneck in ResNet or linear bottleneck in MobileNetV2, to showcase the unique advantages or potential shortcomings of the proposed method. This claim is 3 as it provides a logical reasoning for the need to include such comparisons to better understand the method\"s performance in a broader context. However, the comment lacks specific examples or references to existing works that have conducted similar comparisons, which would strengthen the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the lack of comparative experiments with other nonlinear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2. This feedback is clear and actionable, as it suggests that including such comparisons could help showcase the unique advantages or potential shortcomings of the proposed method in a broader context. By highlighting this gap, the comment provides the authors with a concrete direction for enhancing their draft. However, it could be more helpful if it offered specific suggestions on which blocks to compare or how to conduct these experiments. Overall, the comment is 4 as it effectively guides the authors toward improving their work, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the submission would benefit from additional attention to related work, specifically mentioning references [1], [2], and [3]. However, it does not provide any guidance on how the authors should incorporate these references or what specific aspects of the related work should be addressed. The action is implicit and lacks concrete details on how to implement the suggestion, leaving the authors uncertain about the exact steps to take. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the submission would benefit from additional attention to related work, specifically mentioning references [1], [2], and [3]. However, it does not specify which part of the paper should include this additional attention or how it should be integrated. The authors can infer that it relates to the literature review or discussion sections, but the comment lacks full grounding as it does not explicitly mention these sections. Additionally, while it suggests a specific area for improvement, it does not provide detailed guidance on what aspects of the related work should be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the submission would benefit from additional attention to related work, specifically mentioning references [1], [2], and [3]. However, the comment does not provide any reasoning or justification for why these specific references are relevant or how they could enhance the paper. Without further explanation or context, the authors may find it challenging to understand the importance of these references or how to incorporate them into their work. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the submission would benefit from additional attention to related work, specifically mentioning references [1], [2], and [3]. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on how the authors should incorporate these references or what aspects of the related work should be addressed. The comment is 3 as it points out a gap in the paper but does not offer detailed suggestions for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper should have focused more on the algorithmic aspects of the solution, implying that the novelty of the paper is limited once the concept of Blackwell winner is proposed. However, it does not provide explicit guidance on how the authors should address this issue or what specific aspects of the algorithm should be explored. The action is implicit and vague, as the authors are left to infer that they need to expand their discussion on the algorithmic aspects but are not given concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the paper should have focused more on the algorithmic aspects of the solution, implying that the novelty of the paper is limited once the concept of Blackwell winner is proposed. However, it does not specify which part of the paper should have included more algorithmic aspects or how the current focus on the concept of Blackwell winner limits the novelty. Without explicit references to specific sections or examples, the authors cannot confidently determine which parts of the paper need revision. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the paper should have focused more on the algorithmic aspects of the solution, implying that the novelty of the paper is limited once the concept of Blackwell winner is proposed. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to substantiate why the algorithmic aspects are crucial or how they could enhance the novelty of the paper. Without such support, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper should have focused more on the algorithmic aspects of the solution, implying that the novelty of the paper is limited once the concept of Blackwell winner is proposed. While it identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue. The comment does not provide actionable steps or examples of what aspects of the algorithm should be explored or how the novelty could be enhanced. As a result, the feedback is 3, as it points out a weakness but does not fully support the authors in making improvements. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should specify what \"valid\" and \"orig\" differ in, providing a clear and direct action for the authors to take. The comment is specific and provides a concrete step for the authors to follow, ensuring they know exactly what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the difference between \"valid\" and \"orig.\" This provides clear guidance on what the authors should clarify in their figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the difference between \"valid\" and \"orig\" in Fig. 5. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for additional information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the need to clarify what \"valid\" and \"orig\" differ in, as shown in Fig. 5. This feedback is clear and actionable, as it directly points out a gap in the explanation of the figure and suggests a way to enhance the clarity of the paper. By addressing this point, the authors can improve the comprehensibility of their work for readers. However, the comment could be more helpful if it provided additional context or examples of how this clarification might impact the understanding of the results. Overall, the comment is 4 as it guides the authors toward a specific improvement, but it could be more comprehensive with further elaboration."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that including a comparison to one of the methods mentioned in the computer vision setting would be more beneficial than comparing to lossbased sampling. The reviewer acknowledges that these methods may not always be applicable and typically require a supervised setup, but suggests that some of them could be adapted to language tasks relatively easily. While the comment implies that the authors should consider including such a comparison, it does not explicitly instruct them to do so or provide specific guidance on how to adapt these methods to language tasks. The action is implicit and somewhat vague, as the authors need to infer that they should consider this comparison and figure out how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that including a comparison to one of the methods mentioned in the computer vision setting would be more beneficial than comparing to lossbased sampling. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where comparisons are discussed. Additionally, while the comment provides a rationale for the suggestion, it lacks specificity in terms of which method from computer vision should be considered or how it could be adapted to language tasks. As a result, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that including a comparison to one of the methods mentioned in the computer vision setting would be more beneficial than comparing to lossbased sampling. The reviewer acknowledges that these methods may not always be applicable and typically require a supervised setup, but suggests that some of them could be adapted to language tasks relatively easily. While the comment provides a logical reasoning for the suggestion, it lacks specific examples or references to support the claim that these methods could be adapted. This makes the claim 3, as the authors would need to explore and justify the adaptation themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that including a comparison to one of the methods mentioned in the computer vision setting would be more beneficial than comparing to lossbased sampling. The reviewer acknowledges that these methods may not always be applicable and typically require a supervised setup, but suggests that some of them could be adapted to language tasks relatively easily. This feedback is 3 as it provides a specific suggestion for improvement, offering a potential direction for the authors to enhance their work. However, the comment could be more helpful if it provided examples of specific methods from computer vision that could be adapted or detailed the benefits of such a comparison. Overall, the comment is 3, as it offers a constructive suggestion but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should consider connecting the third point of definition one to the properties of universal kernels, specifically referencing chapter 4 of Steinwart and Christmann. While the comment implies that the authors should explore this connection, it does not provide explicit instructions on how to make this connection or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the third point of definition one,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting a connection to properties of universal kernels, referencing chapter 4 of Steinwart and Christmann. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests a connection between the third point of definition one and the properties of universal kernels, referencing chapter 4 of Steinwart and Christmann. This provides a specific reference to support the claim, making the comment 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how this connection might be made, which would align it with a score of 5. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment suggests a potential connection between the third point of definition one and the properties of universal kernels, as discussed in chapter 4 of Steinwart and Christmann. This feedback is 3 as it points out a possible area for further exploration or enhancement of the paper. However, the comment lacks specific guidance on how to make this connection or what aspects of the paper should be revised to incorporate this idea. While it provides a direction for improvement, it does not offer detailed actionable steps, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
