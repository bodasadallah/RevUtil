{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point highlights two issues with the adopted baseline models. First, it notes that the authors do not compare their models to Campos et al. (2020), which also uses feedback in QA tasks. Second, it points out that the authors do not compare their models to other domain adaptation methods, as mentioned in Section 8. The comment also corrects a grammatical error in the paper. While the comment identifies specific areas for improvement, it does not provide explicit guidance on how the authors should address these issues or conduct the comparisons. The actions are implicit and somewhat vague, as the authors need to infer that they should include comparisons with Campos et al. (2020) and other domain adaptation methods. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper, such as \"Line 277,\" allowing the authors to accurately identify the parts being addressed. It also specifies the issues with the adopted baseline models, noting the lack of comparison with Campos et al. (2020) and other domain adaptation methods. Additionally, it corrects a grammatical error. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the adopted baseline models are weak, providing two reasons for this assertion. First, it notes that the authors do not compare their models to Campos et al. (2020), which also uses feedback in QA tasks. Second, it points out that the authors do not compare their models to other domain adaptation methods, as mentioned in Section 8. These claims are supported by specific references to external works, providing a clear basis for the reviewer\"s critique. However, the comment could be strengthened by providing more detailed reasoning or examples of how these comparisons would improve the paper. Overall, the claim is 4, as it provides a solid foundation for the critique but lacks some depth in the explanation. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies two significant weaknesses in the paper. First, it points out that the adopted baseline models are weak, suggesting that the authors should compare their models to Campos et al. (2020), which also uses feedback in QA tasks. Second, it notes that the authors do not compare their models to other domain adaptation methods, as mentioned in Section 8. This feedback is clear and actionable, as it provides specific suggestions for improving the paper by including relevant comparisons. Additionally, the comment corrects a grammatical error, which is a minor but important detail. Overall, the comment is 5 as it offers concrete and constructive feedback that can significantly enhance the quality and comprehensiveness of the paper. Therefore, it aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point provides two explicit actions for the authors to take. First, it suggests adding that the input to the Lample et al. BiLSTMCRF model is word embeddings, similar to Lample et al. Second, it asks for clarification regarding whether the KNs in Figure 3 are in the source language or in English, given that the mentions have been translated to English. The authors are given clear instructions on what to do to improve their draft, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 2.3\" and \"Figure 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear suggestions for improvement, such as adding that the input to the Lample et al. BiLSTMCRF model is word embeddings and clarifying whether the KNs in Figure 3 are in the source language or in English. This level of detail helps the authors understand what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point consists of factual statements and requests for clarification, such as asking about the input to the Lample et al. BiLSTMCRF model and whether the KNs in Figure 3 are in the source language or English. It does not contain subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback, addressing two distinct areas for improvement. First, it suggests that the authors should clarify the input to the Lample et al. BiLSTMCRF model, which is relevant to the methodology section. Second, it questions whether the KNs in Figure 3 are in the source language or English, given that the mentions have been translated to English. This feedback is clear and directs the authors to make specific corrections or clarifications, which can enhance the clarity and accuracy of their work. However, the comment could be more helpful if it included additional context or suggestions for how these clarifications might impact the overall understanding of the paper. Overall, the comment is 4 as it provides actionable guidance for improving the draft."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the claims in the paper would benefit from more indepth analysis. However, it does not provide specific guidance on what aspects of the claims need further analysis or how the authors should conduct this analysis. The action is implicit and vague, as the authors are left to infer that they need to provide more detailed analysis but without concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the claims in the paper would benefit from more indepth analysis, but it does not specify which claims or parts of the paper are being referred to. This lack of specificity and grounding makes it difficult for the authors to identify the exact areas that need improvement. The comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that \"a number of claims from this paper would benefit from more indepth analysis.\" However, it does not provide any specific examples or reasoning to support this claim. Without detailed justification or references to particular claims or areas that need further analysis, the comment lacks verifiability. Therefore, it is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, suggesting that several claims could benefit from more indepth analysis. However, it lacks specificity and does not provide any guidance on what aspects of the claims need further analysis or how the authors might address this issue. Without detailed feedback or suggestions for improvement, the comment offers limited value to the authors in terms of actionable steps to enhance their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies two areas that need improvement in the presentation of the model: the pooling method used for embedding features and the clarity of Equation (7). It provides specific questions and suggestions for clarification, such as defining whether E_i represents the type or identity of AC i. The comment also suggests that the lefthand side of Equation (7) should be a conditional probability. These explicit and concrete actions provide clear guidance for the authors on how to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (397 and 472) and equations (7) in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies what needs to be improved, such as the pooling method used for embedding features and the clarity of Equation (7). The comment provides detailed questions and suggestions for clarification, ensuring that the authors know exactly what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a series of questions and suggestions for clarification, such as the pooling method used for embedding features and the interpretation of Equation (7). These questions are factual and do not contain subjective claims or opinions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by identifying two areas that need improvement in the presentation of the model. It asks for clarification on the pooling method used for embedding features, which is important for understanding the model\"s architecture. Additionally, it questions the clarity of Equation (7), suggesting that the random variable E_i could represent either the type or identity of AC i, and that the lefthand side of the equation should be a conditional probability. This feedback is clear and detailed, offering the authors concrete steps to enhance the clarity and comprehensibility of their work. However, the comment could be more helpful if it provided additional context or examples to further guide the authors in making these improvements. Overall, the comment is 4, as it effectively directs the authors to specific areas needing attention, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide empirical evidence to support their claim that the proposed algorithm works better for the Column Subset Selection problem. This is an explicit request for additional data or analysis to substantiate the claim made in the paper. However, the comment does not specify how the authors should conduct this empirical evaluation or what specific metrics or analyses should be used. While the action is clear, the lack of detailed guidance makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should provide empirical evidence to support their claim that the proposed algorithm works better for the Column Subset Selection problem. However, it does not specify which part of the paper this claim is made in, nor does it provide details on what specific evidence or analysis is needed. This lack of grounding makes it difficult for the authors to identify the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what kind of evidence or analysis would be most beneficial. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the authors should provide empirical evidence to support their claim that the proposed algorithm works better for the Column Subset Selection problem. However, the comment does not provide any specific examples, references, or detailed reasoning to support why this evidence is necessary or how it would improve the paper. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should provide empirical evidence to support their claim that the proposed algorithm works better for the Column Subset Selection problem. This feedback is clear and actionable, as it identifies a specific area where the paper could be strengthened by including additional data or analysis. However, the comment could be more helpful if it provided guidance on what specific metrics or analyses should be used to demonstrate the algorithm\"s effectiveness. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly recommends additional analysis and comments on the performance trends of increasing the number of parameters for ViT (DeiT) in Figure 3. It also disagrees with the authors\" viewpoint that \"Both CNNs and ViTs seem to benefit similarly from increased model capacity\" and provides specific examples to support this disagreement. The comment clearly states what needs to be addressed and provides concrete guidance on how to improve the analysis, making it 5. The authors know exactly what additional analysis and comments are needed to address the reviewer\"s concerns. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed feedback on the performance trends of increasing the number of parameters for ViT (DeiT) in Figure 3, specifically questioning the authors\" viewpoint that \"Both CNNs and ViTs seem to benefit similarly from increased model capacity.\" The comment provides specific examples and observations, such as the performance of DeiTB models on APTOS2019 and the lack of significant improvement over DeiTS on multiple datasets, which helps the authors understand what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a claim that the authors\" viewpoint on the performance of ViT (DeiT) is incorrect and provides specific examples to support this claim. It references the performance trends in Figure 3 and provides detailed observations about the performance of DeiTB models on different datasets compared to DeiTT and DeiTS. This level of detail and specific examples make the claim 5, as it provides a clear basis for the reviewer\"s disagreement. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by recommending additional analysis and comments on the performance trends of increasing the number of parameters for ViT (DeiT) in Figure 3. It challenges the authors\" viewpoint that \"Both CNNs and ViTs seem to benefit similarly from increased model capacity\" by pointing out specific instances where DeiTB models do not outperform DeiTT or DeiTS on certain datasets. The comment also highlights that CNNs can provide more consistent model improvements as capacity increases, except on the ISIC2019 dataset. This feedback is clear and constructive, offering the authors a specific area for further analysis and discussion to enhance the validity of their claims. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the proposed method is too similar to other attentional modules in previous works, specifically mentioning ResNeSt [4]. It notes that although these works did not evaluate their performance on object detection and instance segmentation, the overall structures are similar. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest ways to differentiate their work. The action is implicit and vague, as the authors are left to infer that they need to clarify the differences or provide additional context, but without concrete steps to take. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the novelty of the proposed method by comparing it to other attentional modules in previous works, specifically mentioning ResNeSt [4]. It highlights that the group attention design is similar to ResNeSt but is not discussed in the paper. However, the comment does not specify which part of the paper this comparison should be made in, making it weakly grounded. The comment is specific in detailing the similarities and differences between the proposed method and existing works, providing a clear direction for the authors to address the issue of novelty. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the novelty of the proposed method is limited due to its similarity to other attentional modules in previous works. It provides specific references to these works, which helps support the claim. However, the comment could be strengthened by providing more detailed comparisons or examples of how the proposed method differs from these previous works. This would make the claim more 5. Therefore, the comment is 4, as it provides a solid foundation for the claim but lacks comprehensive evidence or detailed comparisons.", "helpfulness_rationale": "The review comment identifies a significant issue with the novelty of the proposed method, noting that it is too similar to other attentional modules in previous works. It specifically mentions the group attention design and its resemblance to ResNeSt, which is not discussed in the paper. While the comment highlights a critical area for improvement, it lacks specific suggestions or guidance on how the authors might differentiate their work or address the similarity concerns. The feedback is 3 as it points out a key weakness, but it could be more actionable with additional guidance or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point identifies a specific issue with the \"implicit call to the Witness oracle,\" describing it as confusing. However, it does not provide any guidance or suggestions on how to clarify this aspect or what changes should be made to improve the draft. The comment lacks explicit instructions or concrete details on how to address the confusion, leaving the authors without a clear understanding of what actions to take. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment identifies a specific issue with the \"implicit call to the Witness oracle,\" suggesting that it is confusing. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact location of the problem. Additionally, the comment lacks specificity regarding what aspect of the call is confusing or how it could be clarified. Without explicit references or detailed guidance, the authors cannot effectively address the issue. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the \"implicit call to the Witness oracle\" is confusing. However, it does not provide any supporting evidence, reasoning, or examples to justify why this call is confusing. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the paper, noting that the \"implicit call to the Witness oracle\" is confusing. However, it lacks depth and does not provide any suggestions or guidance on how to clarify this aspect or improve the draft. Without actionable feedback or detailed explanations, the authors are left without a clear understanding of what changes are needed to address the confusion. Therefore, the comment is 1, as it does not offer any meaningful direction for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the authors for reproducing a wellknown result in the literature regarding left political bias in ChatGPT and LLMs in general. It questions the need for the authors to use a \"coarse\" methodology, such as passing a binary stance classifier over ChatGPT\"s output, to make this observation. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might improve their methodology or present their findings more effectively. Without actionable suggestions or a clear direction for improvement, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the authors for reproducing a wellknown result in the literature regarding left political bias in ChatGPT and LLMs in general. It questions the need for the authors to use a \"coarse\" methodology, such as passing a binary stance classifier over ChatGPT\"s output, to make this observation. However, the comment does not specify which part of the paper this critique is based on, making it difficult for the authors to identify the exact section that needs attention. Additionally, while it provides some context by mentioning the evolution of language models, it lacks specific details on what aspects of the methodology or results are problematic. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point critiques the authors for reproducing a wellknown result in the literature regarding left political bias in ChatGPT and LLMs in general. It questions the need for the authors to use a \"coarse\" methodology, such as passing a binary stance classifier over ChatGPT\"s output, to make this observation. The comment references the evolution of language models, from word2vec to BERT to ChatGPT, to support the claim that this observation has been made at each step. However, the comment lacks specific examples or references to substantiate the claim that the observation is wellknown and unnecessary. This makes the claim 3, as it provides some context but requires more detailed evidence to fully support the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the authors for reproducing a wellknown result in the literature regarding left political bias in ChatGPT and LLMs in general. It questions the need for the authors to use a \"coarse\" methodology, such as passing a binary stance classifier over ChatGPT\"s output, to make this observation. The comment points out that this observation has been made at each step of the evolution of language models, from word2vec to BERT to ChatGPT, and suggests that the authors should provide a more nuanced or novel approach to their analysis. However, the comment lacks specific suggestions or guidance on how the authors might improve their methodology or present their findings more effectively. While it identifies a potential weakness, it does not provide actionable feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to clarify the distinction between when their proposed method is trained using only weak supervision and when it is semisupervised trained. It provides a specific suggestion for renaming the column in Table 1 to \"Fully supervised\" from \"Supervised\" to reflect the semisupervised training. Additionally, it proposes a more comprehensive approach by specifying the data used to train each model and suggesting two big columns to differentiate between mixture and singlesource data. This feedback is clear and provides concrete steps for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the distinction between when the proposed method is trained using only weak supervision and when it is semisupervised trained. The comment provides a specific suggestion for renaming the column in Table 1 and proposes a more comprehensive approach for differentiating between mixture and singlesource data. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors clarify the distinction between when their proposed method is trained using only weak supervision and when it is semisupervised trained. It provides a specific example by suggesting a renaming of the column in Table 1 to \"Fully supervised\" from \"Supervised.\" The comment also proposes a more comprehensive approach by specifying the data used to train each model and suggesting two big columns to differentiate between mixture and singlesource data. This feedback is clear and provides a logical reasoning for the suggested changes, making it 4. However, the comment could be strengthened by providing more detailed examples or references to support the proposed changes. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides clear and actionable feedback by identifying a specific area where the paper lacks clarity: the distinction between when the proposed method is trained using only weak supervision and when it is semisupervised trained. It suggests a specific change to Table 1, recommending the renaming of a column to \"Fully supervised\" from \"Supervised\" to reflect the semisupervised training. Additionally, the comment proposes a more comprehensive approach by specifying the data used to train each model and suggesting two big columns to differentiate between mixture and singlesource data. This feedback is detailed and provides concrete steps for the authors to improve the clarity and organization of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that the authors should expand their experiments to include more datasets from the Federated learning benchmarks, such as LEAF, and consider relevant works like FedProx and FedMAX. It provides specific examples of datasets and references to relevant literature, which gives the authors clear guidance on how to improve their experimental section. The comment also highlights the importance of a comprehensive experimental evaluation for the paper to be considered strong. This level of detail and specificity makes the action 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiments section\" and the \"results presented only on CIFAR10 dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the experiments, namely the lack of consideration for other datasets from Federated learning benchmarks and the need to include relevant works like FedProx and FedMAX. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments section is weak due to the limited dataset used (CIFAR10) and the lack of consideration for other datasets from Federated learning benchmarks. The reviewer suggests that the authors should refer to relevant works like FedProx and FedMAX for details on different datasets and model types. This claim is 4 as it provides specific references to external works that could be used to expand the experimental evaluation. However, the comment could be strengthened by providing more detailed reasoning or examples of how these works could be applied to enhance the paper. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, specifically the limited scope of the experiments, which are only conducted on the CIFAR10 dataset. It highlights the importance of considering other datasets from Federated learning benchmarks, such as LEAF, and suggests that the authors should refer to relevant works like FedProx and FedMAX for details on different datasets and model types. This feedback is clear and actionable, providing the authors with specific guidance on how to improve the comprehensiveness of their experimental evaluation. By addressing this issue, the authors can significantly enhance the strength and impact of their paper. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should use a more convincing setting for their unlabeled data, similar to the one used in the Adaptive Semisupervised Learning for Crossdomain Sentiment Classification paper by He et al. (2018). The comment explicitly states that the current setting, which uses perfectly balanced unlabeled data, is impractical in realworld applications. It provides a specific reference to a paper that uses a more convincing setting, which gives the authors a clear direction for improvement. However, the comment could be more actionable by explaining why the current setting is impractical or how the suggested setting would be more convincing. Overall, the comment is 4 as it provides a concrete suggestion with a reference, but it could be more detailed in its explanation.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"unlabeled data (2000) from the preprocessed Amazon review dataset (Blitzer version),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the data is perfectly balanced, which is impractical in realworld applications. The comment further suggests using a more convincing setting, referencing a specific paper by He et al. (2018) for guidance. This level of detail provides clear guidance on what needs to be addressed and how, making the comment 5. Therefore, this comment aligns with a score of 5.", "verifiability_rationale": "The review point claims that the use of perfectly balanced unlabeled data from the Amazon review dataset is impractical in realworld applications. It suggests that the authors should use a more convincing setting, referencing a specific paper by He et al. (2018) for guidance. The claim is 3 as it provides a reference to a specific paper that uses a different approach, offering a basis for the suggestion. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced paper to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of perfectly balanced unlabeled data from the Amazon review dataset, which the reviewer argues is impractical in realworld applications. The comment suggests that the authors should use a more convincing setting, referencing a specific paper by He et al. (2018) for guidance. This feedback is clear and actionable, as it provides a specific example of a more realistic approach and directs the authors to a relevant reference. By suggesting a change in methodology and offering a concrete reference, the comment offers valuable guidance for improving the draft. However, it could be more helpful if it explained why the current setting is impractical or how the suggested approach would be more convincing. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a confusion in the description of the MFDA setting, specifically regarding the use of unlabeled data in source domains. It questions whether the unlabeled data in source domains are used during training, as in the original MFDA paper. The comment also points out a discrepancy between the problem setting description and the original MFDA paper. While the comment highlights an issue, it does not provide explicit instructions or concrete suggestions on how the authors should address this confusion or align their description with the original paper. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the description and align it with the original paper. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"first paragraph of the Method Section\" and references specific elements within that paragraph, such as the use of \"sparse labels\" and the notation for the target domain. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it details the confusion regarding the use of unlabeled data in source domains and the discrepancy with the original MFDA paper. It raises questions about the problem setting description and suggests that the authors clarify these points. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the confusion in the description of the MFDA setting, specifically regarding the use of unlabeled data in source domains. It references the original MFDA paper (Yue et al., 2021a) to highlight a discrepancy in the problem setting description. The comment questions whether the unlabeled data in source domains are used during training, as in the original paper. This provides a logical basis for the claim, as it points out a potential inconsistency in the paper\"s description. However, the comment could be strengthened by providing more detailed examples or references to specific sections in the paper where this confusion arises. Overall, the claim is 4, as it provides a logical reasoning and references an external work, but it lacks detailed evidence or examples within the paper itself. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a significant confusion in the description of the MFDA setting, specifically regarding the use of unlabeled data in source domains. It points out a discrepancy between the paper\"s description and the original MFDA paper, questioning whether the unlabeled data in source domains are used during training. This feedback is valuable as it highlights a critical issue that could lead to misunderstandings in the paper. However, the comment could be more helpful if it provided specific suggestions on how to clarify the description or align it with the original paper. Despite this, the comment is 4 as it directs the authors\" attention to a crucial area that needs clarification, making it a 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights several issues with the paper, including the incremental nature of the contribution, the lack of citation for key baselines, and the absence of essential RAG algorithms like MedRetriever and KGRAG. While the comment identifies specific areas that need attention, it does not provide explicit instructions or concrete suggestions on how the authors should address these issues. The authors are left to infer that they should include these citations and algorithms, but the comment lacks detailed guidance on how to implement these changes. Therefore, the comment is 3, as it points out areas for improvement but does not provide direct steps for the authors to take.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"your code\" and \"the details in the article,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the incremental nature of the contribution, the lack of citation for key baselines, and the absence of essential RAG algorithms like MedRetriever and KGRAG. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the contribution of the article is incremental, stating that it is essentially a combination of GraphRAG and GraphCare. It also points out the lack of citation for key baselines and suggests that essential RAG algorithms like MedRetriever and KGRAG should have been introduced. While the comment provides some reasoning by referencing specific algorithms, it lacks detailed justification or examples to fully substantiate the claim about the incremental nature of the contribution. The mention of specific algorithms and baselines adds some support, but the overall justification is not robust. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed evidence or examples to be fully convincing.", "helpfulness_rationale": "The review comment provides a detailed critique of the paper, identifying several areas for improvement. It highlights the incremental nature of the contribution, noting that it is essentially a combination of existing methods like GraphRAG and GraphCare. The comment also points out the lack of citation for key baselines and suggests that essential RAG algorithms, such as MedRetriever and KGRAG, should have been introduced. This feedback is valuable as it helps the authors understand the limitations of their work and provides specific suggestions for improvement, such as including relevant citations and introducing additional algorithms. However, the comment could be more helpful if it offered guidance on how to integrate these algorithms or suggestions for enhancing the original contribution. Overall, the comment is 4, as it provides clear and actionable feedback that can guide the authors in improving their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a missing stateoftheart reference in the experiment of face recognition, specifically mentioning the work \"Targeting Ultimate Accuracy: Face Recognition via Deep Embedding\" by Baidu. It also provides a link to the work and notes that the triplet loss is used, reporting results on a dataset similar to Webface. The comment further compares the results achieved by the VRF on LFW, noting that it is better than the results presented in Table 3 of the paper. This feedback is explicit and provides concrete details on what reference should be included and how it compares to the current results. The authors know exactly what action to take to improve their draft by adding this reference and potentially revising their results. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiment of face recognition\" and the \"stateoftheart references,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the missing reference, \"Targeting Ultimate Accuracy: Face Recognition via Deep Embedding\" by Baidu, and provides a link to the work. Additionally, it details the comparison with the VRF results on LFW, noting that it is better than the results in Table 3. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that some stateoftheart references are missing in the experiment of face recognition, specifically mentioning the work \"Targeting Ultimate Accuracy: Face Recognition via Deep Embedding\" by Baidu. The reviewer provides a link to the work and notes that it uses the triplet loss and reports results on a dataset similar to Webface. The comment further compares the results achieved by the VRF on LFW, noting that it is better than the results presented in Table 3 of the paper. This level of detail, including references and comparisons, provides a robust basis for the claim, making it 5. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, noting the absence of certain stateoftheart references in the experiment of face recognition. It mentions a particular work by Baidu, \"Targeting Ultimate Accuracy: Face Recognition via Deep Embedding,\" and provides a link to the work. The comment also highlights that the work uses the triplet loss and reports results on a dataset similar to Webface, which is relevant to the paper. Additionally, it compares the results achieved by the VRF on LFW, noting that it is better than the results presented in Table 3 of the paper. This feedback is actionable and provides clear guidance on how to enhance the paper by including relevant references and potentially revising the results. However, it could be more helpful if it offered suggestions on how to integrate these references or discuss the implications of the comparison. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to cite the source of the rockpaperscissors example, which is clearly inspired by an example from previous work. This is a direct and concrete action, leaving no ambiguity about what the authors need to do. The comment provides a clear and specific instruction, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"rockpaperscissors example,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of not citing the source of the example, which is inspired by previous work. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the rockpaperscissors example is inspired by an example from previous work and requests appropriate citation. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to verify the claim or identify the source of inspiration. Without detailed evidence or references, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the rockpaperscissors example is inspired by an example from previous work and requests appropriate citation. This feedback is clear and actionable, as it directs the authors to address a potential issue with plagiarism or lack of attribution. By citing the source, the authors can ensure proper credit and avoid any potential ethical or academic integrity concerns. However, the comment could be more helpful if it provided examples of similar work or suggested how to integrate the citation into the text. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review comment points out a specific line in the paper (L.490) where the authors mention taking the embedding of the first subword token as the verb embedding. It suggests that it is also common to average over subword representations, as demonstrated by a reference to Hewitt and Manning (2019, footnote 4). While the comment highlights a potential alternative approach, it does not explicitly instruct the authors to adopt this method or provide detailed guidance on how to implement it. The action is implicit and somewhat vague, as the authors can infer that they might consider averaging over subword representations but are not given explicit instructions on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L.490,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out a potential alternative approach to handling subword representations, referencing Hewitt and Manning (2019, footnote 4). This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point provides a specific reference to Hewitt and Manning (2019, footnote 4), which supports the claim that averaging over subword representations is a common practice. This reference provides a clear and explicit example, making the claim 5. The inclusion of a specific reference enhances the credibility and justification of the claim, ensuring that the authors can understand and address the suggestion effectively. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the paper by pointing out a common practice in handling subword representations, as demonstrated by a reference to Hewitt and Manning (2019, footnote 4). This feedback is actionable and offers a concrete alternative approach that the authors can consider to enhance their methodology. By suggesting a specific reference and practice, the comment is 5 as it provides clear guidance for improving the draft. Therefore, it aligns with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point acknowledges the comprehensive experiments conducted by the authors to validate the efficacy of CATER in various settings, including an architectural mismatch and crossdomain imitation. However, it does not provide any explicit or implicit suggestions for improvement or areas that need further exploration. Without any actionable feedback or guidance, the authors are left without a clear understanding of how to enhance their work based on this comment. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment acknowledges the comprehensive experiments conducted by the authors to validate the efficacy of CATER in various settings, including an architectural mismatch and crossdomain imitation. However, it does not specify which part of the paper these experiments are discussed in, nor does it provide any feedback or suggestions for improvement. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention. Additionally, the comment lacks specificity regarding what aspects of the experiments could be improved or what additional analysis might be beneficial. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point acknowledges the comprehensive experiments conducted by the authors to validate the efficacy of CATER in various settings, including an architectural mismatch and crossdomain imitation. However, it does not express any opinions, judgments, or suggestions that require verification. It is purely descriptive, making it a factual statement without a claim. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment acknowledges the comprehensive experiments conducted by the authors to validate the efficacy of CATER in various settings, including an architectural mismatch and crossdomain imitation. However, it does not provide any feedback, suggestions, or critique that could help the authors improve their work. Without any actionable advice or guidance, the comment lacks value and does not assist the authors in enhancing their draft. Therefore, it is rated as 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the bounded noise assumption as somewhat restrictive in the context of stochastic optimization literature. It mentions several efforts to extend these noise conditions, referencing specific works by A. Khaled and P. Richt\"arik, and R. Gower, O. Sebbouh, and N. Loizou. However, the comment does not provide explicit guidance or suggestions for the authors on how to address this issue in their own work. While it identifies a potential area for improvement, it lacks actionable details on how the authors might incorporate these extensions or address the bounded noise assumption. Therefore, the comment is 3, as it points out a limitation but does not offer concrete steps for improvement.", "grounding_specificity_rationale": "The comment addresses the bounded noise assumption, which is a specific aspect of the paper. However, it does not specify which part of the paper discusses this assumption, making it weakly grounded. The comment is specific in mentioning efforts to extend these noise conditions and provides references to specific works by A. Khaled and P. Richt\"arik, and R. Gower, O. Sebbouh, and N. Loizou. This provides a clear direction for the authors to consider in their work. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the bounded noise assumption is somewhat restrictive in the stochastic optimization literature and references several efforts to extend these noise conditions. The claim is supported by specific references to works by A. Khaled and P. Richt\"arik, and R. Gower, O. Sebbouh, and N. Loizou. These references provide a basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed explanations or examples from these works to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment highlights a potential limitation in the paper, specifically the bounded noise assumption, which is somewhat restrictive in the stochastic optimization literature. It provides references to several efforts to extend these noise conditions, which could be valuable for the authors to consider in their work. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or incorporate these extensions into their own work. While it identifies a relevant area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as 3, as it provides some insight but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the meaning of \"100 steps\" in the context of a search model comparison. It asks whether this refers to 100 sampled strategies. This comment is explicit in its request for clarification, as it directly asks for an explanation of the term \"100 steps.\" However, it does not provide any guidance on how the authors should address this issue or what specific information should be included in the explanation. The action is explicit but lacks concrete details on how to implement the clarification, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Search models comparison 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the meaning of \"100 steps\" and whether it refers to 100 sampled strategies. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the meaning of \"100 steps\" in the context of a search model comparison. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the meaning of \"100 steps\" in the context of a search model comparison, specifically asking if it refers to 100 sampled strategies. This is a clear and specific question that prompts the authors to clarify an aspect of their work that may be unclear to readers. By addressing this question, the authors can ensure that their explanation is clear and comprehensible, which is important for the understanding and reproducibility of their results. However, the comment does not provide any additional suggestions or feedback beyond the clarification request. Therefore, while it is 3 in identifying a specific area for improvement, it lacks depth and does not fully guide the authors in enhancing their draft. Overall, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment raises a concern about the modulator being heuristically designed, questioning whether there might be scalability issues that require tedious hyperparameter tuning for diverse training data. However, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve the scalability of their modulator. The comment lacks actionable details, such as recommending specific methods or approaches to mitigate potential scalability issues. As a result, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the modulator being heuristically designed, questioning its scalability and potential need for tedious hyperparameter tuning for diverse training data. However, it does not specify which part of the paper discusses the modulator or its design, making it difficult for the authors to pinpoint the exact section that needs attention. The comment lacks specificity as it does not provide detailed guidance on what aspects of the modulator design or scalability need to be addressed. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a concern about the modulator being heuristically designed, questioning its scalability and potential need for tedious hyperparameter tuning for diverse training data. However, the comment lacks specific examples, references, or detailed reasoning to support the claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the modulator being heuristically designed, questioning its scalability and potential need for tedious hyperparameter tuning for diverse training data. While it identifies a potential issue, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this concern. Without detailed feedback or recommendations, the authors are left without a clear understanding of what steps to take to improve the scalability or design of their modulator. Therefore, the comment is 2, as it highlights an area for improvement but does not offer sufficient guidance for the authors to effectively address it."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment acknowledges the interesting aspect of the OOD experiments, noting that the trained network provides strong OOD generalization. However, it suggests that the authors should mention recent papers that have shown the effectiveness of untrained NNs in solving inverse problems across a wide class of images. The comment implies that the authors should place their method in context and potentially compare it with these methods. While the action is implicit, it is concrete in suggesting specific areas for improvement, such as mentioning recent papers and comparing with other methods. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the OOD experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion to mention recent papers that have shown the effectiveness of untrained NNs in solving inverse problems across a wide class of images. The comment further suggests placing the current method in context and comparing it with those methods. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point acknowledges the interesting aspect of the OOD experiments and the strong OOD generalization provided by the trained network. However, it suggests that the authors should mention recent papers that have shown the effectiveness of untrained NNs in solving inverse problems across a wide class of images. This claim is 3 as it references specific papers (Ulyanov et al., CVPR 2018) and provides a logical reasoning for the suggestion. However, the comment could be strengthened by providing more detailed references or examples of these papers to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the interesting aspect of the OOD experiments, noting the strong OOD generalization provided by the trained network. However, it suggests that the authors should mention recent papers that have shown the effectiveness of untrained NNs in solving inverse problems across a wide class of images. This feedback is valuable as it encourages the authors to place their work in context and potentially compare it with existing methods, which could enhance the paper\"s contribution. The comment provides a clear and actionable suggestion for improvement, making it 4. However, it could be more comprehensive by offering specific examples or references to these recent papers, which would further enhance its helpfulness. Therefore, the comment is rated as 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies specific issues with the first two sections of the paper, noting that the author has stacked a number of previous approaches without clear explanations. It provides examples of unclear sections, such as the conversion of stacked LSTM in Fig 2(a) to sequential LSTM in Fig 2(b), and the sentence \"our lower hierarchical layers zoom in time.\" These examples help the authors understand what needs to be clarified or explained. The comment is explicit in its suggestions for improvement, as it points out specific areas where the authors need to provide more detailed explanations. However, it does not offer detailed guidance on how to improve the explanations or what specific information should be included. Therefore, the comment is 4, as it provides clear direction but lacks detailed instructions on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first two sections of the paper, allowing the authors to accurately identify the parts being addressed. It also provides specific examples of what is unclear, such as the conversion of stacked LSTM in Fig 2(a) to sequential LSTM in Fig 2(b), and the sentence \"our lower hierarchical layers zoom in time.\" This level of detail helps the authors understand exactly what needs to be clarified or explained. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements and questions, such as \"I do not understand why the stacked LSTM in Fig 2(a) is \"trivial\" to convert to the sequential LSTM Fig2(b),\" and \"I do not understand the sentence \"our lower hierarchical layers zoom in time\" and the sentence following that.\" These statements are descriptive and do not contain subjective opinions, judgments, or suggestions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies specific issues with the first two sections of the paper, noting that the author has stacked a number of previous approaches without clear explanations. It provides examples of unclear sections, such as the conversion of stacked LSTM in Fig 2(a) to sequential LSTM in Fig 2(b), and the sentence \"our lower hierarchical layers zoom in time.\" This feedback is actionable as it directs the authors to clarify and explain their methods more effectively. However, the comment could be more helpful if it offered suggestions on how to improve the explanations or provided examples of clear explanations. Overall, the comment is 4 as it highlights areas for improvement and guides the authors toward enhancing the clarity of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point raises concerns about the goal of the paper and the lack of comparison or justification for the proposed method. It suggests that if the paper claims to be a foundation model, it should be clearer and should demonstrate or justify a future useful application. While the comment implies that the authors should clarify the paper\"s goal and provide comparisons or justifications, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the paper\"s goal and provide comparisons or justifications. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the goal of the paper and references a specific earthquake detector, \"PhaseNetDas,\" by Zhu et al. (2023), which the authors cited. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue with the paper\"s goal, namely the lack of comparison or justification for the proposed method, and suggests that the authors should clarify their claims and demonstrate or justify a future useful application. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the paper\"s goal and the lack of comparison or justification for the proposed method. It suggests that if the paper claims to be a foundation model, it should be clearer and should demonstrate or justify a future useful application. The comment references a specific earthquake detector, \"PhaseNetDas,\" by Zhu et al. (2023), which the authors cited, providing some context. However, the claim is 4 as it lacks detailed reasoning or examples of how the proposed method could be compared or applied in a future context. The reference to PhaseNetDas provides some support but does not fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises a critical concern about the paper\"s goal and the lack of comparison or justification for the proposed method. It points out that while earthquake detectors like PhaseNetDas exist, the paper does not compare or justify its method against these existing detectors. If the paper claims to be a foundation model, it should be clearer and should demonstrate or justify a future useful application. This feedback is clear and actionable, as it identifies a specific gap in the paper and suggests ways to address it. By highlighting the need for comparison and justification, the comment provides the authors with a clear path to improve their draft. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that similar analyses are already present in prior works, suggesting that the results are not particularly surprising. It references specific examples, such as the robustness of CIFAR10 models on distribution shifts, which were studied in RobustBench and by [A, B]. However, the comment does not provide explicit guidance or suggestions for the authors to address this issue. It lacks actionable details on how the authors might differentiate their work or present their findings in a novel or more impactful manner. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific prior works and analyses, such as the robustness of CIFAR10 models on distribution shifts, which were studied in RobustBench and by [A, B]. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it details the existing analyses and their similarity to the current work, providing a clear basis for the authors to understand what needs to be addressed. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that similar analyses are already present in prior works, suggesting that the results are not particularly surprising. It supports this claim by referencing specific examples, such as the robustness of CIFAR10 models on distribution shifts, which were studied in RobustBench and by [A, B]. This provides a clear and logical basis for the claim, making it 5. The inclusion of specific references and examples enhances the credibility of the claim, allowing the authors to understand the context and potential limitations of their work. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment highlights that similar analyses are already present in prior works, suggesting that the results are not particularly surprising. It references specific examples, such as the robustness of CIFAR10 models on distribution shifts, which were studied in RobustBench and by [A, B]. This feedback is 3 as it alerts the authors to the potential limitations of their work and the need to differentiate it from existing studies. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or present their findings in a novel or more impactful manner. While it provides some insight into the context of the work, it does not offer actionable advice for improvement, making it 3 but incomplete."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies two specific issues with the paper. First, it points out that the statement about the Walkman algorithm being solved by ADMM is inaccurate, as it has two versions, one solving a local optimization problem and the other solving a gradient approximation. This feedback is explicit and provides a clear action for the authors to correct the statement. Second, the comment notes that the reference to \"it\" in Section 3 is unclear, suggesting that the authors need to clarify the reference. Both points are explicit and provide concrete guidance on how to improve the draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Page 2, second paragraph in Related Work\" and \"Section 3, first paragraph,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the inaccuracies in the statement about the Walkman algorithm and clarifies the reference to \"it\" in Section 3. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point consists of two claims. The first claim challenges the statement that the Walkman algorithm is solved by ADMM, pointing out that it has two versions, one solving a local optimization problem and the other solving a gradient approximation. This claim is 3 as it provides a specific critique of the statement, but it lacks detailed reasoning or references to support the assertion about the two versions of the algorithm. The second claim points out an unclear reference to \"it\" in Section 3, which is a factual observation requiring no verification. Therefore, the overall comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on two separate issues. First, it corrects an inaccurate statement about the Walkman algorithm being solved by ADMM, pointing out that it has two versions, one solving a local optimization problem and the other solving a gradient approximation. This feedback is clear and helps the authors ensure the accuracy of their claims. Second, it identifies an unclear reference to \"it\" in Section 3, which the authors need to clarify. Both points are specific and provide clear guidance for improvement, making the comment 4. However, it could be more helpful if it offered suggestions on how to clarify the reference or provided additional context for the correction. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should add more experiments to demonstrate the effectiveness of their proposed method. It explicitly states that the authors should include additional experimental comparisons with other works, such as those mentioned in references [1, 2, 3]. This feedback is clear and provides a direct action for the authors to take, making it 5. The comment is specific about what needs to be done, which is to include more experiments, and it even provides examples of works to consider for comparison. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by suggesting the addition of more experiments to demonstrate the effectiveness of the proposed method. The comment provides examples of other works that focus on similar questions, which further guides the authors on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should include more experiments to demonstrate the effectiveness of their proposed method. It claims that there are several works focusing on similar questions, and references [1, 2, 3] as examples. However, the comment does not provide specific details or examples from these references to support the claim that additional experiments are necessary. The lack of detailed reasoning or references makes it difficult for the authors to fully understand and address the suggestion. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient evidence or examples to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a specific weakness in the experimental section, noting that the authors have only compared their work with two baselines. It suggests that more experiments should be conducted to demonstrate the effectiveness of the proposed method, particularly by including comparisons with other works that focus on similar questions. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their experimental section by adding additional comparisons. However, the comment could be more helpful if it included suggestions on which specific works to consider or how to structure the additional experiments. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that more information is needed regarding the filtering process used to create the Arabic climate change QA dataset, specifically the translation and filtering methodology. This provides a clear action for the authors to take, which is to provide additional details on these aspects. The comment is explicit and concrete, as it specifies exactly what information is missing and what needs to be addressed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"filtering process\" used to create the Arabic climate change QA dataset, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is lacking, namely more information on the translation and filtering methodology, which is necessary to assess the dataset quality. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the details around the filtering process used to create the Arabic climate change QA dataset are lacking. It suggests that more information on the translation and filtering methodology is needed to assess the dataset quality. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the missing information. The lack of detailed justification or evidence makes the claim 3, as it requires the authors to infer the specific details needed to address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks detail, namely the filtering process used to create the Arabic climate change QA dataset. It highlights the need for more information on the translation and filtering methodology to assess the dataset quality. This feedback is clear and actionable, as it directs the authors to provide additional details that are crucial for evaluating the dataset\"s reliability and usefulness. By addressing this point, the authors can enhance the transparency and credibility of their work. However, the comment could be more helpful if it provided specific suggestions on what aspects of the methodology should be detailed or examples of what information would be beneficial. Overall, the comment is 4, as it guides the authors toward improving their draft but could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly states that the Related Work section lacks details and suggests that the paragraph on longcontext language models should provide a more comprehensive overview of existing methods and their limitations. It specifically mentions several types of methods that should be discussed, including sparseattention mechanisms, segmentationbased approaches, memoryenhanced segmentation strategies, and recursive methods. This feedback provides clear and concrete guidance on what needs to be added to the Related Work section, making it 5. The authors know exactly which methods to include and how to position SSMs in relation to these existing approaches. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Related Work\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed guidance on what is lacking in the section, specifically suggesting that the paragraph on longcontext language models should include a more comprehensive overview of existing methods and their limitations. The comment explicitly mentions several types of methods that should be discussed, such as sparseattention mechanisms, segmentationbased approaches, memoryenhanced segmentation strategies, and recursive methods. This level of detail provides clear direction on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the Related Work section lacks details and suggests that the paragraph on longcontext language models should provide a more comprehensive overview of existing methods and their limitations. The comment supports this claim by explicitly mentioning specific types of methods that should be discussed, such as sparseattention mechanisms, segmentationbased approaches, memoryenhanced segmentation strategies, and recursive methods. This provides a clear and detailed rationale for the claim, making it 5. The inclusion of references [1, 2, 3, 4, 5, 6, 7] further strengthens the verifiability by providing specific examples of relevant literature. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a specific weakness in the Related Work section, noting that it lacks details and does not provide a comprehensive overview of existing methods and their limitations. It suggests that the paragraph on longcontext language models should include a discussion of sparseattention mechanisms, segmentationbased approaches, memoryenhanced segmentation strategies, and recursive methods for handling very long documents. This feedback is clear and actionable, as it provides specific guidance on what the authors need to address to improve the Related Work section. By following this advice, the authors can enhance the depth and comprehensiveness of their literature review, which is crucial for establishing the novelty and significance of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the writing should be improved, indicating that certain points in the paper are unclear. However, it does not specify which points are unclear or how the writing could be improved. The action is implicit and vague, as the authors are left without clear guidance on what specific changes to make. Without concrete details or examples, the authors may struggle to determine how to address the issue. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the writing should be improved and mentions that some points in the paper are unclear. However, it does not specify which parts of the paper are unclear or how the writing could be improved. Without explicit references to sections, figures, or specific content, the authors cannot confidently determine which parts of the paper need attention. The comment is 1 because it does not identify a specific area, and it is not specific because it lacks detailed guidance on what needs to be clarified or improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the writing should be improved because some points in the paper are unclear. However, it does not provide specific examples or details about what is unclear or how the writing could be improved. Without such details, the claim lacks sufficient evidence or justification, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the writing should be improved, indicating that some points in the paper are unclear. However, it lacks specificity and does not provide detailed guidance or examples of what needs to be clarified or improved. Without actionable feedback or suggestions, the authors are left without a clear understanding of how to address the issue. This makes the comment 2, as it identifies a potential problem but does not offer meaningful guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the synthetic experiment in a nonseparable case, questioning how the data distribution illustrated in Figure 1 is inseparable from the network model, given the nonlinear expression ability of neural networks. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on what specific aspects of the experiment or explanation need to be addressed or improved. Without actionable suggestions or a clear direction for the authors, this comment leaves them without a clear path forward. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the synthetic experiment in a nonseparable case, mentioning the nonlinear expression ability of neural networks and the data distribution illustrated in Figure 1. However, it does not specify which part of the paper discusses this experiment or where Figure 1 is located, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the data distribution and its relationship to the network model, but it lacks grounding as it does not explicitly mention the section or figure being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the synthetic experiment in a nonseparable case, questioning how the data distribution illustrated in Figure 1 is inseparable from the network model, given the nonlinear expression ability of neural networks. However, the comment lacks specific examples, detailed reasoning, or references to support the claim that the data distribution is indeed inseparable. Without such evidence or explanation, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered 2, as it provides a basis for the claim but requires more detailed justification.", "helpfulness_rationale": "The review comment identifies a specific issue with the synthetic experiment in a nonseparable case, questioning how the data distribution illustrated in Figure 1 is inseparable from the network model, given the nonlinear expression ability of neural networks. This is a relevant observation that could lead to a deeper understanding of the experiment and its results. However, the comment lacks actionable suggestions or guidance on how the authors might address this issue or improve their explanation. Without specific feedback or direction, the authors may struggle to determine how to enhance their draft. Therefore, the comment is 3, as it points out a potential area for improvement but does not provide detailed guidance on how to address it."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a concern about the efficiency of pairwise matching, suggesting that it is not suitable for practical application systems. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve efficiency or what specific changes could be made to enhance the practicality of the system. Without actionable suggestions or concrete steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a concern about the efficiency of pairwise matching, suggesting it is not suitable for practical application systems. However, it does not specify which part of the paper discusses this issue, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of efficiency are problematic or how they could be improved. Without clear guidance or references to specific sections, the authors cannot effectively address the feedback. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the efficiency of pairwise matching is low, making it difficult to use in practical application systems. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references to justify the assertion, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a potential issue with the efficiency of pairwise matching, suggesting that it may not be suitable for practical application systems. However, it lacks specificity and does not provide any actionable advice or suggestions on how the authors might address this concern. Without detailed guidance or examples, the authors are left without a clear understanding of what changes or improvements could be made to enhance the efficiency of their approach. As a result, the comment is not particularly helpful, as it identifies a problem but does not offer a path for resolution. Therefore, it aligns with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point acknowledges the addition of a method to improve transferability as a positive step but dismisses it as not being a significant contribution. However, it does not provide any specific guidance or suggestions on how the authors might enhance their contribution or address the reviewer\"s concerns. The comment lacks actionable details, leaving the authors uncertain about what steps to take to improve their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper discusses the addition of a method to improve transferability. It also lacks specificity because it does not provide details on what aspects of the contribution are considered insignificant or how the authors might address this concern. Without clear references to the paper or specific suggestions for improvement, the authors cannot effectively respond to the feedback. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that adding a method to improve transferability is a positive step but not a significant contribution. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this addition is not significant. Without additional context or explanation, the claim remains 1, as it lacks the necessary details to substantiate the opinion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment acknowledges the addition of a method to improve transferability as a positive step but dismisses it as not being a significant contribution. However, it does not provide any specific feedback or suggestions on how the authors might enhance their contribution or address the reviewer\"s concerns. The comment lacks actionable guidance or detailed critique, leaving the authors without a clear understanding of what aspects of their work need improvement. As a result, the comment is 1, as it does not offer any constructive feedback that could assist the authors in enhancing their draft."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point consists of multiple comments, each addressing different aspects of the paper. The first comment suggests toning down the statement about the neural network memorizing critical points, providing a specific reference to TopoNet [24] to support the suggestion. This is an explicit action with concrete guidance on how to improve the draft. The second comment suggests compressing the method section and correcting grammatical errors, which are also explicit actions with some level of detail. However, the comment does not specify which grammatical errors need correction, making it somewhat vague. Overall, the comment provides clear and actionable feedback, but the lack of detailed guidance on grammatical errors limits its full actionability. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"34\" and \"the method section,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear suggestions for improvement, such as toning down a statement about neural networks memorizing critical points, compressing the method section, and correcting grammatical errors. The comment even provides a specific example of a grammatical error (\"l\"). Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of multiple claims and suggestions. The first claim about the neural network not memorizing critical points is supported by a reference to TopoNet [24], providing a specific source for the reviewer\"s understanding. This makes the claim 4. The second suggestion about compressing the method section and correcting grammatical errors is based on the reviewer\"s subjective opinion and does not require external evidence. The third suggestion about grammatical errors is a request for clarification, not a claim. Therefore, the overall comment is 4, as it provides some support for the first claim but lacks detailed evidence for the second and third points.", "helpfulness_rationale": "The review comment provides several actionable suggestions for improvement. It suggests toning down a statement about the neural network memorizing critical points, which is a specific and constructive feedback that could enhance the clarity and accuracy of the paper. Additionally, it points out that the method section could be compressed to focus on essential definitions, which is a clear and actionable suggestion for streamlining the content. The comment also highlights grammatical errors, which is a common issue that can affect the readability and credibility of a paper. By suggesting a focus on plurals and articles, the reviewer offers a specific area for improvement. Overall, the comment is 4 as it provides clear and actionable feedback on multiple aspects of the paper, guiding the authors on how to enhance the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the overrating of the comparison with Megatron and suggests that the performance of Megatron and COCOLM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. It questions the claim of parameter efficiency for COCOLM and implies that the conclusion might be applicable to these other approaches as well. The comment also includes a question about the experimental setup, specifically asking why the authors switched the types of BPE vocabulary and whether this change could affect performance. While the comment raises important points and questions, it does not provide explicit instructions or detailed guidance on how the authors should address these issues. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their claims and provide a rationale for the experimental setup. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Megatron\" and \"COCOLM,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the overrating of the comparison with Megatron and pointing out that the performance of Megatron and COCOLM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. Additionally, it raises a question about the experimental setup, specifically asking why the authors switched the types of BPE vocabulary and whether this change could affect performance. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with a score of 5.", "verifiability_rationale": "The review point claims that the comparison with Megatron is overrated and suggests that the performance of Megatron and COCOLM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. This claim is 3 as it provides a logical comparison with other models of similar size, which supports the argument that the performance of Megatron and COCOLM is not significantly different. However, the comment lacks specific references or detailed comparisons to fully substantiate the claim, making it 3. The authors would need to further explore the data and comparisons to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the overrating of the comparison with Megatron, suggesting that the performance of Megatron and COCOLM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. It questions the claim of parameter efficiency for COCOLM and implies that the conclusion might be applicable to these other approaches as well. Additionally, the comment includes a question about the experimental setup, specifically asking why the authors switched the types of BPE vocabulary and whether this change could affect performance. This feedback is 3 as it identifies a potential issue with the comparison and provides a question that prompts the authors to consider the impact of their experimental choices. However, the comment could be more helpful if it offered specific suggestions or guidance on how to address the overrated comparison or the impact of the BPE change. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the analysis from line 128 to 149, specifically questioning the validity of the observation that GSP50 shares more features and ResNet50 learns more classspecific features. The reviewer suggests that the authors should provide a reason for this observation to indicate that GSP50 learns better representation. However, the comment does not explicitly instruct the authors to address this issue or provide specific guidance on how to improve the analysis. The action is implicit and somewhat vague, as the authors can infer that they need to provide additional reasoning or evidence, but they are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific lines (128149) and references Figure 3, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the validity of the observation that GSP50 shares more features and ResNet50 learns more classspecific features. The comment further suggests that the authors should provide a reason for this observation to indicate that GSP50 learns better representation. Additionally, it references external works to support the claim. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the validity of the analysis from line 128 to 149, specifically regarding the observation that GSP50 shares more features and ResNet50 learns more classspecific features. The reviewer suggests that the authors should provide a reason for this observation to indicate that GSP50 learns better representation. The comment references two external works, [1] and [2], which provide some context and support for the claim. However, the references are not directly integrated into the reasoning, and the comment lacks detailed explanation or examples from the paper to fully substantiate the claim. Therefore, the comment is 3, as it provides some support but requires more detailed justification and integration of the references into the critique.", "helpfulness_rationale": "The review comment identifies a specific issue with the analysis presented in the paper, from line 128 to 149, questioning the validity of the observation that GSP50 shares more features and ResNet50 learns more classspecific features. The reviewer suggests that the authors should provide a reason for this observation to indicate that GSP50 learns better representation. This feedback is 3 as it points out a potential weakness in the analysis and prompts the authors to clarify or justify their findings. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address this issue. Overall, the comment offers a direction for improvement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the conclusions being unconvincing and suggests that the results might be due to limited exploration of combination methods. It provides specific examples of works that have shown potential in rehearsalfree continual learning, such as [R1], [R2], and [R3]. While the comment implies that the authors should consider these works and their methods, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they should explore these methods further but are not given specific guidance on how to integrate them into their work. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific conclusions that are not convincing, allowing the authors to accurately identify the parts of the paper being addressed. It also provides specific examples of works that have shown potential in rehearsalfree continual learning, such as [R1], [R2], and [R3], which helps the authors understand the areas that need further exploration. The comment is specific in detailing the issues with the conclusions and suggesting alternative approaches, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that some conclusions are not convincing, specifically mentioning the statement about continuous learning with unlabeled data accumulating noise. The reviewer provides examples of works that have shown potential in rehearsalfree continual learning, such as [R1], [R2], and [R3], which employ feature replay methods. This provides some support for the claim by referencing relevant literature, making the comment 4. However, the comment could be strengthened by providing more detailed comparisons or analyses of these works to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the conclusions of the paper, suggesting that they are not convincing. It provides a detailed example of a claim that is questioned, specifically the assertion that continuous learning with unlabeled data accumulates noise, which is detrimental to representation quality. The comment also highlights the potential of featurereplay methods in rehearsalfree continual learning, referencing specific works like [R1], [R2], and [R3] that have shown promising results. This feedback is actionable as it directs the authors to consider these works and their methods, which could help improve the credibility and validity of their conclusions. However, the comment could be more helpful if it provided a more detailed analysis or suggestions on how to integrate these methods into the paper. Overall, the comment is 4, as it offers clear guidance for improvement but could be expanded to be more comprehensive."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that some observations and design decisions might be hardware and software dependent, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this issue or what specific changes should be made to improve the draft. Without any actionable steps or suggestions, the authors are left without a clear understanding of how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that some observations and design decisions might be hardware and software dependent, but it does not specify which parts of the paper this applies to. Without explicit references to sections, tables, or figures, the authors cannot confidently determine the exact parts of the paper being addressed. Additionally, the comment lacks specificity regarding which observations or design decisions are hardware or software dependent, leaving the authors without clear guidance on what needs to be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that some observations and design decisions might be hardware and software dependent, but it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how it impacts their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a potential issue with the paper, suggesting that some observations and design decisions might be hardware and software dependent. This is a relevant observation that could impact the generalizability and applicability of the findings. However, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue or mitigate its impact. Without actionable feedback or detailed advice, the authors are left without a clear understanding of how to improve their draft. Therefore, the comment is 2, as it highlights a potential concern but does not offer meaningful guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the paper for being a straightforward application of existing literature, specifically DeCorr, in a specific application domain. It highlights the contribution as the transposition of DeCorr\"s insights into graph collaborative filtering with different datasets and backbones. The comment also mentions modifications like different penalty coefficients for users and items but notes that the paper lacks insights into the unique challenges of overcorrelation in recommender systems. While the comment identifies the lack of novelty and suggests that the paper lacks insights into the unique challenges, it does not provide explicit guidance on how the authors might address these issues or improve the paper. The action is implicit and somewhat vague, as the authors are left to infer what specific changes or additions are needed to enhance the paper\"s novelty and insights. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment critiques the paper for being a straightforward application of existing literature, specifically DeCorr, in a specific application domain. It highlights the contribution as the transposition of DeCorr\"s insights into graph collaborative filtering with different datasets and backbones. The reviewer also mentions modifications like different penalty coefficients for users and items but notes that the paper lacks insights into the unique challenges of overcorrelation in recommender systems. However, the comment does not specify which part of the paper this critique is based on, making it difficult for the authors to pinpoint the exact sections that need revision. While the authors might infer that it relates to the introduction or discussion sections, the lack of explicit grounding makes it challenging to address the feedback effectively. The comment is specific in its critique of the paper\"s novelty and contribution but lacks grounding, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper lacks novelty and is a straightforward application of existing literature, specifically DeCorr, in a specific application domain. The reviewer provides a detailed explanation of how the paper merely transposes DeCorr\"s insights into graph collaborative filtering with different datasets and backbones, mentioning modifications like different penalty coefficients for users and items. However, the comment does not provide specific references or examples to support the claim of lack of novelty, which would strengthen the argument. While the reasoning is clear, the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the paper for being a straightforward application of existing literature, specifically DeCorr, in a specific application domain. It highlights the contribution as the transposition of DeCorr\"s insights into graph collaborative filtering with different datasets and backbones. The comment also notes that the paper lacks insights into the unique challenges of overcorrelation in recommender systems. While it identifies a potential weakness in the paper\"s novelty and contribution, it does not provide specific suggestions or guidance on how the authors might address these issues or enhance the paper\"s originality. The feedback is 3 as it points out a critical area for improvement but lacks actionable advice, making it difficult for the authors to effectively respond to the critique. Therefore, the comment is rated as 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point critiques the novelty of the paper, specifically mentioning that the ENCODE part is already proposed in [10] and that the incremental contribution lies in the decomposition part, which factorizes M_v into D and Phi_v. However, the comment does not provide any explicit or implicit actions for the authors to take in response to this critique. It lacks guidance on how the authors might address the perceived lack of novelty or improve their contribution. Without actionable suggestions or a clear direction for improvement, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the novelty of the paper, specifically mentioning the ENCODE part and the incremental contribution in the decomposition part. However, it does not specify which part of the paper these aspects are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. The comment lacks specificity as it does not detail what aspects of the ENCODE part or the decomposition part are problematic or how they could be improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the novelty of the paper is limited, specifically mentioning that the ENCODE part is already proposed in [10] and that the incremental contribution lies in the decomposition part. However, the comment does not provide any references or detailed reasoning to support this claim, such as comparing the proposed method to the existing work in [10] or explaining how the decomposition part differs from previous approaches. Without specific evidence or detailed analysis, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment critiques the novelty of the paper, specifically pointing out that the ENCODE part is already proposed in [10] and that the incremental contribution lies in the decomposition part, which factorizes M_v into D and Phi_v. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. Without actionable feedback or constructive advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states that the authors have reduced whitespace throughout the paper, resulting in equations being crammed together and captions being too close to the figures. It further suggests that this is grounds for rejection because it effectively violates the 9page paper limit. The comment provides a clear and direct action for the authors to address, which is to increase the whitespace in their paper to comply with the page limit. The feedback is explicit and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of reduced whitespace, crammed equations, and captions too close to figures, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the problem of violating the 9page paper limit due to these formatting issues. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors have reduced whitespace throughout the paper, resulting in equations being crammed together and captions being too close to the figures. It suggests that this is grounds for rejection because it effectively violates the 9page paper limit. However, the comment lacks specific examples or references to support the claim, such as screenshots or detailed explanations of how the formatting issues impact the paper. Without concrete evidence or detailed reasoning, the claim is difficult for the authors to verify or address effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a significant issue with the formatting of the paper, specifically noting that the authors have reduced whitespace, resulting in equations being crammed together and captions being too close to the figures. It suggests that this formatting issue effectively violates the 9page paper limit, which is a critical concern for the authors. While the comment highlights a specific problem, it does not provide actionable suggestions on how to address the issue or improve the formatting. The feedback is clear in its identification of the problem but lacks depth and guidance for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the technical details and formulations are limited, suggesting that the main novelty lies in the scheme or procedure. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to enhance the technical details or formulations, nor is there a suggestion on how to better highlight the scheme or procedure novelty. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions \"technical details and formulations\" as being limited, suggesting that the main novelty lies in the scheme or procedure. However, it does not specify which parts of the paper these details are lacking in, making it difficult for the authors to pinpoint the exact sections that need attention. Additionally, the comment lacks specificity regarding what aspects of the technical details or formulations are limited or how they could be improved. Without explicit references to sections or examples, the authors cannot effectively address the feedback. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the technical details and formulations are limited, suggesting that the main novelty lies in the scheme or procedure. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed justification or evidence, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a limitation in the technical details and formulations of the paper, suggesting that the main novelty lies in the scheme or procedure. However, it does not provide specific guidance or suggestions on how the authors might enhance these details or highlight the novelty more effectively. Without actionable feedback or examples, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential risk associated with methods that exploit relationships between action units, specifically the variability in these relationships across datasets. It provides an example of how AU6 can occur in different contexts, such as pain and happiness, and suggests that this difference in correlation can be seen in Figure 1. The comment implies that the paper lacks crossdataset experiments to test the generalization of the work. While the action is implicit, it is clear and concrete, as it specifies the need for crossdataset experiments to address the issue. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by discussing the potential risk of methods exploiting relationships between action units and the variability in these relationships across datasets. The comment suggests performing crossdataset experiments to test the generalization of the work, which provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point highlights a potential risk in methods that exploit relationships between action units, specifically the variability in these relationships across datasets. It provides an example of how AU6 can occur in different contexts, such as pain and happiness, and suggests that this difference in correlation can be seen in Figure 1. The comment also recommends performing crossdataset experiments to test the generalization of the work. This reasoning is logical and provides a clear basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential risk in methods that exploit relationships between action units, specifically the variability in these relationships across datasets. It provides a specific example of how AU6 can occur in different contexts, such as pain and happiness, and suggests that this difference in correlation can be seen in Figure 1. The comment offers a clear and actionable suggestion to address this issue by recommending crossdataset experiments to test the generalization of the work. This feedback is valuable as it highlights a critical area for improvement and provides a concrete step for the authors to take. However, the comment could be more helpful if it included additional guidance on how to design and interpret these crossdataset experiments. Overall, the comment is 4, as it provides actionable feedback that can significantly enhance the paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a contradiction between the statement in lines 4748 and the observation that overparameterization is beneficial for supervised learning of deep neural networks in practice. It also mentions theoretical works supporting the benefits of overparameterization. However, the comment does not provide explicit guidance on how the authors should address this contradiction or integrate the theoretical works into their paper. The action is implicit and somewhat vague, as the authors are left to infer that they should reconcile the contradiction or discuss the theoretical works, but without specific instructions on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (4748) in the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it points out a contradiction between the statement about overparametrization and the observation that it is beneficial for supervised learning. Additionally, the comment provides a reference to theoretical works supporting the benefits of overparametrization, which further specifies the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a contradiction between the statement in lines 4748 and the observation that overparameterization is beneficial for supervised learning. It supports this claim by referencing theoretical works that demonstrate the benefits of overparameterization. However, the comment does not provide specific references to these theoretical works, which would strengthen the verifiability of the claim. While the mention of theoretical works provides some support, the lack of detailed references or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a contradiction in the paper regarding the statement that overparametrization leads to worse performance, while also noting that overparameterization is beneficial for supervised learning in practice. It provides a reference to theoretical works supporting the benefits of overparametrization, which is a valuable addition to the discussion. However, the comment could be more helpful if it offered specific suggestions on how to reconcile this contradiction or integrate the theoretical works into the paper. While it highlights an important issue, the feedback lacks actionable guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential issue with the experimental comparison, suggesting that the proposed method may have an unfair advantage due to pretraining. It questions whether the compared methods were also initialized with a similar pretrained model and points out that the proposed method without SSL performs inferior to most of the compared methods. While the comment identifies a potential issue, it does not explicitly instruct the authors to address this concern or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the experimental setup and potentially reevaluate the results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the experimental comparison, questioning the fairness of the comparison due to the pretraining of the proposed method. The comment further specifies that the proposed method without SSL performs inferior to most of the compared methods, providing a clear basis for the critique. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental comparison is unfair because the proposed method was pretrained before finetuning, while it is unclear if the compared methods were also initialized with a similar pretrained model. The comment supports this claim by referencing Table 1, which shows that the proposed method without SSL performs inferior to most of the compared methods. This provides a logical basis for the claim, as it highlights a potential bias in the experimental setup. However, the comment could be strengthened by providing specific examples of methods that were not pretrained or by referencing relevant literature on pretraining practices. Overall, the claim is 4, as it provides a logical reasoning and some evidence, but it lacks detailed references or examples to fully substantiate the claim. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the experimental comparison, specifically questioning the fairness of the comparison due to the pretraining of the proposed method. It points out that the proposed method without SSL performs inferior to most of the compared methods, suggesting that this may be due to the unfair advantage of pretraining. This feedback is clear and actionable, as it prompts the authors to clarify the experimental setup and potentially reevaluate the results to ensure a fair comparison. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or offered examples of how to ensure a fair comparison. Overall, the comment is 4 as it directs the authors to a critical area that needs attention and improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should consider using better metadata embeddings for their zeroshot learning results on the CUB dataset. It references a specific paper, \"Learning Deep Representations of FineGrained Visual Descriptions, Reed et al, CVPR 2016,\" and suggests that the performance of the proposed method could be improved with better metadata embeddings. The comment explicitly instructs the authors to update their results with these improved embeddings, providing a clear and concrete action to take. The reference to a specific paper and the suggestion for improvement make the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3 page 7\" and \"attribute,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a suggestion for improvement by recommending the use of better metadata embeddings, referencing a specific paper and table for comparison. The comment also includes a request for the authors to update their results with these improved embeddings. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the metadata used for zeroshot learning on the CUB dataset, as presented in Table 3 on page 7, is \"attribute.\" It claims that this choice is good for fair comparison but notes that better metadata embeddings are available, referencing a specific paper and table. The reviewer provides a clear suggestion for improvement by recommending the use of better metadata embeddings and references a specific source for comparison. This level of detail and specific reference to external work makes the claim 4, as it provides a clear path for the authors to follow in improving their work. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the paper. It identifies a potential weakness in the choice of metadata embeddings for zeroshot learning on the CUB dataset, noting that better options are available. The reviewer references a specific paper and table that could be used for comparison, offering a clear direction for the authors to enhance their results. This feedback is valuable as it not only points out a specific area for improvement but also provides a concrete reference for the authors to consider. By addressing this feedback, the authors can potentially improve the performance and robustness of their method. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should discuss the use of moment matching instead of quantile regression in distributional reinforcement learning (DRL), as this is a relevant topic in the literature. It references a specific paper by NguyenTang et al. (AAAI\"21) that discusses moment matching for DRL. While the comment implies that the authors should include this discussion, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should discuss moment matching and its relevance to DRL. However, the reference to the specific paper provides some guidance on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific lines (2230) where the discussion about distributional RL is taking place. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it points out the lack of relevant literature on using moment matching instead of quantile regression in DRL, as discussed in the referenced paper by NguyenTang et al. (AAAI\"21). It suggests that this topic should be properly discussed when talking about various approaches to DRL, even though the paper still uses quantile regression. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper lacks relevant literature on using moment matching (instead of quantile regression) for distributional reinforcement learning (DRL), as discussed in the paper by NguyenTang et al. (AAAI\"21). The reviewer provides a specific reference to support their claim, which is a clear and direct way to verify the assertion. This makes the comment 5, as it offers a concrete reference that the authors can use to address the issue. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by discussing the use of moment matching instead of quantile regression in distributional reinforcement learning (DRL). It references a relevant paper by NguyenTang et al. (AAAI\"21) that discusses moment matching for DRL, providing a specific reference for the authors to consider. This feedback is actionable and provides a clear direction for the authors to enhance their discussion on DRL methods. However, the comment could be more helpful if it included suggestions on how to integrate this discussion into the paper or highlighted the potential benefits of discussing moment matching. Overall, the comment is 4 as it directs the authors to a relevant area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point claims that the novelty of the work is limited, as interpreting the prediction of deep neural networks using a linear model is not a new approach for model interpretation. However, the comment does not provide any actionable advice or suggestions for the authors to address this issue. It lacks specific guidance on how the authors might enhance the novelty or provide additional context to differentiate their work. Without concrete steps or suggestions, the authors are left without a clear understanding of what changes, if any, are needed to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the novelty of the paper, specifically mentioning that interpreting the prediction of deep neural networks using a linear model is not a new approach. However, it does not specify which part of the paper this critique is based on, such as a particular section or methodology. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs revision. Additionally, while the comment provides some specificity by pointing out the lack of novelty, it does not offer detailed guidance on how to address this issue or improve the paper. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the novelty of the paper is limited, as interpreting the prediction of deep neural networks using a linear model is not a new approach. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a perceived limitation in the novelty of the work, specifically noting that interpreting the prediction of deep neural networks using a linear model is not a new approach. However, the comment lacks specificity and does not provide any actionable advice or suggestions for the authors to enhance the novelty or originality of their work. Without guidance on how to address this issue or what specific aspects could be improved, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the novelty and significance of using PCA to reduce interaction count, suggesting that it seems intuitive and lacks clarity. It questions the assumptions behind PCA and asks for clarification on how well these assumptions are met. While the comment implies that the authors should provide more information on the assumptions and their relevance, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the assumptions and their impact on the results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises concerns about the novelty and significance of using PCA to reduce interaction count, suggesting that it seems intuitive and lacks clarity. It questions the assumptions behind PCA and asks for clarification on how well these assumptions are met. However, the comment does not specify which part of the paper discusses the use of PCA or where the assumptions are mentioned, making it weakly grounded. The comment is specific in its critique of the novelty and significance of the approach, but without clear grounding, the authors may struggle to identify the exact sections needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a claim about the novelty and significance of using PCA to reduce interaction count, suggesting that it seems intuitive and lacks clarity. The reviewer questions the assumptions behind PCA and asks for clarification on how well these assumptions are met. The comment references a specific paper by Dombrowski et al. (2022) to support the claim that PCA is a wellknown technique. However, the reference is not directly used to substantiate the claim about the assumptions or the lack of novelty, making the comment 3. The authors would need to further explore the referenced work to fully understand the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises concerns about the novelty and significance of using PCA to reduce interaction count, suggesting that it seems intuitive and lacks clarity. It questions the assumptions behind PCA and asks for clarification on how well these assumptions are met. While the comment identifies a potential weakness in the paper, it does not provide specific guidance or suggestions on how the authors might address these concerns or improve the clarity of their work. The feedback is 3 as it points out an area for improvement, but it lacks depth and actionable advice, leaving the authors with limited direction for enhancing their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the evaluative framework is limited in scope, considering only three QuestionAnswering tasks and two language models. It raises concerns about the framework\"s applicability to other reasoning or generation tasks or more advanced models like vicunna or alpaca. However, the comment does not provide explicit guidance or suggestions on how the authors might expand the scope of their framework or address these concerns. The action is implicit and vague, as the authors are left to infer that they should consider broader applicability but are not given specific steps to take. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the scope of the evaluative framework, specifically mentioning the limitations due to considering only three QuestionAnswering tasks and two language models. It raises concerns about the framework\"s applicability to other reasoning or generation tasks and more advanced models like vicunna or alpaca. However, the comment does not specify which part of the paper discusses the evaluative framework, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but the lack of explicit reference makes it challenging to pinpoint the exact part of the paper. The comment is specific in detailing the limitations and potential areas for expansion, but the lack of grounding reduces its overall score to 3.", "verifiability_rationale": "The review point claims that the evaluative framework is limited in scope, considering only three QuestionAnswering tasks and two language models. It raises concerns about the framework\"s applicability to other reasoning or generation tasks and more advanced models. However, the comment lacks specific examples or references to support the claim that the framework is limited. Without detailed evidence or comparisons to other frameworks or models, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is classified as 3, as it provides some justification but lacks comprehensive evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a limitation in the scope of the evaluative framework, noting that it is restricted to only three QuestionAnswering tasks and two language models. It raises concerns about the framework\"s applicability to other reasoning or generation tasks and more advanced models, such as vicunna or alpaca. This feedback is 3 as it points out a potential weakness in the paper\"s methodology and suggests areas for expansion or generalization. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address these limitations or expand the framework\"s applicability. Overall, the feedback is 3 as it prompts the authors to consider broader applicability, but it lacks depth and actionable guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that Figure 6C is awkward because it implies negative rates, which is not the case. The reviewer recommends using a second yaxis or another visualization that is more physically accurate. This feedback is explicit and provides a clear action for the authors to take, which is to revise the visualization to better represent the data. The suggestion is also concrete, as it specifies the use of a second yaxis or another visualization. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 6C,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, namely that it implies negative rates when this is not the case, and suggests using a second yaxis or another visualization to make it more physically accurate. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 6C is awkward because it implies negative rates, which is not the case. The reviewer suggests using a second yaxis or another visualization to make it more physically accurate. While the comment identifies a potential issue with the figure, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion for a second yaxis or alternative visualization is logical but not thoroughly explained. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed justification or examples to be fully convincing.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 6C, noting that it implies negative rates when this is not the case. It provides a clear and actionable suggestion to address this issue by recommending the use of a second yaxis or another visualization that is more physically accurate. This feedback is valuable as it directs the authors to a specific area of their draft that requires improvement and offers a concrete solution. By following this advice, the authors can enhance the clarity and accuracy of their presentation, making the comment 4. However, it could be more helpful if it included additional context or explanation about why the current visualization is problematic or how the suggested changes would improve the figure. Therefore, the comment is rated as 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment suggests that there is room for improvement in the complexity of Algorithm 2, but it does not provide any explicit guidance or concrete suggestions on how to achieve this improvement. The authors are left to infer that they should enhance the algorithm\"s complexity, but without specific details or examples, it is difficult to determine what changes might be necessary. This lack of direction makes the comment vague and 1.", "grounding_specificity_rationale": "The comment refers to \"Algorithm 2,\" which provides full grounding as it allows the authors to accurately identify the specific part of the paper being addressed. However, the comment lacks specificity as it does not detail what aspects of the algorithm\"s complexity need improvement or how it could be enhanced. The authors are left to infer the specific areas that require attention, making the comment 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests that there is room for improvement in the complexity of Algorithm 2, but it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a potential area for improvement in the complexity of Algorithm 2, suggesting that there is room for enhancement. However, it lacks specificity and does not provide any guidance or suggestions on how to improve the algorithm\"s complexity. Without actionable feedback or detailed advice, the authors are left without a clear understanding of what changes might be necessary or how to implement them. This makes the comment 3, as it points out a general area for improvement but does not offer sufficient guidance for the authors to effectively address it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the statement in the supplemental section D.4 regarding the necessity of smaller architectures for language models (LMs) compared to generative adversarial networks (GANs). The reviewer points out that this claim is not consistent with their experience and references a study by Zaremba et al. (2014) that trains 1500dimensional LSTMs on PTB. The comment also suggests that the baseline models may not be properly regularized and asks whether dropout is applied to the hidden states. While the comment raises a specific issue and provides a reference for comparison, it does not explicitly instruct the authors to revise or clarify their statement. The action is implicit and somewhat vague, as the authors need to infer that they should address the inconsistency and provide clarification on the regularization methods used. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"supplemental section D.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the statement about the necessity of smaller architectures for language models (LMs) compared to generative adversarial networks (GANs), provides a reference to Zaremba et al. (2014) to support the claim, and asks whether dropout is applied to the hidden states. This level of detail provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point questions the statement in the supplemental section D.4 regarding the necessity of smaller architectures for language models (LMs) compared to generative adversarial networks (GANs). The reviewer provides a counterexample from Zaremba et al. (2014), which suggests that the baseline models may not be properly regularized. This provides a logical reasoning and a specific reference to support the claim, making it 4. However, the comment could be strengthened by further elaborating on the specific issues with the regularization methods or providing more detailed examples. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises a question about a specific statement in the supplemental section D.4 regarding the necessity of smaller architectures for language models (LMs) compared to generative adversarial networks (GANs). The reviewer provides a counterexample from Zaremba et al. (2014) to challenge the claim, suggesting that the baseline models may not be properly regularized. This feedback is valuable as it prompts the authors to reconsider their statement and potentially revise their analysis or provide additional evidence to support their claim. Additionally, the comment asks whether dropout is applied to the hidden states, which could be a relevant detail for the authors to clarify. However, the comment could be more helpful if it offered suggestions on how to address the issue or provided specific guidance on how to improve the regularization methods. Overall, the comment is 4 as it identifies a potential weakness and provides a reference for comparison, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the main part, particularly the introduction, could be more concise and should include empirical results. However, it does not provide specific guidance on how to achieve this conciseness or what specific empirical results should be included. The action is implicit and somewhat vague, as the authors are left to infer what changes are needed without detailed instructions. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the main part, particularly the introduction, could be more concise and should include empirical results. However, it does not specify which part of the main section or the introduction is being referred to, making it difficult for the authors to pinpoint the exact areas needing improvement. Additionally, the comment lacks specificity regarding what aspects of the empirical results should be included or how they could be integrated. As a result, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the main part, particularly the introduction, could be more concise and should include empirical results. However, it does not provide any specific reasoning, examples, or references to support why the current content is not concise or why empirical results are necessary. Without additional context or justification, the authors may find it challenging to understand and address the feedback. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the main part of the paper, particularly the introduction, could be more concise and should include empirical results. While it identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on how to achieve conciseness or what specific empirical results should be included. The feedback is 3 as it points out a general area for improvement, but it does not offer actionable steps or detailed suggestions, leaving the authors with limited direction for enhancing their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment states that the technical contribution is unclear and that most of the analysis is standard. However, it does not provide any specific guidance or suggestions on how to clarify the technical contribution or what aspects of the analysis could be improved. The comment lacks actionable details, such as identifying which parts of the analysis are considered standard or how the authors could enhance their contribution. As a result, the authors are left without a clear understanding of what changes are needed to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the technical contribution of the paper, stating that most of the analysis is standard. However, it does not specify which parts of the paper are considered standard or what aspects of the analysis are unclear. This lack of specificity makes it difficult for the authors to identify the exact areas that need improvement. Additionally, the comment does not provide any grounding by not mentioning specific sections, figures, or tables that are being addressed. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the technical contribution is unclear and that most of the analysis is standard. However, it does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the technical contribution is unclear and that most of the analysis is standard. However, it lacks specificity and does not provide any actionable feedback or suggestions on how the authors might clarify their contribution or enhance their analysis. Without detailed guidance or examples, the authors are left without a clear understanding of what changes are needed to improve their draft. Therefore, the comment is 1, as it does not offer any actionable insights or direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy between the regularization applied to the LN model and the GLM model, suggesting that the authors should try to reproduce the main features of previous models to make the comparison fair. While the comment implies that the authors should consider adjusting their regularization approach, it does not explicitly instruct them to do so or provide specific guidance on how to implement this change. The suggestion is implicit and somewhat vague, as the authors need to infer the action and determine how to apply it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"LN model\" and \"GLM,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out a discrepancy in the regularization approach between the LN model and the GLM model, as well as suggesting that the authors should try to reproduce the main features of previous models to make the comparison fair. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the GLM model presented by pillow et al. did not crop the image but used L1 regularization for the filters and a low rank approximation to the spatial filter. This claim is 3 as it references specific regularization techniques used in the GLM model, providing some context for the comparison. However, the comment lacks detailed references or examples from pillow et al. to fully substantiate the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison between the LN model and the GLM model, noting that the authors apply regularization (in the form of a cropped stimulus) to both models, while the GLM model presented by pillow et al. did not crop the image but used L1 regularization for the filters and a low rank approximation to the spatial filter. The comment suggests that to make the comparison fair, the authors should try to reproduce the main features of previous models. This feedback is clear and actionable, as it highlights a specific area for improvement and provides a direction for the authors to enhance their work. However, it could be more helpful if it included specific suggestions on how to implement these changes or references to similar studies that have successfully made such comparisons. Overall, the comment is 4, as it provides valuable insight into improving the fairness and validity of the comparison, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should include some failure cases and related discussion in their paper. While the comment implies that the authors should add this information, it does not provide specific guidance on which failure cases to include or how to structure the discussion. The action is implicit and somewhat vague, as the authors need to infer what specific failure cases to address and how to discuss them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests including failure cases and related discussion, but it does not specify which part of the paper this suggestion pertains to. The authors cannot confidently determine whether this relates to the methodology, results, or discussion sections. Additionally, the comment lacks specificity regarding which failure cases should be included or how they should be discussed. Without clear guidance on where to make these additions or what specific aspects to address, the comment is 1 and not specific. Therefore, this comment aligns with a score of 1.", "verifiability_rationale": "The review point suggests that including failure cases and related discussion would be beneficial. However, it does not provide any specific examples, reasoning, or references to support why this is necessary or how it would enhance the paper. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the importance of addressing failure cases. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment suggests that the authors include failure cases and related discussion in their paper. While this feedback identifies a potential area for improvement, it lacks specificity and does not provide guidance on which failure cases to include or how to structure the discussion. The suggestion is 3 as it points out a gap in the paper, but it could be more actionable with additional details or examples. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential clarity issue regarding the use of epsilon in equations (10) and (11). It suggests that introducing epsilon when discussing equation (11) might improve clarity. While the comment implies an action\u2014introducing epsilon in the discussion of equation (11)\u2014it does not explicitly instruct the authors to make this change. The action is concrete but implicit, as the authors can infer what needs to be done. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.1\" and refers to specific equations (10) and (11), allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that introducing epsilon when discussing equation (11) might improve clarity. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that introducing epsilon when discussing equation (11) might improve clarity. However, it does not provide any reasoning or evidence to support why this change would be beneficial or how it would enhance the clarity of the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential clarity issue in the paper, specifically regarding the use of epsilon in equations (10) and (11). It suggests that introducing epsilon when discussing equation (11) might improve the clarity of the paper. While the comment highlights a specific area for improvement, it does not provide detailed guidance on how to introduce epsilon or why it would enhance clarity. The feedback is 3 as it points out a potential issue, but it lacks depth and actionable suggestions, leaving the authors with a general direction for improvement. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the claim about evolutionary dropout addressing internal covariate shift is limited, as it can only increase the variance of some lowvariance units. It further mentions that batch normalization standardizes the variance and centers the activation, and recommends discussing these limitations explicitly. While the comment implies that the authors should address these limitations, it does not provide specific guidance on how to do so, such as suggesting which aspects to focus on or how to present the discussion. The action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment addresses the claim about evolutionary dropout addressing internal covariate shift, suggesting that it is limited in its ability to increase the variance of some lowvariance units. It also mentions batch normalization as a more effective method for standardizing variance and centering activations. However, the comment does not specify which part of the paper discusses evolutionary dropout or batch normalization, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in detailing the limitations of evolutionary dropout and suggesting a discussion of these limitations, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the claim about evolutionary dropout addressing internal covariate shift is limited, as it can only increase the variance of some lowvariance units. The reviewer contrasts this with batch normalization, which standardizes the variance and centers the activation. While the comment provides a logical reasoning for the limitation, it lacks specific examples or references to support the claim fully. The authors might need to refer to the original paper or other sources to fully understand the comparison. Therefore, the comment is 3, as it provides a logical basis but requires additional evidence for full verification.", "helpfulness_rationale": "The review comment identifies a specific limitation in the claim about evolutionary dropout addressing internal covariate shift, suggesting that it can only increase the variance of some lowvariance units. It contrasts this with batch normalization, which standardizes the variance and centers the activation. The comment provides a clear and actionable suggestion to discuss these limitations explicitly, which could help the authors refine their understanding and presentation of the method. However, the comment could be more helpful if it offered additional guidance on how to present this discussion or provided specific examples of how to address the limitations. Overall, the feedback is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with further elaboration."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the author should provide more description about the contribution of the paper. However, it does not specify what aspects of the contribution should be elaborated on or how the authors should go about doing so. The action is implicit and vague, leaving the authors without clear guidance on how to address the feedback. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the author should provide more description about the contribution of the paper. However, it does not specify which part of the paper lacks this description or what specific aspects of the contribution need elaboration. Without explicit references to sections or examples, the authors cannot confidently determine which parts of the paper need improvement. This makes the comment weakly grounded, as the authors cannot pinpoint the exact areas needing attention. Additionally, the comment lacks specificity because it does not provide detailed guidance on what aspects of the contribution should be expanded upon. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the author should provide more description about the contribution of the paper. However, it does not provide any specific reasoning, examples, or references to support why this additional description is necessary or how it would enhance the paper. Without such supporting evidence or justification, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The comment suggests that the author should provide more description about the contribution of the paper. While it identifies a potential area for improvement, it lacks specificity and does not offer guidance on what aspects of the contribution should be elaborated upon or how to effectively communicate them. Without detailed feedback or suggestions, the authors are left with a general direction but no clear steps to take. Therefore, the comment is 2, as it provides limited value for improving the draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that in Section 4, the term \"X\" should be a multiset rather than a set, as the histogram needs to represent graphs with repeated vertex or edge labels. The comment provides a clear and explicit action for the authors to take, specifying that the set should be replaced with a multiset. Additionally, it explains the reasoning behind this change, which helps the authors understand the necessity of the action. Therefore, the comment is 5, as it provides a concrete and direct suggestion for improvement.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the terminology used in section 4, suggesting that \"X\" should be a multiset rather than a set to accurately represent graphs with repeated vertex or edge labels. The comment provides a clear and actionable suggestion for improvement, making it 5.", "verifiability_rationale": "The review point suggests that the term \"X\" should be a multiset rather than a set, as it is necessary to represent graphs with repeated vertex or edge labels. The comment provides a logical reasoning for this claim, explaining that the histogram should accurately represent the graph, which requires considering the multiplicities of labels. This reasoning is clear and provides a basis for the suggestion, making the claim 4. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improvement in the paper. It identifies a potential issue with the terminology used in Section 4, suggesting that the term \"X\" should be a multiset rather than a set to accurately represent graphs with repeated vertex or edge labels. This feedback is clear and offers a concrete way for the authors to enhance the clarity and accuracy of their work. By addressing this suggestion, the authors can improve the rigor and precision of their draft. Therefore, the comment is rated as 5, as it provides valuable guidance for enhancing the paper."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the authors\" derivation falls into classical learning theorybased bounds, which are not considered realistic unless Bayesian considerations are taken into account. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or improve their derivation. The comment lacks concrete details on what changes or additions should be made to enhance the realism of the bounds. As a result, the authors are left without a clear understanding of how to proceed, making the comment 1.", "grounding_specificity_rationale": "The comment addresses the authors\" derivation, which is a specific part of the paper. However, it does not specify which section or part of the derivation is being discussed, making it weakly grounded. The comment provides some specificity by mentioning that the derivation falls into classical learning theorybased bounds and suggests that Bayesian considerations are needed to yield realistic bounds. However, it does not specify which aspects of the derivation are problematic or how the authors could incorporate Bayesian considerations. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors\" derivation falls into classical learning theorybased bounds, which are not considered realistic unless Bayesian considerations are taken into account. The reviewer provides a specific example of BayesianPAC based bounds as a reference. This provides a clear and logical reasoning for the claim, making it 4. However, the comment could be strengthened by providing more detailed examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the authors\" derivation, noting that it falls into classical learning theorybased bounds, which are not considered realistic unless Bayesian considerations are taken into account. This feedback is 3 as it points out a potential limitation in the current approach and suggests a direction for improvement by considering BayesianPAC based bounds. However, the comment lacks detailed guidance or examples on how to incorporate Bayesian considerations or what specific changes would be necessary to address this issue. While it provides some insight, it does not offer comprehensive or actionable advice, leaving the authors with a general direction but without clear steps to take. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies a lack of significance testing to support claims about the differences between methods. It provides a specific example from line 486, where the authors claim that ChatGPT and GPT4 significantly improve translation quality and discourse awareness. The reviewer points out that the difference between the scores for ChatGPT and GPT4 is minimal and suggests that proper testing, including distribution checks and multiple comparisons, is needed to determine significance. This feedback is clear and provides concrete guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 486,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the lack of significance testing and provides a concrete example from line 486, where the authors claim a significant difference in translation quality and discourse awareness between ChatGPT and GPT4. The comment suggests that proper testing, including distribution checks and multiple comparisons, is needed to determine significance. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point claims that the authors make significant claims about the differences between methods without providing significance testing. The reviewer provides a specific example from line 486, where the authors claim that ChatGPT and GPT4 significantly improve translation quality and discourse awareness. The reviewer points out that the difference between the scores for ChatGPT and GPT4 is minimal and suggests that proper testing, including distribution checks and multiple comparisons, is needed to determine significance. This reasoning is clear and provides a logical basis for the claim, making it 4. However, the comment could be strengthened by including references to specific statistical methods or examples of how significance testing should be conducted. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment is 5 as it identifies a significant issue with the paper: the lack of significance testing to support claims about the differences between methods. It provides a specific example from line 486, where the authors claim that ChatGPT and GPT4 significantly improve translation quality and discourse awareness, but the reviewer points out that the difference between the scores is minimal and suggests that proper testing is needed. This feedback is actionable, as it directs the authors to conduct significance testing to substantiate their claims and improve the rigor of their analysis. The comment is clear and provides a concrete suggestion for improvement, making it 5 for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the potential impact of regularization effects rather than distillation on the improvements in the teacher\"s performance. It suggests that the authors should conduct proper ablation studies to verify their claims. While the comment implies that the authors should conduct additional experiments, it does not provide specific guidance on how to design these experiments or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the need for additional experiments and determine the specifics themselves. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper, namely the claim that distilling knowledge from the student to the teacher improves the teacher\"s performance. It raises a concern about the potential impact of regularization effects rather than distillation, specifically mentioning the use of finetuning for 10 epochs without earlystopping. This provides clear guidance on what needs to be addressed, such as conducting proper ablation studies to verify the claims. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the improvements in the teacher\"s performance could be due to regularization effects rather than distillation, as all finetuning is performed for 10 epochs without earlystopping. The reviewer suggests that this could lead to high variances and recommends conducting proper ablation studies to verify the claims. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion about the potential impact of regularization effects. This makes the claim 3, as it requires further elaboration or evidence to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s claim that distilling knowledge from the student to the teacher improves the teacher\"s performance. It suggests that the improvements could be due to regularization effects rather than distillation, as all finetuning is performed for 10 epochs without earlystopping. The reviewer highlights the need for proper ablation studies to verify the claims, which is a clear and actionable suggestion for the authors to consider. However, the comment could be more helpful by providing specific examples or guidance on how to conduct these ablation studies. Overall, the feedback is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point expresses an opinion about the limited contribution and incremental nature of the proposed model. However, it does not provide any specific guidance or suggestions for the authors to address these concerns. There is no explicit or implicit action for the authors to take, nor are there any concrete steps outlined for improvement. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment expresses an opinion about the limited contribution and incremental nature of the proposed model. However, it does not specify which part of the paper this assessment is based on, nor does it provide details on what aspects of the contribution or model are considered limited or incremental. Without specific references or examples, the authors cannot effectively address the feedback. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses an opinion about the limited contribution and incremental nature of the proposed model. However, it lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses an opinion about the limited contribution and incremental nature of the proposed model. However, it lacks specificity and does not provide any actionable feedback or suggestions for improvement. Without detailed guidance or examples, the authors are left without a clear understanding of what aspects of their work need to be addressed or how to enhance their contribution. As a result, the comment is 1, as it does not offer any constructive direction for the authors to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the potential negative transfer of supervised pretraining based on the prediction of homolumo gap, specifically mentioning the poor performance of TransformerM on most tasks other than homo, lumo, and gap on QM9 in downstream experiments. The comment suggests that this finding may contradict the claim of the paper being a \"generalpurpose neural network model.\" While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this contradiction or improve their model. The action is implicit and somewhat vague, as the authors are left to infer that they should investigate the negative transfer and its implications for their model\"s generalpurpose claim. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the prediction of the homolumo gap and the performance of TransformerM on QM9 in downstream experiments, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the potential negative transfer and the contradiction with the claim of the paper being a \"generalpurpose neural network model.\" This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that supervised pretraining based on the prediction of homolumo gap may lead to negative transfer, citing the poor performance of TransformerM on most tasks other than homo, lumo, and gap on QM9 in downstream experiments. The comment provides a specific example from the QM9 dataset to support the claim, which is a clear and logical reasoning. However, it could be strengthened by providing more detailed analysis or references to similar cases in the literature. Overall, the claim is 4, as it provides a solid basis for the argument but lacks comprehensive evidence or references. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment raises a concern about the potential negative transfer of supervised pretraining based on the prediction of homolumo gap, specifically mentioning the poor performance of TransformerM on most tasks other than homo, lumo, and gap on QM9 in downstream experiments. This observation is relevant and could be a significant issue for the authors to address. However, the comment does not provide specific suggestions or guidance on how the authors might investigate or resolve this issue, such as recommending alternative approaches or further analysis. While it identifies a potential problem, the feedback lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point provides explicit actions for the authors to take, such as abating the \"picking\" step and ensuring that the comparison on CIFAR is more convincing by using the same setup as in the DEN paper. These actions are clearly stated and provide concrete guidance on how to improve the draft. The authors know exactly what needs to be done to address the issues raised, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Experimental Evaluation 2.1. Ablations 2.1.1\" and \"Experiments on CIFAR,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details what needs to be addressed, such as abating the \"picking\" step and ensuring a more convincing comparison on CIFAR by using the same setup as in the DEN paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of multiple claims and suggestions, each of which requires verification. The first claim about the \"picking\" step being not ablated is supported by the explicit mention of the paper\"s claim, which provides a clear basis for the reviewer\"s observation. The second claim about the comparison on CIFAR being unconvincing is supported by the explanation that the paper only compares to one approach (DEN) and that it is unclear if DEN is correctly used/evaluated. The suggestion to use the same setup as in the DEN paper to ensure a fair comparison is logical and provides a clear path for improvement. Overall, the comment is 4, as it provides a logical basis for the claims and suggestions, but could be strengthened with more detailed examples or references. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the experimental evaluation section of the paper. It points out that the \"picking\" step is not ablated, which is a critical aspect of the paper\"s claims. Additionally, it highlights the lack of convincing comparison on CIFAR, noting that the paper only compares to one approach (DEN) and that it is unclear if DEN is correctly used/evaluated. The comment suggests that using the same setup as in the DEN paper would make the comparison more fair and convincing. This feedback is clear and actionable, guiding the authors on how to improve the experimental section of their paper. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the tradeoff between computation time reduction and the loss of information due to the reduced search space. It questions the extent to which the ancestral graphs encode the information of DAGs. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or what specific actions they should take to improve their draft. The comment implies that the authors should consider the impact of this tradeoff on their results, but it lacks concrete steps or recommendations for improvement. As a result, the comment is 3, as it highlights an area for consideration but does not offer direct guidance on how to address it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed method and its comparison with [10], allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by discussing the tradeoff between computation time reduction and the loss of information due to the reduced search space. The comment raises a question about the extent to which ancestral graphs encode the information of DAGs, which provides a clear direction for the authors to address. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method reduces computation time by limiting the search space to ancestral graphs, which results in a loss of information compared to the output of [10], which has a richer search space of DAGs. The comment questions the extent to which ancestral graphs encode the information of DAGs. While the claim is based on a logical comparison of search spaces and their implications, it lacks specific examples or references to support the assertion about the loss of information. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a tradeoff in the proposed method, noting that while it reduces computation time, it does so by limiting the search space to ancestral graphs, which results in a loss of information compared to the output of a method with a richer search space (DAGs). The comment raises a question about the extent to which ancestral graphs encode the information of DAGs, which is a relevant point for the authors to consider. However, the comment does not provide specific suggestions or guidance on how the authors might address this tradeoff or improve their method. While it highlights an important issue, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises doubts about the definitions in Table 1, specifically questioning the difference between anchorbased regression and the regression in RepPoints. It also mentions that RetinaNet and ATSS use a oneshot regression, which is similar to the method in RepPoints. The reviewer suggests that the authors clarify this issue, as the motivations for the method may not be solid without a clear distinction. While the comment implies that the authors should clarify the definitions, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the definitions and motivations. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the doubts about the definitions in Table 1, particularly the distinction between anchorbased regression and the regression in RepPoints. The comment further explains the similarities between RetinaNet, ATSS, and RepPoints, and suggests that the method of directly regressing [w, h] to the center point is sufficient. The reviewer also requests clarification on this issue, which adds specificity to the comment. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises doubts about the definitions in Table 1, specifically questioning the difference between anchorbased regression and the regression in RepPoints. It also mentions that RetinaNet and ATSS use a oneshot regression, which is similar to the method in RepPoints. The reviewer suggests that the method of directly regressing [w, h] to the center point is sufficient, and that RepPoints regresses distance to the location of feature maps. The comment provides a logical reasoning by comparing different methods and their similarities, which helps the authors understand the basis of the doubt. However, it lacks specific references or detailed examples to fully substantiate the claim. Therefore, the comment is 3, as it provides a logical basis but could be strengthened with more detailed evidence or references.", "helpfulness_rationale": "The review comment raises a specific concern about the definitions in Table 1, particularly the distinction between anchorbased regression and the regression in RepPoints. It also compares the methods used in RetinaNet, ATSS, and RepPoints, suggesting that the method of directly regressing [w, h] to the center point is sufficient. The reviewer questions the need for RepPoints\" method of regressing distance to the location of feature maps, suggesting that there may be no significant difference between the two methods. This feedback is 3 as it identifies a potential area of confusion or overlap in the paper, prompting the authors to clarify their definitions and motivations. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or offered alternative ways to present the information. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that when discussing Fourier modes as numbers, the authors should clarify whether they are real or complex. This is an explicit request for clarification, providing a clear action for the authors to take. The comment is specific and concrete, as it directly instructs the authors on what needs to be clarified. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests clarifying whether Fourier modes are real or complex when discussing them as numbers. However, it does not specify which part of the paper this discussion occurs in, making it weakly grounded. The comment is specific in its request for clarification, as it identifies a particular aspect of the paper that needs clarification. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that when discussing Fourier modes as numbers, the authors should clarify whether they are real or complex. This is a request for clarification rather than a claim or opinion. It does not contain any subjective statements, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment suggests that when discussing Fourier modes as numbers, the authors should clarify whether they are real or complex. This is a specific and actionable piece of feedback that can help the authors improve the clarity and precision of their work. By addressing this suggestion, the authors can enhance the comprehensibility of their paper for readers. However, the comment could be more helpful if it provided additional context or examples of how this clarification might impact the understanding of the paper. Overall, the feedback is 3 as it identifies a clear area for improvement but lacks depth in terms of guidance or examples."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly identifies a specific error in the paper, namely the incorrect reference to Fig. 5.1 instead of Fig. 1. It provides a clear and direct action for the authors to take, which is to correct the reference and ensure that the label is placed after the caption in LaTeX. This feedback is concrete and leaves no ambiguity about what needs to be done to address the issue. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 205,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the error, which is the incorrect reference to Fig. 5.1 instead of Fig. 1, and provides a solution by suggesting the correct placement of the label in LaTeX. This level of detail guides the authors on what needs to be corrected, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a factual correction regarding a typographical error in the paper, specifically the incorrect reference to Fig. 5.1 instead of Fig. 1. It provides a clear and specific suggestion for the authors to correct the error by placing the label after the caption in LaTeX. This feedback is factual and does not contain any subjective claims or opinions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 5 as it provides specific and actionable feedback regarding a typographical error in the paper. It identifies a mistake in the reference to Figure 1, which should be corrected to Figure 5.1. Additionally, it offers a clear solution by suggesting the correct placement of the label in LaTeX, which is a straightforward and effective way to address the issue. This level of detail and guidance empowers the authors to make a precise correction, ensuring the accuracy and clarity of their draft. Therefore, the comment is rated as 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should include case studies and error studies to highlight the effectiveness of each proposed component. It provides an example of how this could be done, mentioning the Elementlevel Graph Pretraining and suggesting a specific reference for a case study. This feedback is explicit and provides concrete guidance on how to improve the draft by including additional examples and studies. The authors know exactly what needs to be done to enhance the clarity and persuasiveness of their work. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests discussing case studies and error studies to highlight the effectiveness of each proposed component, specifically mentioning the Elementlevel Graph Pretraining. It provides an example of how this could be done, referencing a specific paper (\"Graph pretraining for AMR parsing and generation\"). This provides clear guidance on what needs to be addressed and offers a concrete example for improvement. The comment is fully grounded as it explicitly mentions the Elementlevel Graph Pretraining, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a particular approach and references an external work for further guidance. Therefore, this comment is labeled as 5.", "verifiability_rationale": "The review point suggests that discussing case studies and error studies would enhance the paper\"s effectiveness. It provides a specific example of how the Elementlevel Graph Pretraining could be better explained by referencing a case study in another paper. This provides a clear and logical reasoning for the suggestion, making the claim 4. However, the comment could be strengthened by including more detailed references or examples from the referenced paper, which would fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the paper by recommending the inclusion of case studies and error studies to highlight the effectiveness of each proposed component. It offers a concrete example of how this could be done, referencing the Elementlevel Graph Pretraining and suggesting a specific reference for a case study. This feedback is actionable and provides clear guidance on how the authors can enhance the persuasiveness of their work. By following this advice, the authors can better illustrate the strengths and weaknesses of their approach, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point consists of two questions regarding the experimental dataset and the design choices in the model architecture. While it highlights specific aspects of the paper that need clarification, it does not provide explicit instructions or suggestions for the authors to address these questions. The authors can infer that they need to provide explanations for these design choices, but the comment lacks concrete guidance on how to do so. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues by asking for the main rationales behind two specific design choices: (a) having a separate timbre encoder module and (b) using SADTW with the outputs of the content encoder rather than the timbre encoder. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of two questions seeking clarification about the experimental dataset and the design choices in the model architecture. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises two specific questions about the experimental dataset and the design choices in the model architecture, particularly regarding the timbre encoder module and the input to the SADTW module. This feedback is 3 as it prompts the authors to clarify their experimental setup and design decisions, which can lead to a more transparent and comprehensible presentation of their work. However, the comment does not provide suggestions or guidance on how to address these questions or improve the clarity of the paper. To be more helpful, the comment could include suggestions on how to present the rationale for these design choices or provide examples of similar approaches in the literature. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment indicates that the writing or presentation is \"jumbled\" at times, but it does not provide any specific examples or suggestions for improvement. It lacks explicit guidance or concrete actions for the authors to take to address the issue. The comment is vague and does not offer any actionable steps for the authors to follow, leaving them without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions that the writing or presentation is \"jumbled\" at times, but it does not specify which parts of the paper are affected or what aspects are particularly jumbled. This makes it difficult for the authors to identify the exact sections that need attention. Additionally, the comment lacks specificity regarding what needs to be clarified or improved. Without explicit references to sections or examples of the jumbled content, the authors cannot effectively address the feedback. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the writing or presentation is \"jumbled\" at times, but it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed explanation or references to particular sections or issues, the authors may find it challenging to understand and address the feedback. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment indicates that the writing or presentation is \"jumbled\" at times, suggesting that the content is not wellorganized or coherent. However, it lacks specificity and does not provide any examples or detailed feedback on what aspects of the writing are unclear or how they could be improved. Without actionable suggestions or guidance, the authors are left without a clear understanding of what needs to be addressed to enhance the clarity and coherence of their draft. Therefore, the comment is 1, as it does not offer any meaningful direction for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the total computational complexity of the method compared to other methods, such as emerging convolutions, and speculates about the potential power demand on a mobile device. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the question or what specific aspects of computational complexity or power demand should be considered. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the total computational complexity of the method compared to other methods, such as emerging convolutions, and speculates about the potential power demand on a mobile device. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, while it provides some context by mentioning emerging convolutions, it lacks specificity in terms of what aspects of computational complexity or power demand should be addressed. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the computational complexity of the method compared to other methods, such as emerging convolutions, and speculates about the potential power demand on a mobile device. However, it does not provide any specific evidence, references, or detailed reasoning to support the claim about the computational complexity or power demand. The comment lacks verifiable data or examples to substantiate the claim, making it difficult for the authors to understand the basis of the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the total computational complexity of the method compared to other methods, such as emerging convolutions, and speculates about the potential power demand on a mobile device. While it identifies a potential area of concern, it lacks specificity and actionable guidance for the authors. The comment does not provide detailed suggestions on how to address the issue of computational complexity or power demand, nor does it offer insights into how the authors might evaluate or improve these aspects. As a result, the feedback is 3, as it prompts the authors to consider these aspects but does not fully support them in making improvements. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point identifies a specific error in the authors\" statement regarding the Induction, Duplicate Token, and Previous Token heads in the base IOI circuit. It corrects the authors\" claim by stating that these heads are active at the S2 token but do not primarily attend to it. This feedback is explicit and provides a clear correction, allowing the authors to make the necessary changes to their draft. The action is concrete, as it specifies the exact correction needed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3 of Wang et al., 2023,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it corrects a claim made by the authors regarding the Induction, Duplicate Token, and Previous Token heads in the base IOI circuit. The comment specifies that these heads are active at the S2 token but do not primarily attend to it, providing clear guidance on what needs to be corrected. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors\" statement regarding the Induction, Duplicate Token, and Previous Token heads is incorrect, as it contradicts the findings in Section 3 of Wang et al., 2023. The comment provides a specific reference to an external work, which is a clear and robust form of evidence to support the claim. This makes the claim 5, as it provides a direct and credible source for the authors to verify the correction. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a specific error in the authors\" statement regarding the Induction, Duplicate Token, and Previous Token heads in the base IOI circuit. It corrects the authors\" claim by pointing out that these heads are active at the S2 token but do not primarily attend to it, as stated in Section 3 of Wang et al., 2023. This feedback is clear and actionable, providing the authors with a precise correction to make in their draft. By addressing this error, the authors can improve the accuracy and clarity of their paper. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides two distinct points of feedback. First, it critiques the vagueness of the statement in lines 15, suggesting that certain RNNs work well for certain natural language reasoning tasks. The reviewer references specific literature and a leaderboard to support this claim. This feedback is explicit and provides concrete examples, making it 5. Second, the comment critiques the reinforcement learning / agent analogy in lines 1618, suggesting that it is outofplace and that generalization capabilities are better illustrated later in the paper. While the comment identifies a potential issue, it does not provide specific guidance on how to address it, leaving the authors to infer that they should reconsider the analogy or its placement. Overall, the comment is 4, as it provides clear guidance on one point and suggests an area for improvement on another, but it could be more detailed in the latter part.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (L15, L1618) in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it provides detailed feedback on the vagueness of the statement in line 15, suggesting that certain RNNs work well for certain natural language reasoning tasks and referencing specific literature and a leaderboard. Additionally, it critiques the reinforcement learning / agent analogy in lines 1618, suggesting that it is outofplace and that generalization capabilities are better illustrated later in the paper. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of two distinct claims. The first claim, regarding the vagueness of the statement in line 15, is supported by a reference to specific literature and a leaderboard, providing a clear basis for the critique. This makes the claim 4. The second claim, about the reinforcement learning / agent analogy being outofplace, is supported by a logical reasoning that suggests generalization capabilities are better illustrated later in the paper. However, the comment could be strengthened by providing specific examples or references to support this claim. Overall, the first claim is 4, while the second is 3 due to the lack of detailed examples or references. Therefore, the overall score is 3.", "helpfulness_rationale": "The review comment provides two distinct points of feedback. First, it critiques the vagueness of the statement in line 15, suggesting that certain RNNs work well for certain natural language reasoning tasks. The reviewer references specific literature and a leaderboard, which is a helpful addition to clarify the point. Second, the comment critiques the reinforcement learning / agent analogy in lines 1618, suggesting that it is outofplace and that generalization capabilities are better illustrated later in the paper. This feedback is clear and actionable, as it identifies specific areas for improvement and provides a direction for the authors to enhance their draft. However, the comment could be more helpful if it offered suggestions on how to better integrate the analogy or provide examples of how generalization is better illustrated later. Overall, the comment is 4, as it provides valuable insights and guidance for the authors to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential issue with the statement that \"every kernel can be described by a feature space parameterized by a neural network,\" pointing out that this is not true for RBF kernels. The reviewer suggests that the limitation should be made more clear. While the comment identifies a specific area that needs clarification, it does not provide explicit guidance on how to address this issue or what specific changes should be made to improve the draft. The action is implicit and somewhat vague, as the authors are left to infer the necessary changes without detailed instructions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"104,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the statement about kernels and neural networks, pointing out that it is not true for RBF kernels and that the limitation should be made more clear. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement \"every kernel can be described by a feature space parameterized by a neural network\" is not true, specifically mentioning RBF kernels and their infinitedimensional RKHS. The reviewer provides a logical reasoning by explaining that an NN with infinite width would be needed to represent the RKHS, which is not feasible in practice. This reasoning is clear and provides a logical basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the statement that \"every kernel can be described by a feature space parameterized by a neural network,\" pointing out that this is not true for RBF kernels. It provides a clear and logical explanation of why this claim is incorrect, noting that RBF kernels have an infinitedimensional RKHS, which cannot be represented by a neural network with finite width. The comment suggests that this limitation should be made more clear in the paper. This feedback is actionable and provides a specific area for improvement, making it 4. However, it could be more helpful if it offered suggestions on how to address this issue or clarify the statement in the paper. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the proposed method is not wellpositioned in the literature and suggests that the authors conduct a thorough literature review to better position their work. It mentions that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is wellknown and has been used in various works, such as denoising score matching and scoreinterpolation. While the comment implies that the authors should conduct a literature review, it does not provide specific guidance on how to conduct this review or which works to consider. The action is implicit and somewhat vague, as the authors know they need to conduct a literature review but lack detailed instructions on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that this idea is wellknown and has been used in various works, such as denoising score matching and scoreinterpolation. The comment further suggests that the authors conduct a thorough literature review to better position their work. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed method is not wellpositioned in the literature and suggests that the key idea behind it is wellknown. The reviewer supports this claim by referencing specific works, such as denoising score matching and scoreinterpolation, where this idea has been used. This provides a clear basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed references or examples to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, noting that the proposed method is not wellpositioned in the literature. It points out that the key idea behind the method, representing the marginal score as the expectation of scores of distributions conditioned on inputs, is wellknown and has been used in various works, such as denoising score matching and scoreinterpolation. The comment suggests that the authors conduct a thorough literature review to better position their work within the existing body of knowledge. While the feedback is clear and actionable, it could be more helpful by providing specific examples or references to guide the authors in their literature review. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point states that the technical contribution is limited, as there is no significant technical contribution or extension based on a typical model for the crossdomain recommendation setting. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to enhance the technical contribution or what specific changes could be made to improve the paper. As a result, the authors are left without any actionable steps to follow, making the comment 1.", "grounding_specificity_rationale": "The comment critiques the technical contribution of the paper, stating that it is limited and lacks significant technical contributions or extensions based on a typical model for the crossdomain recommendation setting. However, it does not specify which part of the paper this critique is based on, such as a particular section, experiment, or methodology. Without explicit references to specific parts of the paper, the authors cannot confidently determine which aspects need revision. Additionally, the comment lacks specificity regarding what specific limitations or areas for improvement are being addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the technical contribution is limited, stating that there is no significant technical contribution or extension based on a typical model for the crossdomain recommendation setting. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without specific details or examples, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment critiques the technical contribution of the paper, stating that it is limited and lacks significant technical contributions or extensions based on a typical model for the crossdomain recommendation setting. However, the comment does not provide any specific suggestions or guidance on how the authors might enhance their technical contribution or what areas could be improved. Without actionable feedback or detailed insights, the authors are left without a clear path for improvement. Therefore, the comment is 1, as it does not offer any constructive direction for enhancing the draft."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the novelty of the specific components of the approach, such as the weak predictor and sampling strategy, by comparing them to existing methods. It highlights that the weak predictor is not novel, as it consists of MLP, Regression Tree, or Random Forest, which have been used for NAS performance prediction before. Additionally, it notes that the sampling strategy is similar to epsilongreedy and exactly the same as that in BRPNAS. The comment also points out that the results of WeakNAS are almost identical to BRPNAS, as shown in Table 2 in Appendix C. However, the comment does not provide any explicit or implicit suggestions for improvement or guidance on how the authors might address these issues. Without actionable advice or specific recommendations, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific components of the approach, such as the weak predictor and the sampling strategy, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with these components, noting that they are not novel and are similar to existing methods, such as MLP, Regression Tree, or Random Forest, and that the sampling strategy is the same as that in BRPNAS. Additionally, it points out that the results of WeakNAS are almost identical to BRPNAS, as shown in Table 2 in Appendix C. This level of detail provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the specific components of the approach, such as the weak predictor and sampling strategy, are not novel and are similar to existing methods. It supports this claim by referencing previous works [2,3,7] that have used MLP, Regression Tree, or Random Forest for NAS performance prediction and by comparing the sampling strategy to epsilongreedy and BRPNAS. Additionally, it points out that the results of WeakNAS are almost identical to BRPNAS, as shown in Table 2 in Appendix C. This provides a clear and logical basis for the claim, making it 5. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment provides a detailed critique of the novelty of the specific components of the approach, such as the weak predictor and sampling strategy. It compares these components to existing methods, noting that they are not novel and are similar to epsilongreedy and BRPNAS. The comment also points out that the results of WeakNAS are almost identical to BRPNAS, as shown in Table 2 in Appendix C. While this feedback highlights a significant issue with the originality of the approach, it does not offer suggestions or guidance on how the authors might address these concerns or improve the novelty of their work. The lack of actionable advice limits the comment\"s helpfulness, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises questions about the calculation of precision, recall, and F1score for a 4class classification of breast density and suggests reporting AUC results for comparisons in breast cancer detection. While the comment implies that the authors should provide more detailed information on their methodology and results, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address these points in their draft. However, the comment does provide a clear direction on what information would be more informative, which makes it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"precision/recall/F1score for 4class classification of breast density\" and \"breast cancer detection,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what needs to be addressed, such as calculating and reporting AUC results for comparisons. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the calculation of precision, recall, and F1score for a 4class classification of breast density, and suggests reporting AUC results for comparisons in breast cancer detection. The comment provides a logical reasoning for why AUC results might be more informative, as they offer a comprehensive evaluation of model performance. However, it lacks specific examples or references to support the claim that AUC is the preferred metric for breast cancer detection. This makes the claim 3, as it provides a reasonable suggestion but requires more detailed justification or evidence to be fully convincing.", "helpfulness_rationale": "The review comment raises important questions about the methodology used to calculate precision, recall, and F1score for a 4class classification of breast density, which is a critical aspect of the paper. It also suggests that reporting AUC results with sensitivity and specificity at different operating points would be more informative for comparing model performance in breast cancer detection. This feedback is clear and actionable, as it identifies specific areas where the authors can enhance their analysis and presentation of results. By addressing these points, the authors can improve the comprehensiveness and clarity of their work. However, the comment could be more helpful if it provided examples or references on how to calculate AUC or included more detailed guidance on reporting operating points. Overall, the comment is 4, as it provides valuable insights for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that the creation of the dataset is optional, as the Kialo dataset already provides the necessary pairs of short claims and their counters. It notes that the Kialo dataset is cleaner since it does not rely on automatic processes to construct it. The comment suggests that the dataset created in the paper could serve as additional data for learning. While the comment implies that the authors should consider using the Kialo dataset instead of creating their own, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to integrate the Kialo dataset or what to do with the existing dataset. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the creation of the dataset, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the dataset, noting that the Kialo dataset, which is wellstudied in the community, provides what the authors need\u2014pairs of short claims and their counters. The comment further specifies that the Kialo dataset is cleaner since it does not rely on automatic processes to construct it. Additionally, it suggests that the dataset created in the paper could serve as additional data for learning. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the creation of the dataset is optional, as the Kialo dataset provides what the authors need. It supports this claim by comparing the Kialo dataset to the one created in the paper, noting that the former is cleaner since it does not rely on automatic processes. The comment also suggests that the dataset created in the paper could serve as additional data for learning. This reasoning is logical and provides a clear basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to the Kialo dataset, which would further enhance its verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion by pointing out that the creation of the dataset is optional, as the Kialo dataset already provides the necessary pairs of short claims and their counters. It highlights that the Kialo dataset is cleaner since it does not rely on automatic processes to construct it. The comment also suggests that the dataset created in the paper could serve as additional data for learning. This feedback is valuable as it offers a practical alternative to the authors, allowing them to potentially improve their work by leveraging an existing dataset. However, the comment could be more helpful if it provided specific guidance on how to integrate the Kialo dataset or what aspects of the existing dataset could be improved. Overall, the comment is 4, as it provides clear direction for improvement but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the novelty of the proposed modification to the transformer, specifically the crosslayer approach, and questions its significance in terms of machine learning insights. It also suggests that the improvements over other methods come from using a na\u00efve transformer rather than the proposed modification. While the comment highlights potential issues with the novelty and significance of the work, it does not provide explicit guidance or suggestions for improvement. The authors are left to infer that they might need to clarify the novelty and significance of their approach or address the critique regarding the improvements. However, the lack of concrete advice or specific actions makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 4 and 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the novelty of the proposed modification to the transformer, the limited improvement brought by the selfcross attention, and the main improvements coming from using a na\u00efve transformer. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed modification to the transformer, specifically the crosslayer approach, does not bring much insight in the field of machine learning and that the improvements over other methods come from using a na\u00efve transformer rather than the proposed modification. The reviewer supports this claim by referencing the ablation study (table 4 and 5), which shows limited improvement (<1%) from the selfcross attention. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. The reference to the ablation study is a step in the right direction, but more detailed analysis or references would strengthen the argument. Therefore, the comment is 3, as it provides some support but requires additional evidence to be fully convincing.", "helpfulness_rationale": "The review comment provides a critical evaluation of the novelty and significance of the proposed modification to the transformer, specifically the crosslayer approach. It questions the extent to which this modification brings new insights to the field of machine learning, noting that the improvements over other methods come from using a na\u00efve transformer rather than the proposed modification. The comment also points out the limited improvement (<1%) from the selfcross attention in the ablation study, suggesting that this may not be considered a significant improvement. While the comment identifies areas of concern and provides some insight into the limitations of the work, it lacks specific suggestions or actionable feedback on how the authors might address these issues. The feedback is 3 as it highlights potential weaknesses, but it could be more beneficial with additional guidance or constructive advice. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to discuss a previous work, \"Domain Adaptation with AsymmetricallyRelaxed Distribution Alignment,\" and to illustrate the relationship between that work and their proposed method. It also suggests that the authors should explain why their method is better. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is explicit and detailed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about the lack of research focusing on the joint error for UDA, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the problem of arbitrarily increased joint error has already been studied in a previous work, \"Domain Adaptation with AsymmetricallyRelaxed Distribution Alignment,\" published in ICML2019. The comment further instructs the authors to discuss this work and illustrate the relationship between it and their proposed method, as well as why their method is better. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the authors\" assertion about the lack of research on joint error for UDA is incorrect, as this problem has already been studied in a previous work. The reviewer supports this claim by referencing a specific paper, \"Domain Adaptation with AsymmetricallyRelaxed Distribution Alignment,\" published in ICML2019. This reference provides a clear and specific example to substantiate the claim, making it 5. The reviewer also suggests that the authors should discuss this work and illustrate the relationship between it and their proposed method, which further strengthens the justification. Therefore, the comment is categorized as 5.", "helpfulness_rationale": "The review comment identifies a potential issue with the authors\" claim that there is no research focusing on the joint error for UDA, pointing out that this problem has already been studied in a previous work. It provides a specific reference to the work \"Domain Adaptation with AsymmetricallyRelaxed Distribution Alignment\" and suggests that the authors should discuss this work and illustrate the relationship between it and their proposed method. This feedback is clear and actionable, as it directs the authors to address a specific gap in their literature review and to provide a comparative analysis of their work with existing research. By doing so, the authors can enhance the comprehensiveness and validity of their paper. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the comparison to stateoftheart (SOTA) methods, suggesting that the performance of the paper may be unfairly attributed to the newly collected 209M dataset, while existing methods use smaller datasets. The reviewer provides an example of GEM using only 20M unlabeled data. This feedback implies that the authors should consider the impact of dataset scale on their results and potentially adjust their claims or comparisons. However, the comment does not explicitly instruct the authors to make specific changes or provide detailed guidance on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their comparisons and potentially adjust their claims. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the comparison with stateoftheart (SOTA) methods, specifically mentioning the use of a newly collected 209M dataset compared to existing methods using smaller datasets. It provides an example of GEM using only 20M unlabeled data, which highlights the potential impact of dataset scale on the results. However, the comment does not explicitly mention which part of the paper discusses these comparisons, making it weakly grounded. The authors can infer that it relates to the results or methodology sections, but this inference is not as direct as it could be. The comment is specific in detailing the issue with the comparison and the potential impact of dataset scale, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that the comparison with stateoftheart (SOTA) methods may be unfair due to the use of a newly collected 209M dataset, while existing methods use smaller datasets. The reviewer provides an example of GEM using only 20M unlabeled data, suggesting that the scale of datasets can significantly impact accuracy. This reasoning is logical and provides a clear basis for the claim, making it 4. However, the comment could be strengthened by referencing specific SOTA methods or providing more detailed comparisons to support the claim fully. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison to stateoftheart (SOTA) methods, suggesting that the performance of the paper may be unfairly attributed to the newly collected 209M dataset, while existing methods use smaller datasets. The reviewer provides an example of GEM using only 20M unlabeled data, which highlights the impact of dataset scale on accuracy. This feedback is valuable as it prompts the authors to consider the fairness of their comparisons and potentially adjust their claims or methodology. However, the comment could be more helpful if it offered specific suggestions on how to address this issue or provided examples of how to fairly compare performance across different datasets. Overall, the comment is 3 as it directs the authors to a critical area for improvement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of justification for the need to design a new curriculum learning method for text graphs and points out that the research gap, such as why existing methods cannot be applied, is not discussed. While the comment identifies a gap in the paper, it does not provide explicit guidance on how to address this issue or suggest specific actions for the authors to take. The authors are left to infer that they need to provide a justification for the need for a new method and discuss the limitations of existing approaches. However, the lack of concrete suggestions or detailed guidance makes the action vague and difficult for the authors to implement effectively. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of justification for designing a new curriculum learning method for text graphs and the absence of discussion on why existing methods cannot be applied. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the need for designing a new curriculum learning method for text graphs is not justified and that the research gap, such as why existing methods cannot be applied, is not discussed. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence makes the claim 3, as the authors would need to infer the gaps in the paper themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper regarding the justification for designing a new curriculum learning method for text graphs. It points out that the research gap, such as why existing methods cannot be applied, is not discussed. This feedback is clear and actionable, as it prompts the authors to address the lack of justification and provide a rationale for their approach. However, the comment could be more helpful if it offered specific suggestions on how to frame the discussion or what aspects of existing methods should be considered. Overall, the comment is 4 as it directs the authors to a critical area needing improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should use powerful pretrained language models like BERT and XLNet as the base encoder for all methods and then compare the efficacy of the transfer parts instead of using ngram features. This comment provides a clear and explicit action for the authors to take, specifying exactly what needs to be done to improve their draft. The suggestion is concrete, as it outlines a specific approach to enhance the paper\"s methodology. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests using powerful pretrained language models like BERT and XLNet as the base encoder for all methods, rather than using ngram features. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the methodology or experimental setup, but the lack of explicit grounding makes it difficult to pinpoint the exact part of the paper being addressed. The comment is specific in suggesting a change in methodology, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point claims that powerful pretrained language models like BERT and XLNet can overcome the domainshift problem to some extent. However, it does not provide any supporting evidence, examples, or references to substantiate this claim. The lack of detailed reasoning or specific examples makes it difficult for the authors to understand the basis of the suggestion or to assess its validity. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests using powerful pretrained language models like BERT and XLNet as the base encoder for all methods, rather than relying on ngram features. This feedback is 3 as it provides a specific suggestion for improving the methodology, which could enhance the paper\"s effectiveness. However, the comment lacks detailed reasoning or examples to support why this change would be beneficial or how it would address the domainshift problem. Additionally, it does not offer guidance on how to implement this change or what specific aspects of the paper might be affected. Therefore, while the suggestion is actionable, the comment could be more helpful with additional context and explanation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the quantitive evaluation results in Figure 3, noting that they only reflect middle outputs rather than the final outputs. It also mentions that Figure 4 illustrates the comparison of final results with a single data sample, questioning the validity of the current evaluations. The reviewer suggests that a quantitative comparison on the final outputs would be more convincing. While the comment implies that the authors should include a quantitative comparison on the final outputs, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a quantitative comparison on the final outputs. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3\" and \"Figure 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the quantitative evaluation results in Figure 3 only reflect middle outputs, while Figure 4 illustrates the comparison of final results with a single data sample. The comment further questions the validity of the current evaluations and suggests a quantitative comparison on the final outputs. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with a score of 5.", "verifiability_rationale": "The review point claims that the quantitative evaluation results in Figure 3 only reflect middle outputs, while Figure 4 illustrates the comparison of final results with a single data sample. The reviewer questions the validity of the current evaluations and suggests a quantitative comparison on the final outputs. This claim is 3 as it provides a logical reasoning for the issue, noting that the evaluations are not comprehensive due to the focus on middle outputs. However, the comment lacks specific examples or references to support the claim fully, making it 3. The authors would need to address this concern by providing a more comprehensive evaluation, but the comment could be strengthened with additional evidence or examples.", "helpfulness_rationale": "The review comment identifies a specific issue with the quantitative evaluation results in Figure 3, noting that they only reflect middle outputs rather than the final outputs. It also points out that Figure 4 illustrates the comparison of final results with a single data sample, questioning the validity of the current evaluations. The reviewer suggests that a quantitative comparison on the final outputs would be more convincing. This feedback is clear and actionable, as it highlights a critical gap in the evaluation process and provides a specific suggestion for improvement. By addressing this issue, the authors can strengthen their claims about ModelAngelo\u2019s superiority over competitors. Therefore, the comment is 4, as it offers valuable guidance for enhancing the draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights several areas where the paper lacks detail, making it difficult to reproduce the results. It explicitly points out specific aspects that need clarification, such as the sparsification process, the generation of landmarks, the number of landmarks used, the type of image features, the fixed radius with different scales, and achieving shape invariance. Each of these points provides clear guidance on what the authors need to address to improve the clarity and reproducibility of their work. The comment is explicit and provides concrete details on how to implement the suggested improvements, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific areas that need clarification, such as the sparsification process, the generation of landmarks, the number of landmarks used, the type of image features, the fixed radius with different scales, and achieving shape invariance. This allows the authors to accurately identify the parts of the paper that need attention. The comment is also specific because it details what aspects are unclear or missing, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks detail about the techniques, making it difficult to reproduce the results. It provides specific examples of what is unclear, such as the sparsification process, the generation of landmarks, and the number of landmarks used. These examples are detailed and provide a clear basis for the claim, making it 4. However, the comment could be strengthened by referencing specific sections of the paper where these details are lacking or by providing examples from similar works that address these issues. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, namely the lack of detail about the techniques used, which makes it difficult to reproduce the results. It provides specific examples of what is unclear, such as the sparsification process, the generation of landmarks, and the number of landmarks used. This feedback is clear and actionable, as it guides the authors on what aspects of their methodology need further explanation and clarification. By addressing these points, the authors can enhance the reproducibility and clarity of their work. However, the comment could be more helpful if it offered suggestions on how to improve the clarity or provided examples of how similar techniques are typically described in the literature. Overall, the comment is 4, as it effectively directs the authors to areas that need improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the utilitybased approach used in FIITED for determining chunk significance, suggesting that basing eviction decisions solely on utility scores might introduce biases. It provides an example of how recent chunks might gain a temporary high utility, leading to premature evictions of other valuable chunks. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve their approach. The action is implicit and somewhat vague, as the authors are left to infer that they should consider alternative methods or additional criteria for eviction decisions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"FIITED,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by discussing the utilitybased approach to determining chunk significance and the potential biases introduced by basing eviction decisions solely on utility scores. The comment provides a specific example of how recent chunks might gain a temporary high utility, leading to premature evictions of other valuable chunks. This level of detail helps the authors understand what needs to be addressed in their draft. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that basing eviction decisions purely on utility scores might introduce biases, specifically mentioning the potential for premature evictions of valuable chunks due to recent chunks gaining a temporary high utility. This claim is 3 as it provides a logical reasoning for the potential bias, but it lacks specific examples or references to support the assertion fully. The authors would need to consider this possibility and address it in their work, but the comment could be strengthened with more detailed evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the utilitybased approach used in FIITED for determining chunk significance. It highlights a concern that basing eviction decisions solely on utility scores might introduce biases, such as premature evictions of valuable chunks due to temporary high utility scores of recent chunks. This feedback is 3 as it points out a specific area for improvement in the methodology, prompting the authors to consider alternative approaches or additional criteria for eviction decisions. However, the comment could be more helpful if it provided suggestions or examples of how to address this issue or offered a more detailed analysis of the potential biases. Overall, the comment is 3, as it directs the authors\" attention to a critical aspect of their work but lacks depth and actionable guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the first paragraph of the Introduction is not relevant to the paper\"s focus on detecting drift types and magnitude, as it is entirely devoted to a general introduction of DNNs. The reviewer implies that this section provides little value to readers and should be revised or removed. While the comment identifies a potential issue with the introduction, it does not provide explicit guidance on how to address it, such as suggesting specific changes or improvements. The action is implicit and somewhat vague, as the authors are left to infer that they should revise or remove the section, but without concrete instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first paragraph of the Introduction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the paragraph, namely that it is entirely devoted to a general introduction of DNNs without mentioning drift, which is the core focus of the paper. This provides clear guidance on what needs to be addressed or revised in the introduction. Therefore, the comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point claims that the first paragraph of the Introduction is not relevant to the paper\"s focus on detecting drift types and magnitude, as it is entirely devoted to a general introduction of DNNs. The reviewer suggests that this section provides little value to readers. However, the comment lacks specific examples or detailed reasoning to support why the introduction is not relevant or how it could be improved. Without additional context or evidence, the claim remains somewhat vague, making it difficult for the authors to understand and address the issue effectively. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the first paragraph of the Introduction, noting that it is entirely devoted to a general introduction of DNNs without mentioning drift, which is the core focus of the paper. This feedback is clear and actionable, as it highlights a potential disconnect between the introduction and the paper\"s main topic. By pointing out this issue, the comment provides the authors with a clear direction for revising the introduction to better align with the paper\"s focus. However, the comment could be more helpful if it suggested specific ways to integrate driftrelated content into the introduction or provided examples of how to structure the introduction more effectively. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of clarity regarding the performance of different parts of the framework and their contribution to the final result. It suggests that the authors should include quantitative experiments and comparisons between different algorithms, as well as more detailed explanations of the presented algorithms. While the comment implies that these actions should be taken, it does not explicitly instruct the authors to do so. The feedback is 3 as it provides a clear direction for improvement, but it lacks concrete guidance on how to implement the suggested changes. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment addresses the lack of clarity regarding the performance of different parts of the framework and their contribution to the final result. It mentions the experimental aspect and the result section, providing some grounding by referencing specific sections of the paper. However, it does not specify which parts of the framework are unclear or which algorithms need more detailed explanations, making it weakly grounded. The comment is specific in suggesting the need for quantitative experiments and comparisons between algorithms, as well as more detailed explanations. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the performance of different parts of the framework and their contribution to the final result are unclear. It suggests that the lack of quantitative experiments and comparisons between algorithms, as well as detailed explanations, makes it difficult to assess the framework\"s performance. The comment provides a logical reasoning by pointing out the absence of specific details in the results section, which would help clarify the framework\"s performance. However, it does not provide specific examples or references to support the claim, making it 3. The authors would need to address the gaps in the results section to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper regarding the clarity of the framework\"s performance and contribution of its different parts. It highlights the need for more detailed explanations and quantitative experiments to compare the framework with other solutions. This feedback is clear and actionable, as it provides a specific direction for improvement by suggesting the inclusion of quantitative experiments and comparisons. However, the comment could be more helpful if it offered examples of how these experiments or comparisons might be conducted or suggested specific metrics to consider. Overall, the comment is 4 as it directs the authors to enhance the clarity and comprehensiveness of their results, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to compare their results on the official COOC leader board on the blind test set, referencing a specific URL and mentioning previous winners and other approaches that have improved since the paper was published. This provides clear and concrete guidance on what the authors need to do to improve their draft. The comment is explicit and detailed, leaving no ambiguity about the action required. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"captioning experiment\" and the \"official COOC leader board on the blind test set,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the comparison of results on the official test set and the inclusion of recent approaches that have improved since the paper was published. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper should compare its results on the official COOC leader board on the blind test set, referencing specific examples of previous winners and other approaches that have improved since the paper was published. The reviewer provides a link to the official leaderboard, which supports the claim by offering a clear reference for the authors to compare their results. This level of detail and specific references make the claim 5, as it provides a clear path for the authors to address the feedback. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by pointing out that the paper should compare its results on the official COOC leader board on the blind test set, rather than on a not official test set or dev set. It references previous winners and other approaches that have improved since the paper was published, suggesting that the authors should at least compare to the ones where a corresponding publication is available. This feedback is clear and detailed, offering a concrete direction for the authors to improve their draft by ensuring a fair and accurate comparison of their results. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly questions the meaning of \"wrong\" at line 248 and suggests clarifying the concepts of good, bad, and wrong explanations before using them. This provides a clear and direct action for the authors to take, which is to clarify the terminology used in the paper. The comment is explicit and provides concrete guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions line 248, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the meaning of \"wrong\" and suggests clarifying the concepts of good, bad, and wrong explanations before using them. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the meaning of \"wrong\" at line 248 and suggests clarifying the concepts of good, bad, and wrong explanations. However, it does not provide any specific reasoning or examples to support why this clarification is necessary or how it would improve the paper. The comment lacks detailed justification or references, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific point in the paper where the term \"wrong\" is used without clarification, suggesting that the authors should define what is meant by a good, bad, or wrong explanation. This feedback is clear and actionable, as it directs the authors to clarify the terminology used in their paper, which can help readers better understand the concepts discussed. However, the comment could be more helpful if it provided additional context or examples of how this clarification might impact the paper\"s content or reader understanding. Overall, the comment is 4 as it guides the authors toward improving the clarity and precision of their work."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a lack of experimental demonstration of the contribution points, specifically noting the absence of a comparison between the image classification result of Mid Vision Feedback (MVF) and the baseline without MVF. The comment implies that the authors should include this comparison to prove the superiority of their method over MVF. While the action is implicit, it is clear and concrete, as the authors know exactly what needs to be done to address the issue: include a comparison with MVF. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of experimental demonstration of the contribution points, specifically referencing the absence of a comparison between the image classification result of Mid Vision Feedback (MVF) and the baseline without MVF. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what is missing in the experimental section, namely the comparison with MVF. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks sufficient experimental demonstration of its contribution points. It specifically notes the absence of a comparison between the image classification result of Mid Vision Feedback (MVF) and the baseline without MVF, which is necessary to prove the superiority of the schema searched by the authors\" method over MVF. This claim is 3 as it provides a clear rationale for the need for additional comparisons to substantiate the claims. However, the comment could be strengthened by providing specific examples or references to similar experiments that would support the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental demonstration of the contribution points in the paper. It highlights the lack of a comparison between the image classification result of Mid Vision Feedback (MVF) and the baseline without MVF, which is crucial for proving the superiority of the schema searched by the authors\" method over MVF. This feedback is clear and actionable, as it provides a specific area for improvement that the authors can address to strengthen their experimental results. By suggesting the inclusion of this comparison, the comment offers a concrete step toward enhancing the paper\"s credibility and impact. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the originality of the article, noting similarities to another work. It questions whether the current work is merely an extension of the previous study or if it introduces novel contributions. However, it does not provide explicit guidance or suggestions on how the authors should address these concerns or differentiate their work from the previous study. The action is implicit and vague, as the authors are left to infer that they need to clarify the originality of their work but are not given specific steps to take. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises concerns about the originality of the article, noting similarities to another work. However, it does not specify which parts of the article are similar or how they relate to the previous study. This lack of specificity makes it difficult for the authors to identify the exact areas that need attention or improvement. Additionally, the comment does not provide explicit references to the previous study, making it challenging for the authors to pinpoint the specific similarities. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point raises a concern about the originality of the article, noting similarities to another work. However, it does not provide specific details or examples of these similarities, making it difficult for the authors to understand the exact nature of the overlap. The comment lacks supporting evidence or references to the other work, which would help the authors address the concern. Without this information, the claim remains vague and 1, as the authors are left without a clear path to improve their work. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a concern about the originality of the article, noting similarities to another work. It questions whether the current work is merely an extension of the previous study or if it introduces novel contributions. This feedback is relevant and important, as it prompts the authors to clarify the originality and novelty of their work. However, the comment lacks specific guidance or suggestions on how the authors might address this concern or differentiate their work from the previous study. While it identifies an area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the necessity of learning longrange dependencies for powerful predictors, specifically in the context of semantic segmentation. It notes that while the visualizations in Table 3 suggest this is happening, the comment lacks a discussion on whether it is fully required. The reviewer also speculates that the truth might lie somewhere in between and suggests that the authors should discuss this. However, the comment does not provide explicit guidance on how to address this issue or what specific aspects should be discussed. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide a more detailed discussion on the necessity of longrange dependencies. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the necessity of learning longrange dependencies for powerful predictors, particularly in the context of semantic segmentation. The comment suggests that the truth might lie somewhere in between and highlights the need for a discussion on this topic. Additionally, it raises a concern about the impact of locality in the graph structure on prediction, suggesting that the authors should address this aspect. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a claim about the necessity of learning longrange dependencies for powerful predictors, specifically in the context of semantic segmentation. The reviewer provides a specific example from Table 3, which suggests that longrange dependencies are indeed being learned. However, the comment lacks detailed reasoning or evidence to support the claim that the truth might lie somewhere in between, or that locality in the graph structure affects prediction. The suggestion to discuss this further is based on logical reasoning but requires more explicit justification. Therefore, the comment is 3, as it provides a starting point for discussion but lacks comprehensive evidence or detailed reasoning.", "helpfulness_rationale": "The review comment raises an important point about the necessity of learning longrange dependencies for powerful predictors, particularly in the context of semantic segmentation. It provides a specific example from Table 3, which suggests that longrange dependencies are indeed being learned, but questions whether this is fully required. The comment also highlights the need for a discussion on this topic, suggesting that the truth might lie somewhere in between. Additionally, it raises a concern about the impact of locality in the graph structure on prediction, which could be an interesting area for further exploration. While the comment identifies a potential gap in the discussion and provides some direction for improvement, it could be more helpful by offering specific suggestions on how to address these issues. Overall, the feedback is 3 as it prompts the authors to consider an important aspect of their work but lacks detailed guidance on how to enhance their discussion."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises questions about the notation in Eq. (3) and points out the exponential dependence of corollaries and theorems on the domain data\"s diameter, $M$. It also mentions that the performance is worse than standard random features, suggesting a potential weakness in the proposed approaches. However, the comment does not provide explicit guidance on how the authors should address these issues or improve their draft. The questions and observations are implicit, and the action is vague, as the authors are left to infer what changes might be necessary without concrete suggestions. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific equations (Eq. (3)) and results (Corollaries 1, 2, and 3, Theorem 4), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the exponential dependence on the domain data\"s diameter, $M$, and the impact on the required feature size. Additionally, it discusses the performance compared to standard random features, suggesting a potential weakness in the proposed approaches. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the notation in Eq. (3) and points out the exponential dependence of corollaries and theorems on the domain data\"s diameter, $M$. It also mentions that the performance is worse than standard random features, suggesting a potential weakness in the proposed approaches. However, the comment lacks specific examples, references, or detailed reasoning to fully substantiate the claim about the exponential dependence and its impact on performance. The mention of Figure 1 is vague, as it does not provide a clear link to the figure or its relevance to the claim. Therefore, the comment is 3, as it provides some justification but lacks detailed evidence or references to fully support the claim.", "helpfulness_rationale": "The review comment raises several points that could be helpful for the authors to consider. It questions the notation in Eq. (3), which could help clarify the notation used in the paper. Additionally, it points out the exponential dependence of corollaries and theorems on the domain data\"s diameter, $M$, and its impact on the required feature size. This observation could prompt the authors to reconsider the implications of this dependence and its potential impact on the performance of their proposed approaches. The comment also mentions that the performance is worse than standard random features, suggesting a potential weakness in the proposed approaches. However, the comment lacks specific suggestions or detailed guidance on how the authors might address these issues or improve their draft. While it identifies areas for improvement, it does not provide comprehensive or actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the longrange modelling ability of DGNs, attributing it to oversquashing and vanishing/exploding gradients. It also suggests that oversmoothing could be another factor contributing to poor performance. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their draft. The mention of a specific paper provides some context but does not offer actionable steps for the authors. As a result, the comment is vague and lacks concrete details on how to implement any changes, making it barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of \"poor longrange modelling ability\" of DGNs, which allows the authors to identify the specific part of the paper being addressed. It also provides a specific reason for this issue, namely oversquashing and vanishing/exploding gradients, and suggests that oversmoothing could be another factor. The reference to a specific paper, \"Deeper Insights into Graph Convolutional Networks for SemiSupervised Learning, In AAAI\"18,\" further grounds the comment and provides a basis for the claim. However, the comment does not specify what the authors should do to address these issues or improve their draft, making it specific but not fully grounded. Therefore, this comment aligns with a score of 4.", "verifiability_rationale": "The review point claims that the poor longrange modelling ability of DGNs could be due to oversmoothing, a phenomenon observed in the context of very deep graph networks. The reviewer supports this claim by referencing a specific paper, \"Deeper Insights into Graph Convolutional Networks for SemiSupervised Learning, In AAAI\"18,\" which provides a basis for the assertion. This reference adds credibility to the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced paper to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the longrange modelling ability of DGNs, attributing it to oversquashing and vanishing/exploding gradients. It also suggests that oversmoothing could be another factor contributing to poor performance, referencing a specific paper for context. This feedback is 3 as it highlights a specific area of concern and provides a reference for further exploration. However, the comment lacks actionable suggestions or detailed guidance on how the authors might address these issues or improve their draft. To be more helpful, the comment could include specific recommendations or examples of how to mitigate the effects of oversquashing, vanishing/exploding gradients, or oversmoothing. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the problem formulation is unclear in the statement and introduction examples. However, it does not provide any explicit or implicit guidance on how to clarify the problem formulation or what specific aspects are unclear. Without additional details or suggestions, the authors are left without a clear understanding of what changes are needed to improve the clarity of the problem formulation. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment indicates that the problem formulation is unclear in the statement and introduction examples. However, it does not specify which parts of the statement or introduction are unclear, nor does it provide details on what aspects need clarification. This lack of specificity and lack of explicit references to sections or examples make it difficult for the authors to pinpoint the exact areas that need improvement. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the problem formulation is unclear in the statement and introduction examples. However, it does not provide any specific examples or detailed reasoning to support this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a potential issue with the clarity of the problem formulation in the statement and introduction examples. However, it lacks specificity and does not provide any guidance or suggestions on how to improve the clarity. Without actionable feedback or examples of what needs to be clarified, the authors are left without a clear understanding of what changes are needed to address the issue. This makes the comment 2, as it points out a problem but does not offer a path for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about why the authors did not consider finer grouping for quantization instead of pertensor and perchannel. However, it does not provide any explicit or implicit suggestions for how the authors might address this question or what specific actions they should take to improve their draft. The comment lacks actionable guidance, leaving the authors without a clear understanding of how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the choice of quantization grouping, specifically asking why finer grouping was not considered instead of pertensor and perchannel. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment where quantization is discussed. Without explicit references to the paper, the authors may find it challenging to determine the exact context of the comment. The comment is specific in its question about the choice of quantization grouping but lacks grounding, as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point is a question asking why the authors did not consider finer grouping for quantization instead of pertensor and perchannel. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the choice of quantization grouping, specifically asking why finer grouping was not considered instead of pertensor and perchannel. While it identifies a potential area for improvement, it lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or why finer grouping might be beneficial. The comment does not offer actionable feedback or insights that would help the authors improve their draft. Therefore, it is 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the meaning of \"For training we used an epsilongreedy ...\" and asks whether it refers to an epsilongreedy exploration on top of the proposed strategy. This comment is explicit in its request for clarification, as it directly asks for an explanation of the term \"epsilongreedy\" and its relationship to the proposed strategy. The authors are given a clear action to take, which is to provide a detailed explanation of the term and its role in the context of the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section \"Appendix D.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the meaning of \"For training we used an epsilongreedy ...\" and asks whether it refers to an epsilongreedy exploration on top of the proposed strategy. This provides clear guidance on what needs to be clarified or explained in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the meaning of \"For training we used an epsilongreedy ...\" and whether it refers to an epsilongreedy exploration on top of the proposed strategy. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the meaning of \"For training we used an epsilongreedy ...\" and whether it refers to an epsilongreedy exploration on top of the proposed strategy. This feedback is 3 as it prompts the authors to clarify a potentially ambiguous statement in their paper. However, it does not provide specific guidance on how to address the issue or suggest improvements to enhance the clarity of the paper. While it points out a potential area for improvement, the comment lacks depth and actionable advice, making it 3 but not comprehensive. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that dynamic precision control during training might only show meaningful performance gains on bitserial accelerators, while most existing ML accelerators use bitparallel fixedpoint numbers. This implies that the proposed methodology might be limited in its applicability. However, the comment does not provide explicit guidance or suggestions on how the authors might address this limitation or explore alternative applications. The action is implicit and vague, as it lacks concrete steps for the authors to take. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the potential limitations of the proposed methodology regarding dynamic precision control during training, specifically mentioning its applicability to bitserial accelerators. However, it does not specify which part of the paper discusses this aspect, making it weakly grounded. The comment is specific in detailing the potential restriction due to the use of bitparallel fixedpoint numbers in most existing ML accelerators. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that dynamic precision control during training might only show meaningful performance gains on bitserial accelerators, while most existing ML accelerators use bitparallel fixedpoint numbers. This claim is based on a logical inference about the applicability of the proposed methodology, but it lacks specific examples or references to support the assertion. The comment provides a reasonable basis for the claim, but the lack of detailed evidence or references makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation of the proposed methodology, specifically noting that dynamic precision control during training might only show meaningful performance gains on bitserial accelerators. It also points out that most existing ML accelerators use bitparallel fixedpoint numbers, which could restrict the implications of the proposed methodology. While the comment highlights an important consideration, it lacks specific suggestions or guidance on how the authors might address this limitation or explore alternative applications. The feedback is 3 as it prompts the authors to consider the broader applicability of their work, but it could be more actionable with additional insights or recommendations. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point raises a concern about the clarity of Eq. 12, questioning where the reward comes from at each trial and whether it is derived from Eq. 11. It also suggests that explaining the network model in Section 4.2 with equations would improve clarity. The comment provides specific questions and a suggestion for improvement, which are explicit and concrete. The authors know exactly what needs to be clarified and how to address it by providing equations for the network model. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq. 12\" and \"Sec. 4.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with Eq. 12, questioning the source of the reward and suggesting that explaining the network model with equations would improve clarity. The comment also provides references to external works that could help clarify the network model. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of Eq. 12, questioning the source of the reward and suggesting that explaining the network model in Sec. 4.2 with equations would improve clarity. The comment provides references to external works, which could help the authors understand the context and improve their explanation. However, the references are not directly integrated into the claim, making it 3. The authors would need to explore the referenced works to fully understand the basis of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of Eq. 12, questioning the source of the reward and suggesting that it might be derived from Eq. 11. It also provides a suggestion to improve clarity by explaining the network model in Section 4.2 with equations. This feedback is clear and actionable, as it directs the authors to clarify a critical aspect of their work and provides a specific way to enhance the paper\"s clarity. The inclusion of references to external works further supports the suggestion, making the comment 5 for the authors in improving their draft. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point critiques the novelty of the idea and suggests that both the new metric and method are relatively straightforward. However, it does not provide any explicit or implicit actions for the authors to take to address this critique. There is no guidance on how to enhance the novelty or improve the clarity of the new metric and method. Without actionable suggestions or specific feedback, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the novelty of the idea and mentions the limitations of both the new metric and method, but it does not specify which part of the paper these aspects are discussed in. This makes it difficult for the authors to pinpoint the exact sections that need attention. Additionally, while it highlights the limitations, it does not provide specific guidance on how to address them or improve the novelty. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the novelty of the idea is insufficient, citing the limitations of both the new metric and method as relatively straightforward. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment critiques the novelty of the idea, suggesting that both the new metric and method are relatively straightforward. However, it does not provide specific examples or detailed feedback on how to enhance the novelty or improve the clarity of the new metric and method. Without actionable suggestions or guidance, the authors are left without a clear understanding of what changes or improvements are needed to address the critique. This lack of specificity and actionable feedback makes the comment 2, as it identifies a potential issue but does not offer meaningful guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the model description could be improved by presenting the generative process in separate steps and by including a notation table. While the comment implies that these changes would enhance understanding, it does not provide explicit instructions on how to implement them or what specific steps should be taken. The authors can infer that they need to restructure the model description and consider adding a notation table, but the comment lacks concrete guidance on how to achieve these improvements. Therefore, the comment is 3, as it identifies an area for improvement but does not provide detailed instructions on how to execute it.", "grounding_specificity_rationale": "The comment suggests improvements to the model description, specifically mentioning the need for a better presentation of the generative process in separate steps and the inclusion of a notation table. However, it does not specify which part of the paper this feedback pertains to, such as a particular section or figure where the model description is presented. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing revision. While the comment is specific in suggesting improvements, it is 1 because it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the model description could be improved by presenting the generative process in separate steps and by including a notation table. However, the comment does not provide specific examples or detailed reasoning to support why these changes would enhance understanding. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is 3, as it lacks sufficient detail to fully substantiate the need for these changes.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the model description, suggesting that the generative process could be better understood if presented in separate steps. It also mentions the need for a notation table to enhance clarity. While the comment highlights important aspects for improvement, it lacks detailed guidance or examples on how to implement these suggestions. The feedback is 3 as it points out areas for enhancement, but it could be more actionable with additional details or specific recommendations. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper should better motivate the \"Why\" aspect, explaining why the presented topic is important or relevant. However, it does not provide specific guidance on how to achieve this motivation or what aspects should be highlighted. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide a stronger rationale for their work but without concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the paper should better motivate the \"Why\" aspect, explaining why the presented topic is important or relevant. However, it does not specify which part of the paper lacks this motivation or where it should be added. The authors might infer that it relates to the introduction or the motivation section, but this inference is not explicit. The comment is specific in its suggestion to provide a stronger rationale but lacks grounding, as it does not pinpoint a specific section or element of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should better motivate the \"Why\" aspect, explaining why the presented topic is important or relevant. However, the comment does not provide any specific reasoning, examples, or references to support why this motivation is lacking or how it could be improved. Without additional context or justification, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, noting that it lacks a clear motivation for the \"Why\" aspect of the presented topic. This feedback is 3 as it points out an area where the authors could improve their draft by providing a stronger rationale for their work. However, the comment does not offer specific suggestions or guidance on how to address this issue, such as what aspects of the \"Why\" should be emphasized or how to effectively motivate the topic. While it provides some direction, the lack of detailed advice limits its helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that the proposed approach does not outperform or is even worse than Decouple [Kang et al.] for overall performance. It also notes that Table 5 shows a tradeoff between head and tail categories, but this tradeoff has not been fully investigated for the baselines. The reviewer suggests that by changing the hyperparameters in Decouple [Kang et al.], it could also significantly improve the tail accuracy while slightly decreasing the head accuracy. This feedback provides a clear and explicit action for the authors to take, which is to investigate the tradeoff for the baselines and potentially improve their performance. The comment is 5 as it offers a specific direction for the authors to enhance their work.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the proposed approach does not outperform or is even worse than Decouple [Kang et al.] for overall performance and that the tradeoff between head and tail categories has not been fully investigated for the baselines. The comment suggests that by changing the hyperparameters in Decouple [Kang et al.], it could also significantly improve the tail accuracy while slightly decreasing the head accuracy. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed approach does not outperform or is even worse than Decouple [Kang et al.] for overall performance. It also notes that Table 5 shows a tradeoff between head and tail categories, but this tradeoff has not been fully investigated for the baselines. The reviewer suggests that by changing the hyperparameters in Decouple [Kang et al.], it could also significantly improve the tail accuracy while slightly decreasing the head accuracy. This claim is 3 as it provides a logical reasoning based on the data presented in the paper, but it lacks specific examples or references to support the claim fully. The authors would need to explore the suggested changes to verify the claim themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a detailed critique of the paper, highlighting that the proposed approach does not outperform or is even worse than Decouple [Kang et al.] for overall performance. It also points out that the tradeoff between head and tail categories has not been fully investigated for the baselines, suggesting that by changing the hyperparameters in Decouple [Kang et al.], it could also significantly improve the tail accuracy while slightly decreasing the head accuracy. This feedback is actionable as it identifies specific areas for improvement and provides a clear direction for the authors to enhance their work. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of potential changes to the hyperparameters. Overall, the comment is 4, as it guides the authors toward improving their draft but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the evaluation of weak supervision could be improved by questioning the realism of the evaluated tweets. It points out that the prompt requires all structured elements for perspectives to be present in the generated tweets, which may not be the most realistic. Additionally, it critiques the generation of authors, noting that the use of \"[author] embeddings\" is not realistic. While the comment identifies specific areas for improvement, it does not provide explicit guidance on how to address these issues or what specific changes should be made. The action is implicit and somewhat vague, as the authors can infer that they need to improve the realism of the evaluation and the generation process, but they are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"weak supervision\" and \"evaluated tweets,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the realism of the evaluated tweets and the prompt, as well as critiquing the generation of authors. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that weak supervision could be better evaluated, specifically questioning the realism of the evaluated tweets and the prompt. It provides a detailed critique of the prompt, noting that it requires all structured elements for perspectives to be present in the generated tweets, which may not be the most realistic. Additionally, it critiques the generation of authors, stating that the use of \"[author] embeddings\" is not realistic. While the comment provides specific examples and reasoning, it could be strengthened by referencing similar studies or practices that support the claim. Overall, the comment is 4, as it provides a clear and logical critique but lacks comprehensive references or examples to fully substantiate the claim. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the evaluation of weak supervision. It questions the realism of the evaluated tweets, pointing out that the prompt requires all structured elements for perspectives to be present, which may not be the most realistic. Additionally, it critiques the generation of authors, noting that the use of \"[author] embeddings\" is not realistic. This feedback is clear and constructive, as it identifies specific areas where the evaluation could be improved, offering the authors a clear path to enhance the realism and validity of their approach. However, the comment could be more helpful if it suggested alternative methods or approaches for evaluating weak supervision. Overall, the comment is 4, as it provides valuable insights for improving the draft but could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should compare their proposed model with existing models that use answers as inputs, such as the Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). This is an explicit request for the authors to conduct a specific comparison, which is clear and actionable. The comment provides a concrete suggestion by specifying the model to be compared against, making it easy for the authors to understand and implement the action. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests a comparison with existing models that use answers as inputs, specifically mentioning \"Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16).\" This provides clear guidance on what the authors should do to improve their draft, making the comment specific. However, it does not explicitly mention which part of the paper this suggestion pertains to, such as a specific section or experiment. While the authors can infer that it relates to the performance evaluation or comparison sections, the lack of explicit grounding makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the ternary potential is the main factor in the performance improvement of the proposed model and recommends comparing it with existing models that use answers as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). The claim about the ternary potential is supported by the suggestion to compare with existing models, which provides a logical basis for the claim. However, the comment could be strengthened by providing more detailed reasoning or examples of how the ternary potential contributes to performance improvement. Overall, the claim is 4, as it provides a reasonable basis for the suggestion but lacks comprehensive evidence or detailed explanation. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment suggests a specific comparison with existing models that use answers as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their work by comparing their proposed model with a relevant benchmark. By suggesting this comparison, the reviewer offers a valuable opportunity for the authors to validate and improve the performance of their model. However, the comment could be more helpful if it included a rationale for why this comparison is important or how it might impact the understanding of the proposed model. Overall, the comment is 4 as it provides a clear and actionable suggestion for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the design choice of trimming questions after the first 10, especially since the question model is a bag of words, which is not expensive to encode longer sequences. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their design. The comment lacks actionable guidance, leaving the authors without a clear understanding of what steps to take to enhance their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L254,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the design choice of trimming questions after the first 10 and provides a rationale for this critique, noting that the question model is a bag of words and should not be expensive to encode longer sequences. This provides clear guidance on what aspect of the design needs to be reconsidered. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the design choice of trimming questions after the first 10, suggesting that it is an odd choice given that the question model is a bag of words, which is not expensive to encode longer sequences. The comment provides a logical reasoning for why this choice might be questionable, but it lacks specific examples or references to support the claim. While the reasoning is sound, the lack of detailed evidence or references makes the claim 3, as the authors might need additional context to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the design choice of trimming questions after the first 10, suggesting that it is an odd choice given that the question model is a bag of words, which is not expensive to encode longer sequences. This feedback highlights a potential inconsistency in the design and provides a logical rationale for reconsidering the choice. However, the comment does not offer specific suggestions or alternatives for improving the design, nor does it provide detailed guidance on how the authors might address this issue. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point provides explicit instructions for changes, specifying that two lines in red should be in green in the Supplementary Material. It also provides specific line numbers and references to equations, tables, and algorithms that need to be updated. This feedback is clear and actionable, as it directly tells the authors what changes need to be made and where. The authors know exactly what to do to address the issue, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the Supplementary Material that need to be updated, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be changed, namely the colors of certain lines and references to equations, tables, and algorithms. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements and does not contain any subjective claims, opinions, or suggestions that require verification. It is purely descriptive, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by identifying two lines in the Supplementary Material that should be in green instead of red. It also specifies the line numbers and references to equations, tables, and algorithms that need to be updated. This level of detail is highly beneficial for the authors, as it directly guides them on what changes to make to improve the clarity and accuracy of their draft. The comment is clear and actionable, making it 5 for the authors to address the identified issues. Therefore, it aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to include a comprehensive comparison with the GFF[1] and EfficientFCN[2] works, both of which aim to implement the fast semantic segmentation method in the encodedecoder architecture. This feedback provides a clear and direct action for the authors to take, ensuring that they understand what needs to be done to improve their draft. The comment also includes specific references to the works that should be included in the comparison, providing concrete guidance on how to implement the action. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"societal impact\" shown on the last page of the manuscript, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the missing references, specifically mentioning the GFF[1] and EfficientFCN[2] works, and encourages a comprehensive comparison with these works. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that important references are missing and suggests a comprehensive comparison with the GFF[1] and EfficientFCN[2] works. The reviewer provides specific references to these works, which helps to verify the claim. However, the comment could be strengthened by explaining why these references are important or how they relate to the paper\"s contributions. Despite this, the inclusion of references provides a solid basis for the claim, making it 4. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of important references, specifically mentioning the GFF[1] and EfficientFCN[2] works. It provides specific guidance by suggesting a comprehensive comparison with these works, which would enhance the paper\"s contribution. This feedback is clear and actionable, offering the authors a concrete step to improve their draft by incorporating relevant references and comparisons. However, the comment could be more helpful if it explained why these references are important or how they relate to the paper\"s findings. Overall, the comment is 4 as it provides valuable direction for enhancing the paper, aligning with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the scalability of the proposed NC measure, which takes the entire training and test datasets as input. It questions whether this method can be applied to largescale datasets like ImageNet and suggests that the practical contribution of the paper could be reduced without a solution to address the scalability issue. While the comment implies that the authors should address the scalability concern, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to find a solution to the scalability issue but are not given specific steps or methods to consider. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the scalability of the proposed NC measure, specifically questioning its applicability to largescale datasets like ImageNet. However, it does not specify which part of the paper discusses the NC measure or where the scalability issue is addressed. This makes it weakly grounded, as the authors cannot confidently determine the exact section being addressed. The comment is specific in its critique of the scalability issue and suggests a potential solution, but without explicit references to the paper, it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the scalability of the proposed NC measure, specifically questioning its applicability to largescale datasets like ImageNet. The reviewer suggests that the practical contribution of the paper could be reduced without a solution to address the scalability issue. However, the comment lacks specific examples or detailed reasoning to support the claim that the method is not scalable. While the reviewer highlights a potential issue, the lack of evidence or detailed explanation makes it difficult for the authors to fully understand and address the concern. Therefore, the comment is considered 2, as it provides a basis for the claim but requires more detailed justification.", "helpfulness_rationale": "The review comment raises a significant concern about the scalability of the proposed NC measure, which takes the entire training and test datasets as input. It questions the applicability of this method to largescale datasets like ImageNet and suggests that the practical contribution of the paper could be reduced without a solution to address the scalability issue. This feedback is clear and actionable, as it prompts the authors to consider ways to scale their method to larger datasets, potentially through data sampling or other techniques. However, the comment could be more helpful if it provided specific suggestions or examples of how to address the scalability issue. Overall, the comment is 4 as it identifies a critical area for improvement and encourages the authors to enhance the practicality of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a potential issue with the proposed PSA method, noting that it requires more computation than baselines. It specifically mentions that in Algorithm 1, when feeding forward, the PSA requires the calculation of all the flipped previous layer outputs into the current layer. The reviewer suggests that the comparison of computation complexity should be included in the experiment part. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to conduct the comparison or what specific metrics to use. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the computation complexity of the proposed PSA method and the need for a comparison in the experiment part. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed PSA method requires more computation than baselines. It provides a specific explanation of how the PSA method calculates all the flipped previous layer outputs into the current layer, which supports the claim. However, the comment lacks references or detailed comparisons with other methods to fully substantiate the claim. While the reasoning is clear, the absence of additional evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed PSA method, noting that it requires more computation than baselines. It provides a detailed explanation of how the PSA method calculates all the flipped previous layer outputs into the current layer, which is a critical aspect of the algorithm. The comment suggests that a comparison of computation complexity should be included in the experiment part, which is a clear and actionable piece of feedback. By highlighting this computational complexity issue and recommending a specific area for improvement, the comment is 5 as it provides the authors with a clear direction for enhancing their draft. Therefore, it aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment provides specific suggestions for improving the figures, such as increasing the font size for certain elements and making the font in Figure 2 larger. It also suggests adding details for comparison with other stateoftheart Transformer designs, such as epochs and number of parameters, and proposes a \"table\" manner to emphasize the data. These suggestions are explicit and provide concrete guidance on how to enhance the figures and improve the comparison with other designs. The authors know exactly what changes to make to address the feedback, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific figures (Figures 1 and 2) and provides detailed suggestions for improvements, such as increasing font sizes and adding details for comparison. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it provides clear guidance on what needs to be addressed, such as enlarging fonts, adding explanations, and including details for comparison. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a series of suggestions for improving the figures, such as increasing font sizes and adding details for comparison. These are factual statements that do not require verification or justification. The comment does not contain any subjective claims, opinions, or suggestions that would necessitate verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the figures, suggesting improvements such as increasing font sizes, adding explanations, and making certain elements more legible. It also highlights the need for more detailed comparisons with other stateoftheart Transformer designs, suggesting a \"table\" manner to emphasize the data. This feedback is clear and offers concrete steps for the authors to enhance the clarity and comprehensibility of their figures and comparisons, making it 5. Therefore, the comment is rated as 5, consistent with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the proposed method should be compared to \"ATA\" in addition to \"+LFP\" in Table 2, under the leaveoneout setting. This is an explicit action, as it clearly instructs the authors to include an additional comparison in their analysis. However, the comment does not provide specific guidance on how to implement this comparison or what specific aspects of \"ATA\" should be considered. While the action is explicit, the lack of detailed instructions makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2\" and \"leave one out setting,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of comparison between the proposed method and \"ATA\" in Table 2. The comment suggests that including \"ATA\" in the comparison would make the results more convincing. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the proposed method should be compared to \"ATA\" in addition to \"+LFP\" in Table 2, under the leaveoneout setting. The reviewer provides a logical reasoning by stating that \"ATA\" is a bit better than \"FP\" according to the results in Table 1, implying that including \"ATA\" in the comparison would make the results more convincing. However, the comment lacks specific references or detailed explanations of why \"ATA\" is better than \"FP,\" which would strengthen the justification. Therefore, the claim is 3, as it provides a logical basis but lacks detailed evidence or references to fully substantiate the suggestion.", "helpfulness_rationale": "The review comment identifies a specific issue with the comparison in Table 2, noting that the proposed method is only compared to \"+LFP\" under the leaveoneout setting. It suggests that including \"ATA\" in the comparison would make the results more convincing, given that \"ATA\" is a bit better than \"FP\" according to the results in Table 1. This feedback is clear and actionable, as it provides a specific suggestion for improving the analysis and presentation of results. However, the comment could be more helpful if it explained why including \"ATA\" would be beneficial or how it would impact the overall interpretation of the results. Overall, the comment is 4 as it directs the authors to a meaningful enhancement of their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly points out a lack of mathematical definition for architectural details, such as multihead attention, and questions the split arrow in Figure 2. It suggests that the authors provide a formal definition to help readers understand the model better. The comment is explicit in its request for a mathematical definition and provides a specific example to clarify, making it 5. The authors know exactly what needs to be done to improve their draft by providing the requested formal definition.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2 right, bottom right,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely a formal definition of the architectural details, such as multihead attention, and questions about the split arrow in Figure 2. The comment provides a clear direction for improvement by suggesting that a formal definition would help readers understand the model better. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the lack of mathematical definition for architectural details, such as multihead attention, and seeks clarification about the split arrow in Figure 2. The reviewer provides a logical reasoning by suggesting that the split arrow might represent inputs for the attention layer, namely query, keys, and values. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened by including specific references or examples from the literature to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks mathematical definition, particularly in the architectural details of the model, such as multihead attention. It questions the split arrow in Figure 2 and suggests that it might represent inputs for the attention layer, namely query, keys, and values. The comment provides a clear and actionable suggestion by recommending that the authors provide a formal definition to help readers understand the model better. This feedback is valuable as it directs the authors to a critical area for improvement, offering a specific and constructive way to enhance the clarity and comprehensibility of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment states that the presentation of the paper is difficult to follow for the reviewer, but it does not provide any specific guidance or suggestions on how the authors might improve the clarity or structure of their paper. There is no explicit or implicit action for the authors to take, nor are there any concrete steps outlined to address the issue. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment indicates that the presentation of the paper is difficult to follow, but it does not specify which parts of the paper are problematic or what aspects make it challenging to follow. Without explicit references to sections, figures, or specific content, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specificity regarding what needs to be improved or clarified. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the presentation of the paper is difficult to follow, but it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed explanation or references to particular sections or aspects of the paper that are confusing, the comment lacks verifiability. The authors are left without a clear understanding of what needs to be improved or how to address the issue. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The comment indicates that the presentation of the paper is difficult to follow, but it does not provide any specific details or suggestions on how to improve the clarity or structure of the paper. Without actionable feedback or guidance, the authors are left without a clear understanding of what needs to be addressed or how to enhance the readability of their work. This lack of specificity and direction makes the comment unhelpful, as it does not offer any meaningful insights or suggestions for improvement. Therefore, it aligns with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include works such as Li et al. (2017) and He et al. (2015) in their discussion, as these works are relevant to the taskoriented recommendation perspective. It also recommends discussing how the current work differs from other chatbox research works. While the comment implies that the authors should include these references and discussions, it does not provide explicit instructions on how to integrate them into the paper. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take and may not be entirely sure of the exact changes needed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the perspective of taskoriented recommendation, allowing the authors to identify the relevant part of the paper. It also specifies what needs to be addressed, which is the inclusion of relevant works such as Li et al. (2017) and He et al. (2015), as well as a discussion on how the current work differs from other chatbox research works. This provides clear guidance on what the authors need to do to improve their draft. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that works such as Li et al. (2017) and He et al. (2015) are important to include in the discussion due to their relevance to the taskoriented recommendation perspective. The reviewer provides specific references to these works, which helps to substantiate the claim. However, the comment could be strengthened by explaining how these works are relevant or how they differ from the current work, which would make the claim more 5. Therefore, the comment is 4, as it provides a solid foundation for the claim but lacks detailed explanation or examples. This aligns with a score of 4.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to include relevant works, such as Li et al. (2017) and He et al. (2015), in their discussion. It also recommends discussing how the current work differs from other chatbox research works, which would help the authors contextualize their contribution within the broader field. This feedback is specific and provides a clear direction for the authors to enhance their paper by incorporating relevant literature and comparisons. However, the comment could be more helpful if it offered additional guidance on how to integrate these references or discuss the differences effectively. Overall, the comment is 4 as it provides valuable insights for improving the draft, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to clarify the difference between the meta solvers and the centralized RL where agents share weights. It provides a specific example from Foester et al. (2016) to guide the authors in making this distinction. This feedback is clear and provides a concrete action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"meta solvers\" and \"centralized RL,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by asking for clarification on the difference between meta solvers and centralized RL, where agents share weights. Additionally, it provides a specific reference to Foester et al. (2016) to guide the authors in making this distinction. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the meta solvers are centralized controllers and suggests that the authors clarify the difference between these solvers and centralized RL where agents share weights. The reviewer supports this claim by referencing a specific paper, \"Foester et al., Learning to communicate with deep multiagent reinforcement learning, NIPS 2016,\" which provides a relevant example. This external reference enhances the verifiability of the claim, as it offers a concrete example to guide the authors in making the distinction. Therefore, the comment is 4, as it provides a clear basis for the claim but could be further strengthened with more detailed reasoning or examples within the text.", "helpfulness_rationale": "The review comment identifies a potential confusion in the paper regarding the nature of the meta solvers, suggesting they might be centralized controllers. It provides a specific example from Foester et al. (2016) to clarify the distinction between meta solvers and centralized RL where agents share weights. This feedback is clear and actionable, offering the authors a concrete way to improve their draft by clarifying a critical aspect of their methodology. By providing a reference to a relevant work, the comment also guides the authors in understanding the context of their research. Therefore, the comment is 5, as it offers specific and constructive feedback that can significantly enhance the clarity and comprehensibility of the paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the phrase \"nonsequential information such as chunks,\" asking whether \"chunk\" is still considered sequential information. This question implies that the authors should clarify the meaning of \"chunk\" in the context of the paper. However, the comment does not provide explicit guidance on how to address this confusion or suggest specific changes to improve clarity. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the terminology but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 285,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the phrase \"nonsequential information such as chunks\" and asks whether \"chunk\" is still considered sequential information. This provides clear guidance on what needs to be clarified or corrected in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the phrase \"nonsequential information such as chunks.\" It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the phrase \"nonsequential information such as chunks,\" specifically asking whether \"chunk\" is still considered sequential information. This feedback is 3 as it points out a potential ambiguity in the paper that needs clarification. However, it does not provide specific guidance on how to address this issue or suggest ways to improve the clarity of the text. While it prompts the authors to reconsider their terminology, it lacks depth and actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point identifies a discrepancy between Equation 9 and Figure 1, suggesting that the output patches are not cropped parts of the input image but masked versions of the input image with most pixels being black. The reviewer questions the correctness of this interpretation and points out that Figure 1 might be misleading. Additionally, the reviewer suggests that using bilinear sampling to zoom on the region of interest could provide better results. This comment provides explicit actions for the authors to clarify the discrepancy and consider alternative methods, such as bilinear sampling, to improve their results. The feedback is clear and actionable, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"eq. 9\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out a discrepancy between the equation and the figure, questioning whether the output patches are cropped parts of the input image or masked versions. Additionally, the comment suggests an alternative method, bilinear sampling, to improve the results. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a discrepancy between Equation 9 and Figure 1, suggesting that the output patches are not cropped parts of the input image but masked versions of the input image where most pixels are black. The reviewer questions the correctness of this interpretation and points out that Figure 1 might be misleading. The comment provides a logical reasoning by comparing the equation and the figure, which is a clear and direct way to verify the claim. However, it could be strengthened by providing specific examples or references to support the claim further. Overall, the comment is 4, as it provides a solid basis for the claim but lacks detailed evidence or references. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a specific discrepancy between Equation 9 and Figure 1, questioning whether the output patches are cropped parts of the input image or masked versions of the input image with most pixels being black. This feedback is clear and actionable, as it prompts the authors to clarify the interpretation of their results and potentially revise Figure 1 to avoid misleading representations. Additionally, the comment suggests an alternative method, bilinear sampling, which could improve the results. This level of detail and guidance provides the authors with a clear path to enhance their draft, making the comment 5."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a perceived lack of technical novelty in the paper, comparing it to two previous works (Xing and Tsang, 2022a, b). It notes that while the previous papers focus on graphbased approaches, the idea, coattention mechanism, and architecture of the current paper are similar. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest ways to differentiate their work. The action is implicit and vague, as the authors are left to infer that they need to demonstrate a unique contribution or differentiate their work from the previous studies. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the issue of limited technical novelty by comparing the current paper with two previous works (Xing and Tsang, 2022a, b). It notes that while the previous papers focus on graphbased approaches, the idea, coattention mechanism, and architecture of the current paper are similar. However, the comment does not specify which sections of the paper these comparisons should be made in, nor does it provide detailed guidance on how the authors might differentiate their work. This lack of specificity and explicit references to sections makes it difficult for the authors to pinpoint exactly where improvements are needed. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the paper lacks technical novelty, comparing it to two previous works (Xing and Tsang, 2022a, b). It notes that while the previous papers focus on graphbased approaches, the idea, coattention mechanism, and architecture of the current paper are similar. However, the comment does not provide specific details or examples from the previous works to support the claim of similarity, making it difficult for the authors to fully understand and address the critique. The lack of detailed comparison or references to specific aspects of the previous works limits the verifiability of the claim. Therefore, the comment is rated as 2, as it provides some basis for the claim but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s technical novelty, noting that it is similar to two previous works (Xing and Tsang, 2022a, b) despite focusing on graphbased approaches. However, the comment does not provide specific details or examples of how the current paper is similar to the previous works, nor does it offer suggestions on how the authors might differentiate their work or enhance its originality. This lack of specificity and actionable guidance limits the comment\"s usefulness, as it does not provide the authors with clear steps to improve their draft. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that the authors should compare CPEF with another pretrained model, such as ExpertBert, to demonstrate the advantage of the innovative pretraining module design of CPEF. This feedback provides a clear and direct action for the authors to take, ensuring a fair comparison and highlighting the unique features of their model. The suggestion is concrete, as it specifies which model should be used for comparison, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3\" and \"line 529lin534,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the comparison, namely the unfairness of comparing CPEF with PMEF, and provides a recommendation to compare CPEF with another pretrained model, such as ExpertBert, to showcase the advantage of the innovative pretraining module design. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point claims that the comparison in Figure 3 is unfair because PMEF lacks a pretraining module, which is a key advantage of CPEF. The reviewer suggests comparing CPEF with another pretrained model, such as ExpertBert, to demonstrate the advantage of the innovative pretraining module design. This claim is 4 as it provides a logical reasoning for the unfairness of the comparison and suggests a specific alternative model for a fairer comparison. However, the comment could be strengthened by providing more detailed reasoning or examples of how the pretraining module design impacts the results. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the fairness of the comparison in Figure 3, where the authors compare CPEF with PMEF to demonstrate the advantages of the pretrained question representation model under data scarcity conditions. The reviewer points out that this comparison is unfair because PMEF lacks a pretraining module, which is a key advantage of CPEF. The comment provides a clear and actionable suggestion to address this issue by recommending a comparison with another pretrained model, such as ExpertBert, to showcase the advantage of the innovative pretraining module design of CPEF. This feedback is 5 as it not only identifies a weakness in the current comparison but also offers a concrete solution to improve the fairness and clarity of the results. By following this advice, the authors can enhance the validity and impact of their findings."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the attack methods used in the paper, describing them as naive and suggesting that other classical attack methods in NLP should be considered. However, it does not provide explicit guidance on which specific attack methods should be used or how to incorporate them into the study. The comment references a list of papers but does not explain how these papers relate to the current work or how they could be applied. The action is implicit and vague, as the authors are left to infer that they should explore additional attack methods but without concrete guidance on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment critiques the attack methods used in the paper, specifically mentioning that they are considered naive and suggesting that other classical attack methods in NLP should be considered. However, it does not specify which part of the paper discusses these attack methods, making it weakly grounded. The comment is specific in suggesting the use of other classical attack methods and references specific papers, which provides some guidance on what could be improved. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the attack methods used in the paper are naive and suggests that other classical attack methods in NLP should be considered. The reviewer provides a specific example by referencing other papers, which is a form of external reference. However, the comment lacks detailed reasoning or examples from the referenced papers to fully substantiate the claim. While the suggestion to consider other methods is clear, the lack of detailed justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a weakness in the paper by pointing out that the attack methods used are considered naive. It suggests that other classical attack methods in NLP should be considered, particularly in the context of the toy setting with classification tasks. The comment provides a specific example by referencing other papers, which could guide the authors in exploring more robust and relevant attack methods. However, the comment could be more helpful if it offered a more detailed analysis of the limitations of the current attack methods or provided specific suggestions on how to incorporate these alternative methods into the study. Overall, the feedback is 3 as it highlights an area for improvement but lacks depth and actionable guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the relationship between uncertainty calibration and temperature calibration, specifically questioning the need for both in the context of the regularization term H. It suggests that the authors clarify this point by explaining the role of H in uncertainty calibration and how it relates to temperature calibration. Additionally, it points out a potential contradiction in the paper regarding the effect of reducing entropy, which is against the paper\"s motivation to calibrate networks. While the comment identifies specific areas for clarification, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to clarify the relationship between uncertainty and temperature calibration and reconcile the contradiction regarding entropy reduction. However, the lack of detailed guidance makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (155160) in the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the relationship between uncertainty and temperature calibration, particularly regarding the regularization term H. The comment further clarifies the confusion by pointing out a potential contradiction in the paper regarding the effect of reducing entropy. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a claim about the relationship between uncertainty calibration and temperature calibration, specifically questioning the need for both in the context of the regularization term H. The reviewer provides a detailed explanation of the confusion, noting that the training regularization term (H) requires temperature calibration, yet temperature calibration is applied after training. This reasoning is logical and provides a clear basis for the claim. However, the comment could be strengthened by referencing specific lines or sections of the paper where these issues are discussed, which would make it 5. Therefore, the comment is 4, as it provides a solid foundation for the claim but lacks complete evidence or references.", "helpfulness_rationale": "The review comment identifies a potential confusion in the paper regarding the relationship between uncertainty calibration and temperature calibration. It points out a contradiction in the paper, where the regularization term H requires temperature calibration but is applied after training, which seems counterintuitive. The comment also highlights a contradiction in the paper\"s motivation, as reducing entropy makes predictions more confident, which is against the goal of calibrating networks. This feedback is clear and actionable, as it prompts the authors to clarify the relationship between these concepts and reconcile any contradictions. By addressing these points, the authors can improve the clarity and consistency of their work. Therefore, the comment is rated as 4, as it provides specific guidance for improvement but could be more comprehensive with additional suggestions or examples."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the importance of including a reference to the idea of unrolling, which was first proposed in \"Lista\" by Yann LeCun. It suggests that the paper should discuss the similarities and differences between the proposed work and Lista, and place itself in an appropriate context. While the comment implies that the authors should include this reference and discussion, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to integrate this reference or discussion into the paper. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the idea of unrolling, which is closely related to the paper, and references the work of Lista by Yann LeCun. This allows the authors to accurately identify the part of the paper being addressed, specifically the context and positioning of their work. The comment is also specific because it clearly specifies what is missing, namely a reference to the idea of unrolling and a discussion of the similarities and differences between the proposed work and Lista. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that an important reference is missing, specifically the idea of unrolling, which was first proposed in \"Lista\" by Yann LeCun. The reviewer provides a direct reference to the Lista paper, which supports the claim by offering a specific source for the idea of unrolling. This level of detail and reference makes the claim 5, as it provides a clear and direct link to the missing reference. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a significant omission in the paper, namely the lack of reference to the idea of unrolling, which was first proposed in the Lista paper by Yann LeCun. It highlights the importance of discussing the similarities and differences between the proposed work and Lista, which would help place the paper in an appropriate context. This feedback is clear and actionable, as it provides a specific reference and suggests a direction for the authors to improve their draft by discussing the relevant literature. However, the comment could be more helpful if it offered guidance on how to integrate this reference or discussion into the paper. Overall, the comment is 4, as it directs the authors to a critical area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the clarity of Algorithm 2, specifically regarding the computation of \"avg\" and the meaning of \"j\" and \"i\". It also suggests updating one node based on results from multiple connected nodes, which is an implicit action. However, the comment does not provide explicit guidance on how to address these issues or clarify the algorithm. The authors are left to infer that they need to provide more detailed explanations or updates to the algorithm, but the comment lacks concrete instructions on how to do so. Therefore, the comment is 3, as it identifies areas for improvement but does not provide detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the algorithm, noting that \"avg\" is computed but not used, and questions the meaning of \"j\" and \"i.\" This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the clarity of Algorithm 2, specifically regarding the computation of \"avg\" and the meaning of \"j\" and \"i.\" It also suggests updating one node based on results from multiple connected nodes. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the exact issues or how to address them. The reference to the authors\" response does not provide additional context or justification for the claim. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail and evidence to fully substantiate the claims.", "helpfulness_rationale": "The review comment raises several specific concerns about the clarity and execution of Algorithm 2. It questions the computation of \"avg\" and the meaning of \"j\" and \"i,\" suggesting that these elements are not clearly defined or used in the algorithm. Additionally, it points out that the algorithm is unclear regarding whether it updates one node based on results from multiple connected nodes. The comment is 3 as it identifies specific areas of confusion and provides some guidance on what needs to be clarified or addressed. However, it lacks detailed suggestions or examples on how to improve the algorithm\"s clarity, which would make it more actionable. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to clarify how they handle comparisons between episodes with different lengths in the equation between lines 282 and 283. It also suggests that the authors should explain their decision to pad the shorter sequence by replicating its last state and the lack of a normalization factor of 1/T, which can affect the distance calculation. The comment provides clear and concrete actions for the authors to take, ensuring they know exactly what needs to be addressed and how to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the equation between lines 282 and 283, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the equation, namely the handling of comparisons between episodes with different lengths and the lack of a normalization factor, which affects the distance calculation. The comment also provides a suggestion for how the authors could address this issue by explaining their decision to pad the shorter sequence and the impact of the normalization factor. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the equation between lines 282 and 283, specifically regarding the handling of comparisons between episodes with different lengths. The reviewer provides a detailed explanation of how the authors pad the shorter sequence by replicating its last state and the impact of this decision on the distance calculation. The comment also suggests that the lack of a normalization factor of 1/T can affect the distance calculation and potentially favor longer trajectories. This reasoning is clear and provides a logical basis for the claim, making it 4. However, the comment could be strengthened by referencing specific literature or examples to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the equation between lines 282 and 283, where the authors should clarify how they handle comparisons between episodes with different lengths. It provides a detailed explanation of the issue, noting that the authors pad the shorter sequence by replicating its last state and that this decision can affect the distance calculation. The comment also points out the lack of a normalization factor of 1/T, which can impact the distance calculation and potentially favor longer trajectories. This feedback is clear and actionable, as it guides the authors on what specific aspects of their methodology need clarification and improvement. By addressing these points, the authors can enhance the transparency and comprehensibility of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights issues with the figures, specifically mentioning that the text is too small and that the inputs and outputs for each task are not clearly explained. It also notes that the captions are not selfcontained and difficult to link to the main text. While the comment identifies specific problems, it does not provide explicit guidance on how to address these issues or suggest concrete actions for improvement. The authors are left to infer that they need to make the text larger, clarify the inputs and outputs, and improve the captions. However, the lack of explicit instructions makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig.1 to Fig.3,\" allowing the authors to accurately identify the specific parts of the paper being addressed. It also specifies the issues with the figures, such as the small text, unclear inputs and outputs, and the lack of selfcontained captions. This provides clear guidance on what needs to be addressed to improve the figures. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figures 1 to 3 are difficult to parse due to small text and unclear inputs and outputs. It also notes that the captions are not selfcontained and difficult to link to the main text. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the exact issues and how to address them. The lack of detailed justification or references to similar issues in other works makes the claim 3, as it provides a general critique but lacks the depth needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies specific issues with the figures, noting that they are difficult to parse due to small text and unclear inputs and outputs. It also points out that the captions are not selfcontained and are challenging to link to the main text. This feedback is clear and actionable, as it provides the authors with a direct way to improve the clarity and accessibility of their figures. By addressing these issues, the authors can enhance the readability and comprehensibility of their work, which is crucial for effective communication of their findings. However, the comment could be more helpful if it offered suggestions on how to improve the figures, such as increasing text size or providing additional explanations. Overall, the comment is 4, as it effectively guides the authors toward improving their figures but could be more comprehensive with specific suggestions."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the continuous diffusion model (e.g., GDSS) should be compared as a baseline in Table 3, despite not explicitly presenting a conditional framework. The reviewer provides a reference to recent work that proposes a conditional molecule generation framework using classifier guidance based on GDSS, which could be used as a baseline. This comment is explicit in its suggestion to include GDSS as a baseline and provides a concrete reference for the authors to consider. The action is clear and provides specific guidance on how to implement the suggestion, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of comparing the continuous diffusion model (GDSS) as a baseline in Table 3, despite not explicitly presenting a conditional framework. The comment further provides a reference to recent work that proposes a conditional molecule generation framework using classifier guidance based on GDSS, which could be used as a baseline. This additional information enhances the specificity of the comment. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the continuous diffusion model (GDSS) should be compared as a baseline in Table 3, despite not explicitly presenting a conditional framework. The reviewer supports this claim by referencing recent work that proposes a conditional molecule generation framework using classifier guidance based on GDSS. This external reference provides a logical basis for the suggestion, making the claim 4. However, the comment could be strengthened by providing more detailed information about the specific aspects of the recent work that support the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper. It identifies a potential weakness in the comparison of the continuous diffusion model (GDSS) with the discrete diffusion model (DiGress) in Table 2, noting that GDSS should be compared as a baseline in Table 3 (conditional generation task). The comment also references recent work that proposes a conditional molecule generation framework using classifier guidance based on GDSS, which could be used as a baseline. This feedback is specific and provides a concrete direction for the authors to enhance their analysis and comparison. By addressing this suggestion, the authors can strengthen the validity and comprehensiveness of their results. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the paper should include a comparison against stateoftheart loss functions widely used in face/iris verification, such as CenterLoss, ASoftmax, AMSoftmax, and ArcFace. This provides a clear and direct action for the authors to take, as it specifies the type of comparison that should be added to the paper. The suggestion is concrete, as it provides specific examples of loss functions to consider, making it 5. Therefore, this comment is rated as a 5 on the actionability scale.", "grounding_specificity_rationale": "The comment suggests adding a comparison against stateoftheart loss functions widely used in face/iris verification, such as CenterLoss, ASoftmax, AMSoftmax, and ArcFace. However, it does not specify which part of the paper this comparison should be included in, such as the experimental section or the discussion. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the types of loss functions to consider, which provides clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should include a comparison against stateoftheart loss functions widely used in face/iris verification, such as CenterLoss, ASoftmax, AMSoftmax, and ArcFace. This claim is 3 as it provides a specific suggestion for improvement, but it lacks detailed reasoning or evidence to support why these comparisons are necessary or how they would enhance the paper. The authors would need to infer the importance of these comparisons themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the paper should include a comparison against stateoftheart loss functions widely used in face/iris verification, such as CenterLoss, ASoftmax, AMSoftmax, and ArcFace. This feedback is clear and actionable, as it provides specific examples of loss functions that could be included in the comparison. By suggesting this addition, the comment offers a concrete way for the authors to enhance the comprehensiveness and relevance of their work. However, the comment could be more helpful if it explained why these comparisons are important or how they would contribute to the paper\"s findings. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly points out a confusion in the reference to \"PointNet\" in Figure 1, noting that this name does not appear anywhere in the paper and that there exists another paper with the same name. The reviewer provides a specific reference to the original PointNet paper by Charles R. Qi, Hao Su, Kaichun Mo, and Leonidas J. Guibas. This feedback is clear and actionable, as it directs the authors to correct the reference to avoid confusion and ensure accurate attribution. The authors know exactly what needs to be done to address the issue, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the reference to \"PointNet\" and provides a suggestion to correct it by referencing the original paper by Charles R. Qi, Hao Su, Kaichun Mo, and Leonidas J. Guibas. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point claims that referring to [15] as \"PointNet\" is confusing because the name does not appear anywhere in the paper and there exists another paper with the same name. The reviewer supports this claim by providing a specific reference to the original PointNet paper by Charles R. Qi, Hao Su, Kaichun Mo, and Leonidas J. Guibas. This detailed reference and explanation provide a clear basis for the claim, making it 5. The authors can easily understand and address the issue by correcting the reference to avoid confusion. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a specific issue with the reference to \"PointNet\" in Figure 1, noting that the name does not appear anywhere in the paper and that there exists another paper with the same name. The reviewer provides a specific reference to the original PointNet paper by Charles R. Qi, Hao Su, Kaichun Mo, and Leonidas J. Guibas, which helps the authors correct the reference and avoid confusion. This feedback is clear and actionable, offering a precise suggestion for improvement that can enhance the accuracy and clarity of the paper. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to present the results comparing standard vs. evolutional dropout on shallow models as a mean over many runs (at least 10), ideally with errorbars. It also notes that the plotted curves are from single runs and might be subject to significant fluctuations, suggesting that the models are small and should not be an excuse for not providing statistics. This feedback is clear and provides concrete steps for the authors to take, ensuring they know exactly what changes to make to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the results comparing standard vs. evolutional dropout on shallow models, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely presenting the results as a mean over many runs (at least 10) with errorbars, and explaining why the current presentation might be subject to significant fluctuations. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the results comparing standard vs. evolutional dropout on shallow models should be presented as a mean over many runs, ideally with errorbars, to account for potential fluctuations. The reviewer provides a logical reasoning by noting that the plotted curves are from single runs, which could lead to significant fluctuations due to the small size of the models. This reasoning is clear and provides a basis for the suggestion, making the claim 4. However, the comment could be strengthened by providing specific examples or references to support the claim about the need for statistical analysis. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides clear and actionable feedback by suggesting that the results comparing standard vs. evolutional dropout on shallow models should be presented as a mean over multiple runs, ideally with errorbars, to account for potential fluctuations. This recommendation is important for ensuring the robustness and reliability of the results, particularly given the small size of the models. The comment is specific and offers a concrete suggestion for improvement, making it 5 for the authors. Therefore, the comment is rated as 5, consistent with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to provide more detailed information about the experimental environment, specifically mentioning the CUDA and PyTorch versions. This is a clear and direct action that the authors can take to improve their draft. The comment also explains the importance of this information by highlighting its potential impact on training and inference speeds. The action is explicit and provides concrete guidance on what needs to be included, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need to describe the experimental environment in more detail, specifically mentioning the CUDA and PyTorch versions. This allows the authors to accurately identify the part of the paper that needs revision. The comment is also specific because it clearly specifies what needs to be addressed, namely the detailed description of the experimental environment. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide more detailed information about the experimental environment, specifically mentioning the CUDA and PyTorch versions. The claim is based on the assumption that different versions of these environments can impact training and inference speeds. While the reviewer provides a logical reasoning for the need for more detailed information, it lacks specific examples or references to substantiate the claim. This makes the comment 3, as the authors would need to infer the potential impact themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides clear and actionable feedback by suggesting that the authors should include more detailed information about the experimental environment, specifically mentioning the CUDA and PyTorch versions. This is important because different versions of these environments can impact training and inference speeds, which are crucial aspects of the paper. By addressing this feedback, the authors can enhance the transparency and reproducibility of their work. However, the comment could be more helpful if it explained why these details are important or how they might affect the results. Overall, the feedback is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context or examples. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point expresses doubt about the strength of the paper as it stands, suggesting that it might not be suitable for ICLR. However, it does not provide any specific guidance or suggestions on how the authors could strengthen their contribution or improve the paper to meet the standards of ICLR. The comment lacks actionable details, leaving the authors uncertain about what changes are needed to address the concern. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment expresses doubt about the strength of the paper as it stands, suggesting that it might not be suitable for ICLR. However, it does not specify which aspects of the paper are lacking or what specific contributions are insufficient. Without detailed guidance or references to particular sections or elements of the paper, the authors cannot effectively address the feedback. The comment is 1 as it does not identify a specific part of the paper, and it is also not specific in detailing what needs to be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses doubt about the strength of the paper, suggesting that it might not be suitable for ICLR. However, the comment lacks any supporting evidence, reasoning, or specific examples to justify this claim. Without detailed explanation or references to what aspects of the paper are lacking, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses doubt about the strength of the paper, suggesting that it might not be suitable for ICLR. However, it lacks specificity and does not provide any actionable feedback or suggestions for improvement. Without detailed guidance or examples of what aspects of the paper need strengthening, the authors are left without a clear understanding of how to address the concern. This makes the comment unhelpful, as it does not offer any constructive direction for enhancing the draft. Therefore, it aligns with a score of 1."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that experiments in deep reinforcement learning (RL) should be run multiple times to improve reproducibility and significance. It references a recent suggestion by Henderson et al. (2018) that a community effort towards reproducibility is needed. The comment implies that the authors should consider this suggestion in their paper, but it does not explicitly instruct them to do so. While the action is implicit, it is concrete because it provides a specific suggestion about running multiple experiments and reporting statistics. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Experiments\" and \"deep RL,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion to run multiple experiments and report statistics, referencing a recent suggestion by Henderson et al. (2018) regarding the importance of reproducibility in deep RL. This provides a clear direction for the authors to improve their work. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that experiments in deep reinforcement learning (RL) should be run multiple times to improve reproducibility and significance. It references a recent suggestion by Henderson et al. (2018) that a community effort towards reproducibility is needed. The comment provides a specific reference to support the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how running multiple experiments would improve reproducibility and significance. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a critical issue in deep reinforcement learning (RL) experiments, specifically the lack of reproducibility and the significance of improvements. It references a recent suggestion by Henderson et al. (2018) that a community effort towards reproducibility is needed, which should also be considered in the paper. The comment provides a clear and actionable suggestion by emphasizing the importance of running multiple experiments and reporting statistics. This feedback is valuable as it directs the authors to address a significant concern in their field and provides a specific direction for improvement. However, the comment could be more helpful if it included additional guidance on how to implement these suggestions or specific examples of what to report. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the proposed upweighing and KNN methods, suggesting that they do not appear to be idiomspecific based on the results shown in Figure 3. The comment implies that the methods are not effective in distinguishing between idiomatic and random data, and it concludes that the results indicate that better NMT systems are also better at idiomatic translations. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their methods. The action is implicit and vague, as the authors are left without clear direction on how to enhance their work. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the proposed upweighing and KNN methods, noting that the impact on idiomatic versus random data is similar for most language and score combinations. The comment further critiques the results by suggesting that the methods are not idiomspecific and that the findings merely indicate that better NMT systems are also better at idiomatic translations. This level of detail provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed upweighing and KNN methods do not appear to be idiomspecific, as the impact on idiomatic versus random data is similar for most language and score combinations. The comment references Figure 3, which provides a visual representation of the results, but does not elaborate on the specific findings or provide detailed reasoning to support the claim. While the reference to Figure 3 offers some context, the lack of detailed explanation or additional evidence makes the claim 3. The authors would need to further investigate the results to fully understand the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a critical analysis of the proposed upweighing and KNN methods, suggesting that they do not appear to be idiomspecific based on the results shown in Figure 3. The comment points out that the impact on idiomatic versus random data is similar for most language and score combinations, implying that the methods are not effective in distinguishing between idiomatic and random data. This feedback is valuable as it highlights a potential limitation of the proposed methods and suggests that the results may not be as idiomspecific as claimed. However, the comment could be more helpful if it offered suggestions on how to address this issue or improve the methods to better capture idiomspecific characteristics. Overall, the comment is 3 as it identifies a weakness but lacks actionable guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of direct comparisons between the proposed approach and the prior approach PRANC, specifically in terms of test accuracy. It suggests that without such comparisons, it is unclear if the proposed approach is an improvement over the baseline. The comment implies that the authors should include direct comparisons to demonstrate the effectiveness of their approach. However, it does not provide specific guidance on how to conduct these comparisons or what metrics to use. The action is implicit and somewhat vague, as the authors can infer that they need to add comparisons but are not given detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.4\" and \"Section 3.5,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of direct comparisons with the prior approach PRANC in terms of test accuracy, which is a clear and specific concern. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed approach lacks direct comparisons with the prior approach PRANC, specifically in terms of test accuracy. The reviewer highlights the absence of such comparisons in the language and vision tasks used to evaluate the proposed approach. The comment provides a logical reasoning by pointing out the lack of direct comparisons in Sections 3.4 and 3.5, which focus on training loss and the rank of possible solutions, respectively. However, it does not provide specific examples or references to support the claim, making it 3. The authors would need to infer the importance of direct comparisons and the potential impact on the evaluation of the proposed approach. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the evaluation of the proposed approach by pointing out the lack of direct comparisons with the prior approach PRANC, specifically in terms of test accuracy. It highlights that while there are comparisons in training loss and the rank of possible solutions, the absence of a direct comparison of test accuracy makes it unclear if the proposed approach is an improvement over the baseline. This feedback is clear and actionable, as it provides a specific area for improvement that the authors can address to strengthen their evaluation and demonstrate the effectiveness of their approach. However, the comment could be more helpful if it suggested specific metrics or methods for conducting these comparisons. Overall, the comment is 4, as it effectively guides the authors toward enhancing the evaluation of their work."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point claims that the improvement of the proposed method over existing RL methods is not impressive. However, it does not provide any specific guidance or suggestions on how the authors could improve their method to make it more impressive. There is no explicit or implicit action for the authors to take, leaving them without a clear understanding of what changes or additions might be necessary to address the reviewer\"s concern. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment critiques the improvement of the proposed method over existing RL methods, but it does not specify which part of the paper this critique is based on. The authors cannot confidently determine which sections or aspects of the paper are being addressed, making it weakly grounded. Additionally, the comment lacks specificity as it does not provide details on what aspects of the proposed method are not impressive or how they could be improved. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the improvement of the proposed method over existing RL methods is not impressive. However, the comment lacks any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references to what aspects of the proposed method are lacking or how it compares unfavorably to existing methods, the claim remains 1. The authors are left without a clear understanding of what needs to be addressed or improved to support the claim. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment points out that the improvement of the proposed method over existing RL methods is not impressive. However, it lacks specificity and does not provide any actionable feedback or suggestions on how the authors might address this issue. Without detailed guidance or examples, the authors are left without a clear understanding of what aspects of their method need improvement or how to enhance its effectiveness. As a result, the comment is 1, as it does not offer any constructive direction for the authors to improve their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a lack of clarity in the model design, specifically mentioning the fragmentation or absence of model architecture and learning details. It suggests that the authors could provide a plot of the model illustration, pseudocode table, or code repository to improve clarity. Additionally, the comment emphasizes the importance of demonstrating integrated details, especially since Neurochaos Learning is not a wellknown method. This feedback is explicit and provides concrete suggestions on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"model design\" and \"learning details,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the fragmentation or absence of these details, suggesting that a plot of the model illustration, pseudocode table, or code repository could be provided to improve clarity. Additionally, the comment highlights the importance of demonstrating integrated details, especially since Neurochaos Learning is not a wellknown method. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the model design and learning details are fragmented or missing, suggesting that the authors provide a plot of the model illustration, pseudocode table, or code repository to improve clarity. The comment also emphasizes the importance of demonstrating integrated details, especially since Neurochaos Learning is not a wellknown method. This claim is 3 as it provides a logical reasoning for the need to clarify the model design, but it lacks specific examples or references to support the assertion about the lack of clarity. The suggestion to provide additional details is reasonable, but the comment could be strengthened with more detailed justification or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the clarity and presentation of the model design and learning details in the paper. It highlights the fragmentation or absence of these details, which could hinder reproducibility, especially since Neurochaos Learning is not a wellknown method. The comment provides clear and actionable suggestions by recommending that the authors include a plot of the model illustration, pseudocode table, or code repository to improve clarity. This feedback is valuable as it directly addresses a critical area for improvement and offers specific steps for enhancing the draft. However, the comment could be more helpful if it provided additional guidance on how to present these details effectively or suggested specific elements to include in the model illustration. Overall, the comment is 4, as it effectively guides the authors toward improving the clarity and reproducibility of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential issue with the authors\" approach to pruning, noting that it primarily works with large networks trained in distributed settings. It suggests that the authors should consider finding global top Q values of the metric over the average of gradients to avoid breaking acceleration techniques like quantization and sparsification. While the comment implies that the authors should address this issue, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore this aspect of their work. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"pruning\" and \"large networks,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the potential need to find global top Q values of the metric over the average of gradients to avoid breaking acceleration techniques like quantization and sparsification. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that pruning primarily works with large networks trained in distributed settings and suggests that the authors should consider finding global top Q values of the metric over the average of gradients to avoid breaking acceleration techniques like quantization and sparsification. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that finding global top Q values is necessary or how it would impact acceleration techniques. The lack of detailed justification makes it difficult for the authors to fully understand and address the concern. Therefore, the comment is considered 2, as it provides some insight but requires more detailed evidence or explanation to be 5.", "helpfulness_rationale": "The review comment identifies a potential issue with the authors\" approach to pruning, noting that it primarily works with large networks trained in distributed settings. It suggests that the authors should consider finding global top Q values of the metric over the average of gradients to avoid breaking acceleration techniques like quantization and sparsification. This feedback is 3 as it points out a specific area for improvement and provides a suggestion for addressing it. However, the comment could be more helpful if it offered additional guidance or examples on how to implement this suggestion. Overall, the comment provides a clear direction for the authors to consider, making it 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the possibility of subfigures in Figs 1 and 2 being swapped by mistake. While it implies that the authors should check for this potential error, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to verify or correct the issue. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figs 1 and 2,\" allowing the authors to accurately identify the specific parts of the paper being addressed. It is also specific because it raises a question about the possibility of subfigures being swapped by mistake, providing clear guidance on what needs to be checked. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question asking whether some subfigures in Figs 1 and 2 have been swapped by mistake. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the possibility of subfigures in Figs 1 and 2 being swapped by mistake. While it identifies a potential issue, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this concern. The comment is vague and does not offer actionable feedback, leaving the authors without a clear understanding of what needs to be done to improve their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the paper formatting is off and does not follow the NeurIPS formatting style. It specifies that the abstract font is too large and the bottom page margins seem to be altered. The reviewer suggests that by fixing the paper style, the authors could gain some space and include the NLP experiments in the main body of the paper. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what needs to be done to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue with the paper formatting, specifically the noncompliance with the NeurIPS formatting style, the large abstract font, and the altered bottom page margins. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it provides clear guidance on what needs to be addressed, namely fixing the formatting to gain space and include the NLP experiments in the main body of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper formatting is off and does not follow the NeurIPS formatting style. It provides specific details about the issues, such as the abstract font being too large and the bottom page margins being altered. This level of detail supports the claim, making it 4. However, the comment could be strengthened by referencing specific NeurIPS formatting guidelines or providing examples of how the formatting should be corrected. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper formatting, noting that it does not follow the NeurIPS formatting style. It points out specific problems, such as the abstract font being too large and the bottom page margins being altered. The comment provides a clear and actionable suggestion for improvement by recommending that the authors fix the formatting to gain space and include the NLP experiments in the main body of the paper. This feedback is valuable as it directly addresses a technical issue that could impact the readability and presentation of the paper. However, the comment could be more helpful if it provided examples or detailed guidance on how to correct the formatting issues. Overall, the comment is 4, as it offers actionable advice but could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point criticizes the paper for not discussing and comparing various exploration methods in RL literature, such as countbased methods and intrinsic motivations like RND and ICM. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue. There is no guidance on which methods should be discussed, how they should be compared, or what specific aspects should be highlighted. Without actionable advice, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the paper for not discussing and comparing various exploration methods in RL literature, such as countbased methods and intrinsic motivations like RND and ICM. However, it does not specify which part of the paper this critique pertains to, making it difficult for the authors to identify the exact section that needs revision. The comment is specific in detailing the missing discussion on exploration methods, but it lacks grounding as it does not point to a particular section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is not sound because it does not discuss and compare various exploration methods in RL literature, such as countbased methods and intrinsic motivations like RND and ICM. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence makes it challenging for the authors to address the feedback effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out that it does not discuss and compare various exploration methods in RL literature, such as countbased methods and intrinsic motivations like RND and ICM. This feedback is valuable as it highlights an important area for improvement that could enhance the comprehensiveness and depth of the paper. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as which methods to include or how to structure the comparison. While it provides a clear direction for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is 3, as it identifies a critical area for enhancement but could be more actionable with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the definition of the quantile is confusing and proposes two potential solutions: adding an extra pair of brackets around the term or defining the bracketed term separately if space allows. While the comment provides explicit actions, it does not specify which option the authors should choose or how to implement these suggestions. The authors are given a clear direction but lack detailed guidance on execution. Therefore, the comment is 4, as it provides a concrete idea but lacks detailed instructions on implementation.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"definition of the quantile,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a potential improvement by proposing the addition of an extra pair of brackets or defining the bracketed term separately, if space allows. This provides clear guidance on how to address the issue of confusion in the definition. Therefore, the comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point claims that the definition of the quantile is confusing and suggests potential improvements, such as adding extra brackets or defining the bracketed term separately. However, the comment does not provide any specific reasoning or examples to support why the current definition is confusing or how the suggested changes would improve clarity. Without detailed justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the definition of the quantile, suggesting that it is confusing. It provides a concrete suggestion for improvement by proposing the addition of an extra pair of brackets or defining the bracketed term separately, if space allows. This feedback is clear and actionable, offering the authors a direct way to enhance the clarity and readability of their work. By addressing this feedback, the authors can improve the comprehensibility of their paper, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the redundancy of RQ1 and suggests an alternative analysis that could be more interesting. It provides a specific suggestion for an additional analysis that would be beneficial, particularly regarding the impact of explicit hate information on implicit hate speech detection performance and its effect on RQ2 and RQ3 tsne plots. The reference to a relevant study provides additional context and justification for the suggestion. While the comment implies an action by suggesting an alternative analysis, it does so with concrete details, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"RQ1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the redundancy of RQ1 and suggests an alternative analysis that could be more interesting. The comment provides a specific suggestion for an additional analysis regarding the impact of explicit hate information on implicit hate speech detection performance and its effect on RQ2 and RQ3 tsne plots. Additionally, it references a relevant study, which further grounds the comment. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that RQ1 is redundant and suggests an alternative analysis that would be more interesting. The reviewer provides a specific suggestion for an additional analysis regarding the impact of explicit hate information on implicit hate speech detection performance and its effect on RQ2 and RQ3 tsne plots. This suggestion is supported by a reference to a relevant study, which provides a clear and specific example of the type of analysis the reviewer is suggesting. The inclusion of the reference enhances the verifiability of the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples within the text itself, which would align it with a score of 5.", "helpfulness_rationale": "The review comment identifies a potential redundancy in the paper, specifically regarding RQ1, and suggests an alternative analysis that could be more interesting. It provides a specific suggestion for an additional analysis that would explore the impact of explicit hate information on implicit hate speech detection performance and its effect on RQ2 and RQ3 tsne plots. This feedback is clear and actionable, offering the authors a concrete direction for enhancing their draft. By suggesting a more nuanced analysis, the comment provides valuable guidance that could significantly improve the paper. However, it could be more helpful if it included additional context or examples to further support the suggestion. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to clarify in the introduction that their proposed solution is a \"fix\" of a previous work, rather than a new PIC approach. It provides specific guidance by suggesting how to rephrase the introduction to make this distinction clear. The comment also explicitly states that the authors must mention the previous work that has already proposed the framework. This feedback is clear and provides concrete steps for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction and lines 2930, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified: the distinction between the proposed solution being a \"fix\" of a previous work rather than a new PIC approach. Additionally, it provides a suggestion on how to rephrase the introduction to make this distinction clear. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors need to clarify that their proposed solution is a \"fix\" of a previous work, rather than a new PIC approach. The comment provides a specific reference to lines 2930, where the authors introduce their framework, and suggests that the framework has already been proposed by [12]. This provides a clear basis for the claim, making it 4. However, the comment could be strengthened by including a direct reference to the specific work by [12] or by providing more detailed reasoning on why the distinction is important. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides clear and actionable feedback by identifying a specific issue with the introduction of the paper. It points out that the authors need to clarify that their proposed solution is a \"fix\" of a previous work, rather than a new PIC approach, as introduced in lines 2930. The comment suggests a specific rephrasing to make this distinction clear, which is a valuable contribution to the authors. Additionally, it highlights the need to mention the previous work that has already proposed the framework. This feedback is detailed and provides the authors with a clear path to improve the clarity and accuracy of their introduction. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the rationale behind combining G4RL with HRAC (HRACG4RL) and whether G4RL requires HRAC\"s regularization in the latent space. While it does not explicitly instruct the authors to provide an explanation or address these questions, the comment implies that the authors should clarify these aspects. The action is implicit but clear, as the authors can infer that they need to provide an explanation or clarification. However, the comment lacks concrete guidance on how to address these questions, making it 3.", "grounding_specificity_rationale": "The comment raises questions about the rationale behind combining G4RL with HRAC (HRACG4RL) and whether G4RL requires HRAC\"s regularization in the latent space. However, it does not specify which part of the paper discusses this combination or where the authors should address these questions. The authors can infer that it relates to the methodology or results sections, but the comment lacks full grounding as it does not explicitly mention these sections. The comment is specific in its questions about the rationale and requirements, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point consists of questions seeking clarification about the rationale behind combining G4RL with HRAC (HRACG4RL) and whether G4RL requires HRAC\"s regularization in the latent space. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the rationale behind combining G4RL with HRAC (HRACG4RL) and whether G4RL requires HRAC\"s regularization in the latent space. This feedback prompts the authors to clarify the reasoning behind their approach, which is crucial for understanding the methodology and its implications. However, the comment does not provide specific suggestions or guidance on how to address these questions or improve the clarity of the explanation. While it highlights an area for improvement, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should include comparisons with NeRFbased methods, specifically mentioning \"Zero1to3\" and \"pointe.\" It also questions the relevance of the occlusion experiment, suggesting that the method does not propose anything specific to occlusion. While the comment implies that the authors should make these comparisons, it does not provide explicit instructions on how to implement them or why these comparisons are important. The action is implicit and somewhat vague, as the authors need to infer the specific comparisons needed and how to integrate them into their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should include comparisons with NeRFbased methods, specifically mentioning \"Zero1to3\" and \"pointe.\" It also questions the relevance of the occlusion experiment, suggesting that the method does not propose anything specific to occlusion. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the experimental or results sections where comparisons and experiments are discussed. The comment is specific in suggesting comparisons with specific methods and questioning the relevance of the occlusion experiment. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should include comparisons with NeRFbased methods, specifically mentioning \"Zero1to3\" and \"pointe.\" It also questions the relevance of the occlusion experiment, suggesting that the method does not propose anything specific to occlusion. While the comment provides some context by mentioning specific methods, it lacks detailed reasoning or evidence to support why these comparisons are necessary or how they would enhance the paper. The claim is 3, as it highlights potential areas for improvement but requires more detailed justification or examples to be fully substantiated.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper. It suggests that the authors should include comparisons with NeRFbased methods, specifically mentioning \"Zero1to3\" and \"pointe,\" which could provide a more comprehensive evaluation of the method. Additionally, it questions the relevance of the occlusion experiment, suggesting that the method does not propose anything specific to occlusion. While the comment highlights important areas for improvement, it could be more helpful by providing specific guidance on how to incorporate these comparisons or by explaining why the occlusion experiment is not relevant. Overall, the feedback is 3 as it points out potential enhancements but lacks detailed suggestions for implementation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a missing discussion on the arbitrary hyperparameter \u03b3, including how to set it in practice for a given graph and analyzing its sensitivity. This provides a clear action for the authors to take, which is to include this discussion in their paper. The comment is specific and provides concrete guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the discussion on the arbitrary hyperparameter \u03b3, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the discussion on how to set the hyperparameter in practice for a given graph and the analysis of its sensitivity. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the discussion on the arbitrary hyperparameter \u03b3 is missing, including how to set it in practice for a given graph and analyzing its sensitivity. This claim is 3 as it highlights a gap in the discussion that could be addressed. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand the importance of this discussion. Providing more detailed reasoning or examples would strengthen the verifiability of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the discussion of the arbitrary hyperparameter \u03b3, specifically noting the absence of guidance on how to set it in practice for a given graph and the lack of analysis on its sensitivity. This feedback is clear and actionable, as it highlights a specific area where the authors can enhance their paper by providing additional information and analysis. By addressing these points, the authors can improve the comprehensiveness and utility of their work for researchers interested in replicating or building upon it. However, the comment could be more helpful if it offered suggestions on how to approach these discussions or provided examples of similar analyses in related works. Overall, the comment is 4, as it directs the authors to a critical area for improvement, aligning with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper should place more emphasis on prompt design, given that different prompts can lead to varying performance outcomes. However, it does not provide specific guidance on how to effectively design prompts or what aspects of prompt design should be discussed. The action is implicit and somewhat vague, as the authors are left to infer that they need to discuss prompt design in more detail but without concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that more emphasis should be placed on prompt design, particularly in the context of MenatQA. However, it does not specify which part of the paper should focus on this aspect or where the discussion on prompt design is currently lacking. The authors can infer that it relates to the methodology or results sections, but the comment lacks full grounding as it does not explicitly mention these sections. The suggestion is specific in terms of emphasizing prompt design, but without clear grounding, it aligns with a 3 label.", "verifiability_rationale": "The review point suggests that more emphasis should be placed on prompt design, given the potential impact of different prompts on performance outcomes. However, the comment does not provide specific examples or detailed reasoning to support why this emphasis is necessary or how it could be achieved. The lack of concrete evidence or references makes it difficult for the authors to understand the basis of the suggestion, rendering the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the paper should place more emphasis on prompt design. It acknowledges the importance of different prompts in MenatQA and highlights the need for a discussion on how to effectively design prompts. This feedback is clear and actionable, as it directs the authors to a particular aspect of their work that could benefit from further exploration and explanation. However, the comment could be more helpful if it provided specific suggestions or examples on how to approach prompt design. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to make the legends in Tables 1, 2, and 3 longer and to clarify whether the numbers represent % errors or % correct. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1, 2, 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the legends should be longer and clarify whether the numbers represent % errors or % correct. This provides clear guidance on how to improve the clarity of the tables. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the legends in Tables 1, 2, and 3 should be longer and clarify whether the numbers represent % errors or % correct. This is a request for clarification and does not contain any subjective claims or opinions that require verification. It is purely a suggestion for improvement, making it a normal statement. Therefore, the label \"No\" is appropriate.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the legends in Tables 1, 2, and 3 should be longer and clarify whether the numbers represent % errors or % correct. This is a clear and direct suggestion that can help the authors improve the clarity and comprehensibility of their results. By addressing this feedback, the authors can enhance the readability and interpretability of their work, making the comment 4. However, the comment could be more helpful if it included additional guidance on how to achieve these improvements, such as suggesting specific wording or formatting changes. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides explicit suggestions for improving the paper. It recommends refreshing the idea of energy in Section 5.2, where it is used several times, and provides a hint about how to interpret it. Additionally, it points out that the concept of peak in Figure 5 is not described. These suggestions are clear and concrete, giving the authors specific actions to take to enhance their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1\" and \"Section 5.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details what needs to be addressed, such as refreshing the idea of energy and providing hints about its interpretation, as well as describing the concept of peak in Figure 5. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the concept of energy is mentioned for the first time in Section 3.1 and recommends refreshing the idea of energy in Section 5.2, where it is used several times. It also points out that the concept of peak in Figure 5 is not described. While the comment identifies specific areas for improvement, it lacks detailed reasoning or examples to fully substantiate the claim. The suggestion to provide hints about interpreting energy is vague, and the comment does not reference any external sources or literature to support the need for clarification. Therefore, the claim is 3, as it provides a direction for improvement but lacks comprehensive justification.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by identifying two areas for improvement. First, it suggests refreshing the idea of energy in Section 5.2, where it is used several times, and offers a hint about how to interpret it. Second, it points out that the concept of peak in Figure 5 is not described, which could be important for understanding the results. These suggestions are clear and offer concrete steps for the authors to enhance the clarity and comprehensiveness of their draft. However, the comment could be more helpful if it included specific examples or further elaboration on how to interpret energy or describe the peak concept. Overall, the feedback is 4 as it guides the authors toward improving their manuscript, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests clarifying the title to specify that it refers to machine comprehension of text rather than human reading comprehension. This is an explicit action that the authors can take to improve the clarity of their work. The comment provides a clear direction on what needs to be changed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"General Discussion\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the title, suggesting that it is ambiguous and needs clarification regarding whether it refers to machine comprehension of text or human reading comprehension. The comment provides a clear direction for improvement by suggesting a specific change to the title. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the title is ambiguous and recommends clarifying that it refers to machine comprehension of text rather than human reading comprehension. The comment provides a logical reasoning by explaining that \"reading comprehension\" and \"readability\" are often associated with human understanding, which is different from the context of machine comprehension. This reasoning is clear and provides a basis for the suggestion, making the claim 4. However, the comment could be strengthened by referencing specific examples or studies that support the distinction between machine and human comprehension, which would further enhance its verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential ambiguity in the title, suggesting that it could be clarified to specify that it refers to machine comprehension of text rather than human reading comprehension. This feedback is clear and actionable, as it provides a specific suggestion for improving the clarity and accuracy of the title. By addressing this issue, the authors can enhance the clarity and precision of their work, which is beneficial for both readers and reviewers. However, the comment could be more helpful if it provided additional context or examples to further clarify the distinction between machine and human comprehension. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point identifies an incorrect assertion made by the authors regarding the Central Limit Theorem (CLT) on line 238. It clarifies that the CLT does not guarantee Gaussianity in a nonasymptotic regime and does not hold for a finite linear combination of arbitrary random variables. However, the comment does not provide explicit guidance on how the authors should correct this assertion or what specific changes should be made to the draft. The action is implicit and somewhat vague, as the authors can infer that they need to revise their statement, but they are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 238,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the authors\" claim about the Central Limit Theorem (CLT), pointing out that it does not guarantee Gaussianity in a nonasymptotic regime and does not hold for a finite linear combination of arbitrary random variables. This provides clear guidance on what needs to be corrected or clarified in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors\" statement regarding the Central Limit Theorem (CLT) is incorrect. It provides a clear explanation of why the claim is invalid, stating that the CLT does not guarantee Gaussianity in a nonasymptotic regime and does not hold for a finite linear combination of arbitrary random variables. This reasoning is logical and wellsupported, making the claim 5. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a specific error in the authors\" claim regarding the Central Limit Theorem (CLT) on line 238. It points out that the CLT does not guarantee Gaussianity in a nonasymptotic regime and does not hold for a finite linear combination of arbitrary random variables. This feedback is clear and actionable, as it highlights a critical misunderstanding that needs to be corrected or clarified in the paper. By addressing this issue, the authors can ensure the accuracy and validity of their claims. However, the comment could be more helpful if it provided additional context or examples to further guide the authors in making the necessary corrections. Overall, the comment is 4, as it directs the authors to a specific area of improvement, but it could be more comprehensive with further elaboration."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the lack of confidence intervals for the results, making it unclear whether the performance gains are statistically significant. It also notes that the evaluation is limited to only two datasets, which are standard in the RNP community. The reviewer provides specific references to external works that could be used to address these issues. While the comment implies that the authors should include confidence intervals and evaluate on more datasets, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address these points. However, the references provided offer concrete guidance on how to improve the evaluation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of confidence intervals for results, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the need for confidence intervals to determine statistical significance and the limited evaluation on only two datasets. Additionally, the comment provides specific references to external works that could be used to address these issues, which further enhances the specificity of the feedback. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the lack of confidence intervals makes it unclear whether performance gains are statistically significant and that the evaluation is limited to only two datasets. The reviewer supports this claim by referencing external works that address similar issues, such as [1] DiversitySensitive Conditional Generative Adversarial Networks, [2] Controlling Selection Bias in Causal Inference, [3] An empirical study on robustness to spurious correlations using pretrained language models, and [4] On Feature Learning in the Presence of Spurious Correlations. These references provide a logical basis for the claim, as they suggest that the authors should consider these methods to improve their evaluation. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced works. Overall, the claim is 4, as it is supported by external references but could benefit from additional explanation or examples. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies two significant issues with the paper: the lack of confidence intervals for results, which makes it unclear whether performance gains are statistically significant, and the limited evaluation on only two datasets, which may not adequately represent the diversity of the RNP community. The comment provides specific references to external works that address similar issues, offering a clear path for the authors to improve their evaluation methodology. By suggesting the inclusion of confidence intervals and expanding the dataset evaluation, the comment provides actionable and constructive feedback that can significantly enhance the robustness and validity of the paper. However, it could be more helpful if it included suggestions on how to implement these changes or provided more detailed guidance on which datasets to consider. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the scalability of the method as the corpus size or hidden dimension size increases. However, it does not provide any explicit or implicit actions for the authors to take. The authors are left without guidance on how to address this question or what specific aspects of scalability need to be considered. Without actionable suggestions or a clear direction for improvement, the comment lacks any concrete steps for the authors to follow. Therefore, it is rated as 1.", "grounding_specificity_rationale": "The comment raises a question about the scalability of the method as the corpus size or hidden dimension size increases. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper being addressed. Additionally, the comment does not provide specific guidance on what aspects of scalability need to be addressed or improved. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification about the scalability of the method as the corpus size or hidden dimension size increases. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the scalability of the method as the corpus size or hidden dimension size increases. While it identifies a potential area of concern, it lacks depth and does not provide any suggestions or guidance on how the authors might address this issue. The comment does not offer actionable feedback or insights into how the authors might improve the scalability of their method. As a result, the comment is 2, as it points out a potential weakness but does not assist the authors in making meaningful improvements to their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the method discussed in the paper can be applied to general MDPs but is limited to navigation problems. It also mentions that combining RL and planning has already been discussed in PRMRL~[1] and suggests exploring the application of such algorithms in more general tasks. While the comment implies that the authors should consider expanding the applicability of their method, it does not provide explicit instructions or concrete steps on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore broader applications and may not be entirely sure of the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the applicability of the method discussed in the paper, specifically mentioning that it is limited to navigation problems. It also references PRMRL~[1] as an example of combining RL and planning, suggesting that such algorithms could be applied to more general tasks. However, the comment does not specify which part of the paper discusses the method or where the limitation to navigation problems is mentioned. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the exploration of broader applications, but without explicit references to the paper, it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the method discussed in the paper is limited to navigation problems and suggests exploring its application in more general tasks. The comment references PRMRL~[1] as an example of combining RL and planning, which provides some context for the claim. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim that the method is limited to navigation problems. The reference to PRMRL~[1] is a starting point but does not fully support the claim, making the comment 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, noting that the method discussed is primarily applicable to navigation problems. It suggests that combining RL and planning, as discussed in PRMRL~[1], could be applied to more general tasks. This feedback is 3 as it points out a potential area for expansion and improvement in the paper. However, it lacks specific guidance on how the authors might explore broader applications or integrate RL and planning more effectively. While it provides a direction for further research, it does not offer detailed suggestions or actionable steps, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the suitability of feature spaces for 1NN classification and suggests that feature dimensions should be individually standardized to avoid potential issues. While the comment identifies a potential problem and provides a suggestion for addressing it, it does not explicitly instruct the authors to make this change or offer detailed guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer that they should consider standardizing feature dimensions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 213,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the feature spaces and suggests a potential solution by mentioning the need for individual standardization of feature dimensions. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point raises a concern about the suitability of feature spaces for 1NN classification and suggests that feature dimensions should be individually standardized to avoid potential issues. The comment provides a logical reasoning by explaining that feature spaces that are not close to a spherical Gaussian may perform poorly. This reasoning is based on a common understanding of the properties of 1NN classification and the potential impact of feature space characteristics. However, the comment does not provide specific examples or references to support the claim, which would strengthen the justification. Therefore, the comment is 3, as it provides a logical basis but lacks detailed evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the suitability of feature spaces for 1NN classification, specifically mentioning that feature spaces that are not close to a spherical Gaussian may perform poorly. It provides a suggestion to address this issue by standardizing feature dimensions individually. This feedback is clear and actionable, as it points out a specific area for improvement and offers a concrete solution. However, the comment could be more helpful if it provided additional context or examples to further explain the impact of this issue or the benefits of standardizing feature dimensions. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests including the bottomup method [9] in the tables, as it has reported results on the crowdpose dataset outperforming all methods, including the paper\"s method, with a ResNet50. Additionally, the reviewer suggests evaluating the performance of the method on the standard MS coco dataset to see if there is a drop in performance in easy (nonoccluded) settings. Both suggestions are explicit and provide concrete guidance on what the authors should do to improve their draft. The reviewers clearly specify which methods to include and what aspects to evaluate, making the actions 5.", "grounding_specificity_rationale": "The comment suggests including the bottomup method [9] in the tables and evaluating the performance of the method on the standard MS coco dataset to see if there is a drop in performance in easy (nonoccluded) settings. However, it does not specify which part of the paper these suggestions pertain to, such as which tables or sections should include the method [9] or where the evaluation on the MS coco dataset should be conducted. This lack of explicit grounding makes it difficult for the authors to identify the exact parts of the paper that need attention. The comment is specific in its suggestions but lacks grounding, aligning with a score of 1.", "verifiability_rationale": "The review point suggests including the bottomup method [9] in the tables and evaluating the performance of the method on the standard MS coco dataset to see if there is a drop in performance in easy (nonoccluded) settings. The claim is 3 as it references specific methods and datasets, providing a basis for the suggestion. However, the comment lacks detailed reasoning or evidence to fully substantiate the claim, such as comparisons with other methods or data. This makes the claim 3, as it requires additional information to fully support the suggestion.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting the inclusion of the bottomup method [9] in the tables, as it has reported results on the crowdpose dataset outperforming all methods, including the paper\"s method, with a ResNet50. This recommendation is clear and could help the authors enhance the comprehensiveness of their results. Additionally, the comment suggests evaluating the performance of the method on the standard MS coco dataset to see if there is a drop in performance in easy (nonoccluded) settings. This second suggestion is also specific and actionable, offering a direction for further analysis. The feedback is detailed and provides concrete steps for improvement, making it 5 for the authors. Therefore, the comment is rated as 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point poses a question about what would happen if the original CAD model is already associated with spatiallyvarying (SV) BRDF maps. However, it does not provide any explicit or implicit actions for the authors to take. The question is not phrased as a suggestion or a request for clarification, leaving the authors without any guidance on how to address this issue. As a result, the comment lacks actionability, as it does not offer any direction for improvement or change in the draft. Therefore, it is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment poses a question about a specific scenario involving the original CAD model and SV BRDF maps. However, it does not specify which part of the paper this scenario is discussed in, making it difficult for the authors to identify the exact section being addressed. The comment lacks specificity as it does not detail what the implications or consequences of this scenario might be. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification about a specific scenario involving the original CAD model and SV BRDF maps. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment poses a question about a specific scenario involving the original CAD model and SV BRDF maps. While it highlights a potential area of interest, it does not provide any actionable feedback or suggestions for improvement. The question is more of a curiosity than a critique or a request for change, leaving the authors without any guidance on how to address this issue or its implications. As a result, the comment is not helpful, as it does not offer any actionable insights or suggestions for the authors to enhance their draft. Therefore, it aligns with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to plot a figure showing the decline in accuracy of a predictor over time in different settings to support their claim about the motivation. This provides a clear and concrete action for the authors to take, ensuring they know exactly what needs to be done to address the feedback. The comment is 5 as it specifies a specific task that the authors should undertake to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for a figure to support the claim about the decline in accuracy of a predictor over time in different settings. This allows the authors to accurately identify the part of the paper being addressed, specifically the motivation section. The comment is also specific because it clearly specifies what is missing, namely a figure illustrating the decline in accuracy over time. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evidence for the motivation is not direct and suggests plotting a figure to support the claim. This is a logical request based on the stated problem, which is the accuracy decline due to longterm and continuous usage. The suggestion to plot a figure is a clear and specific action that would help substantiate the claim. However, the comment could be strengthened by providing examples or references to similar plots or studies that support the need for such a figure. Therefore, the claim is 4, as it provides a logical basis but lacks detailed evidence or references.", "helpfulness_rationale": "The review comment identifies a specific issue with the evidence provided for the motivation of the paper, noting that the decline in accuracy due to longterm and continuous usage is not directly supported. It suggests that the authors plot a figure showing the decline in accuracy over time in different settings to substantiate their claim. This feedback is clear and actionable, providing the authors with a concrete step to take to strengthen their argument and improve the clarity of their work. By addressing this suggestion, the authors can enhance the credibility and impact of their paper. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises several questions and requests for clarification regarding the definition of excessive risk, its calculation, and the interpretation of the results. It explicitly asks for an explanation of how to calculate excessive risk in practice, particularly in terms of expectation, and questions the validity of the results shown in Figures 3 and 7. The reviewer also inquires about the comparability of excessive risk values across different groups and whether it is a suitable representation of fairness. While the comment identifies specific areas that need clarification, it does not provide explicit guidance on how to address these questions or improve the draft. The authors are left with a clear understanding of what needs to be clarified but without concrete steps on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 103,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the definition of excessive risk, its calculation, and the interpretation of the results, particularly regarding the positivity of values in Figures 3 and 7. The comment also asks for clarification on the comparability of excessive risk values across different groups and whether it is a suitable representation of fairness. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point consists of a series of questions and requests for clarification, such as the definition of excessive risk, its calculation, and the interpretation of results. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises several important questions and points for clarification regarding the definition and calculation of excessive risk, as well as the interpretation of the results. It specifically asks for an explanation of how to calculate excessive risk in practice, particularly in terms of expectation, and questions the validity of the results shown in Figures 3 and 7. Additionally, it inquires about the comparability of excessive risk values across different groups and whether it is a suitable representation of fairness. These questions are clear and actionable, providing the authors with specific areas to address and clarify in their draft. However, the comment could be more helpful if it offered suggestions on how to address these questions or provided examples of how to calculate excessive risk. Overall, the comment is 4 as it identifies key areas for improvement and guides the authors toward enhancing the clarity and comprehensiveness of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the clarity of the motivation for the task and the potential downstream applications or benefits of amodal tracking. It also questions how uncertainty in amodal predictions might be handled or utilized in subsequent tasks. While the comment identifies areas that need clarification, it does not provide explicit instructions or concrete suggestions on how the authors should address these issues. The authors can infer that they need to provide more detailed explanations and examples, but the comment lacks specific guidance on how to do so. Therefore, the comment is 3, as it highlights important areas for improvement but does not offer detailed steps for execution.", "grounding_specificity_rationale": "The comment addresses the motivation of the task, specifically questioning the clarity of the motivation and the potential downstream applications or benefits of amodal tracking. It also raises concerns about the quality of annotations and the handling of uncertainty in amodal predictions. However, the comment does not explicitly mention which part of the paper discusses the motivation or where these concerns arise, making it weakly grounded. The authors can infer that it relates to the introduction or motivation sections, but this inference is not direct. The comment is specific in detailing what needs to be addressed, such as the potential applications and handling of uncertainty. Therefore, the comment is weakly grounded but specific, aligning with the label 3.", "verifiability_rationale": "The review point raises concerns about the clarity of the motivation for the task and the potential downstream applications or benefits of amodal tracking. It questions the quality of annotations and the handling of uncertainty in amodal predictions. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. The absence of concrete evidence or detailed justification makes it difficult for the authors to understand and address the issues raised. Therefore, the comment is considered 2, as it provides some insight but requires more detailed support to be 5.", "helpfulness_rationale": "The review comment raises important questions about the motivation and potential applications of the task, specifically regarding the difficulty of predicting the state of objects when they are totally occluded. It also questions the quality of annotations and the handling of uncertainty in amodal predictions. While the comment identifies areas that need clarification and improvement, it does not provide specific suggestions or guidance on how the authors might address these issues. The feedback is 3 as it highlights critical areas for improvement, but it lacks actionable advice, making it difficult for the authors to know exactly what steps to take to enhance their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly questions the use of the term \"unreliable neighbors\" and asks for examples of such neighbors. This provides a clear and direct action for the authors to take, which is to provide examples or clarify the concept of \"unreliable neighbors\" in their draft. The comment is explicit and concrete, as it specifies exactly what the authors need to do to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 170 to 171, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the use of the term \"unreliable neighbors\" and asks for examples of such neighbors. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for examples of \"unreliable neighbors,\" which is not a claim but rather a request for clarification. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 3 as it identifies a specific line in the paper (lines 170171) where the term \"unreliable neighbors\" is used. It raises a question about the examples of \"unreliable neighbors\" mentioned in the text, which could prompt the authors to clarify or provide additional context. However, the comment lacks depth and does not offer suggestions on how to address this issue or improve the clarity of the concept. While it points out a potential area for improvement, it does not provide comprehensive guidance or actionable steps for the authors to enhance their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the practicality of the work due to the assumption of known causal relationships between features. It highlights that prior knowledge might not always be available or accurate for specific subpopulations, which is why most researchers focus on mining causal relationships from data automatically. However, the comment does not provide explicit guidance or suggestions on how the authors might address this concern or improve the practicality of their work. The action is implicit and vague, as the authors are left to infer that they should consider the limitations of prior knowledge and explore alternative methods for mining causal relationships. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the practicality of using known causal relationships between features, highlighting that prior knowledge might not always be available or accurate for specific subpopulations. However, it does not specify which part of the paper this critique pertains to, such as a specific section or methodology. The authors can infer that it relates to the discussion of causal relationships, but without explicit grounding, it is challenging to pinpoint the exact part of the paper being addressed. The comment is specific in its critique of the practicality of the work, but it lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point raises a concern about the practicality of the work due to the assumption of known causal relationships between features. It highlights that prior knowledge might not always be available or accurate for specific subpopulations, which is why most researchers focus on mining causal relationships from data automatically. The comment provides a logical reasoning by contrasting the assumption of known causal relationships with the reality of datadriven approaches. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to further explore the limitations and potential solutions to fully understand the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the practicality of the work, specifically regarding the assumption of known causal relationships between features. It highlights a common issue in realworld applications, where prior knowledge might not always be available or accurate for specific subpopulations. This is an important point that the authors should consider, as it could impact the applicability and generalizability of their work. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or explore alternative approaches. While it identifies a potential limitation, it lacks depth and actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point claims that the contrastive learning framework is the same as SimCLR, but it does not provide any explicit or implicit actions for the authors to take. It lacks any guidance or suggestions on how the authors might address this issue or improve their draft. Without any actionable steps or recommendations, the authors are left without a clear understanding of what needs to be done to respond to this comment. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment claims that the contrastive learning framework is the same as SimCLR, but it does not specify which part of the paper this claim pertains to. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine where this issue is discussed. Additionally, the comment lacks specificity regarding what aspects of the framework are identical to SimCLR, leaving the authors without clear guidance on how to address the issue. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the contrastive learning framework is the same as SimCLR, but it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the comparison or how to address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment claims that the contrastive learning framework is the same as SimCLR, but it does not provide any context, explanation, or justification for this assertion. Without additional information or examples, the authors are left without a clear understanding of what aspect of the framework is identical to SimCLR or how this comparison affects the paper. The comment lacks specificity and actionable feedback, making it unhelpful for the authors to address the issue effectively. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests splitting Table 4 and 5 into two tables each, with one table per measure. It provides a concrete example of how to implement this suggestion by recommending that the 8 SFII columns should be placed first, followed by the 8 SPDI columns. This clear and direct guidance gives the authors a specific action to take, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4 and 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides a clear suggestion to split the tables into two, with one table per measure, and offers a concrete example of how to rearrange the columns. This level of detail guides the authors on what changes to make to improve the readability of the tables. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Tables 4 and 5 would be more readable if they were split into two tables each, with one table per measure. The reviewer provides a specific suggestion for rearranging the columns, which is a logical and straightforward recommendation to improve readability. However, the comment does not include any references or detailed reasoning to support why this arrangement would be more effective. While the suggestion is clear, the lack of supporting evidence or references makes the claim 3, as the authors may need to infer the benefits of the proposed change. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the readability of Tables 4 and 5. It recommends splitting each table into two, with one table per measure, and offers a concrete example of how to rearrange the columns. This feedback is clear and provides a straightforward way for the authors to enhance the clarity and organization of their data presentation. By addressing a specific issue with the tables, the comment offers valuable guidance that can help the authors improve the overall readability and effectiveness of their draft. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors could improve their paper by making the comparisons between the present work and the related work of Zemel et al. (2013) more systematic. It specifically recommends comparing the best performance of each method to provide a more comprehensive analysis. While the comment implies an action\u2014making the comparisons more systematic\u2014it does not provide explicit guidance on how to achieve this, such as suggesting specific metrics or analysis techniques to use. The action is concrete in terms of the desired outcome but lacks detailed instructions on execution, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the related work of Zemel et al. (2013) and the present paper, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be improved, namely making the comparisons more systematic with respect to the tuning of each method. This provides clear guidance on what the authors need to address. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper could be improved by making comparisons more systematic with respect to the tuning of each method. It references the work of Zemel et al. (2013) and suggests that the present paper should compare the best performance of each method. However, the comment lacks specific examples or detailed reasoning on how the current comparisons could be improved or what specific aspects need more systematic analysis. This makes the claim 3, as it provides a general direction but lacks the depth needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the comparisons between the present work and the related work of Zemel et al. (2013) could be made more systematic. It provides a clear and actionable suggestion to compare the best performance of each method, which would enhance the paper\"s originality and clarity. However, the comment could be more helpful if it offered additional guidance on how to conduct these systematic comparisons or what specific metrics or analyses could be used. Despite this, the feedback is 4 as it directs the authors to a meaningful enhancement of their draft. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to estimate the time complexity of the learning algorithm to prove its scalability properties. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific task that needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"time complexity of the learning algorithm,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the estimation of the time complexity to prove scalability properties. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the time complexity of the learning algorithm should be explicitly estimated to prove its scalability properties. This is a claim that requires justification, as it implies that the current estimation is insufficient or lacking. However, the comment does not provide any specific reasoning, examples, or references to support why this estimation is necessary or how it would impact scalability. Without additional context or evidence, the claim remains 1, as the authors would need more information to understand and address the issue effectively. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the time complexity of the learning algorithm should be explicitly estimated to prove its scalability properties. This feedback is clear and actionable, as it provides a direct suggestion for enhancing the paper\"s content. By addressing this point, the authors can strengthen their argument regarding the scalability of their algorithm, which is crucial for practical applications. However, the comment could be more helpful if it included additional guidance on how to estimate the time complexity or what specific aspects to consider. Overall, the comment is 4 as it directs the authors toward a meaningful improvement, but it could be more comprehensive with further guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the discussion around equation (10) is terse and not clearly explained. However, it does not provide any explicit or implicit suggestions on how to improve the explanation or what specific aspects need clarification. Without guidance on how to enhance the clarity or what additional information should be included, the authors are left without a clear understanding of what changes are needed. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"equation (10),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the terseness and lack of clarity in the discussion around equation (10). This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the discussion around equation (10) is terse and not clearly explained. However, it does not provide any specific examples or detailed reasoning to support this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the discussion around equation (10), noting that it is terse and not clearly explained. This feedback is 3 as it points out a potential area for improvement in the paper. However, it lacks depth and does not provide specific suggestions or guidance on how to enhance the clarity of the discussion. Without actionable advice, the authors may struggle to determine exactly what changes are needed to improve the explanation. Therefore, the comment is rated as 3, aligning with a score of 3."}
