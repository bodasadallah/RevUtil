{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the description of HIERENC is unclear and suggests that the input (h_i) to the temporal network is the average of the representations of all instantiations of context filled by every possible entity in the vocabulary. The reviewer questions the validity of this approach, stating that only one of these instantiations is likely to be correct and that this could introduce noise. While the comment identifies a potential issue with the description and suggests a possible reason for concern, it does not provide explicit guidance on how to clarify the description or address the potential noise issue. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the description and potentially explore alternative approaches. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"HIERENC,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by describing the unclear description of HIERENC and providing a detailed explanation of what is unclear. This provides clear guidance on what needs to be clarified or improved in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the description of HIERENC is unclear and suggests that the input (h_i) to the temporal network is the average of the representations of all instantiations of context filled by every possible entity in the vocabulary. The reviewer questions the validity of this approach, stating that only one of these instantiations is likely to be correct and that this could introduce noise. While the comment provides a logical reasoning for the potential issue, it lacks specific examples or references to support the claim fully. The authors would need to further explore and substantiate the reasoning to fully understand and address the concern. Therefore, the comment is 3, as it provides a logical basis but requires additional evidence or examples to be fully convincing.", "helpfulness_rationale": "The review comment identifies a specific issue with the description of HIERENC, suggesting that the input (h_i) to the temporal network is the average of the representations of all instantiations of context filled by every possible entity in the vocabulary. The reviewer questions the validity of this approach, noting that only one of these instantiations is likely to be correct and that this could introduce noise. This feedback is clear and actionable, as it highlights a potential weakness in the methodology and provides a specific critique that the authors can address by clarifying the description or exploring alternative approaches. However, the comment could be more helpful if it offered suggestions on how to improve the description or alternative methods to consider. Overall, the comment is 4, as it directs the authors to a critical area that needs clarification or improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential cognitive bias among NLP researchers, noting that instances where the authors perform worse are often labeled as \"on par,\" while instances where they perform better are labeled as \"better.\" The reviewer suggests that this wording should be corrected, implying that the authors should be more specific in their claims. However, the comment does not provide explicit guidance on how to correct this wording or what specific changes should be made. While the action is implicit, it is somewhat vague, as the authors are left to infer the necessary changes without detailed instructions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions line 791, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a potential cognitive bias among NLP researchers and suggests that the wording \"on par or better\" should be corrected. The comment provides a clear direction for improvement by specifying what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that there is a general cognitive bias among NLP researchers, noting that instances where the authors perform worse are often labeled as \"on par,\" while instances where they perform better are labeled as \"better.\" The reviewer suggests that this wording should be corrected. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the claim remains somewhat vague and 1. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a potential cognitive bias among NLP researchers, noting that instances where the authors perform worse are often labeled as \"on par,\" while instances where they perform better are labeled as \"better.\" This observation is relevant and could be a source of confusion for readers. The reviewer suggests that the wording should be corrected to avoid this bias, which is a clear and actionable piece of feedback. However, the comment could be more helpful if it provided specific examples or suggestions on how to rephrase the results to avoid this bias. Overall, the comment is 4 as it directs the authors to a potential issue and offers a constructive suggestion for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the interpretation of results shown in Table 3, specifically regarding the comparison of NVSB to GT Mel A for Chinese MOSQ and the overlap of 95% confidence intervals (CIs) between Baseline and NVSB for Chinese and English MOSV. While the comment highlights areas of confusion, it does not provide explicit instructions or suggestions on how the authors should address these issues. The authors are left to infer that they need to clarify the interpretation of these results, but without concrete guidance on how to do so, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issues with the interpretation of the results, particularly regarding the comparison of NVSB to GT Mel A for Chinese MOSQ and the overlap of 95% confidence intervals between Baseline and NVSB for Chinese and English MOSV. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements and questions about the interpretation of results in Table 3, specifically regarding the comparison of NVSB to GT Mel A for Chinese MOSQ and the overlap of 95% confidence intervals between Baseline and NVSB for Chinese and English MOSV. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises specific questions about the interpretation of results shown in Table 3, specifically regarding the comparison of NVSB to GT Mel A for Chinese MOSQ and the overlap of 95% confidence intervals between Baseline and NVSB for Chinese and English MOSV. While it identifies areas of confusion, it does not provide suggestions or guidance on how the authors might clarify or address these issues. The comment is 3 as it points out potential areas of concern, but it lacks actionable feedback or detailed advice on how to improve the draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors conduct an ablation study to evaluate the importance of the postprocessing steps proposed in the paper. While the comment implies that an ablation study is necessary, it does not explicitly instruct the authors to perform it. The suggestion is concrete in terms of what needs to be done, but it lacks explicit guidance on how to conduct the ablation study. Therefore, the comment is 4, as the authors know what action to take but need more detailed guidance on implementation.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"postprocessing steps\" and \"falsepositive neurons,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the paper, which is the lack of an ablation study to evaluate the importance of the postprocessing steps. The comment provides a clear suggestion for improvement, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper does not demonstrate the importance of the postprocessing steps proposed for filtering out \"falsepositive\" neurons. The reviewer suggests that an ablation study may be needed to evaluate this importance. However, the comment lacks specific examples or detailed reasoning to support the claim that the postprocessing steps are crucial or that an ablation study is necessary. The suggestion is 3, as it provides a logical next step for the authors to consider, but the lack of detailed justification or examples makes it difficult for the authors to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the paper\"s use of integrated gradients for attribution and the proposed postprocessing steps to filter out \"falsepositive\" neurons. It points out that the paper does not demonstrate the importance of these postprocessing steps, suggesting that an ablation study may be needed to evaluate their impact. This feedback is clear and actionable, as it provides a specific suggestion for improving the paper by conducting an ablation study. However, the comment could be more helpful if it offered additional guidance on how to conduct the ablation study or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors toward a meaningful improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about how an antecedent would be identified when the prediction is a pronoun, given the authors\" proposed method of matching the head of noun phrases. It questions the applicability of this method when the head word is not a pronoun. While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this concern. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify or modify their method to handle situations where the head word is not a pronoun. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a specific concern about the identification of antecedents when the prediction is a pronoun, particularly in the context of the authors\" proposed method of matching the head of noun phrases. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the proposed method and how it might not handle situations where the head word is not a pronoun. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the identification of antecedents when the prediction is a pronoun, specifically questioning the applicability of the authors\" proposed method of matching the head of noun phrases. The comment highlights a potential issue with the method\"s limitations, but it does not provide specific examples or detailed reasoning to fully substantiate the claim. While the authors are alerted to a potential weakness, the lack of detailed justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the authors\" proposed method for identifying antecedents, particularly when the prediction is a pronoun. It questions the applicability of the method when the head word is not a pronoun, which is a relevant and important point that could impact the effectiveness of the approach. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their method. While it highlights a potential weakness, it lacks actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of clarity regarding how the proposed models compare to models that only consider different senses but not sememes. It suggests that the MST baseline might be an example of such a model and notes that the emphasis is on soft vs. hard word sense disambiguation rather than on the comparison with other models. The comment implies that the paper would be stronger with the inclusion of more baselines based on related work. While the comment identifies a specific area for improvement, it does not provide explicit instructions on how to implement this suggestion, such as which models to include or how to structure the comparison. The action is implicit and somewhat vague, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed models\" and the \"MST baseline,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of clarity in comparing the proposed models to those that only consider different senses but not sememes. Additionally, it suggests the inclusion of more baselines based on related work to strengthen the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the comparison between the proposed models and models that only consider different senses but not sememes is unclear. It suggests that the MST baseline might be an example of such a model and notes that the emphasis is on soft vs. hard word sense disambiguation rather than on the comparison with other models. The comment implies that the paper would be stronger with the inclusion of more baselines based on related work. While the comment provides some reasoning by mentioning the MST baseline, it lacks specific examples or detailed comparisons to support the claim fully. The suggestion for more baselines is logical but could be strengthened with additional references or detailed explanations. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed evidence or examples to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the comparison of the proposed models with models that only consider different senses but not sememes. It suggests that the MST baseline might be an example of such a model and notes that the emphasis is on soft vs. hard word sense disambiguation rather than on the comparison with other models. The comment provides a clear and actionable suggestion for improvement by recommending the inclusion of more baselines based on related work. This feedback is valuable as it directs the authors to a specific area that needs further clarification and provides a concrete step to enhance the paper. However, the comment could be more helpful if it offered specific examples of models to include or detailed guidance on how to structure the comparison. Overall, the comment is 4, as it effectively guides the authors toward improving the clarity and comprehensiveness of their work."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a lack of clarity regarding how the frame similarity factors and attributes similarity factors are selected. However, it does not provide any explicit guidance or suggestions on how the authors might clarify this aspect of their work. The action is implicit, as the authors can infer that they need to provide more detailed information on the selection process, but it lacks concrete steps or examples to guide them. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment identifies a specific issue regarding the selection of frame similarity factors and attributes similarity factors, but it does not specify which part of the paper this issue is discussed in. The authors can infer that it might be related to the methodology or results sections, but without explicit references, the comment is weakly grounded. It is specific in detailing the issue of clarity regarding the selection process, which provides some guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the clarity of how frame similarity factors and attributes similarity factors are selected. However, it does not provide any specific examples, reasoning, or references to support this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the comment or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific area of confusion regarding the selection of frame similarity factors and attributes similarity factors. This feedback is 3 as it points out a potential issue that the authors need to address to improve the clarity and comprehensibility of their work. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might clarify this aspect of their methodology. To be more helpful, the comment could include examples or explanations of how similar factors are typically selected in related works, or it could suggest alternative ways to present this information. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies several weaknesses in the paper, specifically related to the experiments. It notes that the experiments are limited to an extremely lowresource regime, which may not be representative of realworld applications, and that sentence classification is an easier task. The reviewer suggests that the proposed augmentation method could be applied to more NLP tasks, but this is not demonstrated in the paper. While the comment highlights areas for improvement, it does not provide explicit or concrete actions for the authors to take. The feedback is 3 as it points out specific issues, but it lacks detailed guidance on how to address them. Therefore, the comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment identifies specific weaknesses in the paper, particularly related to the experiments. It mentions that the experiments are limited to an extremely lowresource regime, which may not be representative of realworld applications, and that sentence classification is an easier task. The reviewer also suggests that the proposed augmentation method could be applied to more NLP tasks, but this is not demonstrated in the paper. However, the comment does not specify which sections of the paper these issues are discussed in, making it weakly grounded. The feedback is specific in detailing what needs to be addressed, such as expanding the experiments to more realistic scenarios and demonstrating the method\"s applicability to other NLP tasks. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper\"s experiments are weak due to their focus on an extremely lowresource regime and an easier task (sentence classification). The reviewer suggests that the proposed augmentation method could be applied to more NLP tasks, which is not demonstrated in the paper. However, the comment lacks specific examples or references to support the claim that the experiments are insufficient or that the augmentation method could be applied to other tasks. The reasoning is somewhat vague, making it difficult for the authors to fully understand and address the critique. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies specific weaknesses in the paper, particularly related to the experiments. It points out that the experiments are limited to an extremely lowresource regime, which may not be representative of realworld applications, and that sentence classification is an easier task. The reviewer suggests that the proposed augmentation method could be applied to more NLP tasks, which is not demonstrated in the paper. While the comment highlights important areas for improvement, it lacks detailed guidance or suggestions on how the authors might address these issues or expand their experiments. The feedback is 3 as it provides insights into the limitations of the current work, but it could be more actionable with specific recommendations or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether concept map extraction should be treated as a separate task. It provides a rationale for both sides of the argument, suggesting that generic summarization systems build similar knowledge graphs and that the concept map becomes harder to distinguish with increasing node numbers. However, the comment does not explicitly instruct the authors to make a decision or take any specific action. The authors are left to infer that they might need to reconsider their approach to concept map extraction, but without concrete guidance on how to address this issue, the comment remains 3. Therefore, it aligns with a score of 3.", "grounding_specificity_rationale": "The comment raises a question about the necessity of treating concept map extraction as a separate task, providing a rationale for both sides of the argument. It mentions the use of generic summarization systems that build similar knowledge graphs and the potential difficulty in distinguishing concept maps with increasing node numbers. However, the comment does not specify which part of the paper this discussion is related to, making it weakly grounded. The authors can infer that it might be related to the methodology or results sections, but without explicit references, it is challenging to pinpoint the exact part of the paper being addressed. The comment is specific in its reasoning but lacks grounding, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the necessity of treating concept map extraction as a separate task, providing a rationale for both sides of the argument. It mentions the use of generic summarization systems that build similar knowledge graphs and the potential difficulty in distinguishing concept maps with increasing node numbers. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to further explore the reasoning and evidence to fully understand the basis of the question. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the necessity of treating concept map extraction as a separate task, providing a rationale for both sides of the argument. It mentions the use of generic summarization systems that build similar knowledge graphs and the potential difficulty in distinguishing concept maps with increasing node numbers. While the comment identifies a potential issue and provides some reasoning, it lacks specific suggestions or guidance on how the authors might address this concern. The feedback is 3 as it prompts the authors to reconsider their approach, but it could be more actionable with additional details or recommendations. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a specific issue with the text in lines 102106, stating that it is misleading. It points out that while the terms \"intersection\" and \"probs\" are true, the phrase \"such distribution\" cannot refer to the discussion in the above. However, the comment does not provide any guidance on how to address this issue or suggest alternative wording. The action is implicit and vague, as the authors are left to infer that they need to clarify the reference or rephrase the sentence, but without concrete instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lines 102106,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the text, pointing out that the phrase \"such distribution\" is misleading and cannot refer to the discussion in the above. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that lines 102106 are misleading because the phrase \"such distribution\" cannot refer to the discussion in the above. However, the comment does not provide any further explanation or reasoning to support this claim, such as what specific aspect of the discussion is being referred to or why the phrase is misleading. Without additional context or examples, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the text in lines 102106, pointing out that the phrase \"such distribution\" is misleading because it cannot refer to the discussion in the above. This feedback is clear and actionable, as it directs the authors to clarify the reference or rephrase the sentence to avoid confusion. However, the comment could be more helpful if it provided suggestions on how to rephrase the sentence or offered additional context to clarify the issue. Despite this, the comment is 4 as it effectively points out a potential misunderstanding in the text, prompting the authors to make a specific improvement. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the choice of datasets and the sufficiency of the time period (4 years) to study style shifts. It questions what kind of style shifts might occur within this timeframe and suggests that without these answers, it is difficult to appreciate what the model is capturing. While the comment implies that the authors should provide more information on the datasets and the time period, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to address these questions, but they are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the choice of datasets and the sufficiency of the time period (4 years) to study style shifts. However, it does not specify which part of the paper discusses these datasets or the time period, making it weakly grounded. The comment is specific in questioning the adequacy of the time period and the nature of style shifts that might occur, providing a clear direction for the authors to address. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the sufficiency of the time period (4 years) to study style shifts and asks for clarification on the kind of style shifts that might occur within this timeframe. However, it does not provide any specific reasoning, examples, or references to support the claim that 4 years is insufficient. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the critique. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the choice of datasets and the sufficiency of the time period (4 years) to study style shifts. It questions whether this timeframe is adequate to capture the desired style shifts and suggests that without addressing this issue, it is challenging to appreciate what the model is capturing. This feedback is 3 as it identifies a potential weakness in the study and prompts the authors to provide more context and justification for their dataset selection. However, the comment could be more helpful if it offered specific suggestions on how to address this issue or provided examples of alternative datasets or timeframes that might be more appropriate. Overall, the comment provides a starting point for improvement but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the claim \"there is no corresponding set of tools for the reinforcement learning setting\" is false, and it provides references to support this assertion. The comment is clear and direct, leaving no ambiguity about the action required. The authors know exactly what needs to be done, which is to address the false claim by providing a corresponding set of tools or references. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the part of the paper where the claim is made, \"there is no corresponding set of tools for the reinforcement learning setting.\" This allows the authors to accurately identify the section being addressed. The comment is also specific because it clearly specifies that the claim is false and provides references to support this assertion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement \"there is no corresponding set of tools for the reinforcement learning setting\" is false. It provides references to support this claim, which is a clear and explicit form of evidence. This makes the claim 5, as the authors can easily access the references to understand the basis of the reviewer\"s assertion. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment is 5 as it directly challenges a claim made in the paper, stating that \"there is no corresponding set of tools for the reinforcement learning setting\" is false. It provides references to support this assertion, which is a valuable resource for the authors to address the claim and potentially revise their work. By pointing out this error and offering evidence, the comment empowers the authors to make a significant improvement in their draft by correcting a critical misconception. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a missing link to similar work on Continuous Conditional Random Fields (CCRF) and Continuous Conditional Neural Fields (CCNF), which have a similar structure to the CRF and can perform exact inference. This feedback provides a clear and specific action for the authors to take, which is to include references to these works in their paper. The comment is explicit and provides concrete guidance on how to implement the suggested action, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the missing link to similar work on Continuous Conditional Random Fields (CCRF) and Continuous Conditional Neural Fields (CCNF), which have a similar structure to the CRF and can perform exact inference. This allows the authors to accurately identify the part of the paper that needs attention, specifically the section on related work or references. The comment is also specific because it clearly specifies what is missing, namely the inclusion of these works in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a link to similar work on Continuous Conditional Random Fields (CCRF) and Continuous Conditional Neural Fields (CCNF), which have a similar structure to the CRF and can perform exact inference. This claim is 3 as it references specific works that could be relevant to the paper. However, the comment does not provide detailed reasoning or examples of how these works are similar or how they could enhance the paper. The authors would need to investigate these references themselves to fully understand the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out the absence of a link to similar work on Continuous Conditional Random Fields (CCRF) and Continuous Conditional Neural Fields (CCNF). These works have a similar structure to the CRF and can perform exact inference, which could be relevant to the paper. By suggesting the inclusion of these references, the comment provides clear and actionable feedback that can help the authors enhance the context and relevance of their work. However, the comment could be more helpful if it explained why these references are important or how they relate to the paper\"s contributions. Overall, the comment is 4 as it directs the authors to a specific area for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that Section 4 is tersely written and suggests that it could have benefitted from a slower development for easier readability. However, it does not provide specific guidance on how to achieve this or what changes should be made to improve the section. The action is implicit and somewhat vague, as the authors are left to infer that they should expand the content or structure of Section 4 without concrete instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that the section is tersely written and suggests that it could have benefitted from a slower development for easier readability. This provides clear guidance on what needs to be addressed in the section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Section 4 is tersely written and suggests that it could have benefitted from a slower development for easier readability. However, the comment does not provide any specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered 2, as it lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The comment identifies a specific issue with the writing style of Section 4, noting that it is tersely written and could benefit from a slower development for easier readability. This feedback is 3 as it points out a potential area for improvement, suggesting that the authors might need to expand or clarify their explanations in that section. However, the comment lacks specific suggestions or guidance on how to achieve this slower development or what aspects of the section could be expanded. While it provides some direction, it does not offer detailed actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to include a table showing the distribution of video lengths across the dataset and to explain how they ensured a balanced representation of different video lengths across the 11 categories. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what needs to be done to address the issue. The comment is explicit and detailed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"benchmark\" and the \"distribution of videos of different lengths,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the inclusion of a table showing the distribution of video lengths across the dataset and an explanation of how the authors ensured a balanced representation of different video lengths across the 11 categories. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the distribution of videos of different lengths within the benchmark is crucial for assessing reasoning ability and robustness, but the paper does not provide relevant explanations. The reviewer suggests including a table showing the distribution of video lengths across the dataset and explaining how the authors ensured a balanced representation of different video lengths across the 11 categories. This feedback is 4 as it provides a clear rationale for the importance of the distribution and suggests specific actions to address the issue. However, it could be strengthened by referencing similar studies or benchmarks that support the need for this information. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment is 5 as it identifies a critical aspect of the paper that is not adequately addressed: the distribution of videos of different lengths within the benchmark. It highlights the importance of this distribution for assessing reasoning ability and robustness, and it provides specific suggestions for improvement, such as including a table showing the distribution of video lengths across the dataset and explaining how the authors ensured a balanced representation. This feedback is actionable and detailed, offering clear guidance on how the authors can enhance their draft by providing necessary information and explanations. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly advises the authors to take a cautious approach regarding their contribution until the promised dataset is made publicly available. This is a clear and direct action for the authors to take, as it specifies the need to wait for the dataset to be accessible before making any claims or contributions based on it. The comment provides a concrete step for the authors to follow, making it 5.", "grounding_specificity_rationale": "The comment addresses the issue of the promised dataset not being publicly available, which is a specific concern regarding the contribution of the paper. However, it does not specify which part of the paper discusses the dataset or where the promise was made, making it weakly grounded. The comment is specific in its request for caution until the dataset is openly accessible, but without explicit references to the paper, the authors may struggle to pinpoint the exact sections needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the promised dataset has not been made publicly available, which is a factual statement. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment highlights a critical issue regarding the availability of the promised dataset, which is essential for the paper\"s contribution. By pointing out the lack of public accessibility, the reviewer encourages the authors to take a cautious approach until the dataset is openly accessible. This feedback is clear and actionable, as it prompts the authors to address a significant concern that could impact the credibility and utility of their work. However, the comment could be more helpful if it provided suggestions on how to address this issue or what steps the authors should take to ensure the dataset\"s accessibility. Overall, the comment is 4 as it directs the authors\" attention to a crucial aspect of their work that needs attention."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to mention related work on modular networks for VQA, specifically referencing A. This provides a clear and direct action for the authors to take, ensuring that their discussion of related work is comprehensive and accurate. The comment also highlights the importance of this action, as it helps to avoid misrepresenting the state of the art in modular architectures for VQA. The feedback is explicit and provides concrete guidance on what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"related work\" and \"modular networks for VQA,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the need to mention related work on modular networks for VQA, which is currently missing, and highlights the potential misrepresentation of the state of the art in modular architectures for VQA. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the introduction does not mention related work on modular networks for VQA, which could lead to a misrepresentation of the state of the art. The reviewer provides a specific suggestion to include this work, which is a clear and actionable recommendation. However, the comment does not provide any references or examples of the relevant work, which would strengthen the claim. Without these references, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is 3, as it provides a logical reasoning but lacks specific evidence or references.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by recommending the inclusion of related work on modular networks for VQA. This is important because it ensures that the introduction accurately represents the state of the art in modular architectures for VQA, avoiding potential misrepresentations. The comment is specific and provides a concrete reference (A) to guide the authors in their revisions. This level of detail and guidance makes the comment 5, as it empowers the authors to make a significant improvement to their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy in the ablation experiment, noting that the performance without reinforcement learning dropped lower than without dependency tree. It also points out that the tables do not include cases where both dependency tree and reinforcement learning are not used. While the comment identifies a potential issue with the experimental setup, it does not provide explicit guidance on how to address this problem or what specific changes should be made to improve the clarity or completeness of the tables. The action is implicit and somewhat vague, as the authors can infer that they need to ensure the tables are comprehensive, but they are not given concrete steps on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"ablation experiment\" and the \"two tables,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out a discrepancy in the ablation experiment, noting that the performance without reinforcement learning dropped lower than without dependency tree, and it highlights the omission of cases where both dependency tree and reinforcement learning are not used. This provides clear guidance on what needs to be addressed in the tables. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point highlights a discrepancy in the ablation experiment, noting that the performance without reinforcement learning dropped lower than without dependency tree. It also points out that the tables do not include cases where both dependency tree and reinforcement learning are not used. This is a factual observation about the content of the tables, which requires no verification or justification. The comment does not contain subjective opinions, suggestions, or claims that need to be verified. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the ablation experiment, noting that the performance without reinforcement learning dropped lower than without dependency tree. It also points out that the tables do not include cases where both dependency tree and reinforcement learning are not used. This feedback is clear and actionable, as it highlights a potential oversight in the experimental setup and suggests that the authors should ensure the tables are comprehensive. By addressing these points, the authors can improve the clarity and completeness of their results, which is valuable for readers and reviewers. However, the comment could be more helpful if it provided suggestions on how to address the issue or offered additional context on why this oversight is important. Overall, the comment is 4, as it directs the authors to a specific area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a confusion regarding the notation and the explicit split between \"static\" and temporal features, suggesting that more information is needed. It specifically mentions the variables \"S\" and \"Xt\" and implies that the authors should provide additional information to clarify these terms. While the comment identifies the need for clarification, it does not explicitly instruct the authors to add this information or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the notation, but they are not given detailed instructions on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment identifies a specific issue with the notation and the explicit split between \"static\" and temporal features, suggesting that more information is needed. It mentions the variables \"S\" and \"Xt,\" which provides some grounding as the authors can infer that this relates to the methodology or results sections. However, the comment does not specify which part of the paper this issue occurs in, making it weakly grounded. The comment is specific in detailing what is confusing and what additional information is needed, but it lacks full grounding because it does not explicitly mention the section or figure where this issue arises. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the notation and the explicit split between \"static\" and temporal features are confusing, suggesting that more information is needed. The reviewer provides a specific example by mentioning the variables \"S\" and \"Xt,\" which indicates a lack of clarity in the paper. However, the comment does not provide any further explanation or references to support why this confusion exists or how it could be resolved. The lack of detailed reasoning or examples makes the claim 3, as the authors would need to infer the exact nature of the confusion and how to address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the notation and the explicit split between \"static\" and temporal features, suggesting that more information is needed to clarify the variables \"S\" and \"Xt.\" This feedback is 3 as it points out a potential source of confusion for readers and prompts the authors to provide additional information to enhance clarity. However, the comment could be more helpful if it offered suggestions on how to clarify the notation or provided examples of how similar issues have been addressed in other papers. Overall, the comment is 3 as it directs the authors to a specific area needing improvement but lacks detailed guidance for implementation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment acknowledges that the paper deals with many graph notions, which can make it challenging to understand, but it also notes that the writing is generally good. It suggests that more details could be provided, specifically mentioning the definition of the resistance distance and more explanations for Algorithm 1, including brief sentences defining A_t, Y_t, and so on. While the comment implies that the authors should provide more details, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement the suggested improvements. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment provides some specific feedback, suggesting that more details could be provided, such as the definition of the resistance distance and more explanations for Algorithm 1. However, it does not specify which part of the paper these details should be added to, making it weakly grounded. The authors might infer that it relates to the sections discussing graph notions or the algorithm, but this inference is not direct. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point acknowledges that the paper deals with many graph notions, which can make it challenging to understand, but it also notes that the writing is generally good. It suggests that more details could be provided, specifically mentioning the definition of the resistance distance and more explanations for Algorithm 1. However, the comment lacks specific examples or references to support the claim that more details are needed, making it 3. The authors would need to infer the exact areas where more detail is required, which could be challenging. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges that the paper deals with many graph notions, which can make it challenging to understand, but it also notes that the writing is generally good. It provides specific suggestions for improvement, such as providing more details on the definition of the resistance distance and offering more explanations for Algorithm 1, including brief sentences defining A_t, Y_t, and so on. These suggestions are clear and actionable, offering the authors concrete steps to enhance the clarity and comprehensibility of their work. However, the comment could be more helpful if it included additional guidance or examples on how to effectively incorporate these details. Overall, the feedback is 4 as it directs the authors toward specific areas for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should introduce specific aspects of the model that are relevant to the example model being discussed. It provides a concrete example of what should be clarified, such as the fact that the model operates in a setting with finite subdivisions for certain parameters and that these parameters are bounded on one side. This feedback is explicit and provides clear guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions line 132, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be introduced, namely the specific aspects of the model that are relevant to the example model being discussed. The comment specifies that certain parameters are bounded on one side and that the model operates in a setting with finite subdivisions. This level of detail provides the authors with a clear understanding of what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors should clarify specific aspects of the model, such as the finite subdivisions for certain parameters and the bounded nature of acceleration and scaling parameters. While the comment provides a logical reasoning for why this clarification is necessary, it does not include specific examples or references to support the claim. This makes the comment 3, as it lacks detailed evidence or references to fully substantiate the need for clarification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors introduce the aspects of the specific model that are specific to the example model being discussed. It highlights the need to clarify that the model operates in a setting with finite subdivisions for certain parameters and that these parameters are bounded on one side. This feedback is clear and offers a concrete way for the authors to enhance the clarity and specificity of their paper. By addressing these points, the authors can improve the comprehensibility and relevance of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the required condition on the learning rate, specifically its scalability and the unrealistic nature of the condition. The reviewer acknowledges the need for a way to characterize the benefit of large learning rates but questions the practicality of the condition. While the comment identifies an issue, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve their draft. The action is implicit and somewhat vague, as the authors are left to infer that they need to reconsider the condition or find an alternative approach. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the required condition on the learning rate, specifically its scalability and the unrealistic nature of the condition. However, it does not explicitly mention which part of the paper discusses this condition, making it weakly grounded. The comment is specific in detailing the issue with the condition and the need for a more realistic approach. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the required condition on the learning rate, which scales with the number of samples, is not scalable and is not seen in practice. The reviewer provides a logical reasoning by stating that this condition would lead to unreasonably large learning rates when working with largescale datasets. However, the comment lacks specific examples or references to support the claim that this condition is not seen in practice. While the reasoning is sound, the absence of concrete evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the required condition on the learning rate, which scales with the number of samples. It points out that this condition is not scalable and is not seen in practice, leading to unreasonably large learning rates when working with largescale datasets. The reviewer acknowledges the need for a way to characterize the benefit of large learning rates but questions the practicality of the condition itself. While the comment highlights a critical issue, it does not provide specific suggestions or alternatives for addressing this concern. The feedback is 3 as it directs the authors\" attention to a potential weakness in their approach, but it lacks actionable guidance for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should use a more convincing setting for their unlabeled data, similar to the one used in the Adaptive Semisupervised Learning for Crossdomain Sentiment Classification paper by He et al. (2018). The comment explicitly states the action to take, which is to use a more convincing setting, and provides a specific reference to guide the authors on how to implement this change. This level of detail makes the action 5, as the authors know exactly what needs to be done and where to find guidance. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"unlabeled data (2000) from the preprocessed Amazon review dataset (Blitzer version),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the label distribution of the unlabeled data and suggests using a more convincing setting as done in a referenced paper. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the unlabeled data from the preprocessed Amazon review dataset is perfectly balanced, which is impractical in realworld applications. The reviewer suggests using a more convincing setting as done in a referenced paper, providing a specific reference to support the claim. This level of detail and the inclusion of an external reference make the claim 4, as it provides a clear basis for the suggestion. However, the comment could be strengthened by further elaborating on why the current setting is impractical or how the referenced paper\"s approach addresses this issue. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the unlabeled data used in the paper, noting that it is perfectly balanced, which is impractical in realworld applications. It suggests that the authors should use a more convincing setting, as done in a referenced paper, to address this issue. This feedback is clear and actionable, providing the authors with a specific direction for improvement by referencing a relevant study. However, the comment could be more helpful if it explained why the current setting is impractical or how the referenced paper\"s approach addresses this issue. Overall, the comment is 4 as it offers a clear path for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about sampling from the DPP when the eigenfunctions e_n are inaccessible, as mentioned in Equation (10) on line 130. The reviewer compares this issue to sampling from the leverage score, suggesting that it may not be easier than sampling from the leverage score. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their draft. The action is implicit and vague, as the authors are left to infer that they need to clarify the sampling process or provide additional information, but without concrete steps or examples, the action remains unclear. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq (10) line 130,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the clarity of sampling from the DPP when the eigenfunctions e_n are inaccessible. The comment further compares this issue to sampling from the leverage score, suggesting that it may not be easier than sampling from the leverage score. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of sampling from the DPP when the eigenfunctions e_n are inaccessible, as mentioned in Equation (10) on line 130. The reviewer compares this issue to sampling from the leverage score, suggesting that it may not be easier than sampling from the leverage score. However, the comment lacks specific examples or detailed reasoning to support the claim that sampling from the DPP is more difficult. Without additional context or references, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient evidence or explanation to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of sampling from the DPP when the eigenfunctions e_n are inaccessible, as mentioned in Equation (10) on line 130. It compares this issue to sampling from the leverage score, suggesting that it may not be easier than sampling from the leverage score. This feedback is clear and actionable, as it points out a potential area of confusion in the paper and prompts the authors to clarify the sampling process. However, the comment could be more helpful if it provided additional guidance or suggestions on how to address this issue, such as recommending specific methods or examples to clarify the sampling process. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with further guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the paper, noting that the observations presented do not evaluate their generalizability to fewshot learners beyond Prototypical Networks. This suggests that the scope of the submission\"s contributions may be limited in terms of understanding the properties of episodic training. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or evaluate the generalizability of their observations. The action is implicit and vague, as the authors are left to infer that they need to expand their evaluation to include other fewshot learners, but without concrete steps or examples, the action remains unclear. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the issue of generalizability of the observations presented in the paper, specifically questioning whether they extend to fewshot learners beyond Prototypical Networks. However, it does not specify which part of the paper this critique pertains to, such as a particular section or experiment, making it weakly grounded. The comment is specific in its critique of the lack of evaluation of generalizability, but without clear grounding, the authors may struggle to identify the exact part of the paper that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the observations presented in the paper do not evaluate their generalizability to fewshot learners beyond Prototypical Networks, which limits the scope of the submission\"s contributions. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The lack of evidence or detailed justification makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the paper by pointing out that the observations presented do not evaluate their generalizability to fewshot learners beyond Prototypical Networks. This critique highlights a potential gap in the scope of the submission\"s contributions, suggesting that the paper may not fully explore the properties of episodic training. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or expand their evaluation to include other fewshot learners. While it points out a relevant area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight into a potential weakness but lacks depth and specificity in its feedback."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the potential differences in the contributions of different modalities across instances, specifically mentioning instances with good performance in modality A versus modality B. It questions how Equation 3 addresses this issue by removing the modal subset of all instances. However, the comment does not provide explicit guidance or suggestions on how the authors should address this concern. While it identifies an area of potential improvement, it lacks concrete steps or actions for the authors to take. The feedback is implicit and somewhat vague, leaving the authors with a general idea of what needs to be addressed but without detailed guidance on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the potential differences in the contributions of different modalities across instances, specifically mentioning instances with good performance in modality A versus modality B. It questions how Equation 3 addresses this issue by removing the modal subset of all instances. However, the comment does not specify which part of the paper discusses Equation 3 or where this issue is addressed, making it difficult for the authors to pinpoint the exact section needing revision. While the authors might have an idea of where this discussion could be, the lack of explicit references makes it weakly grounded. The comment is specific in detailing the issue with Equation 3 and the potential problem with modal subsets, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the potential differences in the contributions of different modalities across instances, specifically mentioning instances with good performance in modality A versus modality B. It questions how Equation 3 addresses this issue by removing the modal subset of all instances. However, the comment lacks specific examples or detailed reasoning to support the claim that this issue is problematic or needs further exploration. The lack of evidence or detailed explanation makes it difficult for the authors to understand the basis of the concern, rendering the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper regarding the contribution of different modalities across instances. It highlights a specific concern about instances with good performance in modality A versus modality B, and questions how Equation 3 addresses this issue by removing the modal subset of all instances. This feedback is 3 as it points out a potential weakness in the paper and prompts the authors to consider how to address this issue. However, the comment lacks specific suggestions or guidance on how to resolve the problem, such as proposing alternative methods or analyses. While it provides some insight into an area that needs attention, it does not offer comprehensive or actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a specific issue with the proposed objective equation (Eq. 2) in line 128, noting that it requires optimization over both the parameters of the transformation phi and the shared model theta_S. The comment also points out that the effect on the number of parameters compared to prior work, such as AlignFlow (Grover et al., 2019), has not been discussed clearly. This feedback provides a clear and explicit action for the authors to take: they should discuss the effect of the proposed objective equation on the number of parameters compared to prior work. The comment is specific and provides a concrete direction for improvement, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq. 2 in line 128,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the need for a clearer discussion on the effect of the proposed objective equation on the number of parameters compared to prior work, such as AlignFlow (Grover et al., 2019). This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the effect of the proposed objective equation on the number of parameters compared to prior work has not been discussed clearly. This claim is 3 as it highlights a specific area where the paper lacks clarity. However, it does not provide detailed reasoning or specific examples from prior work to support the claim, which would strengthen the justification. The authors would need to infer the importance of this comparison based on the comment alone. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed objective equation (Eq. 2) in line 128, noting that it requires optimization over both the parameters of the transformation phi and the shared model theta_S. The comment points out that the effect on the number of parameters compared to prior work, such as AlignFlow (Grover et al., 2019), has not been discussed clearly. This feedback is clear and actionable, as it directs the authors to address the gap in their discussion by comparing the number of parameters with prior work. By providing this specific guidance, the comment is 5, as it empowers the authors to make a significant improvement in their draft. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point consists of two parts. The first part is a question about the implications of Eq. 4, asking if it means that u^l in Eq. 3 tends to be 1. This is a clarification question that does not provide any explicit or implicit action for the authors to take. The second part critiques the improvement of the designed solutions in Table 5, noting that the proposed solution provides only a marginal improvement on the OfficeHome dataset. This feedback is 3 as it points out a potential limitation in the results, but it lacks specific guidance on how the authors might address this issue or improve their methodology. Overall, the comment is 3, as it raises questions and points out a potential limitation but does not provide concrete steps for improvement.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq. 4\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the implications of Eq. 4 and critiques the improvement of the designed solutions in Table 5, providing a clear example of the marginal improvement on the OfficeHome dataset. This level of detail helps the authors understand what needs to be addressed in their draft. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts. The first part is a question about the implications of Eq. 4, asking if it means that u^l in Eq. 3 tends to be 1. This is a logical question that requires no verification, as it is a request for clarification. The second part critiques the improvement of the designed solutions in Table 5, noting that the proposed solution provides only a marginal improvement on the OfficeHome dataset. This is a factual statement without a claim or opinion, as it describes the results without suggesting changes or making subjective judgments. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises two points. First, it questions the implications of Eq. 4, asking if it means that u^l in Eq. 3 tends to be 1. This is a logical question that prompts the authors to clarify their mathematical reasoning. Second, it critiques the improvement of the designed solutions in Table 5, noting that the proposed solution provides only a marginal improvement on the OfficeHome dataset. This feedback is 3 as it points out a potential limitation in the results, but it lacks specific suggestions or guidance on how the authors might address this issue or improve their methodology. Overall, the comment provides some insight but could be more actionable with additional details or suggestions for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point states that using a volumetric representation in the deformation field is not a novel idea, referencing the work of VolumeDeform 1. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue of nonnovelty or how to improve the draft based on this information. The comment lacks actionable details, leaving the authors without a clear understanding of what steps to take to enhance their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of a volumetric representation in the deformation field, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it references the work of VolumeDeform 1, which provides a clear context for the nonnovelty claim. This makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that using a volumetric representation in the deformation field is not a novel idea, referencing the work of VolumeDeform 1. This claim is supported by the inclusion of a specific reference, which provides a clear basis for the assertion. However, the comment could be strengthened by providing more detailed information about how VolumeDeform 1 uses volumetric grids or how it relates to the current work. Overall, the claim is 4 due to the reference, but it could be more robust with additional context or explanation. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment points out that using a volumetric representation in the deformation field is not a novel idea, referencing the work of VolumeDeform 1. While this information is relevant, the comment lacks depth and does not provide any actionable feedback or suggestions for improvement. It does not offer guidance on how the authors might address this issue or how it could impact their work. As a result, the comment is 3, as it provides a general insight but does not fully support the authors in enhancing their draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review comment points out a specific line in the paper (L.490) where the authors mention taking the embedding of the first subword token as the verb embedding. It suggests that it is also common to average over subword representations, as demonstrated by a reference to Hewitt and Manning (2019, footnote 4). While the comment highlights a potential alternative approach, it does not explicitly instruct the authors to adopt this method or provide detailed guidance on how to implement it. The action is implicit and somewhat vague, as the authors can infer that they might consider averaging over subword representations but are not given concrete steps on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L.490,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular statement about taking the embedding of the first subword token as the verb embedding and suggests an alternative approach by referencing Hewitt and Manning (2019, footnote 4). This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point claims that it is common to average over subword representations, as demonstrated by a reference to Hewitt and Manning (2019, footnote 4). The inclusion of a specific reference provides a clear and verifiable basis for the claim, making it 5. The reference to a specific footnote in a published work adds credibility to the claim, ensuring that the authors can easily verify the assertion. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the paper by pointing out a common practice in the field of averaging over subword representations, as demonstrated by a reference to Hewitt and Manning (2019, footnote 4). This feedback is actionable and offers a concrete alternative approach that the authors can consider to enhance their work. By suggesting a specific reference and method, the comment is 5 as it empowers the authors to make a meaningful improvement to their draft. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should conduct calibration curves to demonstrate the consistency between predicted scores and actual risks, which is a crucial aspect for the clinical scoring system. It also encourages the authors to prove the feasibility of the generated scoring system and discuss the differences between the traditional method and their own approach. While the comment implies specific actions, it does not provide detailed guidance on how to conduct these analyses or what specific aspects to focus on. The authors can infer the need for additional analyses but may struggle to determine the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"model AUC\" and \"calibration curves,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as demonstrating the consistency between predicted scores and actual risks, conducting calibration curves, and discussing the differences between the traditional method and the proposed approach. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the model AUC can assess discriminant ability but may not demonstrate consistency between predicted scores and actual risks, which is crucial for clinical scoring systems. The reviewer encourages the use of calibration curves to show agreement and questions the feasibility of the generated scoring system. However, the comment lacks specific examples, references, or detailed reasoning to support the claim about the limitations of AUC and the need for calibration curves. This makes the claim 3, as it provides a general direction but requires more detailed justification or evidence to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential limitation in the use of model AUC for assessing discriminant ability, noting that it may not adequately demonstrate the consistency between predicted scores and actual risks. It suggests that calibration curves could be used to show agreement, which is crucial for clinical scoring systems. The comment also encourages the authors to prove the feasibility of their generated scoring system and discuss the differences between their method and traditional approaches. While the feedback highlights important areas for improvement, it could be more helpful by providing specific guidance on how to conduct the calibration curves or discuss the differences. Overall, the comment is 4 as it directs the authors to address critical aspects of their work, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises several concerns about the experiments, questioning the strength and fairness of the baselines used. It suggests that the authors should use the default settings of the baselines in the literature and include baselines related to BO with discrete and categorical variables. Additionally, it points out the need to discuss limitations and societal impacts of the proposed approach. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to address these issues, such as which baselines to include or how to discuss limitations. The actions are implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment addresses several issues related to the experiments, including the strength and fairness of the baselines, the use of position kernels, and the absence of certain baselines. It also mentions the need to discuss limitations and societal impacts. However, the comment does not specify which sections of the paper these issues pertain to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as using the default settings of baselines and including specific baselines related to BO with discrete and categorical variables. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several claims, including the lack of strength and fairness in the experiments, the absence of certain baselines, and the need to discuss limitations and societal impacts. However, the comment lacks specific examples or detailed reasoning to support these claims. It provides general observations but does not offer concrete evidence or references to substantiate the claims. This makes the comment 3, as it highlights areas for improvement but lacks the necessary detail to fully substantiate the claims. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper. It questions the strength and fairness of the experiments, suggesting that the authors should use the default settings of the baselines in the literature and include baselines related to BO with discrete and categorical variables. Additionally, it points out the need to discuss limitations and societal impacts of the proposed approach. While the comment highlights important areas for enhancement, it lacks specific guidance or suggestions on how to address these issues, such as which baselines to include or how to discuss limitations. This limits the comment\"s usefulness, as it provides insight but does not offer actionable steps for improvement. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the lack of insight into why all sparsity patterns perform similarly and suggests that this might be a unique aspect of the sparsity detection problem or a general characteristic of GNNs. It also points out a typo in the text, suggesting a correction. While the comment identifies a potential area for further exploration and provides a specific correction, it does not offer explicit guidance on how the authors should address the lack of insight or conduct further analysis. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the reasons behind the similar performance and consider whether it is specific to the sparsity detection problem or a broader issue with GNNs. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of insight into why all sparsity patterns perform similarly and suggesting that this might be a unique aspect of the sparsity detection problem or a general characteristic of GNNs. Additionally, it corrects a typo in the text, which further clarifies the specific issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the lack of insight into why all sparsity patterns perform similarly and suggests that this might be a unique aspect of the sparsity detection problem or a general characteristic of GNNs. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, noting that all sparsity patterns seem to perform similarly without providing insight into why this is the case. It raises a question about whether this is a unique aspect of the sparsity detection problem or a general characteristic of GNNs. This feedback is 3 as it prompts the authors to consider the implications of their findings and potentially explore further analysis or discussion to provide more insight into the results. However, the comment could be more helpful if it offered specific suggestions or guidance on how to address this issue or what additional analysis might be beneficial. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that Section 6 could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts. While the comment implies that the authors should include a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to conduct the comparison or what aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that Section 6 could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts. However, it does not specify which part of Section 6 is being addressed, making it weakly grounded. The comment is specific in suggesting a comparison with prior efforts, which provides a clear direction for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the related work section could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts. However, the comment does not provide specific examples or references to support this claim, nor does it explain why such a comparison would be beneficial. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a potential area for improvement in the paper, suggesting that Section 6 could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts. This feedback is 3 as it points out a specific aspect of the related work section that could be strengthened by including a comparative analysis. However, the comment lacks detailed guidance on how to conduct this comparison or what specific aspects should be highlighted. While it provides a direction for improvement, it does not offer actionable steps or examples, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the performance is likely related to the number of scenarios used for training and recommends examining the performance with different numbers of scenarios. However, it does not provide explicit instructions on how to conduct this analysis or what specific steps the authors should take to address this suggestion. The action is implicit and somewhat vague, as the authors can infer that they need to explore the impact of varying the number of scenarios, but they are not given concrete guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the performance is closely related to the number of scenarios used for training and recommends examining the performance with different numbers of scenarios. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or analysis. The authors can infer that it relates to the experimental setup or results, but the lack of explicit grounding makes it difficult to pinpoint the exact part of the paper being addressed. The comment is specific in suggesting an analysis of performance with varying numbers of scenarios, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the performance is closely related to the number of scenarios used for training and recommends examining the performance with different numbers of scenarios. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the performance is likely related to the number of scenarios used for training and recommends examining the performance with different numbers of scenarios. This feedback is 3 as it identifies a potential area for further analysis and improvement in the paper. However, it lacks specific guidance on how to conduct this analysis or what specific numbers of scenarios should be considered. While it provides a direction for exploration, the comment could be more actionable with additional details or examples. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the relationship between generating a quality label and the model\"s ability to predict it. It suggests that disturbances in the training data might affect the model\"s ability to generate correct quality labels. However, the comment does not provide explicit guidance or suggestions on how the authors should address this concern or improve their draft. The action is implicit and vague, as the authors are left to infer that they should consider the impact of disturbances on the model\"s performance but are not given specific steps to take. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the relationship between generating a quality label and the model\"s ability to predict it, suggesting that disturbances in the training data might affect the model\"s performance. However, it does not specify which part of the paper this issue pertains to, such as a specific section, experiment, or methodology. The authors can infer that it relates to the model\"s performance evaluation or training process, but the lack of explicit grounding makes it difficult to pinpoint the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what needs to be addressed or improved. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a question about the relationship between generating a quality label and the model\"s ability to predict it, suggesting that disturbances in the training data might affect the model\"s performance. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. It lacks specific examples or detailed explanations that would help the authors understand the basis of the question or how to address it. As a result, the claim is 1, as it does not provide sufficient information for the authors to make improvements based on the feedback. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the relationship between generating a quality label and the model\"s ability to predict it. It suggests that disturbances in the training data might affect the model\"s performance, which is a valid concern that could impact the robustness and accuracy of the model. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this issue or conduct further experiments to validate the model\"s performance under different conditions. While it identifies a potential area for improvement, the feedback is incomplete and does not offer detailed insights or steps for the authors to take. Therefore, the comment is 3, as it prompts the authors to consider a critical aspect of their work but does not fully support them in making improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the bounded noise assumption as somewhat restrictive in the context of stochastic optimization literature. It mentions several efforts to extend these noise conditions, referencing specific works by A. Khaled and P. Richt\"arik, and R. Gower, O. Sebbouh, and N. Loizou. However, the comment does not provide explicit guidance or suggestions for the authors on how to address this issue in their own work. While it identifies a potential area for improvement, it lacks actionable details on how the authors might incorporate these extensions or address the bounded noise assumption. As a result, the comment is 3, as it points out a limitation but does not offer concrete steps for improvement.", "grounding_specificity_rationale": "The comment addresses the bounded noise assumption, which is a specific aspect of the paper. However, it does not specify which part of the paper discusses this assumption, making it weakly grounded. The comment is specific in mentioning efforts to extend these noise conditions and references specific works by A. Khaled and P. Richt\"arik, and R. Gower, O. Sebbouh, and N. Loizou. This provides a clear direction for the authors to consider in their work. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the bounded noise assumption is somewhat restrictive in the stochastic optimization literature and references several efforts to extend these noise conditions. The references provided are specific and support the claim, making it 4. However, the comment could be strengthened by providing more detailed explanations or examples from the referenced works to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment highlights a potential limitation in the paper, specifically the bounded noise assumption, which is somewhat restrictive in the stochastic optimization literature. It references several efforts to extend these noise conditions, providing specific references to works by A. Khaled and P. Richt\"arik, and R. Gower, O. Sebbouh, and N. Loizou. This feedback is valuable as it informs the authors about existing work in the field and suggests that they might consider incorporating these extensions into their own work. However, the comment could be more helpful if it offered specific guidance on how to integrate these extensions or addressed the implications of these assumptions in the context of the paper. Overall, the comment is 4 as it provides relevant information and references, but it could be more comprehensive with additional suggestions for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights several writing issues, such as grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not provide specific examples or guidance on how to address these issues. The comment lacks explicit instructions or suggestions for improvement, leaving the authors uncertain about what actions to take. Without concrete details or examples, the authors may struggle to identify and correct the issues effectively. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights writing issues such as grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not specify which parts of the paper these issues are found in, making it difficult for the authors to pinpoint the exact sections that need attention. Additionally, the comment lacks specificity regarding which grammatical errors, mathematical symbols, or unclear sentences are problematic. Without detailed guidance, the authors cannot effectively address the issues. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper contains severe writing issues, such as grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not provide specific examples or detailed evidence to support these claims. Without concrete examples or references to particular sections of the paper, the authors may find it challenging to understand and address the issues effectively. The lack of specific details makes the claim difficult to verify, resulting in a score of 1.", "helpfulness_rationale": "The review comment identifies several writing issues, such as grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not provide specific examples or detailed guidance on how to address these issues. Without concrete suggestions or actionable feedback, the authors are left with a general understanding of the problems but without a clear path to improvement. This lack of specificity and actionable advice makes the comment 2, as it does not effectively guide the authors in enhancing their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment acknowledges the novelty of using energy models for image generation compared to GANs and VAEs, and encourages further exploration. It also points out that the motivation and goals of the model are similar to those of a prior VAE paper, as detailed in the related work review part. However, the comment does not provide explicit guidance on how the authors should address this similarity or how it might impact their work. The action is implicit, as the authors need to infer that they should address the similarity to the prior VAE paper, but it is not concrete, as it lacks specific instructions on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of energy models for image generation, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the similarity of the model\"s motivation and goals to those of a prior VAE paper, as detailed in the related work review part. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point acknowledges the novelty of using energy models for image generation compared to GANs and VAEs, and encourages further exploration. It also notes that the motivation and goals of the model are similar to those of a prior VAE paper, as detailed in the related work review part. The comment provides a logical reasoning by comparing the model to existing work, which supports the claim that the use of energy models is less explored. However, it does not provide specific references or detailed comparisons to substantiate the claim fully. Therefore, the comment is 4, as it provides a solid basis for the claim but lacks comprehensive evidence or references.", "helpfulness_rationale": "The review comment acknowledges the novelty of using energy models for image generation compared to GANs and VAEs, which is a positive observation. It also points out that the motivation and goals of the model are similar to those of a prior VAE paper, as detailed in the related work review part. This feedback is valuable as it highlights a potential overlap with existing work, prompting the authors to consider how their approach differs or adds value. However, the comment could be more helpful if it provided specific suggestions on how the authors might differentiate their work or address the similarity. Overall, the comment is 4 as it identifies a potential area for improvement and provides some direction, but it could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a gap in the paper regarding the application of imitation learning and the challenges in obtaining labeled data. It suggests that the authors should conduct experiments to determine if there are difficulties in obtaining the corresponding data and how performance changes with varying labeled data sizes. While the comment implies that the authors should conduct these experiments, it does not provide explicit instructions on how to do so. The action is concrete in terms of what needs to be done, but it lacks detailed guidance on execution. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment addresses the application of imitation learning and the challenges in obtaining labeled data. However, it does not specify which part of the paper discusses imitation learning or where the experiments on data acquisition and performance changes are lacking. This makes it difficult for the authors to pinpoint the exact sections that need attention. While the comment is specific in terms of the issues it raises, it lacks grounding as it does not clearly identify the parts of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there are no experiments on the difficulties in obtaining labeled data for imitation learning and how performance changes with varying labeled data sizes. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed evidence or justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the application of imitation learning and the challenges in obtaining labeled data. It suggests that the authors should conduct experiments to determine if there are difficulties in obtaining the corresponding data and how performance changes with varying labeled data sizes. This feedback is clear and actionable, as it provides a specific area for improvement and a direction for further experimentation. However, the comment could be more helpful if it offered suggestions on how to design these experiments or what specific aspects to focus on. Overall, the comment is 4 as it guides the authors toward enhancing their draft by addressing a critical aspect of their methodology."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential issue with the use of the term \"certificate\" in some contexts, suggesting that it might be misinterpreted due to its strong meaning in complexity theory. However, the comment does not provide explicit guidance on how to address this issue or suggest alternative terminology. The action is implicit, as the authors need to infer that they should reconsider the use of \"certificate\" and potentially replace it with a more appropriate term. Additionally, the comment lacks concrete details on how to implement this change, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 267,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of the term \"certificate,\" explaining that it might be misinterpreted due to its strong meaning in complexity theory. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the use of the term \"certificate\" in some contexts might be misinterpreted due to its strong meaning in complexity theory. However, the comment does not provide any specific examples or references to support this claim, nor does it explain how the term might be misinterpreted or why it is problematic. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of the term \"certificate\" in the paper, suggesting that it might be misinterpreted due to its strong meaning in complexity theory. This is a relevant observation that could help the authors clarify their terminology and ensure that their work is understood correctly by readers. However, the comment lacks specific examples or suggestions on how to address this issue, such as recommending alternative terminology or providing context for the term \"certificate.\" While it points out a potential problem, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests conducting more experiments on deeper networks, such as ResNet50, and other network structures, such as MobileNet, to strengthen the paper. It provides specific examples of references that could guide the authors in their experiments. This feedback is clear and actionable, as it directly instructs the authors on what additional experiments to perform and where to find relevant references. The authors know exactly what actions to take to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment suggests conducting more experiments on deeper networks, such as ResNet50, and other network structures, such as MobileNet, to strengthen the paper. It provides specific references to relevant works, which helps ground the suggestion in the context of the paper. However, the comment does not specify which part of the paper these experiments should be conducted in, making it weakly grounded. The suggestion is specific in terms of the types of experiments needed, but without explicit references to sections or parts of the paper, the authors may find it challenging to implement the feedback. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests conducting more experiments on deeper networks, such as ResNet50, and other network structures, such as MobileNet, to strengthen the paper. The comment provides specific references to relevant works, including 1 MoBiNet: A Mobile Binary Network for Image Classification, in WACV 2020, 2 Dynamic Channel Pruning: Feature Boosting and Suppression, in ICLR2019, and 3 Learning Dynamic Routing for Semantic Segmentation, in CVPR2020. These references provide a solid foundation for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how these experiments would enhance the paper. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment suggests conducting more experiments on deeper networks, such as ResNet50, and other network structures, such as MobileNet, to strengthen the paper. It provides specific references to relevant works, which can guide the authors in their experimental design. This feedback is clear and actionable, as it directly suggests a way to enhance the paper by expanding the scope of experiments. However, the comment could be more helpful if it included a rationale for why these additional experiments are necessary or how they would contribute to the paper\"s findings. Overall, the comment is 4 as it provides a concrete direction for improvement, but it could be more comprehensive with additional context or explanation."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the proxlinear subproblem in Eq.(1) can be reformulated using the conjugate function, making it similar to the subproblem in Algorithm 1. The reviewer implies that this reformulation could simplify the proxlinear algorithms for solving the stochastic problem in Eq.(1). However, the comment does not provide explicit instructions on how to implement this reformulation or improve the proxlinear algorithms. While the action is implicit, it is concrete in suggesting a potential improvement, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq.(1)\" and \"Algorithm 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the proxlinear subproblem can be reformulated using the conjugate function, which would make the motivation of Algorithm 1 unclear. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proxlinear subproblem can be reformulated using the conjugate function, making it similar to the subproblem in Algorithm 1. The reviewer suggests that this reformulation could simplify the proxlinear algorithms for solving the stochastic problem in Eq.(1), which would make the motivation of Algorithm 1 unclear. However, the comment lacks specific examples, detailed reasoning, or references to support this claim. The absence of detailed justification or evidence makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered 2, as it provides some insight but requires more detailed explanation to be 5.", "helpfulness_rationale": "The review comment identifies a potential issue with the motivation of Algorithm 1, suggesting that the proxlinear subproblem in Eq.(1) can be reformulated using the conjugate function, making it similar to the subproblem in Algorithm 1. This observation could lead to a simplification of the proxlinear algorithms for solving the stochastic problem in Eq.(1). However, the comment does not provide specific guidance on how to implement this reformulation or improve the algorithms, nor does it offer suggestions for clarifying the motivation of Algorithm 1. While it highlights a potential area for improvement, the feedback lacks depth and actionable advice, making it 3. The authors are given a direction to explore but are not fully equipped with the necessary details to make significant improvements to their draft."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point acknowledges that including multiple local prompts can be intuitive but notes that the features and their positions may not be the same for different categories. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting ways to ensure consistency across categories or proposing alternative methods. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the issue of including multiple local prompts, noting that the features and their positions may not be the same for different categories. However, it does not specify which part of the paper this observation pertains to, such as a specific section or experiment. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper being discussed. Additionally, the comment does not provide specific guidance on how to address this issue or what changes might be necessary. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that including multiple local prompts can be intuitive but notes that the features and their positions may not be the same for different categories. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges that including multiple local prompts can be intuitive but points out a potential issue: the features and their positions may not be the same for different categories. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve their approach. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the alignment of results in Table 6 with those in Table 1 (MCTpair) and asks about the ablation studies of MCT without adaptive metrics. While the questions imply that the authors should address these discrepancies or provide explanations, they do not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors need to infer that they should investigate and clarify these issues. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the alignment of results in Table 6 with those in Table 1 (MCTpair) and asks about the ablation studies of MCT without adaptive metrics. However, it does not specify which part of the paper these tables or studies are located in, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its questions but lacks grounding, as it does not provide clear references to the parts of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions seeking clarification about the alignment of results in Table 6 with those in Table 1 (MCTpair) and the ablation studies of MCT without adaptive metrics. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises questions about the alignment of results in Table 6 with those in Table 1 (MCTpair) and asks about the ablation studies of MCT without adaptive metrics. While it identifies potential inconsistencies or gaps in the presentation of results, it does not provide specific suggestions or guidance on how the authors might address these issues. The comment highlights areas that need clarification but lacks actionable feedback or detailed advice, leaving the authors with a general sense of what needs to be improved but without a clear path forward. Therefore, the comment is 3, as it points out areas for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that similar analyses are already present in prior works, suggesting that the results are not particularly surprising. It references specific examples, such as the robustness of CIFAR10 models on distribution shifts, which were studied in RobustBench and by A, B. However, the comment does not provide explicit guidance or suggestions for the authors to address this issue. It lacks actionable details on how the authors might differentiate their work or present their findings in a novel or more impactful manner. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific prior works and analyses, such as the robustness of CIFAR10 models on distribution shifts, which were studied in RobustBench and by A, B. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it details the existing analyses and their similarities to the current work, providing a clear basis for the authors to understand the critique. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that similar analyses are already present in prior works, making the results not particularly surprising. It supports this claim by referencing specific examples, such as the robustness of CIFAR10 models on distribution shifts, which were studied in RobustBench and by A, B. This provides a clear and logical basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed references or examples to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment highlights that similar analyses are already present in prior works, suggesting that the results are not particularly surprising. It references specific examples, such as the robustness of CIFAR10 models on distribution shifts, which were studied in RobustBench and by A, B. This feedback is 3 as it alerts the authors to the potential lack of novelty in their work. However, it does not provide specific suggestions or guidance on how the authors might address this issue or differentiate their findings. The comment could be more helpful if it offered actionable advice on how to present the results in a novel or more impactful manner. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the 10 subtasks are too simplistic for bAbi and that the authors could solve all the subtasks with their final model. It implies that the authors should provide more discussions on this aspect. However, the comment does not specify what kind of discussions are needed or how to address this issue. The action is implicit and somewhat vague, as the authors are left to infer the specific changes required without detailed guidance. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the 10 subtasks are too simplistic for bAbi and that the authors could solve all the subtasks with their final model. However, it does not specify which part of the paper this critique is based on, such as a particular section or experiment. Without explicit references, the authors may find it challenging to pinpoint the exact part of the paper that needs revision. Additionally, the comment lacks specificity regarding what kind of discussions are required or how the authors should address the issue. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the 10 subtasks are too simplistic for bAbi and that the authors could solve all the subtasks with their final model. However, the comment lacks specific examples, detailed reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the simplicity of the 10 subtasks used in the bAbi dataset, suggesting that the authors could solve all the subtasks with their final model. This feedback highlights a possible weakness in the experimental setup and encourages the authors to provide more discussions on this aspect. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or what additional discussions could be included. While it points out a relevant area for improvement, the lack of detailed feedback limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises two issues: the definition of \"sqeuence of episodes\" and the lack of related work. The first issue is addressed explicitly, as the reviewer asks for clarification on the term \"sqeuence of episodes.\" This provides a clear action for the authors to take, which is to clarify the term in their draft. The second issue, regarding the lack of related work, is also explicit but lacks concrete guidance on how to address it. The authors are informed that related work is missing but are not given specific suggestions on what kind of related work should be included or how to integrate it into the draft. Therefore, while the comment provides explicit actions, it lacks detailed guidance on how to implement them, making it 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L167,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the definition of \"sqeuence of episodes\" and noting the absence of related work. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises two claims: the first is about the definition of \"sqeuence of episodes,\" and the second is about the lack of related work. The comment does not provide any supporting evidence or reasoning for either claim, such as examples or references to related work. This lack of justification makes the claims 1, as the authors are left without a clear understanding of why these issues are significant or how they should be addressed. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises two important points. First, it questions the definition of \"sqeuence of episodes,\" which is unclear in the manuscript. This is a critical issue that the authors need to address to ensure clarity and understanding for readers. Second, the comment points out the absence of related work, suggesting that it is \"very related\" but does not negate the novelty of the work. This feedback is valuable as it highlights a potential gap in the literature review and encourages the authors to include relevant work. However, the comment could be more helpful if it provided specific examples of related work or suggested how to integrate it into the manuscript. Overall, the comment is 4 as it identifies clear areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point questions whether the study on different subdomain sizes can be considered an \"ablation\" study, as it does not involve removing a component of the method. However, the comment does not provide any explicit or implicit guidance on how the authors should address this issue or what changes, if any, are needed. It lacks actionable details, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment questions whether the study on different subdomain sizes can be considered an \"ablation\" study, as it does not involve removing a component of the method. However, it does not specify which part of the paper this discussion is based on, making it difficult for the authors to identify the exact section being addressed. The comment lacks specificity as it does not provide details on what aspect of the study is being questioned or how it should be addressed. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point questions whether the study on different subdomain sizes can be considered an \"ablation\" study, as it does not involve removing a component of the method. The comment provides a logical reasoning by explaining that an ablation study typically involves removing a component to assess its impact. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to consider the context of the study to fully understand the basis of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions whether the study on different subdomain sizes can be considered an \"ablation\" study, as it does not involve removing a component of the method. While the comment raises a valid point about the terminology used, it lacks depth and does not provide any actionable feedback or suggestions for improvement. The authors are left without guidance on how to address this issue or clarify the nature of their study. Therefore, the comment is 2, as it identifies a potential misunderstanding but does not offer any constructive advice for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the evaluation could be strengthened by including a comparison of base DA methods with and without architectural competitors like AutoDial and AdaBN. While the comment implies that the authors should consider adding this comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement the suggested comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the evaluation section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the evaluation could be strengthened by including a comparison of base DA methods with and without architectural competitors like AutoDial and AdaBN. This provides clear guidance on what the authors could do to improve their evaluation. Therefore, the comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point suggests that the evaluation could be strengthened by including a comparison of base DA methods with and without architectural competitors like AutoDial and AdaBN. The comment provides a logical reasoning for this suggestion, as it highlights the importance of comparing the proposed TransferNorm architecture with direct competitors. However, it does not provide specific examples or references to these competitors, which would strengthen the justification. Therefore, the claim is 4, as it requires additional information to fully substantiate the suggestion.", "helpfulness_rationale": "The review comment provides a constructive suggestion for improving the evaluation section of the paper. It acknowledges the current evaluation, which compares several base DA methods with and without the proposed TransferNorm architecture, and suggests that the evaluation could be strengthened by including comparisons with architectural competitors like AutoDial and AdaBN. This feedback is clear and actionable, as it offers a specific direction for enhancing the evaluation to better demonstrate the strengths and weaknesses of the proposed method. However, the comment could be more helpful if it provided additional context or examples of how these competitors might be integrated into the evaluation. Overall, the comment is 4, as it guides the authors toward a meaningful improvement in their evaluation methodology."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly requests clarification on how the attention module is attached to the backbone ResNet20 architecture during the search process. It asks for specific details about the number of attention modules used and their placement, such as whether they are used after each block or stage. This feedback provides clear and direct actions for the authors to take, ensuring they know exactly what information needs to be clarified in their draft. The comment is explicit and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"attention module\" and the \"backbone ResNet20 architecture,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, such as the number of attention modules used, their placement, and whether they are used after each block or stage. This provides clear guidance on what the authors need to address to improve the clarity of their paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the attachment of the attention module to the backbone ResNet20 architecture during the search process. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the attachment of the attention module to the backbone ResNet20 architecture during the search process. It asks for clarification on the number of attention modules used and their placement, such as whether they are used after each block or stage. This feedback is clear and actionable, as it directs the authors to provide more detailed information that could enhance the clarity and understanding of their methodology. By addressing these questions, the authors can improve the comprehensibility of their paper. However, the comment could be more helpful if it provided additional context or suggestions on how to present this information effectively. Overall, the comment is 4, as it guides the authors toward improving the clarity of their draft."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the linear convergence rates rely on Theorem 8, which is buried at the end of the appendix and has a proof that is not clear enough. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to improve the clarity of the proof or where it should be moved within the main text. Without specific suggestions or instructions, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 8,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is the lack of clarity in the proof of Theorem 8, and the fact that it is buried at the end of the appendix. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the linear convergence rates rely on Theorem 8, which is buried at the end of the appendix and has a proof that is not clear enough. However, the comment does not provide any specific reasoning or examples to support why the proof is unclear or how it affects the linear convergence rates. Without detailed justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the linear convergence rates rely on Theorem 8, which is buried at the end of the appendix and has a proof that is not clear enough. This feedback is valuable as it points out a potential weakness in the paper that could impact its clarity and understanding. However, the comment lacks actionable suggestions or guidance on how to improve the clarity of the proof or where it should be moved within the main text. While it highlights an important area for improvement, the lack of detailed feedback limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the analysis on BRPNAS is somewhat barebones, as it only compares against three basic alternatives and ignores other NAS approaches like supernet or oneshot approaches. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should consider including more NAS approaches in their analysis, but it lacks concrete details on which specific approaches to include or how to integrate them into the analysis. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the analysis on BRPNAS, specifically noting that it is somewhat barebones due to only comparing against three basic alternatives and ignoring other NAS approaches like supernet or oneshot approaches. However, it does not specify which part of the paper this analysis is presented in, such as a specific section or table. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper being discussed. While the comment is specific in detailing what is missing in the analysis, it is 1 because it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the analysis on BRPNAS is somewhat barebones, as it only compares against three basic alternatives and ignores other NAS approaches like supernet or oneshot approaches. This claim is 3 as it highlights a limitation in the analysis, but it lacks specific examples or references to other NAS approaches that could have been included. The comment provides a general direction for improvement but does not fully substantiate the claim with detailed evidence or comparisons. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific limitation in the analysis of BRPNAS, noting that it only compares against three basic alternatives and ignores other NAS approaches like supernet or oneshot approaches. This feedback is 3 as it points out a gap in the analysis that could be addressed to provide a more comprehensive evaluation. However, the comment lacks specific suggestions or guidance on how the authors might expand their analysis to include these other approaches, which would make it more actionable. While it highlights an area for improvement, the comment could be more helpful with additional details or examples. Therefore, it is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the applicability of the proposed method to natural images, such as CIFAR10, which are more relevant to realworld applications. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should test the method on CIFAR10, modify the method to accommodate natural images, or address the issue in the paper. The comment lacks actionable details, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the applicability of the proposed method to natural images, such as CIFAR10, which are more relevant to realworld applications. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its inquiry about the method\"s applicability to natural images, but it lacks grounding as it does not reference any particular section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the applicability of the proposed method to natural images, such as CIFAR10, which are more relevant to realworld applications. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the method might not work on natural images. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the applicability of the proposed method to natural images, such as CIFAR10, which are more relevant to realworld applications. This is a valuable observation that prompts the authors to consider expanding the scope of their method to include natural images, which could enhance the practicality and relevance of their work. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as testing the method on CIFAR10 or discussing potential modifications. While it identifies a critical area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the omission of FFNs due to the inability to obtain a linear decomposition, as mentioned in the paper. It suggests that if there is no existing work offering a way around this issue, the authors should consider adding a line or two to acknowledge the lack of a solution and the open (hard) nature of the problem. This feedback is explicit in its suggestion to add a line or two to the paper, providing a clear action for the authors to take. However, it does not specify how to implement this addition, such as what specific information should be included or where it should be placed in the paper. Therefore, the comment is 4, as it provides a clear direction but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"FFNs\" and \"a linear decomposition,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding a line or two to acknowledge the lack of a solution for the issue and the open (hard) nature of the problem. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the omission of FFNs due to the inability to obtain a linear decomposition, as mentioned in the paper. It suggests that if there is no existing work offering a way around this issue, the authors should acknowledge the lack of a solution and the open (hard) nature of the problem. The comment provides a logical reasoning for the suggestion, as it highlights the importance of addressing the omission and its impact on the reader\"s understanding. However, it does not provide specific references or examples of existing work that could offer an approximation or solution, which would strengthen the claim. Therefore, the comment is 4, as it provides a clear rationale but lacks detailed evidence or references.", "helpfulness_rationale": "The review comment identifies a potential gap in the paper regarding the omission of FFNs due to the inability to obtain a linear decomposition. It suggests that the authors should consider adding a line or two to acknowledge the lack of a solution and the open (hard) nature of the problem. This feedback is clear and actionable, as it provides a specific suggestion for improvement that would enhance the paper\"s readability and overall clarity. By addressing this issue, the authors can provide a more comprehensive understanding of the limitations and challenges in their work. However, the comment could be more helpful if it included examples or references to existing work that might offer approximations or solutions. Overall, the comment is 4, as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about questionable design choices related to the use of perplexity as a measure of semantic information retention after finetuning. It questions whether this measure adequately addresses aspects of domain drift and catastrophic forgetting. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their design choices. The action is implicit, as the authors need to infer that they should consider alternative measures or methods to account for domain drift and catastrophic forgetting. Additionally, the comment lacks concrete details on how to implement these changes, making it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises concerns about questionable design choices related to the use of perplexity as a measure of semantic information retention after finetuning. It questions whether this measure adequately addresses aspects of domain drift and catastrophic forgetting. However, the comment does not specify which part of the paper discusses these design choices or where the authors should address these concerns. Without explicit references to sections, tables, or figures, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, while the comment highlights specific issues, it does not provide detailed guidance on how to address them. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a concern about the use of perplexity as a measure of semantic information retention after finetuning, questioning whether it adequately addresses aspects of domain drift and catastrophic forgetting. The comment provides a logical reasoning by suggesting that there are other factors, such as domain drift, that need to be considered. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to further explore and justify their choice of perplexity as a measure, which is a reasonable request but requires additional effort to substantiate. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about questionable design choices related to the use of perplexity as a measure of semantic information retention after finetuning. It questions whether this measure adequately addresses aspects of domain drift and catastrophic forgetting, which are important considerations in the context of finetuning. The comment prompts the authors to consider how these factors are controlled, providing a clear and actionable suggestion for improvement. However, the comment could be more helpful if it offered specific examples or methods for addressing these concerns. Overall, the feedback is 4 as it identifies a potential weakness and guides the authors toward a more comprehensive approach, but it could be more detailed to fully support the authors in making improvements."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the applicability of the method to real and categorical features, given that the work only uses binary features. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or test the method\"s applicability to other feature types. The comment implies that the authors should consider extending their analysis to include real and categorical features, but it lacks concrete steps or examples on how to do so. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the applicability of the method to real and categorical features, given that the work only uses binary features. However, it does not specify which part of the paper this issue pertains to, such as a specific section or experiment, making it weakly grounded. The comment is specific in its critique of the feature types used and the need for clarity on applicability to other types. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the applicability of the method to real and categorical features, given that the work only uses binary features. The comment highlights a potential limitation in the method\"s scope, but it does not provide specific examples or references to support the claim. The lack of detailed reasoning or evidence makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment identifies a potential limitation in the work, noting that it only uses binary features and questioning the applicability of the method to real and categorical features. This is a relevant observation that could impact the generalizability of the method. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or test the method\"s applicability to other feature types. While it points out a critical area for improvement, the feedback could be more actionable and helpful by offering concrete steps or examples. Therefore, the comment is 3, as it provides insight but lacks depth and actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "1", "actionability_rationale": "The review point claims that the algorithm for constructing coresets is not novel, as it extends existing frameworks for classical kmeans and (k,z) clusterings to the kernelized setting. However, it does not provide any explicit or implicit suggestions for improvement or action that the authors should take. There is no guidance on how to address the lack of novelty or how to enhance the originality of the work. Without actionable advice or specific recommendations, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the novelty of the algorithm for constructing coresets, specifically mentioning that it extends existing frameworks for classical kmeans and (k,z) clusterings to the kernelized setting. However, it does not specify which part of the paper discusses this algorithm or its novelty, making it weakly grounded. The comment is specific in detailing the lack of novelty, but without clear grounding, the authors may struggle to identify the exact section needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the algorithm for constructing coresets is not novel, as it extends existing frameworks for classical kmeans and (k,z) clusterings to the kernelized setting. This claim is 3 as it provides a logical reasoning for the lack of novelty, but it lacks specific references or detailed examples to fully substantiate the claim. The authors would need to investigate the existing frameworks to fully understand the basis of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment points out that the algorithm for constructing coresets is not novel, as it extends existing frameworks for classical kmeans and (k,z) clusterings to the kernelized setting. While this observation highlights a potential limitation of the work, it does not provide any actionable feedback or suggestions for improvement. The comment lacks depth and does not offer guidance on how the authors might address this issue or enhance the novelty of their approach. As a result, the comment is not particularly helpful for the authors in improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the rationale behind considering only ECG segments with one label assigned, suggesting that including all reports would be more beneficial. While the comment implies that the authors should reconsider their approach, it does not explicitly instruct them to do so or provide specific guidance on how to address this issue. The action is implicit and somewhat vague, as the authors can infer that they need to reconsider their methodology but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions the rationale behind considering only ECG segments with one label assigned, suggesting that including all reports would be more beneficial. However, it does not specify which part of the paper discusses this methodology, making it weakly grounded. The comment is specific in its critique of the approach, questioning the rationale behind the chosen methodology. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the rationale behind considering only ECG segments with one label assigned, suggesting that including all reports would be more beneficial. The comment provides a logical reasoning by implying that considering all reports would lead to a more comprehensive analysis. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to consider the implications of including all reports to fully understand the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the rationale behind considering only ECG segments with one label assigned, suggesting that including all reports would be more beneficial. This feedback highlights a potential limitation in the methodology and prompts the authors to reconsider their approach. However, the comment does not provide specific suggestions or examples on how to address this issue or improve the methodology. While it identifies a potential area for improvement, it lacks depth and actionable guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should generate instances with more constraints and variables, as the current instances have fewer than 7 variables. This implies that the authors should consider increasing the complexity of their instances to better test the LLMs\" ability to model problems with larger instance sizes. However, the comment does not provide specific guidance on how to achieve this, such as suggesting additional constraints or variables to include. While the action is implicit, it lacks concrete details on how to implement it, making it 3.", "grounding_specificity_rationale": "The comment suggests that the authors should generate instances with more constraints and variables, as the current instances have fewer than 7 variables. This implies that the authors should consider increasing the complexity of their instances to better test the LLMs\" ability to model problems with larger instance sizes. However, the comment does not specify which part of the paper this issue pertains to, such as a specific section or experiment, making it weakly grounded. The comment is specific in suggesting the need for more complex instances, but without clear grounding, it is challenging for the authors to pinpoint the exact area needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should generate instances with more constraints and variables, as the current instances have fewer than 7 variables. The reviewer raises a concern about the LLMs\" ability to model problems with large instance sizes, implying that the current instances may not adequately test this ability. However, the comment lacks specific examples or references to support the claim that more complex instances are necessary. Without detailed justification or evidence, the claim remains 3, as it provides a logical reasoning but lacks concrete support. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper regarding the complexity of the instances used to test the LLMs\" ability to model problems. It suggests that the authors should consider generating instances with more constraints and variables, as the current instances have fewer than 7 variables. This feedback is 3 as it points out an area for improvement, encouraging the authors to explore more complex scenarios to better test the LLMs\" capabilities. However, the comment lacks specific guidance on how to achieve this or what additional constraints or variables might be relevant, which could limit its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the meaning of the statement \"NodeSort differentially sorts nodes depending on the base node.\" It asks whether the base node affects the ordering, the key nodes for attention, and the model performance. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this question or clarify the statement in their draft. As a result, the authors are left without a clear understanding of what steps to take to improve their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the meaning of a statement in the paper, specifically regarding the effect of the base node on the ordering, key nodes for attention, and model performance. However, it does not specify which part of the paper this statement is from, making it difficult for the authors to pinpoint the exact section that needs clarification. The comment is specific in its inquiry about the implications of the base node, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question seeking clarification about the statement \"NodeSort differentially sorts nodes depending on the base node.\" It does not express an opinion, judgment, or suggestion that requires verification. It is a request for clarification, which is factual and does not contain a claim. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the meaning of a statement in the paper, specifically regarding the effect of the base node on the ordering, key nodes for attention, and model performance. While it identifies a potential area of confusion, it does not provide any suggestions or guidance on how the authors might clarify or address this issue in their draft. The comment lacks depth and actionable feedback, leaving the authors with only a vague understanding of what needs to be improved. Therefore, it is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the direction of the arrow in Figure 2, asking why it is from a Gaussian space into the latent space rather than from the latent space to n^(i). The reviewer suggests that the main purpose might be to influence n^(i). While the comment raises a specific question about the direction of the arrow, it does not provide explicit guidance on how the authors should address this issue or what changes, if any, are needed. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the direction of the arrow but are not given specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the direction of the arrow in the figure and provides a rationale for why the arrow should be from the latent space to n^(i). This specificity helps the authors understand what aspect of the figure needs clarification or revision. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the direction of the arrow in Figure 2, suggesting that it should be from the latent space to n^(i) rather than from a Gaussian space. The reviewer provides a logical reasoning for this suggestion, stating that the main purpose might be to influence n^(i). However, the comment lacks specific references or detailed explanations to fully substantiate the claim. While the reasoning is clear, the lack of additional evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a specific question about the direction of the arrow in Figure 2, questioning why it is from a Gaussian space into the latent space rather than from the latent space to n^(i). This feedback is 3 as it prompts the authors to clarify the purpose and direction of the arrow, which could be important for understanding the methodology. However, the comment does not provide detailed guidance or suggestions on how to address this issue, such as explaining the rationale behind the current direction or suggesting alternative explanations. While it identifies a potential area for clarification, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with abbreviations in Table 5, noting that \"AR\" stands for domain adaptation tasks and algorithms. This feedback is explicit and provides a clear action for the authors to take, which is to define the abbreviations used in the table. The comment is concrete because it specifies exactly what needs to be done to improve the clarity of the table. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular issue with abbreviations, namely that \"AR\" stands for domain adaptation tasks and algorithms. This provides clear guidance on what needs to be addressed to improve the clarity of the table. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that many abbreviations lack definition and cause confusion, specifically mentioning that \"AR\" in Table 5 stands for domain adaptation tasks and algorithms. This claim is 3 as it provides a specific example of an abbreviation that is unclear, but it lacks broader context or justification for why other abbreviations might also be problematic. The comment could be strengthened by explaining how this lack of definition impacts the reader\"s understanding or by suggesting ways to improve clarity. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with abbreviations in the paper, noting that many of them lack definition and cause confusion. It provides a concrete example by pointing out that \"AR\" in Table 5 stands for domain adaptation tasks and algorithms. This feedback is clear and actionable, as it directs the authors to define abbreviations used in the paper, particularly those that may be confusing to readers. By addressing this issue, the authors can enhance the clarity and accessibility of their work. However, the comment could be more helpful if it suggested specific ways to define these abbreviations or provided examples of how to improve clarity. Overall, the comment is 4, as it effectively guides the authors toward improving the clarity of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the fairness of the performance comparison in Table 1, specifically mentioning that VINS sets different sample weights W u i in the training process, while most compared baselines like DNS, AOBPR, SA, and PRIS set all sample weights as 1. This comment implies that the authors should address the issue of fairness in the performance comparison, but it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should investigate and potentially adjust the sample weights to ensure fairness. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the unfairness in the performance comparison due to different sample weights used by VINS compared to other baselines like DNS, AOBPR, SA, and PRIS. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the performance comparison in Table 1 is unfair due to different sample weights used by VINS compared to other baselines. This claim is 3 as it provides a specific reason for the perceived unfairness, namely the use of different sample weights. However, the comment lacks detailed examples or references to support the claim fully, such as comparing the performance with and without these sample weights. This makes the claim 3, as it provides a basis for the critique but requires more detailed evidence to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific issue with the performance comparison in Table 1, noting that the fairness of the comparison is compromised due to different sample weights used by VINS compared to other baselines. This feedback is clear and actionable, as it highlights a potential bias in the evaluation that could impact the interpretation of results. By pointing out this issue, the comment provides the authors with a clear direction for improvement, such as adjusting the sample weights or providing additional context to ensure a fair comparison. However, the comment could be more helpful if it suggested specific ways to address the issue or provided examples of how to ensure fairness in the comparison. Overall, the comment is 4 as it directs the authors to a critical area that needs attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a potential issue with the time complexity if the reply buffer is too large. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how to reduce the time complexity, what specific changes should be made, or whether the authors should consider alternative approaches. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions the time complexity issue related to the reply buffer being too large, but it does not specify which part of the paper this issue is discussed in. Without explicit references to sections, tables, or figures, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what needs to be addressed or how to mitigate the time complexity issue. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the time complexity will be too high if the reply buffer is too large, and it references a specific paper, \"PRMRL: Longrange Robotic Navigation Tasks by Combining Reinforcement Learning and Samplingbased Planning.\" This provides a logical basis for the claim, as it suggests that the authors should consider the time complexity implications of their approach. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced paper to fully substantiate the claim. Therefore, the comment is 3, as it requires additional context or explanation to be fully supported.", "helpfulness_rationale": "The review comment identifies a potential issue with the time complexity of the reply buffer being too large, which could impact the overall performance of the system. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or mitigate the time complexity. Without actionable advice or detailed feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to provide a brief conclusion and a summary of their contributions. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific task that the authors need to address, making it 5.", "grounding_specificity_rationale": "The comment explicitly mentions the need for a brief conclusion and a summary of the paper\"s contributions, providing clear guidance on what needs to be addressed. However, it does not specify which part of the paper this feedback pertains to, such as the conclusion section or the introduction. While the authors can infer that it relates to the conclusion or summary sections, the lack of explicit reference makes it weakly grounded. The comment is specific in detailing what needs to be included, making it 3. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point suggests that a brief conclusion and a summary of the paper\"s contributions are needed. This is a request for clarification or improvement, not a claim that requires verification. It does not express an opinion, judgment, or suggestion that needs to be substantiated. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the paper lacks a brief conclusion and a summary of its contributions. This feedback is clear and actionable, as it provides the authors with a direct task to enhance the clarity and completeness of their paper. By addressing this feedback, the authors can better communicate the significance and impact of their work to the readers. However, the comment could be more helpful if it offered suggestions on how to structure the conclusion or what aspects to highlight in the summary. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should compare their framework with a method designed to defend against multiple attacks, as the current comparison with APEGAN may not be comprehensive. While the comment implies that the authors should include this comparison, it does not explicitly instruct them to do so. Additionally, it does not provide specific guidance on which method to compare with or how to present the results. The action is implicit and somewhat vague, as the authors can infer that they need to expand their comparison but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should compare their framework with a method designed to defend against multiple attacks, rather than just APEGAN. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where comparisons are made. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper that needs revision. The comment is specific in suggesting a comparison with a method that defends against multiple attacks, but it is 1 because it does not identify the specific part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should compare their framework with a method designed to defend against multiple attacks, as the current comparison with APEGAN may not be comprehensive. The comment provides a logical reasoning for the suggestion, noting that such a comparison would make the results more meaningful. However, it does not provide specific references or examples of methods that defend against multiple attacks, which would strengthen the claim. Therefore, the comment is 3, as it provides a logical basis but lacks detailed evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment suggests that the authors should expand their comparison by including a method designed to defend against multiple attacks, rather than just APEGAN. This feedback is 3 as it identifies a potential area for improvement in the paper, specifically the comprehensiveness of the comparisons. However, the comment does not provide specific guidance on which method to compare with or how to present the results, leaving the authors with a general direction but without detailed actionable steps. While it highlights a relevant area for enhancement, the lack of specificity limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation of the planbased method, noting that it requires manual design of a plan based on ground truth, which is unrealistic in realworld scenarios. It also points out that the learned plan methods are not comparable to those with predefined plans, as shown in Table 2. The comment suggests that the proposed method may struggle to generalize to new datasets without ground truth summaries. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this limitation or improve the generalizability of their method. The action is implicit and somewhat vague, as the authors are left to infer what steps to take to improve the method\"s generalizability. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the limitations of the planbased method, specifically mentioning the need for manual design of a plan based on ground truth, which is unrealistic in realworld scenarios. It also compares the learned plan methods to those with predefined plans, as shown in Table 2, and suggests that the proposed method may struggle to generalize to new datasets without ground truth summaries. However, the comment does not explicitly mention which part of the paper discusses these methods or tables, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. The comment is specific in detailing the issue with the planbased method and its generalizability, but the lack of explicit grounding limits its effectiveness. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the planbased method requires manual design of a plan based on ground truth, which is unrealistic in realworld scenarios. It also suggests that the learned plan methods are not comparable to those with predefined plans, as shown in Table 2, indicating a potential limitation in generalizability. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. The lack of evidence or detailed explanation makes it difficult for the authors to fully understand and address the issues raised. Therefore, the comment is considered 2, as it provides some insight but requires more detailed justification to be 5.", "helpfulness_rationale": "The review comment identifies a significant limitation of the planbased method, noting that it requires manual design of a plan based on ground truth, which is unrealistic in realworld scenarios. It also points out that the learned plan methods are not comparable to those with predefined plans, as shown in Table 2, indicating a potential issue with generalizability. This feedback is valuable as it highlights a critical weakness in the methodology and suggests that the proposed method may struggle to generalize to new datasets without ground truth summaries. However, the comment could be more helpful if it provided suggestions on how to address this limitation or improve the generalizability of the method. Overall, the comment is 3 as it directs the authors\" attention to a key area for improvement but lacks specific guidance on how to resolve the issue."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests adding a first sentence to introduce the content of Section 3.2. While it explicitly states an action, it lacks specific guidance on what should be included in the introduction sentence. The authors are aware of the need to introduce the section but may struggle to determine the exact content of the introduction. Therefore, the comment is 3, as it provides a clear direction but lacks detailed instructions on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding a first sentence to introduce the section, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests adding a first sentence to introduce Section 3.2. However, it does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification or improvement, fitting the classification of \"No.\"", "helpfulness_rationale": "The comment suggests adding a first sentence to introduce Section 3.2, which is a clear and actionable piece of feedback. By doing so, the authors can better orient the reader to the content of the section, improving the overall clarity and structure of the paper. However, the comment lacks specific guidance on what should be included in the introduction sentence, which could be beneficial for the authors. Despite this, the suggestion is 4 as it provides a straightforward way to enhance the paper\"s readability and organization. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the meaning of the phrase \"initial rationale selector is perfect\" and suggests that if it were perfect, no additional work would be needed. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to clarify or address this point in the draft, nor are there suggestions for improvement or correction. As a result, the comment lacks any actionable advice, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 44,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the meaning of the phrase \"initial rationale selector is perfect\" and provides a logical reasoning for why it might be problematic. The comment clearly specifies what needs to be addressed, which is the clarification of the phrase \"initial rationale selector is perfect.\" Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the phrase \"initial rationale selector is perfect\" and suggests that if it were perfect, no additional work would be needed. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this assumption is problematic or how it affects the paper. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment questions the phrase \"initial rationale selector is perfect\" and suggests that if it were perfect, no additional work would be needed. This raises a valid point about the clarity and logic of the paper, prompting the authors to reconsider the wording and its implications. However, the comment does not provide specific suggestions or guidance on how to address this issue or improve the draft. While it identifies a potential area of confusion, it lacks actionable feedback that could help the authors enhance their work. Therefore, the comment is 3, as it points out a potential issue but does not fully support the authors in resolving it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests a specific way to clarify the definition of uncertainty in the paper. It explicitly states that the epistemic model uncertainty is represented in the prior distribution, and upon observing data, those beliefs can be updated in the form of a posterior distribution, which yields model uncertainty conditioned on observed data. This provides a clear and concrete action for the authors to take, ensuring they know exactly how to improve the clarity of their draft. The comment is explicit and provides detailed guidance, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the definition of uncertainty, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for improving the clarity of the definition by explaining the relationship between the prior and posterior distributions. This feedback offers a concrete way to enhance the paper\"s clarity, making the comment 5.", "verifiability_rationale": "The review point suggests a clarification regarding the definition of uncertainty, specifically mentioning the posterior distribution. The comment provides a logical explanation of how the epistemic model uncertainty is represented in the prior distribution and how it can be updated to a posterior distribution upon observing data. This reasoning is clear and provides a basis for the suggestion, making the claim 4. However, the comment could be strengthened by providing specific examples or references to support the explanation, which would align with a score of 4.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the clarity of the paper\"s definition of uncertainty. It offers a specific explanation of how the epistemic model uncertainty is represented in the prior distribution and how it can be updated to a posterior distribution upon observing data. This feedback is valuable as it guides the authors on how to enhance the clarity and precision of their explanation, which is crucial for understanding the methodology and results. However, the comment could be more helpful if it included examples or further elaboration on how this clarification would impact the overall understanding of the paper. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the authors experimented with the use of domain ontologies to avoid placeholder generation in the evaluated responses. It also asks for specific details regarding the number of questions created for the zeroshot intent classifier and its accuracy. While the comment implies that the authors should provide this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address these questions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 211,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the use of domain ontologies and asks for details regarding the number of questions created for the zeroshot intent classifier and its accuracy. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the use of domain ontologies to avoid placeholder generation in the evaluated responses. It does not contain a claim or opinion but rather seeks clarification on a specific aspect of the methodology. The comment is factual and descriptive, fitting the \"No\" label.", "helpfulness_rationale": "The review comment raises a specific question about the use of domain ontologies to avoid placeholder generation in the evaluated responses. It also requests information on the number of questions created for the zeroshot intent classifier and its accuracy. While the comment identifies a potential area for improvement and provides a clear direction for additional information, it lacks depth and does not offer suggestions on how to address the issue or improve the methodology. The feedback is 3 as it prompts the authors to consider an important aspect of their work, but it could be more comprehensive with additional guidance or suggestions. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a lack of meaningful baselines in the paper, specifically noting that the authors limit their comparisons to simple naive baselines. It suggests that the authors could compare with a chainofthought prompting approach, providing a concrete example of a more meaningful baseline. This feedback is clear and actionable, as it directly instructs the authors on how to enhance their comparisons by including a specific alternative. The authors know exactly what needs to be done to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of lacking meaningful baselines and suggests a comparison with a chainofthought prompting approach. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks meaningful baselines, specifically noting that the authors limit their comparisons to simple naive baselines. The reviewer suggests comparing with a chainofthought prompting approach as a more meaningful baseline. This claim is 3 as it provides a specific suggestion for improvement, but it lacks detailed reasoning or examples of how the current baselines are insufficient. The suggestion for a chainofthought prompting approach is a logical next step, but the comment could be strengthened by explaining why the current baselines are inadequate or how the chainofthought approach would provide a more meaningful comparison. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, specifically the lack of meaningful baselines in the comparisons. It points out that the authors limit their comparisons to simple naive baselines, suggesting that this limits the paper\"s contribution. The comment provides a specific suggestion for improvement by recommending a comparison with a chainofthought prompting approach, which could offer a more meaningful baseline. This feedback is clear and actionable, offering the authors a concrete way to enhance the depth and relevance of their comparisons. However, the comment could be more helpful if it explained why the current baselines are insufficient or how the chainofthought approach would provide a more meaningful comparison. Overall, the comment is 4 as it guides the authors toward a significant improvement in their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the absence of important experimental details and explanations in the main text, with the Appendix being the only source of information. It specifically mentions that the PCA experiments in Figures 3, 7, and 8 are not explained. This feedback provides a clear and explicit action for the authors to take, which is to include detailed explanations and interpretations of these experiments in the main text. The comment is specific and direct, giving the authors a clear understanding of what needs to be addressed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific figures (3, 7, and 8) and the Appendix, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue of missing explanations and interpretations for the PCA experiments, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that important experimental details are missing or relegated to the Appendix, and the Appendix lacks explanations or interpretations. It specifically mentions that the PCA experiments in Figures 3, 7, and 8 are not explained. This claim is 3 as it provides specific examples of missing details, but it lacks detailed reasoning or references to support the assertion that all important experimental details are missing. The comment would be more verifiable with additional examples or references to specific experiments or sections that are lacking in detail. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that important experimental details are missing or relegated to the Appendix, and the Appendix lacks explanations or interpretations. It specifically points out that the PCA experiments in Figures 3, 7, and 8 are not explained, which is a specific and actionable piece of feedback. By highlighting these gaps, the comment provides clear guidance on what the authors need to address to improve the clarity and comprehensiveness of their work. However, the comment could be more helpful if it offered suggestions on how to incorporate these details into the main text or provided examples of how to effectively explain the PCA experiments. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the notation \"K,\" which is used for both a known kernel function and the number of layers. This feedback is explicit and provides clear guidance on the issue, allowing the authors to identify and address the inconsistency in notation. The comment suggests that the authors need to clarify the usage of \"K\" to avoid confusion. However, it does not provide detailed instructions on how to implement this change, such as suggesting alternative notations or specific ways to differentiate the two uses of \"K.\" While the action is explicit, the lack of concrete guidance on execution makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper (L166 and L176) where the notation \"K\" is used for different purposes. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies the issue with the notation, namely its inconsistent use for a known kernel function and the number of layers. This provides clear guidance on what needs to be addressed to improve the clarity and consistency of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the notation \"K\" is being abused, as it is used for both a known kernel function and the number of layers. This claim is 3 as it highlights a potential inconsistency in notation, which could lead to confusion for readers. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. Providing more detailed examples or context would strengthen the verifiability of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the notation \"K,\" which is used inconsistently in the paper. It points out that \"K\" is used for both a known kernel function and the number of layers, which can lead to confusion. This feedback is clear and actionable, as it highlights a potential source of ambiguity that the authors need to address to improve the clarity and readability of their paper. However, the comment could be more helpful if it suggested alternative notations or provided guidance on how to differentiate between the two uses of \"K.\" Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional suggestions or examples."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the relevance of bringing connections to human cognition into the study, given that the problem is reductionist and does not allow for mechanisms like bargaining and negotiation. The reviewer questions the authors\" statement about the interaction between cognitively basic adaptation mechanisms and the structure of the CPR, suggesting that it would be surprising if a behavioral economist would ignore these aspects. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or clarify their statement. The action is implicit and vague, as the authors are left to infer that they need to provide more context or references to support their claim. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific concern about the relevance of bringing connections to human cognition into the study, given that the problem is reductionist and does not allow for mechanisms like bargaining and negotiation. It questions the authors\" statement about the interaction between cognitively basic adaptation mechanisms and the structure of the CPR, suggesting that it would be surprising if a behavioral economist would ignore these aspects. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concern about the relevance of human cognition and the need for more citation for comparison. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the relevance of bringing connections to human cognition into the study, given that the problem is reductionist and does not allow for mechanisms like bargaining and negotiation. The reviewer challenges the authors\" statement about the interaction between cognitively basic adaptation mechanisms and the structure of the CPR, suggesting that it would be surprising if a behavioral economist would ignore these aspects. The comment provides a logical reasoning by contrasting the authors\" claim with the reductionist nature of the problem, but it lacks specific references or examples to fully substantiate the claim. This makes the comment 3, as it requires additional evidence or references to fully support the critique.", "helpfulness_rationale": "The review comment raises a concern about the relevance of bringing connections to human cognition into the study, given that the problem is reductionist and does not allow for mechanisms like bargaining and negotiation. It questions the authors\" statement about the interaction between cognitively basic adaptation mechanisms and the structure of the CPR, suggesting that it would be surprising if a behavioral economist would ignore these aspects. The comment also points out the need for more citation for comparison against \"previously appreciated.\" While the comment identifies a potential issue and suggests a need for clarification or additional references, it lacks specific guidance on how the authors might address this concern or improve their draft. The feedback is 3 as it prompts the authors to reconsider their approach and provide more context, but it could be more actionable with additional suggestions or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the wording in the conclusion is overly exaggerated and that the word choice is \"flamboyant\" in multiple places. However, it does not provide specific suggestions or guidance on how to revise the wording or tone. The action is implicit, as the authors can infer that they need to tone down the language, but it lacks concrete details on how to achieve this. Therefore, the comment is 3, as it identifies an issue but does not offer detailed guidance on how to address it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the conclusion, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue of overly exaggerated wording and provides a concrete example of the problematic phrase, \"our pioneering contributions herald a new era in robotic adaptability.\" This specificity helps the authors understand what needs to be addressed in the conclusion. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the wording in the conclusion is overly exaggerated and that the word choice is \"flamboyant\" in multiple places. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact issues or how to address them. Without detailed evidence or examples, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 2.", "helpfulness_rationale": "The review comment identifies a specific issue with the wording in the conclusion, noting that it is overly exaggerated and \"flamboyant.\" This feedback is clear and actionable, as it points out a potential weakness in the paper\"s tone and suggests a need for more modest language. However, the comment could be more helpful if it provided specific examples or suggestions for alternative wording that would better align with the paper\"s content. Despite this, the comment still offers valuable insight into improving the paper\"s presentation, making it 4. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a significant weakness in the paper, namely the lack of comparison to simple feature acquisition baselines like expected utility or similar measures. This feedback implies that the authors should include such comparisons to demonstrate the effectiveness of their proposed approach. However, the comment does not provide specific guidance on which baselines to consider or how to conduct the comparison. While the action is clear\u2014adding comparisons to demonstrate effectiveness\u2014the lack of concrete details on how to implement this makes the comment 3. The authors know they need to compare to baselines but may struggle to determine the exact steps to take.", "grounding_specificity_rationale": "The comment identifies a significant weakness in the paper, namely the lack of comparison to simple feature acquisition baselines like expected utility or similar measures. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in its critique of the paper\"s lack of comparison to baselines, but without explicit references to sections or parts of the paper, the authors may find it challenging to pinpoint the exact areas needing improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper\"s biggest weakness is the lack of comparison to simple feature acquisition baselines like expected utility or similar measures. However, the comment does not provide any supporting evidence, examples, or references to justify why this comparison is necessary or how it would improve the paper. Without specific reasoning or examples, the claim remains vague and 1, leaving the authors without a clear understanding of the issue or how to address it. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, namely the lack of comparison to simple feature acquisition baselines like expected utility or similar measures. This feedback is important as it highlights a gap in the paper\"s evaluation, which could impact the credibility of the proposed approach. However, the comment does not provide specific suggestions on which baselines to consider or how to conduct the comparison, leaving the authors with a general direction but without detailed guidance. While the feedback is clear about the need for comparison, it could be more helpful with additional details on how to implement this suggestion. Therefore, the comment is rated as 3, as it provides a clear direction for improvement but lacks depth and specificity."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the novelty of the paper\"s contribution by pointing out that the introduction of multigranularity and multiscale to enhance model performance is a common approach in convolutional networks and that migrating this approach to the field of MLMs is not innovative. It also mentions that some algorithms used in the article only perform information enhancement on the input side, while many MLMs can already accomplish object detection tasks. However, the comment does not provide any actionable advice or suggestions for the authors to address these concerns or improve their work. It lacks explicit guidance on how the authors might enhance the novelty or originality of their contribution or how they could better differentiate their work from existing approaches. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the novelty of the paper\"s contribution by pointing out that the introduction of multigranularity and multiscale to enhance model performance is a common approach in convolutional networks and that migrating this approach to the field of MLMs is not innovative. It also mentions that some algorithms used in the article only perform information enhancement on the input side, while many MLMs can already accomplish object detection tasks. However, the comment does not specify which part of the paper this critique is based on, making it difficult for the authors to identify the exact sections that need revision. Additionally, while it provides some specific feedback on the lack of innovation, it lacks detailed guidance on how to address this issue. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point critiques the novelty of the paper\"s contribution by pointing out that the introduction of multigranularity and multiscale to enhance model performance is a common approach in convolutional networks and that migrating this approach to the field of MLMs is not innovative. It also mentions that some algorithms used in the article only perform information enhancement on the input side, while many MLMs can already accomplish object detection tasks. However, the comment lacks specific examples or references to support the claim about the commonality of the approach or the capabilities of MLMs. This makes the claim 3, as it provides a general critique but lacks detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the novelty of the paper\"s contribution by pointing out that the introduction of multigranularity and multiscale to enhance model performance is a common approach in convolutional networks and that migrating this approach to the field of MLMs is not innovative. It also mentions that some algorithms used in the article only perform information enhancement on the input side, while many MLMs can already accomplish object detection tasks. While the comment identifies a potential weakness in the paper\"s originality, it lacks specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. The feedback is 3 as it prompts the authors to reconsider the novelty of their contribution, but it does not provide actionable steps for improvement. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the potential oversmoothing of GNNbased encoders due to similarityaware positive sample selection and the impact on generalization performance. It suggests conducting additional experiments on different downstream tasks and across different domains to address these concerns. While the comment identifies specific areas for improvement, it does not provide explicit instructions or concrete steps on how to conduct these experiments or what specific aspects to focus on. The authors can infer that they need to conduct additional experiments, but the lack of detailed guidance makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises concerns about the potential oversmoothing of GNNbased encoders due to similarityaware positive sample selection and its impact on generalization performance. It suggests conducting additional experiments on different downstream tasks and across different domains to address these concerns. However, the comment does not specify which part of the paper discusses the similarityaware positive sample selection or where the experiments on transfer performance are mentioned. This makes it difficult for the authors to pinpoint the exact sections that need revision. While the authors might have an idea of where these topics are discussed, the lack of explicit references makes the comment weakly grounded. The comment is specific in suggesting additional experiments, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point raises concerns about the potential oversmoothing of GNNbased encoders due to similarityaware positive sample selection and its impact on generalization performance. The reviewer suggests conducting additional experiments on different downstream tasks and across different domains to address these concerns. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the current experiments do not allay the reviewer\"s concerns. This makes the claim 3, as it provides a logical basis for the concern but lacks sufficient evidence or examples to fully substantiate it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises concerns about the potential oversmoothing of GNNbased encoders due to similarityaware positive sample selection, which could lead to excessive convergence and the loss of unique features. It also questions the generalization performance of the model when selecting positive samples from the same dataset without introducing perturbation noise. The reviewer acknowledges that the authors have conducted experiments on transfer performance but suggests that more experiments on different downstream tasks and across different domains would be beneficial. While the comment identifies specific areas of concern and provides a direction for further experimentation, it lacks detailed guidance on how to conduct these experiments or what specific aspects to focus on. The feedback is 4 as it highlights important areas for improvement, but it could be more actionable with additional details. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the expressiveness of fast SMP compared to SMP and expresses a desire for more discussion on the power of different architectures. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the question or what specific aspects of the discussion should be expanded upon. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the expressiveness of fast SMP compared to SMP and expresses a desire for more discussion on the power of different architectures. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its request for more discussion on the power of different architectures, but without clear grounding, the authors may struggle to determine where this discussion should be added. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the expressiveness of fast SMP compared to SMP and expresses a desire for more discussion on the power of different architectures. However, it does not provide any supporting evidence, reasoning, or references to justify why this discussion is necessary or how it would enhance the paper. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a question about the expressiveness of fast SMP compared to SMP and expresses a desire for more discussion on the power of different architectures. While it identifies a potential area for improvement, it lacks specificity and does not provide actionable guidance or suggestions on how the authors might address this issue. The comment does not offer detailed feedback or examples of what additional discussion could include, leaving the authors with a general idea of what might be lacking but without a clear path to improvement. Therefore, the comment is 2, as it provides some insight but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that evaluating the methods across different splits of trainvaltest, rather than just different initialisation seeds, would lead to more robust results. While the comment implies that the authors should consider this approach, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that evaluating the methods across different splits of trainvaltest, rather than just different initialisation seeds, would lead to more robust results. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. This lack of explicit reference makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting an alternative approach for obtaining robust results, but without grounding, it is difficult for the authors to act upon it. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that evaluating the methods across different splits of trainvaltest, rather than just different initialisation seeds, would lead to more robust results. The comment provides a logical reasoning for why this approach would be beneficial, as it addresses potential issues with initialisation bias. However, it does not provide specific examples or references to support the claim, which would strengthen the argument. Therefore, the comment is 3, as it offers a logical rationale but lacks detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment suggests that evaluating the methods across different splits of trainvaltest, rather than just different initialisation seeds, would lead to more robust results. This feedback is clear and actionable, as it provides a specific suggestion for improving the robustness of the experimental setup. By highlighting this potential enhancement, the comment offers the authors a concrete way to strengthen their methodology and potentially improve the reliability of their findings. However, the comment could be more helpful if it provided additional context or examples of how this approach might be implemented. Overall, the comment is 4, as it offers valuable guidance for enhancing the robustness of the study."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that Figure 2 is ambiguous due to unclear symbols and raises a question about potential information redundancy and interference in the multisphere icosahedral discretization process. However, it does not provide explicit guidance on how to address these issues or suggest specific actions for the authors to take. The comment implies that the authors should clarify the symbols in Figure 2 and address the concerns about redundancy and interference, but these actions are not directly stated. As a result, the comment is 3, as it identifies areas for improvement but lacks concrete steps for the authors to follow.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that some symbols are not explained clearly, which provides clear guidance on what needs to be addressed. Additionally, the comment raises a question about potential information redundancy and interference in the multisphere icosahedral discretization process, further specifying the areas of concern. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the ambiguity of Figure 2 due to unclear symbols and questions whether there is information redundancy and interference in the multisphere icosahedral discretization process. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the exact issues or how to address them. The lack of detailed justification or references makes the claim 3, as the authors would need to infer the specific problems and their potential impact on the paper. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 2, noting that some symbols are not explained clearly. This feedback is valuable as it points out a potential area for improvement in the clarity and comprehensibility of the figure. Additionally, the comment raises a question about potential information redundancy and interference in the multisphere icosahedral discretization process, which prompts the authors to consider these aspects and potentially address them in their work. However, the comment could be more helpful if it provided specific suggestions on how to clarify the symbols or addressed the issue of redundancy and interference. Overall, the comment is 4 as it directs the authors to areas that need attention and improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the obtained results, specifically the assumption that the spectrum of a kernel is subgaussian. It notes that while this assumption is acceptable for Gaussian kernels, it excludes other popular classes like Matern kernels, which have a polynomial decay in their spectrum. However, the comment does not provide explicit guidance on how the authors should address this limitation or suggest ways to include Matern kernels in their analysis. The action is implicit and somewhat vague, as the authors are left to infer that they should consider expanding their analysis to include other kernel classes. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a limitation in the obtained results, specifically the assumption that the spectrum of a kernel is subgaussian. It mentions that while this assumption is acceptable for Gaussian kernels, it excludes other popular classes like Matern kernels, which have a polynomial decay in their spectrum. However, the comment does not specify which part of the paper discusses these assumptions or results, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but the lack of explicit references makes it challenging to pinpoint the exact part of the paper being addressed. The comment is specific in detailing the limitation and its implications, but the lack of grounding reduces its clarity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the results of the paper could be restrictive due to the assumption that the spectrum of a kernel is subgaussian. It provides a logical reasoning by explaining that while Gaussian kernels are included in this class, other popular classes like Matern kernels are not, as their spectrum only decays polynomially. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a limitation in the paper\"s results, specifically the assumption that the spectrum of a kernel is subgaussian. It acknowledges that this assumption is acceptable for Gaussian kernels but points out that it excludes other popular classes like Matern kernels, which have a polynomial decay in their spectrum. This feedback is valuable as it highlights a potential restriction in the paper\"s scope and suggests that the authors should consider expanding their analysis to include other kernel classes. However, the comment could be more helpful if it provided specific suggestions on how to incorporate these other classes or addressed the implications of this limitation. Overall, the comment is 3 as it directs the authors\" attention to an important area for improvement but lacks detailed guidance on how to address it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy between the data in Table 4, which indicates the importance of unsupervised pretraining, and the lack of detailed discussion on this topic in the main paper. The reviewer suggests focusing more on the pretraining method in the main paper, implying that the authors should provide a more indepth analysis of this aspect. While the comment explicitly states the need for more focus on pretraining, it does not provide specific guidance on how to achieve this or what aspects of the pretraining method should be emphasized. The action is explicit but somewhat vague, as the authors know they need to address the pretraining method but may not be entirely clear on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4\" and \"the main paper,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of detailed discussion on unsupervised pretraining, which is a key factor in the performance gain, and suggests focusing more on this aspect. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the unsupervised pretraining is a key factor in the performance gain, as indicated by the data in Table 4. However, it notes that there is no detailed discussion on this topic in the main paper, which is a problem. The reviewer further supports this claim by comparing the importance of unsupervised pretraining with other modules, as shown in Table 5. This comparison provides a logical basis for the claim, making it 4. The comment could be strengthened by providing more detailed reasoning or specific examples, but it still offers a solid foundation for the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, specifically the lack of detailed discussion on the unsupervised pretraining method, despite its apparent importance in achieving performance gains. By referencing specific data in Table 4 and comparing it with the ablation study in Table 5, the reviewer provides a clear and actionable suggestion for the authors to focus more on the pretraining method in the main paper. This feedback is valuable as it highlights a critical aspect of the work that needs further elaboration, offering the authors a clear path to improve the comprehensiveness and depth of their analysis. However, the comment could be more helpful if it included specific suggestions on how to enhance the discussion on pretraining or what aspects to focus on. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should test their method on more datasets to get a better understanding of its performance. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not specify which datasets should be used or how the results should be analyzed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the method should be tested on more datasets to better understand its performance. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or results. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing attention. Additionally, the comment lacks specificity regarding which datasets should be considered or how the results should be analyzed. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the method should be tested on more datasets to better understand its performance. However, the comment does not provide any reasoning, examples, or references to support why testing on additional datasets is necessary or how it would improve the understanding of the method\"s performance. Without such evidence or justification, the claim remains 1, as the authors are left without a clear understanding of the basis for the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the authors should test their method on more datasets to better understand its performance. While this feedback identifies a potential area for improvement, it lacks specificity and does not provide guidance on which additional datasets should be considered or how the results should be analyzed. The comment is 3 as it points out a limitation in the current experimental setup, but it could be more beneficial if it included actionable suggestions or examples of datasets that might be relevant. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the domain of the inputs, suggesting that they might be lying in the same sphere but are not mentioned in the paper. While the comment implies that the authors should clarify this information, it does not provide explicit guidance on how to address the issue or what specific details should be included. The action is implicit and somewhat vague, as the authors need to infer that they should provide clarification on the domain of the inputs. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the domain of the inputs, suggesting that they might be lying in the same sphere but are not mentioned in the paper. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in its inquiry about the domain of the inputs, but without clear grounding, the authors may struggle to determine where to address this concern. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the domain of the inputs, suggesting that they might be lying in the same sphere but are not mentioned in the paper. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is a concern or how it affects the paper. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the domain of the inputs, suggesting that they might be lying in the same sphere but are not mentioned in the paper. This is a relevant point that could impact the clarity and comprehensiveness of the paper. However, the comment lacks specificity and does not provide guidance on how the authors might address this issue or what additional information should be included. While it identifies a potential area for improvement, the feedback is somewhat vague and incomplete, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point identifies a potential conflict between the second rule in Lemma 2, specifically Eq. (7), and the definition of minimal conditional dependence. It suggests that taking Z\" in the definition to be the empty set should result in x and y being independent given W, but Eq. (7) contradicts this. This feedback is explicit and provides a clear action for the authors to take: investigate and resolve the apparent contradiction between the second rule and the definition of minimal conditional dependence. The comment is 5 as it specifies the exact issue and guides the authors on how to address it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Second rule in Lemma 2, i.e., Eq (7) and the definition of minimal conditional dependence,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out a potential conflict between the second rule and the definition of minimal conditional dependence. The comment provides a specific example by suggesting that taking Z\" in the definition to be the empty set should result in x and y being independent given W, but Eq. (7) contradicts this. This level of detail makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a conflict between the second rule in Lemma 2, specifically Eq. (7), and the definition of minimal conditional dependence. The reviewer provides a logical reasoning by suggesting that taking Z\" in the definition to be the empty set should result in x and y being independent given W, but Eq. (7) contradicts this. This reasoning is clear and provides a specific example to support the claim, making it 4. However, the comment could be strengthened by referencing relevant literature or providing more detailed explanations of the conflict. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential conflict between the second rule in Lemma 2, specifically Eq. (7), and the definition of minimal conditional dependence. It provides a specific example by suggesting that taking Z\" in the definition to be the empty set should result in x and y being independent given W, but Eq. (7) contradicts this. This feedback is clear and actionable, as it directs the authors to investigate and resolve the apparent contradiction. By pointing out this specific issue, the comment offers a concrete way for the authors to improve their draft, making it 5. Therefore, the comment is rated as 5, consistent with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the distinction between Online Normalization and Batch Normalization, specifically regarding their impact on gradient bias. However, it does not provide any explicit or implicit actions for the authors to take. The comment does not suggest any changes or improvements to the draft, nor does it offer guidance on how the authors might clarify the issue or address the confusion. As a result, the authors are left without any actionable steps to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the distinction between Online Normalization and Batch Normalization, specifically regarding their impact on gradient bias. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its questioning of the bias and lack of clarity regarding the two normalization methods. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the distinction between Online Normalization and Batch Normalization, specifically regarding their impact on gradient bias. The reviewer acknowledges having read other reviews and the author\"s response, but the comment does not provide any additional reasoning, evidence, or references to support the claim that Online Normalization is unbiased and Batch Normalization is biased. Without further explanation or evidence, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the distinction between Online Normalization and Batch Normalization, specifically regarding their impact on gradient bias. It acknowledges having read other reviews and the author\"s response, but it does not provide any additional insights, suggestions, or constructive feedback to help the authors clarify the issue or improve their draft. The comment lacks depth and does not offer actionable guidance, leaving the authors without a clear understanding of how to address the confusion or enhance their work. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the clarity of the concept of \"local interactions,\" asking whether it refers to interactions within a time window or within the same modality. While the comment identifies a potential area of confusion, it does not provide explicit guidance or suggestions on how the authors should clarify this concept. The action is implicit, as the authors need to infer that they should provide additional explanation or clarification to address the confusion. However, the comment lacks concrete details on how to implement this clarification, making it 3.", "grounding_specificity_rationale": "The comment raises a question about the clarity of the concept of \"local interactions,\" specifically asking whether it refers to interactions within a time window or within the same modality. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its inquiry about the nature of local interactions, but without explicit references to sections or parts of the paper, the authors may find it challenging to pinpoint the exact area needing clarification. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the clarity of the concept of \"local interactions,\" specifically asking whether it refers to interactions within a time window or within the same modality. This is a request for clarification rather than a claim, as it does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a potential area of confusion regarding the concept of \"local interactions,\" specifically questioning whether it refers to interactions within a time window or within the same modality. This feedback is 3 as it points out a specific area where the authors might need to clarify their terminology or explanation. However, the comment does not provide detailed guidance on how to address this issue or suggest specific ways to improve the clarity of the concept. While it highlights a potential area for improvement, it lacks actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the results presented in Table 3, specifically questioning the validity and diversity of the proposed constrained method. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how the authors should address this issue, such as suggesting ways to improve the validity or diversity of the results or explaining the discrepancy. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the results, questioning the validity and diversity of the proposed constrained method. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper presents better results in the Molecule generation experiment (Table 3), but it questions the validity and diversity of the proposed constrained method. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without specific details or comparisons to other methods, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the results presented in Table 3, specifically questioning the validity and diversity of the proposed constrained method. This is a relevant observation that could impact the interpretation of the results and the overall validity of the paper. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their analysis. Without actionable feedback or specific recommendations, the authors are left without a clear path to enhance their draft. Therefore, the comment is 3, as it identifies a potential issue but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide more description of the Starcraft environment, possibly in an appendix. While the comment implies an action, it does not explicitly instruct the authors to add this description or specify where it should be included. The action is implicit and somewhat vague, as the authors need to infer that they should add more description and determine where it should be placed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should provide more description of the Starcraft environment, potentially in an appendix. However, it does not specify which part of the paper currently lacks this description, making it weakly grounded. The comment is specific in suggesting that additional information about the environment should be included, but it does not provide details on what aspects of the environment need more description. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper would benefit from more description of the Starcraft environment, potentially in an appendix. However, it does not provide any specific reasoning or examples to support why this additional description is necessary or how it would enhance the paper. Without detailed justification or examples, the claim lacks verifiability, making it difficult for the authors to understand the need for this change. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The comment suggests that the paper would benefit from more description of the Starcraft environment, potentially in an appendix. While it identifies a specific area for improvement, it lacks detailed guidance on what aspects of the environment should be described or how this additional information would enhance the paper. The feedback is 3 as it points out a potential gap in the paper, but it could be more actionable with specific suggestions or examples of what should be included. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the lack of innovation in the authors\" framework, noting that it combines existing techniques without proposing new ones. It specifically mentions that the domain adaptation method used is old and simple, suggesting that more effective methods could be used to improve performance. While the comment implies that the authors should consider using other domain adaptation methods, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on which methods to consider or how to implement them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the combination of existing techniques and the use of an old and simple domain adaptation method, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear critique of the lack of innovation and suggests using more effective domain adaptation methods to improve performance. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors\" framework combines existing techniques without innovation, specifically mentioning the use of an old and simple domain adaptation method. The reviewer provides a logical reasoning by pointing out that there are many effective domain adaptation methods proposed in recent years, suggesting that the authors should consider using them to improve performance. This reasoning is supported by the reference to the age of the domain adaptation method used, which adds credibility to the claim. However, the comment could be strengthened by providing specific examples of more effective methods or references to recent works in the field. Overall, the claim is 4, as it provides a logical basis but lacks detailed evidence or references. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the authors\" framework, noting that it combines existing techniques without innovation. It points out that the domain adaptation method used is old and simple, suggesting that more effective methods could be used to improve performance. The comment provides a clear and actionable suggestion by recommending the use of other domain adaptation methods, which could help the authors enhance their work. However, the comment could be more helpful if it provided specific examples of alternative methods or detailed guidance on how to integrate them into the framework. Overall, the feedback is 4 as it directs the authors toward a potential area for improvement, but it could be more comprehensive with additional details. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states that more experiments are necessary, implying that the authors should conduct additional experiments to broaden the scope of their study. However, it does not specify which game environments should be included or provide any guidance on how to design these experiments. The action is explicit but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment suggests that more experiments are needed, but it does not specify which part of the paper this pertains to, such as the experimental section or the results. Additionally, it does not provide details on what specific experiments are necessary or why they are needed. Without clear grounding or specificity, the authors cannot effectively address the feedback. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that \"more experiments are necessary\" but does not provide any reasoning or evidence to support this claim. It lacks specific examples or references to justify why additional experiments are needed or what benefits they would bring. Without detailed justification or examples, the claim remains 1, as the authors are left without a clear understanding of the basis for the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, noting that the experiments are only conducted on one game environment. It suggests that more experiments are necessary, which is a valid point that could enhance the robustness and generalizability of the findings. However, the comment lacks specificity and does not provide guidance on which additional game environments should be considered or how to design these experiments. While it highlights an area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "1", "actionability_rationale": "The review point critiques the authors\" claim of implementing ImageNet for the first time, noting that the process is slow and the accuracy is low. However, it does not provide any explicit or implicit actions for the authors to take in response to this feedback. There is no guidance on how to address the issues of speed or accuracy, nor are there suggestions for improvement. As a result, the authors are left without any actionable steps to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the authors\" claim of implementing ImageNet for the first time, noting that the process is slow and the accuracy is low. However, it does not specify which part of the paper this claim is based on, making it difficult for the authors to identify the exact section being addressed. Additionally, the comment lacks specificity regarding what aspects of the implementation or results are problematic, such as which steps are slow or how the accuracy could be improved. Without clear grounding and specificity, the authors are left without a clear understanding of what needs to be addressed. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the authors\" implementation of ImageNet is slow and has low accuracy, citing specific times and accuracy rates. This claim is 3 as it provides concrete data points to support the assertion. However, the comment lacks detailed reasoning or references to specific methods or benchmarks used for comparison, which would strengthen the verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the authors\" claim of implementing ImageNet for the first time, noting that the process is slow and the accuracy is low. However, it does not provide any actionable feedback or suggestions for improvement. The comment lacks specificity and does not offer guidance on how the authors might address the issues of speed or accuracy, or how they could enhance their implementation. Without actionable advice or constructive criticism, the comment does not help the authors improve their draft. Therefore, it is rated as 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the classification error of the proposed network compared to the standard softmax network. It suggests that the authors report the classification accuracy of the proposed classifier on ImageNet data and provides a rationale for why this is important. The comment also implies that theoretical justifications would be beneficial for addressing the issue. While the comment explicitly states the need for reporting classification accuracy on ImageNet data, it does not provide specific guidance on how to conduct the analysis or what theoretical justifications might be necessary. The action is explicit but somewhat vague, as the authors know what needs to be done but may not be entirely clear on the specifics of the analysis. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the classification error of the proposed network compared to the standard softmax network, suggesting that the authors report the classification accuracy of the proposed classifier on ImageNet data. It also implies that theoretical justifications would be beneficial for addressing the issue. However, the comment does not specify which part of the paper discusses the proposed network or its classification error, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in suggesting the need for reporting classification accuracy and theoretical justifications, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the classification error of the proposed network compared to the standard softmax network, suggesting that the authors report the classification accuracy of the proposed classifier on ImageNet data. The comment also implies that theoretical justifications would be beneficial for addressing the issue. While the comment provides a logical reasoning for the concern, it lacks specific examples or references to support the claim about the classification error. This makes the claim 3, as it requires additional evidence or detailed reasoning to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the classification error of the proposed network compared to the standard softmax network, suggesting that the authors report the classification accuracy of the proposed classifier on ImageNet data. It also implies that theoretical justifications would be beneficial for addressing the issue. While the comment identifies a potential weakness in the paper and provides a clear suggestion for improvement, it lacks specific guidance on how to conduct the analysis or what theoretical justifications might be necessary. The feedback is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details or examples. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the fairness of the experimental comparison, specifically questioning whether the compared methods were initialized with the same or similar pretrained models as the proposed method. It suggests that this lack of information could impact the results, as shown in Table 1. While the comment implies that the authors should clarify this aspect, it does not explicitly instruct them to do so or provide specific guidance on how to address the issue. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the initialization process, but they are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the experimental comparison, questioning the fairness due to the pretraining stage and the lack of information about the initialization of the compared methods. The comment provides a clear explanation of the problem and suggests that the proposed method without SSL performs inferior to most of the compared methods. This level of detail helps the authors understand what needs to be addressed in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental comparison with other methods is unfair because the proposed method was pretrained before the finetuning stage, while it is unclear if the compared methods were initialized with the same or similar pretrained models. The comment references Table 1, which shows that the proposed method without SSL performs inferior to most of the compared methods. This provides some justification for the claim, but it lacks specific examples or detailed reasoning about how the pretraining affects the results. The comment is 4, as it highlights a potential issue but could be strengthened with more detailed evidence or analysis.", "helpfulness_rationale": "The review comment identifies a potential issue with the experimental comparison, specifically questioning the fairness of the comparison due to the pretraining stage of the proposed method. It points out that the performance of the proposed method without SSL is inferior to most of the compared methods, suggesting that this may be due to the pretraining advantage. This feedback is clear and actionable, as it prompts the authors to clarify whether the compared methods were also initialized with pretrained models and, if not, to consider this factor in their analysis. By addressing this concern, the authors can improve the transparency and fairness of their experimental results. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or included examples of how to account for pretraining in the analysis. Overall, the comment is 4, as it directs the authors to a critical area for improvement in their experimental design."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper should describe possible alternate formulations for Confidence Diversity (CD) and questions the current form of CD, asking why entropy is not a good measure of \"amount of spreading of teacher predictions over the probability simplex among different (training) samples.\" The comment implies that the authors should provide additional explanations or examples to clarify these points. While the action is implicit, it is clear and concrete, as it specifies what the authors need to address: describing alternate formulations for CD and clarifying the role of entropy. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment suggests that the paper should describe possible alternate formulations for Confidence Diversity (CD) and questions the current form of CD, specifically asking why entropy is not a good measure of \"amount of spreading of teacher predictions over the probability simplex among different (training) samples.\" The comment references specific lines in the paper (lines 113 and 115), providing full grounding as the authors can accurately identify the parts being addressed. However, the comment lacks specificity because it does not provide detailed guidance on what aspects of CD should be clarified or how alternate formulations could be described. Therefore, this comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point suggests that the paper should describe possible alternate formulations for Confidence Diversity (CD) and questions the current form of CD, specifically asking why entropy is not a good measure of \"amount of spreading of teacher predictions over the probability simplex among different (training) samples.\" The comment provides a logical reasoning by questioning the current form of CD and suggesting that additional explanations or examples could clarify its role. However, it lacks specific references or detailed examples to fully substantiate the claim, making it 3. The authors would need to provide additional context or evidence to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the paper should describe possible alternate formulations for Confidence Diversity (CD). It questions the current form of CD and asks why entropy is not a good measure of \"amount of spreading of teacher predictions over the probability simplex among different (training) samples.\" This feedback is clear and actionable, as it directs the authors to provide additional explanations or examples to clarify the role of CD and its relationship to entropy. However, the comment could be more helpful if it offered specific suggestions or examples of alternate formulations, which would provide more detailed guidance for the authors. Overall, the comment is 4 as it highlights a critical area for improvement and provides a clear direction for the authors to enhance their draft."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy between the human baseline and the model baseline, noting that the human baseline is weaker due to only following a little more than 1 hour of speech recordings compared to the full 15 hours. The comment also points out that the abstract mentions beating the human baseline, which is misleading given the limited data the human baseline was exposed to. However, the comment does not provide explicit guidance on how the authors should address this issue or improve their draft. The action is implicit and somewhat vague, as it identifies a problem but does not offer specific steps for resolution. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.1\" and \"the abstract,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the discrepancy between the human baseline and the model baseline, noting that the human baseline is weaker due to only following a little more than 1 hour of speech recordings compared to the full 15 hours. Additionally, it critiques the abstract for being misleading given this limited exposure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the human baseline is weaker due to only following a little more than 1 hour of speech recordings compared to the full 15 hours, which is a significant factor in the comparison. The comment also critiques the abstract for being misleading, given this limited exposure. However, the comment lacks specific examples or references to support the claim about the human baseline being weaker, making it 3. The authors would need to further investigate the issue to fully understand the basis of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the human baseline, noting that it is weaker due to only following a little more than 1 hour of speech recordings compared to the full 15 hours. This observation is important as it highlights a potential flaw in the comparison between the human and model baselines. The comment also points out that the abstract is misleading by suggesting that the model baseline has already beaten the human baseline, which is not accurate given the limited data the human baseline was exposed to. However, the comment does not provide specific suggestions on how to address this issue or improve the draft. While it highlights a critical problem, it lacks actionable guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the related work discusses other methods for training NMT models beyond MLE, such as RL methods, but none of these methods is used as a baseline. However, the comment does not provide any explicit or implicit action for the authors to take. It does not suggest whether the authors should include these methods as baselines, compare their performance, or discuss their advantages and disadvantages. Without guidance on how to address this observation, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"related work\" and \"other methods for training NMT models beyond MLE,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that none of the discussed methods is used as a baseline, providing a clear direction for improvement. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the related work discusses other methods for training NMT models beyond MLE, such as RL methods, but none of these methods is used as a baseline. However, the comment does not provide specific examples or references to these other methods, making it difficult for the authors to verify the claim. Without detailed information or references, the authors may find it challenging to address the feedback effectively. Therefore, the comment is considered 2, as it lacks sufficient evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment points out a specific gap in the related work section, noting that while it discusses other methods for training NMT models beyond MLE, none of these methods is used as a baseline. This feedback is 3 as it identifies a potential area for improvement in the paper. However, it lacks actionable guidance on how the authors might address this issue, such as suggesting which methods could be used as baselines or why they are relevant. To be more helpful, the comment could provide more detailed suggestions or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the variability in the results with the chosen random projection matrix and suggests that pathological projection matrices could skew the MFTMA capacity and width scores. The reviewer acknowledges that this is unlikely with random projections but still recommends investigating the resilience of the metric to the choice of random projection. While the comment implies that the authors should explore this aspect, it does not provide explicit instructions on how to conduct this investigation or what specific steps to take. The action is implicit and somewhat vague, as the authors need to infer that they should explore the resilience of the metric and determine how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"3.a),\" indicating the specific part of the paper being addressed, allowing the authors to accurately identify the section. It is also specific because it raises a concern about the variability in results with the chosen random projection matrix and suggests that pathological projection matrices could skew the MFTMA capacity and width scores. The reviewer acknowledges that this is unlikely with random projections but still recommends investigating the resilience of the metric to the choice of random projection. While the comment does not specify where this investigation should be conducted, the authors can infer that it relates to the methodology or results sections. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the variability in results with the chosen random projection matrix and suggests that pathological projection matrices could skew the MFTMA capacity and width scores. The reviewer acknowledges that this is unlikely with random projections but still recommends investigating the resilience of the metric to the choice of random projection. While the comment provides a logical reasoning for the concern, it lacks specific examples or references to support the claim. This makes the claim 3, as the authors would need to further explore and substantiate the issue themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the variability in results with the chosen random projection matrix and suggests that pathological projection matrices could skew the MFTMA capacity and width scores. The reviewer acknowledges that this is unlikely with random projections but still recommends investigating the resilience of the metric to the choice of random projection. While the comment identifies a potential issue, it lacks specific guidance on how to address this concern or what steps the authors should take to investigate the resilience of the metric. The feedback is 3 as it points out a potential area for improvement, but it could be more actionable with additional details or suggestions. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the evaluation of FGT should be used to evaluate the performance of the proposed method and comparative methods, rather than just in the ablation study. This feedback is explicit and provides a clear action for the authors to take, which is to include the evaluation of FGT in the main performance evaluation. However, it does not specify how the authors should implement this change or provide detailed guidance on what specific aspects of FGT should be evaluated. While the action is explicit, the lack of concrete details makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the evaluation of FGT,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the evaluation of FGT should be used to evaluate the performance of the proposed method and comparative methods, rather than just in the ablation study. This provides clear guidance on how to improve the evaluation section of the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation of FGT should be used to evaluate the performance of the proposed method and comparative methods, rather than just in the ablation study. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this change is necessary or beneficial. Without additional context or explanation, the claim remains vague and difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the evaluation of the proposed method, noting that the evaluation of FGT is only used in the ablation study and should be extended to evaluate the performance of the proposed method and comparative methods. This feedback is clear and actionable, as it provides a direct suggestion for improving the evaluation section of the paper. By addressing this point, the authors can enhance the comprehensiveness and robustness of their evaluation, which is crucial for validating the effectiveness of their method. However, the comment could be more helpful if it provided additional guidance on how to incorporate FGT into the main evaluation or suggested specific metrics to consider. Overall, the comment is 4 as it directs the authors toward a meaningful improvement in their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential limitation of the work, noting that its focus on a narrow task and a specific language may restrict its broader impact. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how the authors might broaden the scope of their work or address the issue of limited impact. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment highlights a potential limitation of the work, noting that its focus on a narrow task (climate change QA) and a specific language (Arabic) may limit its broader impact. However, it does not specify which part of the paper this observation is based on, making it difficult for the authors to identify the exact section that needs attention. Additionally, while the comment points out a limitation, it does not provide specific guidance on how to address this issue or improve the broader impact of the work. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the work\"s focus on a narrow task (climate change QA) and a specific language (Arabic) may limit its broader impact. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a potential limitation of the work, noting that its focus on a narrow task (climate change QA) and a specific language (Arabic) may restrict its broader impact. While this observation is relevant, the comment lacks specificity and actionable guidance on how the authors might address this limitation or expand the scope of their work. Without detailed suggestions or examples, the feedback does not provide the authors with a clear path for improvement. Therefore, the comment is 3, as it identifies a potential issue but does not offer comprehensive guidance for addressing it."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the generalizability of the evaluation on a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that the authors should clarify the criteria behind this selection and whether other tasks or datasets might yield different insights. While the comment implies that the authors should provide more information on the selection process and its implications, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the choice to evaluate on only a subset of the Massive Text Embedding Benchmark (MTEB), questioning the generalizability of the results. It suggests that the authors should clarify the criteria behind this selection and whether other tasks or datasets might yield different insights. However, the comment does not specify which part of the paper discusses this evaluation, making it weakly grounded. The authors can infer that it relates to the experimental section, but the lack of explicit reference makes it challenging to pinpoint the exact location. The comment is specific in its request for clarification on the selection criteria and potential implications, but the lack of grounding limits its effectiveness. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the choice to evaluate on only a subset of the Massive Text Embedding Benchmark (MTEB), questioning the generalizability of the results. The comment suggests that the authors should clarify the criteria behind this selection and whether other tasks or datasets might yield different insights. While the comment highlights a potential issue, it does not provide specific examples or references to support the claim that other tasks or datasets might yield different insights. The reasoning is logical but lacks detailed evidence or examples, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the generalizability of the evaluation by questioning the choice to evaluate on only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that the authors should clarify the criteria behind this selection and whether other tasks or datasets might yield different insights. This feedback is clear and actionable, as it prompts the authors to provide more context and justification for their evaluation methodology. By addressing this point, the authors can enhance the transparency and robustness of their results. However, the comment could be more helpful if it provided specific suggestions on how to expand the evaluation or included examples of alternative datasets or tasks that could be considered. Overall, the comment is 4, as it directs the authors to a critical area for improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states that the description of experimental details is lacking clarity, which makes it difficult for the reader to judge the results. It suggests that the manuscript would benefit from increased clarity in the experimental description. However, it does not provide specific guidance on how to improve the clarity or what aspects of the description need more detail. The action is explicit but vague, as the authors are left to infer the exact changes needed to enhance clarity. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiment description,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of lacking detail and suggests that increased clarity is needed to allow the reader to better judge the results. The comment provides a clear direction for improvement by referencing the \"Questions\" section for further details. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the description of experimental details lacks clarity, making it difficult for the reader to judge the results. However, it does not provide specific examples or detailed reasoning to support this claim. The reference to \"Questions\" for further details does not fully substantiate the claim, as it does not offer additional context or evidence. Without specific examples or detailed justification, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is rated as 3, as it provides some basis for the claim but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of clarity in the experimental description, which makes it difficult for the reader to judge the results. It suggests that the manuscript would benefit from increased clarity in the experimental details. However, the comment does not provide specific guidance or examples on how to improve the clarity or what aspects of the description need more detail. While it highlights an important area for improvement, the feedback lacks depth and actionable suggestions, making it 3. The authors are given a general direction but need to infer the exact changes needed to enhance the clarity of the experimental description. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that the paper is not selfcontained and requires the supplementary material to understand large parts of the main paper. It also requests the authors to release the source code of their experiments to allow reproducibility. While the comment explicitly states the need for the supplementary material and the release of source code, it does not provide specific guidance on how to improve the selfcontainment of the main paper or how to make the source code available. The action is explicit but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment addresses the issue of the paper\"s selfcontainment, noting that the supplementary material is necessary to understand large parts of the main paper. It also requests the release of the source code for reproducibility. However, the comment does not specify which parts of the paper are not selfcontained or how the supplementary material is necessary. Additionally, it does not provide specific guidance on how to improve the selfcontainment or release the source code. While the authors can infer that the comment relates to the overall structure and reproducibility of the paper, the lack of specificity and detailed guidance makes it 2. Therefore, this comment is categorized as 2.", "verifiability_rationale": "The review point claims that the paper is not selfcontained and requires the supplementary material to understand large parts of the main paper. It also requests the release of the source code for reproducibility. However, the comment lacks specific examples or detailed reasoning to support the claim that the paper is not selfcontained. Without such evidence or examples, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 2, as it provides some basis for the request but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s selfcontainment, noting that the supplementary material is necessary to understand large parts of the main paper. It also requests the release of the source code for reproducibility, which is a crucial step in ensuring the paper\"s impact and credibility. While the comment highlights important areas for improvement, it could be more helpful by providing specific suggestions on how to enhance the selfcontainment of the main paper or by offering guidance on how to make the source code available. Despite this, the feedback is 4 as it directs the authors to address critical aspects of their work that can significantly improve its quality and impact. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide a description of why certain choices were made, such as the use of the REINFORCE algorithm for training instead of PPO. The reviewer implies that this choice might be related to the attention model paper the current paper iterates on, but clarifies that this is only a presumption. While the comment explicitly states that the authors should provide clarification, it does not specify how to do so or what specific aspects of the choice should be explained. The action is explicit but somewhat vague, as the authors know they need to provide clarification but may not be entirely sure of the exact details to include. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should provide a description of why certain choices were made, such as the use of the REINFORCE algorithm for training instead of PPO. It implies that this choice might be related to the attention model paper the current paper iterates on, but it does not specify which part of the paper this discussion should be included in. While the authors can infer that it relates to the methodology or experimental setup, the comment lacks full grounding as it does not explicitly mention a specific section. However, it is specific in suggesting that the authors should clarify their choice of algorithms. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide a rationale for their choice of algorithms, specifically questioning the use of REINFORCE over PPO. The reviewer implies that this choice might be related to the attention model paper the current paper iterates on, but acknowledges that this is only a presumption. The comment does not provide specific evidence or references to support the claim that REINFORCE is a better choice, nor does it explain why PPO might not be suitable. This lack of detailed justification or evidence makes the claim 3, as the authors would need to infer the reasoning behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should provide a rationale for their choice of algorithms, specifically questioning the use of REINFORCE over PPO. It implies that this choice might be related to the attention model paper the current paper iterates on, but clarifies that this is only a presumption. The comment is clear and actionable, as it prompts the authors to explain their reasoning behind specific choices, which can enhance the transparency and comprehensibility of the paper. However, it could be more helpful if it provided specific guidance on what aspects of the choice should be explained or referenced. Overall, the comment is 4, as it directs the authors to improve their draft by providing additional context and justification for their methodology choices."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly mentions the need for a discussion about the Set Transformer and other related works that use summary tokens. This provides a clear action for the authors to take, which is to include a discussion on these topics. However, the comment does not specify how this discussion should be integrated into the paper or what specific aspects should be covered. While the action is explicit, the lack of detailed guidance makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Set Transformer\" and provides a link to the relevant paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the missing discussion about the Set Transformer and other related works that use summary tokens. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a discussion about the Set Transformer and other related works that use summary tokens. However, it does not provide any specific reasoning or evidence to support why this discussion is necessary or how it would enhance the paper. The reference to the Set Transformer is a factual statement, but it does not contribute to the claim itself. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks discussion, namely the Set Transformer and other related works that use summary tokens. This feedback is clear and actionable, as it directs the authors to include a discussion on these topics, which could enhance the context and relevance of their work. However, the comment could be more helpful if it provided suggestions on how to integrate this discussion or why it is important for the paper. Despite this, the feedback is 4 as it guides the authors toward a meaningful improvement in their draft. Therefore, it aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a lack of details regarding how the network is made to fit the residual instead of directly learning the inputoutput mapping. However, it does not provide explicit guidance or suggestions on what the authors should do to address this issue. The comment implies that the authors should include more details on this aspect, but it lacks concrete instructions on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of fitting the network to the residual rather than directly learning the inputoutput mapping. This allows the authors to accurately identify the part of the paper being addressed. However, the comment is not specific because it does not provide detailed guidance on what aspects of the network fitting process need clarification or improvement. Therefore, this comment is 4, aligning with category 4.", "verifiability_rationale": "The review point questions the lack of details on how the network is made to fit the residual instead of directly learning the inputoutput mapping. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the network architecture, specifically the lack of details on how it fits the residual instead of directly learning the inputoutput mapping. This is a relevant observation that could help the authors clarify their approach and potentially improve the clarity of their work. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending additional explanations or examples. While it points out a potential weakness, it lacks actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks for details about the experiment setup in Section 3.3, specifically mentioning data augmentation methods, learning rate, etc. This request is clear and direct, providing the authors with a specific action to take. The inclusion of a reference to a relevant paper further supports the action by providing a source for the authors to consider. Therefore, this comment is 5, as it clearly instructs the authors on what information to include and where to find additional guidance.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the details about the experiment setup, such as data augmentation methods and learning rate. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a factual question about the experiment setup in Section 3.3, specifically asking for details on data augmentation methods and learning rate. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area for improvement by asking for details about the experiment setup in Section 3.3. It requests information on data augmentation methods and learning rate, which are important aspects of the experimental design. However, the comment could be more helpful if it provided additional context or suggestions on how to present this information effectively. By prompting the authors to clarify these details, the comment does offer some guidance, but it lacks depth and specificity to be fully actionable. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the authors performed a statistical significance test when comparing the proposed method with baselines. While it implies that the authors should consider conducting such a test, the comment does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to conduct the test or what parameters to consider. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the statistical significance of the numbers presented in the paper, specifically in the comparison between the proposed method and baselines. However, it does not specify which part of the paper this comparison is discussed in, making it weakly grounded. The comment is specific in its request for a statistical significance test, but without clear grounding, the authors may struggle to identify the exact section needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the statistical significance of the numbers presented in the paper, specifically in the comparison between the proposed method and baselines. However, it does not provide any evidence, reasoning, or references to support the claim that the numbers are close or to suggest that a statistical significance test is necessary. Without additional context or justification, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the statistical significance of the numbers presented in the paper, specifically in the comparison between the proposed method and baselines. This is a critical aspect that can impact the interpretation and validity of the results. However, the comment lacks depth and does not provide specific guidance on how to address this issue or what statistical tests might be appropriate. While it identifies a potential area for improvement, the feedback is somewhat vague and incomplete, making it 3. The authors are given a direction to consider but are not fully equipped with actionable steps to enhance their draft. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the choice of significance testing might be incorrect and proposes using a paired test setting, such as the Wilcoxon signedrank test, instead of the current method. While the comment implies that the authors should reconsider their choice of test, it does not explicitly instruct them to do so or provide detailed guidance on how to implement this change. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their test choice and potentially switch to a paired test setting. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the choice of significance testing and suggests that the authors should consider using a paired test setting, such as the Wilcoxon signedrank test, instead of the current method. However, it does not specify which part of the paper discusses the significance testing or where the current method is described, making it weakly grounded. The comment is specific in suggesting an alternative test setting, but without clear grounding, the authors may struggle to identify the exact part of the paper that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the choice of significance testing might be incorrect and suggests using a paired test setting, such as the Wilcoxon signedrank test, instead of the current method. However, the comment does not provide any reasoning or evidence to support why the current method is incorrect or why a paired test setting would be more appropriate. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the choice of significance testing in the paper, suggesting that a paired test setting, such as the Wilcoxon signedrank test, might be more appropriate. This feedback is 3 as it points out a specific area for improvement and provides a suggestion for an alternative approach. However, the comment lacks detailed guidance on why the current method might be incorrect or how to implement the suggested change, which could be more beneficial for the authors. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the organization of the paper could be improved by providing more background knowledge on the proposed method and moving the description of related literature forward. However, it does not specify how the authors should achieve this improvement or provide concrete steps for restructuring the paper. The action is implicit and vague, as the authors are left to infer what changes are needed without detailed guidance. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the organization of the paper could be improved by providing more background knowledge on the proposed method and moving the description of related literature forward. However, it does not specify which part of the paper is currently lacking in these aspects, making it difficult for the authors to pinpoint the exact sections that need revision. The comment is 1 as it does not identify a specific part of the paper, and it is also not specific because it lacks detailed guidance on what changes are needed. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the organization of the paper could be improved by providing more background knowledge on the proposed method and moving the description of related literature forward. However, the comment does not provide specific examples or detailed reasoning to support why these changes would improve the paper. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered 2, as it lacks sufficient detail to fully substantiate the recommendation.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the organization of the paper, suggesting that more background knowledge on the proposed method and a forward placement of related literature descriptions could enhance the paper. While the comment highlights a specific aspect that could be addressed, it lacks detailed guidance or suggestions on how to implement these changes. The feedback is 3 as it points out a general area for improvement, but it does not provide actionable steps or specific examples, leaving the authors with a vague idea of what needs to be done. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that some representative panoptic segmentation models, such as PanopticFPN, Mask2Former, etc., are not compared in the paper. While it identifies a specific area for improvement, it does not provide explicit guidance on which models should be included or how they should be integrated into the comparison. The action is implicit and somewhat vague, as the authors need to infer that they should include these models in their comparison. However, the comment does provide a clear direction for improvement by specifying the models that should be considered. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment highlights that some representative panoptic segmentation models, such as PanopticFPN, Mask2Former, etc., are not compared in the paper. However, it does not specify which part of the paper this comparison should be included in, making it weakly grounded. The comment is specific in identifying the models that should be considered for comparison, but without explicit references to sections or parts of the paper, the authors may struggle to determine where to incorporate this feedback. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that \"Some other representative panoptic segmentation models are not compared, like PanopticFPN, Mask2Former, etc.\" However, it does not provide any reasoning or evidence to support why these models should be included in the comparison or how they would contribute to the paper. The comment lacks specific examples or references to justify the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out that some representative panoptic segmentation models, such as PanopticFPN and Mask2Former, are not included in the comparison. This feedback is clear and actionable, as it provides the authors with a specific list of models to consider for inclusion in their comparison. However, the comment could be more helpful if it explained why these models are important or how their inclusion would enhance the paper. Despite this, the feedback is 4 as it directs the authors to a concrete area for improvement, providing them with a clear path to enhance their work."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests adding results in other modalities, specifically mentioning languagerelated tasks. It also implies that expected test loss might not be as meaningful for languagerelated tasks, suggesting that other metrics should be considered. While the comment provides a clear direction for expanding the results to include other modalities, it does not specify which modalities or tasks should be included or how to present the results. The action is explicit but somewhat vague, as the authors need to infer the specific modalities and metrics to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests adding results in other modalities, specifically mentioning languagerelated tasks. It also implies that expected test loss might not be as meaningful for languagerelated tasks, suggesting that other metrics should be considered. However, the comment does not specify which part of the paper should include these additional results or where the current results are presented. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper the comment addresses. The comment is specific in suggesting the inclusion of results in other modalities and questioning the relevance of expected test loss for languagerelated tasks. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests adding results in other modalities, specifically mentioning languagerelated tasks. It also implies that expected test loss might not be as meaningful for languagerelated tasks, suggesting that other metrics should be considered. However, the comment lacks specific examples or references to support the claim that other modalities or metrics are more relevant. The suggestion is 3 as it provides a logical reasoning for considering additional modalities, but the lack of detailed justification or examples makes it difficult for the authors to fully understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests expanding the results to include other modalities, specifically mentioning languagerelated tasks. It also questions the relevance of expected test loss for languagerelated tasks, suggesting that other metrics might be more meaningful. While the comment provides a clear direction for enhancing the paper by including additional results, it lacks specific guidance on which languagerelated tasks to consider or how to present the results. Additionally, the comment could be more helpful if it offered suggestions on alternative metrics or provided examples of how to incorporate them. Despite these limitations, the feedback is 3 as it prompts the authors to consider broader applicability and relevance of their work. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the recent related work CoCoOp should be compared in the experiments, even though it is a CVPR\"22 work that was published after the NeurIPS deadline. The reviewer provides a clear and direct action for the authors to take, which is to include a comparison with CoCoOp in their experiments. This feedback is specific and actionable, as it provides a concrete step for the authors to follow. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the recent related work \"CoCoOp\" and the need to compare it in the experiments. This allows the authors to accurately identify the part of the paper being addressed, specifically the experimental section. The comment is also specific because it clearly specifies what needs to be addressed, which is the comparison with CoCoOp. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the recent related work CoCoOp should be compared in the experiments, even though it is a CVPR\"22 work that was published after the NeurIPS deadline. The reviewer provides a logical reasoning by stating that CoCoOp is an extended version of CoOp, which is relevant to the paper. However, the comment lacks specific references or detailed justification for why CoCoOp should be included in the experiments, making it 3. The authors would need to further explore the relevance and significance of CoCoOp to fully understand the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific omission in the paper\"s experimental comparison, noting that the recent related work CoCoOp should be included despite being published after the NeurIPS deadline. This feedback is clear and actionable, as it provides a direct suggestion for the authors to enhance the comprehensiveness of their experimental evaluation. By including CoCoOp, the authors can provide a more complete comparison and analysis of their work. However, the comment could be more helpful if it explained why CoCoOp is relevant or how it relates to the paper\"s findings. Overall, the comment is 4 as it guides the authors toward a specific improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should conduct experiments on more complex problems, particularly those with larger depths that could lead to significant inputs for value and policy functions. However, it does not provide specific guidance on which complex problems to consider or how to conduct these experiments. The action is implicit and somewhat vague, as the authors are left to infer the need for additional experiments without detailed instructions on how to implement them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should conduct experiments on more complex problems, particularly those with larger depths that could lead to significant inputs for value and policy functions. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the experimental results or methodology, but the lack of explicit grounding makes it difficult to pinpoint the exact part of the paper being addressed. The comment is specific in suggesting the need for more complex experiments, but without clear grounding, it aligns with a score of 2.", "verifiability_rationale": "The review point suggests that the authors should conduct experiments on more complex problems, particularly those with larger depths that could lead to significant inputs for value and policy functions. However, the comment lacks specific examples or references to support the claim that the current experiments are insufficient or that more complex problems are necessary. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should conduct experiments on more complex problems, particularly those with larger depths that could lead to significant inputs for value and policy functions. This feedback is 3 as it identifies a potential area for improvement by suggesting that the current experiments may not adequately address more complex scenarios. However, the comment lacks specificity and does not provide detailed guidance on how to conduct these experiments or what specific complexities should be considered. While it points out a direction for further exploration, it does not offer actionable steps or detailed suggestions, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of discussion on the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. While it identifies an area that needs further exploration, it does not provide explicit guidance on how the authors should address this issue or what specific aspects should be discussed. The action is implicit and somewhat vague, as the authors are left to infer that they need to add a discussion on the theoretical guarantee but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights a lack of discussion on the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in identifying the missing discussion on the theoretical guarantee, but without explicit references to sections or parts of the paper, the authors may find it challenging to pinpoint the exact location for improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks discussion on the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks discussion, namely the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. This feedback is clear and actionable, as it points out a gap in the paper that the authors can address by including a discussion on the theoretical guarantee. However, the comment could be more helpful if it provided suggestions on how to approach this discussion or what aspects to consider. Overall, the comment is 4 as it directs the authors to an important area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of quantitative measures to evaluate the generated VCEs, noting that evaluation is primarily based on visual inspection. While the comment identifies a gap in the evaluation process, it does not provide specific guidance on how to address this issue or suggest alternative quantitative measures that could be used. The action is implicit and somewhat vague, as the authors are left to infer that they need to introduce quantitative evaluation methods but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights a lack of quantitative measures for evaluating the generated VCEs, noting that evaluation is primarily based on visual inspection. However, it does not specify which part of the paper this issue pertains to, such as a specific section or experiment where evaluation is discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in identifying the need for quantitative measures, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the evaluation of the generated VCEs lacks quantitative measures and is primarily based on visual inspection. This claim is 3 as it highlights a potential gap in the evaluation process, suggesting that a more rigorous approach could be beneficial. However, the comment does not provide specific examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. The lack of detailed justification or evidence limits the claim\"s verifiability, aligning with a score of 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the evaluation process of the generated VCEs, noting that it is primarily based on visual inspection rather than quantitative measures. This feedback is valuable as it highlights a gap in the evaluation methodology, prompting the authors to consider incorporating more rigorous and objective evaluation techniques. However, the comment lacks specific suggestions or examples of quantitative measures that could be employed, which would make it more actionable and helpful. While it points out a critical area for improvement, the feedback could be more comprehensive with additional guidance. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights significant artifacts in the generated videos and notes that only some of the beach videos are convincing. It also mentions that the action recognition performance is below the current stateoftheart on the UCF dataset, which uses more complex architectures. However, the comment does not provide explicit guidance or suggestions on how to address these issues or improve the performance. The questions posed are not actionable as they do not offer specific steps for the authors to take. The comment lacks concrete details on how to resolve the issues or enhance the performance, making it 1.", "grounding_specificity_rationale": "The comment highlights issues with the generated videos, specifically mentioning significant artifacts and the performance of action recognition on the UCF dataset. However, it does not specify which sections of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the problems with the generated videos and the action recognition performance, but without clear references to specific sections, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the generated videos have significant artifacts and that the action recognition performance is below the current stateoftheart on the UCF dataset. However, it does not provide specific examples or detailed reasoning to support these claims. The mention of deeper architectures and optic flow processing in the UCF dataset is a vague reference that does not fully substantiate the claim. Without concrete evidence or detailed analysis, the authors may find it challenging to address the issues effectively. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claims.", "helpfulness_rationale": "The review comment identifies two specific issues with the generated videos: significant artifacts and a performance gap in action recognition compared to the current stateoftheart on the UCF dataset. It also raises questions about the quality of the generated videos and the action recognition performance. However, the comment lacks depth and does not provide actionable suggestions or guidance on how to address these issues or improve the performance. Without specific advice or examples, the authors may find it challenging to make meaningful improvements based on this feedback. Therefore, the comment is 3, as it points out areas for improvement but does not offer detailed guidance or actionable steps."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the relevance of the term \"interpretable\" in the context of the work described by DoshiVelez and Kim. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on whether the authors should address this question, clarify the relevance, or make any changes to their draft. Without actionable suggestions or instructions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 54,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the relevance of the term \"interpretable\" in the context of the work of DoshiVelez and Kim. This provides clear guidance on what aspect of the paper needs clarification or further discussion. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the relevance of the term \"interpretable\" in the context of the work described by DoshiVelez and Kim. It does not contain an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the relevance of the term \"interpretable\" in the context of the work described by DoshiVelez and Kim. While it identifies a potential area for clarification, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve their draft. The comment lacks depth and actionable feedback, leaving the authors with only a vague indication of a possible area for improvement. Therefore, it is 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a limitation in the experiments, noting that they are restricted to MNIST and a single realworld dataset. However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or expand their experimental scope. Without guidance on potential additional datasets to include or alternative approaches to consider, the authors are left without a clear path for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a limitation in the experiments, noting that they are restricted to MNIST and a single realworld dataset. However, it does not specify which part of the paper this limitation is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the experiments are limited or how this limitation affects the paper\"s conclusions. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the experiments are limited to MNIST and a single realworld dataset. However, it does not provide any supporting evidence, reasoning, or examples to justify why this limitation is significant or how it affects the paper\"s conclusions. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment points out a limitation in the experiments, noting that they are restricted to MNIST and a single realworld dataset. While this observation is relevant, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this limitation or expand their experimental scope. Without actionable feedback or specific recommendations, the authors are left without a clear path for improvement. Therefore, the comment is 2, as it identifies a potential issue but does not offer meaningful guidance for addressing it."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should quantify and clarify the claim about ReLU not working well in deep or convolutional networks. It provides a specific example, the AlexNet paper, which used ReLUs and was considered deep and convolutional at the time. This feedback is explicit and provides a concrete suggestion for how the authors can address the issue, making it 5. The authors know exactly what needs to be done to improve their draft, which is to quantify and clarify the claim by referencing the AlexNet paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests quantifying and clarifying the claim about ReLU not working well in deep or convolutional networks. It provides a specific example, the AlexNet paper, which used ReLUs and was considered deep and convolutional at the time. This provides a clear direction for the authors to address the issue by referencing the AlexNet paper. However, the comment does not specify which part of the paper this claim is made in, making it weakly grounded. The suggestion is specific, as it provides a concrete example and a direction for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the claim about ReLU not working well in deep or convolutional networks should be quantified and clarified. The reviewer provides a specific example, the AlexNet paper, which used ReLUs and was considered deep and convolutional at the time. This example supports the claim by providing a historical context and a reference to a relevant work. However, the comment could be strengthened by providing more detailed reasoning or additional references to substantiate the claim further. Overall, the comment is 4, as it provides a solid foundation for the claim but lacks comprehensive evidence or detailed reasoning. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment suggests that the claim about ReLU not working well in deep or convolutional networks should be quantified and clarified. It provides a specific example, the AlexNet paper, which used ReLUs and was considered deep and convolutional at the time. This feedback is actionable as it directs the authors to provide more detailed evidence or examples to support their claim. However, the comment could be more helpful if it offered additional suggestions on how to quantify or clarify the claim, such as suggesting specific metrics or experiments to conduct. Overall, the comment is 4 as it provides a clear direction for improvement but could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors provide more explanations regarding the consistency between training and inference, which is implied by the smoothness of neural models. While the comment explicitly states the need for more explanations, it does not specify what aspects of the explanation should be expanded upon or how to present them. The action is explicit but somewhat vague, as the authors know they need to provide more explanations but may not be entirely sure of the specific details or format of those explanations. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (9597 and 308310) where the paper discusses the consistency between training and inference, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that more explanations are needed on this topic. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper addresses the consistency between training and inference, stating that it can be easily satisfied due to the smoothness of neural models. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed evidence or explanation, the authors may find it challenging to understand the basis of the suggestion for more explanations. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by suggesting that more explanations are needed regarding the consistency between training and inference, which is attributed to the smoothness of neural models. This feedback is clear and actionable, as it directs the authors to expand on a particular aspect of their work. However, the comment could be more helpful if it provided specific suggestions on what additional explanations might be necessary or how to present them. Overall, the comment is 4 as it guides the authors toward enhancing their draft, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the authors\" claim of superior performance with fewer parameters compared to a baseline model. It suggests that the authors should test their model with larger word embedding and LSTM parameters to backup their claim. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to conduct these experiments or what parameters to test. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about the model\"s superior performance with fewer parameters compared to a baseline, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the authors\" claim and suggesting that they test their model with larger word embedding and LSTM parameters to backup their claim. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the authors\" claim of superior performance with fewer parameters compared to a baseline model. It suggests that the authors should test their model with larger word embedding and LSTM parameters to backup their claim. This is a logical request for verification, as it challenges the authors to provide evidence for their claim. However, the comment does not provide specific examples or references to support the claim that the baseline model was tested with standard parameters. This makes the claim 3, as it lacks detailed evidence but provides a clear direction for the authors to address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the authors\" claim of superior performance with fewer parameters compared to a baseline model. It suggests that the authors should test their model with larger word embedding and LSTM parameters to backup their claim. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their draft by conducting additional experiments. However, the comment could be more helpful if it included suggestions on how to interpret the results or what parameters to test. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the introduction of two hyperparameters, k and \u03b7, which require finetuning. It suggests that this finetuning depends on the availability of the environment or a good OPE method. However, the comment does not provide any explicit guidance or suggestions on how the authors should address this issue. It lacks concrete details on what actions the authors should take to resolve the problem or improve the draft. As a result, the authors are left without a clear understanding of how to proceed, making the comment 1.", "grounding_specificity_rationale": "The comment addresses the introduction of two hyperparameters, k and \u03b7, and their dependence on finetuning, which is contingent on the availability of the environment or a good OPE method. However, it does not specify which part of the paper discusses these hyperparameters or where the issue of finetuning is raised. Without explicit references to sections or figures, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what needs to be addressed or improved, such as suggestions for addressing the dependency on finetuning or alternative approaches. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the introduction of two hyperparameters, k and \u03b7, requires finetuning, which depends on the availability of the environment or a good OPE method. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the introduction of two hyperparameters, k and \u03b7, which require finetuning. It highlights the dependency on the availability of the environment or a good OPE method, suggesting that this could be a limitation. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or mitigate its impact. Without actionable advice or additional context, the feedback is 3 as it points out a potential concern but does not offer a clear path for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point consists of three parts: a correction of a typographical error, a correction of a punctuation error, and a question about the convergence of the baseline MCL with deep learning. The first two parts are explicit and provide clear actions for the authors to take, making them 5. The third part is a question that seeks clarification, which is also explicit and actionable. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (108 and 115) where corrections are needed, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the corrections required, such as changing \"f\" to \"g\" and removing an extra period. Additionally, it raises a question about the convergence of the baseline MCL with deep learning, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of three parts: a correction of a typographical error, a correction of a punctuation error, and a question about the convergence of the baseline MCL with deep learning. The first two parts are factual corrections that do not require verification. The third part is a question seeking clarification, which is not a claim and does not require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by identifying typographical errors and punctuation mistakes in the manuscript. It also raises a question about the convergence of the baseline MCL with deep learning, which is a relevant concern for the authors to address. This feedback is clear and direct, offering the authors concrete steps to improve the accuracy and clarity of their draft. However, the comment could be more helpful if it included suggestions on how to ensure convergence or provided examples of how to address this issue. Overall, the comment is 4 as it effectively guides the authors in improving their draft, but it could be more comprehensive with additional guidance or examples."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges the limitations of FedPCL, noting its reliance on pretrained models and the sensitivity of model accuracy to these models. It also recognizes the authors\" efforts in developing a lightweight framework and integrating pretrained models for federated aggregation. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the limitations or improve the framework\"s applicability. Without actionable suggestions or specific directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the performance of FedPCL, noting its reliance on pretrained models and the sensitivity of model accuracy to these models. The comment acknowledges the authors\" efforts in developing a lightweight framework and integrating pretrained models for federated aggregation, which is a new approach for federated learning. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point acknowledges the limitations of FedPCL, noting its reliance on pretrained models and the sensitivity of model accuracy to these models. It also recognizes the authors\" efforts in developing a lightweight framework and integrating pretrained models for federated aggregation. However, the comment does not provide specific examples or detailed reasoning to support the claim about the limitations or the authors\" contributions. The lack of detailed evidence or references makes it difficult for the authors to fully understand and address the issues raised. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment acknowledges the limitations of FedPCL, specifically its reliance on pretrained models and the sensitivity of model accuracy to these models. It recognizes the authors\" efforts in developing a lightweight framework and integrating pretrained models for federated aggregation, which is a new approach for federated learning. However, the comment does not provide specific suggestions or guidance on how the authors might address these limitations or improve the framework\"s applicability. While it acknowledges the authors\" contributions, it lacks depth and actionable feedback, leaving the authors with limited insight into how to enhance their work. Therefore, the comment is 3, as it provides some recognition but lacks detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that it would be interesting to include not only the retrieved and final attentions but also the tentative attention maps in the qualitative figures. While the comment implies that the authors should add these maps, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to incorporate the tentative attention maps or what they should look like. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests adding the tentative attention maps to the qualitative figures, which implies that the reviewer is referring to the figures where the retrieved and final attentions are presented. However, it does not explicitly mention which figures or sections these are, making it weakly grounded. The comment is specific in suggesting the inclusion of the tentative attention maps, providing clear guidance on what could be added to enhance the figures. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it would be interesting to include not only the retrieved and final attentions but also the tentative attention maps in the qualitative figures. However, the comment does not provide any reasoning or justification for why this would be beneficial or how it would enhance the understanding of the results. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the significance of the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests an enhancement to the qualitative figures by recommending the inclusion of tentative attention maps alongside the retrieved and final attentions. This feedback is clear and actionable, as it provides a specific suggestion for improving the visual representation of the results. By including the tentative attention maps, the authors can offer a more comprehensive view of the attention mechanisms, which could enhance the understanding and interpretation of the results. However, the comment could be more helpful if it explained why these maps would be beneficial or how they might contribute to the overall understanding of the paper. Overall, the comment is 4 as it offers a constructive suggestion for improving the draft."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review comment indicates a potential issue with Figure 5, either suggesting that the reviewer does not understand it or that the labels are incorrect. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue, such as clarifying the labels or explaining the figure\"s content. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions \"Figure 5,\" which provides full grounding as it allows the authors to accurately identify the part of the paper being addressed. However, the comment lacks specificity because it does not explain what is unclear or what is wrong with the labels. It does not provide any guidance on how to address the issue or what needs to be clarified. Therefore, the comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point consists of a statement questioning the understanding of Figure 5 or the accuracy of its labels. It does not express an opinion, judgment, or suggestion that requires verification. It is purely descriptive and factual, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a concern about either the understanding of Figure 5 or the accuracy of its labels. However, it lacks specificity and does not provide any guidance or suggestions on how to address the issue. Without additional context or details, the authors are left without actionable feedback to improve their draft. The comment identifies a potential problem but does not offer any direction for resolution, making it 2 at best. Therefore, it aligns with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the authors\" derivation falls into classical learning theorybased bounds, which are not considered realistic unless Bayesian considerations are taken into account. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or improve their derivation. The comment lacks actionable details, such as recommending specific Bayesian considerations or suggesting alternative approaches. As a result, the authors are left without a clear understanding of what steps to take to improve their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the authors\" derivation, which is grounded as it pertains to the theoretical aspects of the paper. However, it does not specify which part of the derivation is being discussed, making it weakly grounded. The comment provides a specific critique by suggesting that the bounds are not realistic unless Bayesian considerations are taken into account, but it does not specify where or how these considerations should be incorporated. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors\" derivation falls into classical learning theorybased bounds, which are not considered realistic unless Bayesian considerations are taken into account. The reviewer provides a specific example of BayesianPAC based bounds, which suggests that the claim is 3. However, the comment lacks detailed reasoning or references to support the claim fully, such as explaining why Bayesian considerations are necessary or how they would improve the bounds. This makes the claim 3, as it provides a direction for improvement but requires more detailed justification.", "helpfulness_rationale": "The review comment identifies a specific issue with the authors\" derivation, noting that it falls into classical learning theorybased bounds, which are not considered realistic unless Bayesian considerations are taken into account. This feedback is 3 as it points out a potential limitation in the current approach and suggests a direction for improvement by considering BayesianPAC based bounds. However, the comment lacks detailed guidance or examples on how to incorporate Bayesian considerations or what specific aspects of the derivation need to be revised. While it provides some insight, it does not offer comprehensive or actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the application of weight decay to all layers, suggesting that this could lead to suboptimal training loss and cosine similarities for large weight decay parameters. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their analysis. It lacks concrete details on what actions the authors should take to resolve the problem or how they might interpret the results differently. As a result, the comment is vague and does not offer actionable steps for the authors to follow. Therefore, it is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"weight decay\" and \"cosine similarities,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the plots end at a weight decay strength where cosine similarities are still close to optimal, suggesting that this could be a limitation in the analysis. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that weight decay applied to all layers would lead to suboptimal training loss and cosine similarities for large weight decay parameters. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand or address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the application of weight decay to all layers, suggesting that it could lead to suboptimal training loss and cosine similarities for large weight decay parameters. It points out that the plots end at a weight decay strength where cosine similarities are still close to optimal, implying that this could be a limitation in the analysis. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their analysis. While it highlights a potential area for improvement, the feedback is somewhat vague and does not provide actionable steps for the authors to take. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a significant omission in the paper, noting that the title, abstract, introduction, and discussion do not explain that the results are for unsupervised random forests. This is considered a \"fairly serious omission\" that could lead to incorrect conclusions among casual readers. The reviewer emphasizes the importance of fixing this issue for publication, suggesting that it would be straightforward to do so. However, the comment does not provide specific guidance on how to address this omission, such as suggesting changes to the text or providing examples of how to clarify the results. While the action is explicit, it lacks concrete details on how to implement the suggested changes, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the title, abstract, introduction, and discussion, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the results are for unsupervised random forests, which is a critical omission that could lead to incorrect conclusions among casual readers. The comment provides a clear direction for improvement by suggesting that this omission needs to be fixed for publication. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the title, abstract, introduction, and discussion do not explain that the results are for unsupervised random forests, which is a \"fairly serious omission.\" The reviewer suggests that this omission could lead to incorrect conclusions among casual readers. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the exact nature of the omission and how to address it. The lack of detailed justification or examples makes the claim 3, as the authors would need to infer the specific issues and how to fix them. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical omission in the paper, specifically that the title, abstract, introduction, and discussion do not explain that the results are for unsupervised random forests. This is a significant issue that could lead to incorrect conclusions among casual readers. The reviewer emphasizes the importance of fixing this omission for publication, acknowledging that it would be straightforward to address. However, the comment does not provide specific suggestions or examples on how to clarify the results or improve the clarity of the paper. While it highlights a crucial area for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is rated as 3, as it provides insight into a critical issue but lacks actionable advice for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide more evidence or analysis to support the training effectiveness property of the dataset and other key properties that explain the importance and potential usecases of LMGQS over other QFS datasets. While the comment implies that the authors should include additional evidence or analysis, it does not specify what specific evidence or analysis is needed or how to present it. The action is implicit and somewhat vague, as the authors are left to infer the exact steps to take without detailed guidance. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that more evidence or analysis is needed to support the training effectiveness property of the dataset and other key properties that explain the importance and potential usecases of LMGQS over other QFS datasets. However, it does not specify which part of the paper this feedback pertains to, such as a specific section or analysis. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area that needs improvement. Additionally, while the comment provides a general direction for improvement, it lacks specificity in terms of what evidence or analysis is needed. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that more evidence or analysis is needed to support the training effectiveness property of the dataset and other key properties that explain the importance and potential usecases of LMGQS over other QFS datasets. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion. Without detailed justification or evidence, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper by suggesting that more evidence or analysis is needed to support the training effectiveness property of the dataset and other key properties that explain the importance and potential usecases of LMGQS over other QFS datasets. This feedback is clear and actionable, as it directs the authors to provide additional evidence or analysis to strengthen their claims. However, the comment could be more helpful if it offered specific suggestions on what kind of evidence or analysis would be most beneficial. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point raises a concern about the potential impact of regularization effects rather than distillation on the improvements in the teacher\"s performance. It suggests that the authors should conduct proper ablation studies to verify their claims. While the comment implies that the authors should conduct additional experiments, it does not provide specific guidance on how to design these experiments or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the need for additional experiments and determine the specifics themselves. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper, namely the claim that distilling knowledge from the student to the teacher improves the teacher\"s performance. It raises a concern about the potential impact of regularization effects rather than distillation, specifically mentioning the use of finetuning for 10 epochs without earlystopping. This provides clear guidance on what needs to be addressed, such as conducting proper ablation studies to verify the claims. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the improvements in the teacher\"s performance could be due to regularization effects rather than distillation, as all finetuning is performed for 10 epochs without earlystopping. The reviewer suggests that this could lead to high variances in the results, which is a valid concern. However, the comment lacks specific examples or references to support the claim about the potential impact of regularization effects. While the reasoning is logical, the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s claim that distilling knowledge from the student to the teacher improves the teacher\"s performance. It suggests that the improvements could be due to regularization effects rather than distillation, as all finetuning is performed for 10 epochs without earlystopping. The reviewer highlights the high variance in results when finetuning on GLUE without validation earlystopping, which is a valid concern. The comment provides a clear and actionable suggestion for the authors to conduct proper ablation studies to verify their claims. This feedback is detailed and constructive, offering a specific direction for the authors to improve their draft. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the use of node importance in the 1shot scenario and the absence of a 1shot paper setting in the experiments, despite the inclusion of related works like RALE that do have a 1shot setting. While the comment highlights potential issues and inconsistencies, it does not provide explicit or implicit actions for the authors to take. The authors are left without guidance on how to address these questions or concerns, making the comment 1. Therefore, this comment aligns with a score of 1 on the actionability scale.", "grounding_specificity_rationale": "The comment raises questions about the use of node importance in the 1shot scenario and the absence of a 1shot paper setting in the experiments, despite the inclusion of related works like RALE that do have a 1shot setting. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in its critique of the experimental setup and the comparison with related works, but without clear references to specific sections, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises questions about the use of node importance in the 1shot scenario and the absence of a 1shot paper setting in the experiments, despite the inclusion of related works like RALE that do have a 1shot setting. The comment provides a logical reasoning by pointing out the inconsistency between the paper\"s approach and the related works, which is a valid observation. However, it lacks specific examples or detailed explanations to fully substantiate the claim, making it 3. The authors would need to provide additional context or evidence to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises two important questions about the paper. First, it questions the relevance of node importance in the 1shot scenario, which is a critical aspect of the paper\"s methodology. Second, it points out that the paper does not include a 1shot paper setting in the experiments, despite related works like RALE having such a setting. This feedback is valuable as it highlights potential gaps in the paper\"s methodology and experimental design, prompting the authors to reconsider these aspects. However, the comment could be more helpful if it provided specific suggestions on how to address these issues or offered examples of how other works have implemented a 1shot setting. Overall, the comment is 3 as it identifies areas for improvement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper should include more discussions about why LLMs struggle with finegrained hard constraints and how to address these problems. While the comment implies that the authors should expand their discussion on this topic, it does not provide specific guidance on how to do so or what aspects should be included in the expanded discussion. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the suggestion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should include more discussions about why LLMs struggle with finegrained hard constraints and how to address these problems. However, it does not specify which part of the paper should include these discussions, making it weakly grounded. The comment is specific in its request for additional discussion on a particular topic, but without clear grounding, the authors may find it challenging to determine where to make these additions. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that there should be more discussions about why LLMs struggle with finegrained hard constraints and how to address these problems. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by suggesting that there should be more discussions about why LLMs struggle with finegrained hard constraints and how to address these problems. This feedback is clear and actionable, as it provides a direction for the authors to expand their discussion and potentially enhance the depth and relevance of their work. However, the comment could be more helpful if it offered specific suggestions or examples on how to approach this topic. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of insight into why selfsupervised learning is needed on 360 video data with spatial audio. However, it does not provide explicit guidance or suggestions on how the authors might address this issue. The comment implies that the authors should provide more justification or explanation, but it lacks concrete steps or details on how to achieve this. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the lack of insight into why selfsupervised learning is needed on 360 video data with spatial audio. However, it does not specify which part of the paper this issue pertains to, such as a specific section or discussion where this insight could be provided. Without explicit references to the paper, the authors cannot confidently determine the exact part of the paper being discussed. Additionally, the comment lacks specificity regarding what kind of insight is needed or how it could be provided. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the experimental results suggest the value of the proposed approach for selfsupervised learning on 360 video data with spatial audio, but it lacks insight into why this type of data requires selfsupervised learning. The comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that selfsupervised learning is necessary for this data. Without additional context or justification, the claim remains 1, as it does not offer the authors a clear path to address the issue. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the need for selfsupervised learning on 360 video data with spatial audio. It points out that while the experimental results suggest the value of the proposed approach, there is a lack of insight into why this type of data requires selfsupervised learning. This feedback is 3 as it highlights an area where the authors could provide more justification or explanation. However, the comment does not offer specific suggestions or guidance on how to address this issue, such as what additional insights or explanations could be provided. To be more helpful, the comment could include actionable advice or examples of how to enhance the discussion on the rationale for selfsupervised learning. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the analysis, noting that only the SimCLR case is covered and suggesting that the projection head, which is an important part of the approach, should be analyzed. However, it does not provide explicit guidance on how the authors should conduct this analysis or what specific aspects of the projection head should be examined. The action is implicit and somewhat vague, as the authors can infer that they need to expand their analysis to include the projection head, but they are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"SimCLR\" and \"projection head,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of analysis on an important aspect of the SimCLR approach, namely the projection head, and references recent papers that highlight its significance. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that only the SimCLR case is covered and suggests that the projection head, an important part of the approach, should be analyzed. However, the comment does not provide specific references or examples of recent papers that highlight the significance of the projection head, making it difficult for the authors to fully understand and address the issue. The lack of detailed evidence or references limits the verifiability of the claim, as the authors may struggle to determine the exact nature of the analysis needed. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a gap in the analysis by noting that only the SimCLR case is covered and suggests that the projection head, an important aspect of the approach, should be analyzed. This feedback is 3 as it points out a specific area for improvement, encouraging the authors to expand their analysis to include the projection head. However, the comment lacks detailed guidance on how to conduct this analysis or what specific aspects of the projection head should be examined. While it provides a clear direction for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a concern about the approximations introduced in the paper, specifically mentioning the potential vulnerability due to the assumption of attacks being in the feasible set. The reviewer suggests that this vulnerability should be expanded upon to reassure readers that it is not a real concern. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to address this issue or what specific steps the authors should take to expand on the vulnerability. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide additional explanation or evidence to address the concern. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (107110) where the assumption of attacks being in the feasible set is made. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it highlights a potential vulnerability in the approximations introduced and suggests that this vulnerability should be expanded upon to reassure readers. The feedback provides clear guidance on what needs to be addressed, making this comment 5. Therefore, it aligns with category 5.", "verifiability_rationale": "The review point claims that the approximations introduced in the paper leave loose ends and suggests that the potential vulnerability due to the assumption of attacks being in the feasible set should be expanded upon. However, the comment lacks specific examples or detailed reasoning to support the claim that the approximations are problematic or that the vulnerability is significant. Without additional context or evidence, the authors may find it challenging to understand and address the concern effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment identifies a potential issue with the approximations introduced in the paper, specifically mentioning the assumption of attacks being in the feasible set. It acknowledges the necessity of approximations for deriving clean results but highlights the need to address the potential vulnerability this assumption might introduce. The comment provides a clear direction for improvement by suggesting that the authors expand on this vulnerability to reassure readers that it is not a real concern. This feedback is actionable and constructive, as it guides the authors to address a specific area of their work that could impact the paper\"s credibility. However, it could be more helpful if it included specific suggestions on how to address the vulnerability or expand the discussion. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the experimental results, noting that the proposed method does not have an advantage over the stateoftheart (SOTA) without prior information. It suggests that the comparison is unfair because the proposed method requires two representation models, VAE/GAN and CL, which adds complexity and cost. While the comment identifies a potential issue with the experimental setup, it does not provide explicit guidance on how the authors should address this concern or improve their draft. The action is implicit and somewhat vague, as it lacks specific suggestions on how to adjust the experiments or present the results to address the issue. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental results\" and the \"proposed method,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the comparison, noting that the proposed method lacks an advantage without prior information and that the comparison is unfair due to the additional complexity and cost of using two representation models. The comment provides a clear explanation of what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed method lacks an advantage over the stateoftheart (SOTA) without prior information, and that the advantage only shows when using prior knowledge. The reviewer provides a logical reasoning by pointing out that the proposed method requires two representation models, VAE/GAN and CL, which adds complexity and cost. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the experimental setup, noting that the proposed method lacks an advantage over the stateoftheart (SOTA) without prior information. It points out that the advantage only appears when using prior knowledge, which the reviewer considers unfair because it requires two representation models (VAE/GAN and CL) for each dataset. This feedback highlights a critical aspect of the experimental design that could impact the evaluation of the proposed method. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as proposing alternative experimental setups or methods to mitigate the complexity and cost. Despite this, the comment is 3 as it directs the authors\" attention to a significant flaw in their experimental design, prompting them to consider improvements. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a limitation of the proposed model, stating that it can only be used with a small number of dimensions due to the curse of dimensionality imposed by the core tensor C. However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or improve the model\"s applicability. There is no guidance on potential modifications, alternative approaches, or additional experiments that could be conducted to overcome this issue. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment highlights a limitation of the proposed model, specifically mentioning the \"curse of dimensionality\" imposed by the core tensor C. However, it does not specify which part of the paper discusses the model or its limitations, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in identifying the issue with the model\"s applicability but lacks grounding, as it does not reference a particular section or element of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the new proposed model can only be used with a small number of dimensions due to the curse of dimensionality imposed by the core tensor C. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation of the proposed model, specifically noting that it can only be used with a small number of dimensions due to the curse of dimensionality imposed by the core tensor C. This is a relevant observation that could impact the model\"s applicability and usefulness. However, the comment does not provide any suggestions or guidance on how the authors might address this limitation or improve the model\"s performance. Without actionable feedback or potential solutions, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the potential negative transfer of supervised pretraining based on the prediction of homolumo gap, specifically mentioning the poor performance of TransformerM on most tasks other than homo, lumo, and gap on QM9 in downstream experiments. The comment challenges the claim of \"generalpurpose neural network model\" made in the paper. While the comment highlights a potential issue, it does not provide explicit guidance on how the authors should address this concern or improve their draft. The action is implicit and somewhat vague, as the authors are left to infer that they should reconsider their claims or provide additional evidence to support them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the prediction of homolumo gap and the performance of TransformerM on QM9 in downstream experiments, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of potential negative transfer and the contradiction with the claim of a \"generalpurpose neural network model.\" This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that supervised pretraining based on the prediction of homolumo gap may lead to negative transfer, citing the poor performance of TransformerM on most tasks other than homo, lumo, and gap on QM9 in downstream experiments. The comment challenges the claim of a \"generalpurpose neural network model\" made in the paper. While the claim is based on observed performance data, it lacks specific references or detailed analysis to fully substantiate the claim. The reasoning is 3, as it provides a logical connection between the pretraining method and the observed performance, but it could be strengthened with more detailed evidence or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the potential negative transfer of supervised pretraining based on the prediction of homolumo gap, specifically mentioning the poor performance of TransformerM on most tasks other than homo, lumo, and gap on QM9 in downstream experiments. This feedback challenges the claim of a \"generalpurpose neural network model\" made in the paper, suggesting that the model may not be as versatile as claimed. While the comment identifies a potential issue, it does not provide specific suggestions or guidance on how the authors might address this concern or improve their draft. The feedback is 3 as it highlights a critical area for consideration, but it lacks actionable advice, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point expresses a critique of the theoretical contribution, stating that it is \"ok but not particularly strong\" and that it is a \"weak, unpractical bound.\" However, it does not provide any explicit or implicit actions for the authors to take in response to this feedback. There is no guidance on how to strengthen the theoretical contribution or improve the practicality of the bound. The comment lacks actionable advice, leaving the authors without a clear path for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the theoretical contribution, stating that it is \"ok but not particularly strong\" and that it is a \"weak, unpractical bound.\" However, it does not specify which part of the paper this assessment is based on, nor does it provide details on what aspects of the theoretical contribution are weak or unpractical. Without explicit references to sections, figures, or specific elements of the theoretical contribution, the authors cannot confidently determine which parts of the paper need attention. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point critiques the theoretical contribution, stating that it is \"ok but not particularly strong\" and that it is a \"weak, unpractical bound.\" The reviewer references previous comments about the proof not providing \"particular mathematical novelty,\" which adds some support to the claim. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, making it 3. The authors would need to delve deeper into the context of the previous comments to fully understand the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the theoretical contribution, stating that it is \"ok but not particularly strong\" and that it is a \"weak, unpractical bound.\" It references previous comments about the proof not providing \"particular mathematical novelty,\" which adds some context to the critique. However, the comment lacks specificity and actionable feedback, such as suggesting ways to strengthen the theoretical contribution or improve the practicality of the bound. Without detailed guidance or suggestions for improvement, the authors are left with a general understanding of the critique but without a clear path forward. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a specific issue with the wording in lines 240 and 428, suggesting that the phrase \"is sufficient\" needs clarification. It provides a potential correction, indicating that the authors might want to write that the sum of the \"optimistic\" hopedfor rewards is close to the expected actual rewards. This feedback is explicit and provides a clear direction for the authors to improve their draft by clarifying the intended meaning. The action is concrete, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (L240 and L428), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified: the phrase \"is sufficient\" should be clarified by writing that the sum of the \"optimistic\" hopedfor rewards is close to the expected actual rewards. This provides clear guidance on how to improve the draft. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the phrase \"is sufficient\" in lines 240 and 428, suggesting that it should be clarified. The reviewer provides a potential correction, stating that the sum of the \"optimistic\" hopedfor rewards should be close to the expected actual rewards. However, the comment does not offer any further justification or evidence to support why this clarification is necessary or how it would improve the paper. The suggestion is logical but lacks detailed reasoning or references, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the wording in lines 240 and 428, where the phrase \"is sufficient\" is used without clear context. It suggests that the authors might want to clarify that the sum of the \"optimistic\" hopedfor rewards is close to the expected actual rewards. This feedback is clear and actionable, providing the authors with a specific direction to improve the clarity and precision of their writing. However, the comment could be more helpful if it explained why this clarification is important or how it might impact the reader\"s understanding. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the tradeoff between computation time reduction and the loss of information in the output of the proposed method compared to a previous work. It questions the extent to which the information of a DAG is encoded in its corresponding ancestral graph. While the comment highlights an important consideration, it does not provide explicit guidance or suggestions on how the authors should address this issue. The authors are left to infer that they might need to explore the tradeoffs further or provide additional analysis to clarify the impact of the reduced search space. However, the lack of concrete steps or specific actions makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed method and the work by 10, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by discussing the tradeoff between computation time reduction and the loss of information in the output, particularly in terms of the search space. The comment raises a question about the extent to which information from DAGs is encoded in ancestral graphs, which provides a clear direction for further exploration. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a claim about the tradeoff between computation time reduction and the loss of information in the output of the proposed method compared to a previous work. It provides a logical reasoning by explaining that the reduction in computation time is achieved by limiting the search space to ancestral graphs, which results in less information compared to the output of the previous work that has a richer search space of DAGs. However, the comment lacks specific references or examples to support the claim, making it 3. The authors would need to further explore the implications of this tradeoff to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a tradeoff in the proposed method, specifically the reduction in computation time achieved by limiting the search space to ancestral graphs, which results in a loss of information compared to the output of a previous work that has a richer search space of DAGs. This observation highlights an important consideration for the authors, as it points out a potential drawback of their approach. However, the comment does not provide specific suggestions or guidance on how the authors might address this tradeoff or mitigate the loss of information. While it raises an important issue, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly points out that the VAD description is puzzling and suggests that it is not a true VAD because it discards TF bins with a magnitude less than epsilon, which results in a division by zero. The reviewer provides a clear explanation of what a VAD should do and why the current approach is not accurate. This feedback is explicit and provides concrete guidance on how to improve the description of the VAD, making it 5. The authors know exactly what needs to be changed to align with the expectations of a VAD, and they are given a clear understanding of the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Your VAD description,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the VAD description, namely that it discards TF bins with a magnitude less than epsilon, which is not consistent with the definition of a VAD. The comment provides a detailed explanation of what a VAD should do and why the current approach is incorrect. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the VAD description is puzzling and suggests that it is not a true VAD because it discards TF bins with a magnitude less than epsilon, which results in a division by zero. The reviewer provides a clear explanation of what a VAD should do and why the current approach is not accurate. This reasoning is logical and wellsupported, making the claim 4. However, the comment could be strengthened by providing specific examples or references to established VAD methods for comparison. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a clear and specific critique of the VAD description, pointing out that it is puzzling and does not align with the typical definition of a VAD. The reviewer explains that the current approach discards TF bins with a magnitude less than epsilon, which is not consistent with the expected behavior of a VAD. The comment offers a detailed explanation of what a VAD should do and why the current approach is incorrect, providing the authors with a clear understanding of the issue and actionable guidance on how to improve their description. This feedback is 5 as it directly addresses a critical aspect of the paper, offering a specific and constructive suggestion for improvement. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the fairness of training the student and refinement networks simultaneously, suggesting that it may improve the performance of the teacher network. It also requests the inclusion of KID/FID metrics for the teacher network. While the comment implies that the authors should provide these metrics, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include the requested metrics. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the fairness of training the student and refinement networks simultaneously, suggesting that it may improve the performance of the teacher network. It also requests the inclusion of KID/FID metrics for the teacher network. However, the comment does not specify which part of the paper discusses this training method or where the KID/FID metrics should be included. While the authors might infer that it relates to the methodology or results sections, the lack of explicit references makes it weakly grounded. The comment is specific in its request for metrics, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point raises a question about the fairness of training the student and refinement networks simultaneously, suggesting that it may improve the performance of the teacher network. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. It lacks specific examples or detailed justification, making it difficult for the authors to understand the basis of the concern. As a result, the claim is 1, as it does not provide sufficient information for the authors to address it effectively.", "helpfulness_rationale": "The review comment raises a question about the fairness of training the student and refinement networks simultaneously, suggesting that it may improve the performance of the teacher network. It also requests the inclusion of KID/FID metrics for the teacher network. While the comment identifies a potential issue with the training methodology and provides a specific request for additional metrics, it lacks depth and does not offer detailed guidance on how to address the fairness concern or how to interpret the KID/FID metrics. The feedback is 3 as it points out an area for improvement, but it could be more actionable with additional context or suggestions. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper should include a deeper investigation into how specific models, such as GPT4o and InternVL2, behave differently when ReGuide is applied. It specifically mentions the importance of presenting differences in false positive rates (FPR) between models with and without ReGuide for a better comparison. While the comment implies that the authors should conduct this analysis, it does not provide explicit instructions on how to implement it or what specific metrics to focus on. The action is implicit and somewhat vague, as the authors can infer the need for additional analysis but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should include a deeper investigation into how specific models, such as GPT4o and InternVL2, behave differently when ReGuide is applied. It specifically mentions the importance of presenting differences in false positive rates (FPR) between models with and without ReGuide for a better comparison. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the sections discussing model performance or comparisons. The suggestion is specific in detailing what additional analysis could be included, such as comparing FPR between models. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should include a deeper investigation into how specific models, such as GPT4o and InternVL2, behave differently when ReGuide is applied. It specifically mentions the importance of presenting differences in false positive rates (FPR) between models with and without ReGuide for a better comparison. This claim is 3 as it provides a specific suggestion for enhancing the paper\"s analysis, but it lacks detailed reasoning or examples to fully substantiate the need for this additional investigation. The authors would need to infer the potential benefits of this analysis themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the paper should include a deeper investigation into how specific models, such as GPT4o and InternVL2, behave differently when ReGuide is applied. It provides a concrete example of how this could be achieved by comparing false positive rates (FPR) between models with and without ReGuide. This feedback is actionable and offers a clear direction for the authors to enhance their analysis, providing valuable guidance for improving the depth and nuance of their conclusions. However, the comment could be more helpful if it included additional suggestions or examples of other aspects to explore. Overall, the comment is 4 as it effectively directs the authors to a specific area for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the traditional DCI framework, suggesting that explicitness (E) and size (S) may already be considered in the evaluation. It provides an example of how the disentanglement (D) of different representation methods might be evaluated using a fixed capacity of probing (f) and a fixed latent size. The comment also notes that DCI and ES may be entangled, implying that changes in probing capacity or latent size could affect the DCI evaluation. However, the comment does not provide explicit guidance on how the authors should address these concerns or suggest specific actions to improve the evaluation. The feedback is 3 as it highlights an area for clarification but lacks concrete steps for the authors to follow.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"traditional DCI framework,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with evaluating disentanglement (D) using a fixed capacity of probing (f) and a fixed latent size, noting that DCI and ES may be entangled. The comment further requests clarification on the motivation for considering explicitness (E) and size (S) as extra evaluation. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the traditional DCI framework, suggesting that explicitness (E) and size (S) may already be considered in the evaluation. It provides an example of how the disentanglement (D) of different representation methods might be evaluated using a fixed capacity of probing (f) and a fixed latent size. The comment also notes that DCI and ES may be entangled, implying that changes in probing capacity or latent size could affect the DCI evaluation. However, the comment lacks specific references or detailed reasoning to fully substantiate the claim, making it 3. The authors would need to further explore the logic and evidence behind the claim to fully understand and address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the traditional DCI framework, suggesting that explicitness (E) and size (S) may already be considered in the evaluation. It provides an example of how the disentanglement (D) of different representation methods might be evaluated using a fixed capacity of probing (f) and a fixed latent size. The comment also notes that DCI and ES may be entangled, implying that changes in probing capacity or latent size could affect the DCI evaluation. However, the comment lacks specific suggestions or guidance on how the authors might address these concerns or improve their evaluation methodology. While it highlights an area for clarification, the feedback is somewhat vague and incomplete, making it 3 for the authors to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the practicality and safety of the interventions discussed in the paper, suggesting that the authors should consider these aspects when thinking about querying in the real world. However, it does not provide explicit guidance on how to address this concern or what specific steps the authors should take to evaluate the practicality and safety of their interventions. The action is implicit and somewhat vague, as the authors are left to infer that they need to assess the practicality and safety of their interventions but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the practicality and safety of the interventions discussed in the paper, suggesting that the authors should consider these aspects when thinking about querying in the real world. However, it does not specify which part of the paper discusses these interventions, making it weakly grounded. The comment is specific in its suggestion to consider practicality and safety, but without clear references to specific sections or examples, the authors may find it challenging to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the practicality and safety of the interventions discussed in the paper, suggesting that the authors should consider these aspects when thinking about querying in the real world. However, the comment does not provide specific examples, reasoning, or references to support why these interventions might be impractical or unsafe. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises an important consideration regarding the practicality and safety of the interventions discussed in the paper. It suggests that the authors should think about whether these interventions are feasible and safe for querying in the real world. This is a relevant point that could help the authors refine their work and ensure that their findings are applicable and usable in practical settings. However, the comment lacks specific guidance or suggestions on how to address this concern, such as proposing methods for evaluating practicality or safety. While it identifies a potential area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the manual disentangling in the paper, specifically questioning why the semantic segmentation network is the first module in the pipeline. It suggests that it would be interesting if the paper did not have this type of manual disentangling and everything was learned. While the comment implies that the authors should consider alternative approaches to disentangling, it does not provide explicit guidance on how to achieve this or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer that they should explore alternative methods for disentangling. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of manual disentangling in the paper, specifically questioning why the semantic segmentation network is the first module in the pipeline. It suggests that it would be interesting if the paper did not have this type of manual disentangling and everything was learned. However, the comment does not specify which part of the paper discusses this issue, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but the exact location is not explicitly mentioned. The comment is specific in detailing the issue with manual disentangling and suggesting an alternative approach, but the lack of explicit grounding limits its effectiveness. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a claim about the manual disentangling in the paper, specifically questioning why the semantic segmentation network is the first module in the pipeline. The reviewer suggests that it would be interesting if the paper did not have this type of manual disentangling and everything was learned. However, the comment lacks specific reasoning or evidence to support why this manual disentangling is problematic or how it could be improved. Without detailed justification or examples, the claim remains somewhat vague, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is classified as 2.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the manual disentangling of the semantic segmentation network as the first module in the pipeline. It questions the rationale behind this choice and suggests that it would be more interesting if the paper did not have this type of manual disentangling and everything was learned. This feedback is 3 as it points out a potential weakness in the methodology and encourages the authors to consider alternative approaches. However, the comment lacks detailed guidance on how to address this issue or what specific changes could be made to improve the paper. While it provides some direction, it could be more actionable with additional suggestions or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a lack of clarity regarding the connection between the theoretical analysis and the proposed method, specifically questioning how the proposed method enhances generalization for distant nodes. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve the clarity of the connection. The comment implies that the authors should clarify the relationship between the theoretical analysis and the proposed method, but it lacks concrete steps or examples on how to do so. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the connection between the theoretical analysis and the proposed method, specifically questioning how the proposed method enhances generalization for distant nodes. However, it does not specify which part of the paper discusses the theoretical analysis or the proposed method, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its critique of the connection between theory and application, but it lacks grounding as it does not direct the authors to a particular part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the connection between the theoretical analysis and the proposed method is unclear, specifically questioning how the proposed method enhances generalization for distant nodes. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential disconnect between the theoretical analysis and the proposed method, specifically questioning how the proposed method enhances generalization for distant nodes. It points out that the method seems to be a simple application of the selfattention mechanism from transformers to graphs, without clear justification for its effectiveness. While the comment highlights an area of concern, it lacks specific suggestions or guidance on how the authors might address this issue or improve the clarity of the connection between theory and application. This limits the comment\"s usefulness, as it provides insight but does not offer actionable steps for improvement. Therefore, the comment is 3, as it prompts the authors to consider the connection between theory and application but does not fully support them in making improvements."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point claims that the contribution of the work is incremental and that the proposed pipeline is not impressive or novel, but rather a collection of tricks to improve defense evaluation. However, it does not provide any specific guidance or suggestions on how the authors could improve their work or address these concerns. The comment lacks actionable details, such as recommending specific changes or improvements that could be made to enhance the novelty or impact of the work. As a result, the authors are left without a clear understanding of what steps to take to address the feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the technical contribution of the paper, stating that the proposed pipeline is not impressive or novel but rather a collection of tricks to improve defense evaluation. However, it does not specify which part of the paper this critique is based on, such as a particular section, experiment, or methodology. Without explicit references to specific parts of the paper, the authors cannot confidently determine which aspects need revision. Additionally, the comment lacks specificity in detailing what aspects of the pipeline are considered tricks or how they could be improved. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the contribution of the work is incremental and that the proposed pipeline is not impressive or novel, but rather a collection of tricks to improve defense evaluation. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without concrete evidence or detailed justification, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment critiques the technical contribution of the work, stating that the proposed pipeline is not impressive or novel but rather a collection of tricks to improve defense evaluation. However, it does not provide specific examples or details of what aspects of the pipeline are considered tricks or how they could be improved. Without actionable feedback or suggestions for enhancement, the authors are left without a clear understanding of how to address the critique or improve their work. Therefore, the comment is 1, as it lacks depth and specificity, leaving the authors without guidance on how to enhance their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment questions the rationale behind the choice of a noncentral chisquared distribution for the eta_ri term. However, it does not provide any explicit or implicit guidance on how the authors should address this issue or what changes they should make to clarify the reasoning. The comment lacks actionable details, such as suggesting alternative explanations or methods for justifying the choice. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment questions the choice of a noncentral chisquared distribution for the eta_ri term, but it does not specify which part of the paper discusses this term or where it is introduced. This makes it difficult for the authors to pinpoint the exact section that needs clarification. The comment is specific in its inquiry about the distribution choice, but it lacks grounding as it does not explicitly mention a section or context. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the choice of a noncentral chisquared distribution for the eta_ri term, but it does not provide any supporting evidence, reasoning, or references to justify why this choice is unclear or problematic. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment raises a question about the choice of a noncentral chisquared distribution for the eta_ri term, indicating a lack of clarity in the rationale behind this decision. However, it does not provide any suggestions or guidance on how the authors might address this issue or clarify the reasoning. Without actionable feedback or additional context, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides two distinct points of feedback. First, it critiques the vagueness of the statement in lines 15, suggesting that certain RNNs work well for certain natural language reasoning tasks. The reviewer references specific literature and a leaderboard to support this claim. This feedback is explicit and provides concrete examples, making it 5. Second, the comment critiques the reinforcement learning / agent analogy in lines 1618, suggesting that it is out of place and that generalization capabilities are better illustrated later in the paper. While the comment identifies a potential issue, it does not provide specific guidance on how to address it, leaving the authors to infer that they should reconsider the analogy or its placement. Overall, the comment is 4, as it provides clear guidance on one point but requires more detail on the other.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (L15, L1618) in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it provides detailed feedback on the vagueness of the statement in line 15, suggesting that certain RNNs work well for certain natural language reasoning tasks and referencing specific literature and a leaderboard. Additionally, it critiques the reinforcement learning / agent analogy in lines 1618, suggesting that it is out of place and that generalization capabilities are better illustrated later in the paper. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of two distinct claims. The first claim, regarding the vagueness of the statement in line 15, is supported by a reference to specific literature and a leaderboard, providing a clear basis for the critique. This makes the claim 4. The second claim, about the reinforcement learning / agent analogy being out of place, is supported by the suggestion that generalization capabilities are better illustrated later in the paper. While this reasoning is logical, it lacks specific references or examples to fully substantiate the claim. Therefore, the comment is 3, as it provides a logical basis but could benefit from more detailed evidence or references. Overall, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment provides two distinct points of feedback. First, it critiques the vagueness of the statement in line 15, suggesting that certain RNNs work well for certain natural language reasoning tasks. The reviewer references specific literature and a leaderboard, which is a helpful addition to clarify the point. Second, the comment critiques the reinforcement learning / agent analogy in lines 1618, suggesting that it is out of place and that generalization capabilities are better illustrated later in the paper. This feedback is clear and actionable, as it directs the authors to reconsider the analogy or its placement. Overall, the comment is 4 as it offers specific suggestions for improvement, providing the authors with clear guidance on how to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the lack of speed analysis in the experiments, specifically noting the absence of comparisons between the proposed network and prior work regarding inference speed. It suggests that the improvement in inference speed would be more interesting than reducing FLOPs. While the comment implies that the authors should include speed analysis and comparisons, it does not provide explicit instructions on how to conduct these analyses or what specific metrics to use. The action is implicit and somewhat vague, as the authors need to infer the need for speed analysis and determine how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of speed analysis in the experiments, specifically noting the absence of comparisons between the proposed network and prior work regarding inference speed. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what is missing, namely the comparison of inference speed and the suggestion that such an analysis would be more interesting than reducing FLOPs. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the lack of speed analysis in the experiments is a weakness, noting that the experiments only compare GFLOPs of different segmentation networks but not the inference speed. The reviewer suggests that the improvement in inference speed would be more interesting than reducing FLOPs. While the comment highlights a potential area for improvement, it lacks specific examples or references to support the claim that inference speed is more important than FLOPs. The reasoning is somewhat logical but could be strengthened with additional evidence or examples. Therefore, the comment is 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the lack of speed analysis in the experiments. It points out that while the experiments compare GFLOPs of different segmentation networks, there is no comparison of inference speed between the proposed network and prior work. The comment suggests that the improvement in inference speed would be more interesting than reducing FLOPs, providing a clear direction for the authors to enhance their work. However, the comment could be more helpful if it offered specific suggestions on how to conduct the speed analysis or what metrics to use. Overall, the feedback is 4 as it highlights a critical area for improvement and guides the authors toward a more comprehensive evaluation of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the proposed method is not wellpositioned in the literature and suggests that the authors conduct a thorough literature review to better position their work. It mentions that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is wellknown and has been used in various works, such as denoising score matching and scoreinterpolation. While the comment implies that the authors should conduct a literature review, it does not provide specific guidance on how to conduct this review or which works to consider. The action is implicit and somewhat vague, as the authors know they need to conduct a literature review but lack detailed instructions on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that this idea is wellknown and has been used in various works, such as denoising score matching and scoreinterpolation. The comment further suggests that the authors conduct a thorough literature review to better position their work. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed method is not wellpositioned in the literature and suggests that the key idea behind it is wellknown. The reviewer supports this claim by referencing specific works, such as denoising score matching and scoreinterpolation, where this idea has been used. This provides a clear basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed references or examples to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, noting that the proposed method is not wellpositioned in the literature. It points out that the key idea behind the method, representing the marginal score as the expectation of scores of distributions conditioned on inputs, is wellknown and has been used in various works, such as denoising score matching and scoreinterpolation. The comment suggests that the authors conduct a thorough literature review to better position their work within the existing body of knowledge. While the feedback is clear about the need for a literature review, it could be more helpful by providing specific examples or references to guide the authors in their search. Overall, the comment is 4 as it highlights an important area for improvement and provides a clear direction for the authors to enhance their draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should conduct an additional benchmark using the \"small learning rate for attention parameters\" method, as described earlier in the paper. While the comment implies an action, it does not explicitly instruct the authors to perform this benchmark. Additionally, it lacks concrete details on how to implement this suggestion, such as specific parameters or conditions to test. The action is implicit and somewhat vague, making it barely actionable.", "grounding_specificity_rationale": "The comment suggests conducting an additional benchmark using the \"small learning rate for attention parameters\" method, as described earlier in the paper. However, it does not specify which part of the paper this method is described in, making it weakly grounded. The comment is specific in suggesting a particular benchmark to conduct, but without explicit references to the paper, the authors may find it challenging to pinpoint the exact section being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests conducting an additional benchmark using the \"small learning rate for attention parameters\" method, as described earlier in the paper. However, it does not provide any reasoning or evidence to support why this comparison is necessary or how it would contribute to the paper. The suggestion is based on the reviewer\"s personal interest, but it lacks a clear justification or explanation of its relevance to the paper\"s content. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests conducting an additional benchmark using the \"small learning rate for attention parameters\" method, as described earlier in the paper. While it identifies a potential area for further exploration, it lacks specificity and does not provide detailed guidance on how to conduct this benchmark or what specific aspects to focus on. The suggestion is 3 as it points out a possible enhancement to the paper, but it could be more actionable with additional details or examples. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the resolution of a debate that the paper was previously careful to leave open, specifically questioning why the distribution cannot have changed and whether experiments disentangle changes in distribution from the removal of information. However, it does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their draft. The comment lacks actionable details, such as recommending specific experiments or analyses to conduct, leaving the authors uncertain about how to proceed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions line numbers (L106 and L29), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the resolution of a debate and suggesting that experiments should disentangle changes in distribution from the removal of information. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the resolution of a debate that the paper was previously careful to leave open, specifically questioning why the distribution cannot have changed and whether experiments disentangle changes in distribution from the removal of information. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. The lack of evidence or detailed justification makes it difficult for the authors to understand and address the concerns effectively. Therefore, the comment is considered 2, as it provides some basis for the claim but requires more detailed support to be 5.", "helpfulness_rationale": "The review comment raises a concern about the resolution of a debate that the paper was previously careful to leave open, specifically questioning why the distribution cannot have changed and whether experiments disentangle changes in distribution from the removal of information. This feedback highlights a potential inconsistency or lack of clarity in the paper, prompting the authors to reconsider their approach and potentially conduct additional experiments to address this issue. However, the comment does not provide specific suggestions or guidance on how to resolve the concern or improve the draft. While it identifies an area for improvement, it lacks actionable details, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point expresses curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. However, it does not provide any explicit or implicit action for the authors to take. There is no guidance on whether the authors should investigate this combination, include it in their analysis, or address it in any way. The comment lacks actionable details, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. However, it does not specify which part of the paper this curiosity pertains to, such as a specific section or analysis where this combination could be discussed. Additionally, the comment does not provide any guidance on how the authors might address this curiosity or what specific aspects of the SOTA method or adaptive metric should be considered. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point expresses curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. However, it does not present a claim or opinion that requires verification. It is a factual statement or a request for information, which does not fit the criteria for a claim. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment expresses curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. While it acknowledges that this is not necessary, it prompts the authors to consider this combination, which could be a valuable addition to their analysis. However, the comment lacks specificity and does not provide any guidance on how the authors might explore this combination or what aspects to focus on. Without actionable suggestions or detailed feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the plots are terrible and provides specific reasons for this assessment, such as their small size, hardtodistinguish colors, poorly labeled axes, and visually similar labels. The reviewer emphasizes that these plots are the main presentation of the experimental results and should be much clearer. This feedback is direct and provides concrete guidance on what needs to be improved, such as increasing plot size, distinguishing colors, labeling axes, and ensuring label clarity. The authors know exactly what changes to make to improve the clarity of their plots, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the plots, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the plots, such as their small size, hardtodistinguish colors, poorly labeled axes, and visually similar labels. The comment provides clear guidance on what needs to be improved, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the plots are \"terrible\" due to their small size, hardtodistinguish colors, poorly labeled axes, and visually similar labels. The reviewer provides specific examples of these issues, such as the difficulty in distinguishing between pink and red colors, and the confusion between \"sdropout(tr)\" and \"edropout(tr)\" labels. This level of detail supports the claim, making it 4. However, the comment could be strengthened by providing suggestions on how to improve the plots, which would further enhance its verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the quality of the plots presented in the paper. It identifies several issues, such as the small size of the plots, difficulty in distinguishing colors, poorly labeled axes, and visually similar labels. By pointing out these specific problems, the comment offers clear guidance on how to improve the clarity and presentation of the experimental results, which are crucial for the paper\"s impact. This feedback is 5 as it empowers the authors to make significant improvements to their draft, enhancing its readability and effectiveness. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point notes that the performance gains are not very high, with most metrics showing a difference of less than 1% between the baseline and the best approach. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this observation or improve the performance gains. Without any suggestions or recommendations, the authors are left without a clear understanding of what steps to take to enhance their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the performance gains of the paper, specifically noting that the differences between the baseline and the best approach are less than 1% for most metrics. However, it does not specify which part of the paper this observation is based on, such as a particular section or table that discusses performance metrics. Without explicit references to specific sections or figures, the authors cannot confidently determine which part of the paper the comment pertains to. Additionally, the comment lacks specificity regarding what needs to be addressed or improved in terms of performance gains. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the performance gains are not very high, as most metrics show a difference of less than 1% between the baseline and the best approach. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or data to support the assertion, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that the performance gains are not very high, with most metrics showing a difference of less than 1% between the baseline and the best approach. However, it does not provide any specific suggestions or guidance on how the authors might improve their results or address this issue. Without actionable feedback or recommendations, the comment lacks depth and does not offer much value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the performance boost due to additional parameters in the LinearTop and NLTop models compared to the Unary model. It suggests that using a better Unary baseline could help determine if there is still a performance boost. While the comment implies that the authors should consider using a better baseline for comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Tab 1,2,3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the performance boost due to additional parameters in the LinearTop and NLTop models compared to the Unary model. The comment raises a specific concern about the performance of the Unary model compared to a different and probably better neural network reported in 14. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the performance boost due to additional parameters in the LinearTop and NLTop models compared to the Unary model. It suggests that the performance of the Unary model could be improved by using a better baseline, as reported in 14. This claim is 3 as it provides a logical reasoning based on the comparison with an external reference (14), which suggests that a different and probably better neural network could lead to improved performance. However, the comment lacks specific details or examples from 14 to fully substantiate the claim, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment raises a pertinent question about the performance boost due to additional parameters in the LinearTop and NLTop models compared to the Unary model. It suggests that the performance of the Unary model could be improved by using a better baseline, as reported in 14. This feedback is clear and actionable, as it prompts the authors to consider using a better baseline for comparison, which could lead to a more accurate assessment of the performance boost. However, the comment could be more helpful if it provided specific suggestions on which baseline to use or how to implement it. Overall, the comment is 4 as it directs the authors to a potential area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper would benefit from a more detailed discussion of related work, including not only describing the related works but also discussing the differences to the presented work. While the comment implies that the authors should expand their discussion of related work, it does not provide specific guidance on how to achieve this or what aspects to focus on. The action is implicit and somewhat vague, as the authors are left to infer the details of how to implement the suggested improvement. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Related Work,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: a more detailed discussion of related work, including not only describing the related works but also discussing the differences to the presented work. This provides clear guidance on how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper would benefit from a more detailed discussion of related work, including not only describing the related works but also discussing the differences to the presented work. This claim is 3 as it provides a logical reasoning for why a more detailed discussion would be beneficial, particularly in terms of distinguishing the work from existing literature. However, the comment lacks specific examples or references to existing work that could be used to illustrate the differences, which would strengthen the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the discussion of related work. It suggests that the authors should provide a more detailed discussion, not only describing the related works but also discussing the differences to the presented work. This feedback is clear and actionable, as it guides the authors on how to enhance the depth and relevance of their related work section. By following this advice, the authors can better position their work within the existing literature and provide a more comprehensive context for their research. However, the comment could be more helpful if it included specific examples or suggestions on how to structure the discussion or what aspects to focus on. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the experiments should be extended to include other architectures and classification tasks beyond neural networks and image classification. While the comment implies that the authors should expand their experiments, it does not provide specific guidance on which architectures or classification tasks to consider or how to implement these changes. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests expanding the experiments to include other architectures and classification tasks beyond neural networks and image classification. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. This lack of explicit reference makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the need for broader experimentation, but without grounding, it is challenging for the authors to know where to focus their efforts. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the experiments should be extended to include other architectures and classification tasks beyond neural networks and image classification. This is a request for additional experiments, which is not a claim but rather a suggestion for improvement. The comment does not contain any subjective opinions, judgments, or claims that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment suggests that the experiments should be expanded to include other architectures and classification tasks beyond neural networks and image classification. This feedback is 3 as it points out a potential limitation in the scope of the experiments and encourages the authors to broaden their evaluation. However, the comment lacks specific guidance on which other architectures or classification tasks should be considered, leaving the authors with a general direction but no detailed steps to follow. To be more helpful, the comment could include suggestions or examples of alternative architectures or tasks that might be relevant. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a potential issue with the algorithm, suggesting that the output depends on the order in which the data are processed. It explicitly instructs the authors to clarify this aspect, providing a clear and direct action for improvement. The comment is specific and leaves no ambiguity about what needs to be addressed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the output from the algorithm depends on the order in which the data are processed. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue of data processing order affecting the output, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact location of the issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the output from the algorithm depends on the order in which the data are processed. However, it does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the algorithm, suggesting that the output depends on the order in which the data are processed. This is a critical observation that could impact the reliability and reproducibility of the results. By pointing out this issue, the comment provides the authors with a clear direction for improvement, as they need to clarify this aspect of their methodology. However, the comment does not offer specific suggestions on how to address this issue or provide examples of how to ensure the output is independent of data processing order. While it highlights an important area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the sampling performed to obtain different initializations x_0 and its importance for convergence to the optimum. It notes that this aspect is not experimentally evaluated carefully on the proposed benchmarks, except for a comparison in Table 1 of the supplementary material. While the comment identifies a potential issue with the experimental evaluation, it does not provide explicit guidance on how the authors should address this concern. The action is implicit, as the authors need to infer that they should conduct more thorough experiments to evaluate the impact of different initializations on convergence. However, the comment lacks concrete details on how to conduct these experiments or what specific aspects to focus on. Therefore, the comment is 3, as it points out an area for improvement but does not provide detailed guidance on how to implement it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Tab. 1 in supplementary,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the experimental evaluation of the sampling performed to obtain different initializations x_0, noting that it is not evaluated carefully on the proposed benchmarks except for a comparison to sampling from a uniform distribution. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point claims that the sampling performed to obtain different initializations x_0 is important for convergence to the optimum but is not experimentally evaluated carefully on the proposed benchmarks. The reviewer supports this claim by referencing Table 1 in the supplementary material, where it is compared to sampling from a uniform distribution. This provides some evidence to substantiate the claim, making it 4. However, the comment could be strengthened by providing more detailed analysis or examples of how the sampling affects convergence. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the experimental evaluation of the sampling performed to obtain different initializations x_0. It notes that this aspect is not thoroughly evaluated on the proposed benchmarks, except for a comparison in Table 1 of the supplementary material. This feedback is clear and actionable, as it highlights a gap in the experimental analysis that the authors should address to strengthen their paper. By pointing out this oversight, the comment provides the authors with a clear direction for improvement, making it 4. However, it could be more helpful if it suggested specific experiments or analyses to conduct to fully evaluate the impact of different initializations on convergence. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the logic behind the comparison of the proposed method with specific references, such as 9 and 16. It questions the rationale for comparing the computational cost with 9 but not 16 and asks whether computational cost is a significant contribution or issue in a practical scenario. While the comment highlights areas of confusion, it does not provide explicit instructions or suggestions for the authors to address these questions. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the logic and rationale behind the comparisons, but they are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the logic behind the comparison of the proposed method with specific references, such as 9 and 16. It questions the rationale for comparing the computational cost with 9 but not 16 and asks whether computational cost is a significant contribution or issue in a practical scenario. However, the comment does not specify which part of the paper these comparisons are discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but the lack of explicit references makes it challenging to pinpoint the exact location. The comment is specific in detailing the questions about the logic and rationale behind the comparisons, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the logic and rationale behind the comparisons made in the paper, specifically questioning the choice of references and the focus on computational cost. However, it does not provide any specific evidence, reasoning, or references to support these questions. The comment lacks detailed justification or examples that would help the authors understand the basis of the reviewer\"s concerns. As a result, the claim is 1, as it does not provide sufficient information for the authors to address the issues raised. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises several questions about the logic and rationale behind the comparisons made in the paper, specifically questioning the choice of references and the focus on computational cost. It points out inconsistencies in the comparisons and asks for clarification on the significance of computational cost in the context of the paper. While the comment identifies areas of confusion, it does not provide specific suggestions or guidance on how the authors might address these issues or improve their draft. The feedback is 3 as it prompts the authors to reconsider their comparisons and provide more detailed explanations, but it lacks actionable advice or detailed suggestions for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that it would be interesting to see how the model works for tabular data, although it is not necessary. While the comment implies that the authors should consider exploring this aspect, it does not provide explicit guidance on how to do so or what specific steps to take. The action is implicit and somewhat vague, as the authors are left to infer that they should investigate the model\"s performance on tabular data but without detailed instructions on how to proceed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests exploring the model\"s performance on tabular data, which is a specific area of interest. However, it does not explicitly mention which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the discussion of multimodal data, but this inference is not as direct as it could be. The comment is specific in suggesting an area for exploration, but it lacks full grounding because it does not specify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it would be interesting to explore the model\"s performance on tabular data, which is a form of multimodal data. However, the comment does not provide any specific reasoning, examples, or references to support why this exploration would be beneficial or how it might impact the paper. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 2.", "helpfulness_rationale": "The review comment suggests exploring the model\"s performance on tabular data, which is a form of multimodal data. While the suggestion is interesting, it lacks specificity and actionable guidance. The comment does not provide details on how to incorporate this exploration into the paper, such as which aspects of the model should be tested or what specific questions should be addressed. Without these details, the authors may find it challenging to implement this suggestion effectively. Therefore, the comment is 3, as it identifies a potential area for exploration but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors provide more details on using attention, possibly as an extra appendix. While it implies that the authors should include additional information, it does not specify what specific details should be added or how they should be presented. The action is implicit and somewhat vague, as the authors need to infer that they should add more details on attention and where to include them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests adding more details on using attention, possibly as an extra appendix. However, it does not specify which part of the paper currently lacks these details or where the authors should include them. The authors might infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in suggesting the addition of more details on attention, but it lacks grounding as it does not pinpoint a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more details on using attention would be beneficial, possibly as an extra appendix. However, it does not provide any specific reasoning, examples, or references to support why this additional information is necessary or how it would enhance the paper. Without further explanation or justification, the authors may find it challenging to understand the importance of this suggestion or how to implement it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the authors provide more details on using attention, possibly as an extra appendix. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on what additional details should be included or how they might enhance the paper. The feedback is 3 as it points out a gap in the paper, but it could be more actionable with more detailed suggestions. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point questions the authors about the reason for only showing results on images corrupted with Gaussian noise, despite claiming that their model can work well for various types of image noise. This comment implies that the authors should provide an explanation or justification for this choice. However, it does not explicitly instruct the authors to do so or offer guidance on how to address the issue. The action is implicit and somewhat vague, as the authors can infer that they need to provide an explanation but are not given specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions the authors about the reason for only showing results on images corrupted with Gaussian noise, despite claiming that their model can work well for various types of image noise. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its inquiry about the reason for the limited results, but it lacks grounding as it does not explicitly mention a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the authors about the reason for only showing results on images corrupted with Gaussian noise, despite claiming that their model can work well for various types of image noise. This is a factual observation that does not contain a subjective claim or opinion. It is a request for clarification, which is not a claim requiring verification. Therefore, the label \"No\" is appropriate.", "helpfulness_rationale": "The review comment questions the authors about the reason for only showing results on images corrupted with Gaussian noise, despite claiming that their model can work well for various types of image noise. This is a valid point that prompts the authors to provide a justification or explanation for their choice of experimental setup. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue or improve their experimental design. While it highlights a potential weakness in the paper, it lacks actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the empirical version of the objective (3) might be more appropriate in the supplementary materials. While it implies that the authors should consider moving this content, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to implement this suggestion or what aspects of the objective should be included in the supplementary materials. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests moving the empirical version of the objective (3) to the supplementary materials. However, it does not specify which part of the paper this objective is currently located in, making it weakly grounded. The comment is specific in suggesting a potential relocation, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the empirical version of the objective (3) might be more appropriate in the supplementary materials. However, it does not provide any reasoning or justification for this suggestion, nor does it reference any specific issues with the placement of this objective in the main text. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the empirical version of the objective (3) might be more appropriate in the supplementary materials. While it identifies a potential area for improvement, it lacks specificity and does not provide a clear rationale or explanation for why this change would be beneficial. The feedback is somewhat vague, as it does not offer detailed guidance on how to implement this suggestion or what specific aspects of the objective might be better suited for the supplementary materials. Therefore, the comment is 2, as it provides limited value to the authors in terms of actionable feedback for improving their draft."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a specific issue with the explanation of Corollary 10 in lines 180182, noting that it only shows that uncertainty sampling moves in descent directions of the expected 01 loss, but this does not necessarily mean that uncertainty sampling is not minimizing the expected convex surrogate. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this issue or improve the explanation, leaving the authors without a clear understanding of what steps to take to enhance their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (180182) in the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it details the issue with Corollary 10, explaining that it only shows that uncertainty sampling moves in descent directions of the expected 01 loss, but this does not necessarily mean that uncertainty sampling is not minimizing the expected convex surrogate. This provides clear guidance on what needs to be addressed in the explanation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Corollary 10 only shows that uncertainty sampling moves in descent directions of the expected 01 loss, but this does not necessarily mean that uncertainty sampling is not minimizing the expected convex surrogate. The comment provides a logical reasoning by pointing out the limitations of the corollary, which is a deductive observation based on the information provided. However, it lacks specific references or examples to fully substantiate the claim, making it 3. The authors would need to consider the reasoning and potentially provide additional evidence or clarification to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the explanation of Corollary 10 in lines 180182, pointing out that it only shows that uncertainty sampling moves in descent directions of the expected 01 loss, but this does not necessarily mean that uncertainty sampling is not minimizing the expected convex surrogate. This feedback is 3 as it highlights a potential misunderstanding or misinterpretation in the paper, prompting the authors to clarify or expand their explanation. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as proposing alternative explanations or additional evidence. Therefore, while it points out a relevant area for improvement, it lacks depth and actionable advice, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to add details about the division of the dataset into training and test sets, including the numbers and the method used for division (e.g., random or with other considerations). This feedback provides a clear and concrete action for the authors to take, ensuring they know exactly what information to include in their draft. The comment is explicit and provides specific guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the missing details about the division of the dataset into training and test sets, including the numbers and the method used for division. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what details are missing and what needs to be added, such as the method used for division (e.g., random or with other considerations). Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there are missing details about the division of the dataset into training and test sets, including the numbers and the method used for division. This is a factual statement that requires no verification or justification. It does not express an opinion, judgment, or suggestion that would necessitate verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks details, namely the division of the dataset into training and test sets. It highlights the importance of including information about the numbers and the method used for division, such as whether it was random or involved other considerations. This feedback is clear and actionable, as it provides the authors with a specific area to address and improve their draft. By adding these details, the authors can enhance the transparency and rigor of their experimental setup, which is crucial for reproducibility and credibility. However, the comment could be more helpful if it suggested specific methods or considerations for division, which would provide even more actionable guidance. Overall, the comment is 4, as it directs the authors to a critical area for improvement but could be more comprehensive with additional suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the testing of the model on the bAbI dataset, specifically asking if it was only tested on the single supporting fact dataset (Task 1). However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on what the authors should do in response to this question, such as suggesting additional testing or analysis on other tasks. Without any actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the testing of the model on the bAbI dataset, specifically asking if it was only tested on the single supporting fact dataset (Task 1). However, it does not specify which part of the paper discusses this testing, making it weakly grounded. The comment is specific in its inquiry about the testing on other tasks, which provides some guidance on what the authors might need to address. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the testing of the model on the bAbI dataset, specifically asking if it was only tested on the single supporting fact dataset (Task 1). This is a factual inquiry that does not contain a subjective claim or opinion requiring verification. It is a request for clarification, which is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the testing of the model on the bAbI dataset, specifically asking if it was only tested on the single supporting fact dataset (Task 1). While this is a valid inquiry, the comment lacks depth and does not provide any actionable feedback or suggestions for improvement. It does not offer guidance on how the authors might address this issue or expand their testing to other tasks. As a result, the comment is 2, as it identifies a potential area for improvement but does not provide sufficient direction for the authors to act upon."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges a minor issue with the dataset used in the experiments, noting that they are all very small. The reviewer suggests that results on a medium or large dataset, such as ImageNet, would be more convincing. However, the comment does not provide explicit guidance on how to address this issue or suggest specific actions for the authors to take. The feedback is implicit and lacks concrete details, making it 3. The authors can infer that they should consider using larger datasets, but without specific instructions, the action remains vague.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the dataset used in the experiments, noting that they are all very small. It suggests that results on a medium or large dataset, such as ImageNet, would be more convincing. However, the comment does not specify which part of the paper discusses the dataset or where the results are presented, making it weakly grounded. The comment is specific in suggesting the use of a larger dataset, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the dataset used in the experiments is small and suggests that results on a medium or large dataset, such as ImageNet, would be more convincing. However, the comment does not provide any specific reasoning or evidence to support why a larger dataset would be more convincing or how it would impact the results. Without detailed justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges a minor issue with the dataset used in the experiments, noting that they are all very small. It suggests that results on a medium or large dataset, such as ImageNet, would be more convincing. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue or what specific datasets they could consider. Additionally, the comment does not provide any context or explanation as to why a larger dataset would be more convincing or how it might impact the results. As a result, the feedback is 3, as it points out a potential weakness but does not offer actionable advice or depth to guide the authors in making improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors provide empirical justification for their claim that the proposed algorithm does not require as many points or prior knowledge about subspace dimensions, as compared to existing algorithms. While the comment implies that the authors should include empirical evidence to support this claim, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not specify the exact type of empirical evidence needed or how to present it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the first claimed contribution of the paper, specifically questioning the empirical justification for the claim that the proposed algorithm does not require as many points or prior knowledge about subspace dimensions, as compared to existing algorithms. However, it does not specify which part of the paper discusses this contribution, making it weakly grounded. The comment is specific in its request for empirical justification, which provides some guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the empirical justification for the claim that the proposed algorithm does not require as many points or prior knowledge about subspace dimensions, as compared to existing algorithms. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. The lack of evidence or detailed justification makes it difficult for the authors to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper\"s first claimed contribution, which is that the proposed algorithm does not require as many points or prior knowledge about subspace dimensions, as compared to existing algorithms. It suggests that the authors provide empirical justification for this claim, which is a clear and actionable piece of feedback. However, the comment could be more helpful if it offered specific suggestions on how to conduct the empirical evaluation or what aspects to focus on. Despite this, the feedback provides a valuable direction for the authors to improve their draft, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the proposed S1DBED algorithm is too similar to RMED (Komiyama et al., 2015) and recommends that the paper provide a sufficient discussion on the comparison with RMED. This feedback implies that the authors should address the similarity and differentiate their work from RMED, but it does not specify how to do so or what aspects of the comparison should be discussed. The action is implicit and somewhat vague, as the authors are left to infer the specific steps needed to address the issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed S1DBED algorithm,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the similarity to RMED (Komiyama et al., 2015) and suggesting that the paper needs to provide a sufficient discussion on the comparison with RMED. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed S1DBED algorithm is too similar to RMED (Komiyama et al., 2015), suggesting that the novelty of this part is limited. The reviewer provides a specific reference to RMED, which supports the claim by offering a point of comparison. However, the comment could be strengthened by providing more detailed reasoning or examples of how the algorithms are similar, which would make the claim 5. As it stands, the comment is 4, as it provides a solid basis for the claim but lacks comprehensive evidence or detailed comparison. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty of the proposed S1DBED algorithm, suggesting that it is too similar to RMED (Komiyama et al., 2015). It provides a specific reference to RMED, which is helpful for the authors to understand the context of the comparison. The comment also offers a clear suggestion for improvement by recommending that the paper provide a sufficient discussion on the comparison with RMED. This feedback is actionable and provides a clear direction for the authors to enhance the novelty and differentiation of their work. However, it could be more helpful if it included specific suggestions on how to differentiate the algorithms or what aspects to focus on in the discussion. Overall, the comment is 4, as it effectively guides the authors toward improving their draft."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors include a comparison of their approach\"s transferability to other LLMs, specifically mentioning the ability to craft adversarial prompts and transfer them to other LLMs. This is an explicit action that provides a clear direction for the authors to follow. However, the comment also mentions a minor point about the low jailbreaking percentage for certain LLMs, which is not directly actionable. Overall, the comment is 4 as it provides a concrete suggestion for improvement but lacks detailed guidance on the minor point.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"GCG,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that a comparison of the approach\"s transferability to other LLMs should be included, particularly regarding the ability to craft adversarial prompts and transfer them. Additionally, it mentions a minor point about the low jailbreaking percentage for certain LLMs. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors include a comparison of their approach\"s transferability to other LLMs, specifically mentioning the ability to craft adversarial prompts and transfer them to other LLMs. This claim is 3 as it provides a logical reasoning for the suggestion, but it lacks specific examples or references to support the assertion. The mention of a \"jailbreaking percentage\" for certain LLMs adds some context but does not fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improvement by recommending that the authors include a comparison of their approach\"s transferability to other LLMs. It specifically mentions the ability to craft adversarial prompts and transfer them to other LLMs, which is a valuable addition to the paper. Additionally, the comment points out a minor issue with the jailbreaking percentage for certain LLMs, which could be addressed for completeness. However, the comment could be more helpful if it provided specific guidance on how to conduct this comparison or what aspects to focus on. Overall, the feedback is 4 as it directs the authors to enhance the paper\"s scope and depth, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the limitations of the unified framework, specifically asking if it can handle general POMDP formulations with continuous or infinite spaces. While the comment implies that the authors should address this limitation, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to explore the framework\"s applicability to different POMDP formulations. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the limitations of the unified framework, specifically asking if it can handle general POMDP formulations with continuous or infinite spaces. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the framework\"s applicability to different POMDP formulations, but without clear grounding, the authors may struggle to determine where to address this issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question seeking clarification on the limitations of the unified framework. It does not express an opinion, judgment, or suggestion that requires verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the limitations of the unified framework, specifically asking if it can handle general POMDP formulations with continuous or infinite spaces. This is a relevant inquiry that could help the authors clarify the scope and applicability of their framework. However, the comment does not provide any suggestions or guidance on how the authors might address this limitation or expand the framework\"s capabilities. While it prompts the authors to consider a potential area for improvement, it lacks actionable feedback or detailed advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the creation of the dataset is optional, as the Kialo dataset already provides the necessary pairs of short claims and their counters. It notes that the Kialo dataset is cleaner since it does not rely on automatic processes to construct it. The comment suggests that the dataset created in the paper could serve as additional data for learning. While the comment implies that the authors should consider using the Kialo dataset instead of creating their own, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to integrate the Kialo dataset or what changes to make to the existing dataset. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the creation of the dataset, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the dataset, noting that the Kialo dataset, which is wellstudied in the community, provides what the authors need\u2014pairs of short claims and their counters. The comment further specifies that the Kialo dataset is cleaner since it does not rely on automatic processes to construct it. Additionally, it suggests that the dataset created in the paper could serve as additional data for learning. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the creation of the dataset is optional, as the Kialo dataset provides what the authors need. It supports this claim by comparing the Kialo dataset to the one created in the paper, noting that the former is cleaner since it does not rely on automatic processes. The comment also suggests that the dataset created in the paper could serve as additional data for learning. This reasoning is logical and provides a clear basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to the Kialo dataset, which would further enhance its verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment points out that the creation of the dataset is optional, as the Kialo dataset already provides the necessary pairs of short claims and their counters. It notes that the Kialo dataset is cleaner since it does not rely on automatic processes to construct it. The comment suggests that the dataset created in the paper could serve as additional data for learning. While the feedback highlights a potential alternative dataset and its advantages, it does not provide specific guidance on how to integrate the Kialo dataset or what changes to make to the existing dataset. The comment offers some insight but lacks depth and actionable suggestions, making it 3 for the authors. Therefore, it aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the limited number of tasks in the experiments and suggests that the authors should include more tasks (at least 10) and present sequential results in terms of tasks learned rather than epochs. While the comment explicitly states the need for more tasks and sequential results, it does not provide specific guidance on how to achieve this or what specific tasks should be included. The authors are given a clear direction but lack detailed instructions on how to implement the suggested changes. Therefore, the comment is 4, as it provides a concrete action but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment addresses the experiments, specifically mentioning the limited number of tasks and the desire for more tasks and sequential results. However, it does not specify which part of the experiments this issue pertains to, such as a particular section or figure. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing what the authors should address, namely the number of tasks and the presentation of sequential results. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the number of tasks in the experiments is limited and suggests that more tasks (at least 10) should be included. It also requests sequential results in terms of tasks learned rather than epochs. However, the comment lacks specific examples or references to support the claim that 10 tasks are necessary or that sequential results are more informative. Without detailed justification or evidence, the claim remains somewhat vague, making it difficult for the authors to fully understand and address the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the experiments, noting that the number of tasks is limited and suggesting that more tasks (at least 10) should be included. It also recommends presenting sequential results in terms of tasks learned rather than epochs. This feedback is clear and actionable, providing the authors with a specific direction for improving their experimental setup. However, the comment could be more helpful if it offered suggestions on how to select additional tasks or provided examples of how sequential results might be presented. Overall, the comment is 4 as it directs the authors to enhance their experimental design, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the motivation for analyzing only the last convolutional layer and suggests that numerosity should appear in earlier layers. While it implies that the authors should provide a clearer explanation for their choice, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment questions the motivation for analyzing only the last convolutional layer and suggests that numerosity should appear in earlier layers. However, it does not specify which part of the paper discusses this analysis, making it weakly grounded. The comment is specific in questioning the rationale behind the choice of the last convolutional layer, but it lacks detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the motivation for analyzing only the last convolutional layer, suggesting that numerosity should appear in earlier layers. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this assumption is valid. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment questions the motivation for analyzing only the last convolutional layer, suggesting that numerosity should appear in earlier layers. This feedback highlights a potential gap in the paper\"s explanation and prompts the authors to clarify their reasoning. However, the comment does not provide specific suggestions or guidance on how to address this issue or improve the clarity of the explanation. While it identifies a weakness, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point highlights a problem with setting the parameter \"S,\" but it does not provide any explicit or implicit guidance on how to address this issue. There is no suggestion or direction on what changes or modifications should be made to improve the setting of this parameter. Without any actionable advice or concrete steps, the authors are left without a clear understanding of how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a problem with setting the parameter \"S,\" but it does not specify which part of the paper this issue is discussed in, nor does it provide details on what aspect of setting \"S\" is problematic. Without explicit references to sections, figures, or specific discussions, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what needs to be addressed or improved regarding the setting of \"S.\" Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that \"How to set the parameter S remains a problem.\" However, it does not provide any supporting evidence, reasoning, or examples to justify why this is a problem or what specific issues arise from it. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the concern. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the problem of setting the parameter \"S.\" However, it does not provide any further details, suggestions, or guidance on how to address this problem or improve the setting of the parameter. Without additional context or actionable advice, the authors are left without a clear understanding of what steps to take to resolve this issue. Therefore, the comment is 1, as it does not offer any actionable feedback or direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the claim that \"these shape constraints do not require tuning a free parameter.\" It points out that the choice of employing a convex or concave constraint, and an increasing or decreasing constraint, can be seen as a hyperparameter that needs to be chosen or tuned. While the comment identifies a potential issue with the claim, it does not provide explicit guidance on how the authors should address this issue or suggest specific changes to make. The action is implicit and somewhat vague, as the authors are left to infer that they should clarify or revise their claim regarding the tuning of parameters. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific claim made in the introduction regarding the shape constraints not requiring tuning of a free parameter. It provides a critique by pointing out that the choice of employing a convex or concave constraint, and an increasing or decreasing constraint, can be seen as a hyperparameter that needs to be chosen or tuned. This feedback is specific in identifying the issue with the claim and suggests a potential area for clarification or revision. However, it does not explicitly mention which part of the introduction this claim is made in, making it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that while it is technically true that the shape constraints do not require tuning a free parameter, the choice of employing a convex or concave constraint, and an increasing or decreasing constraint, can be seen as a hyperparameter that needs to be chosen or tuned. The comment provides a logical reasoning by pointing out that the choice of constraints is not entirely free and requires some level of tuning. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to consider the reasoning and potentially provide additional context or evidence to fully understand and address the point. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the claim that \"these shape constraints do not require tuning a free parameter.\" It points out that the choice of employing a convex or concave constraint, and an increasing or decreasing constraint, can be seen as a hyperparameter that needs to be chosen or tuned. This feedback is 3 as it highlights a potential misinterpretation or oversimplification in the paper, prompting the authors to reconsider their claim and potentially clarify or revise it. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or offered examples of how to better articulate the constraints. Overall, the comment provides some direction for improvement but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two main issues: the limited datasets and models used, and the absence of assessments on stateoftheart generative models like GPT. It also notes that the bias benchmarks only assess gender, race, and religion, suggesting that other important biases and datasets are not measured. While the comment identifies specific areas that need attention, it does not provide explicit guidance on how to address these issues or what specific datasets or models should be included. The authors are left to infer that they should expand their dataset and model selection to include more diverse biases and stateoftheart generative models. However, the lack of concrete suggestions or detailed guidance makes the action somewhat vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the limited datasets and models used in the paper, specifically mentioning the bias benchmarks that only assess gender, race, and religion. It also points out the absence of assessments on stateoftheart generative models like GPT. However, the comment does not specify which part of the paper discusses these issues, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but without explicit references, it is challenging to pinpoint the exact location. The comment is specific in detailing what is missing, such as assessments on other important biases and datasets, and the need for evaluations on stateoftheart generative models. Therefore, the comment is weakly grounded but specific, aligning with the label 3.", "verifiability_rationale": "The review point claims that the datasets and models used are limited, specifically mentioning that the bias benchmarks only assess gender, race, and religion, and that other important biases and datasets are not measured. Additionally, it notes the absence of assessments on stateoftheart generative models like GPT. While the comment highlights specific areas where the paper could be improved, it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to infer the specific biases and datasets that should be included, which makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two key areas for improvement: the limited datasets and models used, and the lack of assessment on stateoftheart generative models like GPT. It also points out that the bias benchmarks only assess gender, race, and religion, suggesting that other important biases are not measured. This feedback is clear and actionable, as it provides specific areas for the authors to expand their work, such as including more diverse datasets and models. However, the comment could be more helpful if it offered suggestions on which specific datasets or models to consider or how to incorporate assessments on stateoftheart generative models. Overall, the comment is 4 as it directs the authors to important areas for enhancement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that Figure 3 is challenging to understand due to unclear workflow and captions, as well as confusion regarding the representation of communication modes on the left side. However, it does not provide explicit guidance or suggestions on how to improve the figure or clarify the issues. The authors are left to infer that they need to revise the figure and its captions, but without concrete instructions on what changes to make, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the figure, such as the unclear workflow and captions, and the confusion regarding the representation of communication modes on the left side. This provides clear guidance on what needs to be addressed to improve the figure\"s clarity. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 3 is challenging to understand due to unclear workflow and captions, as well as confusion regarding the representation of communication modes on the left side. However, the comment does not provide any specific examples or detailed reasoning to support why the figure is confusing. Without additional context or explanation, the authors may find it difficult to understand and address the issues raised. Therefore, the claim is considered 2, as it lacks sufficient detail to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 3, noting that it is challenging to understand due to unclear workflow and captions, as well as confusion regarding the representation of communication modes on the left side. This feedback is clear and actionable, as it directs the authors to improve the clarity and comprehensibility of their figure. However, the comment could be more helpful if it provided specific suggestions on how to enhance the figure\"s clarity, such as recommending additional labels or explanations. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly encourages the authors to conduct error analysis in their paper and provide detailed explanations of the model\"s performance under different scenarios. This suggestion is clear and direct, giving the authors a specific action to take. The comment also explains the importance of error analysis in guiding subsequent improvements and expansions of the ERC research. The feedback is concrete and provides a clear path for the authors to enhance their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests conducting error analysis and providing detailed explanations of the model\"s performance under different scenarios. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the evaluation or results sections, but the comment lacks full grounding. It is specific in suggesting the need for error analysis and detailed explanations, but without explicit references to the paper, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that error analysis is crucial for evaluating model performance and identifying potential issues. It encourages the authors to conduct error analysis and provide detailed explanations of the model\"s performance under different scenarios. The comment highlights the importance of error analysis in guiding subsequent improvements and expansions of the ERC research. However, it does not provide specific examples or references to support the claim that error analysis is necessary or how it would benefit the paper. The lack of detailed justification or evidence makes the claim 3, as the authors would need to infer the importance of error analysis based on the general reasoning provided. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment highlights the importance of error analysis in evaluating model performance and identifying potential issues. It provides a clear and actionable suggestion for the authors to conduct error analysis and offer detailed explanations of the model\"s performance under different scenarios. This feedback is valuable as it guides the authors on how to enhance their draft by providing insights into the model\"s strengths and weaknesses. However, the comment could be more helpful if it offered specific examples or methods for conducting error analysis, which would further assist the authors in implementing this suggestion. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the claim that the work is one of the preliminary works discussing the application of LLP to NLP tasks, as it does not appear to be specific to NLP. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue or improve the draft, leaving the authors without a clear path forward. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment questions the claim that the work is one of the preliminary works discussing the application of LLP to NLP tasks, suggesting that it lacks NLPspecific elements. However, it does not specify which part of the paper this claim is based on, making it difficult for the authors to identify the exact section that needs attention. The comment is 1 as it does not mention specific sections, figures, or tables. Additionally, it lacks specificity because it does not provide detailed feedback on what aspects of the work are not NLPspecific or how to address this issue. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point questions the claim that the work is one of the preliminary works discussing the application of LLP to NLP tasks, suggesting that it lacks NLPspecific elements. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment questions the claim that the work is one of the preliminary works discussing the application of LLP to NLP tasks, suggesting that it lacks NLPspecific elements. However, it does not provide specific feedback or suggestions on how the authors might address this issue or improve the relevance of their work to NLP. The comment identifies a potential weakness but lacks actionable guidance, making it 3 as it points out a gap in the paper but does not offer a clear path for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should include at least one NCEbased method for comparison. It provides a specific action by referencing a study that demonstrates the feasibility of learning EBM on natural images with a strong noise distribution. This guidance is clear and concrete, giving the authors a direct and detailed instruction on how to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests including at least one NCEbased method for comparison, referencing a study that shows the feasibility of learning EBM on natural images with a strong noise distribution. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in suggesting the inclusion of an NCEbased method and referencing a study, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests including at least one NCEbased method for comparison, referencing a study that demonstrates the feasibility of learning EBM on natural images with a strong noise distribution. This claim is 3 as it provides a reference to a specific study that supports the feasibility of the suggestion. However, the comment lacks detailed explanation or examples of how this comparison would benefit the paper, making it difficult for the authors to fully understand the rationale behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests including at least one NCEbased method for comparison, referencing a study that demonstrates the feasibility of learning EBM on natural images with a strong noise distribution. This feedback is clear and actionable, providing the authors with a specific direction for improving their draft by including a relevant comparison method. However, the comment could be more helpful if it explained why this comparison is important or how it would enhance the paper\"s contribution. Overall, the comment is 4 as it offers a concrete suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the experiment section could be improved by conducting significance tests on the human evaluation results and comparing the proposed method with recent LLMs. While the comment implies that these actions should be taken, it does not provide explicit instructions on how to conduct the significance tests or which recent LLMs should be compared. The authors can infer the need for these actions but may not be entirely sure of the exact steps to take. Therefore, the comment is 3, as it provides a clear direction but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment suggests improvements to the experiment section, specifically mentioning the need for significance tests on human evaluation results and comparisons with recent LLMs. However, it does not specify which part of the experiment section this feedback pertains to, such as a particular table or figure. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing revision. While the comment is specific in suggesting improvements, it is 1 because it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the experiment section could be improved by conducting significance tests on human evaluation results and comparing the proposed method with recent LLMs. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to recent LLMs that could be used for comparison. This makes the claim 3, as the authors would need to infer which LLMs are most relevant and how to conduct the significance tests. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies specific areas for improvement in the experiment section, suggesting that significance tests should be conducted on the human evaluation results and that the proposed method should be compared with recent LLMs. This feedback is clear and actionable, providing the authors with concrete steps to enhance the rigor and relevance of their experimental analysis. However, the comment could be more helpful if it included suggestions on which specific LLMs to compare with or how to conduct the significance tests. Overall, the comment is 4 as it directs the authors toward meaningful improvements in their experimental section."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the fairness of the comparison with stateoftheart (SOTA) methods due to the use of a newly collected dataset of 209M samples, while existing methods use smaller datasets. The reviewer suggests that the superior performance of the proposed method may be attributed to the larger dataset rather than the method itself. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest ways to improve the fairness of the comparison. The action is implicit and vague, as the authors are left to infer that they should consider the impact of dataset size on their results and potentially reevaluate the comparison. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the fairness of the comparison with stateoftheart (SOTA) methods, specifically mentioning the use of a newly collected dataset of 209M samples compared to the smaller datasets used by existing methods, such as GEM with only 20M unlabeled data. This provides a clear indication of the part of the paper being discussed, allowing the authors to accurately identify the section related to the comparison with SOTA methods. The comment is specific in detailing the issue of dataset size and its potential impact on the results, providing a clear direction for the authors to consider. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the comparison with stateoftheart (SOTA) methods may be unfair due to the use of a newly collected dataset of 209M samples, while existing methods use smaller datasets. The reviewer provides a specific example of GEM using only 20M unlabeled data. This comparison highlights the potential impact of dataset size on the accuracy of the proposed method. The claim is 4 as it provides a logical reasoning based on the difference in dataset sizes, but it could be strengthened by including more detailed comparisons or references to specific studies. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the fairness of the comparison with stateoftheart (SOTA) methods due to the use of a newly collected dataset of 209M samples, while existing methods use smaller datasets. It highlights the impact of dataset size on the accuracy of the proposed method, suggesting that the superior performance may be attributed to the larger dataset rather than the method itself. This feedback is clear and actionable, as it prompts the authors to consider the impact of dataset size on their results and potentially reevaluate the comparison with SOTA methods. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or included references to similar studies that have considered dataset size in their evaluations. Overall, the comment is 4 as it directs the authors to a critical area for improvement in their draft."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of clarity regarding the generalizability of specific examples presented in the paper, such as biases of target statistics and prediction shift of gradient values. However, it does not provide explicit guidance or suggestions on how the authors might address this issue. The comment implies that the authors should clarify the generalizability of these examples, but it lacks concrete steps or actions for the authors to take. As a result, the comment is vague and does not offer actionable advice, making it barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 3.2\" and \"Theorem 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of clarity regarding the generalizability of specific examples presented in the paper, such as biases of target statistics and prediction shift of gradient values. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper presents specific examples of biases of target statistics and prediction shift of gradient values, but it does not specify how these examples are unclear or how they affect the generalizability of the results. The comment lacks specific examples or detailed reasoning to support the claim, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the clarity of the paper, particularly in relation to the generalizability of examples presented in Section 3.2 and Theorem 1. It points out that while the paper demonstrates specific biases and prediction shifts, it does not clarify how general these situations are. This feedback is 3 as it highlights a potential gap in the paper that the authors need to address. However, it lacks detailed suggestions or guidance on how to improve the clarity or provide additional context. To be more helpful, the comment could include specific recommendations or examples of how to enhance the generalizability discussion. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks the authors to clarify whether there is any additional novel effort in Section 3.1 for 3D Gaussian generation, given that it appears to follow the previous work, Luciddreamer. This request is clear and direct, providing the authors with a specific action to take. The comment is concrete because it specifies what needs to be addressed, namely, whether there is any additional novel effort in this section. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 3.1 for 3D Gaussians generation,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests clarification on whether there is any additional novel effort in this section, given that it appears to follow the previous work, Luciddreamer. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions whether the section on 3D Gaussian generation in Section 3.1 is original or merely follows the previous work, Luciddreamer. However, it does not provide any specific reasoning, examples, or references to support the claim that the section is not novel. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the section on 3D Gaussian generation in Section 3.1, suggesting that it may not be original and merely follows the previous work, Luciddreamer. This feedback is 3 as it prompts the authors to clarify whether there is any additional novel effort in this section. However, the comment lacks specific guidance or suggestions on how the authors might address this concern or improve the originality of their work. To be more helpful, the comment could include suggestions for potential novel contributions or ways to differentiate the work from existing literature. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the first paragraph of the Introduction for being overly focused on general DNNs without mentioning drift, which is the core focus of the paper. The reviewer suggests that this paragraph provides little value to readers and is not central to the paper. However, the comment does not provide explicit guidance on what the authors should do to address this issue. It lacks concrete suggestions or actions, such as recommending a reorganization of the Introduction or suggesting specific content to include. As a result, the authors are left without clear direction on how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first paragraph of the Introduction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the paragraph, namely that it is overly focused on general DNNs without mentioning drift, which is the core focus of the paper. The comment provides a clear rationale for why this introduction is not relevant to the paper, making it specific. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the first paragraph of the Introduction is not relevant to the paper because it focuses on general DNNs without mentioning drift, which is the core focus of the paper. However, the comment does not provide any specific reasoning or evidence to support this claim. It lacks detailed justification or examples to explain why the inclusion of DNNrelated content is unnecessary or how it detracts from the paper\"s focus. Without such support, the claim remains 1, as the authors may find it challenging to understand and address the critique effectively. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the first paragraph of the Introduction, noting that it is overly focused on general DNNs without mentioning drift, which is the core focus of the paper. This feedback is 3 as it points out a potential weakness in the paper\"s introduction, suggesting that it may not effectively set the stage for the paper\"s main contributions. However, the comment lacks actionable guidance on how to address this issue or what specific changes could be made to improve the introduction. While it highlights a problem, it does not provide detailed suggestions for improvement, leaving the authors with a general idea of what needs to be revised but without a clear path forward. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors present a simplified version of Theorem 2 for the general audience, similar to how Theorem 1 is presented. This is an explicit request for the authors to simplify the presentation of Theorem 2, which is a concrete action. The comment provides clear guidance on what needs to be done to improve the accessibility of the paper, making it 5.", "grounding_specificity_rationale": "The comment suggests simplifying the presentation of Theorem 2 for the general audience, similar to how Theorem 1 is presented. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or subsection. The authors can infer that it relates to the presentation of Theorem 2, but this inference is not as direct as it could be. The comment is specific in suggesting a simplification for the general audience, but it lacks grounding because it does not explicitly mention the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that Theorem 2 is difficult to understand without a simplified version, similar to Theorem 1. However, the comment does not provide specific examples or detailed reasoning to support why Theorem 2 is challenging or how a simplified version would improve accessibility. Without additional context or explanation, the claim lacks sufficient evidence or justification, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the accessibility of Theorem 2, suggesting that it may be difficult for the general audience to understand without a simplified version. This feedback is 3 as it points out a specific area where the paper could be improved, but it lacks detailed guidance or suggestions on how to simplify the presentation. The authors are given a direction to consider, but the comment does not provide actionable steps or examples to help them achieve this simplification. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests conducting experiments with a larger image resolution to evaluate performance. While it implies that the authors should perform additional experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to conduct these experiments or what parameters to test. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests conducting experiments with a larger image resolution, implying that the current experiments are limited to a resolution of 224*224. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental setup or results section. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting a potential improvement by testing with a larger resolution, but without explicit grounding, it remains 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests conducting experiments with a larger image resolution to evaluate performance. However, it does not provide any supporting evidence, reasoning, or references to justify why this would be interesting or beneficial. The comment lacks specific details or examples that would help the authors understand the potential impact of using a larger resolution. As a result, the claim is 1, as it does not provide sufficient justification or evidence to support the suggestion.", "helpfulness_rationale": "The review comment suggests conducting experiments with a larger image resolution to evaluate performance. While it identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on how to conduct these experiments or what specific resolutions to test. The suggestion is 3 as it points out a possible enhancement, but it could be more actionable with additional details or examples. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors might want to mention that the algorithms follow the sampled policy for a while. This is an explicit suggestion that provides a clear action for the authors to take. The comment is specific and provides a concrete direction on what needs to be added to the draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L37,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a particular addition to the text, namely mentioning that the algorithms follow the sampled policy for a while. This provides clear guidance on what needs to be addressed. Therefore, this comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point suggests that the authors might want to mention that the algorithms follow the sampled policy for a while. This is a suggestion for improvement, not a claim or opinion that requires verification. It is a request for additional information or clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment suggests that the authors might want to mention that the algorithms follow the sampled policy for a while. While this is a specific and actionable suggestion, it is limited in scope and does not provide broader feedback or context for improving the draft. The comment lacks depth and does not address other potential areas for enhancement or clarification. Therefore, it is 3, as it offers a clear direction for improvement but does not fully support the authors in enhancing their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests conducting additional experiments on larger datasets, acknowledging that compute might be an issue. However, it does not provide specific guidance on how to address the potential issue of maintaining probabilities at large batch sizes. The comment implies that this aspect is not critical, but it does not offer actionable advice on how to handle it. The feedback is somewhat vague, as it suggests an additional experiment but lacks concrete details on how to implement it or address the potential issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests conducting additional experiments on larger datasets, acknowledging that compute might be an issue. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment does provide some specificity by suggesting additional experiments, but it lacks detailed guidance on how to address the potential issue of maintaining probabilities at large batch sizes. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests conducting additional experiments on larger datasets, acknowledging that compute might be an issue. The reviewer provides a logical reasoning for the suggestion, noting that larger datasets could provide more robust results. However, the comment does not specify which datasets would be suitable or how they would impact the results, leaving some gaps in the justification. This makes the claim 3, as it provides a logical basis but lacks specific details or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests conducting additional experiments on larger datasets, acknowledging that compute might be an issue. While it provides a clear suggestion for improvement, it lacks specific guidance on how to address the potential issue of maintaining probabilities at large batch sizes. The comment also acknowledges that this aspect is not critical, which could be seen as a limitation in terms of actionable feedback. Overall, the comment offers a 3 direction for improvement but could be more comprehensive and detailed to be fully beneficial to the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper could benefit from more explanation of the meaning of the bounds, possibly in the appendix. While it implies that the authors should provide additional explanation, it does not explicitly instruct them to do so or specify how to implement this suggestion. The action is implicit and somewhat vague, as the authors are left to infer that they need to add more explanation but are not given detailed guidance on what specific aspects to focus on or how to present the additional information. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper could benefit from more explanation of the meaning of the bounds, possibly in the appendix. However, it does not specify which part of the paper currently lacks this explanation, making it weakly grounded. The comment is specific in suggesting that additional explanation could be beneficial, but it does not provide detailed guidance on what aspects of the bounds need clarification. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper could benefit from more explanation of the meaning of the bounds, possibly in the appendix. However, it does not provide any specific reasoning or examples to support why this additional explanation is necessary or how it would enhance the paper. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment acknowledges the space limitations but suggests that the paper could benefit from more explanation of the meaning of the bounds, possibly in the appendix. While it identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on what aspects of the bounds need further explanation or how to present this information in the appendix. The feedback is 3 as it points out a gap in the paper but does not offer actionable steps for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the sufficiency of the datasets for a rigorous evaluation, particularly given the large size of some datasets. It suggests that the authors should consider adding more datasets or providing a repository for reproducing experiments. While the comment implies an action, it does not explicitly instruct the authors to take specific steps, such as identifying additional datasets or creating a repository. The suggestion is somewhat vague, as it lacks concrete details on how to implement the proposed changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the sufficiency of the datasets for a rigorous evaluation, particularly in relation to the number of datasets available for each task. It mentions the large size of some datasets, which could limit the applicability of certain algorithms. However, the comment does not specify which sections or parts of the paper discuss the datasets, making it weakly grounded. The comment is specific in its critique of the dataset selection and size, suggesting that more datasets or a repository for reproducing experiments might be beneficial. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the sufficiency of the datasets for a rigorous evaluation, particularly given the large size of some datasets. The reviewer suggests that having fewer datasets for each task might limit the applicability of certain algorithms. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the concern. The lack of detailed justification or evidence makes the claim 3, as it requires more information to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the sufficiency of the datasets for a rigorous evaluation, particularly given the large size of some datasets. It suggests that having fewer datasets for each task might limit the applicability of certain algorithms. The comment is 3 as it identifies a potential weakness in the dataset selection and provides a direction for improvement by suggesting the addition of more datasets or a repository for reproducing experiments. However, it lacks specific guidance on which datasets to consider or how to address the issue, making it somewhat incomplete. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the results presented, noting that while there is good performance on imageNet classification with ResNet50/34/18, there are no results with larger models like ResNet101/152. This comment implies that the authors should include results with larger models to provide a more comprehensive evaluation of their work. However, it does not explicitly instruct the authors to do so or provide specific guidance on how to incorporate these results. The action is implicit and somewhat vague, as the authors can infer that they need to include additional results but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights a gap in the results presented, noting that while there is good performance on imageNet classification with ResNet50/34/18, there are no results with larger models like ResNet101/152. However, it does not specify which part of the paper this observation is based on, such as a specific section or table where results are presented. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in pointing out the absence of results with larger models, but without explicit grounding, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that while there is good performance on imageNet classification with ResNet50/34/18, there are no results with larger models like ResNet101/152. This claim is based on the observation that the paper does not include results with larger models, which is a logical inference. However, the comment lacks specific references or detailed reasoning to support the claim that larger models should be included. While the claim is 3 due to the logical reasoning, it could be strengthened with additional evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the results presented, noting that while there is good performance on imageNet classification with ResNet50/34/18, there are no results with larger models like ResNet101/152. This feedback is 3 as it points out an area where the authors could expand their evaluation to provide a more comprehensive understanding of their model\"s performance. However, the comment lacks specific suggestions or guidance on how to incorporate these larger models into the study, such as which datasets to use or what specific metrics to consider. While it highlights an important area for improvement, the lack of detailed guidance limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the method\"s ability to address sparse reward problems and compares it to other methods like Qmix. However, it does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their method. The comment lacks concrete actions or details on how to implement changes, leaving the authors uncertain about what steps to take. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises questions about the method\"s ability to address sparse reward problems and compares it to other methods like Qmix. However, it does not specify which part of the paper discusses the method or the experiments, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its critique of the method\"s effectiveness and the comparison with Qmix, but it lacks grounding as it does not clearly identify the parts of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the method\"s ability to address sparse reward problems and compares it to other methods like Qmix. However, the comment lacks specific evidence or examples to support the claim that the method does not address sparse reward problems effectively. It also does not provide references or detailed reasoning to substantiate the comparison with Qmix. Without these elements, the claim remains vague and difficult for the authors to address, making it 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a critical question about the method\"s ability to address sparse reward problems, specifically questioning whether it offers a better solution compared to other methods like Qmix. It also points out a potential issue with the proposed method requiring subtaskspecific rewards, which could be seen as providing a dense reward signal. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address these concerns or improve their method. While it identifies an area for improvement, the feedback is incomplete and does not offer actionable steps, making it 3 but not fully comprehensive. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies two issues: confusing mistakes in the proof of the main results and a lack of detailed discussion and comparison with previous work. It also suggests that the paper does not provide new insights. However, the comment does not provide specific guidance on how to address these issues or what aspects of the proof or comparison need clarification. The feedback is vague and lacks actionable steps, leaving the authors uncertain about how to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment mentions \"confusing mistakes in the proof of the main results\" and a lack of detailed discussion and comparison with previous work. However, it does not specify which part of the paper these issues are found in, making it weakly grounded. The comment also lacks specificity as it does not provide details on what exactly is confusing or how the paper could improve its discussion and comparison with previous work. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that there are \"confusing mistakes\" in the proof of the main results and that the paper lacks a detailed discussion and comparison with previous work. However, it does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issues. The comment also suggests that the paper does not provide new insights, but again, lacks specific evidence or examples to substantiate this claim. As a result, the comment is 1 due to the lack of detailed justification or evidence.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper: confusing mistakes in the proof of the main results and a lack of detailed discussion and comparison with previous work. It also suggests that the paper does not provide new insights. While the comment highlights important areas for improvement, it lacks specific guidance or suggestions on how to address these issues. The authors are left with a general understanding of what needs to be improved but without detailed instructions on how to make those improvements. Therefore, the comment is 3, as it provides some direction but not enough actionable feedback to fully guide the authors in enhancing their draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the clarity of the motivation for using an adversarial network in the model and questions the fairness of the experimental results. It also points out that the proposed model is larger than others due to the addition of CAT and GAN, even when compared to pretrained models. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues. The authors are left to infer that they need to clarify the motivation and potentially revise the experimental setup, but without concrete steps or examples, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises concerns about the clarity of the motivation for using an adversarial network in the model and questions the fairness of the experimental results. It also points out that the proposed model is larger than others due to the addition of CAT and GAN, even when compared to pretrained models. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but without explicit references, it is challenging to pinpoint the exact parts needing revision. The comment is specific in detailing the issues with the motivation and experimental setup, but the lack of grounding limits its effectiveness. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the clarity of the motivation for using an adversarial network in the model and questions the fairness of the experimental results. It also points out that the proposed model is larger than others due to the addition of CAT and GAN, even when compared to pretrained models. However, the comment lacks specific examples, detailed reasoning, or references to support these claims. The lack of evidence or detailed justification makes it difficult for the authors to understand and address the issues effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies several areas of concern, including the lack of clarity in the motivation for using an adversarial network and the fairness of the experimental results. It also points out that the proposed model is larger than others due to the addition of CAT and GAN, even when compared to pretrained models. While the comment highlights important issues, it does not provide specific suggestions or guidance on how the authors might address these concerns. The feedback is 3 as it directs the authors\" attention to areas needing clarification or improvement, but it lacks actionable advice or detailed suggestions for enhancement. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of an adversarial loss to ensure that perturbed data is similar to authentic data. While the comment identifies a potential issue, it does not provide explicit guidance on how to address this concern or suggest specific actions for the authors to take. The action is implicit and somewhat vague, as the authors are left to infer that they need to incorporate an adversarial loss but are not given detailed instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment highlights a specific issue regarding the absence of an adversarial loss to ensure perturbed data is similar to authentic data. However, it does not specify which part of the paper this issue pertains to, such as a particular section or experiment. Without explicit references, the authors may find it challenging to pinpoint the exact location of the issue. The comment is specific in identifying the lack of an adversarial loss but lacks grounding, as it does not clearly indicate where this issue is discussed in the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there is no adversarial loss to ensure perturbed data is similar to authentic data. This is a factual statement that does not require verification or justification. It is a direct observation about the absence of a specific element in the paper, making it a normal statement. Therefore, the label \"No\" is appropriate.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting the absence of an adversarial loss to ensure perturbed data is similar to authentic data. This is a relevant observation that could impact the robustness and validity of the results. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might address this issue or why it is important. Without additional context or actionable advice, the authors are left with a vague understanding of what needs to be improved. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in making improvements."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the number of hyperparameters that need to be tuned and the potential variation in optimal hyperparameters due to the optimization being solved on a samplebysample basis. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their draft. The comment lacks actionable guidance, such as recommending specific methods for tuning hyperparameters or discussing potential strategies to mitigate the variation. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a concern about the number of hyperparameters that need to be tuned and the potential variation in optimal hyperparameters due to the optimization being solved on a samplebysample basis. However, it does not specify which part of the paper this issue pertains to, such as a specific section or experiment. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. Additionally, while the comment identifies a potential issue, it does not provide specific guidance on how to address it or what changes might be necessary. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a concern about the number of hyperparameters that need to be tuned and the potential variation in optimal hyperparameters due to the optimization being solved on a samplebysample basis. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the number of hyperparameters that need to be tuned and the potential variation in optimal hyperparameters due to the optimization being solved on a samplebysample basis. This is a relevant concern that could impact the robustness and generalizability of the results. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as recommending methods for hyperparameter tuning or discussing potential strategies to mitigate the variation. Without actionable advice, the authors are left with a general understanding of the problem but without a clear path to improvement. Therefore, the comment is 3, as it highlights an important area for consideration but does not provide sufficient detail or direction for the authors to effectively address the issue."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the performance of the proposed method should be compared with more methods and that analysis should be provided for inferior results that violate the motivation. While the comment implies that the authors should expand their comparisons and provide additional analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add more comparisons and analysis. However, the comment does provide a clear direction for improvement, making it 3.", "grounding_specificity_rationale": "The comment addresses the comparison of performance with other methods and the consistency of the proposed method\"s superiority. It suggests that analysis should be provided for inferior results that violate the motivation. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for additional analysis, but without clear grounding, it is challenging for the authors to pinpoint the exact sections that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the performance is only compared with a few methods and that the proposed method is not consistently better than others. It suggests that analysis should be provided for inferior results that violate the motivation. However, the comment lacks specific examples or references to support the claim about the limited comparison or the inconsistency in performance. Without detailed evidence or examples, the authors may find it challenging to address the feedback effectively. Therefore, the claim is considered 2, as it provides some basis for the critique but requires more detailed justification.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s performance evaluation, noting that it is only compared with a few methods and that the proposed method is not consistently better than others. It suggests that analysis should be provided for inferior results that violate the motivation. This feedback is clear and actionable, as it directs the authors to expand their comparisons and provide additional analysis to address the inconsistency in performance. However, the comment could be more helpful if it offered specific suggestions on how to conduct this analysis or which methods to include in the comparison. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests an interesting comparison between the support of the solution obtained by the proposed scheme and that obtained by baseline methods, such as using a Jaccard index. While the comment implies that the authors should include this comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to conduct the comparison or what metrics to use. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests a comparison between the support of the solution obtained by the proposed scheme and that obtained by baseline methods, such as using a Jaccard index. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting a particular comparison method, but without clear grounding, the authors may struggle to determine where to incorporate this suggestion. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests an interesting comparison between the support of the solution obtained by the proposed scheme and that obtained by baseline methods, such as using a Jaccard index. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison would be beneficial or how it could improve the paper. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests an interesting comparison between the support of the solution obtained by the proposed scheme and that obtained by baseline methods, such as using a Jaccard index. This feedback is 3 as it provides a specific suggestion for enhancing the paper by adding a comparative analysis. However, the comment lacks depth and does not offer detailed guidance on how to conduct this comparison or what specific metrics to use. While it points the authors in a direction for improvement, it could be more helpful with additional details or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the originality of the article, noting similarities to another work. It questions whether the current work is merely an extension of the previous study or if it introduces novel contributions. However, it does not provide explicit guidance or suggestions on how the authors should address these concerns or differentiate their work from the previous study. The action is implicit and vague, as the authors are left to infer that they need to clarify the originality of their work but are not given specific steps to take. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises concerns about the originality of the article, noting similarities to another work. However, it does not specify which parts of the article are similar or how they relate to the previous study. This lack of specificity makes it difficult for the authors to identify the exact areas that need attention or improvement. Additionally, the comment does not provide explicit references to the previous study, making it challenging for the authors to pinpoint the specific similarities. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point raises a concern about the originality of the article, noting similarities to another work. It questions whether the current work is merely an extension of the previous study or if it introduces novel contributions. However, the comment does not provide specific examples or detailed comparisons to support this claim, making it difficult for the authors to understand the basis of the concern. The lack of detailed reasoning or references leaves the claim 3, as it requires more information to fully substantiate the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the originality of the article, noting similarities to another work. It questions whether the current work is merely an extension of the previous study or if it introduces novel contributions. This feedback is 3 as it prompts the authors to consider the uniqueness and novelty of their work, potentially leading to a more thorough exploration of their contributions. However, the comment lacks specific guidance on how the authors might address these concerns or differentiate their work from the previous study. To be more helpful, the comment could include suggestions on how to articulate the originality or provide examples of novel contributions. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the limited practical significance of the verylongterm forecasting task and suggests improvements to the discussion, such as conducting experiments on more datasets and training baseline models with the \"correct\" forecast horizon. While the comment implies that these actions are necessary, it does not explicitly instruct the authors to do so. The authors can infer the need for these improvements, but the comment lacks concrete guidance on how to implement them. Therefore, the comment is 3, as it provides a clear direction but lacks detailed instructions.", "grounding_specificity_rationale": "The comment addresses the discussion section of the paper, specifically mentioning the need for improvement in the context of the verylongterm forecasting task. It suggests conducting experiments on more datasets and training baseline models with the \"correct\" forecast horizon to provide a proper context for the results. However, the comment does not explicitly mention which part of the discussion is lacking or what specific aspects need improvement. While the authors can infer that it relates to the discussion section, the lack of explicit references makes it weakly grounded. The comment is specific in suggesting improvements, such as conducting additional experiments and training baseline models, but it does not specify which parts of the discussion are problematic. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the verylongterm forecasting task is of limited practical significance and suggests improvements to the discussion, such as conducting experiments on more datasets and training baseline models with the \"correct\" forecast horizon. However, the comment lacks specific reasoning or evidence to support the claim about the limited practical significance of the task. It also does not provide examples or references to justify the need for additional experiments or training with the \"correct\" forecast horizon. Without these details, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the practical significance of the verylongterm forecasting task, suggesting that the discussion could be improved by conducting experiments on more datasets and training baseline models with the \"correct\" forecast horizon. This feedback is 3 as it points out a specific area for improvement and provides a direction for enhancing the discussion. However, the comment lacks detailed guidance on how to conduct these experiments or what specific datasets or forecast horizons should be considered. While it offers a clear direction, the lack of detailed instructions limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should conduct theoretical analyses or extensive experiments to understand why the simple greedy selection approach outperforms more principled acquisition functions and why deterministic MLP predictors outperform probabilistic predictors like GPs, deep ensembles, or Bayesian neural networks. However, the comment does not provide explicit instructions or concrete steps on how to conduct these analyses or experiments. While the authors can infer that they need to perform additional research, the lack of detailed guidance makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should conduct theoretical analyses or extensive experiments to understand the reasons behind the empirical results. It mentions specific aspects that could be explored, such as the performance of simple greedy selection versus more principled acquisition functions and the superiority of deterministic MLP predictors over probabilistic predictors. However, the comment does not specify which part of the paper these analyses or experiments should be conducted in, making it weakly grounded. The suggestion is specific in terms of what needs to be addressed, but without explicit references to sections or parts of the paper, the authors may find it challenging to pinpoint the exact areas for improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the empirical results of the proposed method are strong and that a more novel contribution would be to explore theoretical analyses or extensive experiments to understand the reasons behind the performance of simple greedy selection and deterministic MLP predictors. The comment highlights a gap in the paper regarding rigorous analyses to support these findings. However, it does not provide specific examples, references, or detailed reasoning to substantiate the claim that the current analyses are insufficient. This lack of detailed justification makes the claim 3, as the authors would need to infer the need for additional analyses based on the general suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting that the authors conduct theoretical analyses or extensive experiments to understand the reasons behind the empirical results. It specifically mentions the superiority of simple greedy selection over more principled acquisition functions and the performance of deterministic MLP predictors over probabilistic predictors. While the comment highlights an interesting direction for further exploration, it lacks specific guidance or detailed suggestions on how to conduct these analyses or experiments. The authors are left with a general idea of what could be explored but without concrete steps to follow. Therefore, the comment is 3, as it provides some direction but lacks depth and actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states that the authors have not analyzed the security of their proposed framework, specifically the protection of privacy. This provides a clear and direct action for the authors to take: they should include an analysis of the security aspects of their framework, particularly focusing on privacy protection. The comment is explicit and provides a concrete action for the authors to follow, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of analysis on the security (i.e., protection of privacy) of the proposed framework. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what is missing: an analysis of the security aspects, particularly the protection of privacy. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors have not analyzed the security (i.e., protection of privacy) of the proposed framework. However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of analysis on the security (i.e., protection of privacy) of the proposed framework. This is a critical area that the authors need to address to ensure the robustness and reliability of their work. However, the comment does not provide specific suggestions or guidance on how the authors might approach this analysis or what aspects of security they should consider. While it highlights an important area for improvement, the lack of detailed feedback limits its helpfulness. Therefore, the comment is 3, as it provides a clear direction for improvement but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the use of the term \"multiscale\" in the context of the slow and fast RNNs, suggesting that the statement is misleading because the RNNs operate on a logical time scale rather than a physical one. The reviewer highlights that the only benefit seems to be the reduction of gradient path by the slow RNN. While the comment identifies a potential issue with the terminology, it does not provide explicit guidance on how to address this issue or suggest alternative wording. The action is implicit and somewhat vague, as the authors are left to infer that they should clarify the terminology or provide additional context. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the use of the term \"multiscale\" in the context of the slow and fast RNNs, suggesting that it is misleading because the RNNs operate on a logical time scale rather than a physical one. However, the comment does not specify which part of the paper this discussion is located in, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where this discussion could be, the lack of explicit grounding makes it challenging to identify the specific part of the paper being addressed. The comment is specific in detailing the issue with the terminology, but without full grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point claims that the use of the term \"multiscale\" is misleading because the slow and fast RNNs operate on a logical time scale rather than a physical one. The reviewer provides a logical reasoning by explaining that the RNNs operate on a logical time scale when the stacks are sequentialized in the graph. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the terminology used in the paper, specifically the term \"multiscale,\" which the reviewer suggests is misleading. The reviewer explains that the slow and fast RNNs operate on a logical time scale rather than a physical one, and that the only benefit seems to be the reduction of gradient path by the slow RNN. This feedback is clear and actionable, as it points out a specific area where the authors might need to clarify their terminology or provide additional context to avoid confusion. However, the comment could be more helpful if it offered suggestions on how to rephrase or clarify the terminology. Overall, the comment is 4 as it provides valuable insight into a potential misunderstanding in the paper, prompting the authors to consider revising their terminology for clarity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the feature selection presented in Section 4.2 could be improved by considering representation learning. However, it does not provide explicit guidance on how to incorporate representation learning or what specific aspects of the feature selection need improvement. The comment implies an action but lacks concrete details on how to implement it, leaving the authors with a general direction but no clear steps to follow. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper, including \"Sec. 4.2\" and \"Line 167174, Sec. 4,\" allowing the authors to accurately identify the parts being addressed. It also specifies the issue by pointing out that the proposed invariant learning module focuses on mask selection and rawlevel features, while the former framework seems not limited to rawlevel selection. Additionally, the comment suggests that the feature selection could be improved by considering representation learning. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the feature selection presented in Section 4.2 could be improved by considering representation learning. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The mention of the \"former framework\" and \"representation learning in the appendix\" adds some context but lacks sufficient detail to fully substantiate the claim. As a result, the comment is 3, as it provides a general direction but lacks the depth needed for a 5 claim.", "helpfulness_rationale": "The review comment identifies a potential weakness in the proposed invariant learning module, specifically noting that the feature selection presented in Section 4.2 could be improved by considering representation learning. It points out a discrepancy between the focus on mask selection and rawlevel features in Section 4.2 and the broader discussion about representation learning in the appendix. This feedback is 3 as it highlights an area for improvement and suggests a direction for enhancing the feature selection. However, the comment could be more helpful if it provided specific examples or detailed guidance on how to incorporate representation learning into the feature selection process. Overall, the comment offers a valuable insight but lacks depth and actionable suggestions, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the quality of paraphrases used in the training data, noting that the difference between the paraphrases and the original sentences is unclear. It suggests that this could impact the subsequent steps, as the model relies on the quality of these paraphrases. The comment implies that the authors should ensure the paraphrases are sufficiently different from the originals to maintain the quality of the training data. However, it does not provide explicit guidance on how to achieve this or what specific steps to take. The action is implicit and somewhat vague, as the authors can infer that they need to address the issue of paraphrase quality but are not given concrete instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific concern about the quality of paraphrases used in the training data, questioning how different they are from the original sentences. It highlights the importance of this issue for subsequent steps, as the model relies on the quality of these paraphrases. However, the comment does not specify which part of the paper discusses the generation of paraphrases, making it weakly grounded. The authors can infer that it relates to the methodology or data preparation sections, but this inference is not explicit. The comment is specific in detailing the impact of the paraphrase quality on the training data and subsequent steps. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the quality of paraphrases used in the training data is unclear, which could impact the subsequent steps of the model. The reviewer provides a logical reasoning by suggesting that if the difference between the paraphrases and the original sentences is not significant, the quality of the training data will be compromised. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to further explore and substantiate the claim themselves to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the quality of paraphrases used in the training data, noting that the difference between the paraphrases and the original sentences is unclear. It highlights the importance of this issue, as it directly impacts the subsequent steps of the model, which relies on the quality of these paraphrases. The comment provides a clear and actionable suggestion by pointing out that if the paraphrases are not sufficiently different, the quality of the training data will be compromised, leading to a limited number of pairs being added to the new training data. This feedback is valuable as it directs the authors to address a specific weakness in their methodology, offering a clear path for improvement. However, the comment could be more helpful if it provided specific guidance on how to ensure the quality of the paraphrases or examples of what constitutes a sufficient difference. Overall, the comment is 4, as it effectively highlights a critical area for improvement and provides a clear direction for the authors to enhance their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should further verify the effectiveness and universality of the FlippedQA framework beyond LLMbased models, such as HiTeA and InternVideo. While the comment implies that the authors should conduct additional experiments or evaluations, it does not provide specific guidance on how to implement these tests or what metrics to use. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the FlippedQA framework should be further verified for its effectiveness and universality beyond LLMbased models, specifically mentioning HiTeA and InternVideo. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the discussion of the framework\"s applicability, but the lack of explicit grounding makes it difficult to pinpoint the exact part of the paper being addressed. The comment is specific in suggesting additional verification, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the FlippedQA framework should be further verified for its effectiveness and universality beyond LLMbased models, specifically mentioning HiTeA and InternVideo. The comment provides a logical reasoning by suggesting that the framework\"s applicability should be tested with nonLLMbased models. However, it lacks specific examples or references to support the claim that these models should be included in the evaluation. This makes the claim 3, as it provides a direction for further testing but lacks detailed evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the FlippedQA framework should be further verified for its effectiveness and universality beyond LLMbased models, specifically mentioning HiTeA and InternVideo. This feedback is 3 as it identifies a potential limitation in the paper\"s scope and suggests a direction for further validation. However, the comment lacks specific guidance on how to conduct these additional tests or what metrics to use, which would make it more actionable. The authors are given a general idea of what needs to be addressed but are not provided with detailed steps to improve their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the proposed method primarily builds upon existing methods and lacks significant theoretical novelty. The reviewer expresses willingness to improve their score if the authors address these concerns. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or enhance the theoretical novelty of their work. The action is implicit and vague, as the authors are left to infer what changes might be necessary without concrete direction. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed method and its reliance on existing methods, such as ClopperPearson intervals and Gaussian elimination. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it highlights the lack of theoretical novelty and suggests that the authors address this concern to improve the reviewer\"s score. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method primarily builds upon existing methods and lacks significant theoretical novelty. The reviewer supports this claim by referencing specific existing methods, such as ClopperPearson intervals and Gaussian elimination, which are cited in the text. This provides a clear basis for the claim, making it 5. The inclusion of references to these methods allows the authors to understand the basis of the critique and potentially address it in their response. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, noting that the proposed method primarily builds upon existing methods and lacks significant theoretical novelty. This feedback is 3 as it points out an area where the authors might need to enhance their work to differentiate it from existing approaches. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the theoretical contribution of their work. While it highlights a critical area for improvement, the lack of actionable advice limits the comment\"s usefulness. Therefore, it is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point poses a question about whether the text input can be concatenated by the four text elements of an object. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this question or what the authors should do with the information provided. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, it is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment poses a question about whether the text input can be concatenated by the four text elements of an object. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section being addressed. Additionally, the comment lacks specificity as it does not provide any context or explanation about why this question is relevant or what implications it might have for the paper. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification about whether the text input can be concatenated by the four text elements of an object. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment poses a question about whether the text input can be concatenated by the four text elements of an object. While it highlights a potential area of confusion or misunderstanding, it does not provide any actionable feedback or suggestions for improvement. The authors are left without guidance on how to address this question or clarify the issue in their draft. As a result, the comment is 1, as it does not offer any actionable insights or direction for the authors to enhance their work."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper should better motivate the \"Why\" aspect, explaining why the presented topic is important or relevant. However, it does not provide specific guidance on how to achieve this motivation or what aspects should be highlighted. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide a stronger rationale for their work but without concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the paper should better motivate the \"Why\" aspect, explaining why the presented topic is important or relevant. However, it does not specify which part of the paper lacks this motivation or where it should be added. The authors might infer that it relates to the introduction or the motivation section, but this inference is not explicit. The comment is specific in its suggestion to provide a stronger rationale but lacks grounding, as it does not pinpoint a specific section or element of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should better motivate the \"Why\" aspect, explaining why the presented topic is important or relevant. However, the comment does not provide any specific reasoning, examples, or references to support why this motivation is lacking or how it could be improved. Without additional context or justification, the authors may find it challenging to understand and address the feedback. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a potential weakness in the paper, noting that it lacks a clear motivation for the \"Why\" aspect of the work. It suggests that the authors should better explain why the presented topic is important or relevant, which is a valid point. However, the comment does not provide specific guidance or examples on how to improve this aspect of the paper, such as suggesting what aspects of the motivation should be emphasized or how to present them effectively. While it highlights an area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests conducting additional experiments on realistic noisy datasets like WebVision to provide more support for C2D. While the comment implies that the authors should conduct these experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not specify the exact nature of the experiments or how they should be conducted. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests conducting additional experiments on realistic noisy datasets like WebVision to support the claims made in the paper. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting a particular type of experiment that could be conducted to strengthen the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests conducting additional experiments on realistic noisy datasets like WebVision to provide more support for C2D. However, the comment does not provide any specific reasoning, examples, or references to justify why these experiments would be beneficial or how they would enhance the paper. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests conducting additional experiments on realistic noisy datasets like WebVision to provide more support for the claims made in the paper. This feedback is 3 as it identifies a specific area for improvement and suggests a potential direction for enhancing the paper. However, the comment lacks detailed guidance on how to conduct these experiments or what specific aspects of the dataset would be most beneficial. While it provides a clear suggestion, it could be more helpful with additional details or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of essential visualizations of intermediate processes and comparisons, suggesting that these are necessary for the paper. However, it does not provide specific guidance on what these visualizations should include or how they should be presented. The action is implicit, as the authors can infer that they need to add visualizations, but it is vague because it lacks concrete details on what exactly should be visualized or compared. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment highlights a lack of essential visualizations of intermediate processes and comparisons, but it does not specify which part of the paper lacks these visualizations or where they should be included. This makes it difficult for the authors to pinpoint the exact sections that need improvement. Additionally, the comment lacks specificity regarding what kind of visualizations or comparisons are needed. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that there is a lack of essential visualization of intermediate processes and comparisons. However, it does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific area for improvement by pointing out the lack of essential visualizations of intermediate processes and comparisons. This feedback is valuable as it highlights a potential gap in the paper that could enhance its clarity and comprehensibility. However, the comment lacks specificity regarding what these visualizations should include or how they should be presented, which limits its helpfulness. Providing more detailed guidance on what aspects of the intermediate processes or comparisons should be visualized would make the feedback more actionable and beneficial for the authors. Therefore, the comment is 3, as it points out an area for improvement but does not fully guide the authors on how to address it."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point expresses concern about the importance of the result and suggests that it is not surprising given the findings in 15. It also points out that the iteration complexity is no longer dimensionfree in Theorem 3. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their draft. The action is implicit and vague, as the authors are left to infer that they should clarify the importance of their result or address the iteration complexity issue, but without concrete steps or details on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment expresses concern about the importance of the result and suggests that it is not surprising given the findings in 15. It also mentions a change in iteration complexity in Theorem 3. However, the comment does not specify which part of the paper these concerns relate to, such as a specific section, table, or figure. This makes it difficult for the authors to pinpoint the exact areas that need attention. Additionally, while the comment provides some specific details about the iteration complexity, it lacks specificity regarding the importance of the result or how it relates to the findings in 15. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point expresses concern about the importance of the result, suggesting that it is not surprising given the findings in 15. It also mentions a change in iteration complexity in Theorem 3. However, the comment lacks specific examples or detailed reasoning to support the claim that the result is not surprising or to explain the impact of the iteration complexity change. Without additional context or references, the authors may find it challenging to understand and address the concerns raised. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment expresses concern about the importance of the result, suggesting that it is not surprising given the findings in 15. It also points out a change in iteration complexity in Theorem 3, which is no longer dimensionfree. While the comment identifies potential issues with the result and its implications, it lacks specific suggestions or guidance on how the authors might address these concerns or improve their draft. The feedback is 3 as it highlights areas that need clarification or further explanation, but it does not provide actionable steps for improvement. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the sensitivity of the empirical results to hyperparameter choices, emphasizing that wrong choices could negate any improvement gained from the method. The reviewer explicitly states that they are willing to reconsider their rating if this issue is addressed. While the comment highlights an important area for improvement, it does not provide specific guidance on how the authors should evaluate or address the sensitivity of the results to hyperparameter choices. The action is explicit but lacks concrete details on how to implement it, making it 3.", "grounding_specificity_rationale": "The comment raises a concern about the sensitivity of the empirical results to hyperparameter choices, emphasizing the importance of this issue. However, it does not specify which part of the paper discusses the empirical results or hyperparameter choices, making it weakly grounded. The comment is specific in its request for addressing the sensitivity of the results to hyperparameter choices, which could impact the overall evaluation of the method. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the sensitivity of the empirical results to hyperparameter choices, emphasizing that wrong choices could negate any improvement gained from the method. However, the comment does not provide specific examples, reasoning, or references to support this claim. Without detailed evidence or examples, the authors may find it challenging to understand the basis of the concern or how to address it effectively. Therefore, the comment is considered 2, as it lacks sufficient justification to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a critical concern about the sensitivity of the empirical results to hyperparameter choices, emphasizing that wrong choices could negate any improvement gained from the method. This is an important point that highlights a potential weakness in the paper\"s methodology and results. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue, such as recommending a systematic approach to hyperparameter tuning or suggesting alternative methods to evaluate sensitivity. While it identifies a significant area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a critical issue but does not fully support the authors in resolving it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors need to further claim the novelty and contribution of their proposed method, given that it utilizes existing attack methods on a surrogate model. While the comment implies that the authors should provide additional justification for the novelty of their approach, it does not explicitly instruct them on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the novelty and contribution of their method. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the novelty and contribution of the proposed method, specifically mentioning that it utilizes existing attack methods on a surrogate model. However, it does not specify which part of the paper this critique pertains to, such as a particular section or experiment. The authors can infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in its request for further clarification on the novelty and contribution, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the work utilizes existing attack methods on a surrogate model, which is similar to using the transferability of adversarial examples directly. The reviewer suggests that the authors need to further claim the novelty and contribution of their proposed method. However, the comment lacks specific examples or references to support the claim that the work is not novel or lacks contribution. Without detailed justification or evidence, the claim remains somewhat vague, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is rated as 3, as it provides some justification but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty and contribution of the proposed method, noting that it utilizes existing attack methods on a surrogate model, which is similar to using the transferability of adversarial examples directly. The comment suggests that the authors should further clarify the novelty and contribution of their approach. While it highlights an important area for improvement, the comment lacks specific guidance or suggestions on how the authors might address this issue or enhance their claims of novelty. The feedback is 3 as it points out a critical area for improvement but could be more actionable with additional details or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point identifies several issues with the experiment that estimates the quality of uncertainty estimates. It highlights the use of pseudo feature importance due to the lack of true feature importance, which relies on Proposition 3.2 and a large enough perturbation value. The comment suggests that this makes it difficult to judge the trustworthiness of the experiment, as the difference between the tested method and the pseudo feature importance is only the number of perturbations. The reviewer provides two specific suggestions for strengthening the experiment: first, by using a different method to estimate feature importance, and second, by providing a more detailed analysis of the perturbation value. These suggestions are explicit and provide concrete guidance on how to improve the experiment, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiment that estimates the quality of uncertainty estimates, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the experiment, namely the use of pseudo feature importance due to the lack of true feature importance, and the reliance on Proposition 3.2 and a large enough perturbation value. The comment further suggests ways to strengthen the experiment, such as using a different method to estimate feature importance and providing a more detailed analysis of the perturbation value. This level of detail and specificity provides clear guidance for the authors on how to improve their work. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiment using pseudo feature importance is difficult to trust because it relies on Proposition 3.2 and a large enough perturbation value. The reviewer suggests that the experiment could be strengthened by using a different method to estimate feature importance and providing a more detailed analysis of the perturbation value. While the comment provides some reasoning, it lacks specific examples or references to support the claim about the difficulty in trusting the experiment. This makes the claim 3, as it requires more detailed justification or evidence to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the experiment that estimates the quality of uncertainty estimates, specifically the use of pseudo feature importance due to the lack of true feature importance. It highlights the reliance on Proposition 3.2 and a large enough perturbation value, which makes it difficult to judge the trustworthiness of the experiment. The reviewer provides two specific suggestions for improvement: using a different method to estimate feature importance and providing a more detailed analysis of the perturbation value. These suggestions are clear and actionable, offering the authors concrete steps to enhance the robustness and credibility of their experiment. The feedback is comprehensive and constructive, making it 5 for the authors to improve their draft. Therefore, the comment deserves a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out a potential issue with the nonconvexity of the function Z and suggests that it may not be a problem for the SGD to converge if the function has certain properties. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this issue or what specific properties of the function Z should be considered. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (182184) in the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it highlights a potential issue with the nonconvexity of the function Z and suggests that it may not be a problem for the SGD to converge if the function has certain properties. This provides clear guidance on what aspect of the paper needs attention. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that nonconvexity may not be an issue for the SGD to converge, if the function Z has some good properties. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a potential issue with the nonconvexity of the function Z, suggesting that it may not be a problem for the SGD to converge if the function has certain properties. However, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue or explore the properties of the function Z that could affect convergence. Without actionable advice or detailed feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two issues: the lack of proper mention of experimental settings and the absence of code to reproduce results. While the comment implies that the authors should provide more information about the experimental settings and include the code, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address these issues. However, the comment provides a clear direction on what needs to be improved, making it 3.", "grounding_specificity_rationale": "The comment addresses the lack of proper mention of experimental settings and the absence of code to reproduce results. However, it does not specify which part of the paper discusses the experimental settings or where the code should be included. This makes it weakly grounded, as the authors cannot confidently determine the exact sections being referred to. The comment is specific in identifying the issues with experimental settings and code availability, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point claims that the experimental settings are not mentioned properly, which affects result reproducibility. However, it does not provide specific examples or detailed reasoning to support this claim. The mention of the lack of code further highlights the issue but lacks detailed justification. Without explicit examples or references to specific sections of the paper, the claim is 3, as it provides a general critique but lacks the necessary details for full verification.", "helpfulness_rationale": "The review comment identifies two critical issues with the paper: the lack of proper mention of experimental settings and the absence of code to reproduce results. This feedback is important as it highlights potential weaknesses that could impact the paper\"s credibility and reproducibility. However, the comment does not provide specific suggestions on how to address these issues or what information should be included about the experimental settings. While it points out important areas for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is 3, as it provides insight but lacks actionable advice, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point questions the validity of the claim regarding the effectiveness of the proposed prompts based on the slight improvement observed in Table 6 and Table 7. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue or improve the draft to support the claim. The comment lacks actionable advice, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment questions the validity of the claim regarding the effectiveness of the proposed prompts based on the slight improvement observed in Table 6 and Table 7. However, it does not specify which part of the paper these tables are located in, making it difficult for the authors to pinpoint the exact section being addressed. Additionally, the comment does not provide specific details on what aspects of the claim are questionable or how the slight improvement undermines the effectiveness claim. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point questions the validity of the claim regarding the effectiveness of the proposed prompts based on the slight improvement observed in Table 6 and Table 7. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate why the slight improvement is insufficient to support the claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment questions the validity of the claim regarding the effectiveness of the proposed prompts based on the slight improvement observed in Table 6 and Table 7. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve their draft to support the claim. The comment identifies a potential weakness but lacks actionable feedback, leaving the authors without a clear path for improvement. Therefore, it is rated as 2, as it points out a concern but does not offer constructive advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the analysis of the Cycle FC, which aligns features at different spatial locations to the same channel, is insufficient. It suggests that there could be many different designs of this process and recommends conducting experiments or analysis with different sampling intervals and sample sizes. While the comment implies that the authors should conduct additional experiments or analyses, it does not provide specific guidance on how to implement these suggestions or what specific experiments or analyses should be conducted. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the analysis of the Cycle FC, which aligns features at different spatial locations to the same channel. However, it does not specify which part of the paper discusses this analysis, making it weakly grounded. The comment suggests conducting experiments or analysis with different sampling intervals and sample sizes, which provides some specificity about what could be improved. However, without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing attention. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the analysis of the Cycle FC is insufficient and suggests conducting experiments or analysis with different sampling intervals and sample sizes. However, the comment lacks specific examples or detailed reasoning to support why these additional analyses are necessary or how they would improve the understanding of the Cycle FC. Without such evidence or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2, as it provides some direction but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that could be improved, namely the analysis of the Cycle FC, which aligns features at different spatial locations to the same channel. It suggests that the analysis is insufficient and proposes conducting experiments or analysis with different sampling intervals and sample sizes. This feedback is clear and actionable, providing the authors with a specific direction for enhancing their work. However, the comment could be more helpful if it included examples or detailed suggestions on how to conduct these experiments or analyses. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the dimensionality of each region and asks which feature extractor is used. While it identifies a specific line in the paper where this issue is discussed, it does not provide any explicit or implicit guidance on how the authors should address this question or what action they should take. The comment lacks actionable advice, such as suggesting ways to clarify or provide additional information about the feature extractor. As a result, the authors are left without a clear understanding of how to improve their draft in response to this feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 201,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the dimensionality of each region and asks which feature extractor is used. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the dimensionality of each region and the feature extractor used. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement and fitting the label \"No\".", "helpfulness_rationale": "The review comment raises a specific question about the dimensionality of each region and the feature extractor used, which is a relevant point for clarification. However, it does not provide any suggestions or guidance on how the authors might address this issue or improve their draft. The comment lacks depth and actionable feedback, leaving the authors with only a question to answer. Therefore, it is 2, as it identifies a potential area of confusion but does not offer any constructive advice for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the motivation behind applying CMD (Command and Data Manipulation) in federated learning is unclear and could be improved with a more explicit demonstration or explanation. While the comment implies that the authors should provide a clearer explanation, it does not specify how to achieve this or what aspects of the motivation need further elaboration. The action is implicit and somewhat vague, as the authors are left to infer the specific steps needed to improve the clarity of the motivation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the motivation behind applying CMD in federated learning, suggesting that it is unclear and could benefit from a more explicit demonstration or explanation. However, it does not specify which part of the paper discusses this motivation, making it weakly grounded. The comment is specific in identifying the issue of clarity regarding the motivation, but without explicit references to sections or parts of the paper, the authors may find it challenging to pinpoint the exact areas needing improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the motivation behind applying CMD in federated learning is unclear and suggests that it could benefit from a more explicit demonstration or explanation. However, the comment does not provide any specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, noting that the motivation behind applying CMD (Command and Data Manipulation) in federated learning is unclear. It suggests that the authors could improve their draft by providing a more explicit demonstration or explanation of this motivation. While the comment highlights an area for improvement, it lacks specific guidance or suggestions on how to enhance the clarity of the motivation. This limits the helpfulness of the feedback, as it provides a general direction but does not offer detailed actionable steps for the authors to follow. Therefore, the comment is 3, as it points out a weakness but does not fully support the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the performance boost claimed by the proposed CoNO model, suggesting that it is unclear whether the fractional transform or the UNet operation in the fractional Fourier domain is responsible for the improvement. The reviewer implies that comparisons to UNets are necessary to clarify this point. While the comment identifies a potential area for improvement, it does not explicitly instruct the authors to conduct these comparisons or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to compare their model to UNets, but they are not given detailed instructions on how to execute this comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"CoNO model\" and the \"UNet part after the fractional transform,\" allowing the authors to accurately identify the specific part of the paper being addressed. It also specifies the issue by questioning the source of the performance boost, suggesting that comparisons to UNets are necessary to clarify this point. The comment further references relevant literature, such as Raonic et al and Gupta et al, to support the suggestion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the source of the performance boost claimed by the proposed CoNO model, suggesting that it is unclear whether the fractional transform or the UNet operation in the fractional Fourier domain is responsible. The reviewer implies that comparisons to UNets are necessary to clarify this point, referencing relevant literature. This provides a logical reasoning for the claim, as it highlights the need for additional evidence or comparisons to support the performance claims. However, the comment could be strengthened by providing more detailed references or examples from the literature. Overall, the claim is 4, as it requires further elaboration but provides a solid basis for the authors to address the issue.", "helpfulness_rationale": "The review comment raises a critical question about the source of the performance boost claimed by the proposed CoNO model. It highlights a lack of clarity regarding whether the fractional transform or the UNet operation in the fractional Fourier domain is responsible for the improvement. The reviewer suggests that comparisons to UNets are necessary to clarify this point, especially since UNets have shown strong performance on regular gridded domains, as evidenced by references to Raonic et al and Gupta et al. This feedback is clear and actionable, as it directs the authors to conduct specific comparisons to better understand and substantiate their claims. However, the comment could be more helpful if it provided additional guidance on how to conduct these comparisons or what specific aspects to focus on. Overall, the comment is 4, as it identifies a critical area for improvement and offers a clear direction for the authors to enhance their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point expresses skepticism about the contribution of the paper, suggesting that the methods used in different stages are welldesigned and demonstrated, and that adding another stream for lowresolution might not be a significant contribution for a toptier venue like ICLR. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this concern or improve their contribution. Without actionable suggestions or a clear direction for revision, the authors are left without a path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses skepticism about the contribution of the paper, suggesting that the methods used in different stages are welldesigned and demonstrated, and that adding another stream for lowresolution might not be a significant contribution for a toptier venue like ICLR. However, the comment does not specify which part of the paper this critique is based on, nor does it provide details on what aspects of the contribution are considered marginal. Without explicit references to sections, figures, or specific contributions, the authors cannot confidently determine which parts of the paper are being addressed. This lack of grounding and specificity makes it difficult for the authors to understand and address the feedback effectively. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the contribution is marginal because the methods used in different stages are welldesigned and demonstrated, and that adding another stream for lowresolution might not be a significant contribution for a toptier venue like ICLR. However, the comment lacks specific examples or references to support this claim, such as comparing the contribution to similar work or discussing the novelty of the methods. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses skepticism about the contribution of the paper, suggesting that the methods used in different stages are welldesigned and demonstrated, and that adding another stream for lowresolution might not be a significant contribution for a toptier venue like ICLR. However, the comment lacks specificity and does not provide any actionable feedback or suggestions for improvement. It does not offer guidance on how the authors might enhance their contribution or address the reviewer\"s concerns. Without actionable advice or constructive criticism, the comment does not help the authors in improving their draft. Therefore, it is rated as 1."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges the comprehensive Appendix and appreciates the additional detail it provides. However, it also mentions that the reviewer did not have time to carefully read the additional experiments described in the Appendix, such as the Brusselator. This comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on whether the authors should focus on improving the clarity or accessibility of the Appendix or whether they should prioritize other aspects of the paper. Without actionable suggestions or feedback, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment acknowledges the comprehensive Appendix and appreciates the additional detail it provides. However, it also mentions that the reviewer did not have time to carefully read the additional experiments described in the Appendix, such as the Brusselator. This provides some specificity regarding the parts of the paper that were not fully reviewed, but it does not specify what needs to be addressed or improved in these sections. The comment is weakly grounded as it does not explicitly mention which part of the paper the additional experiments are located, leaving the authors to infer the relevant sections. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point acknowledges the comprehensive Appendix and appreciates the additional detail it provides. However, it also mentions that the reviewer did not have time to carefully read the additional experiments described in the Appendix, such as the Brusselator. This is a factual statement describing the reviewer\"s experience and does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment acknowledges the comprehensive Appendix, which is appreciated for providing additional detail about parts of the paper. However, it also mentions that the reviewer did not have time to carefully read the additional experiments described in the Appendix, such as the Brusselator. This feedback is 3 as it highlights a potential area for improvement, suggesting that the authors might want to prioritize the clarity and accessibility of the Appendix. However, the comment lacks specific guidance or suggestions on how to address this issue, such as recommending ways to streamline the Appendix or improve its organization. Therefore, while it provides some insight, it is not fully actionable or comprehensive, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the authors\" claim regarding the use of active learning in step 2. It asks whether the \"active learning pipeline\" method is the same as traditional active learning, which selects informative samples to label. This implies that the authors should clarify the distinction between the two methods and ensure that their description does not mislead readers. While the comment identifies an area for clarification, it does not provide explicit instructions on how to address the issue or what specific information should be included. The action is implicit and somewhat vague, as the authors need to infer the need for clarification and determine how to provide it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific claim made by the authors regarding the use of active learning in step 2. It questions whether the \"active learning pipeline\" method is the same as traditional active learning, which selects informative samples to label. This provides clear guidance on what needs to be clarified or corrected in the paper. However, the comment does not explicitly mention which part of the paper discusses this claim, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point questions the authors\" claim about using active learning in step 2, suggesting that the \"active learning pipeline\" method might not be the same as traditional active learning. The comment raises a concern about potential confusion in the description, but it does not provide specific evidence or examples to support this claim. The lack of detailed reasoning or references makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered 2, as it provides some basis for questioning but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment raises a concern about the authors\" claim regarding the use of active learning in step 2. It questions whether the \"active learning pipeline\" method is the same as traditional active learning, which selects informative samples to label. This is a valid point that could lead to confusion among readers and highlights the need for clarification in the paper. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending a more detailed explanation or clarification in the manuscript. While it identifies a potential area for improvement, the feedback lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the clarity of the experimental methodology, specifically regarding the use of the 300WLP dataset. It questions whether the dataset is used in all experiments or just some, and if it is used in all, it could provide an unfair advantage to the proposed method. While the comment identifies a potential issue, it does not explicitly instruct the authors to clarify or address this point. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the experimental methodology and address the potential unfair advantage. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental methodology\" and the use of the 300WLP dataset, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the clarity of the experimental methodology, specifically regarding the use of the 300WLP dataset and its potential impact on the fairness of the experiments. The comment raises a clear issue about the consistency and fairness of the experimental setup, providing specific details that need to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of the experimental methodology, specifically regarding the use of the 300WLP dataset. It questions whether the dataset is used in all experiments or just some, and if it is used in all, it could provide an unfair advantage to the proposed method. The comment provides a logical reasoning by pointing out the inconsistency in the experimental setup and its potential impact on fairness. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to clarify the experimental methodology to fully address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the experimental methodology, specifically regarding the use of the 300WLP dataset. It questions whether the dataset is used in all experiments or just some, and if it is used in all, it could provide an unfair advantage to the proposed method. This feedback is clear and actionable, as it prompts the authors to clarify the experimental methodology and address any potential biases in their approach. By highlighting this issue, the comment provides the authors with a concrete step to improve the transparency and fairness of their experimental setup. However, the comment could be more helpful if it provided suggestions on how to address the issue or offered examples of how to clarify the methodology. Overall, the comment is 4, as it directs the authors to a critical area that needs clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point suggests that some techniques used in the algorithm, such as computation offloading and gradient augmentation, may not be particularly novel. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue or improve the novelty of their techniques. The comment lacks actionable details, leaving the authors uncertain about what steps to take to enhance the novelty of their work. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment suggests that some techniques used in the algorithm, such as computation offloading and gradient augmentation, may not be particularly novel. However, it does not specify which part of the paper discusses these techniques, making it difficult for the authors to identify the exact sections that need attention. The comment is vague and lacks specificity, as it does not provide details on why these techniques might not be novel or how they could be improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that some techniques used in the algorithm, such as computation offloading and gradient augmentation, may not be particularly novel. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without specific examples or detailed justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that some techniques used in the algorithm, such as computation offloading and gradient augmentation, may not be particularly novel. However, it does not provide any specific examples or detailed reasoning to support this claim, nor does it offer suggestions on how the authors might address this issue or improve the novelty of their techniques. Without actionable feedback or guidance, the comment lacks utility for the authors in terms of improving their draft. Therefore, it is rated as 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the formulation of Equation (1), suggesting that the observations might be aggregated by methods other than averaging, such as summation or populationweighted average. It also mentions that disease incident data are often available in counts or rates per number of residents. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern or suggest specific changes to their formulation. The action is implicit and somewhat vague, as the authors need to infer that they should consider alternative aggregation methods and discuss the implications for their data. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equation (1),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the formulation assumes observations are obtained by averaging over the support, but this might not always be the case, as other aggregation methods like summation or populationweighted average could be used. Additionally, it provides context by mentioning that disease incident data are often available in counts or rates per number of residents. This level of detail and specificity helps the authors understand the critique and potential areas for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the formulation in Equation (1) assumes observations are obtained by averaging over the support, but this might not always be the case. The reviewer provides a logical reasoning by suggesting alternative aggregation methods, such as summation or populationweighted average, and references the availability of disease incident data in counts or rates per number of residents. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened by referencing specific studies or examples where these alternative aggregation methods are used, which would further enhance its verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the formulation of Equation (1), suggesting that the observations might be aggregated by methods other than averaging, such as summation or populationweighted average. It also mentions that disease incident data are often available in counts or rates per number of residents, which could impact the formulation. This feedback is 3 as it points out a specific area where the authors might need to consider alternative aggregation methods or discuss the implications of different data types. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or offered examples of how other researchers have handled similar situations. Overall, the comment is 3 as it prompts the authors to consider a potential limitation in their formulation but lacks detailed guidance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the experiments focus primarily on presenting results, with insufficient analysis of the method itself and the experimental outcomes. It also questions the extent to which the performance improvement can be attributed to the authors\" claim of moving codeswitched pretraining from the word level to the sense level. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues. While it identifies areas for improvement, it lacks concrete actions or details on how to enhance the analysis or attribution of performance improvements. As a result, the authors are left with a general understanding of what needs to be improved but without specific guidance on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the analysis and presentation of results in the experiments, specifically questioning the comprehensiveness of the method analysis and the attribution of performance improvements. However, it does not explicitly mention which sections or experiments are being referred to, making it weakly grounded. The comment is specific in its critique of the method\"s performance and the authors\" claim about moving codeswitched pretraining, but it lacks detailed guidance on how to address these issues. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments focus primarily on presenting results, with insufficient analysis of the method itself and the experimental outcomes. It also questions the extent to which the performance improvement can be attributed to the authors\" claim of moving codeswitched pretraining from the word level to the sense level. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of evidence or detailed justification makes the claim 3, as it requires more information to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the experiments primarily focus on presenting results rather than comprehensively analyzing the method and its outcomes. It questions the extent to which the performance improvement can be attributed to the authors\" claim of moving codeswitched pretraining from the word level to the sense level. This feedback is valuable as it highlights a potential weakness in the paper\"s methodology and analysis, prompting the authors to reconsider their approach and provide more detailed explanations. However, the comment could be more helpful if it offered specific suggestions on how to improve the analysis or provided examples of what a comprehensive analysis might entail. Overall, the comment is 3 as it directs the authors\" attention to an important area for improvement but lacks detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the theoretical results\" lack of immediate practical implications, noting that this is understandable given the novelty of the work. It suggests that the paper should include more takeaway points for practitioners, specifically mentioning the observation that querying a cluster proportionally to the square root of its size. However, the comment does not provide explicit guidance on how to incorporate these takeaway points or whether this observation is indeed novel. The action is implicit and somewhat vague, as the authors are left to infer that they should include more practical implications and clarify the novelty of their findings. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the theoretical results and their practical implications, acknowledging the novelty of the work. It suggests that the paper should include more takeaway points for practitioners, specifically mentioning the observation that querying a cluster proportionally to the square root of its size. However, the comment does not specify which part of the paper discusses these theoretical results or where the authors should include more practical implications. While the authors might infer that it relates to the theoretical sections, the comment lacks full grounding as it does not explicitly mention specific sections or figures. The suggestion is specific in terms of what the authors should consider, but the lack of explicit grounding makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point acknowledges the theoretical nature of the results and their lack of immediate practical implications, noting that this is understandable given the novelty of the work. It suggests that the paper should include more takeaway points for practitioners, specifically mentioning the observation that querying a cluster proportionally to the square root of its size. However, the comment does not provide specific examples or references to support the claim that this observation is novel or lacks practical implications. The reasoning is somewhat logical but lacks detailed evidence or references, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the theoretical nature of the results and their lack of immediate practical implications, which is understandable given the novelty of the work. It suggests that the paper should include more takeaway points for practitioners, specifically mentioning the observation that querying a cluster proportionally to the square root of its size. However, the comment does not provide specific guidance on how to incorporate these takeaway points or how to make them more practical. While it identifies a potential area for improvement, the feedback lacks depth and actionable suggestions, making it 3. The authors gain some insight into the need for more practical implications but are left without detailed guidance on how to achieve this. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the necessity of introducing separators in section 4 and asks for clarification on what additional information they convey beyond T/I/O. While the comment implies that the authors should provide a justification for the introduction of separators, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to explain the purpose of the separators but are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the reason for introducing separators and asks for clarification on what additional information they convey beyond T/I/O. This provides clear guidance on what needs to be addressed in the section. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the necessity of introducing separators in section 4 and asks for clarification on what additional information they convey beyond T/I/O. However, the comment does not provide any reasoning, examples, or references to support why the introduction of separators is questionable. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment questions the rationale behind the introduction of separators in section 4, asking for clarification on what additional information they convey beyond T/I/O. This feedback is 3 as it prompts the authors to provide a justification for the inclusion of separators, which could enhance the clarity and comprehensiveness of their work. However, the comment lacks specific suggestions or guidance on how to address this issue, such as proposing alternative explanations or examples. To be more helpful, the comment could include more detailed feedback or suggestions for improvement. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges the paper\"s interesting idea and extensive experiments, noting that the results are not perfect but show improved performance over the previous stateoftheart. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issues with the synthesized results, such as inconsistent motion, changing color, or objects disappearing over time. Without actionable suggestions or specific feedback, the authors are left without a clear path for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"UCF101\" and \"synthesized results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the synthesized results, such as inconsistent motion, changing color, and objects disappearing over time. The reviewer suggests running the LSTM over longer time steps to address these issues. This provides clear guidance on what needs to be improved. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point acknowledges the paper\"s interesting idea and extensive experiments, noting that the results are not perfect but show improved performance over the previous stateoftheart. It provides specific examples of issues with the synthesized results, such as inconsistent motion, changing color, and objects disappearing over time. However, the comment lacks detailed reasoning or references to support the claim that these issues are significant or require further investigation. While it highlights areas for improvement, the lack of specific evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the paper\"s interesting idea and extensive experiments, noting that the results are not perfect but show improved performance over the previous stateoftheart. It highlights specific issues with the synthesized results, such as inconsistent motion, changing color, and objects disappearing over time. The reviewer suggests running the LSTM over longer time steps to address these issues. However, the comment does not provide detailed guidance on how to improve the results or specific suggestions for addressing the identified problems. While it points out areas for improvement, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the impact of the method on insurance costs for men and women. However, it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this question or what specific information should be included in the paper to answer it. Without any actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the impact of the method on insurance costs for men and women. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the method or results should be considered in relation to insurance costs. Without clear grounding or specificity, the authors cannot effectively address the issue. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification on a specific aspect of the paper, specifically the impact of the method on insurance costs for men and women. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the impact of the method on insurance costs for men and women. While it identifies a potential area of interest, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this question or incorporate it into their paper. The comment does not offer actionable feedback or insights that would help the authors improve their draft. As a result, it is 2, as it points out a potential area of interest but does not provide enough detail or direction for the authors to effectively address it."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the paper\"s methodology, specifically the use of publication years from the ACL anthology to categorize papers. It points out that many papers are available on arXiv much earlier than their publication in the ACL anthology, using the example of the BERT paper. However, the comment does not provide any explicit or implicit action for the authors to take. It does not suggest whether the authors should reconsider their categorization method, adjust their timeline, or provide additional context. Without guidance on how to address this issue, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue with the paper\"s categorization method, specifically the use of publication years from the ACL anthology. It provides a specific example, the BERT paper, which is available on arXiv much earlier than its publication in the ACL anthology. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly points out the issue with the categorization method and provides a concrete example. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper\"s categorization method, based on publication years from the ACL anthology, is problematic because many papers are available on arXiv much earlier. It provides a specific example, the BERT paper, which is available on arXiv from October. This claim is 4 as it is supported by a concrete example and a logical reasoning that many papers are available on arXiv before their publication in the ACL anthology. However, the comment could be strengthened by providing more examples or a broader analysis of the issue. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s categorization method, specifically the use of publication years from the ACL anthology. It points out that many papers are available on arXiv much earlier than their publication in the ACL anthology, using the example of the BERT paper. This feedback is 3 as it highlights a potential weakness in the paper\"s methodology and provides a specific example to illustrate the issue. However, the comment does not offer suggestions on how the authors might address this issue or improve their categorization method. To be more helpful, the comment could include recommendations or guidance on how to account for earlier arXiv versions in the categorization process. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises two main issues. First, it questions the authors\" choice of using a relaxation of rejection sampling instead of directly using Importance sampling. This implies that the authors should provide a justification for their methodological choice. Second, it points out a lack of clarity in Algorithm 1, specifically regarding the difference between QRS and RS. The reviewer suggests that the authors should demonstrate a scenario where these methods behave differently. While the comment implies that the authors should provide additional explanations or examples, it does not explicitly instruct them on how to address these issues. The actions are implicit and somewhat vague, as the authors need to infer what specific information to include. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the algorithm, namely the lack of clarity between QRS and RS and the need to demonstrate a scenario where they behave differently. Therefore, this comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point consists of two parts. The first part questions the authors\" choice of using a relaxation of rejection sampling instead of directly using Importance sampling, suggesting that the authors should provide a justification for their methodological choice. This is a claim that requires the authors to explain their reasoning, making it 3. The second part questions the difference between QRS and RS in Algorithm 1 and suggests that the authors should demonstrate a scenario where these methods behave differently. This is a request for clarification and does not contain a claim, making it a normal statement. Therefore, the overall comment is a mix of a claim and normal statements, with the first part being 3 and the second part being a normal statement. The final label is \"XNo.\"", "helpfulness_rationale": "The review comment raises two distinct issues. First, it questions the authors\" choice of using a relaxation of rejection sampling instead of directly using Importance sampling, suggesting that the authors should provide a justification for their methodological choice. This is a relevant point that could help the authors clarify their approach and potentially improve the paper. Second, the comment points out a lack of clarity in Algorithm 1, specifically regarding the difference between QRS and RS. The reviewer suggests that the authors should demonstrate a scenario where these methods behave differently, which could enhance the understanding of the algorithm. While the comment identifies important areas for improvement, it could be more helpful by providing specific suggestions or examples of how the authors might address these issues. Overall, the feedback is 4 as it directs the authors to clarify their methodological choices and improve the clarity of their algorithmic presentation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the phrase \"nonsequential information such as chunks,\" asking whether \"chunk\" is still considered sequential information. This comment is explicit in its request for clarification, as it directly points out a potential confusion in the text. However, it does not provide guidance on how to address this confusion or suggest ways to clarify the terminology. While the action is explicit, it lacks concrete details on how to implement the clarification, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 285,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly points out a confusion regarding the phrase \"nonsequential information such as chunks\" and asks whether \"chunk\" is still considered sequential information. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the phrase \"nonsequential information such as chunks,\" specifically asking whether \"chunk\" is still considered sequential information. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the phrase \"nonsequential information such as chunks,\" specifically asking whether \"chunk\" is still considered sequential information. This is a clear and specific point that highlights a potential confusion in the text, which could be addressed by the authors to improve the clarity and accuracy of their work. However, the comment does not provide any suggestions or guidance on how to resolve this confusion or clarify the terminology. While it identifies a specific area for improvement, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a perceived lack of technical novelty in the paper, comparing it to two previous works (Xing and Tsang, 2022a, b). It notes that while the previous papers focus on graphbased approaches, the idea, coattention mechanism, and architecture of the current paper are similar. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest ways to differentiate their work. The action is implicit and vague, as the authors are left to infer that they need to demonstrate a unique contribution or differentiate their work from the previous studies. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the issue of limited technical novelty by comparing the current paper with two previous works (Xing and Tsang, 2022a, b). It notes that while the previous papers focus on graphbased approaches, the idea, coattention mechanism, and architecture of the current paper are similar. However, the comment does not specify which sections of the paper these comparisons should be made in, nor does it provide detailed guidance on how the authors might differentiate their work. This lack of specificity and explicit reference to sections makes it difficult for the authors to pinpoint the exact areas needing attention. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the paper lacks technical novelty, comparing it to two previous works (Xing and Tsang, 2022a, b). It notes that while the previous papers focus on graphbased approaches, the idea, coattention mechanism, and architecture of the current paper are similar. However, the comment does not provide specific details or examples to support the claim of limited novelty, nor does it reference the specific aspects of the previous works that are similar. This lack of detailed comparison or evidence makes it difficult for the authors to understand and address the critique. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail and references to fully substantiate it.", "helpfulness_rationale": "The review comment highlights a perceived lack of technical novelty in the paper, comparing it to two previous works (Xing and Tsang, 2022a, b). It notes that while the previous papers focus on graphbased approaches, the idea, coattention mechanism, and architecture of the current paper are similar. However, the comment does not provide specific suggestions or guidance on how the authors might differentiate their work or address the issue of limited novelty. While it identifies a potential weakness, the lack of actionable feedback limits its usefulness to the authors. Therefore, the comment is 3, as it points out an area for improvement but does not offer detailed guidance on how to address it."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about whether the problem discussed in the paper applies to other downstream tasks or is specific to binding affinity prediction. It also asks for an explanation if the problem is specific to binding affinity prediction. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the question or what additional information should be included in the paper. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the applicability of the problem discussed in the paper to other downstream tasks or if it is specific to binding affinity prediction. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment lacks specificity as it does not provide details on what aspect of the problem needs clarification or why it is relevant. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification on whether the problem discussed in the paper applies to other downstream tasks or is specific to binding affinity prediction. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the applicability of the problem discussed in the paper to other downstream tasks or if it is specific to binding affinity prediction. This is a valid point that could lead to a deeper understanding of the paper\"s scope and relevance. However, the comment lacks specificity and does not provide any suggestions or guidance on how the authors might address this question or improve their draft. Without actionable feedback or additional context, the authors are left without a clear path for improvement. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the comparison of computation cost or running time, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on whether the authors should include this comparison, how to conduct it, or what specific aspects to focus on. Without any actionable suggestions or details, the authors are left without a clear understanding of what steps to take in response to this comment. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the comparison of computation cost or running time, but it does not specify which part of the paper this comparison should be included in or what specific aspects need to be addressed. The authors cannot confidently determine which section of the paper this comment pertains to, making it weakly grounded. Additionally, the comment lacks specificity as it does not provide detailed guidance on what aspects of computation cost or running time should be compared or how this comparison should be presented. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point is a question seeking clarification on the comparison of computation cost or running time. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the comparison of computation cost or running time, which is a relevant aspect of the paper. However, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue or what specific comparisons should be made. Without actionable feedback or detailed advice, the authors are left without a clear understanding of how to improve their draft in this area. Therefore, the comment is 2, as it identifies a potential area for improvement but does not offer sufficient guidance to be actionable."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the division of tables into three types in Section 3, specifically questioning whether one type (the column header) should suffice. However, it does not provide any explicit or implicit guidance on how the authors should address this issue or what changes, if any, are needed. The comment lacks actionable details, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3 (line 247252),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the division of tables into three types and suggests that one type (the column header) might suffice. This provides clear guidance on what aspect of the paper needs clarification or revision. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the division of tables into three types, specifically questioning whether one type (the column header) should suffice. However, it does not provide any supporting evidence, reasoning, or examples to justify why the division into three types is unnecessary or why the column header alone should be sufficient. Without additional context or explanation, the claim remains vague and 1, leaving the authors without a clear understanding of the issue or how to address it. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the division of tables into three types in Section 3, specifically questioning whether one type (the column header) should suffice. While it identifies a potential area of confusion or unnecessary complexity, it lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their presentation. The comment is 3 as it prompts the authors to reconsider their table structure, but it does not offer actionable advice or detailed feedback. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the task is closer to Argument Mining rather than Summarization and recommends that the paper should clarify the differences against Argument Mining/Discussion Summarization. While the comment implies that the authors should clarify the task\"s distinction from these related areas, it does not provide specific guidance on how to make these clarifications or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the task is closer to Argument Mining rather than Summarization and recommends clarifying the differences against Argument Mining/Discussion Summarization. However, it does not specify which part of the paper this observation is based on, making it weakly grounded. The comment is specific in its suggestion to clarify the differences, but without explicit references to sections or parts of the paper, the authors may find it challenging to pinpoint where these clarifications are needed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the task is closer to Argument Mining rather than Summarization and recommends clarifying the differences against Argument Mining/Discussion Summarization. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the task is more aligned with Argument Mining. Without such evidence or explanation, the authors may find it challenging to understand and address the suggestion. Therefore, the comment is considered 2, as it provides a general direction but lacks the necessary details for full verification.", "helpfulness_rationale": "The review comment suggests that the task is closer to Argument Mining rather than Summarization and recommends that the paper should clarify the differences against Argument Mining/Discussion Summarization. This feedback is 3 as it identifies a potential misalignment between the task and its categorization, prompting the authors to clarify their work\"s distinction from related areas. However, the comment lacks specific guidance on how to make these clarifications or what aspects to focus on, which limits its usefulness. To be more helpful, the comment could provide examples or suggestions on how to differentiate the task from Argument Mining or Discussion Summarization. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point raises two main concerns: the lack of clarity in the specific definition of the sparsity of the residual term and the need for evidence supporting the sparsity assumption across various noisy cases. It also suggests that the authors should demonstrate the advantages of their assumptions compared to existing methods. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to clarify the definition of sparsity and provide evidence or examples to support the sparsity assumption, but the comment lacks concrete guidance on how to do so. Therefore, the comment is 3, as it highlights areas for improvement but does not provide detailed steps for execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"specific definition of the sparsity of the residual term,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of clarity in the definition and suggests that the authors provide evidence to support the sparsity assumption across various noisy cases. Additionally, it requests a comparison of the proposed method\"s assumptions with existing methods. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point raises a claim about the lack of clarity in the specific definition of the sparsity of the residual term and suggests that the authors provide evidence to support the sparsity assumption across various noisy cases. The comment also implies that the authors should demonstrate the advantages of their assumptions compared to existing methods. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. The absence of concrete evidence or detailed justification makes it difficult for the authors to understand and address the issues effectively. Therefore, the comment is considered 2, as it provides some basis for the claim but requires more detailed support to be 5.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the clarity of the definition of the sparsity of the residual term. It questions whether the residual term includes many zero elements and suggests that the authors provide evidence to support the sparsity assumption across various noisy cases. Additionally, the comment highlights the need to demonstrate the advantages of the proposed method\"s assumptions compared to existing methods. This feedback is clear and actionable, as it directs the authors to clarify their definition and provide evidence or examples to support their claims. However, the comment could be more helpful if it offered specific suggestions on how to demonstrate the advantages or provided examples of existing methods for comparison. Overall, the comment is 4, as it effectively guides the authors toward improving the clarity and justification of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the models and datasets used are too toylike and proposes specific alternatives, such as CIFAR100, ResNet 34 or 50, and ViTtiny or small, to improve the complexity and difficulty of the experiments. It also asks whether there is a foreseeable challenge to experiment on language tasks. While the comment provides explicit suggestions for improvement, it does not specify how the authors should address these suggestions or what specific changes should be made to the experiments. The action is explicit but somewhat vague, as the authors know what needs to be done but may not be entirely clear on how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the models and datasets, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear suggestions for improving the complexity and difficulty of the experiments by recommending specific models and datasets, such as CIFAR100, ResNet 34 or 50, and ViTtiny or small. Additionally, it raises a question about the feasibility of experimenting on language tasks, which further specifies the areas needing attention. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the models and datasets are \"too toylike\" and suggests specific alternatives, such as CIFAR100, ResNet 34 or 50, and ViTtiny or small. The reviewer provides a logical reasoning by stating that CIFAR100 is of similar size to CIFAR10 but more difficult, and that ResNet 34 or 50 would require more compute but could be manageable by the authors\" machines. The suggestion to include ViTtiny or small is also supported by the reasoning that they have similar compute requirements as ResNet 18. However, the comment lacks specific references or examples to fully substantiate the claim about the toylike nature of the current models and datasets. Therefore, the claim is 4, as it provides a logical basis but could be strengthened with more detailed evidence or references.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the models and datasets used are too toylike and proposes alternative, more challenging datasets and models, such as CIFAR100, ResNet 34 or 50, and ViTtiny or small. It also raises a question about the feasibility of experimenting on language tasks, which could be an interesting direction for the authors to explore. The comment is clear and offers concrete suggestions for improvement, making it 5 for the authors to enhance the rigor and relevance of their work. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the absence of a comparison against baselines in the study, specifically noting that the reported accuracy across optimization levels of binaries lacks baseline comparisons. The reviewer suggests that this is a widelyunderstood binary analysis application and that many papers have developed architectureagnostic similarity comparisons or reported them as code search, which is a similar task. While the comment implies that the authors should include baseline comparisons, it does not explicitly instruct them to do so or provide specific guidance on which baselines to consider. The action is implicit and somewhat vague, as the authors need to infer that they should include baseline comparisons and determine which ones are relevant. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"functionality similarity comparison study\" and the \"accuracy across optimization levels of binaries,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of lacking baseline comparisons and references similar work in the field. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a comparison against baselines, specifically noting the absence of baseline comparisons in the functionality similarity comparison study. The reviewer supports this claim by stating that many papers have developed architectureagnostic similarity comparisons or reported them as code search, which is a similar task. This provides a logical reasoning and reference to common practices in the field, making the claim 4. However, the comment could be strengthened by providing specific examples of papers that have included baseline comparisons or by elaborating on the importance of such comparisons in the context of the paper. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of baseline comparisons in the functionality similarity comparison study. It highlights the importance of including baseline comparisons, particularly in a widelyunderstood binary analysis application like this. The comment also references similar work in the field, such as architectureagnostic similarity comparisons or code search, which provides context and suggests that such comparisons are common practice. This feedback is clear and actionable, as it directs the authors to include baseline comparisons to enhance the validity and relevance of their study. However, it could be more helpful if it offered specific suggestions on which baselines to consider or how to implement the comparisons. Overall, the comment is 4, as it effectively guides the authors toward improving their draft by addressing a critical gap in their analysis."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "1", "actionability_rationale": "The review point critiques the contribution of the paper, stating that it addresses the overfitting problem of training GANs with limited data and proposes differentiable augmentation. However, the comment does not provide any explicit or implicit actions for the authors to take to improve their draft. It lacks specific suggestions or guidance on how to enhance the contribution or address the limitations mentioned. As a result, the authors are left without a clear understanding of what steps to take to improve their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the contribution of the paper, specifically addressing the overfitting problem of training GANs with limited data and the proposed differentiable augmentation. However, it does not specify which part of the paper discusses these contributions, making it weakly grounded. The comment is specific in its critique of the contribution, but without clear grounding, the authors may struggle to identify the exact sections that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point critiques the contribution of the paper, stating that it addresses the overfitting problem of training GANs with limited data and proposes differentiable augmentation. The reviewer suggests that while this is an important factor, the contribution is still limited. However, the comment lacks specific examples, detailed reasoning, or references to support the claim that the contribution is insufficient. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment critiques the contribution of the paper, stating that it addresses the overfitting problem of training GANs with limited data and proposes differentiable augmentation. However, the comment does not provide specific feedback or suggestions on how the authors could enhance their contribution or address the limitations mentioned. It lacks actionable guidance or detailed critique, leaving the authors without a clear understanding of what steps to take to improve their work. As a result, the comment is not particularly helpful, as it does not offer meaningful insights or direction for improvement. Therefore, it aligns with a score of 1."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the proof technique in Appendix A, noting that it relies on a special case where a contradiction arises as matrix norms approach infinity. It acknowledges that the authors have already addressed this issue in Section 3, where they mention that normalizing the input makes the results from Theorem 1 inapplicable. However, the comment does not provide any explicit guidance or suggestions on how the authors might address this issue or improve their proof technique. The action is implicit and vague, as the authors are left without clear direction on how to resolve the problem. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix A\" and \"Section 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the proof technique, noting the reliance on a special case where a contradiction arises as matrix norms approach infinity. The comment further specifies that this issue is acknowledged by the authors in Section 3, where they mention that normalizing the input makes the results from Theorem 1 inapplicable. This level of detail provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proof technique in Appendix A relies on a special case where a contradiction arises as matrix norms approach infinity. It acknowledges that the authors have addressed this issue in Section 3, where they mention that normalizing the input makes the results from Theorem 1 inapplicable. The comment provides a logical explanation of the issue and references the authors\" acknowledgment of it, which is a clear and specific justification. However, it could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the proof technique in Appendix A, noting that it relies on a special case where a contradiction arises as matrix norms approach infinity. It acknowledges that the authors have already addressed this issue in Section 3, where they mention that normalizing the input makes the results from Theorem 1 inapplicable. While the comment highlights a potential weakness in the proof technique, it does not provide any suggestions or guidance on how the authors might address this issue or improve their proof. The feedback is 3 as it points out a specific area for improvement, but it lacks actionable advice, making it incomplete. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests replacing \"t\" with the size of T in the histogram intersection kernel for clarity. It implies that allowing \"t\" to be arbitrary does not provide any added value. While the comment explicitly states the action of replacing \"t\" with the size of T, it does not provide detailed guidance on how to implement this change or why it would improve clarity. The action is explicit but somewhat vague, as the authors know what needs to be done but may not fully understand the rationale behind the suggestion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"histogram intersection kernel,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests replacing \"t\" with the size of T for clarity, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests replacing \"t\" with the size of T in the histogram intersection kernel for clarity. The reviewer provides a logical reasoning by stating that allowing \"t\" to be arbitrary does not add value. However, the comment lacks specific examples or references to support why this change would improve clarity or how it would impact the kernel\"s functionality. While the reasoning is clear, the lack of detailed justification or examples makes the claim 3, as the authors may need more context to fully understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the clarity of the paper by recommending a change in notation. It suggests replacing \"t\" with the size of T in the histogram intersection kernel, which could help clarify the meaning and avoid potential confusion. This feedback is clear and actionable, offering a concrete step the authors can take to enhance the readability and understanding of their work. However, the comment could be more helpful if it explained why allowing \"t\" to be arbitrary is problematic or how this change would benefit the paper. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether it is possible to assume a general Gaussian distribution instead of an isotropic Gaussian in the proposed algorithm. It also asks for clarification on the difference between the two distributions. While the comment implies that the authors should consider this assumption, it does not explicitly instruct them to do so or provide guidance on how to address the question. The action is implicit and somewhat vague, as the authors need to infer that they should consider the assumption and provide a response to the question. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the possibility of assuming a general Gaussian distribution instead of an isotropic Gaussian in the proposed algorithm and asks for clarification on the difference between the two distributions. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for clarification on the difference between the distributions, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question seeking clarification on the use of a general Gaussian distribution instead of an isotropic Gaussian in the proposed algorithm. It does not express an opinion, judgment, or suggestion that requires verification. The comment is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the possibility of assuming a general Gaussian distribution instead of an isotropic Gaussian in the proposed algorithm. It also seeks clarification on the difference between the two distributions. While the comment identifies a potential area for improvement or clarification, it lacks depth and does not provide specific guidance or suggestions on how the authors might address this issue. The feedback is 3 as it prompts the authors to consider an alternative assumption, but it does not offer actionable steps or detailed advice on how to proceed. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point questions the intent of Section 5.2, implying that the authors should clarify the purpose of this section. However, it does not provide any guidance on how to address this question or what specific aspects of the section need clarification. The action is implicit and vague, as the authors are left to infer that they need to provide more context or explanation for the section. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment questions the intent of Section 5.2, indicating that the authors should clarify the purpose of this section. However, it does not specify what aspect of the section is unclear or what specific information is missing. This makes it difficult for the authors to pinpoint the exact part of the paper that needs attention. Additionally, the comment lacks specificity regarding what needs to be clarified or improved. As a result, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification about the intent of Section 5.2. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment questions the intent of Section 5.2, indicating that the authors should clarify the purpose of this section. While it identifies a potential area of confusion, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue. The comment does not offer actionable feedback or insights into what aspects of the section need clarification or improvement. As a result, it is 2, as it points out a potential issue but does not assist the authors in resolving it."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the proposed approach, suggesting that it is merely learning a surrogate model for solving linear/linearized systems of equations arising in FEM. It highlights that the approach still requires careful selection of basis functions and meshes and the assembly of stiffness matrices, which is similar to what specialized numerical solvers do. The comment also notes that current operator learning methods are more universal and do not need to be adapted to specific PDEs. However, the comment does not provide explicit guidance or suggestions for the authors to improve their approach or address the critique. It lacks actionable details, such as recommending alternative methods or strategies to enhance the approach. As a result, the authors are left without a clear understanding of how to address the feedback or improve their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the proposed approach, suggesting that it is merely learning a surrogate model for solving linear/linearized systems of equations arising in FEM. It highlights that the approach still requires careful selection of basis functions and meshes and the assembly of stiffness matrices, similar to what specialized numerical solvers do. The comment also notes that current operator learning methods are more universal and do not need to be adapted to specific PDEs. However, the comment does not specify which part of the paper this critique is based on, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might infer that it relates to the methodology or results sections, the lack of explicit grounding makes it challenging to address the feedback effectively. The comment is specific in its critique but 1, aligning with a score of 1.", "verifiability_rationale": "The review point critiques the proposed approach, suggesting that it is merely learning a surrogate model for solving linear/linearized systems of equations arising in FEM. It highlights that the approach still requires careful selection of basis functions and meshes and the assembly of stiffness matrices, similar to what specialized numerical solvers do. The comment also notes that current operator learning methods are more universal and do not need to be adapted to specific PDEs. While the comment provides a logical critique, it lacks specific examples or references to support the claim that current operator learning methods are less accurate than specialized numerical solvers. This makes the claim 3, as it requires more detailed evidence or examples to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the proposed approach, suggesting that it is merely learning a surrogate model for solving linear/linearized systems of equations arising in FEM. It highlights that the approach still requires careful selection of basis functions and meshes and the assembly of stiffness matrices, similar to what specialized numerical solvers do. The comment also notes that current operator learning methods are more universal and do not need to be adapted to specific PDEs. While the comment identifies a potential limitation of the approach, it lacks actionable suggestions or guidance for the authors to address this critique or improve their work. The feedback is 3 as it points out a weakness, but it does not provide specific advice on how to enhance the approach or overcome the limitations. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses confusion about whether the paper targets singletoken or multitoken cloze queries and notes that a clear clarification is not provided until the conclusion. However, it does not offer any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to clarify the target or improve the clarity of the paper. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses confusion about whether the paper targets singletoken or multitoken cloze queries and notes that a clear clarification is not provided until the conclusion. However, it does not specify which part of the paper lacks this clarification, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in identifying the issue of clarity regarding the target of the paper, but it lacks grounding as it does not explicitly mention a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses confusion about whether the paper targets singletoken or multitoken cloze queries and notes that a clear clarification is not provided until the conclusion. However, the comment does not provide any specific reasoning, examples, or references to support this claim. It lacks detailed justification or evidence to substantiate the confusion, making it difficult for the authors to understand the basis of the reviewer\"s concern. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the target of the paper, whether it focuses on singletoken or multitoken cloze queries. It points out that the paper does not provide a clear clarification until the conclusion, which can be confusing for readers. However, the comment does not offer any suggestions or guidance on how the authors might clarify this aspect of their work. Without actionable feedback or specific recommendations, the comment provides limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the difficulty in reproducing the results and asks whether the code will be made publicly available. While the comment implies that the authors should make their code publicly available, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should make their code accessible. However, the comment does provide a clear direction on what needs to be done to address the issue of reproducibility. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the difficulty in reproducing the results and asks whether the code will be made publicly available. However, it does not specify which part of the paper this issue pertains to, such as a specific section or experiment where reproducibility is an issue. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. The comment is specific in its request for code availability, but without clear grounding, it is challenging for the authors to address the issue effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the difficulty in reproducing the results and asks whether the code will be made publicly available. This is a factual statement without any subjective claims or opinions, as it does not express an opinion, judgment, or suggestion. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a concern about the difficulty in reproducing the results, which is an important issue for the authors to address. It also asks whether the code will be made publicly available, which is a relevant question for transparency and reproducibility. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address the issue of reproducibility or make their code available. While it identifies a critical area for improvement, the feedback is somewhat vague and incomplete, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point claims that $kNNECD$ is very similar to $kNNMT$, which limits the technical contribution of the paper. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how the authors might address this issue or improve the paper\"s contribution. As a result, the comment lacks any actionable advice, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment claims that $kNNECD$ is very similar to $kNNMT$, which limits the technical contribution of the paper. However, it does not specify which part of the paper discusses these methods or how the similarity affects the contribution. Without explicit references to sections, tables, or figures, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what aspects of the paper are considered similar or how the similarity impacts the contribution. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that $kNNECD$ is very similar to $kNNMT$, which limits the technical contribution of the paper. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without specific details or comparisons, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that $kNNECD$ is very similar to $kNNMT$, which limits the technical contribution of the paper. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or differentiate their work. Without actionable feedback or constructive advice, the comment lacks depth and does not help the authors improve their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment indicates a lack of clarity regarding the number of parameters used in each approach discussed in Section B.3. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion on whether the authors should clarify the number of parameters, provide additional details, or make any specific changes to improve the clarity of this section. Without actionable advice or concrete steps, the authors are left without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section B.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity regarding the number of parameters used in each approach. This provides clear guidance on what needs to be addressed in the section. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual statement requesting clarification on the number of parameters used in each approach. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The comment identifies a specific area of confusion in the paper, namely the lack of clarity regarding the number of parameters used in each approach discussed in Section B.3. This feedback is 3 as it points out a potential area for improvement, prompting the authors to clarify this aspect of their work. However, the comment lacks depth and does not provide specific suggestions or guidance on how to address this issue, such as recommending a particular way to present the information or suggesting additional details to include. While it highlights a weakness, it does not offer actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a concern about the statistical significance of the evaluation results reported in Table 1, noting that only three trials were conducted for each case. It suggests that this lack of statistical significance may be the reason why the deviations are often reported as zero. The comment also critiques the statement about performance being \"at least two standard deviation better than the next best baseline,\" arguing that this claim is not supported by the data. While the comment identifies a potential issue with the statistical significance of the results and the validity of certain claims, it does not provide explicit guidance on how the authors should address these concerns. The action is implicit and somewhat vague, as the authors are left to infer that they should conduct more trials or provide additional statistical analysis to support their claims. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the evaluation results, noting the lack of statistical significance due to only three trials per case and the resulting zero deviations. The comment further critiques the statement about performance being \"at least two standard deviation better than the next best baseline,\" explaining why this claim is not supported by the data. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the evaluation results in Table 1 are not statistically significant due to only three trials per case, which leads to deviations being reported as zero. The reviewer provides a logical reasoning by explaining that this lack of statistical significance makes statements about performance improvements, such as being \"at least two standard deviation better,\" invalid. This reasoning is clear and logical, providing a solid basis for the claim. However, the comment could be strengthened by including specific examples or references to support the claim further. Overall, the comment is 4, as it provides a logical argument but lacks detailed evidence or references. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the statistical significance of the evaluation results reported in Table 1, noting that only three trials were conducted for each case. It explains that this lack of statistical significance may be the reason why deviations are often reported as zero, which undermines claims about performance improvements. The comment provides a clear and actionable suggestion for improvement by recommending that more trials be conducted to ensure statistical significance. This feedback is valuable as it highlights a critical flaw in the evaluation methodology and offers a specific way to address it, making the comment 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should provide detailed experimental results on Wikipedia regarding the impact of model size on performance, as recent work by Ni et al. has shown that the scaling law applies to dense retrieval models. This feedback is explicit in its request for additional experimental data, but it lacks specific guidance on how to conduct these experiments or what specific metrics to focus on. While the action is clear, the lack of detailed instructions makes it 3.", "grounding_specificity_rationale": "The comment suggests that it is unreasonable for increasing the model size to hurt performance, referencing a recent paper by Ni et al. that shows the scaling law applies to dense retrieval models. However, it does not specify which part of the paper discusses the model size or performance, making it weakly grounded. The comment is specific in its request for detailed experimental results on Wikipedia regarding model size, which provides some guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that it is unreasonable for increasing the model size to hurt performance, referencing a recent paper by Ni et al. that shows the scaling law applies to dense retrieval models. However, the comment does not provide specific details or references from the Ni et al. paper to support the claim, making it difficult for the authors to fully understand and address the issue. The lack of detailed evidence or examples leaves the claim 3, as the authors would need to invest time in identifying and understanding the referenced work to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential contradiction in the paper regarding the impact of model size on performance. It suggests that the scaling law, as demonstrated in a recent paper by Ni et al., should also apply to dense retrieval models, and it questions the validity of the preliminary experimental results on Wikipedia. This feedback is 3 as it points out a specific area of concern that the authors need to address, such as providing more detailed experimental results on the impact of model size. However, the comment could be more helpful if it offered specific suggestions on how to conduct these experiments or what metrics to focus on. Overall, the comment provides a clear direction for improvement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point expresses interest in whether other multilingual pretraining setups also struggle with Greek. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this question or what specific steps to consider. The comment lacks actionable details, leaving the authors uncertain about how to respond or improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses interest in whether other multilingual pretraining setups also struggle with Greek. However, it does not specify which part of the paper this question pertains to, nor does it provide details on what aspect of Greek is problematic or how it relates to the paper\"s content. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine the exact part being addressed. Additionally, the comment lacks specificity regarding what needs to be addressed or improved. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a request for information, asking if other multilingual pretraining setups also struggle with Greek. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a factual question seeking clarification. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The comment expresses interest in whether other multilingual pretraining setups also struggle with Greek. While it raises an intriguing question, it lacks specificity and does not provide any actionable feedback or suggestions for the authors to address this issue. The comment does not offer guidance on how the authors might investigate or resolve this potential problem, leaving the authors without a clear path for improvement. As a result, the comment is 1, as it does not provide any actionable insights or direction for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the scope of the study, suggesting that it only considers one truck and one drone and asks whether it would be easy to extend to multiple trucks and drones. While the comment implies that the authors should consider a more practical setting with multiple trucks and drones, it does not provide explicit guidance on how to achieve this or what specific steps to take. The action is implicit and somewhat vague, as the authors can infer that they should consider a broader scope but are not given concrete instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the scope of the study, specifically mentioning that it only considers one truck and one drone. It suggests that extending the study to multiple trucks and drones would be more interesting and practical. However, the comment does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The comment is specific in its suggestion to consider a broader scope, but without explicit references to sections or parts of the paper, the authors may find it challenging to pinpoint the exact area needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the scope of the study, noting that it only considers one truck and one drone. It suggests that extending the study to multiple trucks and drones would be more interesting and practical. However, the comment lacks specific reasoning or evidence to support why this extension would be beneficial or how it would impact the study. Without additional context or examples, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is classified as 2.", "helpfulness_rationale": "The review comment raises a valid point about the scope of the study, noting that it only considers one truck and one drone. It suggests that extending the study to multiple trucks and drones would be more interesting and practical. This feedback is 3 as it prompts the authors to consider a broader and more realistic setting for their research. However, the comment lacks specific guidance or suggestions on how to achieve this extension or what aspects of the study might benefit from it. While it identifies a potential area for improvement, it does not provide actionable steps or detailed feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with Equation 8, specifically the subtraction of \"s\" from the dynamic information, which could result in the loss of some dynamic information. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or what changes they should make to improve the equation. The comment implies that the LSTM module might not capture the complete dynamic changes, but it lacks concrete details on how to resolve this problem. As a result, the authors are left without clear direction on how to apply the feedback, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equation 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with subtracting \"s\" from the dynamic information, explaining how it might result in the loss of some dynamic information and affect the LSTM module\"s ability to capture complete dynamic changes. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that subtracting \"s\" from the dynamic information in Equation 8 may result in the loss of some dynamic information, making it difficult for the LSTM module to capture complete dynamic changes. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with Equation 8, specifically the subtraction of \"s\" from the dynamic information, which could result in the loss of some dynamic information. It highlights a concern that this might affect the LSTM module\"s ability to capture complete dynamic changes. While the comment points out a specific area of concern, it does not provide detailed guidance or suggestions on how the authors might address this issue or improve the equation. The feedback is 3 as it alerts the authors to a potential problem, but it lacks actionable advice, making it difficult for the authors to fully understand and resolve the issue. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises questions about the impact of the number of Monte Carlo (MC) samples on performance and how the network structure affects this. While it implies that the authors should investigate these aspects, it does not provide explicit instructions or concrete steps on how to conduct these investigations. The authors can infer that they need to explore these relationships, but the comment lacks specific guidance on how to do so. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment raises questions about the impact of the number of Monte Carlo (MC) samples and the network structure on performance. However, it does not specify which part of the paper these questions pertain to, such as specific sections, figures, or tables. This lack of grounding makes it difficult for the authors to identify the exact parts of the paper that need attention. The comment is specific in its inquiry about the effects of MC samples and network structure, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions seeking clarification on the impact of the number of Monte Carlo (MC) samples and the network structure on performance. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and seek information that would help the authors improve their draft. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the impact of the number of Monte Carlo (MC) samples and the network structure on performance. By asking for empirical evidence on how these factors affect performance, the comment prompts the authors to consider and address these aspects in their draft. This feedback is clear and actionable, as it directs the authors to provide additional analysis or experimentation to support their claims. However, the comment could be more helpful if it offered specific suggestions on how to investigate these factors or what metrics to consider. Overall, the comment is 4 as it guides the authors toward improving their draft by highlighting areas that need further exploration."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the metric learning theory in the paper, suggesting that it does not provide better results compared to previous theoretical results. However, it does not offer any specific guidance or suggestions on how the authors might improve their work or address the critique. The comment lacks actionable details, such as recommending alternative approaches or suggesting ways to enhance the metric learning theory. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the metric learning theory in the paper, suggesting that it does not provide better results compared to previous theoretical results. It also mentions that the metric perspective analysis does not seem to work based on the existing content of the paper. However, the comment does not specify which part of the paper discusses the metric learning theory or where the analysis is presented, making it difficult for the authors to pinpoint the exact sections that need attention. While the authors might have an idea of where these topics are discussed, the comment lacks full grounding. It is specific in its critique of the metric learning theory but does not provide detailed guidance on how to address the issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the metric learning theory in the paper does not provide better results compared to previous theoretical results and that the metric perspective analysis does not seem to work. However, the comment lacks specific references or detailed reasoning to support these claims. It does not provide examples or comparisons to previous work, making it difficult for the authors to understand the basis of the critique. Without sufficient evidence or justification, the claim remains 1, as the authors are left without a clear understanding of what needs to be addressed or improved. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment critiques the metric learning theory in the paper, suggesting that it does not provide better results compared to previous theoretical results. It also claims that the metric perspective analysis does not seem to work based on the existing content of the paper. However, the comment lacks specific details or suggestions on how the authors might improve their work or address the critique. It does not provide actionable feedback or guidance on what aspects of the metric learning theory need to be revised or how the analysis could be improved. As a result, the comment is 3, as it identifies a potential issue but does not offer sufficient detail or direction for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a potential confusion in the use of the symbol \"r\" to denote both the risk for minimization problems and the primal risk for minimax problems. However, it does not provide any explicit or implicit guidance on how to address this issue. The authors are left without a clear understanding of what needs to be done to resolve the confusion. Without specific suggestions or instructions, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment identifies a specific issue with the use of the symbol \"r\" to denote both the risk for minimization problems and the primal risk for minimax problems. However, it does not specify which part of the paper this issue occurs in, such as a particular section or equation where this notation is used. Without explicit references to the sections or equations, the authors cannot confidently determine the exact part of the paper being addressed. This makes the comment weakly grounded, as the authors can only make an educated guess about the context. The comment is specific in identifying the issue with the notation, but without grounding, it aligns with a score of 2.", "verifiability_rationale": "The review point claims that using \"r\" to denote both the risk for minimization problems and the primal risk for minimax problems is confusing. However, the comment does not provide any supporting evidence, reasoning, or examples to explain why this notation is problematic or how it could be improved. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a potential source of confusion in the paper, specifically the use of the symbol \"r\" to denote both the risk for minimization problems and the primal risk for minimax problems. This is a clear and specific observation that could help the authors clarify their notation and improve the readability of their work. However, the comment does not provide any suggestions or guidance on how to resolve this issue, such as recommending alternative notations or explaining the potential impact of the confusion. While it highlights a problem, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the necessity of making claims about the desirability of sparsity in training and suggests that any potential benefits, such as improved training speed or reduced FLOPs, need to be demonstrated. While the comment implies that the authors should provide evidence for their claims, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to demonstrate the benefits or what evidence is needed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment questions the need for certain claims regarding sparsity in training and suggests that any potential benefits, such as improved training speed or reduced FLOPs, need to be demonstrated. However, it does not specify which part of the paper these claims are made in, making it weakly grounded. The comment is specific in its critique of the claims and suggests that the authors should provide evidence for their assertions. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the necessity of making claims about the desirability of sparsity in training and suggests that any potential benefits, such as improved training speed or reduced FLOPs, need to be demonstrated. The reviewer provides a logical reasoning by pointing out that in the age of parallelized computation, the reduction in FLOPs may not necessarily lead to cost savings unless it can be shown to impact practical implementations. However, the comment lacks specific examples or references to support the claim that sparsity is not desirable or that the benefits are not evident. This makes the claim 3, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the necessity of certain claims made in the paper regarding the desirability of sparsity in training and suggests that any potential benefits, such as improved training speed or reduced FLOPs, need to be demonstrated. The reviewer provides a logical reasoning by pointing out that in the age of parallelized computation, the reduction in FLOPs may not necessarily lead to cost savings unless it can be shown to impact practical implementations. While the comment identifies a potential weakness in the paper, it lacks specific suggestions or guidance on how the authors might address this issue or provide the necessary evidence. The feedback is 3 as it prompts the authors to consider the validity of their claims and the need for evidence, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the geometry of the vector space used in the morphfitting results and suggests that the authors provide evidence that the space is meaningful. It also implies that the authors should analyze whether the morphfitting results lead to a more meaningful space. While the comment does not explicitly instruct the authors to perform these analyses, it does provide a clear direction for improvement by suggesting what kind of evidence or analysis would be beneficial. The authors can infer that they need to provide evidence or analysis to support the meaningfulness of the vector space. However, the comment lacks specific guidance on how to conduct these analyses, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"geometry of the space\" and \"morphfitting results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for analysis, asking whether the geometry of the space is meaningful and whether specific semantics can be assigned to different inflections. The comment also suggests analyzing whether \"looking\"  \"look\" + \"walk\" = \"walking,\" which is a concrete example of the type of analysis the authors could perform. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the geometry of the vector space used in the morphfitting results, suggesting that the authors provide evidence that the space is meaningful. It also implies that the authors should analyze whether the morphfitting results lead to a more meaningful space. However, the comment lacks specific examples or references to support the claim that the geometry of the space is not meaningful. While it provides a logical reasoning for why such analysis would be beneficial, the absence of concrete evidence or detailed reasoning makes the claim 3. The authors would need to provide additional context or evidence to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises an important question about the geometry of the vector space used in the morphfitting results, suggesting that the authors should provide evidence that the space is meaningful. It also implies that the authors should analyze whether the morphfitting results lead to a more meaningful space, not just better embeddings. This feedback is clear and actionable, as it prompts the authors to consider the significance of their results beyond mere embedding improvements. By suggesting specific examples like \"looking\"  \"look\" + \"walk\" = \"walking,\" the comment provides a concrete direction for analysis that could enhance the paper\"s contribution. However, the comment could be more helpful if it offered additional guidance on how to conduct this analysis or what specific aspects to focus on. Overall, the comment is 4, as it provides valuable insights and a clear path for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that if the authors did not find improvements in FLOPs or inference time, they should consider looking for improvements in accuracy or specific properties. It provides a specific example of how this could be done, such as examining whether the sequential relationship is easier to model with a recurrent model. This feedback is explicit and provides concrete guidance on what the authors should explore, making it 5.", "grounding_specificity_rationale": "The comment suggests that if the authors did not find improvements in FLOPs or inference time, they should consider looking for improvements in accuracy or specific properties. It provides a specific example of examining whether the sequential relationship is easier to model with a recurrent model. However, the comment does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The suggestion is specific in terms of what the authors should explore, but without clear grounding, the authors may struggle to identify the exact section to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that if the authors did not find improvements in FLOPs or inference time, they should consider looking for improvements in accuracy or specific properties. The reviewer provides a specific example of examining whether the sequential relationship is easier to model with a recurrent model. This suggestion is based on logical reasoning and a clear understanding of the paper\"s focus on recurrent models. However, the comment could be strengthened by providing more detailed examples or references to support the claim that accuracy or specific properties might be improved. Therefore, the comment is 4, as it provides a solid basis for the suggestion but lacks comprehensive evidence or references.", "helpfulness_rationale": "The review comment suggests that if the authors did not find improvements in FLOPs or inference time, they should consider looking for improvements in accuracy or specific properties. It provides a specific example of examining whether the sequential relationship is easier to model with a recurrent model. This feedback is actionable and offers a clear direction for the authors to explore, which can help them refine their work. However, the comment could be more helpful if it provided additional guidance on how to measure or evaluate these specific properties or accuracy improvements. Overall, the comment is 4 as it provides a constructive suggestion for further exploration, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that it is unclear how the authors arrived at the different components of the \"scoring function\" and the different threshold values/ranges. While it identifies a lack of clarity, it does not provide explicit guidance on how the authors should address this issue. The action is implicit, as the authors need to infer that they should clarify these aspects, and it is somewhat vague because it does not specify what information should be included or how to present it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper, namely the clarity of the \"scoring function\" and the different threshold values/ranges. However, it does not specify which part of the paper discusses these components, making it weakly grounded. The comment is specific in detailing what is unclear, providing a clear indication of what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that it is unclear how the authors arrived at the different components of the \"scoring function\" and the different threshold values/ranges. However, the comment does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that is unclear, namely the process by which the authors arrived at the different components of the \"scoring function\" and the different threshold values/ranges. This feedback is valuable as it points out a potential gap in the paper that needs clarification. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending additional explanations or examples. While it highlights an area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights specific issues with the model comparison, noting that the chosen datasets are not adequate for a thorough comparison due to the absence of categorical features and the use of onehot encoding. The comment provides a clear and explicit action for the authors to take, which is to expand the dataset selection to include more diverse features and consider using onehot encoding for categorical features. The feedback is concrete and directly guides the authors on how to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the key contribution of the paper, which is the thorough comparison of models on a wide range of datasets. It also specifies the issue with the dataset selection, noting that only one dataset has categorical features, while all others have exclusively numerical features. This is a clear indication of what needs to be addressed. The comment provides specific reasoning about the impact of this omission on the conclusions and suggests a potential issue with onehot encoding for categorical features. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the chosen dataset selection is inadequate for a thorough comparison due to the absence of categorical features and the use of onehot encoding. The reviewer provides a logical reasoning by explaining that categorical features are generally more challenging for deep learning models, which could affect the conclusions. However, the comment lacks specific examples or references to support the claim that the chosen datasets are insufficient. While the reasoning is clear, the lack of detailed evidence or references makes the claim 3, as the authors may need to further substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a detailed critique of the model comparison section, specifically addressing the selection of datasets. It highlights that the chosen datasets are not adequate for a thorough comparison due to the absence of categorical features, which are generally considered more challenging for deep learning models. The comment also points out that the authors do not employ onehot encoding for the dataset with categorical features, which could negatively impact performance for some models. This feedback is clear and actionable, as it identifies specific issues with the dataset selection and suggests ways to improve the model comparison. By addressing these points, the authors can enhance the robustness and validity of their conclusions. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly states that the choice of IoT datasets, FlatCam Face 26 and Headpose detection 11, is unusual and suggests that better options should have been chosen. It provides specific examples of more popular datasets, such as wearable health or mobile activity recognition data, or even sets from UCI. This feedback is clear and actionable, as it directs the authors to consider alternative datasets that might be more relevant and widely used in the field. The authors know exactly what needs to be done to improve their draft by selecting more appropriate datasets for benchmarking. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the choice of the two IoT datasets, FlatCam Face 26 and Headpose detection 11, as unpopular and strange choices. The reviewer provides specific examples of more popular datasets that could have been used, such as wearable health or mobile activity recognition data, or even sets from UCI. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with a score of 5.", "verifiability_rationale": "The review point claims that the choice of IoT datasets, FlatCam Face 26 and Headpose detection 11, is unusual and suggests that better options should have been chosen. The reviewer provides a logical reasoning by stating that the first dataset is relatively recent but not widely followed, while the second is outdated and no longer used. This reasoning is based on common knowledge about the popularity and relevance of datasets in the field. However, the comment could be strengthened by providing specific examples of more popular or relevant datasets that could have been used instead. Overall, the claim is 4, as it provides a logical basis but lacks detailed references or examples to fully substantiate the suggestion. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by questioning the choice of two IoT datasets, FlatCam Face 26 and Headpose detection 11, as unusual and potentially less relevant for benchmarking. The reviewer suggests that more popular or widely used datasets, such as wearable health or mobile activity recognition data, or even sets from UCI, would be better options. This feedback is clear and constructive, offering the authors a specific direction for improving their dataset selection, which is crucial for the validity and relevance of their benchmarking results. By suggesting alternative datasets, the comment empowers the authors to make informed decisions that can enhance the credibility and impact of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy between the authors\" claim and the actual content of the paper. It points out that the regret bound for the proposed minibatch method is claimed to be in the appendix, but the reviewer could not find it in the supplementary material. The comment references an external work by Zalan Borsos, Andreas Krause, and Kfir Y Levy, which could provide a basis for the authors to address the issue. However, the comment does not explicitly instruct the authors to include the regret bound or provide specific guidance on how to address the discrepancy. The action is implicit and somewhat vague, as the authors need to infer that they should either clarify the location of the regret bound or provide it in the supplementary material. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"regret bound for the proposed minibatch method\" and the \"supplementary,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a discrepancy between the authors\" claim and the actual content of the paper, noting that the regret bound for the minibatch estimator is not found in the supplementary material. The comment references an external work by Zalan Borsos, Andreas Krause, and Kfir Y Levy, which provides a basis for the authors to address the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors have stated that the regret bound for the proposed minibatch method is in the appendix, but the reviewer could not find it in the supplementary material. The comment references an external work by Zalan Borsos, Andreas Krause, and Kfir Y Levy, which could provide a basis for the claim. However, the comment does not provide detailed reasoning or specific examples from the referenced work to substantiate the claim, making it 3. The authors would need to investigate the referenced work to fully understand the basis of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a discrepancy between the authors\" claim and the actual content of the paper. It points out that the regret bound for the proposed minibatch method is claimed to be in the appendix, but the reviewer could not find it in the supplementary material. This feedback is valuable as it highlights a potential error or omission in the paper, prompting the authors to verify and correct their claims. However, the comment could be more helpful if it provided specific guidance on how to address the issue, such as suggesting where the regret bound should be included or offering examples of similar approaches. Overall, the comment is 3 as it directs the authors\" attention to a critical area that needs clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific weakness of the proposed method, namely that it performs worse than PQ when a small code length is allowed. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their method. There is no guidance on potential modifications, alternative approaches, or additional experiments that could be conducted to mitigate this weakness. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the proposed compression method, noting that it performs worse than PQ when a small code length is allowed. However, it does not specify which part of the paper discusses this method or where the comparison with PQ is made. Without explicit references to sections, tables, or figures, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what needs to be addressed or improved in this context. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the proposed compression method performs worse than PQ when a small code length is allowed, which is presented as a main weakness of the method. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or data to support the assertion, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific weakness in the proposed compression method, noting that it performs worse than PQ when a small code length is allowed. This is presented as a main weakness of the method, which is relevant information for the authors to consider. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve their method. Without actionable feedback or specific recommendations, the authors are left with a general understanding of the problem but without a clear path to improvement. Therefore, the comment is 3, as it highlights a critical area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the extraction of parts of sentences and documents and the potential impact of extraction rules on the experiment. It explicitly requests a more detailed analysis. While the comment does not provide specific instructions on how to conduct this analysis, it clearly identifies the areas that need further exploration. The authors know that they need to provide a more detailed analysis of the extraction process and its effects on the experiment. Therefore, the comment is 4, as it provides a clear direction for improvement but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment raises questions about the extraction of parts of sentences and documents and the potential impact of extraction rules on the experiment. However, it does not specify which part of the paper these questions pertain to, making it weakly grounded. The comment is specific in its request for a more detailed analysis, which provides some guidance on what the authors should address. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions seeking clarification about the extraction process and its potential impact on the experiment. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the extraction process and its potential impact on the experiment. It specifically asks how the parts of sentences and documents are extracted and whether the extraction rules have any effect on the experiment. This feedback is valuable as it prompts the authors to provide a more detailed analysis of their methodology, which could enhance the clarity and comprehensiveness of their work. However, the comment could be more helpful if it offered suggestions on how to address these questions or provided examples of what a detailed analysis might entail. Overall, the comment is 3 as it identifies areas for improvement but lacks depth and actionable guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to rephrase a section of the paper (lines 107114) as a remark, an aside in the Discussion section, or to remove it entirely. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to address the issue. The comment is specific and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 107114, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies that the content is speculative or overly opinionated and suggests that it should be rephrased as a remark or an aside in the Discussion section or removed. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that lines 107114 are speculative or overly opinionated, suggesting that they should be rephrased as a remark or an aside in the Discussion section or removed. However, the comment does not provide any specific reasoning or examples to support why these lines are considered speculative or overly opinionated. Without detailed justification or evidence, the claim lacks verifiability, making it difficult for the authors to understand and address the issue effectively. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific section of the paper (lines 107114) as being speculative or overly opinionated. It provides a clear and actionable suggestion to rephrase this section as a remark or an aside in the Discussion section or to remove it entirely. This feedback is valuable as it guides the authors on how to improve the clarity and focus of their work by either rephrasing or removing content that may be perceived as subjective or unnecessary. However, the comment could be more helpful if it provided additional context or examples to further clarify the issue. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the choice of using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector, noting that the motivation behind this choice is unclear. While the comment implies that the authors should provide a clearer explanation for their choice, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to clarify their rationale but are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions the choice of using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector, noting that the motivation behind this choice is unclear. However, it does not specify which part of the paper discusses these distributions or where the authors should provide clarification. The authors can infer that it relates to the methodology or results sections, but the comment lacks full grounding as it does not explicitly mention these sections. The comment is specific in questioning the motivation behind the choice of distributions, but it does not provide detailed guidance on how to address this issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the choice of using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector, noting that the motivation behind this choice is unclear. The comment does not provide any supporting evidence, reasoning, or references to justify why this choice is problematic or how it could be improved. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment questions the choice of using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector, noting that the motivation behind this choice is unclear. While it identifies a potential area of confusion or lack of clarity in the paper, it does not provide specific suggestions or guidance on how the authors might address this issue or improve their explanation. The comment highlights a gap in the paper but lacks actionable feedback, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the clarity of the quantitative results, specifically asking how the data is used for training, validation, and testing. While the comment implies that the authors should provide more detailed information on the data used, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the data usage but are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions the clarity of the quantitative results, specifically asking about the data used for training, validation, and testing. However, it does not specify which part of the paper this issue pertains to, such as a particular section or table where these results are presented. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its request for clarification on the data usage, but without clear grounding, it remains 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point questions the clarity of the quantitative results, specifically asking about the data used for training, validation, and testing. This is a factual question seeking clarification, rather than a claim or opinion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a critical question about the clarity of the quantitative results, specifically asking how the data is used for training, validation, and testing. This is an important point that can help the authors improve the transparency and reproducibility of their work. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending the inclusion of additional details or explanations in the paper. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a significant issue but does not fully support the authors in resolving it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to explain why and how their SE framework can help improve, similar to the feedback provided in comment 2. It also suggests that the authors should not just show what they have achieved but should explain the reasoning behind their achievements. This feedback is clear and provides a direct action for the authors to take, which is to provide a detailed explanation of the benefits and mechanisms of their framework. The reference to a similar comment in point 2 further clarifies the action. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: an explanation of how the SE framework helps improve and why it is beneficial. The comment provides a reference to a similar issue in point 2, which further clarifies the expectation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a request for clarification and a suggestion for improvement. It does not contain any subjective claims, opinions, or judgments that require verification. It is purely a request for additional information and guidance, making it a factual statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment provides clear and actionable feedback by asking the authors to explain why and how their SE framework can help improve, similar to the feedback given in comment 2. It emphasizes the importance of not only showing what has been achieved but also explaining the reasoning and methodology behind the achievements. This feedback is specific and constructive, offering the authors a clear direction for improving their draft by providing a more comprehensive explanation of their work. However, the comment could be more helpful if it included suggestions on how to present this explanation or examples of what might be included. Overall, the comment is 4 as it guides the authors toward enhancing the clarity and depth of their manuscript."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the limitation of the approach to only two views, suggesting that the system should be able to generalize to more views without much difficulty. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or improve the generalizability of the system. The comment lacks actionable details, leaving the authors without a clear understanding of what steps to take to enhance their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment questions the limitation of the approach to only two views, suggesting that the system should be able to generalize to more views without much difficulty. However, it does not specify which part of the paper discusses the limitation or how the authors could address this issue. The comment is 1 as it does not refer to a specific section, figure, or table, making it difficult for the authors to pinpoint the exact area needing attention. Additionally, it lacks specificity regarding what aspects of the approach should be improved or how to generalize to more views. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point questions the limitation of the approach to only two views, suggesting that the system should be able to generalize to more views without much difficulty. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this limitation exists or how it could be addressed. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment questions the limitation of the approach to only two views, suggesting that the system should be able to generalize to more views without much difficulty. While it identifies a potential area for improvement, it lacks specificity and does not provide actionable guidance or suggestions on how the authors might address this limitation. The comment is 3 as it points out a possible weakness, but it does not offer detailed feedback or constructive advice on how to enhance the generalizability of the system. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential limitation of the metrics used for evaluating continual learning, specifically the loss after switch and recovery time after switch. It suggests that these metrics might not be applicable in settings where task boundaries are unknown or not clearly defined. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest alternative metrics that could be more suitable. The action is implicit and somewhat vague, as the authors are left to infer that they should consider alternative metrics or adapt their evaluation approach. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the metrics used for evaluating continual learning, specifically mentioning \"loss after switch\" and \"recovery time after switch.\" However, it does not specify which part of the paper discusses these metrics, making it weakly grounded. The comment is specific in detailing the limitations of these metrics in certain settings, such as when task boundaries are unknown or not clearly defined. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the metrics used for evaluating continual learning, such as loss after switch and recovery time after switch, are not applicable in settings where task boundaries are unknown or not clearly defined. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The lack of evidence or detailed justification makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the metrics used for evaluating continual learning, specifically the loss after switch and recovery time after switch. It points out that these metrics may not be applicable in settings where task boundaries are unknown or not clearly defined. This feedback is 3 as it highlights a specific area where the evaluation methodology might be limited, prompting the authors to consider alternative metrics or adapt their approach to better suit different scenarios. However, the comment could be more helpful if it provided suggestions for alternative metrics or ways to address this limitation. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises concerns about the ablation experiments, suggesting that they deserve a better experiment setup. However, it does not provide specific guidance on how to improve the setup or what questions need to be addressed. The comment lacks explicit instructions or concrete suggestions, leaving the authors uncertain about what changes to make. As a result, the action is implicit and vague, making it barely actionable.", "grounding_specificity_rationale": "The comment raises concerns about the ablation experiments, suggesting that they deserve a better experiment setup. However, it does not specify which part of the paper discusses these ablations or what specific questions arise regarding the setup. Without explicit references to sections or examples, the authors cannot confidently determine which part of the paper is being addressed. The comment is vague and lacks specificity, making it difficult for the authors to pinpoint the exact areas needing improvement. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a concern about the ablation experiments, suggesting that they deserve a better experiment setup. However, it does not provide specific details or examples of what aspects of the setup are lacking or how they could be improved. Without concrete evidence or reasoning, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a potential issue with the ablation experiments, suggesting that they deserve a better experiment setup. However, it does not provide specific guidance or suggestions on how to improve the setup or what aspects of the experiments need attention. Without actionable feedback or detailed advice, the authors are left without a clear path to address the issue. This lack of specificity and direction makes the comment 2, as it highlights a concern but does not offer meaningful guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the error analysis on the movie dataset is missing, and it highlights the importance of understanding the cases where the model fails. This provides a clear action for the authors to take: conducting an error analysis on the movie dataset to identify the cases where the model fails. The comment is explicit and provides concrete guidance on what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment addresses the absence of an error analysis on the movie dataset, which is a specific aspect of the paper. However, it does not specify which part of the paper discusses the movie dataset, making it weakly grounded. The comment is specific in its request for an error analysis to understand the model\"s failures, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the error analysis on the movie dataset is missing, which is a critical aspect for other researchers to continue working on the task. The comment highlights the importance of understanding the cases where the model fails, providing a logical reasoning for why this information is necessary. However, it does not provide specific examples or references to support the claim, making it 3. The authors would need to infer the importance of this analysis based on the provided reasoning. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, specifically the absence of an error analysis on the movie dataset. It highlights the importance of understanding the cases where the model fails, which is crucial for other researchers to continue working on the task. This feedback is clear and actionable, as it provides a specific area for improvement that the authors can address to enhance the comprehensiveness and utility of their work. However, the comment could be more helpful if it suggested methods or approaches for conducting the error analysis, which would provide even more guidance. Overall, the comment is 4, as it effectively directs the authors to a critical area needing attention, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a missing part in the approach method, specifically the lack of a separate section or subsection to introduce the inference strategy. It clearly states that the authors should include a part or subsection to explain how to use multiple prompts in the test stage. This feedback provides a direct and concrete action for the authors to take, ensuring they know exactly what needs to be added to their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"approach method,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of a separate part or subsection to introduce the inference strategy, particularly how to use multiple prompts in the test stage. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the approach method lacks a separate part or subsection to introduce the inference strategy, specifically how to use multiple prompts in the test stage. However, the comment does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks clarity, namely the absence of a separate part or subsection to introduce the inference strategy. It highlights the need to explain how multiple prompts are used in the test stage, which is a critical aspect of the approach method. This feedback is clear and actionable, as it provides the authors with a specific area to address and improve their draft. However, it could be more helpful if it offered suggestions on how to structure this section or provided examples of how other papers have introduced similar strategies. Overall, the comment is 4, as it directs the authors to a significant improvement in the clarity and comprehensiveness of their work."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the low results obtained using only ML in the ablation experiments, noting that they are even lower than some simple early methods. It suggests that more explanations are needed. While the comment implies that the authors should provide additional explanations, it does not explicitly instruct them to do so or offer specific guidance on what aspects of the results or explanations should be addressed. The action is implicit and somewhat vague, as the authors can infer that they need to provide more explanations but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the low results obtained using only ML in the ablation experiments, noting that they are even lower than some simple early methods. However, it does not specify which part of the paper this observation is based on, such as a specific section or experiment. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper being addressed. Additionally, while the comment suggests that more explanations are needed, it does not specify what aspects of the results or explanations should be clarified. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a question about the low results obtained using only ML in the ablation experiments, noting that they are even lower than some simple early methods. The reviewer suggests that more explanations are needed. However, the comment lacks specific examples or references to support the claim that the results are lower than expected, making it difficult for the authors to understand the basis of the comparison. Without detailed evidence or reasoning, the claim remains somewhat vague, making it challenging for the authors to address the issue effectively. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment raises a question about the low results obtained using only ML in the ablation experiments, noting that they are even lower than some simple early methods. It suggests that more explanations are needed to understand this observation. While the comment identifies a potential issue, it lacks specific guidance or suggestions on how the authors might address this concern or provide the requested explanations. The feedback is 3 as it points out a potential area for improvement, but it could be more actionable with additional details or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide a more detailed plan on how they plan to address the limitations mentioned in the paper in their future work. While the comment explicitly states that the authors should include a detailed plan, it does not specify what aspects of the limitations should be addressed or how to structure the plan. The action is explicit but lacks concrete guidance on execution, making it 3.", "grounding_specificity_rationale": "The comment suggests that the authors should provide a more detailed plan on how they plan to address the limitations mentioned in the paper. However, it does not specify which limitations or sections of the paper are being referred to, making it difficult for the authors to pinpoint the exact areas that need improvement. The comment is specific in its request for a detailed plan but lacks grounding as it does not identify the specific parts of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide a more detailed plan on how they plan to address the limitations mentioned in the paper. However, it does not provide any specific examples or reasoning to support why the current plan is insufficient or how a more detailed plan would improve the paper. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment acknowledges that the authors have mentioned limitations in their paper but suggests that they should provide a more detailed plan on how they plan to address these drawbacks in their future work. This feedback is 3 as it encourages the authors to be more specific and transparent about their plans for improvement. However, the comment lacks depth and does not provide specific guidance on what aspects of the limitations should be addressed or how to structure the plan. While it points out an area for improvement, it does not offer detailed suggestions or examples, leaving the authors with a general direction but limited actionable steps. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point mentions that similar methods for multitask learning have already been proposed and have not been discussed in the paper. However, it does not provide any explicit or implicit action for the authors to take. There is no guidance on whether the authors should address this issue, discuss the existing methods, or incorporate them into their work. Without any actionable steps or suggestions, the authors are left without a clear understanding of what they should do to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions that similar methods for multitask learning have already been proposed and have not been discussed in the paper. However, it does not specify which part of the paper should address this issue, such as a specific section or discussion. Additionally, it does not provide details on what aspects of these methods should be discussed or how they relate to the current work. Without explicit references or detailed guidance, the authors cannot confidently determine which part of the paper needs attention or how to address the issue. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that similar methods for multitask learning have already been proposed and have not been discussed in the paper. However, it does not provide any references or examples of these existing methods, making it difficult for the authors to verify the claim. Without specific references or detailed explanations, the authors may find it challenging to understand the basis of the claim or how to address it in their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that similar methods for multitask learning have already been proposed and have not been discussed in the paper. However, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue or integrate these existing methods into their work. Without actionable feedback or detailed advice, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises an expectation that the amount of computation for FedMITR is higher than other methods and asks whether this has been compared. While the comment implies that the authors should compare the computation of FedMITR with other methods, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to compare computation but are not given specific guidance on how to conduct the comparison. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the computational complexity of FedMITR compared to other methods, but it does not specify which part of the paper this comparison should be made in. The authors can infer that it relates to the experimental or computational sections, but without explicit references, it is weakly grounded. The comment is specific in its request for a comparison, but it lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point raises a question about the computational complexity of FedMITR compared to other methods, suggesting that it is expected to be higher. However, the comment does not provide any supporting evidence, reasoning, or references to justify this expectation. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the computational complexity of FedMITR compared to other methods, suggesting that it is expected to be higher. While the comment identifies a potential area for comparison, it lacks specificity and does not provide guidance on how to conduct this comparison or what specific aspects should be considered. The feedback is 3 as it prompts the authors to consider a relevant comparison, but it could be more actionable with additional details or suggestions. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the authors can avoid using \"1) and2)\" by using a generic external knowledge base, as demonstrated in Figure 3. However, the comment is vague because it does not specify which parts of the paper should be revised or how to implement the suggestion of using a generic external knowledge base. Additionally, the comment mentions that the writing is confusing, but it does not provide specific guidance on how to clarify it. As a result, the action is implicit and lacks concrete details, making the comment barely actionable.", "grounding_specificity_rationale": "The comment suggests that \"1) and2)\" can be avoided by using a generic external knowledge base, as shown in Figure 3. However, it does not specify which parts of the paper these references are from, making it weakly grounded. The comment also mentions that the writing is confusing, but it does not provide specific details on what is confusing or how to clarify it. This lack of specificity and grounding makes it difficult for the authors to identify and address the issues effectively. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that \"1) and2)\" can be avoided by using a generic external knowledge base, as shown in Figure 3. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. It lacks specific examples or detailed explanations of how using a generic external knowledge base would address the issues mentioned. Without additional context or justification, the claim remains 1, as the authors are left without a clear understanding of the basis for the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that \"1) and2)\" can be avoided by using a generic external knowledge base, as shown in Figure 3. However, the comment lacks specificity and does not provide detailed guidance on how to implement this suggestion or what exactly \"1) and2)\" refer to. Additionally, the comment mentions that the writing is confusing, but it does not offer any specific feedback or suggestions on how to clarify it. This lack of actionable advice and detailed guidance makes the comment 2, as it provides only a general direction without concrete steps for improvement. Therefore, it aligns with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a perceived weakness in the analysis, specifically mentioning the lack of evidence for the existence and smoothness of the solution of SDE (2a)(2d) and any guarantees of the discretization. However, it does not provide explicit guidance on how the authors should address these issues or what specific steps they should take to strengthen their analysis. The comment implies that the authors should provide additional evidence or guarantees, but it lacks concrete instructions on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the provided analysis\" and \"SDE (2a)(2d),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of evidence for the existence and smoothness of the solution of SDE (2a)(2d) and any guarantees of the discretization. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the provided analysis is weak in light of theoretical work on sampling and particlebased optimization methods. It specifically mentions the lack of evidence for the existence and smoothness of the solution of SDE (2a)(2d) and any guarantees of the discretization. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence makes the claim 3, as it requires the authors to infer the specific issues and address them accordingly. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the analysis seems weak, particularly in the context of theoretical work on sampling and particlebased optimization methods. It points out the lack of evidence for the existence and smoothness of the solution of SDE (2a)(2d) and any guarantees of the discretization. This feedback is clear and actionable, as it highlights a critical gap in the paper that the authors need to address to strengthen their analysis. However, the comment could be more helpful if it provided suggestions on how to address these issues or referenced relevant literature that could guide the authors in their improvements. Overall, the comment is 4 as it directs the authors to a specific area needing attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the model has many components with hyperparameters that are not fully provided, suggesting that someone might need to trace them in the source code. While the comment implies that the authors should provide more detailed information about the hyperparameters, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment mentions that the model has many components with hyperparameters that are not fully provided, suggesting that someone might need to trace them in the source code. However, it does not specify which part of the paper this issue pertains to, such as a specific section or figure where these components are discussed. This lack of explicit reference makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing the issue of missing hyperparameter information, but without grounding, it is difficult for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the model has many components with hyperparameters that are not fully provided, suggesting that someone might need to trace them in the source code. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand which components or hyperparameters are missing. Without detailed information or evidence, the claim is not verifiable, as it does not provide sufficient context or justification for the authors to address the issue effectively. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the model has many components with hyperparameters that are not fully provided. This feedback is 3 as it points out a potential weakness in the presentation of the model, which could impact reproducibility and understanding. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending which hyperparameters should be included or how to present them more clearly. While it highlights an area for improvement, the comment could be more helpful with additional details or actionable advice. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include qualitative results, particularly focusing on cases where previous methods failed but the proposed method succeeded. It also recommends showing failure cases and analyzing the limitations. While the comment provides a clear direction for what the authors should do, it does not specify how to present these results or analyze the limitations. The action is explicit but somewhat vague, as it lacks detailed guidance on execution. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including qualitative results, particularly focusing on cases where previous methods failed but the proposed method succeeded. It also recommends showing failure cases and analyzing limitations. However, it does not specify which part of the paper these suggestions should be applied to, making it weakly grounded. The comment is specific in detailing what kind of results and analysis would be beneficial, but without clear references to specific sections, the authors may struggle to identify where these changes should be made. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests including qualitative results, particularly focusing on cases where previous methods failed but the proposed method succeeded. It also recommends showing failure cases and analyzing limitations. However, the comment lacks specific examples or references to support the claim that such results would be beneficial or necessary. Without detailed justification or evidence, the authors may find it challenging to understand the importance of these suggestions. Therefore, the comment is considered 2, as it provides a general idea but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by recommending the inclusion of qualitative results, particularly focusing on cases where previous methods failed but the proposed method succeeded. It also suggests showing failure cases and analyzing limitations, which can help the authors better understand and communicate the strengths and weaknesses of their approach. However, the comment could be more helpful if it offered specific guidance on how to present these results or analyze the limitations. Despite this, the feedback is 4 as it directs the authors toward enhancing the comprehensiveness and clarity of their work. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a missing evaluation of the magnitude of interpretability tax associated with the method. However, it does not provide any explicit or implicit guidance on how the authors should address this issue or what specific aspects of the interpretability tax should be evaluated. Without any suggestions or concrete steps, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue regarding the evaluation of the magnitude of interpretability tax associated with the method. However, it does not specify which part of the paper this evaluation should be included in, nor does it provide details on what aspects of the interpretability tax should be evaluated. This lack of specificity and grounding makes it difficult for the authors to identify the exact part of the paper that needs attention or how to address the issue. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper does not evaluate the magnitude of interpretability tax associated with the method. However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks evaluation, namely the magnitude of interpretability tax associated with the method. This is a valuable observation that could help the authors enhance their work by providing a more comprehensive analysis. However, the comment does not offer any suggestions or guidance on how to evaluate this aspect or what specific metrics or approaches could be used. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the stability of training the deep localization network with the differentiable Sinkhorn method. It suggests that the authors should include training losses to provide evidence of stability. While the comment implies that the authors should include training losses, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to present the training losses or what metrics to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the stability of training the deep localization network with the differentiable Sinkhorn method and suggests including training losses. However, it does not specify which part of the paper this issue pertains to, such as a specific section or experiment where this method is discussed. Without explicit references, the authors may find it challenging to pinpoint the exact part of the paper that needs attention. The comment is specific in its request for training losses but lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point raises a question about the stability of training the deep localization network with the differentiable Sinkhorn method. It suggests that the authors should include training losses to provide evidence of stability. However, the comment does not provide any supporting evidence, reasoning, or references to justify why training losses are necessary or how they would demonstrate stability. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the stability of training the deep localization network with the differentiable Sinkhorn method. It suggests that the authors should include training losses to provide evidence of stability. This feedback is 3 as it identifies a potential area for improvement by suggesting a specific metric that could be included to enhance the paper\"s transparency and robustness. However, the comment lacks depth and does not provide detailed guidance on how to present the training losses or what specific metrics to focus on. While it points the authors in the right direction, it could be more helpful with additional details or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the paper for overclaiming the strength of the proposed BC loss in theoretical analysis. It identifies specific aspects, such as the geometric interpretability, theorem 1, high/low entropy representations, and hardnegative mining ability, that are claimed to be the same thing. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest ways to clarify or revise their claims. The action is implicit and vague, as the authors are left to infer that they need to clarify or revise their claims but are not given specific instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific aspects of the paper, such as the \"theoretical analysis,\" \"geometric interpretability,\" \"theorem 1,\" \"high/low entropy representations,\" and \"hardnegative mining ability.\" This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it details the issue of overclaiming the strength of the proposed BC loss and explains how these aspects are actually the same thing. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper overclaims the strength of the proposed BC loss in theoretical analysis. It provides specific examples, such as the geometric interpretability, theorem 1, high/low entropy representations, and hardnegative mining ability, which are all described as being the same thing. This detailed explanation supports the claim, making it 4. However, the comment could be strengthened by providing additional references or examples to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely that it overclaims the strength of the proposed BC loss in theoretical analysis. It provides detailed examples of what is being overclaimed, such as the geometric interpretability, theorem 1, high/low entropy representations, and hardnegative mining ability, which are all described as being the same thing. This feedback is clear and actionable, as it directs the authors to clarify or revise their claims to avoid overclaiming. However, the comment could be more helpful if it offered suggestions on how to reframe or present these aspects to avoid confusion. Overall, the comment is 4 as it provides valuable insight into a potential weakness in the paper, prompting the authors to make necessary corrections."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the relevance of the proposed method to the authors\" motivations, specifically questioning the effectiveness of automatic scores and the affordability of human evaluation scores. It also suggests that the proposed framework, FFAEVAL, and similar frameworks like Chatbot Arena are not suitable for evaluating a single dialogue system, such as providing fluency scores. The comment implies that arenabased evaluation systems may not address the issues with current scorebased evaluation systems. However, it does not provide explicit guidance or suggestions on how the authors might address these concerns or improve their draft. The action is implicit and somewhat vague, as the authors are left to infer what changes might be necessary without concrete steps or examples. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the relevance of the proposed method to the authors\" motivations, specifically questioning the effectiveness of automatic scores and the affordability of human evaluation scores. It also discusses the limitations of the proposed framework, FFAEVAL, and similar frameworks like Chatbot Arena in evaluating a single dialogue system. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The authors can infer that it relates to the abstract or methodology sections, but this inference is not direct. The comment is specific in detailing the limitations of the proposed method and its relevance to the authors\" motivations, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a claim about the relevance of the proposed method to the authors\" motivations, specifically questioning the effectiveness of automatic scores and the affordability of human evaluation scores. It also suggests that the proposed framework, FFAEVAL, and similar frameworks like Chatbot Arena are not suitable for evaluating a single dialogue system, such as providing fluency scores. The comment provides a logical reasoning by contrasting the arenabased evaluation systems with the current scorebased evaluation systems, suggesting that the former may not address the issues with the latter. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to further explore the reasoning and evidence to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical point about the relevance of the proposed method to the authors\" motivations, specifically questioning the effectiveness of automatic scores and the affordability of human evaluation scores. It also suggests that the proposed framework, FFAEVAL, and similar frameworks like Chatbot Arena are not suitable for evaluating a single dialogue system, such as providing fluency scores. The comment provides a logical reasoning by contrasting arenabased evaluation systems with current scorebased evaluation systems, suggesting that the former may not address the issues with the latter. However, the comment lacks specific suggestions or guidance on how the authors might address these concerns or improve their draft. While it identifies a potential weakness, it does not offer actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the use of focal loss in regression tasks, suggesting that it may not be appropriate due to its focus on class imbalance. The reviewer implies that the authors may have chosen focal loss for a unified form without considering the differences between classification and regression tasks. While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this concern. The action is implicit and somewhat vague, as the authors are left to infer that they should reconsider their choice of loss function and its implications for regression tasks. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the use of focal loss in regression tasks, suggesting that it may not be appropriate due to its focus on class imbalance. The reviewer provides a logical reasoning for why focal loss might not be suitable for regression tasks, particularly in the context of regressing the IoU. However, the comment does not specify which part of the paper discusses the use of focal loss, making it weakly grounded. The authors can infer that it relates to the methodology or experimental sections, but the exact location is not explicitly mentioned. The comment is specific in its critique of the choice of focal loss and its implications for regression tasks, but without explicit grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point raises a question about the use of focal loss in regression tasks, suggesting that it may not be appropriate due to its focus on class imbalance. The reviewer provides a logical reasoning by explaining that focal loss has lower gradients on easy samples, which could be problematic for regressing the IoU. However, the comment lacks specific examples or references to support the claim that focal loss is not suitable for regression tasks. This makes the claim 3, as the authors would need to further explore the reasoning and evidence to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the use of focal loss in regression tasks, suggesting that it may not be appropriate due to its focus on class imbalance. The reviewer provides a logical reasoning by explaining that focal loss has lower gradients on easy samples, which could be problematic for regressing the IoU. The comment also implies that the authors may have chosen focal loss for a unified form without considering the differences between classification and regression tasks. While the comment identifies a potential issue, it lacks specific suggestions or guidance on how the authors might address this concern or explore alternative approaches. The feedback is 3 as it prompts the authors to reconsider their choice of loss function and its implications for regression tasks, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the scalability of the method as the corpus size or hidden dimension size increases. However, it does not provide any explicit or implicit actions for the authors to take. The authors are left without guidance on how to address this question or what specific aspects of scalability need to be considered. Without actionable suggestions or a clear direction for improvement, the comment lacks any concrete steps for the authors to follow. Therefore, it is rated as 1.", "grounding_specificity_rationale": "The comment raises a question about the scalability of the method as the corpus size or hidden dimension size increases. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. Additionally, the comment is specific in its inquiry about scalability but does not provide guidance on how to address this issue. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point is a question seeking clarification about the scalability of the method as the corpus size or hidden dimension size increases. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the scalability of the method as the corpus size or hidden dimension size increases. While it identifies a potential area of concern, it lacks depth and does not provide any suggestions or guidance on how the authors might address this issue. The comment does not offer actionable feedback or insights into how the authors might improve the scalability of their method. As a result, the comment is 2, as it points out a potential weakness but does not assist the authors in making meaningful improvements to their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about whether improvements could be observed with a different encoder, such as RoBERTabase, instead of BERT. However, it does not provide any explicit or implicit action for the authors to take. There is no guidance on whether the authors should test this hypothesis, make changes to their encoder, or address the issue in their discussion. The comment lacks actionable details, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about whether improvements could be observed with a different encoder, such as RoBERTabase, instead of BERT. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what improvements are expected or how the authors might address this issue. Without clear grounding and specificity, the authors are left without a clear understanding of what needs to be revised or improved. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about whether improvements could be observed with a different encoder, such as RoBERTabase, instead of BERT. However, it does not provide any supporting evidence, reasoning, or examples to justify why this change might lead to improvements. The comment lacks specific details or references that would help the authors understand the basis of the suggestion or the potential benefits of using a different encoder. As a result, the claim is 1, as it does not provide sufficient information for the authors to address the issue effectively.", "helpfulness_rationale": "The review comment raises a question about whether improvements could be observed with a different encoder, such as RoBERTabase, instead of BERT. While it identifies a potential area for exploration, it lacks specificity and does not provide actionable guidance or suggestions for the authors. The comment does not offer a clear direction on how to test this hypothesis or what specific improvements might be expected. Without detailed feedback or suggestions, the authors are left without a clear understanding of how to address this issue or what changes might be beneficial. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the paper lacks information about the type of GPUs used and the inference time during testing. This provides a clear and direct action for the authors to take, which is to include this information in their draft. The comment is explicit and provides concrete guidance on what needs to be added, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of information about the type of GPUs used and the inference time during testing. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what is missing: the type of GPUs and inference time during testing. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks information about the type of GPUs used and the inference time during testing. This is a factual statement that does not require verification or justification. It is a request for additional information to be included in the paper, which is a normal statement and not a claim. Therefore, the label is \"No.\"", "helpfulness_rationale": "The review comment identifies a specific omission in the paper, namely the lack of information about the type of GPUs used and the inference time during testing. This is a clear and actionable piece of feedback that can help the authors improve their draft by providing crucial details that could impact the reproducibility and understanding of their results. However, the comment could be more helpful if it suggested where this information should be included or how it might affect the interpretation of the results. Despite this, the feedback is 4 as it directs the authors to a critical area for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a specific issue with the Perceptual Metric in Figure 2, suggesting that the Second Inpainted Images should be connected to the Inpainted Image rather than the Images Masked by Second Masks. This feedback is explicit and provides a clear action for the authors to take, which is to correct the connection in the figure. The comment is also concrete, as it specifies exactly what needs to be changed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the Perceptual Metric, indicating that the Second Inpainted Images should be connected to the Inpainted Image rather than the Images Masked by Second Masks. This provides clear guidance on what needs to be corrected in the figure. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about the connection between the Second Inpainted Images and the Inpainted Image in Figure 2. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the Perceptual Metric in Figure 2, pointing out that the Second Inpainted Images should be connected to the Inpainted Image rather than the Images Masked by Second Masks. This feedback is clear and actionable, providing the authors with a precise direction for correcting an error in their figure. By addressing this issue, the authors can improve the clarity and accuracy of their presentation, which is crucial for the understanding of their results. However, the comment could be more helpful if it included an explanation of why this connection is important or how it affects the interpretation of the results. Overall, the comment is 4 as it directs the authors to a specific improvement that can enhance the quality of their draft."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the potential impact of using an adaptive gradient method instead of SGD on the findings. It suggests that such a method might amplify updates for weights associated with hard features, which could affect the results. However, the comment does not provide explicit guidance or suggestions on how the authors should address this concern or whether they should consider using an adaptive gradient method. The action is implicit and vague, as the authors are left to infer that they should consider the impact of this change but without concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the potential impact of using an adaptive gradient method instead of SGD on the findings. It suggests that such a method might amplify updates for weights associated with hard features, which could affect the results. However, the comment does not specify which part of the paper this concern pertains to, such as a specific section or experiment where the adaptive gradient method is discussed. Additionally, while it provides a potential issue to consider, it lacks specificity in terms of what specific changes or analyses might be needed to address this concern. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a question about the potential impact of using an adaptive gradient method instead of SGD on the findings. It suggests that such a method might amplify updates for weights associated with hard features, which could affect the results. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. The lack of detailed reasoning or specific examples makes it difficult for the authors to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the potential impact of using an adaptive gradient method instead of SGD on the findings. It suggests that such a method might amplify updates for weights associated with hard features, which could affect the results. While the comment identifies a potential area of concern, it lacks specific guidance or suggestions on how the authors might address this issue or whether they should consider using an adaptive gradient method. The feedback is 3 as it prompts the authors to consider a potential impact of their choice of optimization method, but it does not provide actionable steps or detailed advice. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the experiments for being insufficient, specifically mentioning the limited types of teacher architectures and the fact that most compared methods are proposed before 2019. However, it does not provide any explicit or implicit actions for the authors to take to address these issues. There is no guidance on how to expand the experiments, what additional architectures or methods should be included, or how to improve the comparison. Without specific suggestions or instructions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the experiments for being insufficient, specifically mentioning the limited types of teacher architectures and the fact that most compared methods are proposed before 2019. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the issues with the experiments, such as the limited teacher architectures and the outdated methods being compared. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments are insufficient, specifically mentioning the limited types of teacher architectures and the fact that most compared methods are proposed before 2019. However, the comment does not provide any specific examples, references, or detailed reasoning to support these claims. The lack of evidence or detailed justification makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the experiments, noting that they are insufficient due to limited types of teacher architectures and the fact that most compared methods are proposed before 2019. This feedback is 3 as it points out a potential weakness in the experimental setup, prompting the authors to consider expanding their experiments to include more diverse teacher architectures and uptodate methods. However, the comment lacks actionable suggestions or guidance on how to address these issues, such as recommending specific architectures or methods to include. While it provides some insight, the feedback could be more helpful with additional details or concrete actions for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance of the proposed method in pure combinational logic, suggesting that it might be easier to model without staterelated registers. It also suggests a comparison between sequential and combinational designs. While the comment implies that the authors should consider these aspects, it does not explicitly instruct them to conduct the comparison or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore these comparisons. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the performance of the proposed method in pure combinational logic, suggesting that it might be easier to model without staterelated registers. It also suggests a comparison between sequential and combinational designs. However, the comment does not specify which part of the paper this question pertains to, such as a specific section or experiment. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper being addressed. While the comment is specific in suggesting a comparison, it is 1 because it does not clearly indicate where this comparison should be made. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the performance of the proposed method in pure combinational logic, suggesting that it might be easier to model without staterelated registers. It also suggests a comparison between sequential and combinational designs. However, the comment lacks specific evidence, examples, or references to support the claim that the method performs better in combinational logic. Without detailed justification or data, the claim remains somewhat speculative, making it difficult for the authors to fully understand and address the suggestion. Therefore, the comment is classified as 2.", "helpfulness_rationale": "The review comment raises an interesting question about the performance of the proposed method in pure combinational logic, suggesting that it might be easier to model without staterelated registers. It also suggests a comparison between sequential and combinational designs, which could provide valuable insights into the method\"s applicability. However, the comment lacks specificity and does not provide detailed guidance on how to conduct this comparison or what specific aspects to focus on. While it identifies a potential area for exploration, the feedback could be more actionable and helpful by offering more detailed suggestions or examples. Therefore, the comment is 3, as it provides some direction but lacks depth and specificity."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the practicality of the work due to the assumption of known causal relationships between features. It highlights that prior knowledge might not always be available or accurate for specific subpopulations, which is why most researchers focus on mining causal relationships from data automatically. However, the comment does not provide explicit guidance or suggestions on how the authors might address this concern or improve the practicality of their work. The action is implicit and vague, as the authors are left to infer that they should consider the limitations of prior knowledge and explore alternative methods for mining causal relationships. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the practicality of using known causal relationships between features, highlighting that prior knowledge might not always be available or accurate for specific subpopulations. However, it does not specify which part of the paper this critique pertains to, such as a specific section or methodology. The authors can infer that it relates to the discussion of causal relationships, but the lack of explicit grounding makes it difficult to pinpoint the exact part of the paper being addressed. The comment is specific in its critique of the practicality of the work, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point raises a concern about the practicality of the work due to the assumption of known causal relationships between features. It highlights that prior knowledge might not always be available or accurate for specific subpopulations, which is why most researchers focus on mining causal relationships from data automatically. The comment provides a logical reasoning based on common knowledge in the field, suggesting that the assumption of known causal relationships might be limiting in practice. However, it lacks specific examples or references to support the claim fully, making it 3. The authors would need to consider the limitations and potential alternatives discussed to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the practicality of the work, specifically questioning the assumption of known causal relationships between features. It highlights a common issue in realworld applications, where prior knowledge might not always be available or accurate for specific subpopulations. This feedback is relevant and important, as it prompts the authors to consider the limitations of their approach and potentially explore alternative methods for mining causal relationships from data. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address this concern. Overall, the comment is 3 as it identifies a critical area for improvement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include comparative experiments with other nonlinear blocks, such as bottleneck in ResNet or linear bottleneck in MobileNetV2, to showcase the unique advantages or potential shortcomings of their proposed method. While the comment implies that the authors should conduct these experiments, it does not provide specific guidance on how to implement them or what specific comparisons should be made. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by suggesting the inclusion of comparative experiments with other nonlinear blocks, such as bottleneck in ResNet or linear bottleneck in MobileNetV2, to showcase the unique advantages or potential shortcomings of the proposed method. This provides clear guidance on what the authors need to address in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper lacks comparative experiments with other nonlinear blocks, such as bottleneck in ResNet or linear bottleneck in MobileNetV2, to showcase the unique advantages or potential shortcomings of the proposed method. This claim is 3 as it provides a logical reasoning for the need to include such comparisons to better understand the method\"s performance in a broader context. However, the comment lacks specific examples or references to existing works that have conducted similar comparisons, which would strengthen the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the lack of comparative experiments with other nonlinear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2. This feedback is clear and actionable, as it suggests that including such comparisons could showcase the unique advantages or potential shortcomings of the proposed method in a broader context. By highlighting this gap, the comment provides the authors with a concrete direction for enhancing the comprehensiveness and robustness of their experimental evaluation. However, the comment could be more helpful if it offered specific suggestions on which blocks to compare or how to conduct these experiments. Overall, the feedback is 4 as it directs the authors toward a meaningful improvement in their draft."}
