{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the description of HIERENC is unclear and suggests that the input (h_i) to the temporal network is the average of the representations of all instantiations of context filled by every possible entity in the vocabulary. The reviewer questions the validity of this approach, stating that only one of these instantiations is likely to be correct and that this could introduce noise. While the comment identifies a potential issue with the description and suggests a possible reason for concern, it does not provide explicit guidance on how to clarify the description or address the potential noise issue. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the description and potentially explore alternative approaches. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"HIERENC,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by describing the unclear description of HIERENC and providing a detailed explanation of what is unclear. This provides clear guidance on what needs to be clarified or improved in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the description of HIERENC is unclear and suggests that the input (h_i) to the temporal network is the average of the representations of all instantiations of context filled by every possible entity in the vocabulary. The reviewer questions the validity of this approach, stating that only one of these instantiations is likely to be correct and that this could introduce noise. While the comment provides a logical reasoning for the potential issue, it lacks specific examples or references to support the claim fully. The authors would need to further explore and substantiate the reasoning to fully understand and address the concern. Therefore, the comment is 3, as it provides a logical basis but requires additional evidence or examples to be fully convincing.", "helpfulness_rationale": "The review comment identifies a specific issue with the description of HIERENC, suggesting that the input (h_i) to the temporal network is the average of the representations of all instantiations of context filled by every possible entity in the vocabulary. The reviewer questions the validity of this approach, noting that only one of these instantiations is likely to be correct and that this could introduce noise. This feedback is clear and actionable, as it highlights a potential weakness in the methodology and provides a logical reasoning for why it might be problematic. By pointing out this issue, the comment empowers the authors to reconsider their approach and potentially improve the clarity and accuracy of their work. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of alternative approaches. Overall, the comment is 4, as it effectively directs the authors to a critical area that needs attention and improvement."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors conduct an ablation study to evaluate the importance of the postprocessing steps proposed in the paper. While the comment implies that an ablation study is necessary, it does not explicitly instruct the authors to perform it. The suggestion is concrete in terms of what needs to be done, but it lacks explicit guidance on how to conduct the ablation study. Therefore, the comment is 4, as the authors know what action to take but need more detailed guidance on implementation.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"postprocessing steps\" and \"falsepositive neurons,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the paper, which is the lack of an ablation study to evaluate the importance of the postprocessing steps. The comment provides a clear suggestion for improvement, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper does not demonstrate the importance of the postprocessing steps proposed for filtering out \"falsepositive\" neurons. The reviewer suggests that an ablation study may be needed to evaluate this importance. However, the comment lacks specific examples or detailed reasoning to support the claim that the postprocessing steps are crucial or that an ablation study is necessary. The suggestion is 3, as it provides a logical rationale for conducting an ablation study, but it lacks concrete evidence or references to substantiate the claim fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the paper should conduct an ablation study to evaluate the importance of the postprocessing steps proposed for filtering out \"falsepositive\" neurons. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the paper\"s methodology and analysis. By recommending an ablation study, the reviewer offers a direct path for the authors to strengthen their work. However, the comment could be more helpful if it provided additional context or examples of how such an ablation study might be conducted. Overall, the feedback is 4, as it effectively guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about how an antecedent would be identified when the prediction is a pronoun, given the authors\" proposed method of matching the head of noun phrases. It questions the applicability of this method when the head word is not a pronoun. While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this concern. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify or modify their method to handle situations where the head word is not a pronoun. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a specific concern about the identification of antecedents when the prediction is a pronoun, particularly in the context of the authors\" proposed method of matching the head of noun phrases. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the proposed method and how it might not handle situations where the head word is not a pronoun. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the identification of antecedents when the prediction is a pronoun, specifically questioning the applicability of the authors\" proposed method of matching the head of noun phrases. The comment highlights a potential issue with the method\"s limitations, but it does not provide specific examples or detailed reasoning to fully substantiate the claim. While the authors are alerted to a potential weakness, the lack of detailed justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the authors\" proposed method for identifying antecedents, particularly when the prediction is a pronoun. It questions the applicability of the method when the head word is not a pronoun, which is a relevant concern that could impact the accuracy and effectiveness of the approach. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their method. While it highlights a potential weakness, it lacks actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the work is a straightforward extension of existing retrofitting work and recommends adding additional baselines, such as character embeddings. While the comment implies that the authors should include these baselines, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to implement the suggested baselines or what other baselines might be relevant. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the work is a straightforward extension of existing retrofitting work and recommends adding additional baselines, such as character embeddings. However, it does not specify which part of the paper this comment pertains to, making it weakly grounded. The comment is specific in suggesting the addition of character embeddings as baselines, which provides some guidance on what could be improved. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the work is a \"fairly straightforward extension of existing retrofitting work\" and suggests adding additional baselines, such as character embeddings. However, the comment lacks specific examples or references to support the claim that the work is a straightforward extension or to justify the need for additional baselines. Without detailed evidence or reasoning, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is classified as 2.", "helpfulness_rationale": "The review comment points out that the work is a straightforward extension of existing retrofitting work and suggests adding additional baselines, such as character embeddings. While it identifies a potential area for improvement, the comment lacks specificity and does not provide detailed guidance on how to implement these additional baselines or why they would be beneficial. The feedback is 3 as it prompts the authors to consider expanding their work, but it could be more actionable with additional details or examples. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that it is easier to show that something, such as attention in seq2seq MTL, is not working, but the real value lies in understanding why it fails and making changes to the attention mechanism to make it work. However, the comment does not provide explicit guidance on how to identify the specific issues with the attention mechanism or how to make it work. The action is implicit and somewhat vague, as the authors are left to infer the necessary changes without concrete steps or examples. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that it is easier to show that something, such as attention in seq2seq MTL, is not working, but the value lies in understanding why it fails and making changes to the attention mechanism to make it work. However, the comment does not specify which part of the paper discusses attention in seq2seq MTL, making it weakly grounded. It does provide some specificity by suggesting that the authors should focus on understanding why the attention mechanism fails and how to improve it. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it is easier to show that something, such as attention in seq2seq MTL, is not working, but the value lies in understanding why it fails and making changes to the attention mechanism to make it work. The comment provides a logical reasoning by contrasting the ease of showing failure with the importance of understanding the root cause and making improvements. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to infer the specific issues with the attention mechanism and how to address them, which could be challenging without detailed guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, noting that it is easier to show that something, such as attention in seq2seq MTL, is not working, but the real value lies in understanding why it fails and making changes to the attention mechanism to make it work. This feedback highlights a gap in the paper, suggesting that the authors should focus on understanding the root causes of failure and making improvements to the attention mechanism. However, the comment lacks specific guidance or suggestions on how to address this issue, such as proposing potential changes or areas to explore. While it points out a critical area for improvement, the lack of detailed advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies several weaknesses in the paper, specifically related to the experiments. It notes that the experiments are limited to an extremely lowresource regime, which may not be representative of realworld applications, and that sentence classification is an easier task. The reviewer suggests that the proposed augmentation method could be applied to more NLP tasks, but this is not demonstrated in the paper. While the comment highlights areas for improvement, it does not provide explicit or concrete actions for the authors to take. The feedback is 3 as it points out specific issues, but it lacks detailed guidance on how to address them. Therefore, the comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment identifies specific weaknesses in the paper, particularly related to the experiments. It mentions that the experiments are limited to an extremely lowresource regime, which may not be representative of realworld applications, and that sentence classification is an easier task. The reviewer also suggests that the proposed augmentation method could be applied to more NLP tasks, but this is not demonstrated in the paper. However, the comment does not specify which sections of the paper these issues are discussed in, making it weakly grounded. The feedback is specific in detailing the weaknesses and potential improvements, but without explicit references to sections, it is challenging for the authors to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper\"s experiments are weak due to their focus on an extremely lowresource regime and an easier task (sentence classification). The reviewer suggests that the proposed augmentation method could be applied to more NLP tasks, but this is not demonstrated in the paper. The comment provides a logical reasoning by pointing out the limitations of the experiments and suggesting potential improvements. However, it lacks specific examples or references to support the claim that the augmentation method could be applied to other tasks. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies specific weaknesses in the paper, particularly related to the experiments. It points out that the experiments are limited to an extremely lowresource regime, which may not be representative of realworld applications, and that sentence classification is an easier task. The reviewer suggests that the proposed augmentation method could be applied to more NLP tasks, but this is not demonstrated in the paper. While the comment highlights important areas for improvement, it lacks detailed guidance or suggestions on how the authors might address these issues or expand their experiments to include more challenging tasks. The feedback is 3 as it provides insights into the limitations of the current work, but it could be more actionable with specific recommendations or examples. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that several claims in the paper would benefit from more indepth analysis. However, it does not specify which claims are lacking in depth or provide guidance on how to conduct this analysis. The action is implicit and vague, as the authors are left to infer which claims need more analysis and how to perform it. Without concrete details or examples, the authors may struggle to determine the exact steps needed to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that \"a number of claims\" in the paper would benefit from more indepth analysis. However, it does not specify which claims are lacking in depth or provide examples, making it difficult for the authors to identify the exact parts of the paper that need attention. Additionally, the comment lacks grounding as it does not mention specific sections, figures, or tables, making it challenging for the authors to pinpoint the areas needing improvement. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that \"a number of claims\" in the paper would benefit from more indepth analysis. However, it does not specify which claims are lacking in depth or provide examples or reasoning to support this claim. Without specific details or references, the authors may find it challenging to understand which parts of the paper need further analysis. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a potential issue with the paper, suggesting that several claims could benefit from more indepth analysis. However, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue. Without detailed feedback or actionable advice, the authors are left without a clear understanding of what needs to be improved or how to enhance their claims. This makes the comment 2, as it points out a general area for improvement but does not offer meaningful guidance for the authors to act upon."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the paper\"s claim that the model generalizes to different knowledge, specifically questioning the representation of substructure as a sequence of words and the use of constituent parse as knowledge. The reviewer expresses hesitation in calling it \"knowledge\" and suggests that it is misleading, as it is typically used to refer to external knowledge like a knowledge base of entities. While the comment identifies potential issues with the paper\"s terminology and claims, it does not provide explicit guidance or suggestions on how the authors should address these concerns. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the terminology and the nature of the knowledge being referred to. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific claim made in the paper regarding the model\"s generalization to different knowledge. It questions the representation of substructure as a sequence of words and the use of constituent parse as knowledge, suggesting that it may not be straightforward. The reviewer also expresses hesitation in calling it \"knowledge\" and points out that it is typically used to refer to external knowledge, such as a knowledge base of entities. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the sections discussing the model\"s generalization and knowledge representation. The comment is specific in detailing the issue with the terminology and the nature of the knowledge being referred to. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a claim about the paper\"s use of the term \"knowledge\" in relation to the model\"s generalization. The reviewer questions the representation of substructure as a sequence of words and suggests that it may not be straightforward to use constituent parse as knowledge. The comment also expresses hesitation in calling it \"knowledge\" and points out that it is typically used to refer to external knowledge, such as a knowledge base of entities. While the comment provides some reasoning and references common usage of the term \"knowledge,\" it lacks specific examples or detailed justification to fully substantiate the claim. The authors would need to infer the exact nature of the issue and how to address it. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed explanation or examples to be fully substantiated.", "helpfulness_rationale": "The review comment raises a concern about the paper\"s claim that the model generalizes to different knowledge, specifically questioning the representation of substructure as a sequence of words and the use of constituent parse as knowledge. The reviewer expresses hesitation in calling it \"knowledge\" and suggests that it is misleading, as it is typically used to refer to external knowledge like a knowledge base of entities. This feedback is 3 as it identifies a potential issue with the terminology and the nature of the knowledge being referred to. However, it lacks specific suggestions or guidance on how the authors might address this concern or clarify the terminology. To be more helpful, the comment could include recommendations on how to rephrase or clarify the terminology to align with standard usage. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the relatively poor performance of TWSI on nouns, which is expected due to its nature. It also notes that the oracle GAP for PPDBClus is higher than most clustering approaches, which is disconcerting. The reviewer suggests understanding the gap better and points out a contradiction with the claim that the clustering approach is generalizable to all parts of speech. While the comment identifies areas of concern and suggests further exploration, it does not provide explicit instructions or concrete steps for the authors to take. The action is implicit and somewhat vague, as the authors are left to infer that they should investigate the gap and reconcile the contradictory claims. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the performance of TWSI on nouns, which is expected due to its nature, and the fact that the oracle GAP for PPDBClus is higher than most clustering approaches. It also points out a contradiction with the claim that the clustering approach is generalizable to all parts of speech. However, the comment does not specify which sections of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the concerns about performance and the contradiction with the claim, but without explicit references to sections, it is challenging for the authors to pinpoint the exact parts of the paper that need revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the relatively poor performance of TWSI on nouns is disconcerting, given the nature of TWSI and the fact that the oracle GAP for PPDBClus is higher than most clustering approaches. The comment also points out a contradiction with the claim that the clustering approach is generalizable to all parts of speech. While the reviewer provides some reasoning by mentioning the oracle GAP and the expected performance of TWSI, the comment lacks specific examples or detailed analysis to fully substantiate the claim. The reasoning is 3, as it highlights a potential issue but requires more detailed evidence or examples to be fully convincing. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific concern about the performance of TWSI on nouns, which is expected due to its nature. It also points out a contradiction with the claim that the clustering approach is generalizable to all parts of speech, as the performance is not uniform. The comment suggests that the authors should investigate the gap between the oracle GAP for PPDBClus and the performance of TWSI on nouns. While it highlights an important issue and provides a direction for further exploration, the comment could be more helpful by offering specific suggestions on how to address the contradiction or improve the performance. Overall, the feedback is 3 as it points out a potential weakness and encourages the authors to delve deeper into the issue, but it lacks detailed guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the claim \"there is no corresponding set of tools for the reinforcement learning setting\" is false, and it provides references to support this assertion. The comment is clear and direct, leaving no ambiguity about the action required. The authors know exactly what needs to be done, which is to address the false claim by providing a corresponding set of tools or references. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the part of the paper where the claim is made, \"there is no corresponding set of tools for the reinforcement learning setting.\" This allows the authors to accurately identify the section being addressed. The comment is also specific because it clearly specifies that the claim is false and provides references to support this assertion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement \"there is no corresponding set of tools for the reinforcement learning setting\" is false. It provides references to support this claim, which is a clear and explicit form of evidence. This makes the claim 5, as the authors can easily access the references to understand the basis of the claim and address it in their work. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment directly challenges a claim made in the paper, stating that \"there is no corresponding set of tools for the reinforcement learning setting\" is false. It provides references to support this assertion, which is a valuable contribution to the authors. By pointing out this error, the comment helps the authors correct a potential misconception in their work, ensuring the accuracy and validity of their claims. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided additional context on the tools that do exist for reinforcement learning. Overall, the comment is 4 as it identifies a critical error and provides a basis for correction, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises questions about the fairness of comparing the proposed method with other methods and whether the proposed technique promotes existing Class incremental semantic segmentation methods. It also acknowledges that the authors have addressed the limitations and potential negative societal impact of their work. However, the comment does not provide explicit guidance or suggestions on how the authors should address these questions or improve their draft. The actions are implicit and vague, leaving the authors without clear direction on how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises questions about the fairness of comparing the proposed method with other methods and whether the proposed technique promotes existing Class incremental semantic segmentation methods. However, it does not specify which part of the paper these questions pertain to, making it difficult for the authors to identify the exact sections that need attention. The comment also acknowledges that the authors have addressed the limitations and potential negative societal impact of their work, but this does not provide specific guidance on how to improve the paper. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point raises questions about the fairness of comparing the proposed method with other methods and whether the proposed technique promotes existing Class incremental semantic segmentation methods. However, it does not provide any supporting evidence, reasoning, or references to justify these claims. The comment also acknowledges that the authors have addressed the limitations and potential negative societal impact of their work, but this is not a claim that requires verification. Therefore, the comment lacks verifiability, as it does not provide sufficient evidence or reasoning to support the claims made. The authors would need to infer the issues and address them without clear guidance from the review. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises questions about the fairness of comparing the proposed method with other methods and whether the proposed technique promotes existing Class incremental semantic segmentation methods. It also acknowledges that the authors have addressed the limitations and potential negative societal impact of their work. However, the comment lacks specificity and does not provide actionable feedback or suggestions for improvement. It does not offer guidance on how the authors might address the questions raised or how they could enhance their work. As a result, the comment is 2, as it identifies some areas of concern but does not provide enough detail or direction for the authors to make meaningful improvements to their draft. Therefore, it aligns with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that Section 4 is tersely written and suggests that it could have benefitted from a slower development for easier readability. However, it does not provide specific guidance on how to achieve this or what aspects of the section need to be expanded. The action is implicit and somewhat vague, as the authors are left to infer that they should make the section more detailed without concrete suggestions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that the section is tersely written and suggests that it could have benefitted from a slower development for easier readability. This provides clear guidance on what needs to be addressed in the section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Section 4 is tersely written and suggests that it could have benefitted from a slower development for easier readability. However, the comment does not provide any specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the writing style of Section 4, noting that it is tersely written and could benefit from a slower development for easier readability. This feedback is 3 as it points out a potential area for improvement, suggesting that the authors might need to expand or clarify their explanations in that section. However, the comment lacks specific guidance or suggestions on how to achieve this slower development or what aspects of the section could be expanded. While it provides some direction, it does not offer detailed actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the paper lacks a comparison with a highly relevant method, specifically mentioning the use of \"intertask ensemble\" and \"intratask\" ensemble. It also notes that the authors did not include a method or performance comparison. This feedback provides a clear and explicit action for the authors to take, which is to include a comparison with the relevant method and its performance. The comment is specific and provides concrete guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of comparison with a highly relevant method, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the absence of method and performance comparisons, particularly in relation to the use of \"intertask ensemble\" and \"intratask\" ensemble. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a comparison with a highly relevant method, specifically mentioning the use of \"intertask ensemble\" and \"intratask\" ensemble. The reviewer provides a specific reference to another work that proposes a similar approach, which supports the claim. However, the comment could be strengthened by providing more detailed comparisons or examples of how the proposed method differs from the referenced one. Overall, the claim is 4 as it provides a logical basis for the critique but lacks comprehensive evidence or detailed comparisons. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of comparison with a highly relevant method. It specifically mentions the use of \"intertask ensemble\" and \"intratask\" ensemble, which are not included in the paper. This feedback is clear and actionable, as it directs the authors to include a comparison with the relevant method and its performance, which would enhance the paper\"s contribution and relevance. However, the comment could be more helpful if it provided specific suggestions on how to conduct the comparison or what aspects to focus on. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the pipeline style method, which includes two models, does not provide better average results for both XVNLI and MaRVL. Additionally, it notes that the baseline models in the experiments are not well introduced. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to improve the introduction of baseline models or how to enhance the pipeline style method to achieve better results. Without specific suggestions or instructions, the authors are left without a clear understanding of what changes to make. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the performance of the pipeline style method, which includes two models, and the introduction of baseline models in the experiments. However, it does not specify which sections of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact parts that need attention. The comment is specific in its critique of the results and the introduction of baseline models, but it lacks grounding as it does not explicitly mention the sections where these issues are discussed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the pipeline style method, which includes two models, does not provide better average results for both XVNLI and MaRVL. Additionally, it notes that the baseline models in the experiments are not well introduced. However, the comment lacks specific examples, detailed reasoning, or references to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies two main issues with the paper: the performance of the pipeline style method, which includes two models, and the introduction of baseline models in the experiments. It points out that the method does not provide better average results for both XVNLI and MaRVL, which is a critical observation. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how to improve the performance or introduce the baseline models more effectively. Without detailed feedback or recommendations, the authors are left with a general understanding of the issues but without a clear path to address them. Therefore, the comment is 3, as it highlights areas for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the authors for reproducing a wellknown result in the literature regarding left political bias in ChatGPT and LLMs in general. It questions the need for the authors to use a \"coarse\" methodology, such as passing a binary stance classifier over ChatGPT\"s output, to make this observation. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might improve their methodology or what specific changes they should consider. Without actionable suggestions or a clear direction for improvement, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the authors for reproducing a wellknown result in the literature regarding left political bias in ChatGPT and LLMs in general. It questions the need for the authors to use a \"coarse\" methodology, such as passing a binary stance classifier over ChatGPT\"s output, to make this observation. However, the comment does not specify which part of the paper this critique is based on, making it difficult for the authors to identify the exact section that needs attention. Additionally, while it provides some context by mentioning the evolution of language models, it lacks specific details on what aspects of the methodology or results are problematic. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point critiques the authors for reproducing a wellknown result in the literature regarding left political bias in ChatGPT and LLMs in general. It questions the need for the authors to use a \"coarse\" methodology, such as passing a binary stance classifier over ChatGPT\"s output, to make this observation. The comment provides a logical reasoning by referencing the evolution of language models and the consistent observation of biases in these models. However, it lacks specific references or examples to fully substantiate the claim, making it 3. The authors would need to further explore the literature to fully understand the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the authors for reproducing a wellknown result in the literature regarding left political bias in ChatGPT and LLMs in general. It questions the need for the authors to use a \"coarse\" methodology, such as passing a binary stance classifier over ChatGPT\"s output, to make this observation. The comment points out that this observation has been made at each step of the evolution of language models, from word2vec to BERT to ChatGPT, and suggests that the authors should provide a more nuanced or novel approach to their analysis. While the comment identifies a potential weakness in the paper, it lacks specific suggestions or guidance on how the authors might address this issue or improve their methodology. The feedback is 3 as it highlights a concern but does not provide actionable steps for improvement, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights the need for more explanation regarding how a small degree of bias can be obtained from a clear community structure. It references Theorem 1 and 2, which prove that GCL conforms to a clearer community structure, but notes that the relationship with degree bias is not intuitive enough. While the comment identifies a gap in the explanation, it does not provide explicit guidance on how to address this issue or suggest specific steps for improvement. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide a more detailed explanation of the relationship between community structure and degree bias. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 1 and 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the need for more explanation regarding the relationship between a small degree of bias and a clear community structure, as well as the lack of intuitive understanding of the relationship between GCL and degree bias. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the relationship between a small degree of bias and a clear community structure is not intuitive enough, despite Theorem 1 and 2 proving that GCL conforms to a clearer community structure. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed explanation or references leaves the claim 3, as it requires more information to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by suggesting that the relationship between a small degree of bias and a clear community structure needs more explanation. It references Theorem 1 and 2, which prove that GCL conforms to a clearer community structure, but notes that the relationship with degree bias is not intuitive enough. This feedback is clear and actionable, as it directs the authors to provide a more detailed explanation of the relationship between these concepts. However, the comment could be more helpful if it offered specific suggestions on how to enhance the explanation or provided examples of similar approaches in the literature. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a confusion regarding the notation and the explicit split between \"static\" and temporal features, suggesting that more information is needed. It specifically mentions the variables \"S\" and \"Xt\" and implies that the authors should provide additional information to clarify these terms. While the comment identifies the need for clarification, it does not explicitly instruct the authors to add this information or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the notation, but they are not given detailed instructions on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment identifies a specific issue with the notation and the explicit split between \"static\" and temporal features, suggesting that more information is needed. It mentions the variables \"S\" and \"Xt,\" which provides some grounding as the authors can infer that the comment relates to the section where these variables are introduced. However, the comment does not specify which part of the paper this issue occurs in, making it weakly grounded. The comment is specific in detailing what is confusing and what additional information is needed, but it lacks full grounding because it does not explicitly mention the section or figure where this issue arises. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the notation and explicit split between \"static\" and temporal features are confusing, suggesting that more information is needed. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks references to similar works or explanations of why the current notation is problematic. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the notation and the explicit split between \"static\" and temporal features, suggesting that more information is needed to clarify the variables \"S\" and \"Xt.\" This feedback is 3 as it points out a potential area of confusion in the paper, prompting the authors to provide additional explanations or clarifications. However, the comment could be more helpful if it offered suggestions on how to improve the clarity or provided examples of how to present the information more effectively. Overall, the comment is 3 as it directs the authors to address a specific issue, but it lacks depth and actionable guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states that the claim in section 2 about INRs operating on a perdatainstance basis is true but does not consider it an advantage. The reviewer suggests that a model that can only handle a single time series data is almost useless. However, the comment does not provide any actionable advice or suggestions on how the authors might address this issue or improve their draft. It lacks concrete guidance on how to enhance the model or its capabilities. As a result, the authors are left without a clear understanding of what steps to take to improve their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 2\" and a specific claim within that section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim, pointing out that while it is true, it is not considered an advantage due to the limitation of handling only a single time series data. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that a model that can only handle a single time series data is almost useless, but it does not provide any supporting evidence or reasoning to justify this claim. The comment lacks specific examples or references to substantiate why this limitation is problematic or how it affects the model\"s utility. Without additional context or justification, the claim remains 1, as the authors would need more information to understand and address the issue effectively. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific claim in section 2 of the paper regarding the operation of INRs on a perdatainstance basis. It points out that while the claim is true, it is not considered an advantage because a model that can only handle a single time series data is almost useless. This feedback is 3 as it highlights a potential limitation of the model and prompts the authors to consider the implications of this constraint. However, the comment does not provide actionable suggestions or guidance on how the authors might address this issue or improve the model\"s capabilities. To be more helpful, the comment could offer suggestions for enhancing the model\"s flexibility or discuss potential workarounds. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the required condition on the learning rate, specifically its scalability and the unrealistic nature of the condition. The reviewer acknowledges the need for a way to characterize the benefit of large learning rates but questions the practicality of the condition. While the comment identifies an issue, it does not provide explicit guidance on how the authors should address it or suggest alternative approaches. The action is implicit and somewhat vague, as the authors are left to infer that they need to reconsider the condition or find a more practical solution. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the required condition on the learning rate, specifically its scalability and the unrealistic nature of the condition. However, it does not explicitly mention which part of the paper discusses this condition, making it weakly grounded. The comment is specific in detailing the issue with the condition and the need for a more realistic approach. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the required condition on the learning rate (scaling with the number of samples) is not scalable and is not seen in practice. The reviewer provides a logical reasoning by stating that this condition would lead to unreasonably large learning rates when working with largescale datasets. However, the comment lacks specific examples or references to support the claim that this condition is not seen in practice. While the reasoning is sound, the absence of concrete evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the required condition on the learning rate, noting that it is not scalable and is not seen in practice. It highlights the concern that this condition would lead to unreasonably large learning rates when working with largescale datasets. The reviewer acknowledges the need for a way to characterize the benefit of large learning rates but questions the practicality of the current condition. While the comment points out a critical issue, it does not provide specific suggestions or alternatives for addressing this concern. The feedback is 3 as it directs the authors\" attention to a potential weakness in their approach, but it lacks actionable guidance for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should use a more convincing setting for their unlabeled data, similar to the one used in the Adaptive Semisupervised Learning for Crossdomain Sentiment Classification paper by He et al. (2018). The comment explicitly states that the current setting, which uses perfectly balanced unlabeled data from the preprocessed Amazon review dataset, is impractical in realworld applications. It provides a specific reference to a paper that uses a more convincing setting, which gives the authors a clear direction for improvement. The action is explicit and provides concrete guidance on how to implement the suggested change, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"unlabeled data (2000) from the preprocessed Amazon review dataset (Blitzer version),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the label distribution of unlabeled data is impractical in realworld applications and suggests using a more convincing setting as in the Adaptive Semisupervised Learning for Crossdomain Sentiment Classification paper by He et al. (2018). This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the use of perfectly balanced unlabeled data from the preprocessed Amazon review dataset is impractical in realworld applications. It suggests that the authors should use a more convincing setting, as in the Adaptive Semisupervised Learning for Crossdomain Sentiment Classification paper by He et al. (2018), which directly samples unlabeled data from millions of reviews. The comment provides a specific reference to an external work that supports the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced paper to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the use of perfectly balanced unlabeled data from the preprocessed Amazon review dataset, noting that this is impractical in realworld applications. It suggests that the authors should use a more convincing setting, as in the Adaptive Semisupervised Learning for Crossdomain Sentiment Classification paper by He et al. (2018), which directly samples unlabeled data from millions of reviews. This feedback is clear and actionable, providing the authors with a specific reference and a concrete suggestion for improvement. By addressing this issue, the authors can enhance the practicality and relevance of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about sampling from the DPP when the eigenfunctions e_n are inaccessible, as mentioned in Equation (10) on line 130. The reviewer compares this issue to sampling from the leverage score, suggesting that it may not be easier than sampling from the leverage score. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their draft. The action is implicit and vague, as the authors are left to infer that they need to clarify the sampling process or provide additional information, but without concrete steps or examples, the action remains unclear. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq (10) line 130,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the clarity of sampling from the DPP when the eigenfunctions e_n are inaccessible. The comment further compares this issue to sampling from the leverage score, suggesting that it may not be easier than sampling from the leverage score. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of sampling from the DPP when the eigenfunctions e_n are inaccessible, as mentioned in Equation (10) on line 130. The reviewer compares this issue to sampling from the leverage score, suggesting that it may not be easier than sampling from the leverage score. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that sampling from the DPP is more difficult. This makes the claim 3, as the authors would need to further explore the issue to fully understand and address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of sampling from the DPP when the eigenfunctions e_n are inaccessible, as mentioned in Equation (10) on line 130. It compares this issue to sampling from the leverage score, suggesting that it may not be easier than sampling from the leverage score. This feedback is clear and actionable, as it points out a potential area of confusion in the paper and prompts the authors to clarify the sampling process. However, the comment could be more helpful if it provided additional guidance or suggestions on how to address this issue, such as recommending specific methods or examples to clarify the sampling process. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with further guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment expresses skepticism about the experimental results and questions the usefulness of the experiments section. It suggests that the authors should include experiments on the specific settings mentioned in the paper, such as surveillance in museums with thresholded rewards and privacypreserving data collection. While the comment implies that the authors should conduct additional experiments, it does not provide explicit instructions on how to implement these experiments or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional experiments and determine the details themselves. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental results\" and the \"POMDP problem with nonconvex value function,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the lack of experiments on the specific settings mentioned, such as surveillance in museums with thresholded rewards and privacypreserving data collection. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point expresses skepticism about the experimental results, questioning the usefulness of the experiments section. It suggests that the paper should include experiments on specific settings mentioned, such as surveillance in museums with thresholded rewards and privacypreserving data collection. However, the comment lacks specific examples or detailed reasoning to support why these experiments are necessary or how they would improve the paper. The lack of detailed justification makes the claim 3, as the authors would need to infer the importance of these experiments themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a significant concern about the experimental results, questioning their relevance and usefulness. It points out that the paper claims to solve a POMDP problem with nonconvex value functions, yet the examples provided are not directly related to the problem being addressed. The comment suggests that the experiments section should include simulations or experiments on the specific settings mentioned, such as surveillance in museums with thresholded rewards and privacypreserving data collection. This feedback is clear and actionable, as it identifies a specific area for improvement and provides a concrete suggestion for enhancing the paper. However, it could be more helpful if it offered additional guidance on how to conduct these experiments or what specific aspects to focus on. Overall, the comment is 4, as it provides valuable insights and direction for improving the draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the importance of studying the effect of noise accumulation in the context of homomorphic encryption for sequential ensembling. It also mentions a limitation that prevents the use of even single deep neural networks on homomorphically encrypted data. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or conduct the study. The action is implicit and vague, as the authors are left to infer that they should investigate the effect of noise accumulation and its implications for homomorphic encryption. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the limitations of using homomorphic encryption for sequential ensembling, specifically mentioning the issue of noise accumulation. However, it does not specify which part of the paper discusses sequential ensembling or homomorphic encryption, making it weakly grounded. The comment is specific in identifying the issue of noise accumulation and its impact on the use of deep neural networks, but it lacks grounding in the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the limitations of using homomorphic encryption for sequential ensembling prevent the use of even single deep neural networks on homomorphically encrypted data. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific limitation in the use of homomorphic encryption for sequential ensembling, namely the issue of noise accumulation. It highlights the importance of studying this effect and its implications for the use of even single deep neural networks on homomorphically encrypted data. While the comment points out a relevant area for further investigation, it lacks actionable suggestions or guidance on how the authors might address this limitation or conduct the necessary study. The feedback is 3 as it provides insight into a potential area for improvement, but it could be more beneficial with additional direction or specific recommendations. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should use a standard regularization trick to compare the obtained complexity for the proposed method with the previous result in a stronglyconvex concave case. However, it does not provide specific details on which regularization trick should be used or how to implement it. The action is explicit but vague, as the authors are left to infer the exact steps needed to apply the suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests using a standard regularization trick to compare the obtained complexity for the proposed method with the previous result in a stronglyconvex concave case. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. Without explicit references, the authors may find it challenging to determine where to incorporate this suggestion. The comment is specific in its recommendation but lacks grounding, making it 2. Therefore, this comment aligns with a score of 2.", "verifiability_rationale": "The review point suggests using a standard regularization trick to compare the obtained complexity for the proposed method with the previous result in a stronglyconvex concave case. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this approach is necessary or beneficial. Without additional context or explanation, the authors may find it challenging to understand the rationale behind the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests using a standard regularization trick to compare the obtained complexity for the proposed method with the previous result in a stronglyconvex concave case. While it identifies a potential area for improvement, the comment lacks specificity and does not provide detailed guidance on which regularization trick to use or how to implement it. The suggestion is 3 as it points out a possible enhancement, but it could be more actionable with additional details. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should discuss and present their solutions for dealing with different types of inputs, such as biomedical signals or speech. While the comment implies that the authors should address this issue, it does not provide specific guidance on how to structure the discussion or what specific solutions to present. The mention of \"citation\" being \"a bit disordered\" is vague and does not offer actionable advice. Therefore, the comment is 3, as it identifies an area for improvement but lacks concrete details on how to implement the suggested changes.", "grounding_specificity_rationale": "The comment suggests discussing and presenting solutions for dealing with different types of inputs, such as biomedical signals or speech. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in suggesting a discussion on different types of inputs and the need for solutions, but it lacks detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests discussing and presenting solutions for dealing with different types of inputs, such as biomedical signals or speech. However, it does not provide specific examples or detailed reasoning to support why this discussion is necessary or how it would improve the paper. The mention of \"citation\" being \"a bit disordered\" is vague and lacks context, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered 1, as it lacks sufficient evidence or justification to support the claim.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting that the authors discuss and present solutions for dealing with different types of inputs, such as biomedical signals or speech. This feedback is 3 as it points out a gap in the paper that could be addressed to enhance its comprehensiveness. However, the comment lacks specificity and does not provide detailed guidance on how to structure this discussion or what specific solutions to present. Additionally, the mention of \"citation\" being \"a bit disordered\" is vague and does not offer actionable advice. Therefore, the comment is 3, as it provides a direction for improvement but lacks depth and detail."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a significant drop in accuracy scores (from 70.4 to 55.6) after implementing the ICLHAR, which is a method aimed at improving consistency and verifiability. The comment suggests that this issue should be discussed or acknowledged in more detail in the main text. While the action is explicit, it lacks concrete guidance on how to discuss or acknowledge this issue in detail. The authors are given a clear direction to address the problem but may not be entirely sure of the specific steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the ICLHAR, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting the significant drop in accuracy scores (from 70.4 to 55.6 on TRIP) and suggests that this should be discussed or acknowledged in more detail. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the implementation of ICLHAR has significantly impacted the accuracy scores, specifically noting a drop from 70.4 to 55.6 on TRIP. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant drop in accuracy scores (from 70.4 to 55.6) after implementing the ICLHAR, which is a method aimed at improving consistency and verifiability. It suggests that this issue should be discussed or acknowledged in more detail in the main text. This feedback is clear and actionable, as it highlights a potential tradeoff between consistency and accuracy that the authors should address. However, the comment could be more helpful if it provided specific suggestions on how to discuss or acknowledge this issue in the main text. Overall, the comment is 4 as it directs the authors to a critical area that needs further exploration and clarification."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights several writing issues, such as grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not provide specific examples or guidance on how to address these issues. The comment lacks explicit instructions or suggestions for improvement, leaving the authors uncertain about what actions to take. Without concrete details or examples, the authors may struggle to identify and correct the issues effectively. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights writing issues such as grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not specify which parts of the paper these issues are found in, making it difficult for the authors to pinpoint the exact sections that need attention. Additionally, the comment lacks specificity regarding which grammatical errors, mathematical symbols, or unclear sentences are problematic. Without detailed guidance, the authors cannot effectively address the issues. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper contains severe writing issues, such as grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not provide specific examples or detailed evidence to support these claims. Without concrete examples or references to particular sections of the paper, the authors may find it challenging to understand and address the issues effectively. The lack of specific details makes the claim difficult to verify, resulting in a score of 1.", "helpfulness_rationale": "The review comment identifies several writing issues, such as grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not provide specific examples or detailed guidance on how to address these issues. Without concrete suggestions or actionable feedback, the authors are left with a general understanding of the problems but without a clear path to improvement. This lack of specificity and actionable advice makes the comment 2, as it does not effectively guide the authors in enhancing their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the statement in the introduction regarding the biological plausibility of backpropagation, suggesting that it may be too weak. The reviewer provides a counterargument by stating that backpropagation is widely accepted as biologically implausible. However, the comment does not offer any explicit or implicit actions for the authors to take. It lacks guidance on how to address the issue or improve the statement in the introduction. Without specific suggestions or instructions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific statement in the introduction regarding the biological plausibility of backpropagation. It critiques the statement by suggesting that it may be too weak and provides a counterargument that backpropagation is widely accepted as biologically implausible. However, the comment does not specify which part of the introduction this statement is located in, making it weakly grounded. The comment is specific in its critique of the statement but lacks grounding, as the authors cannot confidently determine the exact section being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the statement regarding the biological plausibility of backpropagation is too weak, as it is widely accepted that backpropagation is biologically implausible. The reviewer provides a counterargument by stating that backpropagation is widely accepted as biologically implausible, which is a logical reasoning based on common knowledge. However, the comment could be strengthened by providing specific references or examples to support the claim, which would make it 5. As it stands, the comment is 4, as it provides a logical argument but lacks detailed evidence. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential weakness in the introduction, specifically the statement regarding the biological plausibility of backpropagation. It points out that the current phrasing may be too weak, as backpropagation is widely accepted as biologically implausible. This feedback is clear and actionable, as it prompts the authors to reconsider or revise their statement to reflect the consensus in the field. However, the comment could be more helpful if it provided specific suggestions on how to rephrase the statement or offered additional context on the implications of this issue. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper provides valuable insights for contrastive learning in code search tasks but does not thoroughly explore the implications of the proposed method for other NLP tasks. This limitation is noted as it somewhat restricts the generalizability of the results. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this limitation or expand the exploration to other NLP tasks. Without specific suggestions or instructions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a limitation in the paper, noting that while it provides valuable insights for contrastive learning in code search tasks, it does not thoroughly explore the implications of the proposed method for other NLP tasks. However, it does not specify which part of the paper this limitation pertains to, such as specific sections or experiments that could be expanded. Additionally, the comment lacks specificity in terms of what aspects of other NLP tasks should be explored or how the generalizability could be improved. As a result, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper provides valuable insights for contrastive learning in code search tasks but does not thoroughly explore the implications of the proposed method for other NLP tasks. This limits the generalizability of the results. However, the comment lacks specific examples or references to other NLP tasks that could be explored, making it difficult for the authors to understand the exact scope of the limitation. The claim is 3 as it highlights a potential gap in the paper, but it requires more detailed justification or examples to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the value of the paper\"s insights for contrastive learning in code search tasks but points out a limitation in its generalizability to other NLP tasks. This feedback is 3 as it identifies an area where the paper could be improved by exploring the implications of the proposed method for other NLP tasks. However, the comment lacks specific suggestions or guidance on how the authors might address this limitation or expand their exploration. Without actionable advice, the authors may find it challenging to determine the best course of action to enhance the generalizability of their work. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential issue with the use of the term \"certificate\" in some contexts, suggesting that it might be misinterpreted due to its strong meaning in complexity theory. However, it does not provide explicit guidance on how the authors should address this issue or suggest alternative terminology. The action is implicit, as the authors need to infer that they should reconsider the use of \"certificate\" and potentially replace it with a more appropriate term. Additionally, the comment lacks concrete details on how to implement this change, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 267,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of the term \"certificate,\" explaining that it might be misinterpreted due to its strong meaning in complexity theory. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the use of the term \"certificate\" in some contexts might be misinterpreted due to its strong meaning in complexity theory. However, the comment does not provide any specific examples or references to support this claim, nor does it explain how the term might be misinterpreted or why it is problematic. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of the term \"certificate\" in the paper, suggesting that it might be misinterpreted due to its strong meaning in complexity theory. This is a relevant observation that could help the authors clarify their terminology and ensure that their work is understood correctly by readers. However, the comment lacks specific examples or suggestions on how to address this issue, such as recommending alternative terminology or providing context for the term \"certificate.\" While it points out a potential problem, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is 3, as it provides some insight but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the experiments are limited to toy data and recommends including realworld data to demonstrate the method\"s performance. While the comment implies that the authors should expand their experiments to include realworld data, it does not provide specific guidance on which realworld problems to consider or how to conduct these experiments. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experiments are limited to toy data and recommends including realworld data to demonstrate the method\"s performance. However, it does not specify which part of the paper discusses the experiments or where the authors should include realworld data. The authors might infer that it relates to the experimental section, but this inference is not explicit. The comment is specific in suggesting the inclusion of realworld data, but it lacks grounding as it does not pinpoint a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments are limited to toy data and suggests that the method should be tested on realworld data. However, the comment lacks specific examples or references to realworld problems where barycenters could be used, making it difficult for the authors to understand the scope of the suggestion. The lack of detailed reasoning or examples makes the claim 3, as the authors would need to infer the relevance of the suggestion without clear guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the experiments, noting that they are restricted to toy data. It suggests that the method should be tested on realworld data to demonstrate its applicability and performance in more practical settings. This feedback is clear and actionable, as it provides a specific direction for the authors to expand their experiments and improve the relevance and impact of their work. However, the comment could be more helpful if it offered examples of realworld problems or suggested specific datasets to consider. Overall, the comment is 4, as it guides the authors toward a meaningful enhancement of their study."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the proxlinear subproblem can be reformulated using the conjugate function, making it equivalent to the subproblem in Algorithm 1. The reviewer implies that this reformulation could simplify the solution for the stochastic problem in Eq.(1), thereby clarifying the motivation of Algorithm 1. However, the comment does not explicitly instruct the authors to make this reformulation or provide detailed guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer the need for reformulation and figure out how to execute it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq.(1)\" and \"Algorithm 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the proxlinear subproblem can be reformulated using the conjugate function, which would make the motivation of Algorithm 1 unclear. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proxlinear subproblem can be reformulated using the conjugate function, making it equivalent to the subproblem in Algorithm 1. This claim is 3 as it provides a logical reasoning for the equivalence, suggesting that the reformulation could simplify the solution for the stochastic problem in Eq.(1). However, the comment lacks specific examples or references to support the claim fully, which would strengthen the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the motivation of Algorithm 1, suggesting that the proxlinear subproblem can be reformulated using the conjugate function, making it equivalent to the subproblem in Algorithm 1. This observation could help the authors clarify the rationale behind their algorithm and potentially simplify its implementation. However, the comment does not provide specific guidance on how to make this reformulation or how it would impact the overall structure of the paper. While it highlights an area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges that KD and LS are not identical but suggests that KD can be viewed as a special form of LS under specific conditions. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this observation or how it might impact the paper. Without any actionable steps or suggestions, the authors are left without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment discusses the relationship between KD (Knowledge Distillation) and LS (Label Smoothing), suggesting that KD can be viewed as a special form of LS under specific conditions. However, it does not specify which part of the paper this discussion is based on, making it difficult for the authors to identify the exact section being addressed. The comment is specific in its claim about the equivalence of KD and LS under certain conditions, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that KD (Knowledge Distillation) can be viewed as a special form of LS (Label Smoothing) under specific conditions. The reviewer provides a logical reasoning by stating that when the teacher network is uniformly distributed and the temperature is set at 1, KD and LS are equivalent. This reasoning is based on a clear understanding of the concepts and their relationship, which provides a solid foundation for the claim. However, the comment could be strengthened by providing specific examples or references to support the claim further. Overall, the claim is 4, as it provides a logical basis but lacks detailed evidence or references. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment acknowledges that KD (Knowledge Distillation) and LS (Label Smoothing) are not identical but suggests that KD can be viewed as a special form of LS under specific conditions. The reviewer provides a logical reasoning by stating that when the teacher network is uniformly distributed and the temperature is set at 1, KD and LS are equivalent. This observation could be valuable for the authors, as it offers a deeper understanding of the relationship between these two methods. However, the comment lacks actionable suggestions or guidance on how this insight might impact the paper or its presentation. While it provides some insight, it does not fully support the authors in improving their draft. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point provides explicit actions for the authors to take, suggesting that they make the captions more descriptive and explain the scramble network better. These suggestions are clear and provide concrete guidance on how to improve the draft. The authors know exactly what needs to be done to enhance the clarity and comprehensibility of their work. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the captions\" and \"the figures,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be improved, such as making the captions more descriptive and explaining the scramble network better. This provides clear guidance on how to enhance the clarity and comprehensibility of the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the captions are not descriptive enough and that the authors should explain the scramble network better. However, it does not provide specific examples or detailed reasoning to support these claims. The comment lacks evidence or references to justify why the current captions are insufficient or how the explanation of the scramble network could be improved. Without such support, the authors may find it challenging to understand and address the feedback effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the captions should be more descriptive and that the explanation of the scramble network could be improved. This guidance is clear and offers a direct way for the authors to enhance the clarity and comprehensibility of their work. By addressing these points, the authors can improve the readability and accessibility of their paper, which is crucial for effective communication of their research. However, the comment could be more helpful if it included examples of how to improve the captions or provided more detailed suggestions for explaining the scramble network. Overall, the feedback is 4 as it directs the authors toward specific improvements, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the motivation behind using randomly sampled CIFAR images as backgrounds to make the task harder. It explicitly asks for an explanation of why this particular dimension of difficulty is interesting. This request is clear and direct, providing the authors with a specific action to take: explaining the rationale behind this choice. The feedback is concrete, as it specifies what the authors need to address, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of randomly sampled CIFAR images as backgrounds, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the motivation behind this choice and asks for an explanation of why this particular dimension of difficulty is interesting. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the motivation behind using randomly sampled CIFAR images as backgrounds to make the task harder, suggesting that this choice is not wellmotivated. The comment does not provide any specific reasoning or evidence to support why this particular dimension of difficulty is not interesting, nor does it offer suggestions or examples to clarify the issue. As a result, the claim lacks sufficient justification and is considered 1.", "helpfulness_rationale": "The review comment questions the motivation behind using randomly sampled CIFAR images as backgrounds to make the task harder, suggesting that this choice is not wellmotivated. It asks for an explanation of why this particular dimension of difficulty is interesting, which is a valid point that could help the authors clarify their rationale. However, the comment does not provide specific suggestions or guidance on how to address this issue or improve the paper. While it identifies a potential weakness, it lacks actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It suggests that adding periodicity to the spectral kernel might be enough to allow it to capture all of the results at a similar level to the explicitly compositional model. While the comment implies that the authors should consider this aspect, it does not explicitly instruct them to conduct additional experiments or analyses to address the question. The action is implicit and somewhat vague, as it lacks specific guidance on how to proceed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It references the comparison model, which cannot capture periodic relationships, and the experiments involving periodicity. However, the comment does not specify which sections of the paper these experiments are discussed in, making it weakly grounded. The comment is specific in its inquiry about the impact of adding periodicity to the spectral kernel, but it lacks explicit references to specific sections or experiments. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It suggests that the comparison model, which cannot capture periodic relationships, may not be able to replicate the results seen in the experiments involving periodicity. The comment implies that adding periodicity to the spectral kernel might be sufficient to capture all of these results. However, the claim lacks specific examples or references to support the assertion that periodicity is the primary factor driving the results. The reasoning is somewhat logical but requires more detailed evidence or examples to be 5. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises an interesting question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It points out that the comparison model cannot capture periodic relationships, and in most experiments, the relationships involve periodicity. The comment suggests that adding periodicity to the spectral kernel might be enough to allow it to capture all of these results at a similar level to the explicitly compositional model. This feedback is 3 as it prompts the authors to consider the role of periodicity in their results and potentially explore its impact on the model\"s performance. However, the comment could be more helpful if it provided specific suggestions or examples on how to address this issue. Overall, the feedback is 3, as it offers a direction for further exploration but lacks detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the goal of the paper and the lack of comparison or justification for the proposed method. It suggests that if the claim is to establish the method as a foundation model, the authors should clarify this and demonstrate or justify its future usefulness. While the comment implies that the authors should provide a comparison or justification, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement the suggested changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the goal of the paper and the lack of comparison with existing DAS earthquake detectors, such as PhaseNetDas. It also references a specific citation by the authors, which helps the authors identify the part of the paper being addressed. The comment is specific because it clearly specifies the issue with the paper\"s goal and suggests that the authors should clarify their claim and demonstrate or justify the future usefulness of their method. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the goal of the paper, specifically questioning the lack of comparison with existing DAS earthquake detectors and the need for justification of the proposed method\"s benefits. The reviewer references a specific citation by the authors, which provides some support for the claim. However, the comment could be strengthened by providing more detailed reasoning or examples of how the proposed method differs from existing ones. Overall, the claim is 3, as it highlights a gap in the paper\"s justification but lacks comprehensive evidence or detailed reasoning to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper regarding the goal and justification of the proposed method. It points out that while DAS earthquake detectors exist, the paper does not compare or justify the benefits of the proposed method over existing ones. The comment suggests that if the claim is to establish the method as a foundation model, the authors should clarify this and demonstrate or justify its future usefulness. This feedback is clear and actionable, providing the authors with a specific direction to improve their draft by addressing the lack of comparison and justification. However, it could be more helpful if it offered examples of how to make these comparisons or justifications. Overall, the comment is 4, as it effectively guides the authors toward enhancing the clarity and relevance of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the limitation of using triplets (or a sliding window of length 3) and asks whether this is a fundamental limitation of the approach or if extending to longer subsequences without a sliding window is straightforward. While the comment implies that the authors should consider extending their approach to longer subsequences, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks concrete guidance on how to address the issue or what specific steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the limitation of using triplets (or a sliding window of length 3) and asks whether this is a fundamental limitation of the approach or if extending to longer subsequences without a sliding window is straightforward. However, it does not specify which part of the paper this limitation is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its questioning of the approach\"s limitations but lacks grounding, as it does not reference a particular section or element of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the limitation of using triplets (or a sliding window of length 3) and asks whether this is a fundamental limitation of the approach or if extending to longer subsequences without a sliding window is straightforward. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this limitation is problematic or how it could be addressed. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to respond to it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the limitation of using triplets (or a sliding window of length 3) and asks whether this is a fundamental limitation of the approach or if extending to longer subsequences without a sliding window is straightforward. This is a relevant question that prompts the authors to consider the applicability and limitations of their approach. However, the comment does not provide specific suggestions or guidance on how to address this limitation or extend the approach to longer subsequences. While it identifies a potential area for improvement, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises two issues: the definition of \"sqeuence of episodes\" and the lack of related work. The first issue is addressed explicitly, as the reviewer asks for clarification on the term \"sqeuence of episodes.\" This provides a clear action for the authors to take, which is to clarify the term in their draft. The second issue is also explicit, as the reviewer suggests that related work is missing and that it seems related but does not negate the novelty of the work. This provides a direct action for the authors to include relevant related work. Both issues are clearly stated, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L167,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the definition of \"sqeuence of episodes\" and suggesting that practice and evaluation might be the two types of this sequence. Additionally, the comment points out the absence of related work, which is relevant to the context. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises two claims: the first is about the definition of \"sqeuence of episodes,\" and the second is about the lack of related work. The first claim is 3 as it questions the clarity of the term \"sqeuence of episodes,\" but it lacks specific examples or references to support the need for clarification. The second claim regarding the absence of related work is 4, as it suggests that the work seems related but does not provide detailed reasoning or specific references to support this assertion. Overall, the comment provides some justification but could be strengthened with more detailed evidence or examples. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment raises two important points. First, it questions the definition of \"sqeuence of episodes,\" which is unclear in the context of the paper. This prompts the authors to clarify the term, ensuring that readers understand the concept being discussed. Second, the comment points out the absence of related work, suggesting that it is related but does not negate the novelty of the work. This feedback is valuable as it highlights a potential gap in the literature review and encourages the authors to include relevant work. However, the comment could be more helpful if it provided specific examples of related work or suggested how to integrate it into the paper. Overall, the comment is 4 as it identifies clear areas for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should distinguish the \"allornothing\" or \"cutoff\" phenomenon from the usual statistical bounds that the machine learning and NeurIPS community is familiar with. While the comment implies that the authors should clarify this distinction, it does not provide specific guidance on how to make this distinction or what aspects of the paper need to be revised to achieve this. The action is implicit and somewhat vague, as the authors are left to infer the necessary changes without detailed instructions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should distinguish the \"allornothing\" or \"cutoff\" phenomenon from the usual statistical bounds that the machine learning and NeurIPS community is familiar with. However, it does not specify which part of the paper this distinction should be made in, nor does it provide details on how to make this distinction. Without explicit references to sections or examples, the authors cannot confidently determine where to address this feedback. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the authors should distinguish the \"allornothing\" or \"cutoff\" phenomenon from the usual statistical bounds that the machine learning and NeurIPS community is familiar with. However, the comment does not provide any supporting evidence, reasoning, or references to explain why this distinction is important or how it would benefit the paper. Without additional context or justification, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the authors should distinguish the \"allornothing\" or \"cutoff\" phenomenon from the usual statistical bounds that the machine learning and NeurIPS community is familiar with. While it identifies a potential area for clarification, the comment lacks specificity and does not provide detailed guidance on how to make this distinction or why it is important. The feedback is 3 as it points out a potential area for improvement, but it could be more actionable with additional details or examples. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the linear convergence rates relying on Theorem 8, which is buried at the end of the appendix and has a proof that is not clear enough. While the comment identifies an issue with the clarity of the proof, it does not provide explicit guidance on how to improve it or suggest specific actions for the authors to take. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the proof or relocate it to a more prominent section. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 8,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is the lack of clarity in the proof of Theorem 8, and the fact that it is buried at the end of the appendix. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the linear convergence rates rely on Theorem 8, which is buried at the end of the appendix and has a proof that is not clear enough. However, the comment does not provide any specific reasoning or examples to support why the proof is unclear or how it affects the linear convergence rates. Without detailed justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the linear convergence rates rely on Theorem 8, which is buried at the end of the appendix and has a proof that is not clear enough. This feedback is valuable as it points out a potential weakness in the paper that could impact its clarity and comprehensibility. However, the comment does not provide specific suggestions or guidance on how to improve the clarity of the proof or where it should be relocated within the paper. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the analysis on BRPNAS is somewhat barebones, as it only compares against three basic alternatives and ignores other NAS approaches like supernet or oneshot approaches. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should consider including more NAS approaches in their analysis, but it lacks concrete details on which specific approaches to include or how to integrate them into the analysis. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the analysis on BRPNAS, specifically noting that it is somewhat barebones due to only comparing against three basic alternatives and ignoring other NAS approaches like supernet or oneshot approaches. However, it does not specify which part of the paper this analysis is presented in, such as a specific section or table. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being discussed. The comment is specific in detailing what is missing in the analysis, namely the inclusion of other NAS approaches. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the analysis on BRPNAS is somewhat barebones, as it only compares against three basic alternatives and ignores other NAS approaches like supernet or oneshot approaches. However, the comment does not provide specific examples or references to support this claim, nor does it explain why these other approaches should be included. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2, as it lacks sufficient support to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific weakness in the analysis of BRPNAS, noting that it only compares against three basic alternatives and ignores other NAS approaches like supernet or oneshot approaches. This feedback is 3 as it points out a gap in the analysis that could be addressed to provide a more comprehensive evaluation. However, the comment lacks specific suggestions or guidance on how the authors might expand their analysis to include these other approaches, which would make it more actionable. To be fully helpful, the comment could suggest which specific NAS approaches should be considered or how to integrate them into the analysis. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the experiment results could be enriched by including attacks with different strengths and by exploring how different thresholds influence detection performance. However, it does not provide explicit instructions on how to implement these suggestions, such as which attacks to consider or how to analyze the impact of different thresholds. The action is implicit and somewhat vague, as the authors can infer that they need to expand their experiments, but they are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experiment results could be enriched by including attacks with different strengths and by exploring how different thresholds influence detection performance. However, it does not specify which part of the paper this feedback pertains to, such as a specific section or experiment, making it weakly grounded. The comment is specific in its suggestion to include different attacks and explore threshold impacts, but without clear grounding, the authors may struggle to identify the exact areas needing improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the experiment results could be enriched by including attacks with different strengths and exploring how different thresholds influence detection performance. However, the comment lacks specific examples or references to support the claim that the current results are insufficient or that different attacks or thresholds are necessary. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient support for the authors to make meaningful improvements.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the experimental results, suggesting that the current setup lacks attacks with different strengths and does not explore how different thresholds influence detection performance. This feedback is clear and actionable, as it provides a direction for the authors to enhance their experimental design by considering a broader range of attack scenarios and threshold variations. However, the comment could be more helpful if it offered specific suggestions on which attacks or thresholds to consider or how to analyze the impact of these variations. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their experimental results."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the applicability of the proposed method to natural images, such as CIFAR10, which are more relevant to realworld applications. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should test the method on CIFAR10, modify the method to accommodate natural images, or address the issue in the paper. The comment lacks actionable advice, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the applicability of the proposed method to natural images, such as CIFAR10, which are more relevant to realworld applications. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its inquiry about the method\"s applicability to natural images, but it lacks grounding as it does not reference any particular section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the applicability of the proposed method to natural images, such as CIFAR10, which are more relevant to realworld applications. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the method might not work on natural images. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the applicability of the proposed method to natural images, such as CIFAR10, which are more relevant to realworld applications. This is a valuable observation that prompts the authors to consider the broader applicability of their method beyond digit or text images. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or expand their method to accommodate natural images. While it identifies a potential limitation, it does not provide actionable feedback for improvement. Therefore, the comment is 3, as it highlights an area for consideration but does not fully support the authors in making improvements."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the prompts in Table 6 and 7 are not wellorganized, with all sentences squeezed together. However, it does not provide any explicit or implicit suggestions on how the authors might improve the organization or formatting of the prompts. Without guidance on what specific changes could be made or how to address the issue, the authors are left without a clear path forward. The comment lacks actionable advice, leaving the authors without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 6 and 7,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by noting that the prompts are not wellorganized, with all sentences squeezed together. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the prompts in Table 6 and 7 are not wellorganized, with all sentences squeezed together. However, the comment does not provide any specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 2, as it lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the organization of prompts in Tables 6 and 7, noting that all sentences are squeezed together. This feedback is 3 as it points out a potential area for improvement in the presentation of the prompts. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending a more structured or visually appealing layout. While it highlights a problem, it does not offer actionable advice, making it 3 but incomplete."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies issues with the clarity of the figures, specifically mentioning confusion in Figure 2 regarding the relationship between the subfigures and the lack of labels for modules like CMAF, L_BT, and VoLTA. This feedback provides clear and actionable guidance for the authors to improve the clarity of their figures by ensuring proper labeling and relationships are evident. The comment is explicit and provides concrete details on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the figures, such as the confusion in the relationship between subfigures and the lack of labels for specific modules. This provides clear guidance on what needs to be addressed to improve the clarity of the figures. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the figures are not clear, specifically mentioning confusion in Figure 2 regarding the relationship between subfigures and the lack of labels for modules like CMAF, L_BT, and VoLTA. This claim is 3 as it provides specific examples of what is unclear in the figures, allowing the authors to understand the issue and potentially address it. However, the comment lacks detailed reasoning or references to support why these specific issues impact the clarity of the figures. Providing more context or examples would strengthen the verifiability of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies specific issues with the clarity of the figures, particularly in Figure 2, where the relationship between subfigures is confusing and some modules are not labeled. This feedback is clear and actionable, as it provides the authors with concrete areas to address in order to improve the clarity and readability of their figures. By specifying the modules that are not labeled, the comment offers a direct path for the authors to enhance the comprehensibility of their work. However, the comment could be more helpful if it included suggestions on how to improve the labeling or provided examples of best practices for figure clarity. Overall, the comment is 4 as it effectively guides the authors toward improving the clarity of their figures, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about questionable design choices related to the use of perplexity as a measure of semantic information retention after finetuning. It questions whether this measure adequately addresses aspects of domain drift and catastrophic forgetting. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their design choices. The action is implicit, as the authors need to infer that they should consider alternative measures or methods to account for domain drift and catastrophic forgetting. Additionally, the comment lacks concrete details on how to implement these changes, making it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises concerns about questionable design choices related to the use of perplexity as a measure of semantic information retention after finetuning. It questions whether this measure adequately addresses aspects of domain drift and catastrophic forgetting. However, the comment does not specify which part of the paper discusses these design choices or where the authors should address these concerns. Without explicit references to sections, tables, or figures, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, while the comment highlights specific issues, it does not provide detailed guidance on how to address them. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a concern about the use of perplexity as a measure of semantic information retention after finetuning, questioning whether it adequately addresses aspects of domain drift and catastrophic forgetting. The comment provides a logical reasoning by suggesting that there are other factors to consider, such as domain drift, which are separate from catastrophic forgetting. However, it does not provide specific examples or references to support the claim, making it 3. The authors would need to further explore and justify their choice of perplexity as a measure, which is a reasonable request but requires additional effort to substantiate. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of perplexity as a measure of semantic information retention after finetuning, questioning whether it adequately addresses aspects of domain drift and catastrophic forgetting. It raises a valid concern about the design choices and suggests that the authors should consider how these factors are controlled. However, the comment lacks specific guidance or suggestions on how the authors might address these concerns or explore alternative measures. While it highlights an important area for consideration, the feedback could be more actionable by providing concrete steps or examples for improvement. Therefore, the comment is 3, as it points out a potential issue but does not fully support the authors in resolving it."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the sufficiency of the training data, specifically questioning whether 44k dialogues can capture a wide range of user traits and personalities across different content topics. The reviewer suggests that LLMs are typically trained on trillions of tokens, implying that the dataset size is insufficient. However, the comment does not provide explicit guidance on how the authors should address this concern or suggest ways to improve the dataset. The action is implicit and vague, as the authors are left to infer that they need to increase the dataset size but without specific instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the sufficiency of the training data, specifically questioning whether 44k dialogues are enough to capture a wide range of user traits and personalities across different content topics. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the dataset size and its implications for capturing user traits and personalities, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the sufficiency of the training data, specifically questioning whether 44k dialogues are sufficient to capture a wide range of user traits and personalities across different content topics. The reviewer compares this dataset size to the trillions of tokens typically used to train LLMs, suggesting that the dataset is insufficient. However, the comment lacks specific examples or references to support the claim that 44k dialogues are inadequate. The reasoning is logical but requires more detailed evidence or examples to be 5. Therefore, the comment is 3, as it provides a logical basis for the claim but lacks comprehensive support.", "helpfulness_rationale": "The review comment raises a concern about the sufficiency of the training data, specifically questioning whether 44k dialogues are sufficient to capture a wide range of user traits and personalities across different content topics. The reviewer compares this dataset size to the trillions of tokens typically used to train LLMs, suggesting that the dataset may be insufficient. While the comment identifies a potential issue, it lacks specific suggestions or guidance on how the authors might address this concern or improve the dataset. The feedback is 3 as it highlights an area for improvement, but it could be more actionable with additional details or recommendations. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the applicability of the method to real and categorical features, given that the work only uses binary features. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or test the method\"s applicability to other feature types. The comment implies that the authors should consider extending their analysis to include real and categorical features, but it lacks concrete steps or examples on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the applicability of the method to real and categorical features, given that the work only uses binary features. However, it does not specify which part of the paper this issue pertains to, such as a specific section or analysis, making it weakly grounded. The comment is specific in its critique of the feature types used and the potential limitations of the method, but without clear grounding, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the applicability of the method to real and categorical features, given that the work only uses binary features. The comment highlights a potential limitation of the method and suggests that it may not be suitable for realworld data, which often includes a mix of feature types. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the method is not applicable to other feature types. This lack of evidence or detailed justification makes the claim 3, as the authors would need to further explore and substantiate the claim themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the applicability of the method to real and categorical features, given that the work only uses binary features. This is a relevant point that highlights a potential limitation of the method and suggests that the authors should consider extending their analysis to include other feature types. However, the comment does not provide specific guidance or suggestions on how to address this issue or test the method\"s applicability to other feature types. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight but lacks depth and specificity in its guidance."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the writing should be improved, indicating that certain points in the paper are unclear. However, it does not specify which points are unclear or how the writing could be improved. The action is implicit and vague, as the authors are left without clear guidance on what specific changes to make or where to focus their efforts. Without concrete details or examples, the authors may struggle to determine how to address the issue effectively. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the writing should be improved and mentions that some points in the paper are unclear. However, it does not specify which parts of the paper are unclear or how the writing could be improved. This lack of specificity and grounding makes it difficult for the authors to identify the exact areas that need attention. The comment is 1 as it does not refer to any specific sections, figures, or tables, and it is not specific because it does not provide detailed feedback on what needs to be clarified or improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the writing should be improved because some points in the paper are unclear. However, it does not provide specific examples or details about what is unclear or how the writing could be improved. Without such details, the claim lacks sufficient evidence or justification, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the writing should be improved, indicating that some points in the paper are unclear. However, it lacks specificity and does not provide detailed guidance or examples on what aspects of the writing need improvement or clarification. Without actionable feedback or suggestions, the authors are left without a clear understanding of how to address the issue. This makes the comment 2, as it identifies a potential problem but does not offer meaningful guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should use other metrics, specifically BERTScore, to evaluate their results. This is an explicit suggestion that provides a clear action for the authors to take. The comment is also concrete because it specifies the exact metric that should be used, giving the authors a direct and specific direction for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests using other metrics, specifically BERTScore, to evaluate the results. However, it does not specify which part of the paper this suggestion pertains to, such as the Results section or a specific table or figure. Without explicit references, the authors may find it challenging to determine where to incorporate this suggestion. The comment is specific in recommending the use of BERTScore, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests using other metrics, specifically BERTScore, to evaluate the results. However, it does not provide any reasoning or evidence to support why BERTScore is a better or more appropriate metric compared to the ones already used. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests using other metrics, specifically BERTScore, to evaluate the results. While it identifies a potential area for improvement, it lacks specificity and does not provide a rationale or examples of why BERTScore might be a better choice over the current metrics. The comment does not offer guidance on how to implement this suggestion or explain the benefits of using BERTScore. As a result, the feedback is 3, as it points out a possible enhancement but does not fully support the authors in making the necessary changes. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of thorough exploration of the scalability bounds of FedDES and the absence of a clear discussion on memory requirements and computational complexity. While it identifies specific areas that need attention, it does not provide explicit guidance on how the authors should address these issues or what specific aspects should be included in the discussion. The action is implicit and somewhat vague, as the authors can infer that they need to expand the discussion on scalability, but they are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the paper\" and \"FedDES,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of limited discussion on scalability bounds, including the lack of exploration of upper limits, memory requirements, and computational complexity. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a thorough discussion of scalability bounds, specifically mentioning the absence of clear discussions on memory requirements and computational complexity. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks depth and clarity, namely the discussion of scalability bounds for FedDES. It points out the absence of a thorough exploration of the upper limits of scalability, as well as the lack of a clear discussion on memory requirements and computational complexity. This feedback is valuable as it highlights a critical aspect of the paper that needs further elaboration. However, the comment could be more helpful if it provided suggestions on how to address these issues or examples of what a comprehensive discussion might entail. Overall, the comment is 3 as it directs the authors to an important area for improvement but lacks detailed guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the meaning of the statement \"NodeSort differentially sorts nodes depending on the base node.\" It asks whether the base node affects the ordering, the key nodes for attention, and the model performance. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this question or clarify the statement in their draft. As a result, the authors are left without a clear understanding of what steps to take to improve their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the meaning of a statement in the paper, specifically regarding the effect of the base node on the ordering, key nodes for attention, and model performance. However, it does not specify which part of the paper this statement is from, making it difficult for the authors to pinpoint the exact section that needs clarification. The comment is specific in its inquiry about the implications of the base node, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question seeking clarification about the statement \"NodeSort differentially sorts nodes depending on the base node.\" It does not express an opinion, judgment, or suggestion that requires verification. It is a request for clarification, which is factual and does not contain a claim. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the meaning of a statement in the paper, specifically regarding the effect of the base node on the ordering, key nodes for attention, and model performance. While it identifies a potential area of confusion, it does not provide any suggestions or guidance on how the authors might clarify or address this issue in their draft. The comment lacks depth and actionable feedback, leaving the authors with only a vague understanding of what needs to be improved. Therefore, it is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point questions the direction of the arrow in Figure 2, asking why it is from a Gaussian space into the latent space rather than from the latent space to n^(i). The reviewer suggests that the main purpose might be to influence n^(i). While the comment raises a specific question about the direction of the arrow, it does not provide explicit guidance on how the authors should address this issue or what changes, if any, are needed. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the purpose of the arrow, but they are not given concrete steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the direction of the arrow in the figure and provides a rationale for why it might be unexpected, suggesting that the main purpose might be to influence n^(i). This level of detail helps the authors understand what aspect of the figure needs clarification or revision. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the direction of the arrow in Figure 2, suggesting that it should be from the latent space to n^(i) rather than from a Gaussian space. The reviewer provides a logical reasoning by stating that the main purpose might be to influence n^(i). However, the comment lacks specific references or detailed explanations to fully substantiate the claim. While the reasoning is clear, the absence of additional evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a specific question about the direction of the arrow in Figure 2, questioning why it is from a Gaussian space into the latent space rather than from the latent space to n^(i). It suggests that the main purpose might be to influence n^(i), which provides a logical rationale for the question. This feedback is clear and actionable, as it prompts the authors to clarify the purpose and direction of the arrow in the figure. By addressing this point, the authors can enhance the clarity and understanding of their work for readers. However, the comment could be more helpful if it offered suggestions on how to clarify the purpose or direction of the arrow. Overall, the comment is 4, as it directs the authors to a specific area needing clarification, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with abbreviations in Table 5, noting that \"AR\" stands for domain adaptation tasks and algorithms. This feedback is explicit and provides a clear action for the authors to take, which is to define the abbreviations used in the table. The comment is concrete because it specifies exactly what needs to be done to improve the clarity of the table. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular issue with abbreviations, namely that \"AR\" stands for domain adaptation tasks and algorithms. This provides clear guidance on what needs to be addressed to improve the clarity of the table. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that many abbreviations lack definition and cause confusion, specifically mentioning that \"AR\" in Table 5 stands for domain adaptation tasks and algorithms. This claim is 3 as it provides a specific example of an abbreviation that is unclear, but it lacks broader context or justification for why other abbreviations might also be problematic. The comment could be strengthened by providing more examples or explaining how these abbreviations impact the clarity of the paper. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with abbreviations in the paper, noting that many of them lack definition and cause confusion. It provides a concrete example by pointing out that \"AR\" in Table 5 stands for domain adaptation tasks and algorithms. This feedback is actionable as it directs the authors to clarify the abbreviations used in their work, which can significantly improve the clarity and accessibility of their paper. However, the comment could be more helpful if it suggested ways to define these abbreviations or provided examples of how to do so effectively. Overall, the comment is 4 as it highlights a clear area for improvement and provides a specific example to address, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the choice of using advantage instead of q value for the analysis, suggesting that there might be other technical considerations. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on whether the authors should explore these considerations, provide an explanation, or make a specific change. Without actionable steps or suggestions, the authors are left without a clear understanding of what needs to be done in response to this comment. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the choice of using advantage instead of q value for the analysis, suggesting that there might be other technical considerations. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its inquiry about technical considerations but lacks grounding as it does not reference a particular section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the choice of using advantage instead of q value for the analysis, suggesting that there might be other technical considerations. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this choice might be problematic or what specific technical considerations are at play. Without additional context or explanation, the claim remains vague and 1, leaving the authors without a clear understanding of the issue or how to address it. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the choice of using advantage instead of q value for the analysis, suggesting that there might be other technical considerations. While it identifies a potential area of concern, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue or explore the potential technical considerations. The comment is 3 as it prompts the authors to consider an alternative approach, but it does not offer actionable advice or depth to fully support the authors in improving their draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the setting of Unsupervised Online Adaptation, suggesting that it is not truly unsupervised because the training set requires annotations. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or clarify the setting. Without specific suggestions or instructions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec 3.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the setting of Unsupervised Online Adaptation is strange because it requires a training set with documents, queries, and labels, which contradicts the notion of unsupervised adaptation. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the setting of Unsupervised Online Adaptation is strange because it requires a training set with documents, queries, and labels, contradicting the notion of unsupervised adaptation. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the setting of Unsupervised Online Adaptation, pointing out that it requires a training set with documents, queries, and labels, which contradicts the notion of unsupervised adaptation. This feedback is 3 as it highlights a possible inconsistency in the paper, prompting the authors to reconsider their approach or clarify the setting. However, the comment lacks specific suggestions or guidance on how to address this issue, such as proposing alternative methods or explaining the rationale behind the current setup. To be more helpful, the comment could provide more detailed feedback or actionable advice. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the fairness of the performance comparison in Table 1, specifically mentioning that VINS sets different sample weights W u i in the training process, while most compared baselines like DNS, AOBPR, SA, and PRIS set all sample weights as 1. This comment implies that the authors should address the issue of fairness in the performance comparison, but it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should investigate and potentially adjust the sample weights to ensure fairness. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the unfairness in the performance comparison due to different sample weights used by VINS compared to other baselines like DNS, AOBPR, SA, and PRIS. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the performance comparison in Table 1 is unfair due to different sample weights used by VINS compared to other baselines. This claim is 3 as it provides a specific reason for the perceived unfairness, namely the use of different sample weights. However, the comment lacks detailed examples or references to support the claim fully, such as comparing the performance with and without these sample weights. This makes the claim 3, as it provides a basis for the critique but requires more detailed evidence to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific issue with the performance comparison in Table 1, noting that the fairness of the comparison is compromised due to different sample weights used by VINS compared to other baselines. This feedback is clear and actionable, as it highlights a potential bias in the evaluation process that could impact the interpretation of results. By pointing out this issue, the comment provides the authors with a clear direction for improvement, such as adjusting the sample weights or providing additional context to ensure a fair comparison. However, the comment could be more helpful if it suggested specific ways to address the issue or provided examples of how to ensure fairness in the comparison. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the results are presented in a convoluted manner, specifically mentioning the disregard of safety violations in the first 1000 episodes. It questions the reason for presenting the results in this way, implying that the authors should clarify or restructure their presentation. However, the comment does not provide explicit guidance on how to address this issue or suggest specific changes to improve the clarity of the results. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the presentation but are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the presentation of results, specifically mentioning the disregard of safety violations in the first 1000 episodes. While it does not explicitly mention a specific section or figure, the authors can infer that it relates to the results section. The comment is specific in detailing what is unclear about the presentation, namely the reason for disregarding safety violations. However, it lacks full grounding as it does not explicitly mention the section or figure being addressed. Therefore, this comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the results are presented in a convoluted manner, specifically mentioning the disregard of safety violations in the first 1000 episodes. The comment questions the reason for presenting the results in this way, suggesting that it may be unclear or misleading. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the exact issue or how to address it. The lack of detailed justification or examples makes the claim 3, as it requires more information to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of results, noting that the results disregard safety violations in the first 1000 episodes. It questions the reason for presenting the results in this way, suggesting that it may be unclear or misleading. This feedback is 3 as it points out a potential weakness in the presentation of results, prompting the authors to reconsider their approach. However, the comment lacks detailed guidance or suggestions on how to address this issue, such as recommending alternative ways to present the results or clarifying the reasoning behind the current presentation. To be more helpful, the comment could provide specific examples or suggestions for improvement. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment identifies a minor weakness in the allocation of Figure 1, suggesting that it is too naive. However, it does not provide specific guidance on how the authors could improve this allocation or what aspects of the figure could be edited to make it more effective. The comment also mentions that the authors could have edited the space of the main paper more wisely, but again, it lacks concrete details on how to achieve this. As a result, the action is implicit and vague, leaving the authors uncertain about how to address the feedback. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment identifies a minor weakness in the allocation of Figure 1, suggesting that it is too naive. However, it does not specify which part of the paper this figure is located in, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment mentions that the authors could have edited the space of the main paper more wisely, but it does not provide specific guidance on what aspects of the paper could be improved. This lack of specificity and grounding makes it challenging for the authors to address the feedback effectively. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the allocation of Figure 1 is too naive and suggests that the authors could have edited the space of the main paper more wisely. However, the comment lacks specific examples or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the feedback effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a minor weakness in the allocation of Figure 1, suggesting that it is too naive. However, it does not provide specific guidance or examples on how the authors could improve the allocation or what aspects of the figure could be edited to make it more effective. Additionally, the comment mentions that the authors could have edited the space of the main paper more wisely, but again, it lacks detailed suggestions or examples. This feedback is vague and lacks actionable advice, leaving the authors with limited insight into how to address the issues raised. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation of the planbased method, noting that it requires manual design of a plan based on ground truth, which is unrealistic in realworld scenarios. It also points out that the learned plan methods are not comparable to methods with predefined plans, as shown in Table 2. The comment suggests that the proposed method may struggle to generalize to new datasets without ground truth summaries. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this limitation or improve the generalizability of their method. The action is implicit and somewhat vague, as the authors are left to infer what steps to take to improve the method\"s generalizability. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the limitations of the planbased method, specifically mentioning the need for manual design of a plan based on ground truth, which is unrealistic in realworld scenarios. It also compares the learned plan methods to those with predefined plans, as shown in Table 2, and suggests that the proposed method may struggle to generalize to new datasets without ground truth summaries. However, the comment does not explicitly mention which part of the paper discusses these methods or tables, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing the issue with the planbased method and its generalizability, but it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the planbased method requires manual design of a plan based on ground truth, which is unrealistic in realworld scenarios. It also suggests that the learned plan methods are not comparable to those with predefined plans, as shown in Table 2, indicating a potential limitation in generalizability. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. The lack of evidence or detailed explanation makes it difficult for the authors to fully understand and address the issues raised. Therefore, the comment is considered 2, as it provides some insight but requires more detailed justification to be 5.", "helpfulness_rationale": "The review comment identifies a significant limitation of the planbased method, noting that it requires manual design of a plan based on ground truth, which is unrealistic in realworld scenarios. It also points out that the learned plan methods are not comparable to those with predefined plans, as shown in Table 2, indicating a potential issue with generalizability. This feedback is valuable as it highlights a critical weakness in the methodology and suggests that the proposed method may struggle to generalize to new datasets without ground truth summaries. However, the comment could be more helpful if it provided suggestions on how to address this limitation or improve the generalizability of the method. Overall, the comment is 3 as it directs the authors\" attention to a key area for improvement but lacks specific guidance on how to resolve the issue."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the conclusions being unconvincing, specifically mentioning the claim that continuous learning with unlabeled data accumulates noise, which is detrimental to representation quality. It suggests that the results might be due to limited exploration of combination methods and points to recent works that employ feature replay, such as R1, R2, and R3, which have shown promising results in continual learning and continual category discovery. While the comment implies that the authors should consider these works and their findings, it does not explicitly instruct them to do so or provide specific guidance on how to incorporate these references into their work. The action is implicit and somewhat vague, as the authors can infer that they should explore these works further but are not given detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific conclusions that are not convincing, such as the claim about continuous learning with unlabeled data accumulating noise. It also references specific works, such as R1, R2, and R3, which provide examples of featurereplay methods that have shown potential in continual learning and continual category discovery. This allows the authors to accurately identify the parts of the paper being addressed and the specific issues raised. The comment is also specific because it provides examples of recent works that could be considered for comparison or improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some conclusions are not convincing, specifically mentioning the claim about continuous learning with unlabeled data accumulating noise. The reviewer provides a rationale by suggesting that the results might be due to limited exploration of combination methods and references recent works that employ feature replay, such as R1, R2, and R3. This provides some support for the claim by offering alternative explanations and examples of successful approaches. However, the comment could be strengthened by providing more detailed comparisons or specific examples of how these works differ from the current study. Overall, the claim is 3 as it offers a logical reasoning but lacks comprehensive evidence or detailed comparisons. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the conclusions of the paper, questioning the validity of the claim that continuous learning with unlabeled data accumulates noise, which is detrimental to representation quality. It suggests that the results might be due to limited exploration of combination methods and points to recent works that employ feature replay, such as R1, R2, and R3, which have shown promising results in continual learning and continual category discovery. This feedback is 3 as it highlights a potential weakness in the paper\"s conclusions and provides references to recent works that could be considered for comparison or improvement. However, the comment could be more helpful if it offered specific guidance on how the authors might address this issue or integrate these references into their work. Overall, the comment provides some direction for improvement but lacks depth and detailed suggestions, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises questions about the accuracy of the ground truth and the differences in the results reported in the ablation study. However, it does not provide explicit instructions or suggestions for the authors to address these questions or improve their draft. The comments are more like clarifications or requests for additional information, leaving the authors without clear actions to take. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises questions about the accuracy of the ground truth and the differences in the results reported in the ablation study. However, it does not specify which part of the paper these questions pertain to, such as which sections or tables discuss the ground truth or the ablation study. Without explicit references, the authors cannot confidently determine the exact parts of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the ground truth or results are unclear or need further explanation. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point consists of two questions: one about the accuracy of the ground truth and the other about the differences in the results reported in the ablation study. Neither question contains a claim or opinion that requires verification. They are factual inquiries seeking clarification or additional information. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the accuracy of the ground truth and the differences in the results reported in the ablation study. However, it does not provide specific suggestions or guidance on how the authors might address these questions or improve their draft. The comment lacks actionable feedback, leaving the authors with a general sense of uncertainty but without a clear path to resolution. As a result, the comment is 2, as it identifies areas of concern but does not offer constructive advice for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the wording in the conclusion is overly exaggerated and that the word choice is \"flamboyant\" in multiple places. However, it does not provide specific suggestions or guidance on how to revise the wording or tone. The action is implicit, as the authors can infer that they need to tone down the language, but it lacks concrete details on how to achieve this. Therefore, the comment is 3, as it identifies an issue but does not offer detailed guidance on how to address it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the conclusion, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue of overly exaggerated wording and provides a concrete example of the problematic phrase, \"our pioneering contributions herald a new era in robotic adaptability.\" This specificity helps the authors understand what needs to be addressed in the conclusion. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the wording in the conclusion is overly exaggerated and that the word choice is \"flamboyant\" in multiple places. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact issues or how to address them. The lack of detailed justification or evidence makes the claim 3, as the authors may struggle to identify and correct the issues without further guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the wording in the conclusion, noting that it is overly exaggerated and \"flamboyant.\" This feedback is clear and actionable, as it points out a potential weakness in the paper\"s presentation and suggests a need for more modest language. However, the comment could be more helpful if it provided specific examples of where the language is excessive or offered suggestions for alternative wording. Despite this, the comment still provides valuable insight into how the authors can improve the clarity and impact of their conclusions. Therefore, it is rated as 4, aligning with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point provides a mix of explicit and implicit actions. It explicitly asks for more explanations regarding Figure 5a and how the authors dealt with DVS input when the input is in aer format. Additionally, it suggests analyzing energy consumption as reference 15 did, which is an implicit action. However, the comment does not specify how to provide more explanations or how to analyze energy consumption, leaving some aspects vague. Overall, the comment is 4 as it clearly identifies areas for improvement but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 5a,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with \"Fig. 5a\" by asking for more explanations. Additionally, the comment provides a specific suggestion to analyze energy consumption as reference 15 did, which is clear and actionable. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of multiple claims and suggestions. The first claim about \"11\" being wonderful is not verifiable as it lacks supporting evidence or context. The second claim about Figure 5a being strange is not supported by any reasoning or examples, making it difficult for the authors to understand the basis of the critique. The suggestion to analyze energy consumption as reference 15 did is 3, as it provides a direction but lacks specific details or examples. Overall, the comment is a mix of 1 and 3 claims, justifying a score of 2.", "helpfulness_rationale": "The review comment provides some helpful feedback by acknowledging the quality of \"11\" and suggesting that the authors consider other bit operations. It also points out a potential issue with Figure 5a, asking for more explanations. Additionally, it raises a question about how the authors dealt with DVS input when the input is in aer format. However, the comment could be more helpful if it offered specific suggestions or examples on how to address these issues. The reference to analyzing energy consumption as done in reference 15 is a constructive suggestion but lacks detailed guidance on how to implement it. Overall, the comment is 3 as it identifies areas for improvement but lacks depth and actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point critiques the novelty of the approach by pointing out that the introduction of multigranularity and multiscale to enhance model performance is a common practice in convolutional networks and that migrating this approach to the field of MLMs is not innovative. It also mentions that some algorithms used in the article only enhance information on the input side, while many MLMs can already perform object detection tasks. However, the comment does not provide any actionable advice or suggestions for the authors to address these concerns or improve their work. It lacks explicit guidance on how the authors might enhance the novelty or originality of their contribution. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the novelty of the approach by mentioning the introduction of multigranularity and multiscale to enhance model performance, which is a common practice in convolutional networks. It also points out that some algorithms used in the article only enhance information on the input side, while many MLMs can already perform object detection tasks. However, the comment does not specify which part of the paper these claims are based on, making it difficult for the authors to identify the exact sections that need attention. Additionally, while it provides some specific critique, it lacks detailed guidance on how to address these issues. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the introduction of multigranularity and multiscale to enhance model performance is a common approach in convolutional networks and that migrating this approach to the field of MLMs is not innovative. It also suggests that some algorithms used in the article only enhance information on the input side, while many MLMs can already perform object detection tasks. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. The lack of evidence or detailed justification makes it difficult for the authors to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment critiques the novelty of the approach by pointing out that the introduction of multigranularity and multiscale to enhance model performance is a common practice in convolutional networks and that migrating this approach to the field of MLMs is not innovative. It also mentions that some algorithms used in the article only enhance information on the input side, while many MLMs can already perform object detection tasks. However, the comment lacks specific suggestions or guidance on how the authors might address these concerns or improve the novelty of their contribution. Without actionable feedback or detailed advice, the authors are left without a clear path for improvement. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the potential oversmoothing of GNNbased encoders due to similarityaware positive sample selection and the impact on generalization performance. It suggests conducting additional experiments on different downstream tasks and across different domains to address these concerns. While the comment identifies specific areas for improvement, it does not provide explicit instructions or concrete steps on how to conduct these experiments or what specific aspects to focus on. The authors can infer that they need to conduct additional experiments, but the lack of detailed guidance makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises concerns about the potential oversmoothing of GNNbased encoders due to similarityaware positive sample selection and the impact on generalization performance. It suggests conducting additional experiments on different downstream tasks and across different domains to address these concerns. However, the comment does not specify which part of the paper discusses the similarityaware positive sample selection or the experiments on transfer performance, making it difficult for the authors to pinpoint the exact sections that need attention. While the authors might have an idea of where these topics are discussed, the lack of explicit references makes the comment weakly grounded. The comment is specific in suggesting additional experiments, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point raises concerns about the potential oversmoothing of GNNbased encoders due to similarityaware positive sample selection and the impact on generalization performance. The reviewer suggests conducting additional experiments on different downstream tasks and across different domains to address these concerns. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that similarityaware positive sample selection could lead to oversmoothing or lower generalization performance. The suggestion for additional experiments is logical but requires more detailed justification or evidence to be 5. Therefore, the comment is classified as 2.", "helpfulness_rationale": "The review comment raises concerns about the potential oversmoothing of GNNbased encoders due to similarityaware positive sample selection and its impact on generalization performance. It suggests conducting additional experiments on different downstream tasks and across different domains to address these concerns. While the comment identifies a potential issue and provides a direction for further exploration, it lacks specific guidance or detailed suggestions on how to conduct these experiments or what specific aspects to focus on. The feedback is 3 as it points out an area for improvement, but it could be more actionable with additional details or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the types of situations or social norms, such as physical or psychological safety, are not clear in the main paper. However, it does not provide explicit guidance on how the authors should clarify these aspects or what specific information should be included. The action is implicit, as the authors can infer that they need to provide more detail on these types of situations or norms, but the comment lacks concrete instructions on how to do so. Therefore, the comment is 3, as it identifies an area for improvement but does not specify how to address it.", "grounding_specificity_rationale": "The comment identifies a lack of clarity regarding the types of situations or social norms, such as physical or psychological safety, in the main paper. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in detailing what is unclear, but without explicit references to sections or parts of the paper, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the types of situations or social norms (e.g., physical or psychological safety) are not clear in the main paper. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed explanation or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks clarity, noting that the types of situations or social norms, such as physical or psychological safety, are not clearly defined. This feedback is 3 as it points out a potential gap in the paper that the authors need to address. However, the comment does not provide specific suggestions or guidance on how to clarify these aspects, leaving the authors with a general direction but without detailed instructions on how to improve the draft. To be more helpful, the comment could include examples or specific questions to help the authors better understand what information is missing. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly requests for more baselines to be compared and more domains to be tested, suggesting that the current choices of weighting and learning density functions are not strongly motivated. It also asks for stronger empirical results by including baselines with other design choices and testing in more domains. This feedback provides clear and specific actions for the authors to take, such as conducting additional experiments and comparing their results with other baselines. The instructions are explicit and concrete, giving the authors a clear understanding of what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that more baselines should be compared and more domains should be tested, and it questions the motivation behind the choices of weighting and learning density functions. However, it does not specify which parts of the paper these suggestions pertain to, making it weakly grounded. The comment is specific in its request for stronger empirical results, but without clear references to specific sections or elements of the paper, the authors may find it challenging to pinpoint the exact areas needing improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more baselines should be compared and more domains tested, and it questions the motivation behind the choices of weighting and learning density functions. The reviewer provides a logical reasoning by asking for stronger empirical results, which implies that the current results are not sufficiently robust. However, the comment lacks specific examples or references to support the claim that other design choices or domains should be tested. This makes the claim 3, as it provides a direction for improvement but lacks detailed justification or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a lack of motivation for the choices of weighting and the way of learning density functions, suggesting that more baselines should be compared and more domains tested to strengthen the empirical results. This feedback is clear and actionable, as it provides specific areas for improvement that the authors can address to enhance the robustness and validity of their work. However, the comment could be more helpful if it offered suggestions on which baselines or domains to consider or how to better motivate the current choices. Overall, the comment is 4 as it directs the authors toward improving their draft by providing a clear path for enhancement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that Figure 2 is ambiguous due to unclear symbols and raises a question about potential information redundancy and interference in the multisphere icosahedral discretization process. However, it does not provide explicit guidance on how to address these issues or suggest specific actions for the authors to take. The comment implies that the authors should clarify the symbols in Figure 2 and address the concerns about redundancy and interference, but these actions are not directly stated. As a result, the comment is 3, as it identifies areas for improvement but lacks concrete instructions on how to implement them.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the ambiguity in the figure due to unclear symbols and raises a question about potential information redundancy and interference in the multisphere icosahedral discretization process. This provides clear guidance on what needs to be clarified or addressed in the figure. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the ambiguity of Figure 2 due to unclear symbols and questions whether there is information redundancy and interference in the multisphere icosahedral discretization process. However, the comment does not provide any specific examples or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 2, noting that some symbols are not explained clearly. It also raises a question about potential information redundancy and interference in the multisphere icosahedral discretization process. While the comment points out areas for improvement, it lacks detailed guidance or suggestions on how the authors might address these issues. Providing specific examples or recommendations would enhance the comment\"s helpfulness. Therefore, the comment is 3, as it highlights areas for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the obtained results, specifically the assumption that the spectrum of a kernel is subgaussian. It notes that while this assumption is acceptable for Gaussian kernels, it excludes other popular classes like Matern kernels, which have a polynomial decay in their spectrum. However, the comment does not provide explicit guidance on how the authors should address this limitation or suggest ways to include Matern kernels in their analysis. The action is implicit and somewhat vague, as the authors are left to infer that they should consider expanding their analysis to include other kernel types. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a limitation in the obtained results, specifically the assumption that the spectrum of a kernel is subgaussian. It mentions that while this assumption is acceptable for Gaussian kernels, it excludes other popular classes like Matern kernels, which have a polynomial decay in their spectrum. However, the comment does not specify which part of the paper discusses these assumptions or results, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but the lack of explicit references makes it challenging to pinpoint the exact part of the paper being addressed. The comment is specific in detailing the limitation and the need to consider other kernel types, but the lack of grounding limits its effectiveness. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the results of the paper could be restrictive due to the assumption that the spectrum of a kernel is subgaussian. It provides a logical reasoning by explaining that while Gaussian kernels are included in this class, other popular classes like Matern kernels are not, as their spectrum only decays polynomially. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a limitation in the paper\"s results, specifically the assumption that the spectrum of a kernel is subgaussian. It acknowledges that this assumption is acceptable for Gaussian kernels but points out that it excludes other popular classes like Matern kernels, which have a polynomial decay in their spectrum. This feedback is valuable as it highlights a potential restriction in the paper\"s scope and suggests that the authors should consider expanding their analysis to include other kernel types. However, the comment could be more helpful if it provided specific suggestions on how to incorporate these other kernels or addressed the implications of this limitation. Overall, the comment is 3 as it directs the authors\" attention to an important area for improvement but lacks detailed guidance on how to address it."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment indicates that the writing is difficult to follow in many places and suggests simplification. However, it does not provide specific examples or guidance on how to simplify the writing, nor does it specify which parts of the paper are particularly challenging. The action is implicit and vague, as the authors are left to infer that they need to simplify the writing but without concrete steps or examples to guide them. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment indicates that the writing is difficult to follow in many places and suggests simplification. However, it does not specify which parts of the paper are particularly challenging or provide examples of where the writing could be improved. This lack of specificity and lack of reference to a specific section or part of the paper makes it difficult for the authors to pinpoint the exact areas needing attention. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the writing is difficult to follow in many places and suggests simplification. However, it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed explanations or references to particular sections where the writing is challenging, the authors may find it difficult to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a general issue with the writing being difficult to follow in many places, suggesting that it could be simplified. However, it lacks specificity and does not provide detailed guidance or examples of where the writing is unclear or how it could be improved. Without actionable suggestions or detailed feedback, the authors are left with a vague understanding of what needs to be addressed. This limits the comment\"s usefulness, making it 2."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should test their method on more datasets to gain a better understanding of its performance. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not specify which datasets should be used or how the results should be analyzed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the method should be tested on more datasets to better understand its performance. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. Without explicit references to specific sections or elements of the paper, the authors cannot confidently determine where to address this feedback. Additionally, the comment lacks specificity regarding which datasets should be considered or how the results should be analyzed. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the method should be tested on more datasets to better understand its performance. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why testing on additional datasets is necessary or how it would improve the understanding of the method\"s performance. Without such support, the claim remains 1, as the authors are left without a clear understanding of the basis for the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the authors should test their method on more datasets to gain a better understanding of its performance. This feedback is 3 as it points out a potential limitation in the current dataset selection and encourages the authors to expand their evaluation. However, the comment lacks specificity regarding which additional datasets should be considered or how the results should be analyzed. Without detailed guidance, the authors may find it challenging to determine the exact steps needed to address this feedback. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the distinction between Online Normalization and Batch Normalization, specifically regarding their impact on gradient bias. However, it does not provide any explicit or implicit actions for the authors to take. The comment does not suggest any changes or improvements to the draft, nor does it offer guidance on how the authors might clarify the issue. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the distinction between Online Normalization and Batch Normalization, specifically regarding their impact on gradient bias. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its questioning of the bias and lack of clarity regarding the two normalization methods. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the distinction between Online Normalization and Batch Normalization, specifically regarding their impact on gradient bias. The reviewer acknowledges having read other reviews and the author\"s response, but the comment does not provide any additional reasoning, evidence, or references to support the claim that Online Normalization is unbiased and Batch Normalization is biased. Without further explanation or evidence, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the distinction between Online Normalization and Batch Normalization, specifically regarding their impact on gradient bias. It acknowledges having read other reviews and the author\"s response, but it does not provide any additional insights, suggestions, or guidance for the authors to address this issue. The comment lacks depth and does not offer actionable feedback or suggestions for improvement, leaving the authors without a clear understanding of how to enhance their draft. Therefore, it is rated as 2, as it provides minimal value for the authors to improve their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a contradiction between the statement in lines 4748 and the observation that overparameterization is beneficial for supervised learning of deep neural networks in practice. It also mentions theoretical works supporting the benefits of overparametrization. However, the comment does not provide specific guidance on how the authors should address this contradiction or integrate the theoretical works into their paper. The action is implicit and somewhat vague, as the authors are left to infer that they need to reconcile the conflicting statements and potentially include references to the theoretical works. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (4748) in the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it points out a contradiction between the statement about overparametrization and the observation that it is beneficial for supervised learning. Additionally, the comment provides a reference to theoretical works supporting the benefits of overparametrization, which further specifies the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a contradiction between the statement in lines 4748 and the observation that overparameterization is beneficial for supervised learning. It supports this claim by referencing theoretical works that demonstrate the benefits of overparametrization. However, the comment does not provide specific references to these theoretical works, which would strengthen the verifiability of the claim. While the mention of theoretical works provides some support, the lack of detailed references or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a contradiction in the paper regarding the statement that overparametrization leads to worse performance, while also noting that overparametrization is beneficial for supervised learning in practice. It provides a reference to theoretical works supporting the benefits of overparametrization, which could be helpful for the authors in reconciling this contradiction. However, the comment could be more helpful if it offered specific suggestions on how to address this contradiction or integrate the theoretical works into the paper. As it stands, the feedback is 3, as it points out an important issue but lacks detailed guidance for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states that more experiments are necessary, indicating a clear action for the authors to take. However, it does not specify which additional experiments should be conducted or how they should be designed. The lack of concrete details on what specific experiments are needed or how to implement them makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that more experiments are needed, but it does not specify which part of the paper this pertains to, such as the experimental section or a specific game environment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. However, the comment is specific in its request for additional experiments, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that \"more experiments are necessary\" but does not provide any reasoning or evidence to support this claim. It lacks specific examples or references to justify why additional experiments are needed or what specific aspects of the current experiments are insufficient. Without further explanation or context, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, noting that the experiments are only conducted on one game environment. It suggests that more experiments are necessary, which is a valid point that could help the authors expand the scope and applicability of their work. However, the comment lacks specificity and does not provide guidance on which additional environments should be considered or how the experiments should be designed. While it highlights an area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the feasibility of implementing and testing concrete predictions based on the argument that recognition lists are recalled based on items. However, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve their approach. The comment lacks actionable details, such as recommending specific changes or experiments to test the feasibility of the proposed method. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper related to the argument that recognition lists are recalled based on items. However, it does not specify which part of the paper this argument is discussed in, making it weakly grounded. The comment provides some specificity by questioning the feasibility of implementing and testing concrete predictions based on this argument, but it lacks detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a claim about the feasibility of implementing and testing concrete predictions based on the argument that recognition lists are recalled based on items. The reviewer provides a logical reasoning by explaining that in the most common case of recognition, new items comprise the list of all items available in memory (minus the ones seen), and it is difficult to see how such an exhaustive list could be effectively implemented. This reasoning is based on common knowledge about memory processes and the challenges of implementing exhaustive lists. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is 3, as it provides a logical basis but lacks detailed evidence or references.", "helpfulness_rationale": "The review comment raises a concern about the feasibility of implementing and testing concrete predictions based on the argument that recognition lists are recalled based on items. It provides a logical reasoning by explaining that in the most common case of recognition, new items comprise the list of all items available in memory (minus the ones seen), and it is difficult to see how such an exhaustive list could be effectively implemented. This feedback highlights a potential limitation in the approach and prompts the authors to consider the practicality of their method. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of alternative approaches. As it stands, the comment is 3 as it identifies a critical area for improvement but lacks detailed guidance. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential issue with the experimental comparison, suggesting that the proposed method may have an unfair advantage due to pretraining. It questions whether the compared methods were also initialized with a similar pretrained model and points out that the proposed method without SSL performs inferior to most of the compared methods. While the comment identifies a potential issue, it does not provide explicit guidance on how to address it or suggest specific actions for the authors to take. The authors are left to infer that they should clarify the pretraining process and ensure a fair comparison, but the comment lacks concrete details on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the experimental comparison, questioning the fairness of the comparison due to pretraining and pointing out that the proposed method without SSL performs inferior to most of the compared methods. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental comparison with other methods is unfair due to the proposed method being pretrained before finetuning, while it is unclear if the compared methods were also initialized with a similar pretrained model. The comment supports this claim by referencing Table 1, which shows that the proposed method without SSL performs inferior to most of the compared methods. This provides a logical basis for the claim, as it highlights a potential bias in the experimental setup. However, the comment could be strengthened by providing specific examples or references to other methods that were not pretrained, which would make the claim 5. Therefore, the comment is 4, as it provides a solid foundation for the claim but lacks complete evidence.", "helpfulness_rationale": "The review comment identifies a potential issue with the experimental comparison, specifically questioning the fairness of the comparison due to the proposed method being pretrained before finetuning. It points out that the proposed method without SSL performs inferior to most of the compared methods, suggesting that this may be due to an unfair advantage. This feedback is clear and actionable, as it prompts the authors to clarify the pretraining process and ensure a fair comparison with other methods. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or offered examples of how to ensure a fair comparison. Overall, the comment is 4 as it directs the authors to a critical area for improvement in their experimental setup."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should consider using better metadata embeddings for their zeroshot learning results on the CUB dataset. It references a specific paper, \"Learning Deep Representations of FineGrained Visual Descriptions, Reed et al, CVPR 2016,\" and suggests that the performance of the proposed method could be improved with better metadata embeddings. While the comment implies an action, it does not explicitly instruct the authors to make this change or provide detailed guidance on how to implement it. The suggestion is 3, as the authors can infer the need to explore better metadata embeddings but may not be entirely clear on how to proceed.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3 page 7\" and \"attribute,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a suggestion for improving the results by referencing a specific paper and suggesting the use of better metadata embeddings. The comment specifies what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the metadata used for zeroshot learning on the CUB dataset, as presented in Table 3, is \"attribute.\" It claims that this choice is good for fair comparison but notes that better metadata embeddings are available, referencing a specific paper. The reviewer provides a clear suggestion for improvement by recommending the use of better metadata embeddings and references a relevant source. This level of detail and specific reference makes the claim 4, as it provides a logical basis for the suggestion and points to a potential avenue for improvement. However, the comment could be strengthened by including more detailed reasoning or examples from the referenced paper. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the paper. It identifies a potential weakness in the use of \"attribute\" metadata for zeroshot learning on the CUB dataset, suggesting that better metadata embeddings could lead to improved performance. The comment references a specific paper, \"Learning Deep Representations of FineGrained Visual Descriptions, Reed et al, CVPR 2016,\" which provides a concrete example of better metadata embeddings. This feedback is valuable as it not only points out a specific area for improvement but also offers a clear direction for the authors to enhance their work. The inclusion of a reference to a relevant paper further supports the suggestion, making the comment 5 for the authors in refining their draft. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of clarity in describing the contribution of the paper with respect to ECE_sweep. It explicitly suggests that the paper should be upfront about its contribution and clarifies that the contribution is essentially a way to choose the number of bins using data, which is not fundamentally different from existing estimators. The comment provides a clear and concrete action for the authors to take, which is to clarify the contribution of their work. This makes the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ECE_sweep,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the contribution, explaining that it is essentially a way to choose the number of bins using data, which is not fundamentally different from existing estimators. The comment suggests that the paper should be upfront about its contribution and clarifies that the authors were confused about the paper\"s point until they realized this. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point claims that the contribution of the paper with respect to ECE_sweep is not clearly described. The reviewer provides a specific explanation of what the contribution entails, which is a way to choose the number of bins using data, similar to autotuning a hyperparameter in the estimate. The reviewer also suggests that this is not fundamentally different from existing estimators. This reasoning is clear and provides a logical basis for the claim, making it 4. However, the comment could be strengthened by referencing specific examples or studies that support the claim, which would align with a score of 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of clarity in describing the contribution with respect to ECE_sweep. It provides a concrete explanation of what the contribution entails, which is essentially a way to choose the number of bins using data, similar to autotuning a hyperparameter in the estimate. The comment suggests that this is not fundamentally different from existing estimators and recommends that the paper should be upfront about its contribution. This feedback is clear and actionable, as it guides the authors on how to improve the clarity and specificity of their contribution. However, it could be more helpful if it offered suggestions on how to rephrase or present the contribution more effectively. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the variability in results with the chosen random projection matrix and suggests that pathological projection matrices could skew the MFTMA capacity and width scores. The reviewer acknowledges that this is unlikely with random projections but still recommends checking the resilience of the metric to the choice of random projection. While the comment implies that the authors should investigate this aspect, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore the resilience of the metric to random projection choices. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"3.a),\" indicating the specific part of the paper being addressed, allowing the authors to accurately identify the section. It is also specific because it raises a concern about the variability in results with the chosen random projection matrix and suggests that pathological projection matrices could skew the MFTMA capacity and width scores. The reviewer acknowledges that this is unlikely with random projections but still recommends checking the resilience of the metric to the choice of random projection. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the variability in results with the chosen random projection matrix and suggests that pathological projection matrices could skew the MFTMA capacity and width scores. The reviewer acknowledges that this is unlikely with random projections but still recommends checking the resilience of the metric to the choice of random projection. The comment provides a logical reasoning for the concern, suggesting that the authors should investigate this aspect further. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to explore the issue themselves to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the variability in results with the chosen random projection matrix and suggests that pathological projection matrices could skew the MFTMA capacity and width scores. The reviewer acknowledges that this is unlikely with random projections but still recommends checking the resilience of the metric to the choice of random projection. This feedback is clear and actionable, as it prompts the authors to investigate the robustness of their metric to different random projection choices. By addressing this concern, the authors can enhance the reliability and robustness of their results. However, the comment could be more helpful if it provided specific guidance on how to conduct this investigation or what aspects to focus on. Overall, the comment is 4, as it identifies a potential weakness and suggests a meaningful area for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the evaluation of FGT should be used to evaluate the performance of the proposed method and comparative methods, rather than just in the ablation study. This feedback is explicit and provides a clear action for the authors to take, which is to include the evaluation of FGT in the main performance evaluation. However, it does not specify how the authors should implement this change or provide detailed guidance on what specific aspects of FGT should be evaluated. While the action is clear, the lack of concrete details makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the evaluation of FGT,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the evaluation of FGT should be used to evaluate the performance of the proposed method and comparative methods, rather than just in the ablation study. This provides clear guidance on how to improve the evaluation section of the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation of FGT should be used to evaluate the performance of the proposed method and comparative methods, rather than just in the ablation study. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this change is necessary or beneficial. Without additional context or explanation, the claim remains vague and 1, leaving the authors without a clear understanding of the basis for the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the evaluation of the proposed method, noting that the evaluation of FGT is only used in the ablation study and should be extended to evaluate the performance of the proposed method and comparative methods. This feedback is clear and actionable, as it provides a direct suggestion for improving the evaluation section of the paper. By addressing this point, the authors can enhance the comprehensiveness and robustness of their evaluation, which is crucial for validating the effectiveness of their method. However, the comment could be more helpful if it provided additional guidance on how to incorporate FGT into the main performance evaluation or suggested specific metrics to consider. Overall, the comment is 4, as it directs the authors toward a meaningful improvement in their draft."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the winnertakeall property has been widely used in previous works and questions the novelty of the paper\"s contribution in this regard. It specifically mentions that the paper\"s findings have been reported in previous works, particularly in Section 5. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address the concerns about novelty or improve their contribution. Without actionable suggestions or a clear direction for improvement, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue by questioning the novelty of the paper\"s contribution to the understanding of the winnertakeall property, particularly in light of previous works and the simplified settings used. The comment provides a clear basis for the authors to address the concerns about originality and potential overlap with existing literature. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper\"s contribution to the understanding of the winnertakeall property is unclear, given its reliance on previous works and simplified settings. The reviewer supports this claim by referencing specific sections of the paper (Sec 5) and mentioning previous works that have already explored this behavior. This provides a logical basis for the claim, as it highlights the lack of novelty in the paper\"s approach. However, the comment could be strengthened by providing more detailed examples or references to specific previous works, which would make the claim 5. Therefore, the comment is 4, as it provides a solid foundation for the claim but lacks comprehensive evidence.", "helpfulness_rationale": "The review comment identifies a potential issue with the originality of the paper, specifically questioning the novelty of the paper\"s contribution to the understanding of the winnertakeall property. It points out that this property has been widely used in previous works and that the paper\"s findings have been reported in previous studies, particularly in Section 5. This feedback is 3 as it highlights a critical area where the paper may lack originality, prompting the authors to consider how their work differs from existing literature. However, the comment could be more helpful if it provided specific suggestions on how the authors might address this issue or enhance the novelty of their contribution. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the authors use the complexity of checking on the Witness oracle, which is polynomial time in the tabular case, as a way to address the problem. However, it suggests that this approach is not direct enough. While the comment implies that the authors should find a more direct way to address the problem, it does not provide specific guidance or suggestions on how to achieve this. The action is implicit and somewhat vague, as the authors are left to infer that they need to find a more direct solution but without concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the authors\" use of the complexity of checking on the Witness oracle, which is described as \"polynomial time\" in the tabular case. However, it does not specify which part of the paper this discussion is located in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment also lacks specificity regarding what aspect of the approach is not direct or how it could be improved. As a result, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the authors\" approach to addressing the problem is not direct, specifically mentioning the complexity of checking on the Witness oracle. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this approach is not direct. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a potential issue with the authors\" approach to addressing the problem, specifically noting that using the complexity of checking on the Witness oracle as a solution feels indirect. However, the comment lacks specificity and does not provide any actionable suggestions or guidance on how the authors might improve their approach or address the issue more directly. Without detailed feedback or constructive advice, the authors are left without a clear path to enhance their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment expresses confusion about a statement in Theorem 5.1, suggesting that it might indicate a disadvantage of MMD DRO. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to clarify the statement, address the potential disadvantage, or improve the explanation of Theorem 5.1. Without any actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clarifies the confusion about the statement in Theorem 5.1, suggesting that it might indicate a disadvantage of MMD DRO. The comment provides a clear indication of what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point expresses confusion about a statement in Theorem 5.1, suggesting that it might indicate a disadvantage of MMD DRO. However, the comment does not provide any further explanation, reasoning, or examples to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the confusion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses confusion about a statement in Theorem 5.1, suggesting that it might indicate a disadvantage of MMD DRO. However, it does not provide any further explanation, reasoning, or suggestions on how the authors might clarify or address this potential issue. Without additional context or guidance, the authors are left without actionable feedback to improve their draft. Therefore, the comment is 1, as it does not offer any constructive direction for the authors to enhance their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper should provide more information on how to use morphologic segmentation across different domains and how it should be conducted differently for different domains. It also questions whether morphologic segmentation is invariant across domains. The comment implies that the paper lacks insight into these aspects and assumes invariance. While the comment identifies areas that need further exploration, it does not provide explicit instructions or concrete steps for the authors to follow. The action is implicit and somewhat vague, as the authors are left to infer what specific information should be added or clarified. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should provide more information on how to use morphologic segmentation across different domains and how it should be conducted differently for different domains. It also questions whether morphologic segmentation is invariant across domains. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where morphologic segmentation is discussed. The comment is specific in detailing what additional information is needed, such as insights into domain adaptation and the potential differences in morphologic segmentation across domains. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a claim about the lack of information on how to use morphologic segmentation across different domains and questions whether morphologic segmentation is invariant across domains. The comment suggests that the paper assumes invariance without providing insight into this aspect. However, the claim is not 5 as it lacks specific examples, references, or detailed reasoning to support the assertion that morphologic segmentation should be conducted differently for different domains. The authors would need more information to fully understand and address the critique. Therefore, the comment is categorized as 2.", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the use of morphologic segmentation across different domains and questions whether morphologic segmentation is invariant across domains. It suggests that the paper lacks insight into how morphologic segmentation should be conducted differently for different domains, which is an important consideration given the task domain adaptation. The comment highlights a critical area for improvement by pointing out the lack of discussion on this topic, which could help the authors enhance their draft. However, the comment could be more helpful if it provided specific suggestions or examples on how to address this issue. Overall, the feedback is 3 as it directs the authors to a specific area needing further exploration and clarification."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly asks for clarification regarding the object detection based attention, specifically whether it is performed on the image or on a convolutional feature map. It also suggests that the authors should clarify if any rescaling is done based on the receptive field to determine which image regions correspond to which spatial locations in the feature map. This feedback provides clear and explicit actions for the authors to take, ensuring they know exactly what needs to be clarified and how to address it. The comment is 5 as it offers concrete guidance on how to improve the draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"object detection based attention,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be clarified, namely whether the attention is performed on the image or on a convolutional feature map, and whether rescaling is done based on the receptive field. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a request for clarification regarding the object detection based attention, specifically whether it is performed on the image or on a convolutional feature map. It also asks about the rescaling process based on the receptive field. This is a factual request for clarification and does not contain any subjective claims or opinions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 5 as it identifies a specific area of confusion in the paper regarding the object detection based attention. It asks for clarification on whether the attention is performed on the image or on a convolutional feature map, and whether rescaling is done based on the receptive field. This feedback is clear and actionable, providing the authors with a precise direction to improve their draft by clarifying these aspects. By addressing these points, the authors can enhance the clarity and comprehensiveness of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly mentions the need for a discussion about the Set Transformer and other related works that use summary tokens. This provides a clear action for the authors to take, which is to include a discussion on these related works. However, the comment does not specify how this discussion should be integrated into the paper or what specific aspects should be covered. While the action is explicit, the lack of detailed guidance makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Set Transformer\" and provides a link to the relevant paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the missing discussion about related works that use summary tokens. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a discussion about the Set Transformer and other related works that use summary tokens. However, it does not provide any specific reasoning or evidence to support why this discussion is necessary or how it would enhance the paper. The reference to the Set Transformer paper is a factual statement and does not constitute a claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks discussion, namely the Set Transformer and other related works that use summary tokens. This feedback is clear and actionable, as it directs the authors to include a discussion on these related works, which could enhance the context and relevance of their own work. However, the comment could be more helpful if it provided specific suggestions on how to integrate this discussion or what aspects to focus on. Despite this, the feedback is 4 as it guides the authors toward a meaningful improvement in their draft. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the authors performed a statistical significance test when comparing the proposed method with baselines. While it implies that the authors should consider conducting such a test, the comment does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to conduct the test or what parameters to consider. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the statistical significance of the numbers presented in the paper, specifically when comparing the proposed method with baselines. However, it does not specify which part of the paper these numbers are found in, making it weakly grounded. The comment is specific in its request for a statistical significance test, but without clear grounding, the authors may struggle to identify the exact sections needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the statistical significance of the numbers presented in the paper, specifically when comparing the proposed method with baselines. However, it does not provide any supporting evidence, reasoning, or references to justify why a statistical significance test is necessary or how it could impact the results. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the statistical significance of the numbers presented in the paper, specifically when comparing the proposed method with baselines. This is a valid point that could impact the interpretation of the results and the overall validity of the findings. However, the comment lacks specificity and does not provide guidance on how to address this issue or what statistical tests might be appropriate. While it identifies a potential area for improvement, the feedback is somewhat vague and incomplete, making it 3. The authors are given a direction to consider but are not fully equipped with actionable steps to enhance their draft. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the choice of significance testing might be incorrect and proposes using a paired test setting, such as the Wilcoxon signedrank test, instead of the current method. While the comment implies that the authors should reconsider their choice of test, it does not explicitly instruct them to do so or provide detailed guidance on how to implement this change. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their test choice and potentially switch to a paired test setting. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the choice of significance testing and suggests that a paired test setting, such as the Wilcoxon signedrank test, might be more appropriate. However, it does not specify which part of the paper discusses significance testing, making it weakly grounded. The comment is specific in suggesting an alternative test setting, which provides clear guidance on what could be improved. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the choice of significance testing might be incorrect and suggests using a paired test setting, such as the Wilcoxon signedrank test. However, the comment does not provide any reasoning or evidence to support why the current choice is incorrect or why a paired test setting would be more appropriate. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the choice of significance testing in the paper, suggesting that a paired test setting, such as the Wilcoxon signedrank test, might be more appropriate. This feedback is 3 as it points out a specific area for improvement and provides a suggestion for a potential alternative. However, the comment lacks detailed guidance on why the current choice might be incorrect or how to implement the suggested change, which would make it more actionable. To be fully helpful, the comment could include more detailed reasoning or examples to support the suggestion. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the organization of the paper could be improved by providing more background knowledge on the proposed method and moving the description of related literature forward. However, it does not specify how the authors should achieve this improvement or what specific changes should be made. The action is implicit and lacks concrete guidance, leaving the authors uncertain about how to implement the suggested changes. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the organization of the paper could be improved by providing more background knowledge on the proposed method and moving the description of related literature forward. However, it does not specify which part of the paper is currently lacking in these aspects, making it difficult for the authors to pinpoint the exact sections that need revision. The comment is vague and lacks specific guidance, leaving the authors without a clear understanding of what needs to be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the organization of the paper could be improved by providing more background knowledge on the proposed method and moving the description of related literature forward. However, the comment does not provide specific examples or reasoning to support why these changes would improve the paper. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the organization of the paper, specifically suggesting that more background knowledge on the proposed method and a forward placement of related literature descriptions could enhance the paper. While the comment highlights a specific aspect that could be addressed, it lacks detailed guidance or suggestions on how to implement these changes. The feedback is 3 as it points out a general area for improvement, but it does not provide actionable steps or examples to help the authors make the necessary adjustments. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that some representative panoptic segmentation models, such as PanopticFPN, Mask2Former, etc., are not compared in the paper. While it identifies a specific area for improvement, it does not provide explicit guidance on which models should be included or how they should be integrated into the comparison. The action is implicit and somewhat vague, as the authors need to infer that they should include these models in their comparison. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights a specific issue by mentioning that \"Some other representative panoptic segmentation models are not compared, like PanopticFPN, Mask2Former, etc.\" However, it does not specify which part of the paper this comparison should be included in, such as a specific section or table. The authors can infer that it relates to the experimental results or methodology sections, but this inference is not explicit. The comment is specific in identifying the missing comparisons, but it lacks full grounding as it does not explicitly mention the relevant sections. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that \"Some other representative panoptic segmentation models are not compared, like PanopticFPN, Mask2Former, etc.\" However, it does not provide any reasoning or justification for why these models should be included in the comparison. Without specific examples or explanations of how these models would enhance the study, the claim lacks verifiability. The authors may infer that the models are relevant, but the comment does not provide sufficient evidence or context to support the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out that some representative panoptic segmentation models, such as PanopticFPN and Mask2Former, are not included in the comparison. This feedback is clear and actionable, as it provides a concrete suggestion for the authors to consider when expanding their experimental evaluation. However, the comment could be more helpful if it explained why these models are relevant or how their inclusion would enhance the study. Despite this, the feedback is 4 as it directs the authors to a specific area for improvement, providing them with a clear path to enhance their draft. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point expresses concern about the lack of explicit enforcement of diversity in the model, despite the extensive motivation for diversity in the paper. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how to incorporate diversity into the model or suggestions for improvements. As a result, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the title, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the discrepancy between the extensive motivation for diversity and the lack of explicit enforcement of diversity in the model. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper extensively motivates \"diversity\" but does not enforce it explicitly in the model. The reviewer expresses disappointment at the lack of diversity enforcement, suggesting that the authors\" efforts to incorporate diversity were not realized. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. Without detailed justification or evidence, the claim remains 3, as it provides a general critique but lacks the necessary depth to fully substantiate the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the lack of explicit enforcement of diversity in the model, despite the extensive motivation for diversity in the paper. This feedback is valuable as it highlights a potential gap between the theoretical framework and its practical implementation. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as proposing methods or techniques to incorporate diversity into the model. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 3, as it provides insight but lacks depth and specificity in its suggestions."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that some experiments are missing, specifically mentioning contrastive learning and adversarial learning. This provides a clear and direct action for the authors to take, which is to include these experiments in their study. The comment is explicit and concrete, as it specifies exactly what needs to be added to the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment mentions that \"some experiments are missing,\" specifically mentioning contrastive learning and adversarial learning. However, it does not specify which part of the paper these experiments should be included in, making it weakly grounded. The comment is specific in identifying the missing experiments, but without clear grounding, the authors may struggle to determine where these experiments should be integrated. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that \"some experiments are missing,\" specifically mentioning contrastive learning and adversarial learning. However, it does not provide any reasoning, examples, or references to support this claim. Without further explanation or evidence, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out that some experiments are missing, specifically mentioning contrastive learning and adversarial learning. This feedback is clear and actionable, as it provides the authors with a direct suggestion to enhance their study by including these experiments. However, the comment could be more helpful if it explained why these experiments are important or how they would contribute to the overall research. Despite this, the feedback is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should consider introducing inverse triples in other embedding models besides CP and test such cases in their experiments. However, it does not provide explicit instructions on how to implement this suggestion or what specific models should be tested. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to address the suggestion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should consider introducing inverse triples in other embedding models besides CP and test such cases in their experiments. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. Without explicit references, the authors may find it challenging to determine where to incorporate this suggestion. The comment is specific in suggesting a potential extension of the work but lacks grounding, as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that introducing inverse triples might be beneficial in other embedding models besides CP, but the authors did not test such cases in their experiments. This claim is 3 as it provides a logical suggestion for further exploration, but it lacks specific examples or references to other embedding models where inverse triples could be applied. The authors would need to infer the potential benefits and applications themselves, making the claim 3.", "helpfulness_rationale": "The review comment suggests that the authors should consider introducing inverse triples in other embedding models besides CP and test such cases in their experiments. This feedback is 3 as it identifies a potential area for expansion or exploration in the paper. However, the comment lacks specificity and does not provide detailed guidance on how to implement this suggestion or which other embedding models should be considered. While it points out a possible direction for improvement, it does not offer actionable steps or detailed advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the S2D structure, specifically why the number of parameters does not change despite an increase in depth. The reviewer acknowledges that the efficiency could be improved but suggests that more details are needed regarding the parameters. While the comment implies that the authors should provide additional information on the parameters, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"S2D structure,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue regarding the number of parameters not changing despite an increase in depth, and it suggests that more details are needed on the parameters. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the S2D structure, specifically why the number of parameters does not change despite an increase in depth. The reviewer acknowledges that the efficiency could be improved but suggests that more details are needed regarding the parameters. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion about the parameters. This makes the claim 3, as it provides a basis for the question but requires further elaboration or evidence to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific issue with the S2D structure, questioning why the number of parameters does not change despite an increase in depth. It acknowledges that the efficiency could be improved but suggests that more details are needed regarding the parameters. This feedback is 3 as it points out a potential area for clarification or improvement in the paper. However, it lacks specific suggestions or guidance on how the authors might address this issue, such as proposing alternative approaches or providing examples of how to present the parameter details. Therefore, while it highlights an area for improvement, it does not fully support the authors in making those improvements, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a limitation in the Atari game results, noting that they are limited to a single game and a single baseline, making it difficult to interpret. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to expand the results, what additional games or baselines to include, or how to improve the interpretability of the results. Without specific suggestions or instructions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 7.2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the limitation of the Atari game results, which are limited to a single game and a single baseline, making it difficult to interpret. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the Atari game result (Section 7.2) is limited to a single game and a single baseline, making it difficult to interpret. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific limitation in the Atari game results, noting that they are limited to a single game and a single baseline, which makes it difficult to interpret. This is a clear and actionable feedback that highlights a weakness in the paper\"s presentation of results. However, the comment does not provide suggestions or guidance on how the authors might address this limitation, such as recommending additional games or baselines to include or suggesting ways to improve the interpretability of the results. While it points out a significant issue, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight into a critical area for improvement but lacks detailed guidance for the authors to effectively address it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors might find it helpful to quantify and clarify the claim about ReLU not working well in deep or convolutional networks. It provides a specific example, the AlexNet paper, which used ReLUs and was considered deep and convolutional at the time. However, the comment does not explicitly instruct the authors to include this information or suggest how to quantify or clarify the claim. The action is implicit and somewhat vague, as the authors can infer that they should provide more context or evidence, but they are not given specific guidance on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors might find it helpful to quantify and clarify the claim about ReLU not working well in deep or convolutional networks. It provides a specific example, the AlexNet paper, which used ReLUs and was considered deep and convolutional at the time. However, the comment does not specify which part of the paper this claim is made in, making it weakly grounded. The suggestion to clarify and quantify the claim is specific, as it provides a concrete direction for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the claim about ReLU not working well in deep or convolutional networks could be clarified by referencing the AlexNet paper, which used ReLUs and was considered deep and convolutional at the time. This provides a specific example to support the claim, making it 3. However, the comment could be strengthened by providing more detailed reasoning or additional references to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors might find it helpful to quantify and clarify the claim about ReLU not working well in deep or convolutional networks. It provides a specific example, the AlexNet paper, which used ReLUs and was considered deep and convolutional at the time. This feedback is 3 as it offers a concrete example to consider when evaluating the claim, potentially leading the authors to provide more context or evidence to support their assertion. However, the comment could be more helpful if it included suggestions on how to quantify or clarify the claim further. Overall, the feedback provides some direction but lacks depth, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the introduction of two hyperparameters, k and \u03b7, which require finetuning. It suggests that this finetuning depends on the availability of the environment or a good OPE method. However, the comment does not provide any explicit guidance or suggestions on how the authors should address this issue. It lacks concrete details on what actions the authors should take to resolve the problem or improve the draft. As a result, the authors are left without a clear understanding of how to proceed, making the comment 1.", "grounding_specificity_rationale": "The comment addresses the introduction of two hyperparameters, k and \u03b7, and their dependence on finetuning, which is contingent on the availability of the environment or a good OPE method. However, it does not specify which part of the paper discusses these hyperparameters or where the issue of finetuning is mentioned. This lack of explicit reference to a specific section or part of the paper makes it weakly grounded. The comment is specific in detailing the issue with the hyperparameters and their dependence on finetuning, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point claims that the introduction of two hyperparameters, k and \u03b7, requires finetuning, which depends on the availability of the environment or a good OPE method. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the introduction of two hyperparameters, k and \u03b7, which require finetuning. It highlights the dependency on the availability of the environment or a good OPE method, suggesting that this could be a limitation. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or mitigate its impact. Without actionable advice or additional context, the feedback is 3, as it points out a potential concern but does not offer a clear path for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review comment indicates a potential issue with Figure 5, either suggesting that the reviewer does not understand it or that the labels are incorrect. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue, such as clarifying the labels or explaining the figure\"s content. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions \"Figure 5,\" which provides full grounding as it allows the authors to accurately identify the part of the paper being addressed. However, the comment lacks specificity because it does not explain what is unclear or what is wrong with the labels. It does not provide any guidance on how to address the issue or what needs to be clarified. Therefore, the comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point consists of a statement questioning the understanding of Figure 5 or the accuracy of its labels. It does not express an opinion, judgment, or suggestion that requires verification. It is purely descriptive and factual, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a concern about either the understanding of Figure 5 or the accuracy of its labels. However, it lacks specificity and does not provide any guidance or suggestions on how to address the issue. Without additional context or details, the authors are left without actionable feedback to improve their draft. The comment identifies a potential problem but does not offer any direction for resolution, making it 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the performance differences between methods are minimal across evaluations, with differences less than 1 percentage point. It also mentions that the benchmarks are outdated and likely saturated. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the issue of minimal performance differences or outdated benchmarks. Without actionable suggestions or recommendations, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the performance differences between methods and the minimal variations across evaluations. It also references the outdated nature of the benchmarks, providing a specific reason for concern. This allows the authors to accurately identify the parts of the paper being addressed. The comment is specific because it details the issue of minimal performance differences and the outdatedness of the benchmarks, providing a clear direction for improvement. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance differences between methods are minimal, with variations less than 1 percentage point, and attributes this to random variation. It also mentions that the benchmarks are outdated and likely saturated. The claim is 3 as it provides a logical explanation for the minimal performance differences, but it lacks specific examples or references to substantiate the claim about the outdatedness of the benchmarks. Including references to studies or benchmarks that support the assertion about saturation would strengthen the verifiability of the comment. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s results, noting that the performance differences between methods are minimal, with variations less than 1 percentage point. It attributes this to random variation and suggests that the benchmarks are outdated and likely saturated. While the comment highlights a concern, it lacks actionable suggestions or guidance on how the authors might address this issue or improve their methodology. Without specific recommendations or a clear path forward, the feedback is 3, as it points out a potential weakness but does not provide detailed advice for improvement. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two areas for improvement in the experiments section. First, it suggests that the discussion lacks interpretive insights that would explain why the proposed gyrostructures outperform existing methods. Second, it points out the absence of comparisons with other stateoftheart methods that do not rely on gyrostructures, which could provide a clearer understanding of the proposed approach\"s performance. While the comment identifies specific areas for improvement, it does not provide explicit guidance on how to address these issues or what specific comparisons or insights should be included. The actions are implicit and somewhat vague, as the authors need to infer the exact steps to take to improve the discussion and comparisons. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiments part,\" allowing the authors to accurately identify the section being addressed. It is also specific because it details what is missing in the discussion, namely interpretive insights that would explain the superiority of the proposed gyrostructures over existing methods. Additionally, it points out the lack of comparison with other stateoftheart methods that might not rely on gyrostructures, which could provide a clearer understanding of the proposed approach\"s performance. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the related discussion lacks interpretive insights to explain why the proposed gyrostructures outperform existing methods. It also notes the absence of comparisons with other stateoftheart methods that might not rely on gyrostructures, which could provide a clearer understanding of the proposed approach\"s performance. While the comment identifies a gap in the discussion, it does not provide specific examples or references to support the claim that simpler or more commonly used techniques might outperform the proposed approach. The lack of detailed evidence or examples makes the claim 3, as the authors would need to infer the potential issues and address them themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific areas for improvement in the experiments section. First, it points out the lack of interpretive insights in the discussion, which would help explain why the proposed gyrostructures outperform existing methods. Second, it notes the absence of comparisons with other stateoftheart methods that might not rely on gyrostructures, which could provide a clearer understanding of the proposed approach\"s performance. These observations are clear and actionable, as they guide the authors to enhance the interpretability of their results and broaden the scope of their comparisons. However, the comment could be more helpful if it provided specific suggestions on how to incorporate these insights or comparisons. Overall, the feedback is 4, as it directs the authors to important areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the potential impact of regularization effects rather than distillation on the improvements in the teacher\"s performance. It suggests that the authors should conduct proper ablation studies to verify their claims. While the comment implies that the authors should conduct additional experiments, it does not provide specific guidance on how to design these experiments or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the need for additional experiments and determine the specifics themselves. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific aspect of the paper being addressed, namely the case where the student distills knowledge to the teacher, which improves the teacher\"s performance. It also specifies the issue by pointing out that the improvements could be due to regularization effects rather than distillation, as all finetuning is performed for 10 epochs without earlystopping. The comment further suggests that proper ablation studies are needed to verify the claims. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the improvements in the teacher\"s performance could be due to regularization effects rather than distillation, as all finetuning is performed for 10 epochs without earlystopping. The reviewer suggests that proper ablation studies are needed to verify this claim. While the comment provides a logical reasoning for the potential issue, it lacks specific examples or references to support the claim fully. The suggestion for ablation studies is a reasonable next step, but the comment could be strengthened by providing more detailed evidence or examples. Therefore, the claim is 3, as it requires additional information to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s claim that improvements in the teacher\"s performance are due to distillation rather than regularization effects. It points out that all finetuning is performed for 10 epochs without earlystopping, which could lead to high variances in the results. The comment suggests that proper ablation studies are needed to verify the claims, which is a clear and actionable piece of feedback. However, the comment could be more helpful if it provided specific suggestions on how to conduct these ablation studies or what aspects to focus on. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper lacks insights into why selfsupervised learning is needed on 360 video data with spatial audio. However, it does not provide explicit guidance or concrete suggestions on how the authors might address this issue. The comment implies that the authors should provide more justification or explanation, but it does not specify what kind of insights or reasoning should be included. As a result, the action is implicit and vague, leaving the authors uncertain about how to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the lack of insights into why selfsupervised learning is needed on 360 video data with spatial audio. However, it does not specify which part of the paper this issue pertains to, such as a specific section or experiment. This makes it difficult for the authors to pinpoint the exact area that needs attention. The comment is specific in its critique of the lack of insights but lacks grounding, as it does not clearly identify the part of the paper being discussed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks insights into why selfsupervised learning is needed on 360 video data with spatial audio. However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. The comment lacks specific details or references that would help the authors understand the basis of the critique or how to address it. As a result, the claim is 1, as it does not provide sufficient information for the authors to make improvements based on the feedback. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the need for selfsupervised learning on 360 video data with spatial audio. It points out that the paper lacks insights into why this approach is valuable, which is a valid critique. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what additional insights could be provided. While it highlights an area for improvement, the feedback lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a gap in the analysis, noting that only the SimCLR case is covered and suggesting that the projection head, which is an important part of the approach, should be analyzed. However, it does not provide explicit guidance on how to conduct this analysis or what specific aspects of the projection head should be examined. The action is implicit and somewhat vague, as the authors can infer that they need to expand their analysis to include the projection head, but they are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the SimCLR case,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of analysis on the projection head, which is an important aspect of the SimCLR approach. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that only the SimCLR case is covered and suggests that the projection head, an important part of the approach, should be analyzed. However, the comment does not provide specific references or examples of recent papers that show the importance of the projection head, nor does it explain why this aspect is crucial. This lack of detailed justification or references makes the claim 3, as the authors would need to independently investigate the significance of the projection head to fully understand and address the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific gap in the analysis by noting that only the SimCLR case is covered and suggests that the projection head, an important aspect of the approach, should be analyzed. This feedback is clear and actionable, as it directs the authors to expand their analysis to include a critical component of the SimCLR approach. However, the comment could be more helpful if it provided specific suggestions on how to analyze the projection head or referenced relevant literature on this topic. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft, but it could be more comprehensive with additional guidance or references."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the paper lacks additional necessary experiments, including comparison experiments, ablation studies, and hyperparameter analysis. This provides a clear and direct action for the authors to take, which is to conduct these additional experiments to enhance the paper. The comment is specific and provides concrete guidance on what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of additional necessary experiments, including comparison experiments, ablation studies, and hyperparameter analysis. This allows the authors to accurately identify the part of the paper being addressed, which is the experimental section. The comment is also specific because it clearly specifies what is missing in the experiments, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks additional necessary experiments, including comparison experiments, ablation studies, and hyperparameter analysis. However, it does not provide any specific examples, reasoning, or references to support this claim. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. This feedback is clear and actionable, as it provides specific areas where the authors can enhance their work by conducting additional experiments. However, the comment could be more helpful if it offered suggestions on which specific comparisons or ablations should be conducted or how to analyze hyperparameters. Despite this, the comment is 4 as it directs the authors to a critical area for improvement, providing a clear path for enhancing the draft."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the experimental results, noting that the proposed method does not have an advantage over the stateoftheart (SOTA) without prior information. It suggests that the comparison is unfair because the proposed method requires two representation models, VAE/GAN and CL, which adds complexity and cost. While the comment identifies a potential issue with the experimental setup, it does not provide explicit guidance on how the authors should address this concern or improve their draft. The action is implicit and somewhat vague, as it lacks specific suggestions on how to adjust the experiments or present the results to address the issue. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental results\" and the \"proposed method,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the comparison, noting that the proposed method does not have an advantage without prior information and that the comparison is unfair due to the additional complexity and cost of using two representation models. The comment provides a clear basis for the authors to understand what needs to be addressed in their draft. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method does not have an advantage over the stateoftheart (SOTA) without prior information, and that the advantage only shows when using prior knowledge. The reviewer provides a logical reasoning by pointing out that the proposed method requires two representation models, VAE/GAN and CL, which adds complexity and cost. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the experimental results, noting that the proposed method does not have an advantage over the stateoftheart (SOTA) without prior information. It points out that the advantage only appears when using prior knowledge, which is considered unfair because it requires two representation models (VAE/GAN and CL) for each dataset. This feedback highlights a critical flaw in the experimental setup and suggests that the complexity and cost of the proposed method should be considered. While the comment effectively identifies a weakness, it could be more helpful by offering suggestions on how to address this issue, such as adjusting the experimental design or providing a more balanced comparison. Overall, the comment is 3 as it provides valuable insights but lacks actionable guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment raises concerns about the adhoc nature of the regularization term and suggests that the authors provide theoretical support for it. It also implies that other statistics, such as the median, could be used to replace the mean and standard deviation in the regularization. While the comment identifies areas for improvement, it does not explicitly instruct the authors to make specific changes or provide detailed guidance on how to address the issues. The action is implicit and somewhat vague, as the authors can infer that they need to provide theoretical justification and consider alternative statistics, but they are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"regularization term,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear critique of the adhoc nature of the regularization term and suggests alternative statistics, such as the median, that could be used instead of the mean and standard deviation. The comment also raises a question about why these alternatives were not considered, which further specifies the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the regularization term is adhoc and lacks theoretical support, suggesting that other statistics, such as the median, could be used instead of the mean and standard deviation. The comment provides a logical reasoning by pointing out the potential sensitivity of the mean to outliers, which could impact the regularization. However, it lacks specific examples or references to other statistics that could be used, making the claim 3. The authors would need to explore these alternatives themselves to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the regularization term, noting that it appears adhoc and lacks theoretical support. It suggests that other statistics, such as the median, could be used to replace the mean and standard deviation in the regularization, which could provide a more robust and theoretically grounded approach. The comment also raises a question about why these alternatives were not considered, which encourages the authors to explore and justify their choice of regularization. This feedback is clear and actionable, providing the authors with a specific direction for improvement by suggesting alternative statistical methods and prompting them to address the theoretical basis of their regularization term. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to discuss the iteration cost (computational budget) of the proposed method and suggests including the iteration cost of related methods, including baseline methods. This provides a clear and direct action for the authors to take, specifying what needs to be discussed and which methods should be considered. The feedback is concrete and actionable, as it gives the authors a specific task to address in their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need to discuss the iteration cost (computational budget) of the proposed method and related methods, including baseline methods. This allows the authors to accurately identify the part of the paper that needs revision. The comment is also specific because it clearly specifies what needs to be addressed, namely the iteration cost of the proposed method and related methods. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should discuss the iteration cost (computational budget) of the proposed method and related methods, including baseline methods. This is a request for additional information or analysis, rather than a claim or opinion that requires verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to include a discussion on the iteration cost (computational budget) of the proposed method and related methods, including baseline methods. This feedback is valuable as it highlights an important aspect that could enhance the comprehensiveness and rigor of the paper. By addressing this point, the authors can provide a more complete analysis of the computational efficiency of their method, which is crucial for practical applications. However, the comment could be more helpful if it offered specific guidance on how to present this information or suggested potential methods for estimating iteration costs. Overall, the comment is 4 as it directs the authors to an area that could significantly improve their draft, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly points out that the VAD description is puzzling and suggests that it is not a true VAD because it discards TF bins with a magnitude less than epsilon, which results in a division by zero. The reviewer clarifies that a VAD should look for the presence of speech and is typically defined over time, not frequency. This feedback provides a clear and direct action for the authors to reconsider their VAD description and ensure it aligns with the true definition of a VAD. The comment is explicit and provides concrete guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Your VAD description,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is puzzling about the VAD description and provides a detailed explanation of what a VAD should entail. The comment explains that the VAD is not properly defined and suggests that it is not a true VAD because it discards TF bins with a magnitude less than epsilon, which results in a division by zero. It also clarifies that a VAD should look for the presence of speech and is typically defined over time, not frequency. This level of detail provides clear guidance on what needs to be addressed in the VAD description, making the comment 5.", "verifiability_rationale": "The review point claims that the VAD description is puzzling and suggests that it is not a true VAD because it discards TF bins with a magnitude less than epsilon, which results in a division by zero. The reviewer provides a clear explanation of what a VAD should entail, emphasizing that it should look for the presence of speech and is typically defined over time, not frequency. This reasoning is logical and provides a clear basis for the claim, making it 4. However, the comment could be strengthened by referencing specific examples or literature to further substantiate the claim, which would align with a score of 4.", "helpfulness_rationale": "The review comment provides a clear and specific critique of the VAD description in the paper, pointing out that it is puzzling and does not align with the true definition of a VAD. The reviewer explains that the VAD is not properly defined because it discards TF bins with a magnitude less than epsilon, which results in a division by zero. The comment also clarifies that a VAD should look for the presence of speech and is typically defined over time, not frequency. This feedback is 5 as it identifies a significant issue with the VAD description and provides clear guidance on how to address it. By pointing out the discrepancy between the VAD description and its actual implementation, the comment empowers the authors to make necessary corrections and improvements to their draft. Therefore, the comment is rated as 5."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that including results on ImageNet could make the proposed method more convincing. However, it does not provide explicit guidance on how to achieve this or what specific results should be included. The action is implicit and somewhat vague, as the authors are left to infer that they should conduct experiments on ImageNet but are not given detailed instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that including results on ImageNet could make the proposed method more convincing. However, it does not specify which part of the paper should include these results or how they would enhance the method\"s credibility. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine where to incorporate these suggestions. The comment is 1 and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1.", "verifiability_rationale": "The review point suggests that including results on ImageNet could make the proposed method more convincing. However, it does not provide any reasoning, examples, or references to support why ImageNet results would be more convincing or how they would enhance the method\"s credibility. The comment lacks specific details or evidence to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that including results on ImageNet could make the proposed method more convincing. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on how to incorporate ImageNet results or what specific aspects of the method could be enhanced by these results. The feedback is 3 as it points out a direction for improvement, but it does not offer actionable steps or detailed suggestions, leaving the authors with limited guidance on how to address the suggestion. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the insufficient contribution of the paper, specifically noting that while the authors studied the connection between complementary and model robustness, they did not explore how to leverage this connection to improve robustness. The reviewer suggests that the paper should include more insightful findings or possible solutions beyond the analysis of the connection. While the comment implies that the authors should expand their work to provide more insights, it does not explicitly instruct them on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to add more depth to their findings. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the contribution of the paper, specifically critiquing the lack of further studies on how to leverage the connection between complementary and model robustness to improve robustness. It suggests that the paper should include more insightful findings or possible solutions beyond the analysis of the connection. However, the comment does not explicitly mention which part of the paper this critique pertains to, such as a specific section or analysis. The authors can infer that it relates to the conclusion or discussion sections, but this inference is not as direct as it could be. The comment is specific in detailing what is missing, but it lacks full grounding because it does not specify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the contribution of the paper is insufficient, specifically noting that the authors studied the connection between complementary and model robustness but did not explore how to leverage this connection to improve robustness. The reviewer suggests that the paper should include more insightful findings or possible solutions beyond the analysis of the connection. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion that the conclusion could be easily obtained. This makes the claim 3, as it requires further elaboration or evidence to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, specifically the lack of contribution beyond the analysis of the connection between complementary and model robustness. It points out that the paper does not explore how to leverage this connection to improve robustness, which is a critical area for further study. The comment suggests that the paper should include more insightful findings or possible solutions, which would enhance its contribution. While the feedback is clear and highlights an important area for improvement, it could be more helpful if it provided specific suggestions or examples of what additional insights or solutions could be explored. Overall, the comment is 4 as it directs the authors to a key area for enhancing their work, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a lack of clarity regarding the connection between the theoretical analysis and the proposed method, specifically questioning how the proposed method enhances generalization for distant nodes. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve the clarity of the connection. The comment implies that the authors should clarify the relationship between the theoretical analysis and the proposed method, but it lacks concrete steps or examples on how to do so. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the connection between the theoretical analysis and the proposed method, specifically questioning how the proposed method enhances generalization for distant nodes. However, it does not specify which part of the paper discusses the theoretical analysis or the proposed method, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its critique of the connection between theory and application, but it lacks grounding as it does not direct the authors to a particular part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the connection between the theoretical analysis and the proposed method is unclear, specifically questioning how the proposed method enhances generalization for distant nodes. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential disconnect between the theoretical analysis and the proposed method, specifically questioning how the proposed method enhances generalization for distant nodes. It highlights a lack of clarity in the connection between theory and application, which is an important area for improvement. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or enhance the clarity of the connection. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight but lacks depth and specificity in its feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point identifies a specific error in the authors\" statement regarding the Induction, Duplicate Token, and Previous Token heads in the base IOI circuit. It corrects the authors\" claim by stating that these heads are active at the S2 token but do not primarily attend to it. This feedback is explicit and provides a clear correction, allowing the authors to make the necessary changes to their draft. The action is concrete, as it specifies the exact wording that needs to be corrected. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3 of Wang et al., 2023,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the error in the authors\" statement regarding the Induction, Duplicate Token, and Previous Token heads in the base IOI circuit. The comment provides a correction to the authors\" claim, which is detailed and actionable. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors\" statement regarding the Induction, Duplicate Token, and Previous Token heads in the base IOI circuit is incorrect, as it contradicts the findings in Section 3 of Wang et al., 2023. The comment provides a specific reference to an external source, which is a common method of verification. This reference allows the authors to verify the claim and understand the basis of the correction. Therefore, the comment is considered 5.", "helpfulness_rationale": "The review comment identifies a specific error in the authors\" statement regarding the Induction, Duplicate Token, and Previous Token heads in the base IOI circuit. It corrects the authors\" claim by pointing out that these heads are active at the S2 token but do not primarily attend to it, as stated in Section 3 of Wang et al., 2023. This feedback is clear and actionable, providing the authors with a precise correction to make in their draft. By addressing this error, the authors can improve the accuracy and clarity of their paper. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment questions the rationale behind the choice of a noncentral chisquared distribution for the eta_ri term. However, it does not provide any explicit or implicit guidance on how the authors should address this issue or what changes they should make to clarify the reasoning. The comment lacks actionable details, such as suggesting alternative explanations or methods for justifying the choice. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment questions the choice of a noncentral chisquared distribution for the eta_ri term, but it does not specify which part of the paper discusses this term or where it is introduced. This makes it difficult for the authors to pinpoint the exact section that needs clarification. Additionally, the comment lacks specificity regarding what is unclear about the choice of distribution or how it could be clarified. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point questions the choice of a noncentral chisquared distribution for the eta_ri term, but it does not provide any supporting evidence, reasoning, or references to justify why this choice is unclear or problematic. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment questions the choice of a noncentral chisquared distribution for the eta_ri term, indicating that it is unclear why this distribution was selected. However, the comment does not provide any further explanation, reasoning, or suggestions for improvement. Without additional context or guidance, the authors are left without a clear understanding of what aspect of the choice is unclear or how they might address it. This lack of specificity and actionable feedback makes the comment 2, as it does not offer meaningful guidance for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the lack of speed analysis in the experiments, specifically noting the absence of comparisons between the proposed network and prior work regarding inference speed. It suggests that the improvement in inference speed would be more interesting than reducing FLOPs. While the comment implies that the authors should include speed analysis and comparisons, it does not provide explicit instructions on how to conduct these analyses or what specific metrics to use. The action is implicit and somewhat vague, as the authors need to infer the need for speed analysis and determine how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of speed analysis in the experiments, specifically noting the absence of comparisons between the proposed network and prior work regarding inference speed. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what is missing, namely the comparison of inference speed and the suggestion that such an analysis would be more interesting than reducing FLOPs. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the lack of speed analysis in the experiments is a weakness, noting that the experiments only compare GFLOPs of different segmentation networks but not the inference speed. The reviewer suggests that the improvement in inference speed would be more interesting than reducing FLOPs. While the comment highlights a potential area for improvement, it lacks specific examples or references to support the claim that inference speed is more important than FLOPs. The reasoning is somewhat logical but could be strengthened with additional evidence or examples. Therefore, the comment is 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the lack of speed analysis in the experiments. It points out that while the experiments compare GFLOPs of different segmentation networks, there is no comparison of inference speed between the proposed network and prior work. The comment suggests that the improvement in inference speed would be more interesting than reducing FLOPs. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their work by including speed analysis. However, it could be more helpful if it offered suggestions on how to conduct the speed analysis or what metrics to use. Overall, the comment is 4, as it effectively guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the proposed method is not wellpositioned in the literature and suggests that the authors conduct a thorough literature review to understand the context better. It mentions that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is wellknown and has been used in various works, such as denoising score matching and scoreinterpolation. While the comment implies that the authors should conduct a literature review, it does not provide specific guidance on how to conduct this review or which works to focus on. The action is implicit and somewhat vague, as the authors know they need to conduct a literature review but lack detailed instructions on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that this idea is wellknown and has been used in various works, such as denoising score matching and scoreinterpolation. The comment further suggests that the authors conduct a thorough literature review to understand the context better. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed method is not wellpositioned in the literature and suggests that the key idea behind it is wellknown. The reviewer supports this claim by referencing specific works, such as denoising score matching and scoreinterpolation, where this idea has been used. This provides a clear basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed references or examples to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed method, noting that it is not wellpositioned in the literature. It points out that the key idea behind the method, representing the marginal score as the expectation of scores of distributions conditioned on inputs, is wellknown and has been used in various works, such as denoising score matching and scoreinterpolation. The comment suggests that the authors conduct a thorough literature review to understand the context better. While the feedback highlights an important area for improvement, it could be more helpful by providing specific examples or references to guide the authors in their literature review. Overall, the comment is 3 as it directs the authors to a critical area for improvement but lacks detailed guidance, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point expresses curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. However, it does not provide any explicit or implicit action for the authors to take. There is no guidance on whether the authors should investigate this combination, include it in their analysis, or address it in any way. The comment lacks actionable details, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. However, it does not specify which part of the paper this curiosity pertains to, such as a specific section or analysis where this combination could be discussed. Without explicit references to sections or figures, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the performance or combination are of interest. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. However, it does not contain any claims, opinions, or suggestions that require verification. It is a factual statement expressing interest in a specific combination, which does not necessitate any justification or evidence. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment expresses curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. While it acknowledges that this is not necessary, it prompts the authors to consider this combination, which could potentially lead to a deeper understanding of their work. However, the comment lacks specificity and does not provide any guidance on how the authors might explore this combination or what aspects of the performance should be evaluated. Without actionable suggestions or detailed feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper would benefit from a more detailed discussion of related work, including not only describing the related works but also discussing the differences to the presented work. While the comment implies that the authors should expand their discussion of related work, it does not provide specific guidance on how to achieve this or what aspects to focus on. The action is implicit and somewhat vague, as the authors are left to infer the details of how to implement the suggested improvement. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Related Work,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: a more detailed discussion of related work, including not only describing the related works but also discussing the differences to the presented work. This provides clear guidance on how to improve the paper. Therefore, the comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point suggests that the paper would benefit from a more detailed discussion of related work, including not only describing the related works but also discussing the differences to the presented work. This claim is 3 as it provides a logical reasoning for why a more detailed discussion would be beneficial, particularly in terms of distinguishing the work from existing literature. However, the comment lacks specific examples or references to existing work that could be used to illustrate the differences, which would strengthen the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the discussion of related work. It suggests that the authors should provide a more detailed discussion, not only describing the related works but also discussing the differences to the presented work. This feedback is clear and actionable, as it guides the authors on how to enhance the depth and relevance of their related work section. By following this advice, the authors can better position their work within the existing literature and provide a more comprehensive context for their research. However, the comment could be more helpful if it included specific examples or suggestions on how to structure the discussion or what aspects to focus on. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the experiments should be extended to include other architectures and classification tasks beyond neural networks and image classification. While the comment implies that the authors should expand their experiments, it does not provide specific guidance on which architectures or classification tasks to consider or how to implement these changes. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experiments should be extended to include other architectures and classification tasks beyond neural networks and image classification. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing revision. The comment is specific in suggesting the need for broader experimentation, but it is 1 because it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the experiments should be extended to include other architectures and classification tasks beyond neural networks and image classification. This is a request for additional experiments, which is not a claim but rather a suggestion for improvement. The comment does not contain any subjective opinions, judgments, or claims that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment suggests that the experiments should be extended to include other architectures and classification tasks beyond neural networks and image classification. This feedback is 3 as it points out a potential limitation in the scope of the experiments and encourages the authors to broaden their evaluation. However, the comment lacks specific guidance on which other architectures or classification tasks should be considered, leaving the authors with a general direction but no detailed steps to take. To be more helpful, the comment could include suggestions or examples of alternative architectures or tasks that might be relevant. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a potential issue with the algorithm, suggesting that the output depends on the order in which the data are processed. It explicitly instructs the authors to clarify this aspect, providing a clear and direct action for improvement. The comment is specific and concrete, as it tells the authors exactly what needs to be addressed and how to do so. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the output from the algorithm depends on the order in which the data are processed. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue of data processing order affecting the output, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact part of the paper that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the output from the algorithm depends on the order in which the data are processed. However, it does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the algorithm, suggesting that the output depends on the order in which the data are processed. This is a critical observation that could impact the reliability and reproducibility of the results. However, the comment lacks specificity and does not provide guidance on how the authors might address this issue or clarify the dependency. Without actionable suggestions or examples, the feedback is 3 as it points out a potential problem but does not fully support the authors in resolving it. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the impact of mitigation strategies on the overall performance of the model, suggesting that there might be a tradeoff between reducing a particular behavior and maintaining high performance. However, it does not provide explicit guidance or suggestions on how the authors should address this concern or evaluate the impact of these strategies. The comment implies that the authors should consider the potential negative effects of these strategies on the model\"s utility, but it lacks concrete steps or actions for the authors to take. As a result, the comment is vague and does not provide actionable advice, making it barely actionable.", "grounding_specificity_rationale": "The comment addresses the impact of mitigation strategies on the overall performance of the model, specifically questioning whether these strategies might significantly impair the model\"s utility. However, it does not specify which part of the paper discusses these mitigation strategies or where the authors should consider their impact. The authors can infer that it relates to the sections discussing model performance or mitigation strategies, but the comment lacks full grounding as it does not explicitly mention these sections. The comment is specific in detailing the concern about the tradeoff between reducing a particular behavior and maintaining high performance, but it does not provide detailed guidance on how to address this issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the impact of mitigation strategies on the overall performance of the model, suggesting that there might be a tradeoff between reducing a particular behavior and maintaining high performance. The comment provides a logical reasoning by stating that if these mitigation strategies significantly impair the model\"s utility, it might deter their adoption. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to further explore and substantiate the potential tradeoffs themselves to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the impact of mitigation strategies on the overall performance of the model. It highlights a potential tradeoff between reducing a particular behavior and maintaining high performance, which is an important consideration for the authors to address. However, the comment does not provide specific suggestions or guidance on how the authors might evaluate or mitigate this tradeoff. While it identifies a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the use of 6fold crossvalidation in the paper, questioning the necessity of this approach given that other papers in the field do not use crossvalidation. While the comment implies that the authors should provide a justification for their choice of crossvalidation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to explain the rationale behind their methodological choice. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of 6fold crossvalidation for each dataset, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the necessity of crossvalidation, given that other papers in the field do not use it. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the necessity of using 6fold crossvalidation, noting that other papers in the field do not use it. This claim is 3 as it provides a logical reasoning based on the absence of crossvalidation in other papers. However, the comment lacks specific references to these other papers or detailed explanations of why crossvalidation is not necessary in this context. Providing more detailed evidence or examples would strengthen the verifiability of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of 6fold crossvalidation in the paper, questioning its necessity given that other papers in the field do not use it. This feedback is 3 as it prompts the authors to consider whether their choice of methodology is justified and to provide a rationale for their approach. However, the comment could be more helpful if it offered suggestions on how to address this issue, such as providing a justification for the use of crossvalidation or exploring alternative methods. Overall, the comment provides some direction for improvement but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the method, ODA, has learned a policy to imitate problemsolving but does not clearly explain how it improves performance and computation speed compared to just using ODA. While the comment identifies a gap in the explanation, it does not provide explicit guidance on how the authors should address this issue. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide a clearer explanation of the method\"s advantages. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ODA,\" one of the methods for solving the MOIP problem, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the method has learned a policy to imitate problemsolving but does not clearly explain how it improves performance and computation speed compared to just using ODA. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the method, ODA, has learned a policy to imitate problemsolving but does not clearly explain how it improves performance and computation speed compared to just using ODA. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 2, as it provides some insight but requires more detailed justification to be 5.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the method, ODA, has learned a policy to imitate problemsolving but does not clearly explain how it improves performance and computation speed compared to just using ODA. This feedback is 3 as it points out a gap in the explanation of the method\"s advantages, prompting the authors to provide a clearer justification for their approach. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of how other methods have improved performance. Overall, the comment is 3 as it directs the authors\" attention to an area needing clarification but lacks depth and actionable guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the sampling performed to obtain different initializations x_0 and its impact on convergence to the optimum. It notes that this aspect is not experimentally evaluated carefully on the proposed benchmarks, except for a comparison in Table 1 of the supplementary material. While the comment identifies an area for improvement, it does not provide explicit guidance on how the authors should address this issue or what specific experiments or analyses should be conducted. The action is implicit and somewhat vague, as the authors are left to infer that they need to conduct more thorough experiments to evaluate the impact of sampling on convergence. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Tab. 1 in supplementary,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the sampling performed to obtain different initializations x_0 and its impact on convergence to the optimum. The comment further specifies that this aspect is not experimentally evaluated carefully on the proposed benchmarks, except for a comparison in Table 1 of the supplementary material. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with a score of 5.", "verifiability_rationale": "The review point claims that the sampling performed to obtain different initializations x_0 is important for convergence to the optimum but is not experimentally evaluated carefully on the proposed benchmarks. The reviewer supports this claim by referencing Table 1 in the supplementary material, where the sampling is compared to sampling from a uniform distribution. This provides some evidence to substantiate the claim, making it 4. However, the comment could be strengthened by providing more detailed analysis or examples of how the sampling affects convergence. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the sampling performed to obtain different initializations x_0 and its impact on convergence to the optimum. It notes that this aspect is not experimentally evaluated carefully on the proposed benchmarks, except for a comparison in Table 1 of the supplementary material. This feedback is clear and actionable, as it highlights a gap in the experimental evaluation and suggests that the authors should conduct more thorough experiments to assess the impact of sampling on convergence. However, the comment could be more helpful if it provided specific suggestions on how to conduct these experiments or what metrics to focus on. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that it would be interesting to see how the model works for tabular data, although it is not necessary. While the comment implies that the authors should consider exploring this aspect, it does not provide explicit guidance on how to do so or what specific steps to take. The action is implicit and somewhat vague, as the authors are left to infer that they should investigate the model\"s performance on tabular data but without detailed instructions on how to proceed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests exploring the model\"s performance on tabular data, which is a specific area of interest. However, it does not explicitly mention which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the discussion of multimodal data, but this inference is not as direct as it could be. The comment is specific in suggesting an area for exploration, but it lacks full grounding because it does not specify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it would be interesting to explore the model\"s performance on tabular data, which is a form of multimodal data. However, the comment does not provide any specific reasoning, examples, or references to support why this exploration would be beneficial or how it might impact the paper. Without additional context or justification, the claim remains vague and difficult for the authors to understand or address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests exploring the model\"s performance on tabular data, which is a form of multimodal data. While the suggestion is interesting and could provide additional insights into the model\"s versatility, it lacks specificity and actionable guidance. The comment does not explain why this exploration would be beneficial or how it might impact the paper\"s findings. Without detailed instructions or a clear rationale, the authors may find it challenging to prioritize this suggestion over other potential improvements. Therefore, the comment is 3, as it provides a direction for further exploration but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors provide more details on using attention, possibly as an extra appendix. While it implies that the authors should include additional information, it does not specify what specific details should be added or how they should be presented. The action is implicit and somewhat vague, as the authors need to infer that they should add more details on attention and where to include them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests adding more details on using attention, possibly as an extra appendix. However, it does not specify which part of the paper currently lacks these details or where the authors should include them. The authors might infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in suggesting the addition of more details on attention, but it lacks grounding as it does not pinpoint a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more details on using attention would be beneficial, possibly as an extra appendix. However, it does not provide any specific reasoning, examples, or references to support why this additional information is necessary or how it would enhance the paper. Without further explanation or evidence, the claim lacks verifiability, making it difficult for the authors to understand the need for these details. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the authors provide more details on using attention, possibly as an extra appendix. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on what additional details should be included or how they might enhance the paper. The comment is 3 as it points out a gap in the paper but does not offer actionable advice or detailed suggestions for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about why explicit methods perform better than implicit methods on locomotion tasks and notes the absence of pseudocode for the proposed method. It provides two references, 1 and 2, which could be helpful for the authors in understanding the context of the question. However, the comment does not explicitly instruct the authors to include the pseudocode or provide guidance on how to address the question about the performance difference. The action is implicit and somewhat vague, as the authors need to infer that they should include the pseudocode and address the performance question. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the performance difference between explicit and implicit methods on locomotion tasks and notes the absence of pseudocode for the proposed method. It provides references to relevant literature, which could help the authors understand the context of the question. However, the comment does not specify which part of the paper discusses the explicit and implicit methods, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in its request for the pseudocode and the explanation of the performance difference, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the performance difference between explicit and implicit methods on locomotion tasks and notes the absence of pseudocode for the proposed method. It provides references to relevant literature, which can help the authors understand the context of the question. However, the comment does not provide specific reasoning or evidence to support why the explicit methods perform better, nor does it explain how the absence of pseudocode impacts the understanding of the proposed method. This makes the claim 3, as it lacks detailed justification or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the performance difference between explicit and implicit methods on locomotion tasks, which is a relevant and important point for the authors to address. It also notes the absence of pseudocode for the proposed method, which is a critical omission that could help clarify the methodology. The comment provides references to relevant literature, which can guide the authors in understanding the context of the question and potentially inform their response. However, the comment could be more helpful if it included specific suggestions on how to address the performance question or how to present the pseudocode. Overall, the comment is 3 as it identifies a significant gap in the paper and provides some direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point identifies specific issues with the convoluted nature of the results description, providing examples of unnecessarily complex language. It also suggests that the authors should consider related work on speakerlistener communication from a teachability perspective, as well as checking for useful communication in light of a specific reference. The comment includes concrete suggestions for improvement, such as referencing specific papers and checking for meaningful differences in figures. This provides clear and actionable guidance for the authors, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific examples of convoluted language in the results description, allowing the authors to accurately identify the parts of the paper being addressed. It also provides specific suggestions for improvement, such as considering related work on speakerlistener communication and checking for useful communication in light of specific references. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results description is unnecessarily convoluted, providing an example of complex language. It suggests considering related work on speakerlistener communication and checking for useful communication in light of specific references. The comment is 4 as it provides specific examples of convoluted language and references relevant literature, which can help the authors understand and address the issue. However, the claim could be strengthened by providing more detailed reasoning or examples of how the convoluted language affects the clarity of the results. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the convoluted nature of the results description, providing an example of unnecessarily complex language. It offers actionable suggestions for improvement by recommending related work on speakerlistener communication and checking for useful communication in light of specific references. This feedback is clear and provides concrete steps for the authors to enhance the clarity and relevance of their results. However, the comment could be more helpful if it included additional guidance on how to simplify the language or integrate the suggested references into the paper. Overall, the comment is 4 as it directs the authors toward specific areas for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises several issues with the experimental validation, including the lack of consideration for deeper networks and the absence of a description of the optimization strategy, particularly the grid search for hyperparameter selection. It also mentions a minor issue with the positioning of the work with respect to related works, specifically the consideration of layer redundancy in network pruning. The comment provides a specific reference to a related work that addresses layer redundancy, which could help the authors better position their work. While the comment identifies several areas for improvement, it does not explicitly instruct the authors on how to address these issues, such as suggesting specific experiments or changes to the optimization strategy. The action is implicit and somewhat vague, as the authors need to infer the specific actions needed to improve their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses several issues with the experimental validation, including the lack of consideration for deeper networks and the absence of a description of the optimization strategy, particularly the grid search for hyperparameter selection. It also mentions a minor issue with the positioning of the work with respect to related works, specifically the consideration of layer redundancy in network pruning. The comment provides a specific reference to a related work that addresses layer redundancy, which helps ground the comment by suggesting a relevant context for the authors to consider. However, the comment does not explicitly mention which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the consideration of deeper networks and the optimization strategy. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experimental validation is not convincing due to the lack of consideration for deeper networks and the absence of a description of the optimization strategy, including the grid search for hyperparameter selection. It also mentions a minor issue with the positioning of the work with respect to related works, specifically the consideration of layer redundancy in network pruning. The comment provides a specific reference to a related work that addresses layer redundancy, which supports the claim about the positioning of the work. However, the comment lacks detailed reasoning or examples to fully substantiate the claim about the experimental validation, making it 3. The authors would need to provide additional context or evidence to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the experimental validation and positioning of the work. It points out that only shallow networks (2 or 3 layers) are considered, which limits the generalizability of the results. Additionally, it notes the absence of a description of the optimization strategy, including the grid search for hyperparameter selection. The comment also highlights a minor issue with the positioning of the work with respect to related works, specifically the consideration of layer redundancy in network pruning. This feedback is clear and actionable, as it provides specific areas for the authors to address, such as considering deeper networks and describing the optimization strategy. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of how to improve the positioning with respect to related works. Overall, the comment is 4 as it directs the authors to important areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the testing of the model on the bAbI dataset, specifically asking if it was only tested on the single supporting fact dataset (Task 1). However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on what the authors should do in response to this question, such as suggesting additional testing or analysis on other tasks. Without any actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the testing of the model on the bAbI dataset, specifically asking if it was only tested on the single supporting fact dataset (Task 1). However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment, making it weakly grounded. The comment is specific in its inquiry about the testing on other tasks, but without clear grounding, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the testing of the model on the bAbI dataset, specifically asking if it was only tested on the single supporting fact dataset (Task 1). This is a factual inquiry that does not contain a claim or opinion requiring verification. It is a request for clarification, which is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the testing of the model on the bAbI dataset, specifically asking if it was only tested on the single supporting fact dataset (Task 1). While this is a valid inquiry, the comment lacks depth and does not provide any actionable feedback or suggestions for improvement. It does not offer guidance on how the authors might address this issue or expand their testing to other tasks. As a result, the comment is 2, as it identifies a potential area for improvement but does not provide sufficient direction for the authors to act upon."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that Section 3.2 is difficult to follow and recommends that the author improve it by providing more illustrations and examples. While the comment explicitly states that the author should improve the section, it does not provide specific guidance on how to enhance it or what kind of illustrations or examples would be most beneficial. The action is explicit but vague, as the authors are left to infer the exact changes needed without detailed guidance. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the section, namely that it is difficult to follow, and suggests improvements by recommending the addition of more illustrations and examples. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Section 3.2 is difficult to follow and suggests that the author improve it by providing more illustrations and examples. However, the comment does not provide any specific reasoning or examples to support why the section is challenging to follow. Without detailed justification or examples, the authors may find it difficult to understand and address the issue effectively. Therefore, the claim is considered 1, as it lacks sufficient evidence or explanation to substantiate the critique.", "helpfulness_rationale": "The review comment identifies a specific issue with Section 3.2, noting that it is difficult to follow. It provides a clear and actionable suggestion by recommending that the author improve the section by adding more illustrations and examples. This feedback is valuable as it directs the authors to a specific area that needs attention and offers a concrete way to enhance the clarity and comprehensibility of their work. However, the comment could be more helpful if it included more detailed guidance on what kind of illustrations or examples would be most beneficial. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors include a comparison of their approach\"s transferability to other LLMs, specifically mentioning the ability to craft adversarial prompts and transfer them to other LLMs. This is an explicit action that provides a clear direction for the authors to follow. However, the comment also mentions a minor point about the low jailbreaking percentage for certain LLMs, which is not directly actionable. Overall, the comment is 4 as it provides a concrete suggestion for improvement but lacks detailed guidance on the minor point.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"GCG,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that a comparison of the approach\"s transferability to other LLMs should be included, particularly regarding the ability to craft adversarial prompts and transfer them to other LLMs. Additionally, it mentions a minor point about the low jailbreaking percentage for certain LLMs. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors include a comparison of their approach\"s transferability to other LLMs, specifically mentioning the ability to craft adversarial prompts and transfer them to other LLMs. This claim is 3 as it provides a logical reasoning for the suggestion, but it lacks specific examples or references to support the assertion. The mention of a \"jailbreaking percentage\" for certain LLMs adds some context but does not fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improvement by recommending that the authors include a comparison of their approach\"s transferability to other LLMs. It specifically mentions the ability to craft adversarial prompts and transfer them to other LLMs, which is a valuable addition to the paper. Additionally, the comment points out a minor issue with the jailbreaking percentage for certain LLMs, which could be addressed for completeness. This feedback is specific and actionable, offering the authors a clear path to enhance their draft. However, it could be more helpful if it provided additional context or examples on how to conduct the comparison or address the minor point. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a problem with setting the parameter \"S,\" but it does not provide any explicit or implicit guidance on how to address this issue. It lacks specific suggestions or actions for the authors to take, such as recommending alternative methods or providing examples of how to set the parameter. Without any actionable advice, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a problem with setting the parameter \"S,\" but it does not specify which part of the paper this issue is discussed in, nor does it provide details on what aspect of setting \"S\" is problematic. Without explicit references to sections, figures, or specific discussions, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what needs to be addressed or improved regarding the parameter \"S.\" Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that \"How to set the parameter S remains a problem.\" However, it does not provide any supporting evidence, reasoning, or examples to justify why this is a problem or how it affects the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the problem of setting the parameter \"S.\" However, it does not provide any actionable feedback or suggestions on how to address this problem. Without guidance or examples on how to improve the setting of \"S,\" the authors are left without a clear path to enhance their draft. The comment highlights a potential area of concern but lacks depth and specificity, making it 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the claim that \"these shape constraints do not require tuning a free parameter.\" It points out that the choice of employing a convex or concave constraint, and an increasing or decreasing constraint, can be seen as a hyperparameter that needs to be chosen or tuned. While the comment identifies a potential issue with the claim, it does not provide explicit guidance on how the authors should address this issue or suggest specific changes to make. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify or revise their claim regarding the tuning of parameters. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific claim made in the introduction regarding the shape constraints not requiring tuning of a free parameter. It provides a critique by pointing out that the choice of employing a convex or concave constraint, and an increasing or decreasing constraint, can be seen as a hyperparameter that needs to be chosen or tuned. This feedback is specific in identifying the issue with the claim and suggests a potential area for clarification or revision. However, it does not explicitly mention which part of the introduction this claim is made in, making it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that while it is technically true that the shape constraints do not require tuning a free parameter, the choice of employing a convex or concave constraint, and an increasing or decreasing constraint, can be seen as a hyperparameter that needs to be chosen or tuned. The comment provides a logical reasoning by pointing out that the choice of constraints is not entirely free and requires some level of tuning. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to consider the reasoning and potentially provide additional context or evidence to fully understand and address the point. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the claim that \"these shape constraints do not require tuning a free parameter.\" It points out that the choice of employing a convex or concave constraint, and an increasing or decreasing constraint, can be seen as a hyperparameter that needs to be chosen or tuned. This feedback is 3 as it highlights a potential misinterpretation or oversimplification in the paper, prompting the authors to reconsider their claim and potentially clarify or revise it. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or offered examples of how to better articulate the constraints. Overall, the feedback is 3 as it directs the authors to a specific area that requires clarification or revision."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two main issues: the limited datasets and models used in the study, and the absence of assessments on stateoftheart generative models like GPT. It also notes that the bias benchmarks only assess gender, race, and religion, suggesting that other important biases and datasets are not measured. While the comment identifies specific areas for improvement, it does not provide explicit guidance on how to address these issues or what specific datasets or models should be included. The authors are left to infer that they should expand their dataset and model selection to include more diverse biases and stateoftheart generative models. However, the lack of concrete suggestions or examples makes the action somewhat vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the limited datasets and models used in the study, specifically mentioning the bias benchmarks that only assess gender, race, and religion. It also points out the absence of assessments on stateoftheart generative models like GPT. However, the comment does not specify which part of the paper discusses these issues, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing what is missing, such as assessments on other important biases and datasets, and the need for evaluations on stateoftheart generative models. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the datasets and models used are limited, specifically mentioning that the bias benchmarks only assess gender, race, and religion, and that other important biases and datasets are not measured. It also notes the absence of assessments on stateoftheart generative models like GPT. While the comment highlights specific areas where the study could be improved, it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to infer the specific biases or datasets that should be included and the rationale for assessing stateoftheart generative models. Therefore, the comment is 3, as it provides a general direction for improvement but lacks detailed justification or evidence.", "helpfulness_rationale": "The review comment identifies two key areas for improvement: the limited datasets and models used in the study, and the lack of assessment on stateoftheart generative models like GPT. It also points out that the bias benchmarks only assess gender, race, and religion, suggesting that other important biases and datasets are not measured. This feedback is clear and actionable, as it highlights specific areas where the authors can expand their study to include more diverse datasets and models, and to address a broader range of biases. However, the comment could be more helpful if it provided specific suggestions on which datasets or models to consider or how to incorporate assessments on stateoftheart generative models. Overall, the comment is 4 as it directs the authors to important areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that Figure 3 is challenging to understand due to unclear workflow and captions, as well as confusion regarding the representation of communication modes on the left side. However, it does not provide specific guidance on how to improve the figure or what changes should be made to enhance clarity. The authors are left with a general understanding of the issues but without concrete steps to address them. Therefore, the comment is 3, as it identifies areas for improvement but lacks detailed instructions on how to implement those changes.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the figure, such as the unclear workflow and captions, and the confusion regarding the representation of communication modes on the left side. This provides clear guidance on what needs to be addressed to improve the figure\"s clarity. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 3 is challenging to understand due to unclear workflow and captions, as well as confusion regarding the representation of communication modes on the left side. However, the comment does not provide specific examples or detailed reasoning to support why these aspects are unclear or confusing. Without additional context or explanation, the authors may find it difficult to understand and address the issues raised. Therefore, the claim is considered 2, as it lacks sufficient detail to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 3, noting that it is challenging to understand due to unclear workflow and captions, as well as confusion regarding the representation of communication modes on the left side. This feedback is clear and actionable, as it points out specific areas that need improvement in the figure\"s presentation. However, the comment could be more helpful if it provided suggestions on how to clarify the workflow or improve the figure\"s layout. Despite this, the comment is 4 as it directs the authors\" attention to a critical aspect of their work that requires revision. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the meaning of the \"learned MASK embedding\" in the SSL pretraining stage of the proposed method. While it identifies a specific area of confusion, it does not provide any guidance or suggestions on how the authors might clarify this point in their draft. The comment lacks explicit instructions or concrete steps for the authors to follow, leaving them without a clear understanding of what actions to take to address the issue. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the meaning of \"learned MASK embedding\" in the SSL pretraining stage of the proposed method. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs clarification. The comment is specific in identifying the issue of unclear terminology but lacks grounding as it does not provide a clear reference to the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the meaning of \"learned MASK embedding\" in the SSL pretraining stage. However, it does not provide any supporting evidence, reasoning, or references to justify why this term is unclear or how it could be clarified. Without additional context or explanation, the authors may find it challenging to understand the basis of the comment or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the meaning of \"learned MASK embedding\" in the SSL pretraining stage of the proposed method. This is a clear and actionable feedback that prompts the authors to clarify a term that may be unclear to readers. However, the comment does not provide suggestions on how to clarify this term or what specific aspects of the pretraining stage might need further explanation. While it highlights an important area for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is rated as 3, as it provides a clear direction for improvement but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly encourages the authors to conduct error analysis in their paper and provide detailed explanations of the model\"s performance under different scenarios. This suggestion is clear and direct, giving the authors a specific action to take. The comment also explains the importance of error analysis in guiding subsequent improvements and expansions of the ERC research. The feedback is concrete and provides a clear path for the authors to enhance their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests conducting error analysis and providing detailed explanations of the model\"s performance under different scenarios. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its request for error analysis and detailed explanations, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point suggests that error analysis is crucial for evaluating model performance and guiding improvements in ERC research. It encourages the authors to conduct error analysis and provide detailed explanations of the model\"s performance under different scenarios. However, the comment does not provide specific examples or references to support why error analysis is necessary or how it would benefit the paper. The suggestion is logical but lacks detailed justification or evidence, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment highlights the importance of error analysis in evaluating model performance and guiding improvements in ERC research. It provides a clear and actionable suggestion for the authors to conduct error analysis and offer detailed explanations of the model\"s performance under different scenarios. This feedback is valuable as it directs the authors to a specific area that can enhance the comprehensiveness and depth of their analysis, ultimately improving the quality of their draft. However, the comment could be more helpful if it included examples or specific guidance on how to conduct the error analysis. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point questions the claim that the work is one of the preliminary works discussing the application of LLP to NLP tasks, as it does not appear to be specific to NLP. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue or improve the draft, leaving the authors without a clear path forward. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment questions the claim that the work is one of the preliminary works discussing the application of LLP to NLP tasks, suggesting that it lacks NLPspecific elements. However, it does not specify which part of the paper this claim is based on, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment does not provide specific details on what aspects of the work are not NLPspecific, leaving the authors without clear guidance on how to address the issue. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point questions the claim that the work is one of the preliminary works discussing the application of LLP to NLP tasks, suggesting that it lacks NLPspecific elements. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment questions the claim that the work is one of the preliminary works discussing the application of LLP to NLP tasks, suggesting that it lacks NLPspecific elements. However, it does not provide specific feedback or suggestions on how the authors might address this issue or improve the relevance of their work to NLP tasks. Without actionable guidance or detailed critique, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the comparison to stateoftheart (SOTA) methods, suggesting that the performance of the paper may be unfairly attributed to the newly collected 209M dataset, while existing methods use smaller datasets. The reviewer provides an example of GEM using only 20M unlabeled data. This feedback implies that the authors should consider the impact of dataset scale on their results and potentially adjust their claims or comparisons. However, the comment does not explicitly instruct the authors to make specific changes or provide detailed guidance on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their comparisons and potentially adjust their claims. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the comparison with stateoftheart (SOTA) methods, specifically mentioning the use of a newly collected 209M dataset compared to existing methods using smaller datasets. It provides an example of GEM using only 20M unlabeled data, which highlights the potential impact of dataset scale on the accuracy. However, the comment does not explicitly mention which part of the paper discusses the comparison with SOTA methods, making it weakly grounded. The authors can infer that it relates to the results or methodology sections, but this inference is not as direct as it could be. The comment is specific in detailing the issue with the comparison and the potential impact of dataset scale, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that the comparison with stateoftheart (SOTA) methods may be unfair due to the use of a newly collected 209M dataset, while existing methods use smaller datasets. The reviewer provides an example of GEM using only 20M unlabeled data, suggesting that the scale of datasets can significantly impact accuracy. This reasoning is logical and provides a clear basis for the claim, making it 4. However, the comment could be strengthened by referencing specific SOTA methods or providing more detailed comparisons to support the claim fully. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison to stateoftheart (SOTA) methods, suggesting that the performance of the paper may be unfairly attributed to the newly collected 209M dataset, while existing methods use smaller datasets. The reviewer provides an example of GEM using only 20M unlabeled data, which highlights the impact of dataset scale on accuracy. This feedback is valuable as it prompts the authors to consider the fairness of their comparisons and potentially adjust their claims or methodology. However, the comment could be more helpful if it offered specific suggestions on how to address this issue or provided examples of how to fairly compare performance across different datasets. Overall, the comment is 3 as it directs the authors to a critical area for improvement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that some claims in the paper may be inspired by existing studies and recommends adding supportive references. It provides an example by referencing lines 5564, where it identifies four critical factors affecting chainofthought prompting. The reviewer implies that these factors have been discussed in existing studies, but does not specify which studies or provide detailed guidance on how to incorporate these references. While the comment highlights an area for improvement, it lacks concrete instructions on how to implement the suggested action, such as identifying specific references or studies to include. Therefore, the comment is 3, as it provides a clear direction but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lines 5564,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what needs to be addressed, namely the need to add supportive references for claims that may be inspired by existing studies. The comment provides a clear example of the factors discussed in the paper that have been covered in existing studies, which helps the authors understand the specific areas that require further referencing. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some claims in the paper may be inspired by existing studies and suggests adding supportive references. It provides an example by referencing lines 5564, where it identifies four critical factors affecting chainofthought prompting. The reviewer implies that these factors have been discussed in existing studies, but does not specify which studies or provide detailed references. This lack of specific evidence or references makes the claim 3, as the authors would need to invest time and effort to identify the relevant studies themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, noting that some claims may be inspired by existing studies and suggesting that supportive references should be added. It provides a specific example by referencing lines 5564, where it highlights four critical factors affecting chainofthought prompting. The reviewer implies that these factors have been discussed in existing studies, which is a valuable observation. However, the comment could be more helpful if it included specific references or examples of existing studies that the authors should consider. While it provides a clear direction for improvement, the lack of detailed guidance limits its usefulness. Therefore, the comment is rated as 3, as it offers a starting point for improvement but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the first paragraph of the Introduction is not relevant to the paper\"s focus on detecting drift types and magnitude, as it is entirely devoted to a general introduction of DNNs. The reviewer implies that this section provides little value to readers and should be revised or removed. While the comment identifies a potential issue with the introduction, it does not provide explicit guidance on how to address it, such as suggesting specific changes or improvements. The action is implicit and somewhat vague, as the authors are left to infer that they should revise or remove the section, but without concrete instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first paragraph of the Introduction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the paragraph, namely that it is entirely devoted to a general introduction of DNNs without mentioning drift, which is the core focus of the paper. This provides clear guidance on what needs to be addressed or revised in the introduction. Therefore, the comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point claims that the first paragraph of the Introduction is not relevant to the paper\"s focus on detecting drift types and magnitude, as it is entirely devoted to a general introduction of DNNs. The reviewer suggests that this section provides little value to readers. However, the comment lacks specific examples or detailed reasoning to support why the introduction is not relevant or how it could be improved. Without additional context or evidence, the claim remains somewhat vague, making it difficult for the authors to understand and address the issue effectively. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the first paragraph of the Introduction, noting that it is entirely devoted to a general introduction of DNNs without mentioning drift, which is the core focus of the paper. This feedback is clear and actionable, as it highlights a potential disconnect between the introduction and the paper\"s main topic. By pointing out this issue, the comment provides the authors with a clear direction for revising the introduction to better align with the paper\"s focus. However, the comment could be more helpful if it suggested specific ways to integrate driftrelated content into the introduction or provided examples of how to structure the introduction more effectively. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the prompting technique used in the study is basic and suggests that carefully curated prompts could lead to better results in generating systematic reviews. However, it does not provide specific guidance on how to curate these prompts or what aspects of the current technique need improvement. The action is implicit and somewhat vague, as the authors are left to infer that they should explore more advanced prompting techniques but without concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment critiques the prompting technique used in the study, suggesting that it is basic and does not fully leverage the potential of LLMs. It implies that carefully curated prompts could lead to better results in generating systematic reviews. However, the comment does not specify which part of the paper discusses the prompting technique, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but without explicit references, it is challenging to pinpoint the exact part of the paper being addressed. The comment is specific in suggesting that better results could be achieved with carefully curated prompts, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the prompting technique used in the study is basic and does not fully leverage the potential of LLMs. The reviewer suggests that carefully curated prompts could lead to better results in generating systematic reviews. However, the comment lacks specific examples or references to support the claim that the current technique is insufficient or how carefully curated prompts could improve results. Without detailed evidence or examples, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is classified as 2.", "helpfulness_rationale": "The review comment identifies a potential weakness in the study by pointing out that the prompting technique used is basic and may not fully leverage the potential of LLMs. It suggests that carefully curated prompts could lead to better results in generating systematic reviews. This feedback is 3 as it highlights an area for improvement and provides a direction for enhancing the study. However, the comment lacks specific guidance on how to curate these prompts or what aspects of the current technique need to be improved. To be more helpful, the comment could include examples or suggestions on how to enhance the prompting technique. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the proposed method achieves only a modest improvement over baselines, particularly on a small backbone like ResNet50. It suggests that the method might struggle on larger backbone models like SwinB or SwinL due to the introduction of global pooling. While the comment implies that the authors should test their method on larger models, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the issue or what specific tests to conduct. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed method\" and the \"relative gains\" achieved on different frameworks and tasks, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the proposed method only achieves a modest improvement over baselines, particularly on a small backbone like ResNet50. The comment further suggests that the method might struggle on larger backbone models like SwinB or SwinL due to the introduction of global pooling. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method achieves only modest improvements over baselines, particularly on a small backbone like ResNet50. The reviewer suggests that this might be due to the introduction of global pooling, which could limit the method\"s effectiveness on larger backbone models like SwinB or SwinL. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion about the relative gains or the impact of global pooling on larger models. This makes the claim 3, as it requires further evidence or detailed analysis to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a potential limitation in the proposed method, noting that the relative gains are not very strong, especially on a small backbone like ResNet50. It suggests that the introduction of global pooling might be a factor in this limitation, as it could lead to improved performance on smaller models but not necessarily on larger ones. The comment raises a valid concern about the scalability of the method and provides a specific example of a baseline model to consider. However, it does not offer detailed suggestions or guidance on how the authors might address this issue or improve the method\"s performance on larger models. While the feedback is 3 in identifying a potential weakness, it lacks actionable advice, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the sufficiency of the datasets for a rigorous evaluation, particularly given the large size of some datasets. It suggests that the authors should consider adding more datasets or providing a repository for reproducing experiments. While the comment implies an action, it does not explicitly instruct the authors to take specific steps, such as identifying additional datasets or creating a repository. The suggestion is somewhat vague, as it lacks concrete guidance on how to address the issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the sufficiency of the datasets for a rigorous evaluation, particularly in relation to the number of datasets available for each task. It mentions that having 5, 6, and 4 datasets for the three tasks, respectively, might not be sufficient. However, the comment does not specify which sections or parts of the paper discuss these datasets, making it weakly grounded. The comment is specific in its critique of the dataset selection and its impact on evaluation rigor. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the sufficiency of the datasets for a rigorous evaluation, particularly given the large size of some datasets. The reviewer suggests that having fewer datasets for each task might not provide a comprehensive evaluation. However, the comment lacks specific examples or references to support the claim that the datasets are insufficient. Without detailed justification or evidence, the claim remains somewhat vague, making it difficult for the authors to address the concern effectively. Therefore, the comment is classified as 3.", "helpfulness_rationale": "The review comment raises a concern about the sufficiency of the datasets for a rigorous evaluation, particularly given the large size of some datasets. It suggests that having fewer datasets for each task might not provide a comprehensive evaluation. The comment is 3 as it identifies a potential weakness in the dataset selection and evaluation process. However, it lacks specific suggestions or guidance on how the authors might address this issue, such as recommending additional datasets or providing insights into how to balance dataset size and comprehensiveness. While it points out a relevant area for improvement, the comment could be more helpful with additional details or actionable advice. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point identifies two issues: confusing mistakes in the proof of the main results and a lack of detailed discussion and comparison with previous work. It also suggests that the paper does not provide new insights. However, the comment does not provide specific guidance on how to address these issues or what aspects of the proof or comparison need clarification. The feedback is vague and lacks actionable steps, leaving the authors uncertain about how to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment mentions \"confusing mistakes in the proof of the main results\" and a lack of detailed discussion and comparison with previous work. However, it does not specify which part of the paper these issues are found in, making it weakly grounded. The comment also lacks specificity as it does not provide details on what exactly is confusing or what specific aspects of the proof or comparison are lacking. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that there are \"confusing mistakes\" in the proof of the main results and that the paper lacks a detailed discussion and comparison with previous work. However, it does not provide specific examples or detailed reasoning to support these claims. The lack of detailed evidence or references makes it difficult for the authors to understand and address the issues effectively. Therefore, the comment is considered 2, as it provides some basis for the claims but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper: confusing mistakes in the proof of the main results and a lack of detailed discussion and comparison with previous work. It also suggests that the paper does not provide new insights. While the comment highlights important areas for improvement, it lacks specific guidance or suggestions on how to address these issues. The authors are left with a general understanding of what needs to be improved but without detailed instructions on how to make those improvements. Therefore, the comment is 3, as it points out areas for enhancement but does not provide actionable steps for the authors to take."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the clarity of the motivation for using an adversarial network in the model and questions the fairness of the experimental results. It also points out that the proposed model is larger than others due to the addition of CAT and GAN, even when compared to pretrained models. However, the comment does not provide explicit guidance on how to address these issues or suggest specific actions for improvement. The authors are left to infer that they need to clarify the motivation and ensure fairness in the experimental results, but without concrete steps or examples, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the motivation for using an adversarial network in the model and questions the fairness of the experimental results. It also mentions the addition of CAT and GAN, which makes the proposed model larger than others. However, the comment does not specify which part of the paper discusses the motivation or the experimental results, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in pointing out the issues with the motivation and experimental fairness, but without explicit references to sections, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the clarity of the motivation for using an adversarial network in the model and questions the fairness of the experimental results. It also points out that the proposed model is larger than others due to the addition of CAT and GAN, even when compared to pretrained models. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the exact issues or how to address them. The lack of evidence or detailed explanation makes the claims 3, as the authors would need to infer the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two main issues with the paper: the lack of clarity in the motivation for using an adversarial network in the model and the perceived unfairness in the experimental results. It also points out that the proposed model is larger than others due to the addition of CAT and GAN, even when compared to pretrained models. While the comment highlights important areas for improvement, it does not provide specific suggestions or guidance on how to address these issues. The authors are left with a general understanding of what needs to be clarified or improved but without detailed instructions on how to do so. Therefore, the comment is 3, as it points out areas for improvement but lacks depth and actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the reliability of the experimental results, specifically in Table 1, where the MSE is significantly smaller than the MAE. However, it does not provide any explicit or implicit guidance on how the authors should address this issue or improve the reliability of their results. There is no suggestion on what specific steps should be taken to rectify the problem or how the authors might validate their results. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the experimental results, pointing out the concern about the reliability of the results due to the significant difference between the MSE and MAE. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental results are unreliable, specifically in Table 1, where the MSE is significantly smaller than the MAE. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this discrepancy raises concerns about the validity of the results. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental results, noting that the MSE is significantly smaller than the MAE in Table 1, which raises concerns about the reliability of the results. This is a clear and actionable feedback that highlights a potential problem in the paper. However, the comment does not provide suggestions on how the authors might address this issue or improve the reliability of their results. While it points out a critical area for improvement, it lacks depth and specific guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of an adversarial loss to ensure that perturbed data remains similar to authentic data. While the comment identifies a potential issue, it does not provide explicit guidance on how to address this concern or suggest specific actions for the authors to take. The action is implicit and somewhat vague, as the authors are left to infer that they need to incorporate an adversarial loss but are not given detailed instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment highlights a specific issue regarding the absence of an adversarial loss to ensure the perturbed data remains similar to authentic data. However, it does not specify which part of the paper this issue pertains to, such as a particular section or experiment where this loss is expected. Without explicit references, the authors may find it challenging to pinpoint the exact location of the issue. The comment is specific in identifying the lack of an adversarial loss but lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that there is no adversarial loss to ensure the perturbed data remains similar to authentic data. This is a subjective claim that requires justification or evidence to support the assertion. The comment does not provide any reasoning, examples, or references to substantiate why this is a concern or how it affects the paper\"s methodology or results. Without such support, the claim remains 1, as the authors would need to infer the importance of this issue based on the comment alone. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting the absence of an adversarial loss to ensure the perturbed data remains similar to authentic data. This is a clear and actionable feedback that highlights a potential weakness in the methodology or results. By pointing out this omission, the comment provides the authors with a specific area to address and improve their work. However, the comment could be more helpful if it suggested potential ways to incorporate an adversarial loss or explained its importance in the context of the paper. Overall, the comment is 3 as it directs the authors\" attention to a critical aspect of their methodology that needs attention."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the number of hyperparameters that need to be tuned and the potential variation in optimal hyperparameters due to the optimization being solved on a samplebysample basis. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their draft. The comment lacks actionable guidance, such as recommending specific methods for tuning hyperparameters or discussing potential strategies to mitigate the variation. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a concern about the number of hyperparameters that need to be tuned and the potential variation in optimal hyperparameters due to the optimization being solved on a samplebysample basis. However, it does not specify which part of the paper this issue pertains to, such as a specific section or experiment, making it weakly grounded. The comment is specific in detailing the issue with hyperparameter tuning and the potential variation, but without clear grounding, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the number of hyperparameters that need to be tuned and the potential variation in optimal hyperparameters due to the optimization being solved on a samplebysample basis. However, the comment lacks specific examples, references, or detailed reasoning to support the claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment identifies a potential issue with the number of hyperparameters that need to be tuned and the potential variation in optimal hyperparameters due to the optimization being solved on a samplebysample basis. This is a relevant concern that could impact the robustness and generalizability of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending methods for hyperparameter tuning or discussing potential strategies to mitigate the variation. While it highlights an important area for consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the limited practical significance of the verylongterm forecasting task and suggests improvements to the discussion, such as conducting experiments on more datasets and training baseline models with the \"correct\" forecast horizon. While the comment implies that these actions are necessary, it does not explicitly instruct the authors to do so. The authors can infer the need for these improvements, but the comment lacks concrete guidance on how to implement them. Therefore, the comment is 3, as it provides a clear direction but lacks detailed instructions.", "grounding_specificity_rationale": "The comment addresses the discussion section of the paper, specifically mentioning the need for improvement in the context of the verylongterm forecasting task. It suggests conducting experiments on more datasets and training baseline models with the \"correct\" forecast horizon to provide a proper context for the results. However, the comment does not explicitly mention which part of the discussion is lacking or what specific aspects need improvement. While the authors can infer that it relates to the discussion section, the lack of explicit references makes it weakly grounded. The comment is specific in suggesting improvements, such as conducting additional experiments and training baseline models, but it does not specify which parts of the discussion are problematic. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the verylongterm forecasting task is of limited practical significance and suggests improvements to the discussion, such as conducting experiments on more datasets and training baseline models with the \"correct\" forecast horizon. However, the comment lacks specific reasoning or evidence to support the claim about the limited practical significance of the task. It also does not provide examples or references to justify the need for additional experiments or training with the \"correct\" forecast horizon. Without these details, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the practical significance of the verylongterm forecasting task, suggesting that the discussion could be improved by conducting experiments on more datasets and training baseline models with the \"correct\" forecast horizon. This feedback is 3 as it points out a specific area for improvement and provides a direction for enhancing the discussion. However, the comment lacks detailed guidance on how to conduct these experiments or what specific datasets or forecast horizons should be considered. While it offers a clear suggestion, it could be more helpful with additional details or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states that the authors have not analyzed the security of their proposed framework, specifically the protection of privacy. This provides a clear and direct action for the authors to take: they should include an analysis of the security aspects of their framework, particularly focusing on privacy protection. The comment is explicit and provides a concrete action for the authors to follow, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of analysis on the security (i.e., protection of privacy) of the proposed framework. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what is missing: an analysis of the security aspects, particularly the protection of privacy. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors have not analyzed the security (i.e., protection of privacy) of the proposed framework. However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of analysis on the security (i.e., protection of privacy) of the proposed framework. This is a critical area that the authors need to address to ensure the robustness and reliability of their work. However, the comment does not provide specific suggestions or guidance on how the authors might approach this analysis or what aspects of security they should focus on. While it highlights an important area for improvement, the lack of detailed feedback limits its helpfulness. Therefore, the comment is rated as 3, as it provides a clear direction for improvement but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point notes that \"Memb\" is apparently the previous stateoftheart but lacks a reference. This implies that the authors should include a reference to support this claim. However, the comment does not explicitly instruct the authors to do so, leaving it as an implicit action. Additionally, while the action is clear, it lacks concrete guidance on which reference to include or how to integrate it into the text. Therefore, the comment is 3, as it provides a clear direction but lacks detailed instructions on execution.", "grounding_specificity_rationale": "The comment mentions \"Memb,\" implying that it is a previous stateoftheart method. However, it does not specify which part of the paper this claim pertains to, such as a section or a discussion of related work. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in pointing out the lack of a reference for \"Memb,\" but without explicit grounding, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that \"Memb\" is the previous stateoftheart but lacks a reference. This is a subjective claim that requires justification or evidence to support the assertion. The comment does not provide any references, examples, or detailed reasoning to substantiate the claim, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a specific issue with the paper, noting that \"Memb\" is apparently the previous stateoftheart but lacks a reference. This feedback is relevant and actionable, as it highlights a potential gap in the literature review or discussion section. By addressing this omission, the authors can ensure their work is properly contextualized within the field. However, the comment could be more helpful if it provided suggestions on how to integrate this reference or discussed its significance in the context of the paper. Overall, the comment is 3 as it identifies a clear area for improvement but lacks depth in guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the difficulty of finding examples that illustrate the loss principles clearly, similar to those presented in the paper and the supplement. It also mentions specific weaknesses of the proposed FSR metric. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the issue of finding examples or improve the FSR metric. Without specific suggestions or instructions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the difficulty of finding examples that illustrate the loss principles clearly, similar to those presented in the paper and the supplement. It also mentions specific weaknesses of the proposed FSR metric. However, it does not specify which part of the paper these examples or weaknesses are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its critique of the FSR metric but lacks grounding as it does not clearly identify the parts of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the difficulty of finding examples that illustrate the loss principles clearly, similar to those presented in the paper and the supplement. It also mentions specific weaknesses of the proposed FSR metric. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate the claim about the difficulty of finding such examples or the weaknesses of the FSR metric. Without specific details or references, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the difficulty of finding examples that illustrate the loss principles clearly, similar to those presented in the paper and the supplement. It also mentions specific weaknesses of the proposed FSR metric. However, the comment lacks specificity and does not provide actionable feedback or suggestions for improvement. It does not offer guidance on how the authors might address the issue of finding such examples or how to enhance the FSR metric. Without detailed advice or constructive criticism, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the quality of paraphrases used in the training data, noting that the difference between the paraphrases and the original sentences is unclear. It suggests that this could impact the subsequent steps, as the model relies on the quality of these paraphrases. The comment implies that the authors should ensure the paraphrases are sufficiently different from the originals to maintain the quality of the training data. However, it does not provide explicit guidance on how to achieve this or what specific steps to take. The action is implicit and somewhat vague, as the authors can infer that they need to address the issue of paraphrase quality but are not given concrete instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific concern about the quality of paraphrases used in the training data, questioning how different they are from the original sentences. It highlights the importance of this issue for subsequent steps, as the model relies on the quality of these paraphrases. However, the comment does not specify which part of the paper discusses the generation of paraphrases, making it weakly grounded. The authors can infer that it relates to the methodology or data preparation sections, but this inference is not explicit. The comment is specific in detailing the impact of the paraphrase quality on the training data and subsequent steps. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the quality of paraphrases used in the training data is unclear, which could impact the subsequent steps of the model. The reviewer provides a logical reasoning by suggesting that if the difference between the paraphrases and the original sentences is not significant, the quality of the training data will be compromised. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to further explore and substantiate the claim themselves to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the quality of paraphrases used in the training data, noting that the difference between the paraphrases and the original sentences is unclear. It highlights the importance of this issue, as it directly impacts the subsequent steps of the model, which relies on the quality of these paraphrases. The comment provides a clear and actionable suggestion by pointing out that if the paraphrases are not sufficiently different, the quality of the training data will be compromised, leading to a limited number of pairs being added to the new training data. This feedback is valuable as it directs the authors to address a specific weakness in their methodology, offering a clear path for improvement. However, the comment could be more helpful if it provided specific guidance on how to ensure the quality of the paraphrases or examples of what constitutes a sufficient difference. Overall, the comment is 4, as it effectively highlights a critical area for improvement and provides a clear direction for the authors to enhance their work."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about whether the text input can be concatenated by the four text elements of an object. However, it does not provide any explicit or implicit actions for the authors to take. The question is not phrased as a suggestion or a request for clarification, leaving the authors without any guidance on how to address the issue. As a result, the comment lacks actionability, as the authors are not given any direction on how to improve their draft. Therefore, this comment is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment poses a question about whether the text input can be concatenated by the four text elements of an object. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section being addressed. Additionally, the comment lacks specificity as it does not provide any context or details about the issue being raised. Without clear grounding and specificity, the authors are left without a clear understanding of what needs to be addressed or improved. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification about whether the text input can be concatenated by the four text elements of an object. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment poses a question about whether the text input can be concatenated by the four text elements of an object. While it highlights a potential area of confusion or misunderstanding, it does not provide any actionable feedback or suggestions for improvement. The comment lacks depth and does not offer guidance on how the authors might address this issue or clarify their work. As a result, it is 2, as it identifies a potential problem but does not assist the authors in resolving it. Therefore, it aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper should better motivate the \"Why\" aspect, explaining why the presented topic is important or relevant. However, it does not provide explicit guidance on how to achieve this motivation or what specific aspects should be highlighted. The action is implicit and somewhat vague, as the authors can infer that they need to provide a stronger rationale for their work but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should better motivate the \"Why\" aspect, explaining why the presented topic is important or relevant. However, it does not specify which part of the paper lacks this motivation or where it should be added. The authors might infer that it relates to the introduction or the motivation section, but this inference is not explicit. The comment is specific in its suggestion to provide a stronger rationale but lacks grounding, as it does not pinpoint a specific section or element of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should better motivate the \"Why\" aspect, explaining why the presented topic is important or relevant. However, the comment does not provide any specific reasoning, examples, or references to support why this motivation is lacking or how it could be improved. Without additional context or justification, the authors may find it challenging to understand and address the feedback. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, noting that it lacks a clear motivation for the \"Why\" aspect of the presented topic. This feedback is 3 as it points out an area where the paper could be improved by providing a stronger rationale for the importance and relevance of the work. However, the comment does not offer specific suggestions or guidance on how to address this issue, such as what aspects of the \"Why\" should be emphasized or how to effectively motivate the topic. While it provides some direction, the lack of detailed advice limits its helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights that the domainspecific model is trained on Pix3D and the experiments are conducted on Pix3D, making comparisons to zeroshot singleimage 3D reconstruction models even more unfair. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their methodology. The comment lacks actionable guidance, such as recommending alternative datasets or methods for comparison, or suggesting ways to mitigate the unfairness. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the domainspecific model being trained on Pix3D and the experiments being conducted on Pix3D. This allows the authors to accurately identify the part of the paper being addressed. However, the comment lacks specificity as it does not provide detailed feedback on what aspects of the comparison to zeroshot singleimage 3D reconstruction models are unfair or how the authors might address this issue. The comment identifies a potential problem but does not offer guidance on how to improve the fairness of the comparisons. Therefore, the comment is fully grounded but underspecific, aligning with a score of 4.", "verifiability_rationale": "The review point claims that the domainspecific model is trained on Pix3D and the experiments are conducted on Pix3D, making comparisons to zeroshot singleimage 3D reconstruction models even more unfair. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is unfair. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a potential issue with the experimental setup, noting that the domainspecific model is trained on Pix3D and the experiments are conducted on Pix3D, which could lead to unfair comparisons with zeroshot singleimage 3D reconstruction models. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the fairness of their comparisons. Without actionable advice or detailed feedback, the authors are left without a clear understanding of how to enhance their draft. Therefore, the comment is 2, as it identifies a potential problem but lacks depth and specificity in its guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests conducting additional experiments on realistic noisy datasets like WebVision to provide more support for C2D. While the comment implies that the authors should perform these experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not specify the exact nature of the experiments or how they should be conducted. However, the authors can infer that they need to perform additional experiments to strengthen their claims. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests conducting additional experiments on realistic noisy datasets like WebVision to support the claims made in the paper. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing revision. The comment is specific in suggesting additional experiments, but it is 1 because it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests conducting additional experiments on realistic noisy datasets like WebVision to support the claims made in the paper. However, the comment does not provide any specific reasoning, examples, or references to justify why these experiments would be beneficial or how they would enhance the paper\"s support for C2D. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests conducting additional experiments on realistic noisy datasets like WebVision to provide more support for the claims made in the paper. This feedback is 3 as it identifies a potential area for improvement by suggesting a specific type of experiment that could strengthen the paper\"s support for the claims. However, the comment lacks detailed guidance on how to conduct these experiments or what specific aspects should be tested. While it provides a direction for enhancing the paper, it does not offer comprehensive or actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about whether the grid search of the learning rate is done on the validation set. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this question or what steps to take to clarify this aspect of the methodology. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the grid search of the learning rate, specifically asking if it is done on the validation set. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its inquiry about the validation set, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact location of the issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the grid search of the learning rate, specifically asking if it is done on the validation set. This is a factual inquiry that does not contain a claim or opinion requiring verification. It is a request for clarification, which is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the grid search of the learning rate, specifically asking if it is done on the validation set. While this is a relevant inquiry, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve their methodology. Without actionable feedback or additional context, the authors are left without a clear understanding of what steps to take to enhance their work. Therefore, the comment is 2, as it identifies a potential area of concern but does not offer meaningful guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the racial and economic diversity of the sample and the generalizability of the results to other groups, particularly marginalized groups. While it implies that the authors should consider these aspects, it does not explicitly instruct them to include this information or conduct additional analyses. The action is implicit and somewhat vague, as the authors can infer that they should address these concerns but are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L393,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the racial and economic diversity of the sample and the generalizability of the results to other groups, particularly marginalized groups. This provides clear guidance on what aspects need to be addressed or considered in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the racial and economic diversity of the sample and the generalizability of the results to other groups, particularly marginalized groups. However, it does not provide any supporting evidence, reasoning, or references to justify why these aspects are important or how they might impact the results. The comment is more of a suggestion for further exploration rather than a claim that requires verification. Therefore, it is classified as \"1.\"", "helpfulness_rationale": "The review comment raises an important question about the racial and economic diversity of the sample and the generalizability of the results to other groups, particularly marginalized groups. This is a relevant concern that could impact the validity and applicability of the findings. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or conduct further analysis to ensure inclusivity. While it highlights an important area for consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it prompts the authors to consider an important aspect of their work but does not fully guide them in making improvements."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out a potential issue with the nonconvexity of the function Z, suggesting that it may not be a problem for the SGD to converge if the function has certain properties. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this issue or what specific properties of the function Z should be considered. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (182184) in the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it highlights a potential issue with the nonconvexity of the function Z and suggests that it may not be a problem for the SGD to converge if the function has certain properties. This provides clear guidance on what aspect of the paper needs attention. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that nonconvexity may not be an issue for the SGD to converge, if the function Z has some good properties. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a potential issue with the nonconvexity of the function Z, suggesting that it may not be a problem for the SGD to converge if the function has certain properties. However, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue or explore the properties of the function Z that could affect convergence. Without actionable feedback or detailed advice, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the experimental settings are not mentioned properly, which is crucial for result reproducibility. It also notes that the author does not provide the code. These are clear actions that the authors need to take to improve their draft. The comment provides explicit guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental settings\" and \"result reproducibility,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the experimental settings and the lack of code provision, which are critical for result reproducibility. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental settings are not mentioned properly, which is critical for result reproducibility. However, it does not provide specific examples or detailed reasoning to support this claim. The mention of the lack of code provision is a factual statement, but it does not directly contribute to the claim about the experimental settings. Therefore, the comment is 3, as it lacks detailed evidence or examples to fully substantiate the claim about the experimental settings.", "helpfulness_rationale": "The review comment identifies a critical issue with the experimental settings, noting that they are not mentioned properly and that result reproducibility is compromised without sufficient information. It also points out the lack of code provision, which is essential for replicating the experiments. This feedback is clear and actionable, as it highlights specific areas that need improvement to enhance the paper\"s credibility and reproducibility. However, it could be more helpful if it provided suggestions on how to improve the experimental setup or code provision. Overall, the comment is 4, as it directs the authors to important aspects that need attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the motivation behind applying CMD (Command and Data Manipulation) in federated learning is unclear and could be improved with a more explicit demonstration or explanation. While the comment implies that the authors should provide a clearer explanation, it does not specify how to achieve this or what specific aspects of the motivation need further elaboration. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to improve the clarity of the motivation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the motivation behind applying CMD in federated learning, suggesting that it is unclear and could benefit from a more explicit demonstration or explanation. However, it does not specify which part of the paper discusses this motivation, making it weakly grounded. The comment is specific in identifying the issue of clarity regarding the motivation, but without explicit references to sections or parts of the paper, the authors may find it challenging to pinpoint the exact areas needing improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the motivation behind applying CMD in federated learning is unclear and suggests that it could benefit from a more explicit demonstration or explanation. However, the comment does not provide any specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the exact nature of the issue or how to address it. Therefore, the claim is considered 2, as it lacks sufficient support to be fully actionable.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, specifically the lack of clarity in the motivation behind applying CMD in federated learning. It suggests that the authors should provide a more explicit demonstration or explanation to enhance the understanding of this motivation. While the comment highlights an area for improvement, it does not offer specific guidance or suggestions on how to achieve this clarity. The feedback is 3 as it points out a critical area for enhancement, but it lacks depth and actionable advice, leaving the authors with a general direction but not a clear path to improvement. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the performance boost claimed by the proposed CoNO model, suggesting that it is unclear whether the fractional transform or the UNet operation in the fractional Fourier domain is responsible for the improvement. The reviewer implies that comparisons to UNets are necessary to clarify this point. While the comment identifies a potential area for improvement, it does not explicitly instruct the authors to conduct these comparisons or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to compare their model to UNets, but they are not given detailed instructions on how to execute this comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"CoNO model\" and the \"UNet part after the fractional transform,\" allowing the authors to accurately identify the specific part of the paper being addressed. It also specifies the issue by questioning the source of the performance boost and suggesting that comparisons to UNets are necessary. The comment provides specific examples of works that have shown strong performances with UNets on regular gridded domains, which further clarifies the need for comparisons. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the source of the performance boost claimed by the CoNO model, suggesting that it is unclear whether the fractional transform or the UNet operation in the fractional Fourier domain is responsible. The reviewer provides a logical reasoning by comparing the UNet operation in the fractional Fourier domain to pointwise multiplication, as done in FNOs, and suggests that comparisons to UNets are necessary. Additionally, the comment references specific works by Raonic et al and Gupta et al, which have shown strong performances with UNets on regular gridded domains. This provides a basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed comparisons or examples from the referenced works. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises a critical question about the source of the performance boost claimed by the proposed CoNO model. It highlights a potential ambiguity in the paper regarding whether the fractional transform or the UNet operation in the fractional Fourier domain is responsible for the improvement. The reviewer suggests that comparisons to UNets are necessary to clarify this point, especially since UNets have shown strong performances on regular gridded domains, as evidenced by references to Raonic et al and Gupta et al. This feedback is clear and actionable, as it directs the authors to conduct specific comparisons that could help clarify the source of the performance boost. However, the comment could be more helpful if it provided additional guidance on how to conduct these comparisons or what specific aspects to focus on. Overall, the comment is 4, as it identifies a critical area for improvement and offers a clear direction for the authors to enhance their draft."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges the comprehensive Appendix and appreciates the additional detail it provides. However, it also mentions that the reviewer did not have time to carefully read the additional experiments described in the Appendix, such as the Brusselator. This comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on whether the authors should focus on improving the clarity or accessibility of the Appendix or whether they should prioritize other aspects of the paper. Without actionable suggestions or feedback, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment acknowledges the comprehensive Appendix and appreciates the additional detail it provides. However, it also mentions that the reviewer did not have time to carefully read the additional experiments described in the Appendix, such as the Brusselator. This provides some specificity regarding the parts of the paper that were not fully reviewed, but it does not specify what needs to be addressed or improved in these sections. The comment is weakly grounded as it does not explicitly mention which part of the paper the additional experiments are located, leaving the authors to infer the relevant sections. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point acknowledges the comprehensive Appendix and appreciates the additional detail it provides. However, it also mentions that the reviewer did not have time to carefully read the additional experiments described in the Appendix, such as the Brusselator. This is a factual statement describing the reviewer\"s experience and does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment acknowledges the comprehensive Appendix, which is appreciated for providing additional detail about parts of the paper. However, it also mentions that the reviewer did not have time to carefully read the additional experiments described in the Appendix, such as the Brusselator. This feedback is 3 as it highlights a potential area for improvement, suggesting that the authors might want to prioritize the clarity and accessibility of the Appendix. However, the comment lacks specific guidance or suggestions on how to address this issue, such as recommending ways to streamline the Appendix or improve its organization. Therefore, while it provides some insight, it is not fully actionable or comprehensive, making it 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that certain terms, such as W1, W2, W, and V, are not defined in the paper. It suggests that these terms might refer to the Encoder and Decoder networks, but this inference is not explicitly stated. The comment provides a clear indication of what needs to be addressed, which is the definition of these terms. However, it lacks specific guidance on how to define them or where to include the definitions in the paper. While the action is implicit, it is concrete once the authors understand the issue. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper where terms are not defined, such as \"p.3, A4, eq.3.\" This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what is missing, namely the definitions of W1, W2, W, and V. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements about the absence of definitions for certain terms (W1, W2, W, and V) in the paper. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a significant issue by pointing out that certain terms, such as W1, W2, W, and V, are not defined in the paper. This is a critical oversight that can lead to confusion for readers. The comment provides specific examples of where these terms are used, allowing the authors to easily locate and address the issue. By highlighting the need for definitions, the comment offers clear and actionable feedback that can help the authors improve the clarity and comprehensibility of their draft. However, the comment could be more helpful if it suggested where these definitions should be included or provided examples of how they might be defined. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the formulation of Equation (1), suggesting that the observations might be aggregated by methods other than averaging, such as summation or populationweighted average. It also mentions that disease incident data are often available in counts or rates per number of residents. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern or suggest specific changes to their formulation. The action is implicit and somewhat vague, as the authors need to infer that they should consider alternative aggregation methods and discuss the implications for their data. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equation (1),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the formulation assumes observations are obtained by averaging over the support, but this might not always be the case, as other aggregation methods like summation or populationweighted average could be used. Additionally, it provides context by mentioning that disease incident data are often available in counts or rates per number of residents. This level of detail and specificity helps the authors understand the issue and potential improvements needed in their formulation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the formulation in Equation (1) assumes observations are obtained by averaging over the support, but this might not always be the case. The reviewer provides a logical reasoning by suggesting alternative aggregation methods, such as summation or populationweighted average, and references the availability of disease incident data in counts or rates per number of residents. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened by referencing specific studies or examples where these alternative aggregation methods are used, which would further enhance its verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the formulation of Equation (1), suggesting that the observations might be aggregated by methods other than averaging, such as summation or populationweighted average. It also mentions that disease incident data are often available in counts or rates per number of residents, which could impact the formulation. This feedback is 3 as it points out a specific area where the authors might need to consider alternative aggregation methods or discuss the implications of different data types. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or offered examples of how other researchers have handled similar situations. Overall, the comment is 3 as it prompts the authors to consider a potential limitation in their formulation but lacks detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should consider making the policy nonfixed, which would allow for more complex tasks. It also suggests comparing the results with a reinforcement learning algorithm baseline. While the comment implies an action, it does not provide explicit instructions on how to implement these suggestions, such as which tasks to consider or which reinforcement learning algorithms to use. The authors can infer the action but may find it challenging to execute without further guidance. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the current setting with a fixed policy is a subset of reinforcement learning and proposes a way to make the tasks more complex. It also suggests comparing the results with a reinforcement learning algorithm baseline. However, the comment does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The authors might infer that it relates to the sections discussing the policy or the experimental setup, but this is not explicitly stated. The comment is specific in suggesting a way to enhance the complexity of the tasks and the need for a reinforcement learning baseline, but without clear grounding, it remains 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the current setting with a fixed policy is a subset of reinforcement learning and proposes a way to make the tasks more complex. It also suggests comparing the results with a reinforcement learning algorithm baseline. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the tasks can be made more complex or that a reinforcement learning baseline is necessary. The suggestion is 3 as it provides a logical direction for improvement, but the lack of detailed justification or examples makes it difficult for the authors to fully understand and address the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the current setting with a fixed policy is a subset of reinforcement learning and proposes a way to make the tasks more complex. It also suggests comparing the results with a reinforcement learning algorithm baseline. While the comment identifies a potential area for improvement by suggesting a more complex setting, it lacks specific guidance on how to implement this change or which reinforcement learning algorithms to consider. The feedback is 3 as it provides a direction for enhancing the study, but it could be more actionable with additional details or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights an incomplete study, specifically noting that the relationship between the top selected patches and the disease has not been established. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to establish this relationship, what specific steps to take, or what additional analysis or experiments might be needed. As a result, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights an issue with the study, specifically noting that the relationship between the top selected patches and the disease has not been established. However, it does not specify which part of the paper this issue pertains to, such as a particular section, table, or figure. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what needs to be addressed or how to establish this relationship. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the study is incomplete because the relationship between the top selected patches and the disease has not been established. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the study, noting that the relationship between the top selected patches and the disease has not been established. This is a critical observation that highlights a fundamental weakness in the paper, as understanding this relationship is crucial for the validity and applicability of the study. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this issue. Without detailed feedback or suggestions, the authors are left with a general understanding of the problem but without a clear path to improvement. Therefore, the comment is 3, as it points out a significant issue but does not fully support the authors in resolving it."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the numerical evaluation, specifically noting that the method is only evaluated on synthetic data and that the comparison with 5 is not fair due to the different complexity of the problem. However, the comment does not provide explicit guidance on how the authors should address these issues. It lacks concrete suggestions on what steps to take to improve the evaluation or how to make the comparison more fair. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the numerical evaluation and the comparison with a specific reference, 5, which provides some grounding by indicating the part of the paper being discussed. However, it does not specify which section of the paper discusses the numerical evaluation or the comparison with 5, making it weakly grounded. The comment is specific in pointing out the issue with the evaluation on synthetic data and the unfair comparison with 5, but it lacks detailed guidance on how to address these issues. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the numerical evaluation is not fully convincing because the method is only evaluated on synthetic data, and the comparison with 5 is not fair due to the different complexity of the problem. The comment provides a logical reasoning by pointing out the limitations of the evaluation setup and the unfair comparison with 5. However, it lacks specific examples or references to support the claim fully, such as detailed comparisons or data that demonstrate the unfairness. This makes the claim 3, as it provides a basis for the critique but requires more detailed evidence to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant limitation in the numerical evaluation of the method, noting that it is only evaluated on synthetic data. It also points out that the comparison with 5 is not fair due to the different complexity of the problem. This feedback is valuable as it highlights a critical weakness in the evaluation process and suggests that the authors should consider expanding their evaluation to include realworld data or more complex scenarios. However, the comment could be more helpful if it provided specific suggestions on how to address this issue, such as recommending additional datasets or experimental setups. Overall, the comment is 3 as it directs the authors\" attention to a key area for improvement but lacks detailed guidance on how to enhance the evaluation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises two main issues. First, it questions the authors\" choice of using a relaxation of rejection sampling instead of directly using Importance sampling. This implies that the authors should provide a justification for their approach. Second, it points out a lack of clarity in Algorithm 1, specifically regarding the difference between QRS and RS. The reviewer suggests that the authors should demonstrate a scenario where these methods behave differently. While the comment implies that the authors should provide additional explanations or examples, it does not explicitly instruct them on how to address these issues. The actions are implicit and somewhat vague, as the authors need to infer what specific information to include. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the algorithm, namely the lack of clarity between QRS and RS and the need to demonstrate a scenario where they behave differently. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts. The first part questions the authors\" choice of using a relaxation of rejection sampling instead of directly using Importance sampling, suggesting that the authors should provide a justification for their approach. This is a claim that requires justification, as it implies a potential flaw in the methodology. However, the comment does not provide any specific reasoning or evidence to support this claim, making it difficult for the authors to understand the basis of the critique. The second part of the comment questions the difference between QRS and RS in Algorithm 1 and suggests that the authors should demonstrate a scenario where these methods behave differently. This part is more factual and does not contain a claim. Therefore, the overall comment is 4, as the first part lacks sufficient justification, while the second part is factual.", "helpfulness_rationale": "The review comment raises two distinct issues. First, it questions the authors\" choice of using a relaxation of rejection sampling instead of directly using Importance sampling, suggesting that the authors should provide a justification for their approach. This feedback is 3 as it prompts the authors to clarify their methodology and potentially reconsider their approach. Second, the comment points out a lack of clarity in Algorithm 1, specifically regarding the difference between QRS and RS. The reviewer suggests that the authors should demonstrate a scenario where these methods behave differently, which could help clarify the algorithm\"s logic. This feedback is more actionable, as it provides a specific direction for improvement. Overall, the comment offers some guidance but could be more comprehensive by providing additional context or examples. Therefore, it is rated as 4."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the comparison of computation cost or running time, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on whether the authors should include this comparison, how to conduct it, or what specific aspects to focus on. Without any actionable suggestions or details, the authors are left without a clear understanding of what steps to take in response to this comment. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the comparison of computation cost or running time, but it does not specify which part of the paper this comparison should be included in or what specific aspects need to be addressed. The authors cannot confidently determine which section of the paper this comment pertains to, making it weakly grounded. Additionally, the comment lacks specificity as it does not provide detailed guidance on what aspects of computation cost or running time should be compared or how this comparison should be presented. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point is a question seeking clarification on the comparison of computation cost or running time. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the comparison of computation cost or running time, which is a relevant aspect of the paper. However, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue or what specific comparisons should be made. Without actionable feedback or detailed advice, the authors are left without a clear understanding of how to improve their draft in this area. Therefore, the comment is 2, as it identifies a potential area for improvement but does not offer sufficient guidance to be actionable."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the absence of a comparison against baselines in the study, specifically noting that the reported accuracy across optimization levels of binaries lacks baseline comparisons. The reviewer suggests that this is a widelyunderstood binary analysis application and that many papers have developed architectureagnostic similarity comparisons or reported similar tasks as code search. While the comment implies that the authors should include baseline comparisons, it does not explicitly instruct them to do so or provide specific guidance on which baselines to consider. The action is implicit and somewhat vague, as the authors need to infer that they should include baseline comparisons and determine which ones are relevant. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"functionality similarity comparison study\" and the \"accuracy across optimization levels of binaries,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of lacking baseline comparisons and references similar work in the field. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a comparison against baselines, specifically noting the absence of baseline comparisons in the functionality similarity comparison study. The reviewer supports this claim by stating that many papers have developed architectureagnostic similarity comparisons or reported similar tasks as code search. This provides a logical reasoning and reference to common practices in the field, making the claim 4. However, the comment could be strengthened by providing specific examples of papers that have included baseline comparisons or by elaborating on the importance of such comparisons in the context of the paper. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of baseline comparisons in the functionality similarity comparison study. It highlights the importance of including baselines to provide context and comparison for the reported accuracy across optimization levels of binaries. The comment also references similar work in the field, suggesting that many papers have developed architectureagnostic similarity comparisons or reported similar tasks as code search. This feedback is clear and actionable, as it directs the authors to include baseline comparisons to enhance the validity and relevance of their findings. However, it could be more helpful if it provided specific suggestions on which baselines to consider or how to integrate them into the study. Overall, the comment is 4, as it effectively guides the authors toward improving their draft by addressing a critical gap in their analysis."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The review point points out a specific issue with the abstract, where the authors claim that the proposal distribution upper bounds the target everywhere, which is not true as the authors themselves clarify in the text. However, the comment does not provide any explicit or implicit action for the authors to take. It does not suggest how the authors should address this issue or clarify the discrepancy in the abstract. Without guidance on how to resolve the contradiction or improve the clarity of the abstract, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular issue with the abstract, namely that the authors require the proposal distribution to upper bound the target everywhere, which is not true as the authors themselves clarify in the text. This provides clear guidance on what needs to be addressed in the abstract. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors require the proposal distribution to upper bound the target everywhere, which is not true as the authors themselves clarify in the text. This claim is based on a specific observation within the paper, which provides a clear and direct contradiction to the authors\" claim. The reasoning is logical and straightforward, making the claim 5. The authors can easily verify the claim by referring to the text where the clarification is made. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a specific issue with the abstract, where the authors claim that the proposal distribution upper bounds the target everywhere, which is not true as the authors themselves clarify in the text. This feedback is valuable as it points out a contradiction in the abstract, which can lead to confusion for readers. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or clarify the discrepancy. While it highlights a critical problem, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point questions the intent of Section 5.2, but it does not provide any guidance or suggestions on how the authors should address this concern. It lacks explicit or implicit actions for the authors to take, such as clarifying the purpose of the section or suggesting ways to improve it. Without any direction on how to proceed, the comment is 1.", "grounding_specificity_rationale": "The comment questions the intent of Section 5.2, but it does not specify what aspect of the section is unclear or what specific issue needs clarification. This makes it difficult for the authors to identify the exact part of the paper being addressed and what needs to be improved. The comment lacks grounding and specificity, as it does not provide any details or context to guide the authors in understanding and addressing the issue. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification about the intent of Section 5.2. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment questions the intent of Section 5.2, indicating a lack of clarity or purpose in this section. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve the clarity of the section. Without actionable feedback or detailed insights, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the need for clarification on several aspects of the approach, particularly regarding how the approach allows knowledge about objects to interact with knowledge about verbs to overcome reporting bias. However, it does not provide explicit guidance on what specific aspects need clarification or how the authors should address these concerns. The comment suggests that the paper lacks a clear explanation of the overall approach and its benefits, but it does not offer concrete steps for improvement. As a result, the authors are left with a general understanding of what needs to be clarified but without detailed instructions on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment highlights the need for clarification on several aspects of the approach, particularly regarding how the approach allows knowledge about objects to interact with knowledge about verbs to overcome reporting bias. However, it does not specify which parts of the paper need clarification, making it weakly grounded. The comment is specific in identifying the lack of clarity regarding the approach and its benefits, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the approach needs clarification and questions the understanding of how it allows knowledge about objects to interact with knowledge about verbs to overcome reporting bias. However, the comment lacks specific examples or detailed reasoning to support this claim. It provides a general critique of the paper\"s technical details and the lack of clarity in explaining the overall approach, but it does not offer sufficient evidence or justification to substantiate the claim. As a result, the comment is considered 2, as it provides some insight but lacks the necessary detail to fully support the claim.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that many aspects of the approach need clarification. It specifically questions how the approach allows knowledge about objects to interact with knowledge about verbs to overcome reporting bias, which is a critical aspect of the methodology. The comment also points out that the paper gets into highly technical details without adequately explaining the overall approach and its benefits. This feedback is clear and actionable, as it highlights specific areas where the authors need to provide more detailed explanations to improve the clarity and comprehensibility of their work. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of how to clarify the approach. Overall, the comment is 4, as it directs the authors to focus on critical areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that the chatgpt baseline is rudimentary and suggests testing a fewshot approach. It also recommends including discourse relation information in the prompts, which the reviewer believes could yield good results. However, the comment does not provide explicit instructions on how to implement these suggestions or what specific changes should be made. While the authors can infer that they should test the fewshot approach and consider incorporating discourse relation information, the comment lacks concrete guidance on how to execute these actions. Therefore, the comment is 3, as it provides a general direction but lacks detailed instructions.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"chatgpt baseline\" and the \"fewshot approach,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides a clear suggestion to test the fewshot approach and includes a recommendation to incorporate discourse relation information in the prompts, which could potentially yield better results. The comment also specifies that this addition would enhance the paper\"s evaluation but is extraneous to the current line of evaluation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the chatgpt baseline is rudimentary and suggests testing a fewshot approach. It also recommends including discourse relation information in the prompts, which the reviewer believes could yield good results. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. The suggestion to include discourse relation information is not fully explained, and the claim about the rudimentary nature of the chatgpt baseline is not substantiated with evidence or comparisons. As a result, the comment is 3, as it provides some justification but lacks detailed support, making it difficult for the authors to fully understand and address the feedback.", "helpfulness_rationale": "The review comment identifies a weakness in the paper\"s baseline, specifically noting that the chatgpt baseline is rudimentary and lacks testing of a fewshot approach. It also suggests that incorporating discourse relation information in the prompts, possibly through a ChainofThought style approach, could yield better results. This feedback is clear and actionable, as it provides a specific direction for improvement by suggesting an additional evaluation method. However, the comment could be more helpful if it offered more detailed guidance on how to implement the ChainofThought approach or provided examples of how discourse relation information could be incorporated. Overall, the comment is 4 as it directs the authors to enhance their evaluation by considering a more advanced baseline and additional analysis, but it could be more comprehensive with further elaboration."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment indicates a lack of clarity regarding the number of parameters used in each approach discussed in Section B.3. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion on whether the authors should clarify the number of parameters, provide additional details, or make any specific changes to improve the clarity of this section. Without actionable advice or concrete steps, the authors are left without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section B.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity regarding the number of parameters used in each approach. This provides clear guidance on what needs to be addressed in the section. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual statement requesting clarification on the number of parameters used in each approach. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely a request for information, making it a normal statement and fitting the label \"No\".", "helpfulness_rationale": "The comment identifies a specific area of confusion in the paper, namely the lack of clarity regarding the number of parameters used in each approach discussed in Section B.3. This feedback is 3 as it points out a potential issue that the authors need to address to improve the clarity and comprehensiveness of their draft. However, the comment does not provide specific suggestions or guidance on how to clarify this information, such as recommending the inclusion of specific details or examples. To be more helpful, the comment could offer actionable advice on how to address the issue. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a concern about the statistical significance of the evaluation results reported in Table 1, noting that only three trials were conducted for each case. It suggests that this lack of statistical significance may be the reason why deviations are often reported as zero. The comment also critiques the statement \"our performance is at least two standard deviation better than the next best baseline,\" arguing that it does not make sense due to the limited number of trials. While the comment identifies a potential issue with the statistical significance of the results and the interpretation of deviations, it does not provide explicit guidance on how the authors should address these concerns. The action is implicit and somewhat vague, as the authors are left to infer that they should conduct more trials or provide additional statistical analysis to support their claims. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the evaluation results, noting that only three trials were conducted for each case, which is statistically insignificant. The comment further explains why this lack of statistical significance leads to deviations being reported as zero and questions the validity of statements about performance being significantly better than the next best baseline. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point claims that the evaluation results in Table 1 are based on only three trials for each case, which is statistically insignificant. The reviewer argues that this lack of statistical significance is the reason why deviations are often reported as zero, and it questions the validity of statements about performance being significantly better than the next best baseline. The comment provides a logical reasoning for the claim, noting the limited number of trials as the basis for the lack of statistical significance. However, it could be strengthened by providing specific examples or references to support the claim further. Overall, the comment is 4, as it provides a clear rationale but lacks detailed evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant issue with the statistical significance of the evaluation results reported in Table 1, noting that only three trials were conducted for each case. It explains why this lack of statistical significance may lead to deviations being reported as zero, which in turn affects the validity of statements about performance being significantly better than the next best baseline. This feedback is clear and actionable, as it highlights a critical flaw in the experimental design and suggests that the authors should conduct more trials to ensure statistical significance. By addressing this issue, the authors can improve the robustness and credibility of their results. Therefore, the comment is rated as 5, as it provides specific and actionable guidance for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the architecture used for the experiments is not clearly explained in the paper, and instead, the authors refer to an external source for details. This feedback implies that the authors should provide a clear explanation of the architecture within the paper, rather than relying solely on external references. However, the comment does not specify how the authors should present this information or what specific details should be included. While the action is implicit, it is clear that the authors need to improve the clarity of the architecture explanation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"architecture used for the experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clear explanation of the architecture within the paper. Instead, the authors refer to an external source, making the paper not selfcontained. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the architecture used for the experiments is not clearly explained in the paper, and instead, the authors refer to an external source for details. This claim is 3 as it highlights a potential issue with the paper\"s selfcontainedness. However, the comment lacks specific examples or references to the external source, which would provide more context and justification for the claim. The authors might need to investigate the referenced work to fully understand the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the architecture used for the experiments is not clearly explained within the paper. Instead, the authors rely on an external reference, making the paper less selfcontained. This feedback is clear and actionable, as it highlights a critical area for improvement that directly impacts the comprehensibility and selfsufficiency of the paper. By suggesting that the authors should provide a clear explanation of the architecture within the paper, the comment offers a specific direction for enhancing the draft. However, it could be more helpful if it provided additional guidance on how to present the architecture details effectively. Overall, the comment is 4, as it effectively directs the authors to a key area needing attention, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point identifies several specific issues with the presentation quality of the paper, such as the use of \"\" in tables, the lack of informative \"Dataset\" columns, and the management of Figure 3 and Table 2. However, it does not provide explicit guidance on how to address these issues or suggest specific actions for improvement. The authors can infer that they need to improve the presentation quality, but the comment lacks concrete details on how to do so. Therefore, the comment is 3, as it identifies areas for improvement but does not provide detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific aspects of the paper, such as Figures 1&2, tables with a \"\" for the method, the \"Dataset\" columns in the tables, the management of Figure 3 and Table 2, and a \"*\" appearing in Table 1 with no indication of meaning. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it details what aspects of the presentation quality are considered weaknesses, providing clear guidance on what needs to be improved. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point identifies specific issues with the presentation quality of the paper, such as the use of \"\" in tables, the lack of informative \"Dataset\" columns, and the management of Figure 3 and Table 2. However, it does not provide detailed reasoning or examples to support why these aspects are considered weaknesses or how they impact the overall quality of the paper. The comment lacks specific references or evidence to substantiate the claim, making it difficult for the authors to understand and address the issues effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail and justification.", "helpfulness_rationale": "The review comment identifies specific issues with the presentation quality of the paper, such as the use of \"\" in tables, the lack of informative \"Dataset\" columns, and the management of Figure 3 and Table 2. It also points out the appearance of a \"*\" in Table 1 without explanation. While the comment highlights areas for improvement, it does not provide detailed guidance or suggestions on how to address these issues. The feedback is 3 as it directs the authors\" attention to specific aspects of the presentation that need attention, but it lacks actionable advice or examples of how to improve these areas. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the proposed upweighing and KNN methods, suggesting that they do not seem to be idiomspecific based on the results presented in Figure 3. The comment implies that the methods are not effective in distinguishing between idiomatic and random data, and it concludes that the results merely indicate that better NMT systems are also better at idiomatic translations. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their methods. The action is implicit and vague, as the authors are left without clear direction on how to enhance their work. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the proposed upweighing and KNN methods, noting that the impact on idiomatic versus random data is similar for most language and score combinations. The comment further critiques the results by suggesting that the methods are not idiomspecific and that the findings merely indicate that better NMT systems are also better at idiomatic translations. This level of detail provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed upweighing and KNN methods do not seem to be idiomspecific, as the impact on idiomatic versus random data is similar for most language and score combinations. The comment references Figure 3, which provides some visual support for the claim. However, the claim is 3 because it lacks specific examples or detailed analysis to fully substantiate the assertion. The authors would need to examine Figure 3 more closely to understand the basis of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a critical analysis of the proposed upweighing and KNN methods, suggesting that they do not seem to be idiomspecific based on the results presented in Figure 3. The comment points out that the impact on idiomatic versus random data is similar for most language and score combinations, implying that the methods are not effective in distinguishing between idiomatic and random data. This feedback is valuable as it highlights a potential limitation in the proposed methods, prompting the authors to reconsider their approach or provide further justification for the effectiveness of their methods. However, the comment could be more helpful if it offered suggestions on how to address this issue or improve the methods. Overall, the comment is 3, as it identifies a weakness but lacks actionable guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to include important references for domain adaptation and to discuss them in the revised manuscript. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and actionable, as it specifies the type of references that should be included and the action of discussing them in the manuscript. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the paper lacks important references for domain adaptation and instructs the authors to include them in the revised manuscript. However, it does not specify which references are missing or where in the paper these references should be included. This makes it difficult for the authors to pinpoint the exact parts of the paper that need revision. The comment is specific in its request for additional references but lacks grounding as it does not identify a specific section or part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks important references for domain adaptation and suggests that the authors should include and discuss these references in the revised manuscript. However, the comment does not provide specific examples of the missing references or explain why they are crucial for the paper. Without detailed justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2, as it lacks sufficient evidence or reasoning to fully support the claim.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of important references for domain adaptation. It provides a clear and actionable suggestion for the authors to include and discuss these references in the revised manuscript. This feedback is valuable as it directs the authors to a specific area for improvement, ensuring that their work is more comprehensive and aligned with current literature. However, the comment could be more helpful if it provided specific examples of the missing references or discussed how these references would enhance the paper. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a specific issue with the claim that PACE addresses a gap in climate emulation by treating it as a diagnostictype prediction, noting that prior work (e.g., ClimateBench or ClimateSet) already does this. However, the comment does not provide explicit guidance on how the authors should address this issue or clarify the claim. It lacks concrete suggestions on how to revise the claim or what additional information should be included to make it clearer. As a result, the authors are left with an implicit action to clarify the claim but without detailed guidance on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim that \"To address this gap, we propose PACE, which treats climate emulation as a diagnostictype prediction,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that prior work (e.g., ClimateBench or ClimateSet) already addresses this gap, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement \"To address this gap, we propose PACE, which treats climate emulation as a diagnostictype prediction\" is misleading because prior work (e.g., ClimateBench or ClimateSet) already addresses this gap. The comment provides a specific example of prior work that contradicts the claim, which is a clear and logical reasoning to support the claim. This makes the comment 5, as it provides a direct and specific reference to external work that challenges the claim. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a specific issue with the claim that PACE addresses a gap in climate emulation by treating it as a diagnostictype prediction. It points out that prior work, such as ClimateBench or ClimateSet, already addresses this gap, making the claim misleading. This feedback is clear and actionable, as it prompts the authors to clarify their claim or provide a more nuanced explanation of how PACE differs from existing work. However, the comment could be more helpful if it suggested ways to address this issue or offered examples of how PACE might contribute to the field. Overall, the comment is 4 as it directs the authors to a critical area needing clarification, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a potential confusion in the use of the symbol \"r\" to denote both the risk for minimization problems and the primal risk for minimax problems. However, it does not provide any explicit or implicit guidance on how to address this issue. The authors are left without a clear understanding of what needs to be done to resolve the confusion. Without specific suggestions or instructions, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment identifies a specific issue with the use of the symbol \"r\" to denote both the risk for minimization problems and the primal risk for minimax problems. However, it does not specify which part of the paper this issue occurs in, such as a particular section or equation where this notation is used. Without explicit references to the sections or equations, the authors cannot confidently determine the exact part of the paper being addressed. This makes the comment weakly grounded, as the authors can only infer the general area where the issue might be. The comment is specific in identifying the confusion regarding the use of \"r,\" but without full grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point claims that using \"r\" to denote both the risk for minimization problems and the primal risk for minimax problems is confusing. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this notation is problematic or how it could be improved. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment identifies a potential source of confusion in the paper, specifically the use of the symbol \"r\" to denote both the risk for minimization problems and the primal risk for minimax problems. This is a clear and specific observation that could help the authors clarify their notation and improve the readability of their work. However, the comment does not provide any suggestions or guidance on how to resolve this issue, such as recommending alternative notations or explaining the potential impact of the confusion. While it highlights a problem, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point criticizes the use of a table to present factors, suggesting that it does not provide additional information compared to pure text. However, it does not offer any explicit or implicit actions for the authors to take. There is no guidance on how to improve the presentation of the factors or what specific changes should be made to enhance the clarity or effectiveness of the information. Without any actionable suggestions or concrete steps, the authors are left without a clear understanding of how to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment criticizes the use of a table to present factors, suggesting that it does not provide additional information compared to pure text. However, it does not specify which table or section of the paper this critique pertains to, making it difficult for the authors to identify the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the table are problematic or how it could be improved. Without clear grounding and specificity, the authors are left without a clear understanding of what needs to be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that \"making the factors in a table does not help convey more messages than pure text\" and that \"there is no more information at all.\" However, the comment lacks any supporting evidence, reasoning, or examples to substantiate this claim. Without specific examples or references to illustrate why the table is ineffective, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment criticizes the use of a table to present factors, suggesting that it does not provide additional information compared to pure text. However, it lacks specificity and does not offer any actionable suggestions or guidance on how the authors might improve the presentation of the factors or the effectiveness of the table. Without detailed feedback or constructive advice, the authors are left without a clear understanding of what changes could be made to enhance the clarity or impact of their work. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the authors\" approach to pruning, noting that it primarily works with large networks trained in distributed settings. It suggests that the authors should consider finding global top Q values of the metric over the average of gradients to avoid breaking acceleration techniques like quantization and sparsification. While the comment implies that the authors should address this issue, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore this aspect of their work. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"pruning\" and \"large networks,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the potential need to find global top Q values of the metric over the average of gradients to avoid breaking acceleration techniques like quantization and sparsification. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that pruning primarily works with large networks trained in distributed settings and suggests that the authors should consider finding global top Q values of the metric over the average of gradients to avoid breaking acceleration techniques like quantization and sparsification. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that finding global top Q values is necessary or how it would impact acceleration techniques. The lack of detailed justification makes it difficult for the authors to fully understand and address the concern. Therefore, the comment is considered 2, as it provides some insight but requires more detailed evidence or explanation to be 5.", "helpfulness_rationale": "The review comment identifies a potential issue with the authors\" approach to pruning, noting that it primarily works with large networks trained in distributed settings. It suggests that the authors should consider finding global top Q values of the metric over the average of gradients to avoid breaking acceleration techniques like quantization and sparsification. This feedback is 3 as it points out a specific area where the authors might need to address potential limitations or tradeoffs in their methodology. However, the comment could be more helpful if it provided additional context or examples on how to implement this suggestion or why it is important. Overall, the comment offers a valuable insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review comment points out that multiple entities exist in both sentences and documents, even in relation classification tasks, which is not limited to documentlevel RE or joint entity and relation extraction. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this observation or how it might impact the paper. Without any actionable suggestions or questions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 2627, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clarifies that multiple entities exist in both sentences and documents, even in relation classification tasks, which is not limited to documentlevel RE or joint entity and relation extraction. This provides clear guidance on what the authors need to address in their paper. Therefore, this comment is labeled as 5, corresponding to a score of 5.", "verifiability_rationale": "The review point is a factual statement describing the existence of multiple entities in both sentences and documents, even in relation classification tasks. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment points out a factual observation regarding the existence of multiple entities in both sentences and documents, even in relation classification tasks. However, it does not provide any actionable feedback or suggestions for improvement. The comment lacks depth and does not offer guidance on how this observation might impact the paper or how the authors could address it. As a result, the comment is 1, as it does not provide any actionable insights or suggestions for the authors to enhance their draft."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point asks for a comparison of the proposed method with prior art, but it does not provide any guidance or suggestions on how to conduct this comparison or what specific aspects should be considered. The action is implicit and vague, as the authors are left to infer that they need to provide a comparison but without concrete details on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment asks for a comparison of the proposed method with prior art, but it does not specify which part of the paper this comparison should be included in. This makes it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the comparison are of interest or what specific prior art should be considered. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification on how the proposed method compares with prior art. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a critical question about the comparison of the proposed method with prior art. This is an important aspect that the authors need to address to provide context and relevance for their work. However, the comment lacks specificity and does not offer any guidance or suggestions on how to conduct this comparison or what specific aspects should be considered. While it identifies a key area for improvement, the lack of detailed feedback limits its helpfulness. Therefore, the comment is 3, as it points out an important area for improvement but does not provide actionable steps for the authors to take."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the redundancy of RQ1, suggesting that it does not provide additional information for the audience. It implies that the authors should focus on analyzing how the percentage of explicit hate information in the dataset affects implicit hate speech detection performance and its impact on RQ2 and RQ3 tsne plots. While the comment highlights an area for improvement, it does not explicitly instruct the authors to make these changes or provide detailed guidance on how to implement them. The action is implicit and somewhat vague, as the authors need to infer that they should focus on these specific analyses. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"RQ1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the redundancy of RQ1 and suggesting an alternative analysis that could be more informative. The comment provides a specific suggestion for an additional analysis, which is clear and actionable. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that RQ1 is redundant and suggests an alternative analysis that would be more informative. The reviewer provides a specific reference to a related work that could support this claim, which enhances the verifiability of the comment. However, the comment could be strengthened by providing more detailed reasoning or examples within the paper to fully substantiate the claim. Therefore, the comment is 4, as it provides a solid foundation but lacks complete evidence within the paper itself.", "helpfulness_rationale": "The review comment identifies a potential redundancy in the paper, specifically questioning the need for RQ1. It suggests that the expected outcome of varying performance across multiple hate speech datasets in a crossdata setting is already implied, and proposes an alternative analysis that could be more informative. The comment provides a specific suggestion for an additional analysis, which is clear and actionable. However, it could be more helpful if it included a detailed explanation of why the current analysis is redundant or how the proposed analysis would enhance the paper. Overall, the comment is 4 as it offers a constructive suggestion for improvement, but it could be more comprehensive with additional context and reasoning."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the objective for the LSTM part would be the same for pretraining and finetuning, as it involves computing the probabilities of actions. It also implies that in the finetuning stage, the authors may add another head to the network to compute value functions for states. While the comment provides some guidance on potential changes, it does not explicitly instruct the authors to make these modifications. The action is implicit and somewhat vague, as it lacks specific instructions on how to implement the suggested changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"LSTM part,\" allowing the authors to accurately identify the section being addressed. It is also specific because it details the objective for the LSTM part, which would be the same for pretraining and finetuning, and suggests adding another head to the network for computing value functions in the finetuning stage. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point suggests that the objective for the LSTM part would be the same for pretraining and finetuning, as it involves computing the probabilities of actions. It also implies that in the finetuning stage, the authors may add another head to the network to compute value functions for states. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. The suggestion is based on logical reasoning, but without further elaboration, it remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the paper by clarifying the objective for the LSTM part, which would be the same for pretraining and finetuning. It also suggests adding another head to the network to compute value functions for states in the finetuning stage. This feedback is clear and actionable, offering the authors a concrete way to enhance their draft. However, the comment could be more helpful if it explained why this change is necessary or how it would benefit the paper. Overall, the comment is 4 as it provides valuable guidance for improving the draft, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should acknowledge older works in the related works section, specifically mentioning the use of supervised, multilingual systems. While the comment implies that the authors should include these older works, it does not provide specific examples or guidance on which older works to include or how to integrate them into the related works section. The action is implicit and somewhat vague, as the authors need to infer which older works to include and how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"related works\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests acknowledging older works in the context of using supervised, multilingual systems. This provides clear guidance on what needs to be addressed in the related works section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should acknowledge older works in the related works section, specifically mentioning the use of supervised, multilingual systems. However, the comment does not provide specific examples of older works that should be acknowledged or detailed reasoning for why these works are relevant. Without such examples or detailed justification, the claim lacks sufficient evidence to be 5. Therefore, the comment is considered 2, as it provides a general suggestion but lacks the necessary details to fully substantiate the claim.", "helpfulness_rationale": "The review comment suggests that the authors should acknowledge older works in the related works section, specifically mentioning the use of supervised, multilingual systems. This feedback is 3 as it points out a potential gap in the literature review, encouraging the authors to include relevant older works. However, the comment lacks specificity and does not provide examples of specific older works that should be acknowledged or detailed guidance on how to integrate them into the related works section. While it identifies a potential area for improvement, the feedback could be more actionable and comprehensive to be fully helpful. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the results in Table 2, specifically the comparison between linear/exponentialdecay sampling and uniform sampling. The reviewer suggests that if the predictor is accurate on the good subregion, as argued by the authors, increasing the sampling probability for topperforming predicted architectures should lead to better performance than uniform sampling. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their analysis. The action is implicit and vague, as the authors are left to infer that they need to clarify or further explore the results in Table 2. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the results, questioning the logic behind the comparison between linear/exponentialdecay sampling and uniform sampling. The comment provides a clear rationale for why the results are confusing and suggests a potential explanation for the observed underperformance. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the results in Table 2, specifically the comparison between linear/exponentialdecay sampling and uniform sampling. The reviewer suggests that if the predictor is accurate on the good subregion, as argued by the authors, increasing the sampling probability for topperforming predicted architectures should lead to better performance than uniform sampling. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the results in Table 2, specifically the comparison between linear/exponentialdecay sampling and uniform sampling. It suggests that if the predictor is accurate on the good subregion, as argued by the authors, increasing the sampling probability for topperforming predicted architectures should lead to better performance than uniform sampling. This feedback is 3 as it points out a potential inconsistency or misunderstanding in the results, prompting the authors to reconsider their analysis or provide further explanation. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as recommending additional experiments or analyses. Therefore, while it identifies a potential area for improvement, it does not provide comprehensive or actionable feedback, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to explain why and how their SE framework can help improve, similar to the feedback provided in comment 2. It also suggests that the authors should not just show what they have achieved but should explain the reasoning behind their achievements. The comment provides a clear action for the authors to take, which is to provide a detailed explanation of the benefits and mechanisms of their framework. Additionally, it offers a concrete suggestion to increase the rating based on the authors\" response. This makes the comment 5, as it gives the authors specific guidance on how to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"4\" and \"2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, which is the explanation of how the SE framework helps improve and why it is beneficial. The comment provides a reference to a relevant work, further grounding the feedback. However, it could be more specific in detailing exactly what aspects of the framework need further explanation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a request for clarification and a suggestion for improvement. It does not contain any subjective claims, opinions, or judgments that require verification. It is purely a request for additional information and guidance, making it a factual statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment provides clear and actionable feedback by asking the authors to explain why and how their SE framework can help improve, similar to the feedback given in comment 2. It emphasizes the importance of not only showing what has been achieved but also explaining the reasoning and methodology behind the achievements. This feedback is valuable as it directs the authors to enhance the clarity and depth of their explanations, which can significantly improve the comprehensibility and impact of their work. However, the comment could be more helpful if it offered specific suggestions on how to present this information or provided examples of effective explanations. Overall, the comment is 4, as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential limitation of the metrics used for evaluating continual learning, specifically the loss after switch and recovery time after switch. It suggests that these metrics may not be applicable in settings where task boundaries are unknown or not clearly defined. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest alternative metrics that could be more suitable. The action is implicit and somewhat vague, as the authors are left to infer that they should consider alternative metrics or adapt their evaluation approach. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the metrics used for evaluating continual learning, specifically mentioning \"loss after switch\" and \"recovery time after switch.\" However, it does not specify which part of the paper discusses these metrics, making it weakly grounded. The comment is specific in detailing the limitations of these metrics in certain settings, such as when task boundaries are unknown or not clearly defined. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the metrics used for evaluating continual learning, such as loss after switch and recovery time after switch, are not applicable in settings where task boundaries are unknown or not clearly defined. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The lack of evidence or detailed justification makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the metrics used for evaluating continual learning, specifically the loss after switch and recovery time after switch. It points out that these metrics may not be applicable in settings where task boundaries are unknown or not clearly defined. This feedback is 3 as it highlights a specific area where the evaluation methodology might be limited, prompting the authors to consider alternative metrics or adapt their approach to better suit different scenarios. However, the comment could be more helpful if it provided suggestions for alternative metrics or ways to address this limitation. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the potential bias in the sketch due to the need to compute the statistical dimension d_lambda of the design matrix A. It suggests that this computation requires the same runtime as solving the ridge regression problem, which could defeat the purpose of the approach. The comment implies that the authors should address this issue by discussing it in the paper, but it does not provide explicit instructions on how to do so. While the action is implicit, it is 3 as it points out a potential issue that the authors should consider. However, the lack of concrete guidance on how to address the issue limits its actionability.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the computation of the statistical dimension d_lambda of the design matrix A, which is crucial for debiasing the sketch. It also mentions a similar issue when computing the surrogate sketch. However, the comment does not specify which part of the paper discusses these issues, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but without explicit references, it is challenging to pinpoint the exact location. The comment is specific in detailing the issue and its potential impact on the approach, but the lack of grounding limits its effectiveness. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the statistical dimension d_lambda of the design matrix A is necessary for debiasing the sketch, but this computation requires the same runtime as solving the ridge regression problem, potentially defeating the purpose of the approach. The reviewer supports this claim by providing logical reasoning about the computational complexity involved. However, the comment lacks specific references or examples to fully substantiate the claim, making it 3. The authors would need to consider the reasoning and potentially seek additional evidence to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the debiasing of the sketch, specifically the need to compute the statistical dimension d_lambda of the design matrix A. It points out that this computation requires the same runtime as solving the ridge regression problem, which could defeat the purpose of the approach. The comment also mentions a similar issue when computing the surrogate sketch. While it highlights a critical concern, it does not provide specific suggestions or guidance on how the authors might address this issue or mitigate the potential bias. The feedback is 3 as it alerts the authors to a potential weakness in their approach, but it lacks actionable advice for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the error analysis on the movie dataset is missing, which is a clear action for the authors to take. It also provides a specific suggestion for improvement by indicating that other researchers need to know the cases where the model fails. This feedback is concrete and direct, giving the authors a clear understanding of what needs to be addressed in their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment addresses the absence of an error analysis on the movie dataset, which is a specific aspect of the paper. However, it does not explicitly mention which part of the paper discusses the movie dataset, making it weakly grounded. The comment is specific in its request for an error analysis to help other researchers understand the model\"s failures. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the error analysis on the movie dataset is missing, which is a critical aspect for other researchers to continue working on the task. However, the comment does not provide any specific examples or detailed reasoning to support why this analysis is necessary or how it would benefit the research community. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2, as it lacks sufficient justification or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of an error analysis on the movie dataset. This feedback is valuable as it highlights a critical area that needs attention to ensure the paper\"s contribution is fully understood and reproducible. By suggesting that other researchers need to know the cases where the model fails, the comment provides a clear direction for improvement. However, the comment could be more helpful if it offered specific suggestions on how to conduct the error analysis or what aspects to focus on. Overall, the comment is 4 as it directs the authors to a crucial area for enhancement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide a more detailed plan on how they plan to address the limitations mentioned in the paper in their future work. While the comment explicitly states that the authors should include a detailed plan, it does not specify what aspects of the limitations should be addressed or how to structure the plan. The action is explicit but lacks concrete guidance on execution, making it 3.", "grounding_specificity_rationale": "The comment suggests that the authors should provide a more detailed plan on how they plan to address the limitations mentioned in the paper. However, it does not specify which limitations or sections of the paper are being referred to, making it difficult for the authors to pinpoint the exact areas that need improvement. The comment is specific in its request for a detailed plan but lacks grounding as it does not identify the specific parts of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide a more detailed plan on how they plan to address the limitations mentioned in the paper. However, it does not provide any specific examples or reasoning to support why the current plan is insufficient or how a more detailed plan would improve the paper. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand and address the feedback effectively. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment acknowledges that the authors have mentioned limitations in their paper but suggests that they should provide a more detailed plan on how they plan to address these drawbacks in their future work. This feedback is 3 as it encourages the authors to be more specific and transparent about their plans for improvement. However, it lacks depth and does not provide detailed guidance on what aspects of the limitations should be addressed or how to structure the plan. While it points out an area for improvement, it does not offer actionable steps or suggestions, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises an expectation that the amount of computation for FedMITR is higher than other methods and asks whether this has been compared. While the comment implies that the authors should compare the computation of FedMITR with other methods, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to compare the computation but are not given specific guidance on how to conduct the comparison. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the computational complexity of FedMITR compared to other methods, but it does not specify which part of the paper this comparison should be made in. The authors can infer that it relates to the experimental results or methodology sections, but this inference is not explicit. The comment is specific in its request for a comparison, but it lacks grounding as it does not directly reference a particular section or element of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the computational complexity of FedMITR compared to other methods, suggesting that it is expected to be higher. However, the comment does not provide any supporting evidence, reasoning, or references to justify this expectation. Without additional context or data, the claim remains 1, as the authors are left without a clear understanding of why this comparison is expected or how to address it. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the computational complexity of FedMITR compared to other methods, suggesting that it is expected to be higher. This is a relevant point that could be addressed in the paper, as it provides an opportunity to compare the efficiency of the proposed method with existing alternatives. However, the comment lacks specificity and does not offer any guidance on how to conduct this comparison or what specific aspects of computation should be considered. While it identifies a potential area for improvement, the feedback is somewhat vague and incomplete, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the authors can avoid using \"1) and2)\" by using a generic external knowledge base, as demonstrated in Figure 3. However, the comment is vague because it does not specify which parts of the paper should be revised or how to implement the suggestion. The authors are left without clear guidance on how to address the issue of confusion in the writing. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that \"1) and2)\" can be avoided by using a generic external knowledge base, as shown in Figure 3. However, it does not specify which parts of the paper these references are from, making it weakly grounded. The comment also lacks specificity as it does not detail what is confusing or how the writing could be improved. Therefore, this comment is 2, aligning with category 2.", "verifiability_rationale": "The review point suggests that \"1) and2)\" can be avoided by using a generic external knowledge base, as shown in Figure 3. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide a clear explanation of how using a generic external knowledge base would address the issues with \"1) and2),\" making it difficult for the authors to understand and address the feedback. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that \"1) and2)\" can be avoided by using a generic external knowledge base, as shown in Figure 3. However, the comment lacks specificity and does not provide detailed guidance on how to implement this suggestion or what aspects of the paper should be revised. Additionally, the comment mentions that the writing is confusing, but it does not specify which parts are confusing or how they could be clarified. This lack of detail and actionable feedback makes the comment 2, as it provides only a vague direction for improvement without concrete steps for the authors to follow."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a mistake in the definition of perplexity and provides a correction. It also points out that the equation presented does not look like perplexity but rather like crossentropy. This feedback is clear and direct, providing the authors with specific actions to take: correcting the definition of perplexity and ensuring that the equation presented is indeed perplexity. The comment is 5 as it provides concrete steps for the authors to follow, ensuring they can make the necessary changes to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific line numbers (\"L259\") and equations (\"Eq1\") where the issues are identified, allowing the authors to accurately pinpoint the parts of the paper being addressed. It is also specific because it clearly specifies the problem with the definition of perplexity and the equation presented, providing a clear direction for correction. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the definition of perplexity at line 259 is incorrect and that the equation presented (Eq1) does not look like perplexity but rather like crossentropy. This claim is verifiable as it provides a clear and specific correction to the definition of perplexity, which is a wellestablished concept in natural language processing. The comment also points out the discrepancy between the definition and the equation, which helps the authors understand the issue. However, the comment could be strengthened by providing references or examples to further substantiate the claim. Therefore, the comment is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment identifies a specific error in the definition of perplexity and the equation presented, which is a critical aspect of the paper. It provides a clear and direct correction to the definition of perplexity, which is valuable feedback for the authors. By pointing out the discrepancy between the definition and the equation, the comment offers actionable guidance on how to improve the accuracy and clarity of the paper. However, the comment could be more helpful if it included additional context or suggestions on how to address the issue, such as recommending a specific reference or explanation for the correction. Overall, the comment is 4 as it directs the authors to a significant error and provides a clear path for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the model has many components with hyperparameters that are not fully provided, suggesting that someone might need to trace them in the source code. While the comment implies that the authors should provide more detailed information about the hyperparameters, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment mentions that the model has many components with hyperparameters that are not fully provided, suggesting that someone might need to trace them in the source code. However, it does not specify which part of the paper this issue pertains to, such as a specific section or figure where these components are discussed. This lack of explicit reference makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing the issue of missing hyperparameter information, but without grounding, it is difficult for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the model has many components with hyperparameters that are not fully provided, suggesting that someone might need to trace them in the source code. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand which components or hyperparameters are missing. Without detailed information or evidence, the claim is not verifiable, as it does not provide sufficient context or justification for the authors to address the issue effectively. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the model has many components with hyperparameters that are not fully provided. This feedback is 3 as it points out a potential weakness in the presentation of the model, which could impact reproducibility and understanding. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending which hyperparameters should be included or how to present them more clearly. While it highlights an area for improvement, the comment could be more helpful with additional details or actionable advice. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point identifies an incorrect assertion made by the authors regarding the Central Limit Theorem (CLT) on line 238. It clarifies that the CLT does not guarantee Gaussianity in a nonasymptotic regime and does not hold for a finite linear combination of arbitrary random variables. However, the comment does not provide explicit guidance on how the authors should correct this assertion or what specific changes should be made to the draft. The action is implicit and somewhat vague, as the authors can infer that they need to revise their statement, but they are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 238,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the authors\" claim regarding the Central Limit Theorem (CLT), pointing out that it makes multiple incorrect assertions. The comment provides a detailed explanation of why the claim is incorrect, which helps the authors understand what needs to be revised. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors\" statement regarding the Central Limit Theorem (CLT) is incorrect. It provides a detailed explanation of why the claim is invalid, specifically noting that the CLT does not guarantee Gaussianity in a nonasymptotic regime and does not hold for a finite linear combination of arbitrary random variables. This reasoning is clear and logical, providing a robust basis for the claim. Therefore, the comment is 5.", "helpfulness_rationale": "The review comment identifies a specific issue with the authors\" claim regarding the Central Limit Theorem (CLT) on line 238. It points out that the statement is incorrect, as the CLT does not guarantee Gaussianity in a nonasymptotic regime and does not hold for a finite linear combination of arbitrary random variables. This feedback is clear and actionable, as it provides the authors with a precise correction to their claim, which is crucial for the accuracy and validity of their work. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided additional context or references to support the correction. Overall, the comment is 4, as it effectively directs the authors to a critical error in their draft and guides them toward a more accurate understanding of the CLT."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the relevance of the proposed method to the authors\" motivations, specifically questioning the effectiveness of automatic scores and the affordability of human evaluation scores. It also suggests that the proposed framework, FFAEVAL, and similar frameworks like Chatbot Arena are not suitable for evaluating a single dialogue system, such as providing fluency scores. The comment implies that arenabased evaluation systems may not address the issues with scorebased evaluation systems. However, it does not provide explicit guidance or suggestions on how the authors might address these concerns or improve their draft. The action is implicit and somewhat vague, as the authors are left to infer what changes might be necessary without concrete steps or examples. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the relevance of the proposed method to the authors\" motivations, specifically questioning the effectiveness of automatic scores and the affordability of human evaluation scores. It also discusses the limitations of the proposed framework, FFAEVAL, and similar frameworks like Chatbot Arena in evaluating a single dialogue system. However, the comment does not explicitly mention which part of the paper these issues are discussed in, making it weakly grounded. The authors can infer that it relates to the abstract or introduction sections, but this inference is not direct. The comment is specific in detailing the limitations of the proposed method and its relevance to the authors\" motivations. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a claim about the relevance of the proposed method to the authors\" motivations, specifically questioning the effectiveness of automatic scores and the affordability of human evaluation scores. It also suggests that the proposed framework, FFAEVAL, and similar frameworks like Chatbot Arena are not suitable for evaluating a single dialogue system. The comment provides a logical reasoning by contrasting the arenabased evaluation systems with the current scorebased evaluation systems, suggesting that the former may not address the issues with the latter. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to further explore the reasoning and evidence to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical point about the relevance of the proposed method to the authors\" motivations, specifically questioning the effectiveness of automatic scores and the affordability of human evaluation scores. It also suggests that the proposed framework, FFAEVAL, and similar frameworks like Chatbot Arena are not suitable for evaluating a single dialogue system, such as providing fluency scores. The comment provides a logical reasoning by contrasting arenabased evaluation systems with scorebased evaluation systems, suggesting that the former may not address the issues with the latter. However, the comment lacks specific suggestions or guidance on how the authors might address these concerns or improve their draft. While it identifies a potential weakness, it does not offer actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about whether improvements could be observed with a different encoder, such as RoBERTabase, instead of BERT. However, it does not provide any explicit or implicit action for the authors to take. There is no guidance on whether the authors should test this hypothesis, make changes to their encoder, or address the issue in their discussion. The comment lacks actionable details, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about whether improvements could be observed with a different encoder, such as RoBERTabase, instead of BERT. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment lacks specificity as it does not detail what improvements are expected or how the encoder choice might impact the results. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question asking for clarification on whether improvements could be observed with a different encoder, such as RoBERTabase, instead of BERT. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information or clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about whether improvements could be observed with a different encoder, such as RoBERTabase, instead of BERT. While it identifies a potential area for exploration, it lacks specificity and does not provide any actionable guidance or suggestions for the authors. The comment does not offer insights into why this change might be beneficial or how it could impact the results, leaving the authors without a clear direction for improvement. As a result, the comment is 2, as it points out a possible area of interest but does not provide enough detail or direction to be actionable."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should demonstrate how their proposed method can achieve fair policy learning without severely damaging the performance of the predictive model. This is an explicit request for the authors to provide additional evidence or examples to support their claims. However, the comment does not specify how the authors should present this information or what specific aspects of the method should be highlighted. While the action is clear, the lack of detailed guidance makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should demonstrate how their proposed method can achieve fair policy learning without severely damaging the performance of the predictive model. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper that needs revision. Additionally, while the comment provides a clear suggestion for improvement, it does not specify what aspects of the method should be highlighted or how to present the evidence. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the authors should demonstrate how their proposed method can achieve fair policy learning without severely damaging the performance of the predictive model. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it could be achieved. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the authors should demonstrate how their proposed method can achieve fair policy learning without severely damaging the performance of the predictive model. This is a clear and actionable suggestion that could help the authors improve their draft by providing additional evidence or examples to support their claims. However, the comment could be more helpful if it offered specific guidance on how to present this information or what aspects of the method should be highlighted. Despite this, the feedback is 4 as it directs the authors to a critical area for improvement, providing a clear path for enhancing their work. Therefore, the comment is rated as 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out a specific issue with the use of the phrase \"to meet\" in the paper, stating that it is difficult to understand. However, it does not provide any explicit or implicit guidance on how the authors should address this issue or suggest alternative phrasing. The comment lacks actionable details, such as recommending a different way to express the concept or explaining why the current phrasing is problematic. As a result, the authors are left without a clear understanding of what needs to be changed or improved. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific line number (\"line 280\") where the issue with the phrase \"to meet\" is observed. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue with the phrase \"to meet,\" indicating that it is difficult to understand. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the phrase \"to meet\" is used in a way that is difficult to understand, specifically mentioning \"a response candidate can meet each utterance\" on line 280. However, the comment does not provide any further explanation or context to support why this usage is problematic or how it could be improved. Without additional details or examples, the claim lacks sufficient justification, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the use of the phrase \"to meet\" in the paper, noting that it is difficult to understand. However, it does not provide any suggestions or guidance on how to improve the clarity or rephrase the sentence to make it more understandable. Without actionable feedback or examples, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, as it points out a potential issue but lacks depth and specificity in its feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a specific issue with the Perceptual Metric in Figure 2, suggesting that the Second Inpainted Images should be connected to the Inpainted Image rather than the Images Masked by Second Masks. This feedback is explicit and provides a clear action for the authors to take, which is to correct the connection in the figure. The comment is also concrete, as it specifies exactly what needs to be changed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the Perceptual Metric, indicating that the Second Inpainted Images should be connected to the Inpainted Image rather than the Images Masked by Second Masks. This provides clear guidance on what needs to be corrected in the figure. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about the connection between the Second Inpainted Images and the Inpainted Image in Figure 2. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the Perceptual Metric in Figure 2, pointing out that the Second Inpainted Images should be connected to the Inpainted Image rather than the Images Masked by Second Masks. This feedback is clear and actionable, providing the authors with a precise direction for correcting an error in their figure. By addressing this issue, the authors can improve the clarity and accuracy of their presentation, which is crucial for the understanding of their results. However, the comment could be more helpful if it included an explanation of why this connection is important or how it affects the interpretation of the results. Overall, the comment is 4 as it directs the authors to a specific improvement that can enhance the quality of their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out an inconsistency between Figures 1 and 2, specifically noting that Figure 2 shows one encoderdecoder per auxiliary task, while Figure 1 shows a single shared encoderdecoder for multiple tasks. This feedback is explicit and provides a clear action for the authors to take, which is to ensure consistency between the figures. The comment is also concrete, as it specifies the exact inconsistency and guides the authors on how to address it. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig 1\" and \"Fig 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the inconsistency between the figures, noting that Figure 2 shows one encoderdecoder per auxiliary task, while Figure 1 shows a single shared encoderdecoder for multiple tasks. This provides clear guidance on what needs to be addressed to ensure consistency. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 1 is inconsistent with Figure 2, specifically noting that Figure 2 shows one encoderdecoder per auxiliary task, while Figure 1 shows a single shared encoderdecoder for multiple tasks. This claim is based on a direct observation of the figures, which is a factual statement. However, the comment does not provide any additional reasoning or context to support why this inconsistency is significant or how it affects the paper\"s conclusions. Therefore, the claim is 3, as it requires further explanation or examples to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a specific inconsistency between Figures 1 and 2, noting that Figure 2 shows one encoderdecoder per auxiliary task, while Figure 1 shows a single shared encoderdecoder for multiple tasks. This feedback is clear and actionable, as it points out a critical inconsistency that the authors need to address to ensure the figures are consistent and accurate. By highlighting this issue, the comment provides the authors with a clear direction for improvement, making it 4. However, it could be more helpful if it included suggestions on how to resolve the inconsistency or why it is important for the paper\"s clarity. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights several issues with the paper, including the lack of clarity in the main contribution and the unclear explanation of how the proposed method copes with dynamic largescale multitasking. It also points out that the automation aspect is unclear. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues. The actions are implicit and somewhat vague, as the authors are left to infer what specific changes are needed to clarify the main contribution and the automation aspect. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the main contribution of the paper, which is unclear, and points out that the proposed method\"s ability or applicability is either overstated or not wellsupported. It also mentions that the main idea of how the proposed method copes with dynamic largescale multitasking is unclear and that the automation aspect is unclear. However, the comment does not specify which sections of the paper these issues pertain to, making it weakly grounded. The comment is specific in detailing what is unclear about the main contribution and the automation aspect. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the main contribution of the paper is unclear and that the proposed method\"s ability or applicability is either overstated or not wellsupported. It also mentions that the main idea of how the proposed method copes with dynamic largescale multitasking is unclear and that the automation aspect is unclear. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of detailed justification or references makes the claim 3, as the authors would need to invest effort to identify and address the issues themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several critical areas where the paper lacks clarity and specificity. It points out that the main contribution of the paper is unclear, questioning the novelty and applicability of the proposed method. Additionally, it highlights that the main idea of how the proposed method copes with dynamic largescale multitasking is not clear, and the automation aspect is also unclear. This feedback is valuable as it directs the authors to specific areas that need further elaboration and clarification. However, the comment could be more helpful if it provided suggestions on how to improve the clarity or offered examples of what additional information would be beneficial. Overall, the comment is 3 as it identifies key areas for improvement but lacks detailed guidance on how to address these issues."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the need to train multiple models to test the approach and suggests exploring unlabelled data or applying constraints to improve model stability. While it implies that the authors should consider these alternatives, it does not provide explicit instructions or concrete steps on how to implement these suggestions. The action is implicit and somewhat vague, as the authors are left to infer the specific changes needed without detailed guidance. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises concerns about the need to train multiple models to test the approach and suggests exploring unlabelled data or applying constraints to improve model stability. However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in suggesting alternative approaches but lacks grounding, as it does not reference any particular part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses a subjective opinion about the need to train multiple models to test the approach, describing it as \"not particularly appealing.\" However, the comment does not provide any supporting evidence, reasoning, or examples to justify this claim. It lacks specific details or references that would help the authors understand the basis of this opinion or how it could be addressed. As a result, the claim is 1, as it does not provide sufficient information for the authors to make improvements based on the feedback. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a concern about the need to train multiple models to test the approach, describing it as \"not particularly appealing.\" It suggests exploring unlabelled data or applying constraints as alternative directions for dealing with churn. While the comment identifies a potential issue and offers a suggestion for improvement, it lacks specific guidance or detailed advice on how to implement these alternatives. The feedback is 3 as it provides a direction for further exploration, but it could be more actionable with additional details or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the experiments for being insufficient, specifically mentioning the limited types of teacher architectures and the fact that most compared methods are proposed before 2019. However, it does not provide any explicit or implicit actions for the authors to take to address these issues. There is no guidance on how to expand the experiments, what additional architectures or methods should be included, or how to improve the comparison. Without specific suggestions or instructions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the experiments for being insufficient, specifically mentioning the limited types of teacher architectures and the fact that most compared methods are proposed before 2019. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the issues with the experiments, such as the limited teacher architectures and the outdated methods being compared. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments are insufficient, specifically mentioning the limited types of teacher architectures and the fact that most compared methods are proposed before 2019. However, the comment does not provide any specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence makes it challenging for the authors to address the feedback effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient support for the authors to fully understand and act upon the critique.", "helpfulness_rationale": "The review comment identifies a specific issue with the experiments, noting that they are insufficient due to limited types of teacher architectures and the fact that most compared methods are proposed before 2019. This feedback is 3 as it points out a potential weakness in the experimental setup, prompting the authors to consider expanding their experiments to include more diverse teacher architectures and uptodate methods. However, the comment lacks detailed guidance or suggestions on how to address these issues, such as which specific architectures or methods should be included or how to improve the comparison. While it provides some direction, the feedback could be more actionable and comprehensive to be fully helpful. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises questions about the comparability of the results in Table 2, specifically regarding the use of different amounts of data in the comparisons. The reviewer suggests that comparisons should be made using the same amount of data, pointing out specific examples where this is not the case. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern or suggest specific actions to take. The authors can infer that they need to ensure consistency in the data used for comparisons, but the comment lacks concrete details on how to implement this change. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the comparability of the results in Table 2, specifically regarding the use of different amounts of data in the comparisons. The comment provides examples of where this issue arises, such as comparing H>N and H>B with H>N+B, and H>N>H with H>N+B>H. This level of detail helps the authors understand what needs to be addressed in the table. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the comparability of results in Table 2, specifically questioning whether the comparisons are made using the same amount of data. The reviewer provides specific examples, such as comparing H>N and H>B with H>N+B, and H>N>H with H>N+B>H, to illustrate the issue. This level of detail and specific examples provide a clear basis for the claim, making it 4. However, the comment could be strengthened by further explaining why this issue is important or how it affects the interpretation of the results. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises a valid concern about the comparability of results in Table 2, specifically questioning whether the comparisons are made using the same amount of data. It provides specific examples, such as comparing H>N and H>B with H>N+B, and H>N>H with H>N+B>H, to illustrate the issue. This feedback is clear and actionable, as it prompts the authors to ensure consistency in the data used for comparisons, which is crucial for accurate analysis and interpretation of the results. However, the comment could be more helpful if it suggested ways to address this issue, such as adjusting the experimental setup or providing additional explanations in the text. Overall, the comment is 4 as it identifies a significant area for improvement and provides specific examples, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the practicality of the work due to the assumption of known causal relationships between features, which might not always be available or accurate for specific subpopulations. The reviewer suggests that most researchers focus on mining causal relationships from data automatically. While the comment highlights a potential limitation and provides a general direction for improvement, it does not offer specific guidance on how the authors might address this issue or what steps they should take to enhance the practicality of their work. The action is implicit and somewhat vague, as the authors are left to infer that they should consider alternative methods or address the issue of prior knowledge availability. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the practicality of using known causal relationships between features, which is a relevant concern for the paper. However, it does not specify which part of the paper discusses this aspect, making it weakly grounded. The comment is specific in its critique of the assumption of known causal relationships and the potential limitations of prior knowledge, particularly for specific subpopulations. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the practicality of the work due to the assumption of known causal relationships between features, which might not always be available or accurate for specific subpopulations. The reviewer suggests that most researchers focus on mining causal relationships from data automatically. While the comment provides a logical reasoning for the concern, it lacks specific examples or references to support the claim about the prevalence of this approach in the field. This makes the claim 3, as it provides a logical basis but requires more detailed evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the practicality of the work, specifically questioning the assumption of known causal relationships between features. It highlights a potential limitation by pointing out that prior knowledge might not always be available or accurate for specific subpopulations. The comment also references a common approach in the field, which is to mine causal relationships from data automatically. While the comment identifies a critical issue, it lacks specific suggestions or guidance on how the authors might address this concern or improve the practicality of their work. The feedback is 3 as it provides insight into a potential limitation, but it could be more actionable with additional guidance or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights several issues with the presentation of empirical findings, including missing axis labels, randomly masked out portions of curves, single seed experiments, and the use of only two smallscale datasets and a single architecture type for core findings. While the comment identifies specific areas that need improvement, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they should add axis labels, clarify the masking of curves, conduct multiple seed experiments, and expand the dataset and architecture types for core findings. However, the lack of concrete guidance on how to implement these changes makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific issues with the figures and empirical results, such as missing axis labels, randomly masked out portions of curves, single seed experiments, and the use of only two smallscale datasets and a single architecture type for core findings. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it details what is lacking in the figures and empirical results, providing clear guidance on how to improve them. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks clarity and confidence in its empirical findings due to issues with the presentation of figures and results. It mentions specific problems, such as missing axis labels, randomly masked out portions of curves, single seed experiments, and the use of only two smallscale datasets and a single architecture type for core findings. While the comment identifies specific areas for improvement, it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to infer the exact nature of the issues and how they impact the confidence in the results. Therefore, the comment is 3, as it provides a general direction but requires more detailed justification to be fully convincing.", "helpfulness_rationale": "The review comment identifies several specific issues with the presentation of empirical findings, such as missing axis labels, randomly masked out portions of curves, and the use of single seed experiments. It also points out that core findings are based on only two smallscale datasets and a single architecture type. These observations are clear and actionable, providing the authors with concrete steps to improve the clarity and confidence in their empirical results. However, the comment could be more helpful by suggesting ways to address these issues, such as recommending the use of multiple seeds or larger datasets. Overall, the feedback is 4 as it directs the authors to specific areas needing improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include comparative experiments with other nonlinear blocks, such as bottleneck in ResNet or linear bottleneck in MobileNetV2, to showcase the unique advantages or potential shortcomings of their proposed method. While the comment implies that the authors should conduct these experiments, it does not provide specific guidance on how to implement them or what specific comparisons should be made. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by suggesting the inclusion of comparative experiments with other nonlinear blocks, such as bottleneck in ResNet or linear bottleneck in MobileNetV2, to showcase the unique advantages or potential shortcomings of the proposed method. This provides clear guidance on what needs to be addressed in the section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper lacks comparative experiments with other nonlinear blocks, such as bottleneck in ResNet or linear bottleneck in MobileNetV2, to showcase the unique advantages or potential shortcomings of the proposed method. This claim is 3 as it provides a logical reasoning for the need to include such comparisons to better understand the method\"s performance in a broader context. However, the comment lacks specific examples or references to existing works that have conducted similar comparisons, which would strengthen the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the lack of comparative experiments with other nonlinear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2. This feedback is clear and actionable, as it suggests that including such comparisons could showcase the unique advantages or potential shortcomings of the proposed method in a broader context. By highlighting this gap, the comment provides the authors with a concrete direction for enhancing the comprehensiveness and robustness of their experimental evaluation. However, the comment could be more helpful if it offered specific suggestions on which blocks to compare or how to conduct these experiments. Overall, the feedback is 4 as it directs the authors toward a meaningful improvement in their draft."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the discussion around equation (10) is terse and not clearly explained. However, it does not provide any explicit or implicit suggestions on how to improve the explanation or what specific aspects need clarification. Without guidance on how to enhance the clarity or what additional information should be included, the authors are left without a clear understanding of what changes are needed. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"equation (10),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the terseness and lack of clarity in the discussion around equation (10). This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the discussion around equation (10) is terse and not clearly explained. However, it does not provide any specific examples or detailed reasoning to support this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the discussion around equation (10), noting that it is terse and not clearly explained. This feedback is 3 as it points out a potential area for improvement in the paper. However, it lacks depth and does not provide specific suggestions or guidance on how to enhance the clarity of the discussion. Without actionable advice, the authors may struggle to determine exactly what changes are needed to improve the explanation. Therefore, the comment is rated as 3, aligning with a score of 3."}
